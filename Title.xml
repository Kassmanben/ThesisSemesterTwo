<?xml version = "1.0" encoding = "UTF-8"?><?xml-stylesheet type = "text/css" href = "daisy.css" media = "screen" ?><?xml-stylesheet type = "text/xsl" href = "daisyTransform.xsl" media = "screen" ?><!DOCTYPE dtbook SYSTEM "dtbook-2005-3.dtd"><dtbook xmlns="http://www.w3.org/2001/SMIL20/"><head><meta content="Title" name="dc:Title" /><meta content="Jane Doe, Arnold, Karen" name="dc:TitleCreator" /><meta content="Publisher" name="dc:TitleCreatorPublisher" /><meta content="2018" name="dc:TitleCreatorPublisherDate" /><meta content="12341234" name="dc:TitleCreatorPublisherDateIdentifier" /><meta content="Default" name="dc:TitleCreatorPublisherDateIdentifierFormat" /><meta content="EN" name="dc:TitleCreatorPublisherDateIdentifierFormatLanguage" /><meta content="text" name="dtb:multimediaType" /><meta content="text" name="dtb:multimediaTypemultimediaContent" /><meta content="00:00:00" name="dtb:multimediaTypemultimediaContenttotalTime" /><meta content="12341234" name="dtb:multimediaTypemultimediaContenttotalTimeuid" /></head><book id="12341234"><frontmatter id="frontmatter_00000"><doctitle id="doctitle_00000">Title</doctitle><docauthor id="docauthor_00000">Jane Doe</docauthor><docauthor id="docauthor_00001">Arnold</docauthor><docauthor id="docauthor_00002">Karen</docauthor><level1 id="toc" /><level1 id="pref"><pagenum id="p10" page="normal" smilref="Title.smil#p10" /><p attribs="{'xml:space': 'preserve'}" id="_00000" smilref="Title.smil#_00000"> PREFACE</p><p attribs="{'xml:space': 'preserve'}" id="_00001" smilref="Title.smil#_00001"> This book is intended to survey the most important computer algorithms in use today, and to teach fundamental techniques to the growing number of people in need of knowing them. It is intended for use as a textbook for a second course in computer science, after students have acquired basic programming skills and familiarity with computer systems. The book also may be useful for self-study or as a reference for people engaged in the development of computer systems or applications programs, since it contains implementations of useful algorithms and detailed information on performance characteristics and clients. The broad perspective taken makes the book an appropriate introduction to the fi eld.</p><p attribs="{'xml:space': 'preserve'}" id="_00002" smilref="Title.smil#_00002"> th e study o f a lgor ithm s and data structure s is fundamental to any computer-</p><p attribs="{'xml:space': 'preserve'}" id="_00003" smilref="Title.smil#_00003"> science curriculum, but it is not just for programmers and computer-science students. Every- one who uses a computer wants it to run faster or to solve larger problems. The algorithms in this book represent a body of knowledge developed over the last 50 years that has become indispensable. From N-body simulation problems in physics to genetic-sequencing problems in molecular biology, the basic methods described here have become essential in scientific research; from architectural modeling systems to aircraft simulation, they have become essential tools in engineering; and from database systems to internet search engines, they have become essential parts of modern software systems. And these are but a few examples&#8212;as the scope of computer applications continues to grow, so grows the impact of the basic methods covered here. Before developing our fundamental approach to studying algorithms, we develop data types for stacks, queues, and other low-level abstractions that we use throughout the book. Then we survey fundamental algorithms for sorting, searching, graphs, and strings. The last chapter is an overview placing the rest of the material in the book in a larger context.</p><p attribs="{'xml:space': 'preserve'}" id="_00004" smilref="Title.smil#_00004"> ix</p><p attribs="{'xml:space': 'preserve'}" id="_00005" smilref="Title.smil#_00005" /></level1></frontmatter><bodymatter id="bodymatter_00000"><level1 id="ch1"><section epub:type="chapter" id="section_00000"><header id="header_00000"><pagenum epub:type="pagebreak" id="p15" page="normal" smilref="Title.smil#p15" /><h1 id="ch1-start" smilref="Title.smil#ch1-start" xml:space="preserve">1 Fundamentals</h1></header></section><pagenum id="p15" page="normal" smilref="Title.smil#p15" /><p attribs="{'xml:space': 'preserve'}" id="_00006" smilref="Title.smil#_00006"> O N E</p><p attribs="{'xml:space': 'preserve'}" id="_00007" smilref="Title.smil#_00007"> Fundamentals</p><p attribs="{'xml:space': 'preserve'}" id="_00008" smilref="Title.smil#_00008"> 1.1 Basic Programming Model. . . . . . . . . 8 1.2 Data Abstraction . . . . . . . . . . . . . . 64 1.3 Bags, Queues, and Stacks . . . . . . . 120 1.4 Analysis of Algorithms . . . . . . . . . 172 1.5 Case Study : Union-Find. . . . . . . . . 216</p><p attribs="{'xml:space': 'preserve'}" id="_00009" smilref="Title.smil#_00009" /><pagenum id="p16" page="normal" smilref="Title.smil#p16" /><p attribs="{'xml:space': 'preserve'}" id="_00010" smilref="Title.smil#_00010"> The objective of this book is to study a broad variety of important and useful algorithms&#8212;methods for solving problems that are suited for computer imple- mentation. Algorithms go hand in hand with data structures&#8212;schemes for organizing data that leave them amenable to efficient processing by an algorithm. This chapter introduces the basic tools that we need to study algorithms and data structures. First, we introduce our basic programming model. All of our programs are implemented using a small subset of the Java programming language plus a few of our own libraries for input/output and for statistical calculations. Section 1.1 is a summary of language constructs, features, and libraries that we use in this book. Next, we emphasize data abstraction, where we define abstract data types (ADTs) in the service of modular programming. In Section 1.2 we introduce the process of implementing an ADT in Java, by specifying an applications programming interface (API) and then using the Java class mechanism to develop an implementation for use in client code. As important and useful examples, we next consider three fundamental ADTs: the bag, the queue, and the stack. Section 1.3 describes APIs and implementations of bags, queues, and stacks using arrays, resizing arrays, and linked lists that serve as models and starting points for algorithm implementations throughout the book. Performance is a central consideration in the study of algorithms. Section 1.4 describes our approach to analyzing algorithm performance. The basis of our approach is the scientific method: we develop hypotheses about performance, create mathematical models, and run experiments to test them, repeating the process as necessary. We conclude with a case study where we consider solutions to a connectivity problem that uses algorithms and data structures that implement the classic union-&#64257; nd ADT.</p><p attribs="{'xml:space': 'preserve'}" id="_00011" smilref="Title.smil#_00011"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_00012" smilref="Title.smil#_00012" /><pagenum id="p17" page="normal" smilref="Title.smil#p17" /><p attribs="{'xml:space': 'preserve'}" id="_00013" smilref="Title.smil#_00013"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_00014" smilref="Title.smil#_00014"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00015" smilref="Title.smil#_00015"> Algorithms When we write a computer program, we are generally implementing a method that has been devised previously to solve some problem. This method is often independent of the particular programming language being used&#8212;it is likely to be equally appropriate for many computers and many programming languages. It is the method, rather than the computer program itself, that specifies the steps that we can take to solve the problem. The term algorithm is used in computer science to describe a fi nite, deterministic, and effective problem-solving method suitable for implementation as a computer program. Algorithms are the stuff of computer science: they are central objects of study in the fi eld. We can define an algorithm by describing a procedure for solving a problem in a natural language, or by writing a computer program that implements the procedure, as shown at right for Euclid&#8217;s algorithm for finding the greatest common divisor of two numbers, a variant of which was devised over 2,300 years ago. If you are not familiar with Euclid&#8217;s algorithm, you are encour-</p><p attribs="{'xml:space': 'preserve'}" id="_00016" smilref="Title.smil#_00016"> English-language description</p><p attribs="{'xml:space': 'preserve'}" id="_00017" smilref="Title.smil#_00017"> aged to work Exercise 1.1.24 and Exercise</p><p attribs="{'xml:space': 'preserve'}" id="_00018" smilref="Title.smil#_00018"> Compute the greatest common divisor of two nonnegative integers p and q as follows: If q is 0, the answer is p. If not, divide p by q and take the remainder r. The answer is the greatest common divisor of q and r.</p><p attribs="{'xml:space': 'preserve'}" id="_00019" smilref="Title.smil#_00019"> Java-language description</p><p attribs="{'xml:space': 'preserve'}" id="_00020" smilref="Title.smil#_00020"> public static int gcd(int p, int q) { if (q == 0) return p; int r = p % q; return gcd(q, r); }</p><p attribs="{'xml:space': 'preserve'}" id="_00021" smilref="Title.smil#_00021"> 1.1.25, perhaps after reading Section 1.1. In this book, we use computer programs to describe algorithms. One important reason for doing so is that it makes easier the task of checking whether they are fi nite, determin- istic, and effective, as required. But it is also important to recognize that a program in a particular language is just one way to express an algorithm. The fact that many of the algorithms in this book have been expressed in multiple programming languages over the past several decades reinforces the idea that each algorithm is a method suitable for implementation on any computer in any programming language. Most algorithms of interest involve organizing the data involved in the computa- tion. Such organization leads to data structures, which also are central objects of study in computer science. Algorithms and data structures go hand in hand. In this book we take the view that data structures exist as the byproducts or end products of algorithms and that we must therefore study them in order to understand the algorithms. Simple algorithms can give rise to complicated data structures and, conversely, complicated algorithms can use simple data structures. We shall study the properties of many data structures in this book; indeed, we might well have titled the book Algorithms and Data Structures.</p><p attribs="{'xml:space': 'preserve'}" id="_00022" smilref="Title.smil#_00022"> Euclid&#8217;s algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_00023" smilref="Title.smil#_00023" /><pagenum id="p18" page="normal" smilref="Title.smil#p18" /><p attribs="{'xml:space': 'preserve'}" id="_00024" smilref="Title.smil#_00024"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00025" smilref="Title.smil#_00025"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_00026" smilref="Title.smil#_00026"> When we use a computer to help us solve a problem, we typically are faced with a number of possible approaches. For small problems, it hardly matters which approach we use, as long as we have one that correctly solves the problem. For huge problems (or applications where we need to solve huge numbers of small problems), however, we quickly become motivated to devise methods that use time and space ef&#64257; ciently. The primary reason to learn about algorithms is that this discipline gives us the potential to reap huge savings, even to the point of enabling us to do tasks that would otherwise be impossible. In an application where we are processing millions of objects, it is not unusual to be able to make a program millions of times faster by using a well- designed algorithm. We shall see such examples on numerous occasions throughout the book. By contrast, investing additional money or time to buy and install a new computer holds the potential for speeding up a program by perhaps a factor of only 10 or 100. Careful algorithm design is an extremely effective part of the process of solving a huge problem, whatever the applications area. When developing a huge or complex computer program, a great deal of effort must go into understanding and defining the problem to be solved, managing its complex- ity, and decomposing it into smaller subtasks that can be implemented easily. Often, many of the algorithms required after the decomposition are trivial to implement. In most cases, however, there are a few algorithms whose choice is critical because most of the system resources will be spent running those algorithms. These are the types of algorithms on which we concentrate in this book. We study fundamental algorithms that are useful for solving challenging problems in a broad variety of applications areas. The sharing of programs in computer systems is becoming more widespread, so although we might expect to be using a large fraction of the algorithms in this book, we also might expect to have to implement only a small fraction of them. For example, the Java libraries contain implementations of a host of fundamental algorithms. However, implementing simple versions of basic algorithms helps us to understand them better and thus to more effectively use and tune advanced versions from a library. More important, the opportunity to reimplement basic algorithms arises frequently. The primary reason to do so is that we are faced, all too often, with completely new computing environments (hardware and software) with new features that old implementations may not use to best advantage. In this book, we concentrate on the simplest reasonable implementations of the best algorithms. We do pay careful attention to coding the critical parts of the algorithms, and take pains to note where low-level optimization effort could be most bene&#64257; cial. The choice of the best algorithm for a particular task can be a complicated process, perhaps involving sophisticated mathematical analysis. The branch of computer science that comprises the study of such questions is called analysis of algorithms. Many</p><p attribs="{'xml:space': 'preserve'}" id="_00027" smilref="Title.smil#_00027" /><pagenum id="p19" page="normal" smilref="Title.smil#p19" /><p attribs="{'xml:space': 'preserve'}" id="_00028" smilref="Title.smil#_00028"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_00029" smilref="Title.smil#_00029"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00030" smilref="Title.smil#_00030"> of the algorithms that we study have been shown through analysis to have excellent theoretical performance; others are simply known to work well through experience. Our primary goal is to learn reasonable algorithms for important tasks, yet we shall also pay careful attention to comparative performance of the methods. We should not use an algorithm without having an idea of what resources it might consume, so we strive to be aware of how our algorithms might be expected to perform.</p><p attribs="{'xml:space': 'preserve'}" id="_00031" smilref="Title.smil#_00031"> Summary of topics As an overview, we describe the major parts of the book, giving specific topics covered and an indication of our general orientation toward the material. This set of topics is intended to touch on as many fundamental algorithms as possible. Some of the areas covered are core computer-science areas that we study in depth to learn basic algorithms of wide applicability. Other algorithms that we discuss are from advanced fields of study within computer science and related fi elds. The algorithms that we consider are the products of decades of research and development and continue to play an essential role in the ever-expanding applications of computation. Fundamentals (Chapter 1) in the context of this book are the basic principles and methodology that we use to implement, analyze, and compare algorithms. We consider our Java programming model, data abstraction, basic data structures, abstract data types for collections, methods of analyzing algorithm performance, and a case study. Sorting algorithms (Chapter 2) for rearranging arrays in order are of fundamental importance. We consider a variety of algorithms in considerable depth, including insertion sort, selection sort, shellsort, quicksort, mergesort, and heapsort. We also encounter algorithms for several related problems, including priority queues, selection, and merging. Many of these algorithms will find application as the basis for other algorithms later in the book. Searching algorithms (Chapter 3) for finding specific items among large collections of items are also of fundamental importance. We discuss basic and advanced methods for searching, including binary search trees, balanced search trees, and hashing. We note relationships among these methods and compare performance. Graphs (Chapter 4) are sets of objects and connections, possibly with weights and orientation. Graphs are useful models for a vast number of difficult and important problems, and the design of algorithms for processing graphs is a major field of study. We consider depth-&#64257; rst search, breadth-&#64257; rst search, connectivity problems, and several algorithms and applications, including Kruskal&#8217;s and Prim&#8217;s algorithms for finding minimum spanning tree and Dijkstra&#8217;s and the Bellman-Ford algorithms for solving shortest-paths problems.</p><p attribs="{'xml:space': 'preserve'}" id="_00032" smilref="Title.smil#_00032" /><pagenum id="p20" page="normal" smilref="Title.smil#p20" /><p attribs="{'xml:space': 'preserve'}" id="_00033" smilref="Title.smil#_00033"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00034" smilref="Title.smil#_00034"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_00035" smilref="Title.smil#_00035"> Strings (Chapter 5) are an essential data type in modern computing applications. We consider a range of methods for processing sequences of characters. We begin with faster algorithms for sorting and searching when keys are strings. Then we consider substring search, regular expression pattern matching, and data-compression algo- rithms. Again, an introduction to advanced topics is given through treatment of some elementary problems that are important in their own right. Context (Chapter 6) helps us relate the material in the book to several other advanced fields of study, including scientific computing, operations research, and the theory of computing. We survey event-driven simulation, B-trees, suffix arrays, maximum fl ow, and other advanced topics from an introductory viewpoint to develop appreciation for the interesting advanced fields of study where algorithms play a critical role. Finally, we describe search problems, reduction, and NP-completeness to introduce the theoretical underpinnings of the study of algorithms and relationships to material in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_00036" smilref="Title.smil#_00036"> The study of algorithms is interesting and exciting because it is a new field</p><p attribs="{'xml:space': 'preserve'}" id="_00037" smilref="Title.smil#_00037"> (almost all the algorithms that we study are less than 50 years old, and some were just recently discovered) with a rich tradition (a few algorithms have been known for hundreds of years). New discoveries are constantly being made, but few algorithms are completely understood. In this book we shall consider intricate, complicated, and dif&#64257; cult algorithms as well as elegant, simple, and easy ones. Our challenge is to understand the former and to appreciate the latter in the context of scientific and commercial ap- plications. In doing so, we shall explore a variety of useful tools and develop a style of algorithmic thinking that will serve us well in computational challenges to come.</p><p attribs="{'xml:space': 'preserve'}" id="_00038" smilref="Title.smil#_00038" /><pagenum id="p22" page="normal" smilref="Title.smil#p22" /><p attribs="{'xml:space': 'preserve'}" id="_00039" smilref="Title.smil#_00039"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00040" smilref="Title.smil#_00040"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_00041" smilref="Title.smil#_00041"> import a Java library (see page 27)</p><p attribs="{'xml:space': 'preserve'}" id="_00042" smilref="Title.smil#_00042"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_00043" smilref="Title.smil#_00043"> code must be in file BinarySearch.java (see page 26)</p><p attribs="{'xml:space': 'preserve'}" id="_00044" smilref="Title.smil#_00044"> parameter variables</p><p attribs="{'xml:space': 'preserve'}" id="_00045" smilref="Title.smil#_00045"> static method (see page 22)</p><p attribs="{'xml:space': 'preserve'}" id="_00046" smilref="Title.smil#_00046"> initializing declaration statement (see page 16)</p><p attribs="{'xml:space': 'preserve'}" id="_00047" smilref="Title.smil#_00047"> loop statement (see page 15)</p><p attribs="{'xml:space': 'preserve'}" id="_00048" smilref="Title.smil#_00048"> return type</p><p attribs="{'xml:space': 'preserve'}" id="_00049" smilref="Title.smil#_00049"> parameter type</p><p attribs="{'xml:space': 'preserve'}" id="_00050" smilref="Title.smil#_00050"> public class BinarySearch { public static int rank(int key, int[] a) { int lo = 0; int hi = a.length - 1; while (lo &lt;= hi) { int mid = lo + (hi - lo) / 2; if (key &lt; a[mid]) hi = mid - 1; else if (key &gt; a[mid]) lo = mid + 1; else return mid; } return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_00051" smilref="Title.smil#_00051"> expression (see page 11)</p><p attribs="{'xml:space': 'preserve'}" id="_00052" smilref="Title.smil#_00052"> return statement</p><p attribs="{'xml:space': 'preserve'}" id="_00053" smilref="Title.smil#_00053"> system calls main()</p><p attribs="{'xml:space': 'preserve'}" id="_00054" smilref="Title.smil#_00054"> unit test client (see page 26)</p><p attribs="{'xml:space': 'preserve'}" id="_00055" smilref="Title.smil#_00055"> public static void main(String[] args) {</p><p attribs="{'xml:space': 'preserve'}" id="_00056" smilref="Title.smil#_00056"> no return value; just side effects (see page 24)</p><p attribs="{'xml:space': 'preserve'}" id="_00057" smilref="Title.smil#_00057"> int[] whitelist = In.readInts(args[0]);</p><p attribs="{'xml:space': 'preserve'}" id="_00058" smilref="Title.smil#_00058"> Arrays.sort(whitelist);</p><p attribs="{'xml:space': 'preserve'}" id="_00059" smilref="Title.smil#_00059"> call a method in a Java library (see page 27)</p><p attribs="{'xml:space': 'preserve'}" id="_00060" smilref="Title.smil#_00060"> conditional statement (see page 15)</p><p attribs="{'xml:space': 'preserve'}" id="_00061" smilref="Title.smil#_00061"> while (!StdIn.isEmpty()) { int key = StdIn.readInt(); if (rank(key, whitelist) == -1) StdOut.println(key); } }</p><p attribs="{'xml:space': 'preserve'}" id="_00062" smilref="Title.smil#_00062"> call a method in our standard library; need to download code (see page 27)</p><p attribs="{'xml:space': 'preserve'}" id="_00063" smilref="Title.smil#_00063"> call a local method (see page 27)</p><p attribs="{'xml:space': 'preserve'}" id="_00064" smilref="Title.smil#_00064"> }</p><p attribs="{'xml:space': 'preserve'}" id="_00065" smilref="Title.smil#_00065"> command line (see page 36)</p><p attribs="{'xml:space': 'preserve'}" id="_00066" smilref="Title.smil#_00066"> system passes argument value "largeW.txt" to main()</p><p attribs="{'xml:space': 'preserve'}" id="_00067" smilref="Title.smil#_00067"> file name (args[0])</p><p attribs="{'xml:space': 'preserve'}" id="_00068" smilref="Title.smil#_00068"> StdOut (see page 37)</p><p attribs="{'xml:space': 'preserve'}" id="_00069" smilref="Title.smil#_00069"> % java BinarySearch largeW.txt &lt; largeT.txt 499569 984875 ...</p><p attribs="{'xml:space': 'preserve'}" id="_00070" smilref="Title.smil#_00070"> file redirected from StdIn (see page 40)</p><p attribs="{'xml:space': 'preserve'}" id="_00071" smilref="Title.smil#_00071"> Anatomy of a Java program and its invocation from the command line</p><p attribs="{'xml:space': 'preserve'}" id="_00072" smilref="Title.smil#_00072" /><pagenum id="p23" page="normal" smilref="Title.smil#p23" /><p attribs="{'xml:space': 'preserve'}" id="_00073" smilref="Title.smil#_00073"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_00074" smilref="Title.smil#_00074"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00075" smilref="Title.smil#_00075"> Basic structure of a Java program</p><p attribs="{'xml:space': 'preserve'}" id="_00076" smilref="Title.smil#_00076"> A Java program ( class) is either a library of static methods (functions) or a data type defi nition. To create libraries of static methods and data-type defi nitions, we use the following seven components, the basis of programming in Java and many other modern languages: </p><p attribs="{'xml:space': 'preserve'}" id="_00077" smilref="Title.smil#_00077"> javac BinarySearch.java (which creates a file BinarySearch.class that contains</p><p attribs="{'xml:space': 'preserve'}" id="_00078" smilref="Title.smil#_00078"> a lower-level version of the program in Java bytecode in the file BinarySearch.class). Then we type java BinarySearch (followed by a whitelist file name) to transfer control to the bytecode version of the program. To develop a basis for understanding the effect of these actions, we next consider in detail primitive data types and expressions, the various kinds of Java statements, arrays, static methods, strings, and input/output.</p><p attribs="{'xml:space': 'preserve'}" id="_00079" smilref="Title.smil#_00079" /><level3 id="_00000"><h3 id="ch1-s1-ss1" smilref="Title.smil#ch1-s1-ss1" xml:space="preserve">Primitive data types</h3><pagenum id="p24" page="normal" smilref="Title.smil#p24" /><p attribs="{'xml:space': 'preserve'}" id="_00080" smilref="Title.smil#_00080"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00081" smilref="Title.smil#_00081"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_00082" smilref="Title.smil#_00082"> Primitive data types and expressions A data type is a set of values and a set of operations on those values. We begin by considering the following four primitive data types that are the basis of the Java language: </p><p attribs="{'xml:space': 'preserve'}" id="_00083" smilref="Title.smil#_00083"> term</p><p attribs="{'xml:space': 'preserve'}" id="_00084" smilref="Title.smil#_00084"> primitive data type</p><p attribs="{'xml:space': 'preserve'}" id="_00085" smilref="Title.smil#_00085"> identifier </p><p attribs="{'xml:space': 'preserve'}" id="_00086" smilref="Title.smil#_00086"> variable</p><p attribs="{'xml:space': 'preserve'}" id="_00087" smilref="Title.smil#_00087"> operator</p><p attribs="{'xml:space': 'preserve'}" id="_00088" smilref="Title.smil#_00088"> literal</p><p attribs="{'xml:space': 'preserve'}" id="_00089" smilref="Title.smil#_00089"> examples</p><p attribs="{'xml:space': 'preserve'}" id="_00090" smilref="Title.smil#_00090"> definition</p><p attribs="{'xml:space': 'preserve'}" id="_00091" smilref="Title.smil#_00091"> int double boolean char</p><p attribs="{'xml:space': 'preserve'}" id="_00092" smilref="Title.smil#_00092"> a abc Ab$ a_b ab123 lo hi</p><p attribs="{'xml:space': 'preserve'}" id="_00093" smilref="Title.smil#_00093"> [any identifi er]</p><p attribs="{'xml:space': 'preserve'}" id="_00094" smilref="Title.smil#_00094"> + - * /</p><p attribs="{'xml:space': 'preserve'}" id="_00095" smilref="Title.smil#_00095"> a set of values and a set of operations on those values (built in to the Java language)</p><p attribs="{'xml:space': 'preserve'}" id="_00096" smilref="Title.smil#_00096"> a sequence of letters, digits, _, and $, the first of which is not a digit</p><p attribs="{'xml:space': 'preserve'}" id="_00097" smilref="Title.smil#_00097"> names a data-type value</p><p attribs="{'xml:space': 'preserve'}" id="_00098" smilref="Title.smil#_00098"> names a data-type operation</p><p attribs="{'xml:space': 'preserve'}" id="_00099" smilref="Title.smil#_00099"> int double boolean char</p><p attribs="{'xml:space': 'preserve'}" id="_00100" smilref="Title.smil#_00100"> 1 0 -42 2.0 1.0e-15 3.14 true false 'a' '+' '9' '\n'</p><p attribs="{'xml:space': 'preserve'}" id="_00101" smilref="Title.smil#_00101"> source-code representation of a value</p><p attribs="{'xml:space': 'preserve'}" id="_00102" smilref="Title.smil#_00102"> expression</p><p attribs="{'xml:space': 'preserve'}" id="_00103" smilref="Title.smil#_00103"> int double boolean</p><p attribs="{'xml:space': 'preserve'}" id="_00104" smilref="Title.smil#_00104"> lo + (hi - lo)/2 1.0e-15 * t lo &lt;= hi</p><p attribs="{'xml:space': 'preserve'}" id="_00105" smilref="Title.smil#_00105"> a literal, a variable, or a sequence of operations on literals and/or variables that produces a value</p><p attribs="{'xml:space': 'preserve'}" id="_00106" smilref="Title.smil#_00106"> Basic building blocks for Java programs</p><p attribs="{'xml:space': 'preserve'}" id="_00107" smilref="Title.smil#_00107" /><pagenum id="p25" page="normal" smilref="Title.smil#p25" /><p attribs="{'xml:space': 'preserve'}" id="_00108" smilref="Title.smil#_00108"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_00109" smilref="Title.smil#_00109"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00110" smilref="Title.smil#_00110"> To define a data type, we need only specify the values and the set of operations on those values. This information is summarized in the table below for Java&#8217;s int, double, boolean, and char data types. These data types are similar to the basic data types found in many programming languages. For int and double, the operations are familiar arithmetic operations; for boolean, they are familiar logical operations. It is important to note that +, -, *, and / are overloaded&#8212;the same symbol specifies operations in multiple different types, depending on context. The key property of these primitive operations is that an operation involving values of a given type has a value of that type. This rule highlights the idea that we are often working with approximate values, since it is often the case that the exact value that would seem to be defined by the expression is not a value of the type. For example, 5/3 has the value 1 and 5.0/3.0 has a value very close to 1.66666666666667 but neither of these is exactly equal to 5/3. This table is far from complete; we discuss some additional operators and various exceptional situations that we occasionally need to consider in the Q&amp;A at the end of this section.</p><p attribs="{'xml:space': 'preserve'}" id="_00111" smilref="Title.smil#_00111"> type</p><p attribs="{'xml:space': 'preserve'}" id="_00112" smilref="Title.smil#_00112"> set of values</p><p attribs="{'xml:space': 'preserve'}" id="_00113" smilref="Title.smil#_00113"> operators</p><p attribs="{'xml:space': 'preserve'}" id="_00114" smilref="Title.smil#_00114"> int</p><p attribs="{'xml:space': 'preserve'}" id="_00115" smilref="Title.smil#_00115"> double</p><p attribs="{'xml:space': 'preserve'}" id="_00116" smilref="Title.smil#_00116"> integers between</p><p attribs="{'xml:space': 'preserve'}" id="_00117" smilref="Title.smil#_00117"> &#11002;231 and&#11001;231&#11002; 1</p><p attribs="{'xml:space': 'preserve'}" id="_00118" smilref="Title.smil#_00118"> (32-bit two&#8217;s complement)</p><p attribs="{'xml:space': 'preserve'}" id="_00119" smilref="Title.smil#_00119"> double-precision real numbers (64-bit IEEE 754 standard)</p><p attribs="{'xml:space': 'preserve'}" id="_00120" smilref="Title.smil#_00120"> boolean</p><p attribs="{'xml:space': 'preserve'}" id="_00121" smilref="Title.smil#_00121"> true or false</p><p attribs="{'xml:space': 'preserve'}" id="_00122" smilref="Title.smil#_00122"> + (add) - (subtract) * (multiply) / (divide) % (remainder)</p><p attribs="{'xml:space': 'preserve'}" id="_00123" smilref="Title.smil#_00123"> + (add) - (subtract) * (multiply) / (divide)</p><p attribs="{'xml:space': 'preserve'}" id="_00124" smilref="Title.smil#_00124"> &amp;&amp; (and) || (or) ! (not) ^ (xor)</p><p attribs="{'xml:space': 'preserve'}" id="_00125" smilref="Title.smil#_00125"> typical expressions expression</p><p attribs="{'xml:space': 'preserve'}" id="_00126" smilref="Title.smil#_00126"> value</p><p attribs="{'xml:space': 'preserve'}" id="_00127" smilref="Title.smil#_00127"> 5 + 3 5 - 3 5 * 3 5 / 3 5 % 3</p><p attribs="{'xml:space': 'preserve'}" id="_00128" smilref="Title.smil#_00128"> 8 2 15 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_00129" smilref="Title.smil#_00129"> 3.141 - .03 2.0 - 2.0e-7 100 * .015 6.02e23 / 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_00130" smilref="Title.smil#_00130"> true &amp;&amp; false false || true !false true ^ true</p><p attribs="{'xml:space': 'preserve'}" id="_00131" smilref="Title.smil#_00131"> 3.111 1.9999998 1.5 3.01e23</p><p attribs="{'xml:space': 'preserve'}" id="_00132" smilref="Title.smil#_00132"> false true true false</p><p attribs="{'xml:space': 'preserve'}" id="_00133" smilref="Title.smil#_00133"> char</p><p attribs="{'xml:space': 'preserve'}" id="_00134" smilref="Title.smil#_00134"> characters (16-bit)</p><p attribs="{'xml:space': 'preserve'}" id="_00135" smilref="Title.smil#_00135"> [arithmetic operations, rarely used]</p><p attribs="{'xml:space': 'preserve'}" id="_00136" smilref="Title.smil#_00136"> Primitive data types in Java</p><p attribs="{'xml:space': 'preserve'}" id="_00137" smilref="Title.smil#_00137" /><pagenum id="p26" page="normal" smilref="Title.smil#p26" /><p attribs="{'xml:space': 'preserve'}" id="_00138" smilref="Title.smil#_00138"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00139" smilref="Title.smil#_00139"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_00140" smilref="Title.smil#_00140"> Expressions. As illustrated in the table at the bottom of the previous page, typical expressions are in&#64257; x: a literal (or an expression), followed by an operator, followed by another literal (or another expression). When an expression contains more than one operator, the order in which they are applied is often signi&#64257; cant, so the following precedence conventions are part of the Java language speci&#64257; cation: The operators * and / ( and %) have higher precedence than (are applied before) the + and - operators; among logical operators, ! is the highest precedence, followed by &amp;&amp; and then ||. Generally, operators of the same precedence are applied left to right. As in standard arithmetic ex- pressions, you can use parentheses to override these rules. Since precedence rules vary slightly from language to language, we use parentheses and otherwise strive to avoid dependence on precedence rules in our code.</p><p attribs="{'xml:space': 'preserve'}" id="_00141" smilref="Title.smil#_00141"> Type conversion. Numbers are automatically promoted to a more inclusive type if no information is lost. For example, in the expression 1 + 2.5 , the 1 is promoted to the double value 1.0 and the expression evaluates to the double value 3.5 . A cast is a type name in parentheses within an expression, a directive to convert the following value into a value of that type. For example (int) 3.7 is 3 and (double) 3 is 3.0. Note that casting to an int is truncation instead of rounding&#8212;rules for casting within complicated expressions can be intricate, and casts should be used sparingly and with care. A best practice is to use expressions that involve literals or variables of a single type.</p><p attribs="{'xml:space': 'preserve'}" id="_00142" smilref="Title.smil#_00142"> Comparisons. The following operators compare two values of the same type and produce a boolean value: equal (==), not equal (!=), less than (&lt;), less than or equal (&lt;=), greater than (&gt;), and greater than or equal (&gt;=). These operators are known as mixed-type operators because their value is boolean, not the type of the values being compared. An expression with a boolean value is known as a boolean expression. Such expressions are essential components in conditional and loop statements, as we will see.</p><p attribs="{'xml:space': 'preserve'}" id="_00143" smilref="Title.smil#_00143"> Other primitive types. Java&#8217;s int has 232 different values by design, so it can be represented in a 32-bit machine word (many machines have 64-bit words nowadays, but the 32-bit int persists). Similarly, the double standard specifies a 64-bit representation. These data-type sizes are adequate for typical applications that use integers and real numbers. To provide fl exibility, Java has five additional primitive data types: </p><p attribs="{'xml:space': 'preserve'}" id="_00144" smilref="Title.smil#_00144" /><pagenum id="p27" page="normal" smilref="Title.smil#p27" /><p attribs="{'xml:space': 'preserve'}" id="_00145" smilref="Title.smil#_00145"> 14</p><p attribs="{'xml:space': 'preserve'}" id="_00146" smilref="Title.smil#_00146"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00147" smilref="Title.smil#_00147"> Statements A Java program is composed of statements, which define the computation by creating and manipulating variables, assigning data-type values to them, and controlling the flow of execution of such operations. Statements are often organized in blocks, sequences of statements within curly braces. </p><p attribs="{'xml:space': 'preserve'}" id="_00148" smilref="Title.smil#_00148"> Declarations. A declaration statement associates a variable name with a type at compile time. Java requires us to use declarations to specify the names and types of vari- ables. By doing so, we are being explicit about any computation that we are specify- ing. Java is said to be a strongly typed language, because the Java compiler checks for consistency (for example, it does not permit us to multiply a boolean and a double). Declarations can appear anywhere before a variable is first used&#8212;most often, we put them at the point of first use. The scope of a variable is the part of the program where it is defi ned. Generally the scope of a variable is composed of the statements that follow the declaration in the same block as the declaration.</p><p attribs="{'xml:space': 'preserve'}" id="_00149" smilref="Title.smil#_00149"> Assignments. An assignment statement associates a data-type value (de&#64257; ned by an ex- pression) with a variable. When we write c = a + b in Java, we are not expressing mathematical equality, but are instead expressing an action: set the value of the variable c to be the value of a plus the value of b. It is true that c is mathematically equal to a + b immediately after the assignment statement has been executed, but the point of the statement is to change the value of c (if necessary). The left-hand side of an assignment statement must be a single variable; the right-hand side can be an arbitrary expression that produces a value of the type.</p><p attribs="{'xml:space': 'preserve'}" id="_00150" smilref="Title.smil#_00150" /></level3><level3 id="_00001"><h3 id="ch1-s1-ss2" smilref="Title.smil#ch1-s1-ss2" xml:space="preserve">Loops and conditionals</h3><pagenum id="p28" page="normal" smilref="Title.smil#p28" /><p attribs="{'xml:space': 'preserve'}" id="_00151" smilref="Title.smil#_00151"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00152" smilref="Title.smil#_00152"> 15</p><p attribs="{'xml:space': 'preserve'}" id="_00153" smilref="Title.smil#_00153"> Conditionals. Most computations require different actions for different inputs. One way to express these differences in Java is the if statement:</p><p attribs="{'xml:space': 'preserve'}" id="_00154" smilref="Title.smil#_00154"> if (&lt;boolean expression&gt;) { &lt;block statements&gt; }</p><p attribs="{'xml:space': 'preserve'}" id="_00155" smilref="Title.smil#_00155"> This description introduces a formal notation known as a template that we use occasionally to specify the format of Java constructs. We put within angle brackets (&lt; &gt;) a construct that we have already defi ned, to indicate that we can use any instance of that construct where speci&#64257; ed. In this case, &lt;boolean expression&gt; represents an expression that has a boolean value, such as one involving a comparison operation, and &lt;block statements&gt; represents a sequence of Java statements. It is possible to make formal definitions of &lt;boolean expression&gt; and &lt;block statements&gt;, but we refrain from going into that level of detail. The meaning of an if statement is self- explanatory : the statement(s) in the block are to be executed if and only if the boolean expression is true. The if-else statement:</p><p attribs="{'xml:space': 'preserve'}" id="_00156" smilref="Title.smil#_00156"> if (&lt;boolean expression&gt;) { &lt;block statements&gt; } else { &lt;block statements&gt; }</p><p attribs="{'xml:space': 'preserve'}" id="_00157" smilref="Title.smil#_00157"> allows for choosing between two alternative blocks of statements.</p><p attribs="{'xml:space': 'preserve'}" id="_00158" smilref="Title.smil#_00158"> Loops. Many computations are inherently repetitive. The basic Java construct for handling such computations has the following format:</p><p attribs="{'xml:space': 'preserve'}" id="_00159" smilref="Title.smil#_00159"> while (&lt;boolean expression&gt;) { &lt;block statements&gt; }</p><p attribs="{'xml:space': 'preserve'}" id="_00160" smilref="Title.smil#_00160"> The while statement has the same form as the if statement (the only difference being the use of the keyword while instead of if), but the meaning is quite different. It is an instruction to the computer to behave as follows: if the boolean expression is false, do nothing; if the boolean expression is true, execute the sequence of statements in the block (just as with if) but then check the boolean expression again, execute the sequence of statements in the block again if the boolean expression is true, and continue as long as the boolean expression is true. We refer to the statements in the block in a loop as the body of the loop.</p><p attribs="{'xml:space': 'preserve'}" id="_00161" smilref="Title.smil#_00161"> Break and continue. Some situations call for slightly more complicated control flow than provided by the basic if and while statements. Accordingly, Java supports two additional statements for use within while loops: </p><p attribs="{'xml:space': 'preserve'}" id="_00162" smilref="Title.smil#_00162" /><pagenum id="p29" page="normal" smilref="Title.smil#p29" /><p attribs="{'xml:space': 'preserve'}" id="_00163" smilref="Title.smil#_00163"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_00164" smilref="Title.smil#_00164"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00165" smilref="Title.smil#_00165"> Shortcut notations There are several ways to express a given computation; we seek clear, elegant, and efficient code. Such code often takes advantage of the following widely used shortcuts (that are found in many languages, not just Java).</p><p attribs="{'xml:space': 'preserve'}" id="_00166" smilref="Title.smil#_00166"> Initializing declarations. We can combine a declaration with an assignment to initialize a variable at the same time that it is declared (created). For example, the code int i = 1; creates an int variable named i and assigns it the initial value 1. A best practice is to use this mechanism close to first use of the variable (to limit scope).</p><p attribs="{'xml:space': 'preserve'}" id="_00167" smilref="Title.smil#_00167"> Implicit assignments. The following shortcuts are available when our purpose is to modify a variable&#8217;s value relative to its current value: </p><p attribs="{'xml:space': 'preserve'}" id="_00168" smilref="Title.smil#_00168"> Single-statement blocks. If a block of statements in a conditional or a loop has only a single statement, the curly braces may be omitted.</p><p attribs="{'xml:space': 'preserve'}" id="_00169" smilref="Title.smil#_00169"> For notation. Many loops follow this scheme: initialize an index variable to some value and then use a while loop to test a loop continuation condition involving the index variable, where the last statement in the while loop increments the index variable. You can express such loops compactly with Java&#8217;s for notation:</p><p attribs="{'xml:space': 'preserve'}" id="_00170" smilref="Title.smil#_00170"> for (&lt;initialize&gt;; &lt;boolean expression&gt;; &lt;increment&gt;) { &lt;block statements&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_00171" smilref="Title.smil#_00171"> }</p><p attribs="{'xml:space': 'preserve'}" id="_00172" smilref="Title.smil#_00172"> This code is, with only a few exceptions, equivalent to</p><p attribs="{'xml:space': 'preserve'}" id="_00173" smilref="Title.smil#_00173"> &lt;initialize&gt;; while (&lt;boolean expression&gt;) { &lt;block statements&gt; &lt;increment&gt;; }</p><p attribs="{'xml:space': 'preserve'}" id="_00174" smilref="Title.smil#_00174"> We use for loops to support this initialize-and-increment programming idiom.</p><p attribs="{'xml:space': 'preserve'}" id="_00175" smilref="Title.smil#_00175" /><pagenum id="p30" page="normal" smilref="Title.smil#p30" /><p attribs="{'xml:space': 'preserve'}" id="_00176" smilref="Title.smil#_00176"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00177" smilref="Title.smil#_00177"> 17</p><p attribs="{'xml:space': 'preserve'}" id="_00178" smilref="Title.smil#_00178"> statement</p><p attribs="{'xml:space': 'preserve'}" id="_00179" smilref="Title.smil#_00179"> examples</p><p attribs="{'xml:space': 'preserve'}" id="_00180" smilref="Title.smil#_00180"> definition</p><p attribs="{'xml:space': 'preserve'}" id="_00181" smilref="Title.smil#_00181"> declaration</p><p attribs="{'xml:space': 'preserve'}" id="_00182" smilref="Title.smil#_00182"> int i;</p><p attribs="{'xml:space': 'preserve'}" id="_00183" smilref="Title.smil#_00183"> double c;</p><p attribs="{'xml:space': 'preserve'}" id="_00184" smilref="Title.smil#_00184"> create a variable of a specified type, named with a given identifier</p><p attribs="{'xml:space': 'preserve'}" id="_00185" smilref="Title.smil#_00185"> assignment</p><p attribs="{'xml:space': 'preserve'}" id="_00186" smilref="Title.smil#_00186"> initializing declaration</p><p attribs="{'xml:space': 'preserve'}" id="_00187" smilref="Title.smil#_00187"> a = b + 3;</p><p attribs="{'xml:space': 'preserve'}" id="_00188" smilref="Title.smil#_00188"> discriminant = b*b - 4.0*c;</p><p attribs="{'xml:space': 'preserve'}" id="_00189" smilref="Title.smil#_00189"> assign a data-type value to a variable</p><p attribs="{'xml:space': 'preserve'}" id="_00190" smilref="Title.smil#_00190"> int i = 1;</p><p attribs="{'xml:space': 'preserve'}" id="_00191" smilref="Title.smil#_00191"> double c = 3.141592625;</p><p attribs="{'xml:space': 'preserve'}" id="_00192" smilref="Title.smil#_00192"> declaration that also assigns an initial value</p><p attribs="{'xml:space': 'preserve'}" id="_00193" smilref="Title.smil#_00193"> implicit assignment</p><p attribs="{'xml:space': 'preserve'}" id="_00194" smilref="Title.smil#_00194"> i++;</p><p attribs="{'xml:space': 'preserve'}" id="_00195" smilref="Title.smil#_00195"> i += 1;</p><p attribs="{'xml:space': 'preserve'}" id="_00196" smilref="Title.smil#_00196"> i = i + 1;</p><p attribs="{'xml:space': 'preserve'}" id="_00197" smilref="Title.smil#_00197"> conditional (if) if (x &lt; 0) x = -x;</p><p attribs="{'xml:space': 'preserve'}" id="_00198" smilref="Title.smil#_00198"> execute a statement, depending on boolean expression</p><p attribs="{'xml:space': 'preserve'}" id="_00199" smilref="Title.smil#_00199"> conditional</p><p attribs="{'xml:space': 'preserve'}" id="_00200" smilref="Title.smil#_00200"> (if-else)</p><p attribs="{'xml:space': 'preserve'}" id="_00201" smilref="Title.smil#_00201"> if (x &gt; y) max = x; else max = y;</p><p attribs="{'xml:space': 'preserve'}" id="_00202" smilref="Title.smil#_00202"> execute one or the other statement, depending on boolean expression</p><p attribs="{'xml:space': 'preserve'}" id="_00203" smilref="Title.smil#_00203"> loop (while)</p><p attribs="{'xml:space': 'preserve'}" id="_00204" smilref="Title.smil#_00204"> int v = 0; while (v &lt;= N) v = 2*v;</p><p attribs="{'xml:space': 'preserve'}" id="_00205" smilref="Title.smil#_00205"> double t = c; while (Math.abs(t - c/t) &gt; 1e-15*t) t = (c/t + t) / 2.0;</p><p attribs="{'xml:space': 'preserve'}" id="_00206" smilref="Title.smil#_00206"> execute statement until boolean expression is false</p><p attribs="{'xml:space': 'preserve'}" id="_00207" smilref="Title.smil#_00207"> loop (for)</p><p attribs="{'xml:space': 'preserve'}" id="_00208" smilref="Title.smil#_00208"> call</p><p attribs="{'xml:space': 'preserve'}" id="_00209" smilref="Title.smil#_00209"> return</p><p attribs="{'xml:space': 'preserve'}" id="_00210" smilref="Title.smil#_00210"> for (int i = 1; i &lt;= N; i++) sum += 1.0/i;</p><p attribs="{'xml:space': 'preserve'}" id="_00211" smilref="Title.smil#_00211"> for (int i = 0; i &lt;= N; i++) StdOut.println(2*Math.PI*i/N);</p><p attribs="{'xml:space': 'preserve'}" id="_00212" smilref="Title.smil#_00212"> compact version of while statement</p><p attribs="{'xml:space': 'preserve'}" id="_00213" smilref="Title.smil#_00213"> int key = StdIn.readInt();</p><p attribs="{'xml:space': 'preserve'}" id="_00214" smilref="Title.smil#_00214"> invoke other methods (see page 22)</p><p attribs="{'xml:space': 'preserve'}" id="_00215" smilref="Title.smil#_00215"> return false;</p><p attribs="{'xml:space': 'preserve'}" id="_00216" smilref="Title.smil#_00216"> return from a method (see page 24)</p><p attribs="{'xml:space': 'preserve'}" id="_00217" smilref="Title.smil#_00217"> Java statements</p><p attribs="{'xml:space': 'preserve'}" id="_00218" smilref="Title.smil#_00218" /></level3><level3 id="_00002"><h3 id="ch1-s1-ss3" smilref="Title.smil#ch1-s1-ss3" xml:space="preserve">Arrays</h3><pagenum id="p31" page="normal" smilref="Title.smil#p31" /><p attribs="{'xml:space': 'preserve'}" id="_00219" smilref="Title.smil#_00219"> 18</p><p attribs="{'xml:space': 'preserve'}" id="_00220" smilref="Title.smil#_00220"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00221" smilref="Title.smil#_00221"> Arrays An array stores a sequence of values that are all of the same type. We want not only to store values but also to access each individual value. The method that we use to refer to individual values in an array is numbering and then indexing them. If we have N values, we think of them as being numbered from 0 to N&#11002;1. Then, we can unambiguously specify one of them in Java code by using the notation a[i] to refer to the ith value for any value of i from 0 to N-1. This Java construct is known as a one- dimensional array.</p><p attribs="{'xml:space': 'preserve'}" id="_00222" smilref="Title.smil#_00222"> long form</p><p attribs="{'xml:space': 'preserve'}" id="_00223" smilref="Title.smil#_00223"> declaration</p><p attribs="{'xml:space': 'preserve'}" id="_00224" smilref="Title.smil#_00224"> creation</p><p attribs="{'xml:space': 'preserve'}" id="_00225" smilref="Title.smil#_00225"> Creating and initializing an array. Making an array in a Java program involves three distinct steps: </p><p attribs="{'xml:space': 'preserve'}" id="_00226" smilref="Title.smil#_00226"> double[] a; a = new double[N]; for (int i = 0; i &lt; N; i++) a[i] = 0.0;</p><p attribs="{'xml:space': 'preserve'}" id="_00227" smilref="Title.smil#_00227"> int[] a = { 1, 1, 2, 3, 5, 8 };</p><p attribs="{'xml:space': 'preserve'}" id="_00228" smilref="Title.smil#_00228"> double[] a = new double[N];</p><p attribs="{'xml:space': 'preserve'}" id="_00229" smilref="Title.smil#_00229"> short form</p><p attribs="{'xml:space': 'preserve'}" id="_00230" smilref="Title.smil#_00230"> initialization</p><p attribs="{'xml:space': 'preserve'}" id="_00231" smilref="Title.smil#_00231"> initializing declaration</p><p attribs="{'xml:space': 'preserve'}" id="_00232" smilref="Title.smil#_00232"> Declaring, creating, and initializing an array</p><p attribs="{'xml:space': 'preserve'}" id="_00233" smilref="Title.smil#_00233"> Default array initialization. For economy in code, we often take advantage of Java&#8217;s default array initialization convention and combine all three steps into a single state- ment, as in the &#8220;short form&#8221; code in our example. The code to the left of the equal sign constitutes the declaration; the code to the right constitutes the creation. The for loop is unnecessary in this case because the default initial value of variables of type double</p><p attribs="{'xml:space': 'preserve'}" id="_00234" smilref="Title.smil#_00234" /><pagenum id="p32" page="normal" smilref="Title.smil#p32" /><p attribs="{'xml:space': 'preserve'}" id="_00235" smilref="Title.smil#_00235"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00236" smilref="Title.smil#_00236"> 19</p><p attribs="{'xml:space': 'preserve'}" id="_00237" smilref="Title.smil#_00237"> in a Java array is 0.0, but it would be required if a nonzero value were desired. The default initial value is zero for numeric types and false for type boolean.</p><p attribs="{'xml:space': 'preserve'}" id="_00238" smilref="Title.smil#_00238"> Initializing declaration. The third option shown for our example is to specify the initialization values at compile time, by listing literal values between curly braces, separated by commas.</p><p attribs="{'xml:space': 'preserve'}" id="_00239" smilref="Title.smil#_00239"> Using an array. Typical array-processing code is shown on page 21. After declaring and creating an array, you can refer to any individual value anywhere you would use a variable name in a program by enclosing an integer index in square brackets after the array name. Once we create an array, its size is fi xed. A program can refer to the length of an array a[] with the code a.length. The last element of an array a[] is always a[a.length-1]. Java does automatic bounds checking&#8212;if you have created an array of size N and use an index whose value is less than 0 or greater than N-1, your program will terminate with an ArrayOutOfBoundsException runtime exception.</p><p attribs="{'xml:space': 'preserve'}" id="_00240" smilref="Title.smil#_00240"> Aliasing. Note carefully that an array name refers to the whole array&#8212;if we assign one array name to another, then both refer to the same array, as illustrated in the following code fragment.</p><p attribs="{'xml:space': 'preserve'}" id="_00241" smilref="Title.smil#_00241"> int[] a = new int[N]; ... a[i] = 1234; ... int[] b = a; ... b[i] = 5678; // a[i] is now 5678.</p><p attribs="{'xml:space': 'preserve'}" id="_00242" smilref="Title.smil#_00242"> This situation is known as aliasing and can lead to subtle bugs. If your intent is to make a copy of an array, then you need to declare, create, and initialize a new array and then copy all of the entries in the original array to the new array, as in the third example on page 21.</p><p attribs="{'xml:space': 'preserve'}" id="_00243" smilref="Title.smil#_00243"> Two-dimensional arrays. A two-dimensional array in Java is an array of one-dimen- sional arrays. A two-dimensional array may be ragged (its arrays may all be of differing lengths), but we most often work with (for appropriate parameters M and N) M-by-N two-dimensional arrays that are arrays of M rows, each an array of length N (so it also makes sense to refer to the array as having N columns). Extending Java array constructs to handle two-dimensional arrays is straightforward. To refer to the entry in row i and column j of a two-dimensional array a[][], we use the notation a[i][j]; to declare a two-dimensional array, we add another pair of square brackets; and to create the array,</p><p attribs="{'xml:space': 'preserve'}" id="_00244" smilref="Title.smil#_00244" /><pagenum id="p33" page="normal" smilref="Title.smil#p33" /><p attribs="{'xml:space': 'preserve'}" id="_00245" smilref="Title.smil#_00245"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_00246" smilref="Title.smil#_00246"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00247" smilref="Title.smil#_00247"> we specify the number of rows followed by the number of columns after the type name (both within square brackets), as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_00248" smilref="Title.smil#_00248"> double[][] a = new double[M][N];</p><p attribs="{'xml:space': 'preserve'}" id="_00249" smilref="Title.smil#_00249"> We refer to such an array as an M-by-N array. By convention, the first dimension is the number of rows and the second is the number of columns. As with one-dimensional arrays, Java initializes all entries in arrays of numeric types to zero and in arrays of boolean values to false. Default initialization of two-dimensional arrays is useful because it masks more code than for one-dimensional arrays. The following code is equivalent to the single-line create-and-initialize idiom that we just considered:</p><p attribs="{'xml:space': 'preserve'}" id="_00250" smilref="Title.smil#_00250"> double[][] a; a = new double[M][N]; for (int i = 0; i &lt; M; i++) for (int j = 0; j &lt; N; j++) a[i][j] = 0.0;</p><p attribs="{'xml:space': 'preserve'}" id="_00251" smilref="Title.smil#_00251"> This code is superfluous when initializing to zero, but the nested for loops are needed to initialize to other value(s).</p><p attribs="{'xml:space': 'preserve'}" id="_00252" smilref="Title.smil#_00252" /><pagenum id="p34" page="normal" smilref="Title.smil#p34" /><p attribs="{'xml:space': 'preserve'}" id="_00253" smilref="Title.smil#_00253"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00254" smilref="Title.smil#_00254"> 21</p><p attribs="{'xml:space': 'preserve'}" id="_00255" smilref="Title.smil#_00255"> task</p><p attribs="{'xml:space': 'preserve'}" id="_00256" smilref="Title.smil#_00256"> implementation (code fragment)</p><p attribs="{'xml:space': 'preserve'}" id="_00257" smilref="Title.smil#_00257"> find the maximum of the array values</p><p attribs="{'xml:space': 'preserve'}" id="_00258" smilref="Title.smil#_00258"> double max = a[0]; for (int i = 1; i &lt; a.length; i++) if (a[i] &gt; max) max = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_00259" smilref="Title.smil#_00259"> compute the average of the array values</p><p attribs="{'xml:space': 'preserve'}" id="_00260" smilref="Title.smil#_00260"> int N = a.length; double sum = 0.0; for (int i = 0; i &lt; N; i++) sum += a[i]; double average = sum / N;</p><p attribs="{'xml:space': 'preserve'}" id="_00261" smilref="Title.smil#_00261"> copy to another array</p><p attribs="{'xml:space': 'preserve'}" id="_00262" smilref="Title.smil#_00262"> int N = a.length; double[] b = new double[N]; for (int i = 0; i &lt; N; i++) b[i] = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_00263" smilref="Title.smil#_00263"> reverse the elements within an array</p><p attribs="{'xml:space': 'preserve'}" id="_00264" smilref="Title.smil#_00264"> int N = a.length; for (int i = 0; i &lt; N/2; i++) { double temp = a[i]; a[i] = a[N-1-i]; a[N-i-1] = temp; }</p><p attribs="{'xml:space': 'preserve'}" id="_00265" smilref="Title.smil#_00265"> matrix-matrix multiplication (square matrices)</p><p attribs="{'xml:space': 'preserve'}" id="_00266" smilref="Title.smil#_00266"> a[][]*b[][] = c[][]</p><p attribs="{'xml:space': 'preserve'}" id="_00267" smilref="Title.smil#_00267"> int N = a.length; double[][] c = new double[N][N]; for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) { // Compute dot product of row i and column j. for (int k = 0; k &lt; N; k++) c[i][j] += a[i][k]*b[k][j]; }</p><p attribs="{'xml:space': 'preserve'}" id="_00268" smilref="Title.smil#_00268"> Typical array-processing code</p><p attribs="{'xml:space': 'preserve'}" id="_00269" smilref="Title.smil#_00269" /></level3><level3 id="_00003"><h3 id="ch1-s1-ss4" smilref="Title.smil#ch1-s1-ss4" xml:space="preserve">Static methods</h3><pagenum id="p35" page="normal" smilref="Title.smil#p35" /><p attribs="{'xml:space': 'preserve'}" id="_00270" smilref="Title.smil#_00270"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_00271" smilref="Title.smil#_00271"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00272" smilref="Title.smil#_00272"> Static methods Every Java program in this book is either a data-type definition (which we describe in detail in Section 1.2) or a library of static methods (which we describe here). Static methods are called functions in many programming languages, since they can behave like mathematical functions, as described next. Each static method is a sequence of statements that are executed, one after the other, when the static method is called, in the manner described below. The modifier static distinguishes these methods from instance methods, which we discuss in Section 1.2. We use the word method without a modifier when describing characteristics shared by both kinds of methods.</p><p attribs="{'xml:space': 'preserve'}" id="_00273" smilref="Title.smil#_00273"> signature</p><p attribs="{'xml:space': 'preserve'}" id="_00274" smilref="Title.smil#_00274"> local variables</p><p attribs="{'xml:space': 'preserve'}" id="_00275" smilref="Title.smil#_00275"> method body</p><p attribs="{'xml:space': 'preserve'}" id="_00276" smilref="Title.smil#_00276"> return type</p><p attribs="{'xml:space': 'preserve'}" id="_00277" smilref="Title.smil#_00277"> method name</p><p attribs="{'xml:space': 'preserve'}" id="_00278" smilref="Title.smil#_00278"> argument type</p><p attribs="{'xml:space': 'preserve'}" id="_00279" smilref="Title.smil#_00279"> De&#64257; ning a static method. A method encapsulates a computation that is defined as a sequence of statements. A method takes arguments (values of given data types) and computes a return value of some data type that depends upon the arguments (such as a value defined by a mathematical function) or causes a side effect that depends on the arguments (such as printing a value). The static method rank() in BinarySearch is an example of the fi rst; main() is an example of the second. Each static method is composed of a signature (the keywords public static followed by a return type, the method name, and a sequence of ar- guments, each with a declared type) and a body (a statement block: a sequence of statements, enclosed in curly braces). Ex- amples of static methods are shown in the table on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_00280" smilref="Title.smil#_00280"> public static double sqrt ( double c ) { if (c &lt; 0) return Double.NaN; double err = 1e-15; double t = c; while (Math.abs(t - c/t) &gt; err * t) t = (c/t + t) / 2.0; return t; }</p><p attribs="{'xml:space': 'preserve'}" id="_00281" smilref="Title.smil#_00281"> argument variable</p><p attribs="{'xml:space': 'preserve'}" id="_00282" smilref="Title.smil#_00282"> call on another method</p><p attribs="{'xml:space': 'preserve'}" id="_00283" smilref="Title.smil#_00283"> return statement</p><p attribs="{'xml:space': 'preserve'}" id="_00284" smilref="Title.smil#_00284"> Invoking a static method. A call on a static</p><p attribs="{'xml:space': 'preserve'}" id="_00285" smilref="Title.smil#_00285"> Anatomy of a static method</p><p attribs="{'xml:space': 'preserve'}" id="_00286" smilref="Title.smil#_00286"> method is its name followed by expressions that specify argument values in parenthe- ses, separated by commas. When the method call is part of an expression, the method computes a value and that value is used in place of the call in the expression. For example the call on rank() in BinarySearch() returns an int value. A method call followed by a semicolon is a statement that generally causes side effects. For example, the call Arrays.sort() in main() in BinarySearch is a call on the system method Arrays.sort() that has the side effect of putting the entries in the array in sorted order. When a method is called, its argument variables are initialized with the values of the corresponding expressions in the call. A return statement terminates a static method, returning control to the caller. If the static method is to compute a value, that value must be specified in a return statement (if such a static method can reach the end of its sequence of statements without a return, the compiler will report the error).</p><p attribs="{'xml:space': 'preserve'}" id="_00287" smilref="Title.smil#_00287" /><pagenum id="p36" page="normal" smilref="Title.smil#p36" /><p attribs="{'xml:space': 'preserve'}" id="_00288" smilref="Title.smil#_00288"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00289" smilref="Title.smil#_00289"> 23</p><p attribs="{'xml:space': 'preserve'}" id="_00290" smilref="Title.smil#_00290"> task</p><p attribs="{'xml:space': 'preserve'}" id="_00291" smilref="Title.smil#_00291"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_00292" smilref="Title.smil#_00292"> absolute value of an int value</p><p attribs="{'xml:space': 'preserve'}" id="_00293" smilref="Title.smil#_00293"> absolute value of a double value</p><p attribs="{'xml:space': 'preserve'}" id="_00294" smilref="Title.smil#_00294"> primality test</p><p attribs="{'xml:space': 'preserve'}" id="_00295" smilref="Title.smil#_00295"> square root ( Newton&#8217;s method)</p><p attribs="{'xml:space': 'preserve'}" id="_00296" smilref="Title.smil#_00296"> public static int abs(int x) { if (x &lt; 0) return -x; else return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_00297" smilref="Title.smil#_00297"> public static double abs(double x) { if (x &lt; 0.0) return -x; else return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_00298" smilref="Title.smil#_00298"> public static boolean isPrime(int N) { if (N &lt; 2) return false; for (int i = 2; i*i &lt;= N; i++) if (N % i == 0) return false; return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_00299" smilref="Title.smil#_00299"> public static double sqrt(double c) { if (c &lt; 0.0) return Double.NaN; double err = 1e-15; double t = c; while (Math.abs(t - c/t) &gt; err * t) t = (c/t + t) / 2.0; return t; }</p><p attribs="{'xml:space': 'preserve'}" id="_00300" smilref="Title.smil#_00300"> hypotenuse of a right triangle</p><p attribs="{'xml:space': 'preserve'}" id="_00301" smilref="Title.smil#_00301"> public static double hypotenuse(double a, double b) { return Math.sqrt(a*a + b*b); }</p><p attribs="{'xml:space': 'preserve'}" id="_00302" smilref="Title.smil#_00302"> Harmonic number (see page 185)</p><p attribs="{'xml:space': 'preserve'}" id="_00303" smilref="Title.smil#_00303"> public static double H(int N) { double sum = 0.0; for (int i = 1; i &lt;= N; i++) sum += 1.0 / i; return sum; }</p><p attribs="{'xml:space': 'preserve'}" id="_00304" smilref="Title.smil#_00304"> Typical implementations of static methods</p><p attribs="{'xml:space': 'preserve'}" id="_00305" smilref="Title.smil#_00305" /><pagenum id="p37" page="normal" smilref="Title.smil#p37" /><p attribs="{'xml:space': 'preserve'}" id="_00306" smilref="Title.smil#_00306"> 24</p><p attribs="{'xml:space': 'preserve'}" id="_00307" smilref="Title.smil#_00307"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00308" smilref="Title.smil#_00308"> Properties of methods. A complete detailed description of the properties of methods is beyond our scope, but the following points are worth noting: </p><p attribs="{'xml:space': 'preserve'}" id="_00309" smilref="Title.smil#_00309" /></level3><level3 id="_00004"><h3 id="ch1-s1-ss5" smilref="Title.smil#ch1-s1-ss5" xml:space="preserve">Recursion</h3><pagenum id="p38" page="normal" smilref="Title.smil#p38" /><p attribs="{'xml:space': 'preserve'}" id="_00310" smilref="Title.smil#_00310"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00311" smilref="Title.smil#_00311"> 25</p><p attribs="{'xml:space': 'preserve'}" id="_00312" smilref="Title.smil#_00312"> Recursion. A method can call itself (if you are not comfortable with this idea, known as recursion, you are encouraged to work Exercises 1.1.16 through 1.1.22). For ex- ample, the code at the bottom of this page gives an alternate implementation of the rank() method in BinarySearch. We often use recursive implementations of methods because they can lead to compact, elegant code that is easier to understand than a corresponding implementation that does not use recursion. For example, the comment in the implementation below provides a succinct description of what the code is supposed to do. We can use this comment to convince ourselves that it operates correctly, by mathematical induction. We will expand on this topic and provide such a proof for binary search in Section 3.1. There are three important rules of thumb in developing recursive programs: </p><p attribs="{'xml:space': 'preserve'}" id="_00313" smilref="Title.smil#_00313"> public static int rank(int key, int[] a) { return rank(key, a, 0, a.length - 1); }</p><p attribs="{'xml:space': 'preserve'}" id="_00314" smilref="Title.smil#_00314"> public static int rank(int key, int[] a, int lo, int hi) { // Index of key in a[], if present, is not smaller than lo // and not larger than hi. if (lo &gt; hi) return -1; int mid = lo + (hi - lo) / 2; if (key &lt; a[mid]) return rank(key, a, lo, mid - 1); else if (key &gt; a[mid]) return rank(key, a, mid + 1, hi); else return mid; }</p><p attribs="{'xml:space': 'preserve'}" id="_00315" smilref="Title.smil#_00315"> Recursive implementation of binary search</p><p attribs="{'xml:space': 'preserve'}" id="_00316" smilref="Title.smil#_00316" /><pagenum id="p39" page="normal" smilref="Title.smil#p39" /><p attribs="{'xml:space': 'preserve'}" id="_00317" smilref="Title.smil#_00317"> 26</p><p attribs="{'xml:space': 'preserve'}" id="_00318" smilref="Title.smil#_00318"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00319" smilref="Title.smil#_00319"> Basic programming model. A library of static methods is a set of static methods that are defined in a Java class, by creating a file with the keywords public class followed by the class name, followed by the static methods, enclosed in braces, kept in a file with the same name as the class and a .java extension. A basic model for Java programming is to develop a program that addresses a specific computational task by creating a library of static methods, one of which is named main(). Typing java followed by a class name followed by a sequence of strings leads to a call on main() in that class, with an array containing those strings as argument. After the last statement in main() executes, the program terminates. In this book, when we talk of a Java program for accomplishing a task, we are talking about code developed along these lines (possibly also including a data-type defi nition, as described in Section 1.2). For example, BinarySearch is a Java program composed of two static methods, rank() and main(), that accomplishes the task of printing numbers from an input stream that are not found in a whitelist file given as command-line argument.</p><p attribs="{'xml:space': 'preserve'}" id="_00320" smilref="Title.smil#_00320"> Modular programming. Of critical importance in this model is that libraries of static methods enable modular programming where we build libraries of static methods (modules) and a static method in one library can call static methods defined in other libraries. This approach has many important advantages. It allows us to </p><p attribs="{'xml:space': 'preserve'}" id="_00321" smilref="Title.smil#_00321" /><pagenum id="p40" page="normal" smilref="Title.smil#p40" /><p attribs="{'xml:space': 'preserve'}" id="_00322" smilref="Title.smil#_00322"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00323" smilref="Title.smil#_00323"> 27</p><p attribs="{'xml:space': 'preserve'}" id="_00324" smilref="Title.smil#_00324"> standard system libraries</p><p attribs="{'xml:space': 'preserve'}" id="_00325" smilref="Title.smil#_00325"> String&#8224; StringBuilder</p><p attribs="{'xml:space': 'preserve'}" id="_00326" smilref="Title.smil#_00326"> imported system libraries</p><p attribs="{'xml:space': 'preserve'}" id="_00327" smilref="Title.smil#_00327"> java.util.Arrays</p><p attribs="{'xml:space': 'preserve'}" id="_00328" smilref="Title.smil#_00328"> our standard libraries</p><p attribs="{'xml:space': 'preserve'}" id="_00329" smilref="Title.smil#_00329"> Math</p><p attribs="{'xml:space': 'preserve'}" id="_00330" smilref="Title.smil#_00330"> Integer&#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_00331" smilref="Title.smil#_00331"> Double&#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_00332" smilref="Title.smil#_00332"> External libraries. We use static methods from four different kinds of libraries, each requiring (slightly) differing procedures for code reuse. Most of these are libraries of static methods, but a few are data-type definitions that also include some static methods. </p><p attribs="{'xml:space': 'preserve'}" id="_00333" smilref="Title.smil#_00333"> StdRandom</p><p attribs="{'xml:space': 'preserve'}" id="_00334" smilref="Title.smil#_00334"> StdStats</p><p attribs="{'xml:space': 'preserve'}" id="_00335" smilref="Title.smil#_00335"> In&#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_00336" smilref="Title.smil#_00336"> Out&#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_00337" smilref="Title.smil#_00337"> StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_00338" smilref="Title.smil#_00338"> StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_00339" smilref="Title.smil#_00339"> System</p><p attribs="{'xml:space': 'preserve'}" id="_00340" smilref="Title.smil#_00340"> StdDraw</p><p attribs="{'xml:space': 'preserve'}" id="_00341" smilref="Title.smil#_00341"> Libraries of methods implemented by ourselves and by others in a modular</p><p attribs="{'xml:space': 'preserve'}" id="_00342" smilref="Title.smil#_00342"> programming environment can vastly expand the scope of our programming model. Beyond all of the libraries available in a standard Java release, thousands more are available on the web for applications of all sorts. To limit the scope of our programming model to a manageable size so that we can concentrate on algorithms, we use just the libraries listed in the table at right on this page, with a subset of their methods listed in APIs, as described next.</p><p attribs="{'xml:space': 'preserve'}" id="_00343" smilref="Title.smil#_00343"> &#8224; data type definitions that include some static methods</p><p attribs="{'xml:space': 'preserve'}" id="_00344" smilref="Title.smil#_00344"> Libraries with static methods used in this book</p><p attribs="{'xml:space': 'preserve'}" id="_00345" smilref="Title.smil#_00345" /></level3><level3 id="_00005"><h3 id="ch1-s1-ss6" smilref="Title.smil#ch1-s1-ss6" xml:space="preserve">APIs</h3><pagenum id="p41" page="normal" smilref="Title.smil#p41" /><p attribs="{'xml:space': 'preserve'}" id="_00346" smilref="Title.smil#_00346"> 28</p><p attribs="{'xml:space': 'preserve'}" id="_00347" smilref="Title.smil#_00347"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00348" smilref="Title.smil#_00348"> APIs A critical component of modular programming is documentation that explains the operation of library methods that are intended for use by others. We will consistently describe the library methods that we use in this book in application programming interfaces (APIs) that list the library name and the signatures and short descriptions of each of the methods that we use. We use the term client to refer to a program that calls a method in another library and the term implementation to describe the Java code that implements the methods in an API.</p><p attribs="{'xml:space': 'preserve'}" id="_00349" smilref="Title.smil#_00349"> Example. The following example, the API for commonly used static methods from the standard Math library in java.lang, illustrates our conventions for APIs:</p><p attribs="{'xml:space': 'preserve'}" id="_00350" smilref="Title.smil#_00350"> public class Math static double abs(double a)</p><p attribs="{'xml:space': 'preserve'}" id="_00351" smilref="Title.smil#_00351"> static double max(double a, double b)</p><p attribs="{'xml:space': 'preserve'}" id="_00352" smilref="Title.smil#_00352"> static double min(double a, double b)</p><p attribs="{'xml:space': 'preserve'}" id="_00353" smilref="Title.smil#_00353"> absolute value of a maximum of a and b minimum of a and b</p><p attribs="{'xml:space': 'preserve'}" id="_00354" smilref="Title.smil#_00354"> Note 1: abs(), max(), and min() are defined also for int, long, and fl oat.</p><p attribs="{'xml:space': 'preserve'}" id="_00355" smilref="Title.smil#_00355"> static double sin(double theta)</p><p attribs="{'xml:space': 'preserve'}" id="_00356" smilref="Title.smil#_00356"> static double cos(double theta)</p><p attribs="{'xml:space': 'preserve'}" id="_00357" smilref="Title.smil#_00357"> static double tan(double theta)</p><p attribs="{'xml:space': 'preserve'}" id="_00358" smilref="Title.smil#_00358"> sine function cosine function tangent function</p><p attribs="{'xml:space': 'preserve'}" id="_00359" smilref="Title.smil#_00359"> Note 2: Angles are expressed in radians. Use toDegrees() and toRadians() to convert. Note 3: Use asin(), acos(), and atan() for inverse functions.</p><p attribs="{'xml:space': 'preserve'}" id="_00360" smilref="Title.smil#_00360"> static double exp(double a)</p><p attribs="{'xml:space': 'preserve'}" id="_00361" smilref="Title.smil#_00361"> static double log(double a)</p><p attribs="{'xml:space': 'preserve'}" id="_00362" smilref="Title.smil#_00362"> static double pow(double a, double b)</p><p attribs="{'xml:space': 'preserve'}" id="_00363" smilref="Title.smil#_00363"> static double random()</p><p attribs="{'xml:space': 'preserve'}" id="_00364" smilref="Title.smil#_00364"> static double sqrt(double a)</p><p attribs="{'xml:space': 'preserve'}" id="_00365" smilref="Title.smil#_00365"> static double E</p><p attribs="{'xml:space': 'preserve'}" id="_00366" smilref="Title.smil#_00366"> static double PI</p><p attribs="{'xml:space': 'preserve'}" id="_00367" smilref="Title.smil#_00367"> See booksite for other available functions.</p><p attribs="{'xml:space': 'preserve'}" id="_00368" smilref="Title.smil#_00368"> exponential (e a) natural log (loge a, or ln a) raise a to the bth power (ab )</p><p attribs="{'xml:space': 'preserve'}" id="_00369" smilref="Title.smil#_00369"> random number in [0, 1) square root of a</p><p attribs="{'xml:space': 'preserve'}" id="_00370" smilref="Title.smil#_00370"> value of e (constant) value of &#9266; (constant)</p><p attribs="{'xml:space': 'preserve'}" id="_00371" smilref="Title.smil#_00371"> API for Java&#8217;s mathematics library (excerpts)</p><p attribs="{'xml:space': 'preserve'}" id="_00372" smilref="Title.smil#_00372" /><pagenum id="p42" page="normal" smilref="Title.smil#p42" /><p attribs="{'xml:space': 'preserve'}" id="_00373" smilref="Title.smil#_00373"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00374" smilref="Title.smil#_00374"> 29</p><p attribs="{'xml:space': 'preserve'}" id="_00375" smilref="Title.smil#_00375"> These methods implement mathematical functions&#8212;they use their arguments to compute a value of a specified type (except random(), which does not implement a mathematical function because it does not take an argument). Since they all operate on double values and compute a double result, you can consider them as extending the double data type&#8212;extensibility of this nature is one of the characteristic features of modern programming languages. Each method is described by a line in the API that specifies the information you need to know in order to use the method. The Math library also defines the precise constant values PI (for &#9266;) and E (for e), so that you can use those names to refer to those constants in your programs. For example, the value</p><p attribs="{'xml:space': 'preserve'}" id="_00376" smilref="Title.smil#_00376"> of Math.sin(Math.PI/2) is 1.0 and the value of Math.log(Math.E) is 1.0 (because</p><p attribs="{'xml:space': 'preserve'}" id="_00377" smilref="Title.smil#_00377"> Math.sin() takes its argument in radians and Math.log() implements the natural logarithm function).</p><p attribs="{'xml:space': 'preserve'}" id="_00378" smilref="Title.smil#_00378"> Java libraries. Extensive online descriptions of thousands of libraries are part of every Java release, but we excerpt just a few methods that we use in the book, in order to clearly delineate our programming model. For example, BinarySearch uses the sort() method from Java&#8217;s Arrays library, which we document as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_00379" smilref="Title.smil#_00379"> public class Arrays</p><p attribs="{'xml:space': 'preserve'}" id="_00380" smilref="Title.smil#_00380"> static void sort(int[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00381" smilref="Title.smil#_00381"> put the array in increasing order</p><p attribs="{'xml:space': 'preserve'}" id="_00382" smilref="Title.smil#_00382"> Note : This method is defined also for other primitive types and Object.</p><p attribs="{'xml:space': 'preserve'}" id="_00383" smilref="Title.smil#_00383"> Excerpt from Java&#8217;s Arrays library (java.util.Arrays)</p><p attribs="{'xml:space': 'preserve'}" id="_00384" smilref="Title.smil#_00384"> The Arrays library is not in java.lang, so an import statement is needed to use it, as in BinarySearch. Actually, Chapter 2 of this book is devoted to implementations of sort() for arrays, including the mergesort and quicksort algorithms that are implemented in Arrays.sort(). Many of the fundamental algorithms that we consider in this book are implemented in Java and in many other programming environments. For example, Arrays also includes an implementation of binary search. To avoid confusion, we generally use our own implementations, although there is nothing wrong with using a finely tuned library implementation of an algorithm that you understand.</p><p attribs="{'xml:space': 'preserve'}" id="_00385" smilref="Title.smil#_00385" /><pagenum id="p43" page="normal" smilref="Title.smil#p43" /><p attribs="{'xml:space': 'preserve'}" id="_00386" smilref="Title.smil#_00386"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_00387" smilref="Title.smil#_00387"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00388" smilref="Title.smil#_00388"> Our standard libraries. We have developed a number of libraries that provide useful functionality for introductory Java programming, for scientific applications, and for the development, study, and application of algorithms. Most of these libraries are for input and output; we also make use of the following two libraries to test and analyze our implementations. The first extends Math.random() to allow us to draw random values from various distributions; the second supports statistical calculations:</p><p attribs="{'xml:space': 'preserve'}" id="_00389" smilref="Title.smil#_00389"> public class StdRandom</p><p attribs="{'xml:space': 'preserve'}" id="_00390" smilref="Title.smil#_00390"> static void initialize(long seed) static double random()</p><p attribs="{'xml:space': 'preserve'}" id="_00391" smilref="Title.smil#_00391"> static int uniform(int N)</p><p attribs="{'xml:space': 'preserve'}" id="_00392" smilref="Title.smil#_00392"> static int uniform(int lo, int hi)</p><p attribs="{'xml:space': 'preserve'}" id="_00393" smilref="Title.smil#_00393"> static double uniform(double lo, double hi)</p><p attribs="{'xml:space': 'preserve'}" id="_00394" smilref="Title.smil#_00394"> static boolean bernoulli(double p)</p><p attribs="{'xml:space': 'preserve'}" id="_00395" smilref="Title.smil#_00395"> static double gaussian()</p><p attribs="{'xml:space': 'preserve'}" id="_00396" smilref="Title.smil#_00396"> static double gaussian(double m, double s)</p><p attribs="{'xml:space': 'preserve'}" id="_00397" smilref="Title.smil#_00397"> static int discrete(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00398" smilref="Title.smil#_00398"> static void shuffle(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00399" smilref="Title.smil#_00399"> initialize real between 0 and 1</p><p attribs="{'xml:space': 'preserve'}" id="_00400" smilref="Title.smil#_00400"> integer between 0 and N-1 integer between lo and hi-1 real between lo and hi true with probability p normal, mean 0, std dev 1 normal, mean m, std dev s i with probability a[i] randomly shuffle the array a[]</p><p attribs="{'xml:space': 'preserve'}" id="_00401" smilref="Title.smil#_00401"> Note: overloaded implementations of shuffle() are included for other primitive types and for Object.</p><p attribs="{'xml:space': 'preserve'}" id="_00402" smilref="Title.smil#_00402"> API for our library of static methods for random numbers</p><p attribs="{'xml:space': 'preserve'}" id="_00403" smilref="Title.smil#_00403"> public class StdStats</p><p attribs="{'xml:space': 'preserve'}" id="_00404" smilref="Title.smil#_00404"> static double max(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00405" smilref="Title.smil#_00405"> static double min(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00406" smilref="Title.smil#_00406"> static double mean(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00407" smilref="Title.smil#_00407"> largest value</p><p attribs="{'xml:space': 'preserve'}" id="_00408" smilref="Title.smil#_00408"> smallest value</p><p attribs="{'xml:space': 'preserve'}" id="_00409" smilref="Title.smil#_00409"> average</p><p attribs="{'xml:space': 'preserve'}" id="_00410" smilref="Title.smil#_00410"> static double var(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00411" smilref="Title.smil#_00411"> sample variance</p><p attribs="{'xml:space': 'preserve'}" id="_00412" smilref="Title.smil#_00412"> static double stddev(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00413" smilref="Title.smil#_00413"> sample standard deviation</p><p attribs="{'xml:space': 'preserve'}" id="_00414" smilref="Title.smil#_00414"> static double median(double[] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00415" smilref="Title.smil#_00415"> median</p><p attribs="{'xml:space': 'preserve'}" id="_00416" smilref="Title.smil#_00416"> API for our library of static methods for data analysis</p><p attribs="{'xml:space': 'preserve'}" id="_00417" smilref="Title.smil#_00417" /><pagenum id="p44" page="normal" smilref="Title.smil#p44" /><p attribs="{'xml:space': 'preserve'}" id="_00418" smilref="Title.smil#_00418"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00419" smilref="Title.smil#_00419"> 31</p><p attribs="{'xml:space': 'preserve'}" id="_00420" smilref="Title.smil#_00420"> The initialize() method in StdRandom allows us to seed the random number generator so that we can reproduce experiments involving random numbers. For reference, implementations of many of these methods are given on page 32. Some of these methods are extremely easy to implement; why do we bother including them in a library? An- swers to this question are standard for well-designed libraries: </p><p attribs="{'xml:space': 'preserve'}" id="_00421" smilref="Title.smil#_00421"> Your own libraries. It is worthwhile to consider every program that you write as a library implementation, for possible reuse in the future. </p><p attribs="{'xml:space': 'preserve'}" id="_00422" smilref="Title.smil#_00422" /><pagenum id="p45" page="normal" smilref="Title.smil#p45" /><p attribs="{'xml:space': 'preserve'}" id="_00423" smilref="Title.smil#_00423"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_00424" smilref="Title.smil#_00424"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00425" smilref="Title.smil#_00425"> intended result</p><p attribs="{'xml:space': 'preserve'}" id="_00426" smilref="Title.smil#_00426"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_00427" smilref="Title.smil#_00427"> random double value in [a, b)</p><p attribs="{'xml:space': 'preserve'}" id="_00428" smilref="Title.smil#_00428"> public static double uniform(double a, double b) { return a + StdRandom.random() * (b-a); }</p><p attribs="{'xml:space': 'preserve'}" id="_00429" smilref="Title.smil#_00429"> random int value in [0..N)</p><p attribs="{'xml:space': 'preserve'}" id="_00430" smilref="Title.smil#_00430"> public static int uniform(int N) { return (int) (StdRandom.random() * N); }</p><p attribs="{'xml:space': 'preserve'}" id="_00431" smilref="Title.smil#_00431"> random int value in [lo..hi)</p><p attribs="{'xml:space': 'preserve'}" id="_00432" smilref="Title.smil#_00432"> public static int uniform(int lo, int hi) { return lo + StdRandom.uniform(hi - lo); }</p><p attribs="{'xml:space': 'preserve'}" id="_00433" smilref="Title.smil#_00433"> random int value drawn from discrete distribution (i with probability a[i])</p><p attribs="{'xml:space': 'preserve'}" id="_00434" smilref="Title.smil#_00434"> public static int discrete(double[] a) { // Entries in a[] must sum to 1. double r = StdRandom.random(); double sum = 0.0; for (int i = 0; i &lt; a.length; i++) { sum = sum + a[i]; if (sum &gt;= r) return i; } return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_00435" smilref="Title.smil#_00435"> randomly shuffle the elements in an array of double values (See Exercise 1.1.36)</p><p attribs="{'xml:space': 'preserve'}" id="_00436" smilref="Title.smil#_00436"> public static void shuffle(double[] a) { int N = a.length; for (int i = 0; i &lt; N; i++) { // Exchange a[i] with random element in a[i..N-1] int r = i + StdRandom.uniform(N-i); double temp = a[i]; a[i] = a[r]; a[r] = temp; } }</p><p attribs="{'xml:space': 'preserve'}" id="_00437" smilref="Title.smil#_00437"> Implementations of static methods in StdRandom library</p><p attribs="{'xml:space': 'preserve'}" id="_00438" smilref="Title.smil#_00438" /><pagenum id="p46" page="normal" smilref="Title.smil#p46" /><p attribs="{'xml:space': 'preserve'}" id="_00439" smilref="Title.smil#_00439"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00440" smilref="Title.smil#_00440"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_00441" smilref="Title.smil#_00441"> The purpose of an API is to separate the client from the implementation: the client should know nothing about the implementation other than information given in the API, and the implementation should not take properties of any particular client into account. APIs enable us to separately develop code for various purposes, then reuse it widely. No Java library can contain all the methods that we might need for a given computation, so this ability is a crucial step in addressing complex programming ap- plications. Accordingly, programmers normally think of the API as a contract between the client and the implementation that is a clear specification of what each method is to do. Our goal when developing an implementation is to honor the terms of the contract. Often, there are many ways to do so, and separating client code from implementation code gives us the freedom to substitute new and improved implementations. In the study of algorithms, this ability is an important ingredient in our ability to understand the impact of algorithmic improvements that we develop.</p><p attribs="{'xml:space': 'preserve'}" id="_00442" smilref="Title.smil#_00442" /></level3><level3 id="_00006"><h3 id="ch1-s1-ss7" smilref="Title.smil#ch1-s1-ss7" xml:space="preserve">Strings</h3><pagenum id="p47" page="normal" smilref="Title.smil#p47" /><p attribs="{'xml:space': 'preserve'}" id="_00443" smilref="Title.smil#_00443"> 34</p><p attribs="{'xml:space': 'preserve'}" id="_00444" smilref="Title.smil#_00444"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00445" smilref="Title.smil#_00445"> Strings A String is a sequence of characters (char values). A literal String is a sequence of characters within double quotes, such as "Hello, World". The data type String is a Java data type but it is not a primitive type. We consider String now because it is a fundamental data type that almost every Java program uses.</p><p attribs="{'xml:space': 'preserve'}" id="_00446" smilref="Title.smil#_00446"> Concatenation. Java has a built-in concatenation operator (+) for String like the built-in operators that it has for primitive types, justifying the addition of the row in the table below to the primitive-type table on page 12. The result of concatenating two String values is a single String value, the first string followed by the second.</p><p attribs="{'xml:space': 'preserve'}" id="_00447" smilref="Title.smil#_00447"> type</p><p attribs="{'xml:space': 'preserve'}" id="_00448" smilref="Title.smil#_00448"> set of values</p><p attribs="{'xml:space': 'preserve'}" id="_00449" smilref="Title.smil#_00449"> typical literals</p><p attribs="{'xml:space': 'preserve'}" id="_00450" smilref="Title.smil#_00450"> operators</p><p attribs="{'xml:space': 'preserve'}" id="_00451" smilref="Title.smil#_00451"> typical expressions</p><p attribs="{'xml:space': 'preserve'}" id="_00452" smilref="Title.smil#_00452"> expression</p><p attribs="{'xml:space': 'preserve'}" id="_00453" smilref="Title.smil#_00453"> value</p><p attribs="{'xml:space': 'preserve'}" id="_00454" smilref="Title.smil#_00454"> String</p><p attribs="{'xml:space': 'preserve'}" id="_00455" smilref="Title.smil#_00455"> character sequences</p><p attribs="{'xml:space': 'preserve'}" id="_00456" smilref="Title.smil#_00456"> "AB" "Hello" "2.5"</p><p attribs="{'xml:space': 'preserve'}" id="_00457" smilref="Title.smil#_00457"> +</p><p attribs="{'xml:space': 'preserve'}" id="_00458" smilref="Title.smil#_00458"> (concatenate)</p><p attribs="{'xml:space': 'preserve'}" id="_00459" smilref="Title.smil#_00459"> "Hi, " + "Bob" "12" + "34" "1" + "+" + "2"</p><p attribs="{'xml:space': 'preserve'}" id="_00460" smilref="Title.smil#_00460"> "Hi, Bob" "1234" "1+2"</p><p attribs="{'xml:space': 'preserve'}" id="_00461" smilref="Title.smil#_00461"> Java&#8217;s String data type</p><p attribs="{'xml:space': 'preserve'}" id="_00462" smilref="Title.smil#_00462"> Conversion. Two primary uses of strings are to convert values that we can enter on a keyboard into data-type values and to convert data-type values to values that we can read on a display. Java has built-in operations for String to facilitate these operations. In particular, the language includes libraries Integer and Double that contain static methods to convert between String values and int values and between String values and double values, respectively.</p><p attribs="{'xml:space': 'preserve'}" id="_00463" smilref="Title.smil#_00463"> public class Integer</p><p attribs="{'xml:space': 'preserve'}" id="_00464" smilref="Title.smil#_00464"> static int parseInt(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_00465" smilref="Title.smil#_00465"> static String toString(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_00466" smilref="Title.smil#_00466"> convert s to an int value convert i to a String value</p><p attribs="{'xml:space': 'preserve'}" id="_00467" smilref="Title.smil#_00467"> public class Double</p><p attribs="{'xml:space': 'preserve'}" id="_00468" smilref="Title.smil#_00468"> static double parseDouble(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_00469" smilref="Title.smil#_00469"> static String toString(double x)</p><p attribs="{'xml:space': 'preserve'}" id="_00470" smilref="Title.smil#_00470"> convert s to a double value convert x to a String value</p><p attribs="{'xml:space': 'preserve'}" id="_00471" smilref="Title.smil#_00471"> APIs for conversion between numbers and String values</p><p attribs="{'xml:space': 'preserve'}" id="_00472" smilref="Title.smil#_00472" /><pagenum id="p48" page="normal" smilref="Title.smil#p48" /><p attribs="{'xml:space': 'preserve'}" id="_00473" smilref="Title.smil#_00473"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00474" smilref="Title.smil#_00474"> 35</p><p attribs="{'xml:space': 'preserve'}" id="_00475" smilref="Title.smil#_00475"> Automatic conversion. We rarely explicitly use the static toString() methods just described because Java has a built-in mechanism that allows us to convert from any data type value to a String value by using concatenation: if one of the arguments of + is a String, Java automatically converts the other argument to a String (if it is not already</p><p attribs="{'xml:space': 'preserve'}" id="_00476" smilref="Title.smil#_00476"> a String). Beyond usage like "The square root of 2.0 is " + Math.sqrt(2.0)</p><p attribs="{'xml:space': 'preserve'}" id="_00477" smilref="Title.smil#_00477"> this mechanism enables conversion of any data-type value to a String, by concatenating it with the empty string "".</p><p attribs="{'xml:space': 'preserve'}" id="_00478" smilref="Title.smil#_00478"> Command-line arguments. One important use of strings in Java programming is to enable a mechanism for passing information from the command line to the program. The mechanism is simple. When you type the java command followed by a library name followed by a sequence of strings, the Java system invokes the main() method in that library with an array of strings as argument: the strings typed after the library name. For example, the main() method in BinarySearch takes one command-line argument, so the system creates an array of size one. The program uses that value, args[0], to name the file containing the whitelist, for use as the argument to In.readInts(). An- other typical paradigm that we often use in our code is when a command-line argument is intended to represent a number, so we use parseInt() to convert to an int value or parseDouble() to convert to a double value.</p><p attribs="{'xml:space': 'preserve'}" id="_00479" smilref="Title.smil#_00479"> Computing with strings is an essential component of modern computing. For the moment, we make use of String just to convert between external representation of numbers as sequences of characters and internal representation of numeric data-type values. In Section 1.2, we will see that Java supports many, many more operations on String values that we use throughout the book; in Section 1.4, we will examine the internal representation of String values; and in Chapter 5, we consider in depth algorithms that process String data. These algorithms are among the most interesting, intricate, and impactful methods that we consider in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_00480" smilref="Title.smil#_00480" /></level3><level3 id="_00007"><h3 id="ch1-s1-ss8" smilref="Title.smil#ch1-s1-ss8" xml:space="preserve">Input and output</h3><pagenum id="p49" page="normal" smilref="Title.smil#p49" /><p attribs="{'xml:space': 'preserve'}" id="_00481" smilref="Title.smil#_00481"> 36</p><p attribs="{'xml:space': 'preserve'}" id="_00482" smilref="Title.smil#_00482"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00483" smilref="Title.smil#_00483"> standard input</p><p attribs="{'xml:space': 'preserve'}" id="_00484" smilref="Title.smil#_00484"> file I/O</p><p attribs="{'xml:space': 'preserve'}" id="_00485" smilref="Title.smil#_00485"> standard output</p><p attribs="{'xml:space': 'preserve'}" id="_00486" smilref="Title.smil#_00486"> command-line arguments</p><p attribs="{'xml:space': 'preserve'}" id="_00487" smilref="Title.smil#_00487"> Input and output The primary purpose of our standard libraries for input, out- put, and drawing is to support a simple model for Java programs to interact with the outside world. These libraries are built upon extensive capabilities that are available in Java libraries, but are generally much more complicated and much more difficult to learn and use. We begin by briefly reviewing the model. In our model, a Java program takes input values from command-line arguments or from an abstract stream of characters known as the standard input stream and writes to another abstract stream of characters known as the standard output stream. Necessarily, we need to consider the interface between Java and the operating system, so we need to briefly discuss basic mechanisms that are provided by most modern operating systems and program-development environ- ments. You can find more details about your particular system on the booksite. By default, command-line argu- ments, standard input, and standard output are associated with an application supported by either the operating system or the program development environment that takes commands. We use the generic term terminal window to refer to the window maintained by this application, where we type and read text. Since early Unix systems in the 1970s this model has proven to be a convenient and direct way for us to interact with our programs and data. We add to the classical model a standard drawing that allows us to create visual representations for data analysis.</p><p attribs="{'xml:space': 'preserve'}" id="_00488" smilref="Title.smil#_00488"> standard drawing</p><p attribs="{'xml:space': 'preserve'}" id="_00489" smilref="Title.smil#_00489"> A bird&#8217;s-eye view of a Java program</p><p attribs="{'xml:space': 'preserve'}" id="_00490" smilref="Title.smil#_00490"> Commands and arguments. In the terminal window, we see a prompt, where we type commands to the operating system that may take arguments. We use only a few commands in this book, shown in the table below. Most often, we use the .java com- mand, to run our programs. As mentioned on page 35, Java classes have a main() static method that takes a String array args[] as its argument. That array is the sequence of command-line arguments that we type, provided to Java by the operating system. By convention, both Java and the operating system process the arguments as strings. If we intend for an argument to be a number, we use a method</p><p attribs="{'xml:space': 'preserve'}" id="_00491" smilref="Title.smil#_00491"> .class file name (no extension) and command-line arguments</p><p attribs="{'xml:space': 'preserve'}" id="_00492" smilref="Title.smil#_00492"> compile Java program</p><p attribs="{'xml:space': 'preserve'}" id="_00493" smilref="Title.smil#_00493"> run Java program</p><p attribs="{'xml:space': 'preserve'}" id="_00494" smilref="Title.smil#_00494"> .java file name</p><p attribs="{'xml:space': 'preserve'}" id="_00495" smilref="Title.smil#_00495"> arguments</p><p attribs="{'xml:space': 'preserve'}" id="_00496" smilref="Title.smil#_00496"> purpose</p><p attribs="{'xml:space': 'preserve'}" id="_00497" smilref="Title.smil#_00497"> any text file name</p><p attribs="{'xml:space': 'preserve'}" id="_00498" smilref="Title.smil#_00498"> print file contents</p><p attribs="{'xml:space': 'preserve'}" id="_00499" smilref="Title.smil#_00499"> Typical operating-system commands</p><p attribs="{'xml:space': 'preserve'}" id="_00500" smilref="Title.smil#_00500"> such as Integer.parseInt()</p><p attribs="{'xml:space': 'preserve'}" id="_00501" smilref="Title.smil#_00501"> to convert it from String to the appropriate type.</p><p attribs="{'xml:space': 'preserve'}" id="_00502" smilref="Title.smil#_00502"> command</p><p attribs="{'xml:space': 'preserve'}" id="_00503" smilref="Title.smil#_00503"> javac</p><p attribs="{'xml:space': 'preserve'}" id="_00504" smilref="Title.smil#_00504"> java</p><p attribs="{'xml:space': 'preserve'}" id="_00505" smilref="Title.smil#_00505"> more</p><p attribs="{'xml:space': 'preserve'}" id="_00506" smilref="Title.smil#_00506" /><pagenum id="p50" page="normal" smilref="Title.smil#p50" /><p attribs="{'xml:space': 'preserve'}" id="_00507" smilref="Title.smil#_00507"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00508" smilref="Title.smil#_00508"> 37</p><p attribs="{'xml:space': 'preserve'}" id="_00509" smilref="Title.smil#_00509"> call the static method main() in RandomSeq</p><p attribs="{'xml:space': 'preserve'}" id="_00510" smilref="Title.smil#_00510"> prompt</p><p attribs="{'xml:space': 'preserve'}" id="_00511" smilref="Title.smil#_00511"> % java RandomSeq 5 100.0 200.0</p><p attribs="{'xml:space': 'preserve'}" id="_00512" smilref="Title.smil#_00512"> invoke Java runtime</p><p attribs="{'xml:space': 'preserve'}" id="_00513" smilref="Title.smil#_00513"> args[0] args[1] args[2]</p><p attribs="{'xml:space': 'preserve'}" id="_00514" smilref="Title.smil#_00514"> Anatomy of a command</p><p attribs="{'xml:space': 'preserve'}" id="_00515" smilref="Title.smil#_00515"> Standard output. Our StdOut library provides support for standard output. By default, the system connects standard output to the terminal window. The print() method puts its argument on standard out- put; the println() method adds a newline; and the printf() method supports formatted output, as described next. Java provides a similar method in its System.out library ; we use StdOut to treat standard input and standard output in a uniform manner (and to provide a few technical improvements).</p><p attribs="{'xml:space': 'preserve'}" id="_00516" smilref="Title.smil#_00516"> public class StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_00517" smilref="Title.smil#_00517"> static void print(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_00518" smilref="Title.smil#_00518"> static void println(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_00519" smilref="Title.smil#_00519"> static void println()</p><p attribs="{'xml:space': 'preserve'}" id="_00520" smilref="Title.smil#_00520"> static void printf(String f, ... )</p><p attribs="{'xml:space': 'preserve'}" id="_00521" smilref="Title.smil#_00521"> print s print s, followed by newline</p><p attribs="{'xml:space': 'preserve'}" id="_00522" smilref="Title.smil#_00522"> print a new line</p><p attribs="{'xml:space': 'preserve'}" id="_00523" smilref="Title.smil#_00523"> formatted print</p><p attribs="{'xml:space': 'preserve'}" id="_00524" smilref="Title.smil#_00524"> Note: overloaded implementations are included for primitive types and for Object.</p><p attribs="{'xml:space': 'preserve'}" id="_00525" smilref="Title.smil#_00525"> API for our library of static methods for standard output</p><p attribs="{'xml:space': 'preserve'}" id="_00526" smilref="Title.smil#_00526"> To use these methods, download into your working directory StdOut.java from the booksite and use code such as</p><p attribs="{'xml:space': 'preserve'}" id="_00527" smilref="Title.smil#_00527"> StdOut.println("Hello, World");</p><p attribs="{'xml:space': 'preserve'}" id="_00528" smilref="Title.smil#_00528"> to call them. A sample client is shown at right.</p><p attribs="{'xml:space': 'preserve'}" id="_00529" smilref="Title.smil#_00529"> Formatted output. In its simplest</p><p attribs="{'xml:space': 'preserve'}" id="_00530" smilref="Title.smil#_00530"> public class RandomSeq { public static void main(String[] args) { // Print N random values in (lo, hi). int N = Integer.parseInt(args[0]); double lo = Double.parseDouble(args[1]); double hi = Double.parseDouble(args[2]); for (int i = 0; i &lt; N; i++) { double x = StdRandom.uniform(lo, hi); StdOut.printf("%.2f\n", x); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_00531" smilref="Title.smil#_00531"> form, printf() takes two arguments. The first argument is a format string that describes how the second argument is to be converted to a string for output. The simplest type of format string begins with % and ends with a one-letter conversion code. The conversion codes that we use most frequently are d (for decimal values from Java&#8217;s integer types), f (for fl oating-point values), and s (for String values). Between the % and the conversion code is an integer value that specifies the field width of the</p><p attribs="{'xml:space': 'preserve'}" id="_00532" smilref="Title.smil#_00532"> Sample StdOut client</p><p attribs="{'xml:space': 'preserve'}" id="_00533" smilref="Title.smil#_00533"> % java RandomSeq 5 100.0 200.0 123.43 153.13 144.38 155.18 104.02</p><p attribs="{'xml:space': 'preserve'}" id="_00534" smilref="Title.smil#_00534" /><pagenum id="p51" page="normal" smilref="Title.smil#p51" /><p attribs="{'xml:space': 'preserve'}" id="_00535" smilref="Title.smil#_00535"> 38</p><p attribs="{'xml:space': 'preserve'}" id="_00536" smilref="Title.smil#_00536"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00537" smilref="Title.smil#_00537"> converted value (the number of characters in the converted output string). By default, blank spaces are added on the left to make the length of the converted output equal to the field width; if we want the spaces on the right, we can insert a minus sign before the field width. (If the converted output string is bigger than the field width, the field width is ignored.) Following the width, we have the option of including a period followed by the number of digits to put after the decimal point (the precision) for a double value or the number of characters to take from the beginning of the string for a String value. The most important thing to remember about using printf() is that the conversion code in the format and the type of the corresponding argument must match. That is, Java must be able to convert from the type of the argument to the type required by the conversion code. The first argument of printf() is a String that may contain characters other than a format string. Any part of the argument that is not part of a format string passes through to the output, with the format string replaced by the argument value (converted to a String as speci&#64257; ed). For example, the statement</p><p attribs="{'xml:space': 'preserve'}" id="_00538" smilref="Title.smil#_00538"> StdOut.printf("PI is approximately %.2f\n", Math.PI);</p><p attribs="{'xml:space': 'preserve'}" id="_00539" smilref="Title.smil#_00539"> prints the line</p><p attribs="{'xml:space': 'preserve'}" id="_00540" smilref="Title.smil#_00540"> PI is approximately 3.14</p><p attribs="{'xml:space': 'preserve'}" id="_00541" smilref="Title.smil#_00541"> Note that we need to explicitly include the newline character \n in the argument in order to print a new line with printf(). The printf() function can take more than two arguments. In this case, the format string will have a format specifier for each additional argument, perhaps separated by other characters to pass through to the out- put. You can also use the static method String.format() with arguments exactly as just described for printf() to get a formatted string without printing it. Formatted printing is a convenient mechanism that allows us to develop compact code that can produce tabulated experimental data (our primary use in this book).</p><p attribs="{'xml:space': 'preserve'}" id="_00542" smilref="Title.smil#_00542"> type</p><p attribs="{'xml:space': 'preserve'}" id="_00543" smilref="Title.smil#_00543"> code</p><p attribs="{'xml:space': 'preserve'}" id="_00544" smilref="Title.smil#_00544"> int</p><p attribs="{'xml:space': 'preserve'}" id="_00545" smilref="Title.smil#_00545"> double</p><p attribs="{'xml:space': 'preserve'}" id="_00546" smilref="Title.smil#_00546"> String</p><p attribs="{'xml:space': 'preserve'}" id="_00547" smilref="Title.smil#_00547"> d</p><p attribs="{'xml:space': 'preserve'}" id="_00548" smilref="Title.smil#_00548"> f e</p><p attribs="{'xml:space': 'preserve'}" id="_00549" smilref="Title.smil#_00549"> s</p><p attribs="{'xml:space': 'preserve'}" id="_00550" smilref="Title.smil#_00550"> typical literal</p><p attribs="{'xml:space': 'preserve'}" id="_00551" smilref="Title.smil#_00551"> 512</p><p attribs="{'xml:space': 'preserve'}" id="_00552" smilref="Title.smil#_00552"> 1595.1680010754388</p><p attribs="{'xml:space': 'preserve'}" id="_00553" smilref="Title.smil#_00553"> "Hello, World"</p><p attribs="{'xml:space': 'preserve'}" id="_00554" smilref="Title.smil#_00554"> sample format strings</p><p attribs="{'xml:space': 'preserve'}" id="_00555" smilref="Title.smil#_00555"> converted string values for output</p><p attribs="{'xml:space': 'preserve'}" id="_00556" smilref="Title.smil#_00556"> "%14d" "%-14d"</p><p attribs="{'xml:space': 'preserve'}" id="_00557" smilref="Title.smil#_00557"> "%14.2f" "%.7f" "%14.4e"</p><p attribs="{'xml:space': 'preserve'}" id="_00558" smilref="Title.smil#_00558"> " 512" "512 "</p><p attribs="{'xml:space': 'preserve'}" id="_00559" smilref="Title.smil#_00559"> " 1595.17" "1595.1680011" " 1.5952e+03"</p><p attribs="{'xml:space': 'preserve'}" id="_00560" smilref="Title.smil#_00560"> "%14s" "%-14s" "%-14.5s"</p><p attribs="{'xml:space': 'preserve'}" id="_00561" smilref="Title.smil#_00561"> " Hello, World" "Hello, World " "Hello "</p><p attribs="{'xml:space': 'preserve'}" id="_00562" smilref="Title.smil#_00562"> Format conventions for printf() (see the booksite for many other options)</p><p attribs="{'xml:space': 'preserve'}" id="_00563" smilref="Title.smil#_00563" /><pagenum id="p52" page="normal" smilref="Title.smil#p52" /><p attribs="{'xml:space': 'preserve'}" id="_00564" smilref="Title.smil#_00564"> Standard input. Our StdIn library</p><p attribs="{'xml:space': 'preserve'}" id="_00565" smilref="Title.smil#_00565"> takes data from the standard input stream that may be empty or may contain a sequence of values separated by whitespace (spaces, tabs, newline characters, and the like). By default, the system connects standard output to the terminal win- dow&#8212;what you type is the input stream (terminated by &lt;ctrl-d&gt; or &lt;ctrl-z&gt;, depending on your terminal window application). Each value is a String or a value from one of Java&#8217;s primitive types. One of the key features of the standard input stream is that your program consumes values when it reads them. Once your program has read a value, it cannot back up and read it again. This assumption is restrictive, but it reflects physical characteristics of some input devices and simplifies implementing the abstrac- tion. Within the input stream model, the static methods in this library are largely self-documenting (described by their signatures).</p><p attribs="{'xml:space': 'preserve'}" id="_00566" smilref="Title.smil#_00566"> Sample StdIn client</p><p attribs="{'xml:space': 'preserve'}" id="_00567" smilref="Title.smil#_00567"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00568" smilref="Title.smil#_00568"> 39</p><p attribs="{'xml:space': 'preserve'}" id="_00569" smilref="Title.smil#_00569"> public class Average { public static void main(String[] args) { // Average the numbers on StdIn. double sum = 0.0; int cnt = 0; while (!StdIn.isEmpty()) { // Read a number and cumulate the sum. sum += StdIn.readDouble(); cnt++; } double avg = sum / cnt; StdOut.printf("Average is %.5f\n", avg); } }</p><p attribs="{'xml:space': 'preserve'}" id="_00570" smilref="Title.smil#_00570"> % java Average 1.23456 2.34567 3.45678 4.56789 &lt;ctrl-d&gt; Average is 2.90123</p><p attribs="{'xml:space': 'preserve'}" id="_00571" smilref="Title.smil#_00571"> public class StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_00572" smilref="Title.smil#_00572"> static boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_00573" smilref="Title.smil#_00573"> static int readInt()</p><p attribs="{'xml:space': 'preserve'}" id="_00574" smilref="Title.smil#_00574"> static double readDouble()</p><p attribs="{'xml:space': 'preserve'}" id="_00575" smilref="Title.smil#_00575"> static float readFloat()</p><p attribs="{'xml:space': 'preserve'}" id="_00576" smilref="Title.smil#_00576"> static long readLong()</p><p attribs="{'xml:space': 'preserve'}" id="_00577" smilref="Title.smil#_00577"> static boolean readBoolean()</p><p attribs="{'xml:space': 'preserve'}" id="_00578" smilref="Title.smil#_00578"> static char readChar()</p><p attribs="{'xml:space': 'preserve'}" id="_00579" smilref="Title.smil#_00579"> static byte readByte()</p><p attribs="{'xml:space': 'preserve'}" id="_00580" smilref="Title.smil#_00580"> static String readString()</p><p attribs="{'xml:space': 'preserve'}" id="_00581" smilref="Title.smil#_00581"> true if no more values, false otherwise read a value of type int read a value of type double read a value of type float read a value of type long read a value of type boolean read a value of type char read a value of type byte read a value of type String</p><p attribs="{'xml:space': 'preserve'}" id="_00582" smilref="Title.smil#_00582"> static boolean hasNextLine()</p><p attribs="{'xml:space': 'preserve'}" id="_00583" smilref="Title.smil#_00583"> is there another line in the input stream?</p><p attribs="{'xml:space': 'preserve'}" id="_00584" smilref="Title.smil#_00584"> static String readLine()</p><p attribs="{'xml:space': 'preserve'}" id="_00585" smilref="Title.smil#_00585"> static String readAll()</p><p attribs="{'xml:space': 'preserve'}" id="_00586" smilref="Title.smil#_00586"> read the rest of the line</p><p attribs="{'xml:space': 'preserve'}" id="_00587" smilref="Title.smil#_00587"> read the rest of the input stream</p><p attribs="{'xml:space': 'preserve'}" id="_00588" smilref="Title.smil#_00588"> API for our library of static methods for standard input</p><p attribs="{'xml:space': 'preserve'}" id="_00589" smilref="Title.smil#_00589" /><pagenum id="p53" page="normal" smilref="Title.smil#p53" /><p attribs="{'xml:space': 'preserve'}" id="_00590" smilref="Title.smil#_00590"> 40</p><p attribs="{'xml:space': 'preserve'}" id="_00591" smilref="Title.smil#_00591"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00592" smilref="Title.smil#_00592"> Redirection and piping. Standard input and output enable us to take advantage of command-line extensions supported by many operating-systems. By adding a simple directive to the command that invokes a program, we can redirect its standard output to a fi le, either for permanent storage or for input to another program at a later time:</p><p attribs="{'xml:space': 'preserve'}" id="_00593" smilref="Title.smil#_00593"> % java RandomSeq 1000 100.0 200.0 &gt; data.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00594" smilref="Title.smil#_00594"> This command specifies that the standard output stream is not to be printed in the terminal window, but instead is to be written to a text file named data.txt. Each call to</p><p attribs="{'xml:space': 'preserve'}" id="_00595" smilref="Title.smil#_00595"> redirecting from a file to standard input</p><p attribs="{'xml:space': 'preserve'}" id="_00596" smilref="Title.smil#_00596"> % java Average &lt; data.txt data.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00597" smilref="Title.smil#_00597"> standard input</p><p attribs="{'xml:space': 'preserve'}" id="_00598" smilref="Title.smil#_00598"> Average</p><p attribs="{'xml:space': 'preserve'}" id="_00599" smilref="Title.smil#_00599"> redirecting standard output to a file</p><p attribs="{'xml:space': 'preserve'}" id="_00600" smilref="Title.smil#_00600"> % java RandomSeq 1000 100.0 200.0 &gt; data.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00601" smilref="Title.smil#_00601"> RandomSeq</p><p attribs="{'xml:space': 'preserve'}" id="_00602" smilref="Title.smil#_00602"> standard output</p><p attribs="{'xml:space': 'preserve'}" id="_00603" smilref="Title.smil#_00603"> data.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00604" smilref="Title.smil#_00604"> piping the output of one program to the input of another</p><p attribs="{'xml:space': 'preserve'}" id="_00605" smilref="Title.smil#_00605"> % java RandomSeq 1000 100.0 200.0 | java Average</p><p attribs="{'xml:space': 'preserve'}" id="_00606" smilref="Title.smil#_00606"> StdOut.print() or StdOut.println()</p><p attribs="{'xml:space': 'preserve'}" id="_00607" smilref="Title.smil#_00607"> appends text at the end of that fi le. In this example, the end result is a file that contains 1,000 random values. No output appears in the terminal window : it goes directly into the file named after the &gt; symbol. Thus, we can save away information for later retrieval. Note that we do not have to change RandomSeq in any way&#8212;it is using the standard output abstraction and is unaffected by our use of a different implementation of that abstraction. Similarly, we can redirect standard input so that StdIn reads data from a file instead of the terminal application:</p><p attribs="{'xml:space': 'preserve'}" id="_00608" smilref="Title.smil#_00608"> % java Average &lt; data.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00609" smilref="Title.smil#_00609"> RandomSeq</p><p attribs="{'xml:space': 'preserve'}" id="_00610" smilref="Title.smil#_00610"> standard input</p><p attribs="{'xml:space': 'preserve'}" id="_00611" smilref="Title.smil#_00611"> Average</p><p attribs="{'xml:space': 'preserve'}" id="_00612" smilref="Title.smil#_00612"> Redirection and piping from the command line</p><p attribs="{'xml:space': 'preserve'}" id="_00613" smilref="Title.smil#_00613"> standard output</p><p attribs="{'xml:space': 'preserve'}" id="_00614" smilref="Title.smil#_00614"> This command reads a sequence of numbers from the file data.txt and computes their average value. Speci&#64257; - cally, the &lt; symbol is a directive that tells the operating system to implement the standard input stream by reading from the text file data.txt instead of waiting for the user to type something into the terminal window. When the program calls StdIn.readDouble(), the operating system reads the value from the fi le. Combining these to redirect the output of one program to the input of another is known as piping:</p><p attribs="{'xml:space': 'preserve'}" id="_00615" smilref="Title.smil#_00615"> % java RandomSeq 1000 100.0 200.0 | java Average</p><p attribs="{'xml:space': 'preserve'}" id="_00616" smilref="Title.smil#_00616" /><pagenum id="p54" page="normal" smilref="Title.smil#p54" /><p attribs="{'xml:space': 'preserve'}" id="_00617" smilref="Title.smil#_00617"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00618" smilref="Title.smil#_00618"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_00619" smilref="Title.smil#_00619"> This command specifies that standard output for RandomSeq and standard input for Average are the same stream. The effect is as if RandomSeq were typing the numbers it generates into the terminal window while Average is running. This difference is pro- found, because it removes the limitation on the size of the input and output streams that we can process. For example, we could replace 1000 in our example with 1000000000, even though we might not have the space to save a billion numbers on our computer (we do need the time to process them). When RandomSeq calls StdOut.println(), a string is added to the end of the stream; when Average calls StdIn.readInt(), a string is removed from the beginning of the stream. The timing of precisely what happens is up to the operating system: it might run RandomSeq until it produces some numbers, and then run Average to consume those numbers, or it might run Average until it needs to consume a number, and then run RandomSeq until it produces the needed number. The end result is the same, but our programs are freed from worrying about such details because they work solely with the standard input and standard output abstractions. Input and output from a fi le. Our In and Out libraries provide static methods that implement the abstraction of reading from and writing to a file the contents of an array of values of a primitive type (or String). We use readInts(), readDoubles(),</p><p attribs="{'xml:space': 'preserve'}" id="_00620" smilref="Title.smil#_00620"> and readStrings() in the In library and writeInts(), writeDoubles(), and</p><p attribs="{'xml:space': 'preserve'}" id="_00621" smilref="Title.smil#_00621"> writeStrings() in the Out library. The named argument can be a file or a web page. For example, this ability allows us to use a file and standard input for two different purposes in the same program, as in BinarySearch. The In and Out libraries also implement data types with instance methods that allow us the more general ability to treat multiple files as input and output streams, and web pages as input streams, so we will revisit them in Section 1.2.</p><p attribs="{'xml:space': 'preserve'}" id="_00622" smilref="Title.smil#_00622"> public class In</p><p attribs="{'xml:space': 'preserve'}" id="_00623" smilref="Title.smil#_00623"> static int[] readInts(String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00624" smilref="Title.smil#_00624"> static double[] readDoubles(String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00625" smilref="Title.smil#_00625"> static String[] readStrings(String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00626" smilref="Title.smil#_00626"> read int values read double values read String values</p><p attribs="{'xml:space': 'preserve'}" id="_00627" smilref="Title.smil#_00627"> public class Out</p><p attribs="{'xml:space': 'preserve'}" id="_00628" smilref="Title.smil#_00628"> static void write(int[] a, String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00629" smilref="Title.smil#_00629"> static void write(double[] a, String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00630" smilref="Title.smil#_00630"> static void write(String[] a, String name)</p><p attribs="{'xml:space': 'preserve'}" id="_00631" smilref="Title.smil#_00631"> write int values write double values write String values</p><p attribs="{'xml:space': 'preserve'}" id="_00632" smilref="Title.smil#_00632"> Note 1: Other primitive types are supported. Note 2: StdIn and StdOut are supported (omit name argument).</p><p attribs="{'xml:space': 'preserve'}" id="_00633" smilref="Title.smil#_00633" /><pagenum id="p55" page="normal" smilref="Title.smil#p55" /><p attribs="{'xml:space': 'preserve'}" id="_00634" smilref="Title.smil#_00634"> 42</p><p attribs="{'xml:space': 'preserve'}" id="_00635" smilref="Title.smil#_00635"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00636" smilref="Title.smil#_00636"> Standard drawing (basic methods). Up to this point,</p><p attribs="{'xml:space': 'preserve'}" id="_00637" smilref="Title.smil#_00637"> our input/output abstractions have focused exclusively on text strings. Now we introduce an abstraction for producing drawings as output. This library is easy to use and allows us to take advantage of a visual medium to cope with far more information than is possible with just text. As with standard input/output, our standard drawing abstraction is implemented in a library StdDraw that you can access by downloading the file StdDraw.java from the booksite into your working directory. Standard draw is very simple: we imagine an abstract drawing device capable of drawing lines and points on a two-dimensional canvas. The device is capable of responding to the commands to draw basic geometric shapes that our programs issue in the form of calls to static methods in StdDraw, including methods for drawing lines, points, text strings, circles, rect- angles, and polygons. Like the methods for standard input and standard output, these methods are nearly self-documenting: StdDraw.line() draws a straight line segment connecting the point (x0 , y0) with the point (x1 , y1) whose coordinates are given as arguments. StdDraw.point() draws a spot centered on the point (x, y) whose coordinates are given as arguments, and so forth, as illustrated in the diagrams at right. Geometric shapes can be filled (in black, by default). The default scale is the unit square (all coordinates are between 0 and 1). The standard implementation displays the canvas in a window on your computer&#8217;s screen, with black lines and points on a white background.</p><p attribs="{'xml:space': 'preserve'}" id="_00638" smilref="Title.smil#_00638"> StdDraw.point(x0, y0); StdDraw.line(x0, y0, x1, y1);</p><p attribs="{'xml:space': 'preserve'}" id="_00639" smilref="Title.smil#_00639"> (x1, y1)</p><p attribs="{'xml:space': 'preserve'}" id="_00640" smilref="Title.smil#_00640"> (1, 1)</p><p attribs="{'xml:space': 'preserve'}" id="_00641" smilref="Title.smil#_00641"> (x0, y0)</p><p attribs="{'xml:space': 'preserve'}" id="_00642" smilref="Title.smil#_00642"> (0, 0)</p><p attribs="{'xml:space': 'preserve'}" id="_00643" smilref="Title.smil#_00643"> (x2, y2)</p><p attribs="{'xml:space': 'preserve'}" id="_00644" smilref="Title.smil#_00644"> StdDraw.circle(x, y, r);</p><p attribs="{'xml:space': 'preserve'}" id="_00645" smilref="Title.smil#_00645"> r</p><p attribs="{'xml:space': 'preserve'}" id="_00646" smilref="Title.smil#_00646"> (x, y)</p><p attribs="{'xml:space': 'preserve'}" id="_00647" smilref="Title.smil#_00647"> StdDraw.square(x, y, r);</p><p attribs="{'xml:space': 'preserve'}" id="_00648" smilref="Title.smil#_00648"> r</p><p attribs="{'xml:space': 'preserve'}" id="_00649" smilref="Title.smil#_00649"> r</p><p attribs="{'xml:space': 'preserve'}" id="_00650" smilref="Title.smil#_00650"> (x, y)</p><p attribs="{'xml:space': 'preserve'}" id="_00651" smilref="Title.smil#_00651"> double[] x = {x0, x1, x2, x3}; double[] y = {y0, y1, y2, y3}; StdDraw.polygon(x, y);</p><p attribs="{'xml:space': 'preserve'}" id="_00652" smilref="Title.smil#_00652"> (x0, y0)</p><p attribs="{'xml:space': 'preserve'}" id="_00653" smilref="Title.smil#_00653"> (x1, y1)</p><p attribs="{'xml:space': 'preserve'}" id="_00654" smilref="Title.smil#_00654"> (x3, y3)</p><p attribs="{'xml:space': 'preserve'}" id="_00655" smilref="Title.smil#_00655"> (x2, y2)</p><p attribs="{'xml:space': 'preserve'}" id="_00656" smilref="Title.smil#_00656"> StdDraw examples</p><p attribs="{'xml:space': 'preserve'}" id="_00657" smilref="Title.smil#_00657" /><pagenum id="p56" page="normal" smilref="Title.smil#p56" /><p attribs="{'xml:space': 'preserve'}" id="_00658" smilref="Title.smil#_00658"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00659" smilref="Title.smil#_00659"> 43</p><p attribs="{'xml:space': 'preserve'}" id="_00660" smilref="Title.smil#_00660"> public class StdDraw</p><p attribs="{'xml:space': 'preserve'}" id="_00661" smilref="Title.smil#_00661"> static void line(double x0, double y0, double x1, double y1) static void point(double x, double y) static void text(double x, double y, String s) static void circle(double x, double y, double r) static void filledCircle(double x, double y, double r) static void ellipse(double x, double y, double rw, double rh) static void filledEllipse(double x, double y, double rw, double rh) static void square(double x, double y, double r) static void filledSquare(double x, double y, double r) static void rectangle(double x, double y, double rw, double rh) static void filledRectangle(double x, double y, double rw, double rh) static void polygon(double[] x, double[] y) static void filledPolygon(double[] x, double[] y)</p><p attribs="{'xml:space': 'preserve'}" id="_00662" smilref="Title.smil#_00662"> API for our library of static methods for standard drawing (drawing methods)</p><p attribs="{'xml:space': 'preserve'}" id="_00663" smilref="Title.smil#_00663"> Standard drawing (control methods). The library also includes methods to change the scale and size of the canvas, the color and width of the lines, the text font, and the timing of drawing (for use in animation). As arguments for setPenColor() you can use one of the predefined colors BLACK, BLUE, CYAN, DARK_GRAY, GRAY, GREEN,</p><p attribs="{'xml:space': 'preserve'}" id="_00664" smilref="Title.smil#_00664"> LIGHT_GRAY, MAGENTA, ORANGE, PINK, RED, BOOK_RED, WHITE, and YELLOW that are de-</p><p attribs="{'xml:space': 'preserve'}" id="_00665" smilref="Title.smil#_00665"> fined as constants in StdDraw (so we refer to one of them with code like StdDraw.RED). The window also includes a menu option to save your drawing to a fi le, in a format suitable for publishing on the web.</p><p attribs="{'xml:space': 'preserve'}" id="_00666" smilref="Title.smil#_00666"> public class StdDraw</p><p attribs="{'xml:space': 'preserve'}" id="_00667" smilref="Title.smil#_00667"> static void setXscale(double x0, double x1) static void setYscale(double y0, double y1) static void setPenRadius(double r) static void setPenColor(Color c) static void setFont(Font f) static void setCanvasSize(int w, int h) static void clear(Color c) static void show(int dt)</p><p attribs="{'xml:space': 'preserve'}" id="_00668" smilref="Title.smil#_00668"> reset x range to (x0 , x1) reset y range to (y0 , y1) set pen radius to r set pen color to c set text font to f set canvas to w-by-h window clear the canvas; color it c show all; pause dt milliseconds</p><p attribs="{'xml:space': 'preserve'}" id="_00669" smilref="Title.smil#_00669"> API for our library of static methods for standard drawing (control methods)</p><p attribs="{'xml:space': 'preserve'}" id="_00670" smilref="Title.smil#_00670" /><pagenum id="p57" page="normal" smilref="Title.smil#p57" /><p attribs="{'xml:space': 'preserve'}" id="_00671" smilref="Title.smil#_00671"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_00672" smilref="Title.smil#_00672"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00673" smilref="Title.smil#_00673"> In this book, we use StdDraw for data analysis and for creating visual representations of algorithms in operation. The table at on the opposite page indicates some possibli- ties; we will consider many more examples in the text and the exercises throughout the book. The library also supports animation&#8212;of course, this topic is treated primarily on the booksite.</p><p attribs="{'xml:space': 'preserve'}" id="_00674" smilref="Title.smil#_00674" /><pagenum id="p58" page="normal" smilref="Title.smil#p58" /><p attribs="{'xml:space': 'preserve'}" id="_00675" smilref="Title.smil#_00675"> data</p><p attribs="{'xml:space': 'preserve'}" id="_00676" smilref="Title.smil#_00676"> plot implementation (code fragment)</p><p attribs="{'xml:space': 'preserve'}" id="_00677" smilref="Title.smil#_00677"> result</p><p attribs="{'xml:space': 'preserve'}" id="_00678" smilref="Title.smil#_00678"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00679" smilref="Title.smil#_00679"> 45</p><p attribs="{'xml:space': 'preserve'}" id="_00680" smilref="Title.smil#_00680"> function values</p><p attribs="{'xml:space': 'preserve'}" id="_00681" smilref="Title.smil#_00681"> array of random values</p><p attribs="{'xml:space': 'preserve'}" id="_00682" smilref="Title.smil#_00682"> int N = 100; StdDraw.setXscale(0, N); StdDraw.setYscale(0, N*N); StdDraw.setPenRadius(.01); for (int i = 1; i &lt;= N; i++) { StdDraw.point(i, i); StdDraw.point(i, i*i); StdDraw.point(i, i*Math.log(i)); }</p><p attribs="{'xml:space': 'preserve'}" id="_00683" smilref="Title.smil#_00683"> int N = 50; double[] a = new double[N]; for (int i = 0; i &lt; N; i++) a[i] = StdRandom.random(); for (int i = 0; i &lt; N; i++) { double x = 1.0*i/N; double y = a[i]/2.0; double rw = 0.5/N; double rh = a[i]/2.0; StdDraw.filledRectangle(x, y, rw, rh); }</p><p attribs="{'xml:space': 'preserve'}" id="_00684" smilref="Title.smil#_00684"> sorted array of random values</p><p attribs="{'xml:space': 'preserve'}" id="_00685" smilref="Title.smil#_00685"> int N = 50; double[] a = new double[N]; for (int i = 0; i &lt; N; i++) a[i] = StdRandom.random(); Arrays.sort(a); for (int i = 0; i &lt; N; i++) { double x = 1.0*i/N; double y = a[i]/2.0; double rw = 0.5/N; double rh = a[i]/2.0; StdDraw.filledRectangle(x, y, rw, rh); }</p><p attribs="{'xml:space': 'preserve'}" id="_00686" smilref="Title.smil#_00686"> StdDraw plotting examples</p><p attribs="{'xml:space': 'preserve'}" id="_00687" smilref="Title.smil#_00687" /></level3><level3 id="_00008"><h3 id="ch1-s1-ss9" smilref="Title.smil#ch1-s1-ss9" xml:space="preserve">Binary search</h3><pagenum id="p59" page="normal" smilref="Title.smil#p59" /><p attribs="{'xml:space': 'preserve'}" id="_00688" smilref="Title.smil#_00688"> 46</p><p attribs="{'xml:space': 'preserve'}" id="_00689" smilref="Title.smil#_00689"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00690" smilref="Title.smil#_00690"> successful search for 23 lo</p><p attribs="{'xml:space': 'preserve'}" id="_00691" smilref="Title.smil#_00691"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_00692" smilref="Title.smil#_00692"> mid</p><p attribs="{'xml:space': 'preserve'}" id="_00693" smilref="Title.smil#_00693"> lo mid hi</p><p attribs="{'xml:space': 'preserve'}" id="_00694" smilref="Title.smil#_00694"> Binary search The sample Java program that we started with, shown on the facing page, is based on the famous, effective, and widely used binary search algorithm. This example is a prototype of the way in which we will examine new algorithms throughout the book. As with all of the programs we consider, it is both a precise definition of the method and a complete Java implementation that you can download from the booksite. Binary search. We will study the binary search algorithm in detail in Section 3.2, but a brief description is appropriate here. The algorithm is implemented in the static method rank(), which takes an integer key and a sorted array of int values as arguments and returns the index of the key if it is present in the array, -1 otherwise. It accomplishes this task by maintaining variables lo and hi such that the key is in a[lo..hi] if it is in the array, then entering into a loop that tests the middle entry in the interval (at index mid). If the key is equal to a[mid], the return value is mid; otherwise the method cuts the interval size about in half, looking at the left half if the key is less than a[mid] and at the right half if the key is greater than a[mid]. The process terminates when the key is found or the interval is empty. Binary search is effective because it needs to examine just a few array entries (relative to the size of the array) to find the key (or determine that it is not there).</p><p attribs="{'xml:space': 'preserve'}" id="_00695" smilref="Title.smil#_00695"> lo mid hi</p><p attribs="{'xml:space': 'preserve'}" id="_00696" smilref="Title.smil#_00696"> lo mid</p><p attribs="{'xml:space': 'preserve'}" id="_00697" smilref="Title.smil#_00697"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_00698" smilref="Title.smil#_00698"> tinyW.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00699" smilref="Title.smil#_00699"> tinyT.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00700" smilref="Title.smil#_00700"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_00701" smilref="Title.smil#_00701"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_00702" smilref="Title.smil#_00702"> hi lo</p><p attribs="{'xml:space': 'preserve'}" id="_00703" smilref="Title.smil#_00703"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_00704" smilref="Title.smil#_00704"> mid</p><p attribs="{'xml:space': 'preserve'}" id="_00705" smilref="Title.smil#_00705"> Binary search in an ordered array</p><p attribs="{'xml:space': 'preserve'}" id="_00706" smilref="Title.smil#_00706"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00707" smilref="Title.smil#_00707"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00708" smilref="Title.smil#_00708"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00709" smilref="Title.smil#_00709"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00710" smilref="Title.smil#_00710"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_00711" smilref="Title.smil#_00711"> mid</p><p attribs="{'xml:space': 'preserve'}" id="_00712" smilref="Title.smil#_00712"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_00713" smilref="Title.smil#_00713"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00714" smilref="Title.smil#_00714"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00715" smilref="Title.smil#_00715"> unsuccessful search for 50 lo</p><p attribs="{'xml:space': 'preserve'}" id="_00716" smilref="Title.smil#_00716"> mid</p><p attribs="{'xml:space': 'preserve'}" id="_00717" smilref="Title.smil#_00717"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00718" smilref="Title.smil#_00718"> 10 11 12 16 18 23 29 33 48 54 57 68 77 84 98</p><p attribs="{'xml:space': 'preserve'}" id="_00719" smilref="Title.smil#_00719"> Development client. For every algorithm implementation, we include a development client main() that you can use with sample input files provided in the book and on the booksite to learn about the algorithm and to test its performance. In this example, the client reads integers from the file named on the command line, then prints any integers on standard input that do not appear in the fi le. We use small test files such as those shown at right to demonstrate this behavior, and as the basis for traces and examples such as those at left above. We use large test files to model real-world applications and to test performance (see page 48).</p><p attribs="{'xml:space': 'preserve'}" id="_00720" smilref="Title.smil#_00720"> no t in</p><p attribs="{'xml:space': 'preserve'}" id="_00721" smilref="Title.smil#_00721"> tinyW.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00722" smilref="Title.smil#_00722"> 84 48 68 10 18 98 12 23 54 57 48 33 16 77 11 29</p><p attribs="{'xml:space': 'preserve'}" id="_00723" smilref="Title.smil#_00723"> 23 50 10 99 18 23 98 84 11 10 48 77 13 54 98 77 77 68</p><p attribs="{'xml:space': 'preserve'}" id="_00724" smilref="Title.smil#_00724"> Small test files for BinarySearch test client</p><p attribs="{'xml:space': 'preserve'}" id="_00725" smilref="Title.smil#_00725" /><pagenum id="p60" page="normal" smilref="Title.smil#p60" /><p attribs="{'xml:space': 'preserve'}" id="_00726" smilref="Title.smil#_00726"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00727" smilref="Title.smil#_00727"> 47</p><p attribs="{'xml:space': 'preserve'}" id="_00728" smilref="Title.smil#_00728"> Binary Search</p><p attribs="{'xml:space': 'preserve'}" id="_00729" smilref="Title.smil#_00729"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_00730" smilref="Title.smil#_00730"> public class BinarySearch { public static int rank(int key, int[] a) { // Array must be sorted. int lo = 0; int hi = a.length - 1; while (lo &lt;= hi) { // Key is in a[lo..hi] or not present. int mid = lo + (hi - lo) / 2; if (key &lt; a[mid]) hi = mid - 1; else if (key &gt; a[mid]) lo = mid + 1; else return mid; } return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_00731" smilref="Title.smil#_00731"> public static void main(String[] args) { int[] whitelist = In.readInts(args[0]);</p><p attribs="{'xml:space': 'preserve'}" id="_00732" smilref="Title.smil#_00732"> Arrays.sort(whitelist);</p><p attribs="{'xml:space': 'preserve'}" id="_00733" smilref="Title.smil#_00733"> while (!StdIn.isEmpty()) { // Read key, print if not in whitelist. int key = StdIn.readInt(); if (rank(key, whitelist) &lt; 0) StdOut.println(key); }</p><p attribs="{'xml:space': 'preserve'}" id="_00734" smilref="Title.smil#_00734"> }</p><p attribs="{'xml:space': 'preserve'}" id="_00735" smilref="Title.smil#_00735"> }</p><p attribs="{'xml:space': 'preserve'}" id="_00736" smilref="Title.smil#_00736"> This program takes the name of a whitelist file (a sequence of integers) as argument and filters any entry that is on the whitelist from standard input, leaving only integers that are not on the whitelist on standard output. It uses the binary search algorithm, implemented in the static method rank(), to accomplish the task ef&#64257; ciently. See Sec- tion 3.1 for a full discussion of the binary search algorithm, its correctness, its performance analysis, and its applications.</p><p attribs="{'xml:space': 'preserve'}" id="_00737" smilref="Title.smil#_00737"> % java BinarySearch tinyW.txt &lt; tinyT.txt 50 99 13</p><p attribs="{'xml:space': 'preserve'}" id="_00738" smilref="Title.smil#_00738" /><pagenum id="p61" page="normal" smilref="Title.smil#p61" /><p attribs="{'xml:space': 'preserve'}" id="_00739" smilref="Title.smil#_00739"> 48</p><p attribs="{'xml:space': 'preserve'}" id="_00740" smilref="Title.smil#_00740"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00741" smilref="Title.smil#_00741"> Whitelisting. When possible, our development clients are intended to mirror practical situations and demonstrate the need for the algorithm at hand. In this case, the process is known as whitelisting. Speci&#64257; cally, imagine a credit card company that needs to check whether customer transactions are for a valid account. To do so, it can </p><p attribs="{'xml:space': 'preserve'}" id="_00742" smilref="Title.smil#_00742"> Performance. A working program is often not suf&#64257; cient. For example, a much simpler implementation of rank(), which does not even require the array to be sorted, is to check every entry, as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_00743" smilref="Title.smil#_00743"> public static int rank(int key, int[] a) { for (int i = 0; i &lt; a.length; i++) if (a[i] == key) return i; return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_00744" smilref="Title.smil#_00744"> Given this simple and easy-to-understand solution, why do we use mergesort and binary search? If you work Exercise 1.1.38, you will see that your computer is too slow to run this brute-force implementation of rank() for large numbers of inputs (say, 1 million whitelist entries and 10 million transactions). Solving the whitelist problem for a large number of inputs is not feasible without efficient algorithms such as binary search and mergesort. Good performance is often of critical importance, so we lay the groundwork for studying performance in Section 1.4 and analyze the performance characteristics of all of our algorithms (including binary search, in Section 3.1 and mergesort,</p><p attribs="{'xml:space': 'preserve'}" id="_00745" smilref="Title.smil#_00745"> in Section 2.2).</p><p attribs="{'xml:space': 'preserve'}" id="_00746" smilref="Title.smil#_00746"> In the present context, our goal in thoroughly outlining our programming model is to ensure that you can run code like BinarySearch on your computer, use it on test data like ours, and modify it to adapt to various situations (such as those described in the exercises at the end of this section), in order to best understand its applicability. The programming model that we have sketched is designed to facilitate such activities, which are crucial to our approach to studying algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_00747" smilref="Title.smil#_00747" /><pagenum id="p62" page="normal" smilref="Title.smil#p62" /><p attribs="{'xml:space': 'preserve'}" id="_00748" smilref="Title.smil#_00748"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00749" smilref="Title.smil#_00749"> 49</p><p attribs="{'xml:space': 'preserve'}" id="_00750" smilref="Title.smil#_00750"> largeW.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00751" smilref="Title.smil#_00751"> largeT.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00752" smilref="Title.smil#_00752"> 489910 18940 774392 490636 125544 407391 115771 992663 923282 176914 217904 571222 519039 395667 ...</p><p attribs="{'xml:space': 'preserve'}" id="_00753" smilref="Title.smil#_00753"> 1 ,000 ,000 int va lu e s</p><p attribs="{'xml:space': 'preserve'}" id="_00754" smilref="Title.smil#_00754"> 944443 293674 572153 600579 499569 984875 763178 295754 44696 207807 138910 903531 140925 699418 759984 199694 774549 635871 161828 805380 ...</p><p attribs="{'xml:space': 'preserve'}" id="_00755" smilref="Title.smil#_00755"> 10 ,000 ,000 int va lu e s</p><p attribs="{'xml:space': 'preserve'}" id="_00756" smilref="Title.smil#_00756"> no t in</p><p attribs="{'xml:space': 'preserve'}" id="_00757" smilref="Title.smil#_00757"> largeW.txt</p><p attribs="{'xml:space': 'preserve'}" id="_00758" smilref="Title.smil#_00758"> % java BinarySearch largeW.txt &lt; largeT.txt 499569 984875 295754 207807 140925 161828 ...</p><p attribs="{'xml:space': 'preserve'}" id="_00759" smilref="Title.smil#_00759"> 367 ,966 int va lu e s</p><p attribs="{'xml:space': 'preserve'}" id="_00760" smilref="Title.smil#_00760"> Large files for BinarySearch test client</p><p attribs="{'xml:space': 'preserve'}" id="_00761" smilref="Title.smil#_00761" /><pagenum id="p63" page="normal" smilref="Title.smil#p63" /><p attribs="{'xml:space': 'preserve'}" id="_00762" smilref="Title.smil#_00762"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_00763" smilref="Title.smil#_00763"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00764" smilref="Title.smil#_00764"> Perspective</p><p attribs="{'xml:space': 'preserve'}" id="_00765" smilref="Title.smil#_00765"> In this section, we have described a fine and complete programming model that served (and still serves) many programmers for many decades. Modern programming, however, goes one step further. This next level is called data abstraction, sometimes known as object-oriented programming, and is the subject of the next sec- tion. Simply put, the idea behind data abstraction is to allow a program to define data types (sets of values and sets of operations on those values), not just static methods that operate on predefined data types. Object-oriented programming has come into widespread use in recent decades, and data abstraction is central to modern program development. We embrace data abstraction in this book for three primary reasons: </p><p attribs="{'xml:space': 'preserve'}" id="_00766" smilref="Title.smil#_00766" /><pagenum id="p64" page="normal" smilref="Title.smil#p64" /><p attribs="{'xml:space': 'preserve'}" id="_00767" smilref="Title.smil#_00767"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00768" smilref="Title.smil#_00768"> 51</p><p attribs="{'xml:space': 'preserve'}" id="_00769" smilref="Title.smil#_00769"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_00770" smilref="Title.smil#_00770"> Q. What is Java bytecode? A. A low-level version of your program that runs on the Java virtual machine. This level of abstraction makes it easier for the developers of Java to ensure that our programs run on a broad variety of devices. Q. It seems wrong that Java should just let ints overflow and give bad values. Shouldn&#8217;t Java automatically check for over&#64258; ow? A. This issue is a contentious one among programmers. The short answer is that the lack of such checking is one reason such types are called primitive data types. A little knowledge can go a long way in avoiding such problems. We use the int type for small numbers (less than ten decimal digits), and the long type when values run into the billions or more. Q. What is the value of Math.abs(-2147483648)? A. -2147483648. This strange (but true) result is a typical example of the effects of integer over&#64258; ow. Q. How can I initialize a double variable to in&#64257; nity? A. Java has built-in constants available for this purpose: Double.POSITIVE_INFINITY</p><p attribs="{'xml:space': 'preserve'}" id="_00771" smilref="Title.smil#_00771"> and Double.NEGATIVE_INFINITY.</p><p attribs="{'xml:space': 'preserve'}" id="_00772" smilref="Title.smil#_00772"> Q. Can you compare a double to an int? A. Not without doing a type conversion, but remember that Java usually does the requisite type conversion automatically. For example, if x is an int with the value 3, then the expression (x &lt; 3.1) is true&#8212;Java converts x to double (because 3.1 is a double literal) before performing the comparison. Q. What happens if I use a variable before initializing it to a value? A. Java will report a compile-time error if there is any path through your code that would lead to use of an uninitialized variable. Q. What are the values of 1/0 and 1.0/0.0 as Java expressions? A. The first generates a runtime exception for division by zero (which stops your program because the value is unde&#64257; ned); the second has the value Infinity.</p><p attribs="{'xml:space': 'preserve'}" id="_00773" smilref="Title.smil#_00773" /><pagenum id="p65" page="normal" smilref="Title.smil#p65" /><p attribs="{'xml:space': 'preserve'}" id="_00774" smilref="Title.smil#_00774"> 52</p><p attribs="{'xml:space': 'preserve'}" id="_00775" smilref="Title.smil#_00775"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00776" smilref="Title.smil#_00776"> Q&amp;A (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_00777" smilref="Title.smil#_00777"> Q. Can you use &lt; and &gt; to compare String variables? A. No. Those operators are defined only for primitive types. See page 80. Q. What is the result of division and remainder for negative integers? A. The quotient a/b rounds toward 0; the remainder a % b is defined such that (a / b) * b + a % b is always equal to a. For example, -14/3 and 14/-3 are both -4, but</p><p attribs="{'xml:space': 'preserve'}" id="_00778" smilref="Title.smil#_00778"> -14 % 3 is -2 and 14 % -3 is 2.</p><p attribs="{'xml:space': 'preserve'}" id="_00779" smilref="Title.smil#_00779"> Q. Why do we say (a &amp;&amp; b) and not (a &amp; b)? A. The operators &amp;, |, and ^ are bitwise logical operations for integer types that do and, or, and exclusive or (respectively) on each bit position. Thus the value of 10&amp;6 is 2, the value of 10|6 is 14, and the value of 10^6 is 12. We use these operators rarely (but occa- sionally) in this book. The operators &amp;&amp; and || are valid only in boolean expressions are included separately because of short-circuiting: an expression is evaluated left-to-right and the evaluation stops when the value is known. Q. Is ambiguity in nested if statements a problem? A. Yes. In Java, when you write</p><p attribs="{'xml:space': 'preserve'}" id="_00780" smilref="Title.smil#_00780"> if &lt;expr1&gt; if &lt;expr2&gt; &lt;stmntA&gt; else &lt;stmntB&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_00781" smilref="Title.smil#_00781"> it is equivalent to</p><p attribs="{'xml:space': 'preserve'}" id="_00782" smilref="Title.smil#_00782"> if &lt;expr1&gt; { if &lt;expr2&gt; &lt;stmntA&gt; else &lt;stmntB&gt; }</p><p attribs="{'xml:space': 'preserve'}" id="_00783" smilref="Title.smil#_00783"> even if you might have been thinking</p><p attribs="{'xml:space': 'preserve'}" id="_00784" smilref="Title.smil#_00784"> if &lt;expr1&gt; { if &lt;expr2&gt; &lt;stmntA&gt; } else &lt;stmntB&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_00785" smilref="Title.smil#_00785"> Using explicit braces is a good way to avoid this dangling else pitfall. Q. What is the difference between a for loop and its while formulation? A. The code in the for loop header is considered to be in the same block as the for loop body. In a typical for loop, the incrementing variable is not available for use in later statements; in the corresponding while loop, it is. This distinction is often a reason to use a while instead of a for loop. Q. Some Java programmers use int a[] instead of int[] a to declare arrays. What&#8217;s the difference?</p><p attribs="{'xml:space': 'preserve'}" id="_00786" smilref="Title.smil#_00786" /><pagenum id="p66" page="normal" smilref="Title.smil#p66" /><p attribs="{'xml:space': 'preserve'}" id="_00787" smilref="Title.smil#_00787"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00788" smilref="Title.smil#_00788"> 53</p><p attribs="{'xml:space': 'preserve'}" id="_00789" smilref="Title.smil#_00789"> A. In Java, both are legal and equivalent. The former is how arrays are declared in C. The latter is the preferred style in Java since the type of the variable int[] more clearly indicates that it is an array of integers. Q. Why do array indices start at 0 instead of 1? A. This convention originated with machine-language programming, where the address of an array element would be computed by adding the index to the address of the beginning of an array. Starting indices at 1 would entail either a waste of space at the beginning of the array or a waste of time to subtract the 1. Q. If a[] is an array, why does StdOut.println(a) print out a hexadecimal integer, such as @f62373 , instead of the elements of the array? A. Good question. It is printing out the memory address of the array, which, unfortu- nately, is rarely what you want. Q. Why are we not using the standard Java libraries for input and graphics? A. We are using them, but we prefer to work with simpler abstract models. The Java libraries behind StdIn and StdDraw are built for production programming, and the libraries and their APIs are a bit unwieldy. To get an idea of what they are like, look at</p><p attribs="{'xml:space': 'preserve'}" id="_00790" smilref="Title.smil#_00790"> the code in StdIn.java and StdDraw.java.</p><p attribs="{'xml:space': 'preserve'}" id="_00791" smilref="Title.smil#_00791"> Q. Can my program reread data from standard input? A. No. You only get one shot at it, in the same way that you cannot undo println(). Q. What happens if my program attempts to read after standard input is exhausted? A. You will get an error. StdIn.isEmpty() allows you to avoid such an error by checking whether there is more input available. Q. What does this error message mean?</p><p attribs="{'xml:space': 'preserve'}" id="_00792" smilref="Title.smil#_00792"> Exception in thread "main" java.lang.NoClassDefFoundError: StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_00793" smilref="Title.smil#_00793"> A. You probably forgot to put StdIn.java in your working directory. Q. Can a static method take another static method as an argument in Java? A. No. Good question, since many other languages do support this capability.</p><p attribs="{'xml:space': 'preserve'}" id="_00794" smilref="Title.smil#_00794" /><pagenum id="p67" page="normal" smilref="Title.smil#p67" /><p attribs="{'xml:space': 'preserve'}" id="_00795" smilref="Title.smil#_00795"> 54</p><p attribs="{'xml:space': 'preserve'}" id="_00796" smilref="Title.smil#_00796"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00797" smilref="Title.smil#_00797"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_00798" smilref="Title.smil#_00798"> 1.1.1 Give the value of each of the following expressions:</p><p attribs="{'xml:space': 'preserve'}" id="_00799" smilref="Title.smil#_00799"> a. ( 0 + 15 ) / 2 b. 2.0e-6 * 100000000.1 c. true &amp;&amp; false || true &amp;&amp; true</p><p attribs="{'xml:space': 'preserve'}" id="_00800" smilref="Title.smil#_00800"> 1.1.2 Give the type and value of each of the following expressions:</p><p attribs="{'xml:space': 'preserve'}" id="_00801" smilref="Title.smil#_00801"> a. (1 + 2.236)/2 b. 1 + 2 + 3 + 4.0 c. 4.1 &gt;= 4 d. 1 + 2 + "3"</p><p attribs="{'xml:space': 'preserve'}" id="_00802" smilref="Title.smil#_00802"> 1.1.3 Write a program that takes three integer command-line arguments and prints equal if all three are equal, and not equal otherwise. 1.1.4 What (if anything) is wrong with each of the following statements?</p><p attribs="{'xml:space': 'preserve'}" id="_00803" smilref="Title.smil#_00803"> a. if (a &gt; b) then c = 0; b. if a &gt; b { c = 0; } c. if (a &gt; b) c = 0; d. if (a &gt; b) c = 0 else b = 0;</p><p attribs="{'xml:space': 'preserve'}" id="_00804" smilref="Title.smil#_00804"> 1.1.5 Write a code fragment that prints true if the double variables x and y are both strictly between 0 and 1 and false otherwise. 1.1.6 What does the following program print?</p><p attribs="{'xml:space': 'preserve'}" id="_00805" smilref="Title.smil#_00805"> int f = 0; int g = 1; for (int i = 0; i &lt;= 15; i++) { StdOut.println(f); f = f + g; g = f - g; }</p><p attribs="{'xml:space': 'preserve'}" id="_00806" smilref="Title.smil#_00806" /><pagenum id="p68" page="normal" smilref="Title.smil#p68" /><p attribs="{'xml:space': 'preserve'}" id="_00807" smilref="Title.smil#_00807"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00808" smilref="Title.smil#_00808"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_00809" smilref="Title.smil#_00809"> 1.1.7 Give the value printed by each of the following code fragments:</p><p attribs="{'xml:space': 'preserve'}" id="_00810" smilref="Title.smil#_00810"> a.</p><p attribs="{'xml:space': 'preserve'}" id="_00811" smilref="Title.smil#_00811"> double t = 9.0; while (Math.abs(t - 9.0/t) &gt; .001) t = (9.0/t + t) / 2.0; StdOut.printf("%.5f\n", t);</p><p attribs="{'xml:space': 'preserve'}" id="_00812" smilref="Title.smil#_00812"> b.</p><p attribs="{'xml:space': 'preserve'}" id="_00813" smilref="Title.smil#_00813"> int sum = 0; for (int i = 1; i &lt; 1000; i++) for (int j = 0; j &lt; i; j++) sum++; StdOut.println(sum);</p><p attribs="{'xml:space': 'preserve'}" id="_00814" smilref="Title.smil#_00814"> c.</p><p attribs="{'xml:space': 'preserve'}" id="_00815" smilref="Title.smil#_00815"> int sum = 0; for (int i = 1; i &lt; 1000; i *= 2) for (int j = 0; j &lt; 1000; j++) sum++; StdOut.println(sum);</p><p attribs="{'xml:space': 'preserve'}" id="_00816" smilref="Title.smil#_00816"> 1.1.8 What do each of the following print?</p><p attribs="{'xml:space': 'preserve'}" id="_00817" smilref="Title.smil#_00817"> a. System.out.println('b'); b. System.out.println('b' + 'c'); c. System.out.println((char) ('a' + 4));</p><p attribs="{'xml:space': 'preserve'}" id="_00818" smilref="Title.smil#_00818"> Explain each outcome.</p><p attribs="{'xml:space': 'preserve'}" id="_00819" smilref="Title.smil#_00819"> 1.1.9 Write a code fragment that puts the binary representation of a positive integer N into a String s.</p><p attribs="{'xml:space': 'preserve'}" id="_00820" smilref="Title.smil#_00820"> Solution: Java has a built-in method Integer.toBinaryString(N) for this job, but the point of the exercise is to see how such a method might be implemented. Here is a particularly concise solution:</p><p attribs="{'xml:space': 'preserve'}" id="_00821" smilref="Title.smil#_00821"> String s = ""; for (int n = N; n &gt; 0; n /= 2) s = (n % 2) + s;</p><p attribs="{'xml:space': 'preserve'}" id="_00822" smilref="Title.smil#_00822" /><pagenum id="p69" page="normal" smilref="Title.smil#p69" /><p attribs="{'xml:space': 'preserve'}" id="_00823" smilref="Title.smil#_00823"> 56</p><p attribs="{'xml:space': 'preserve'}" id="_00824" smilref="Title.smil#_00824"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00825" smilref="Title.smil#_00825"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_00826" smilref="Title.smil#_00826"> 1.1.10 What is wrong with the following code fragment?</p><p attribs="{'xml:space': 'preserve'}" id="_00827" smilref="Title.smil#_00827"> int[] a; for (int i = 0; i &lt; 10; i++) a[i] = i * i;</p><p attribs="{'xml:space': 'preserve'}" id="_00828" smilref="Title.smil#_00828"> Solution:</p><p attribs="{'xml:space': 'preserve'}" id="_00829" smilref="Title.smil#_00829"> It does not allocate memory for a[] with new. This code results in a</p><p attribs="{'xml:space': 'preserve'}" id="_00830" smilref="Title.smil#_00830"> variable a might not have been initialized compile-time error.</p><p attribs="{'xml:space': 'preserve'}" id="_00831" smilref="Title.smil#_00831"> 1.1.11 Write a code fragment that prints the contents of a two-dimensional boolean array, using * to represent true and a space to represent false. Include row and column numbers. 1.1.12 What does the following code fragment print?</p><p attribs="{'xml:space': 'preserve'}" id="_00832" smilref="Title.smil#_00832"> int[] a = new int[10]; for (int i = 0; i &lt; 10; i++) a[i] = 9 - i; for (int i = 0; i &lt; 10; i++) a[i] = a[a[i]]; for (int i = 0; i &lt; 10; i++) System.out.println(i);</p><p attribs="{'xml:space': 'preserve'}" id="_00833" smilref="Title.smil#_00833"> 1.1.13 Write a code fragment to print the transposition (rows and columns changed) of a two-dimensional array with M rows and N columns. 1.1.14 Write a static method lg() that takes an int value N as argument and returns the largest int not larger than the base-2 logarithm of N. Do not use Math. 1.1.15 Write a static method histogram() that takes an array a[] of int values and an integer M as arguments and returns an array of length M whose ith entry is the number of times the integer i appeared in the argument array. If the values in a[] are all between 0 and M&#8211;1, the sum of the values in the returned array should be equal to</p><p attribs="{'xml:space': 'preserve'}" id="_00834" smilref="Title.smil#_00834"> a.length.</p><p attribs="{'xml:space': 'preserve'}" id="_00835" smilref="Title.smil#_00835"> 1.1.16 Give the value of exR1(6):</p><p attribs="{'xml:space': 'preserve'}" id="_00836" smilref="Title.smil#_00836"> public static String exR1(int n) { if (n &lt;= 0) return ""; return exR1(n-3) + n + exR1(n-2) + n; }</p><p attribs="{'xml:space': 'preserve'}" id="_00837" smilref="Title.smil#_00837" /><pagenum id="p70" page="normal" smilref="Title.smil#p70" /><p attribs="{'xml:space': 'preserve'}" id="_00838" smilref="Title.smil#_00838"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00839" smilref="Title.smil#_00839"> 57</p><p attribs="{'xml:space': 'preserve'}" id="_00840" smilref="Title.smil#_00840"> 1.1.17 Criticize the following recursive function:</p><p attribs="{'xml:space': 'preserve'}" id="_00841" smilref="Title.smil#_00841"> public static String exR2(int n) { String s = exR2(n-3) + n + exR2(n-2) + n; if (n &lt;= 0) return ""; return s; }</p><p attribs="{'xml:space': 'preserve'}" id="_00842" smilref="Title.smil#_00842"> Answer : The base case will never be reached. A call to exR2(3) will result in calls to</p><p attribs="{'xml:space': 'preserve'}" id="_00843" smilref="Title.smil#_00843"> exR2(0), exR2(-3), exR3(-6), and so forth until a StackOverflowError occurs.</p><p attribs="{'xml:space': 'preserve'}" id="_00844" smilref="Title.smil#_00844"> 1.1.18 Consider the following recursive function:</p><p attribs="{'xml:space': 'preserve'}" id="_00845" smilref="Title.smil#_00845"> public static int mystery(int a, int b) { if (b == 0) return 0; if (b % 2 == 0) return mystery(a+a, b/2); return mystery(a+a, b/2) + a; }</p><p attribs="{'xml:space': 'preserve'}" id="_00846" smilref="Title.smil#_00846"> What are the values of mystery(2, 25) and mystery(3, 11)? Given positive integers a and b, describe what value mystery(a, b) computes. Answer the same question, but replace + with * and replace return 0 with return 1.</p><p attribs="{'xml:space': 'preserve'}" id="_00847" smilref="Title.smil#_00847"> 1.1.19 Run the following program on your computer:</p><p attribs="{'xml:space': 'preserve'}" id="_00848" smilref="Title.smil#_00848"> public class Fibonacci { public static long F(int N) { if (N == 0) return 0; if (N == 1) return 1; return F(N-1) + F(N-2); }</p><p attribs="{'xml:space': 'preserve'}" id="_00849" smilref="Title.smil#_00849"> public static void main(String[] args) { for (int N = 0; N &lt; 100; N++) StdOut.println(N + " " + F(N)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_00850" smilref="Title.smil#_00850" /><pagenum id="p71" page="normal" smilref="Title.smil#p71" /><p attribs="{'xml:space': 'preserve'}" id="_00851" smilref="Title.smil#_00851"> 58</p><p attribs="{'xml:space': 'preserve'}" id="_00852" smilref="Title.smil#_00852"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00853" smilref="Title.smil#_00853"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_00854" smilref="Title.smil#_00854"> What is the largest value of N for which this program takes less 1 hour to compute the value of F(N)? Develop a better implementation of F(N) that saves computed values in an array. 1.1.20 Write a recursive static method that computes the value of ln (N !) 1.1.21 Write a program that reads in lines from standard input with each line containing a name and two integers and then uses printf() to print a table with a column of the names, the integers, and the result of dividing the first by the second, accurate to three decimal places. You could use a program like this to tabulate batting averages for baseball players or grades for students. 1.1.22 Write a version of BinarySearch that uses the recursive rank() given on page 25 and traces the method calls. Each time the recursive method is called, print the argument values lo and hi, indented by the depth of the recursion. Hint: Add an argument to the recursive method that keeps track of the depth. 1.1.23 Add to the BinarySearch test client the ability to respond to a second argu- ment: + to print numbers from standard input that are not in the whitelist, to print numbers that are in the whitelist. 1.1.24 Give the sequence of values of p and q that are computed when Euclid&#8217;s algorithm is used to compute the greatest common divisor of 105 and 24. Extend the code given on page 4 to develop a program Euclid that takes two integers from the command line and computes their greatest common divisor, printing out the two arguments for each call on the recursive method. Use your program to compute the greatest common divisor of 1111111 and 1234567. 1.1.25 Use mathematical induction to prove that Euclid&#8217;s algorithm computes the greatest common divisor of any pair of nonnegative integers p and q.</p><p attribs="{'xml:space': 'preserve'}" id="_00855" smilref="Title.smil#_00855" /><pagenum id="p72" page="normal" smilref="Title.smil#p72" /><p attribs="{'xml:space': 'preserve'}" id="_00856" smilref="Title.smil#_00856"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00857" smilref="Title.smil#_00857"> 59</p><p attribs="{'xml:space': 'preserve'}" id="_00858" smilref="Title.smil#_00858"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_00859" smilref="Title.smil#_00859"> 1.1.26 Sorting three numbers. Suppose that the variables a, b, c, and t are all of the same numeric primitive type. Show that the following code puts a, b, and c in ascending order:</p><p attribs="{'xml:space': 'preserve'}" id="_00860" smilref="Title.smil#_00860"> if (a &gt; b) { t = a; a = b; b = t; } if (a &gt; c) { t = a; a = c; c = t; } if (b &gt; c) { t = b; b = c; c = t; }</p><p attribs="{'xml:space': 'preserve'}" id="_00861" smilref="Title.smil#_00861"> 1.1.27 Binomial distribution. Estimate the number of recursive calls that would be used by the code</p><p attribs="{'xml:space': 'preserve'}" id="_00862" smilref="Title.smil#_00862"> public static double binomial(int N, int k, double p) { if ((N == 0) &amp;&amp; (k == 0)) return 1.0; if ((N &lt; 0) || (k &lt; 0)) return 0.0; return (1 - p)*binomial(N-1, k, p) + p*binomial(N-1, k-1, p); }</p><p attribs="{'xml:space': 'preserve'}" id="_00863" smilref="Title.smil#_00863"> to compute binomial(100, 50, 0.25). Develop a better implementation that is based on saving computed values in an array.</p><p attribs="{'xml:space': 'preserve'}" id="_00864" smilref="Title.smil#_00864"> 1.1.28 Remove duplicates. Modify the test client in BinarySearch to remove any duplicate keys in the whitelist after the sort. 1.1.29 Equal keys. Add to BinarySearch a static method rank() that takes a key and a sorted array of int values (some of which may be equal) as arguments and returns the number of elements that are smaller than the key and a similar method count() that returns the number of elements equal to the key. Note : If i and j are the values returned by rank(key, a) and count(key, a) respectively, then a[i..i+j-1] are the values in the array that are equal to key. 1.1.30 Array exercise. Write a code fragment that creates an N-by-N boolean array a[][] such that a[i][j] is true if i and j are relatively prime (have no common fac- tors), and false otherwise. 1.1.31 Random connections. Write a program that takes as command-line arguments an integer N and a double value p (between 0 and 1), plots N equally spaced dots of size .05 on the circumference of a circle, and then, with probability p for each pair of points, draws a gray line connecting them.</p><p attribs="{'xml:space': 'preserve'}" id="_00865" smilref="Title.smil#_00865" /><pagenum id="p73" page="normal" smilref="Title.smil#p73" /><p attribs="{'xml:space': 'preserve'}" id="_00866" smilref="Title.smil#_00866"> 60</p><p attribs="{'xml:space': 'preserve'}" id="_00867" smilref="Title.smil#_00867"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00868" smilref="Title.smil#_00868"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_00869" smilref="Title.smil#_00869"> 1.1.32 Histogram. Suppose that the standard input stream is a sequence of double values. Write a program that takes an integer N and two double values l and r from the command line and uses StdDraw to plot a histogram of the count of the numbers in the standard input stream that fall in each of the N intervals defined by dividing (l , r) into N equal-sized intervals. 1.1.33 Matrix library. Write a library Matrix that implements the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_00870" smilref="Title.smil#_00870"> public class Matrix static double dot(double[] x, double[] y)</p><p attribs="{'xml:space': 'preserve'}" id="_00871" smilref="Title.smil#_00871"> static double[][] mult(double[][] a, double[][] b)</p><p attribs="{'xml:space': 'preserve'}" id="_00872" smilref="Title.smil#_00872"> static double[][] transpose(double[][] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00873" smilref="Title.smil#_00873"> static double[] mult(double[][] a, double[] x)</p><p attribs="{'xml:space': 'preserve'}" id="_00874" smilref="Title.smil#_00874"> static double[] mult(double[] y, double[][] a)</p><p attribs="{'xml:space': 'preserve'}" id="_00875" smilref="Title.smil#_00875"> vector dot product</p><p attribs="{'xml:space': 'preserve'}" id="_00876" smilref="Title.smil#_00876"> matrix-matrix product</p><p attribs="{'xml:space': 'preserve'}" id="_00877" smilref="Title.smil#_00877"> transpose</p><p attribs="{'xml:space': 'preserve'}" id="_00878" smilref="Title.smil#_00878"> matrix-vector product</p><p attribs="{'xml:space': 'preserve'}" id="_00879" smilref="Title.smil#_00879"> vector-matrix product</p><p attribs="{'xml:space': 'preserve'}" id="_00880" smilref="Title.smil#_00880"> Develop a test client that reads values from standard input and tests all the methods.</p><p attribs="{'xml:space': 'preserve'}" id="_00881" smilref="Title.smil#_00881"> 1.1.34 Filtering. Which of the following require saving all the values from standard input (in an array, say), and which could be implemented as a filter using only a fixed number of variables and arrays of fixed size (not dependent on N)? For each, the input comes from standard input and consists of N real numbers between 0 and 1.</p><p attribs="{'xml:space': 'preserve'}" id="_00882" smilref="Title.smil#_00882"> </p><p attribs="{'xml:space': 'preserve'}" id="_00883" smilref="Title.smil#_00883" /><pagenum id="p74" page="normal" smilref="Title.smil#p74" /><p attribs="{'xml:space': 'preserve'}" id="_00884" smilref="Title.smil#_00884"> 1.1 </p><p attribs="{'xml:space': 'preserve'}" id="_00885" smilref="Title.smil#_00885"> 61</p><p attribs="{'xml:space': 'preserve'}" id="_00886" smilref="Title.smil#_00886"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_00887" smilref="Title.smil#_00887"> 1.1.35 Dice simulation. The following code computes the exact probability distribution for the sum of two dice:</p><p attribs="{'xml:space': 'preserve'}" id="_00888" smilref="Title.smil#_00888"> int SIDES = 6; double[] dist = new double[2*SIDES+1]; for (int i = 1; i &lt;= SIDES; i++) for (int j = 1; j &lt;= SIDES; j++) dist[i+j] += 1.0;</p><p attribs="{'xml:space': 'preserve'}" id="_00889" smilref="Title.smil#_00889"> for (int k = 2; k &lt;= 2*SIDES; k++) dist[k] /= 36.0;</p><p attribs="{'xml:space': 'preserve'}" id="_00890" smilref="Title.smil#_00890"> The value dist[i] is the probability that the dice sum to k. Run experiments to validate this calculation simulating N dice throws, keeping track of the frequencies of occurrence of each value when you compute the sum of two random integers between 1 and 6. How large does N have to be before your empirical results match the exact results to three decimal places?</p><p attribs="{'xml:space': 'preserve'}" id="_00891" smilref="Title.smil#_00891"> 1.1.36 Empirical shuffle check. Run computational experiments to check that our shuffling code on page 32 works as advertised. Write a program ShuffleTest that takes command-line arguments M and N, does N shuffles of an array of size M that is initialized with a[i] = i before each shuf&#64258; e, and prints an M-by-M table such that row i gives the number of times i wound up in position j for all j. All entries in the array should be close to N/M. 1.1.37 Bad shuf&#64258; ing. Suppose that you choose a random integer between 0 and N-1 in our shuffling code instead of one between i and N-1. Show that the resulting order is not equally likely to be one of the N! possibilities. Run the test of the previous exercise for this version. 1.1.38 Binary search versus brute-force search. Write a program BruteForceSearch that uses the brute-force search method given on page 48 and compare its running time on your computer with that of BinarySearch for largeW.txt and largeT.txt.</p><p attribs="{'xml:space': 'preserve'}" id="_00892" smilref="Title.smil#_00892" /><pagenum id="p75" page="normal" smilref="Title.smil#p75" /><p attribs="{'xml:space': 'preserve'}" id="_00893" smilref="Title.smil#_00893"> 62</p><p attribs="{'xml:space': 'preserve'}" id="_00894" smilref="Title.smil#_00894"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00895" smilref="Title.smil#_00895"> EXPERIMENTS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_00896" smilref="Title.smil#_00896"> 1.1.39 Random matches. Write a BinarySearch client that takes an int value T as command-line argument and runs T trials of the following experiment for N = 103, 104, 105, and 106: generate two arrays of N randomly generated positive six-digit int values, and find the number of values that appear in both arrays. Print a table giving the average value of this quantity over the T trials for each value of N.</p><p attribs="{'xml:space': 'preserve'}" id="_00897" smilref="Title.smil#_00897" /><pagenum id="p76" page="normal" smilref="Title.smil#p76" /><p attribs="{'xml:space': 'preserve'}" id="_00898" smilref="Title.smil#_00898"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_00899" smilref="Title.smil#_00899" /><pagenum id="p78" page="normal" smilref="Title.smil#p78" /><p attribs="{'xml:space': 'preserve'}" id="_00900" smilref="Title.smil#_00900"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_00901" smilref="Title.smil#_00901"> 65</p><p attribs="{'xml:space': 'preserve'}" id="_00902" smilref="Title.smil#_00902"> Using abstract data types You do not need to know how a data type is implemented in order to be able to use it, so we begin by describing how to write programs that use a simple data type named Counter whose values are a name and a nonnegative integer and whose operations are create and initialize to zero, increment by one, and examine the current value. This abstraction is useful in many contexts. For example, it would be reasonable to use such a data type in electronic voting software, to ensure that the only thing that a voter can do is increment a chosen candidate&#8217;s tally by one. Or, we might use a Counter to keep track of fundamental operations when analyzing the performance of algorithms. To use a Counter, you need to learn our mechanism for specifying the operations defined in the data type and the Java language mechanisms for creating and manipulating data-type values. Such mechanisms are critically important in modern programming, and we use them throughout this book, so this first example is worthy of careful attention.</p><p attribs="{'xml:space': 'preserve'}" id="_00903" smilref="Title.smil#_00903"> API for an abstract data type. To specify the behavior of an abstract data type, we use an application programming interface (API), which is a list of constructors and instance methods (operations), with an informal description of the effect of each, as in this API</p><p attribs="{'xml:space': 'preserve'}" id="_00904" smilref="Title.smil#_00904"> for Counter:</p><p attribs="{'xml:space': 'preserve'}" id="_00905" smilref="Title.smil#_00905"> public class Counter</p><p attribs="{'xml:space': 'preserve'}" id="_00906" smilref="Title.smil#_00906"> Counter(String id)</p><p attribs="{'xml:space': 'preserve'}" id="_00907" smilref="Title.smil#_00907"> void increment()</p><p attribs="{'xml:space': 'preserve'}" id="_00908" smilref="Title.smil#_00908"> int tally()</p><p attribs="{'xml:space': 'preserve'}" id="_00909" smilref="Title.smil#_00909"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_00910" smilref="Title.smil#_00910"> create a counter named id increment the counter by one number of increments since creation string representation</p><p attribs="{'xml:space': 'preserve'}" id="_00911" smilref="Title.smil#_00911"> An API for a counter</p><p attribs="{'xml:space': 'preserve'}" id="_00912" smilref="Title.smil#_00912"> Even though the basis of a data-type definition is a set of values, the role of the values is not visible from the API, only the operations on those values. Accordingly, an ADT definition has many similarities with a library of static methods (see page 24): </p><p attribs="{'xml:space': 'preserve'}" id="_00913" smilref="Title.smil#_00913" /><pagenum id="p79" page="normal" smilref="Title.smil#p79" /><p attribs="{'xml:space': 'preserve'}" id="_00914" smilref="Title.smil#_00914"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_00915" smilref="Title.smil#_00915"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00916" smilref="Title.smil#_00916"> </p><p attribs="{'xml:space': 'preserve'}" id="_00917" smilref="Title.smil#_00917"> Inherited methods. Various Java conventions enable a data type to take advantage of built-in language mechanisms by including specific methods in the API. For example, all Java data types inherit a toString() method that returns a String representation of the data-type values. Java calls this method when any data-type value is to be concatenated with a String value with the + operator. The default implementation is not particularly useful (it gives a string representation of the memory address of the data-type value), so we often provide an implementation that overrides the default, and include toString() in the API whenever we do so. Other examples of such methods include</p><p attribs="{'xml:space': 'preserve'}" id="_00918" smilref="Title.smil#_00918"> equals(), compareTo(), and hashCode() (see page 101).</p><p attribs="{'xml:space': 'preserve'}" id="_00919" smilref="Title.smil#_00919"> Client code. As with modular programming based on static methods, the API allows us to write client code without knowing details of the implementation (and to write implementation code without knowing details of any particular client). The mechanisms introduced on page 28 for organizing programs as independent modules are useful for all Java classes, and thus are effective for modular programming with ADTs as well as for libraries of static methods. Accordingly, we can use an ADT in any program provided that the source code is in a .java file in the same directory, or in the standard Java library, or accessible through an import statement, or through one of the classpath mechanisms described on the booksite. All of the benefits of modular programming follow. By encapsulating all the code that implements a data type within a single Java class, we enable the development of client code at a higher level of abstraction. To develop client code, you need to be able to declare variables, create objects to hold datatype values, and provide access to the values for instance methods to operate on them. These processes are different from the corresponding processes for primitive types, though you will notice many similarities.</p><p attribs="{'xml:space': 'preserve'}" id="_00920" smilref="Title.smil#_00920" /></level3><level3 id="_00009"><h3 id="ch1-s2-ss10" smilref="Title.smil#ch1-s2-ss10" xml:space="preserve">Objects</h3><pagenum id="p80" page="normal" smilref="Title.smil#p80" /><p attribs="{'xml:space': 'preserve'}" id="_00921" smilref="Title.smil#_00921"> Objects. Naturally, you can declare that a variable heads is to be associated with data of type Counter with the code</p><p attribs="{'xml:space': 'preserve'}" id="_00922" smilref="Title.smil#_00922"> Counter heads;</p><p attribs="{'xml:space': 'preserve'}" id="_00923" smilref="Title.smil#_00923"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_00924" smilref="Title.smil#_00924"> 67</p><p attribs="{'xml:space': 'preserve'}" id="_00925" smilref="Title.smil#_00925"> one Counter object</p><p attribs="{'xml:space': 'preserve'}" id="_00926" smilref="Title.smil#_00926"> but how can you assign values or specify operations? The answer to this question involves a fundamental concept in data abstraction: an object is an entity that can take on a data-type value. Objects are characterized by three essential prop- erties: state, identity, and behavior. The state of an object is a value from its data type. The identity of an object distinguishes one object from another. It is useful to think of an object&#8217;s identity as the place where its value is stored in memory. The behavior of an object is the effect of data-type operations. The implementation has the sole responsibility for maintaining an object&#8217;s identity, so that client code can use a data type without regard to the representation of its state by conforming to an API that describes an object&#8217;s behavior. An ob- ject&#8217;s state might be used to provide information to a client or cause a side effect or be changed by one of its data type&#8217;s operations, but the details of the representation of the data-type value are not relevant to client code. A reference is a mechanism for accessing an ob- ject. Java nomenclature makes clear the distinction from primitive types (where variables are associated with values) by using the term reference types for nonprimitive types. The details of implementing references vary in Java implementations, but it is useful to think of a reference as a memory address, as shown at right (for brevity, we use three-digit memory addresses in the diagram).</p><p attribs="{'xml:space': 'preserve'}" id="_00927" smilref="Title.smil#_00927"> heads 460 tails 612</p><p attribs="{'xml:space': 'preserve'}" id="_00928" smilref="Title.smil#_00928"> two Counter objects</p><p attribs="{'xml:space': 'preserve'}" id="_00929" smilref="Title.smil#_00929"> heads 460</p><p attribs="{'xml:space': 'preserve'}" id="_00930" smilref="Title.smil#_00930"> 460</p><p attribs="{'xml:space': 'preserve'}" id="_00931" smilref="Title.smil#_00931"> 460</p><p attribs="{'xml:space': 'preserve'}" id="_00932" smilref="Title.smil#_00932"> Creating objects. Each data-type value is stored in an object. To create (or instantiate) an individual object, we invoke a constructor by using the keyword new, followed by the class name, followed by () (or a list of argument values enclosed in parentheses, if the constructor takes arguments). A constructor has no return type because it always returns a reference to an object of its data type. Each time that a client uses new(), the system </p><p attribs="{'xml:space': 'preserve'}" id="_00933" smilref="Title.smil#_00933"> 612</p><p attribs="{'xml:space': 'preserve'}" id="_00934" smilref="Title.smil#_00934"> Object representation</p><p attribs="{'xml:space': 'preserve'}" id="_00935" smilref="Title.smil#_00935"> reference</p><p attribs="{'xml:space': 'preserve'}" id="_00936" smilref="Title.smil#_00936"> identity (details hidden</p><p attribs="{'xml:space': 'preserve'}" id="_00937" smilref="Title.smil#_00937"> identity</p><p attribs="{'xml:space': 'preserve'}" id="_00938" smilref="Title.smil#_00938"> of heads</p><p attribs="{'xml:space': 'preserve'}" id="_00939" smilref="Title.smil#_00939"> identity</p><p attribs="{'xml:space': 'preserve'}" id="_00940" smilref="Title.smil#_00940"> of tails</p><p attribs="{'xml:space': 'preserve'}" id="_00941" smilref="Title.smil#_00941" /><pagenum id="p81" page="normal" smilref="Title.smil#p81" /><p attribs="{'xml:space': 'preserve'}" id="_00942" smilref="Title.smil#_00942"> 68</p><p attribs="{'xml:space': 'preserve'}" id="_00943" smilref="Title.smil#_00943"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00944" smilref="Title.smil#_00944"> themselves. We can create any number of objects from the same class&#8212; each object has its own identity and may or may not store the same value as another object of the same type. For example, the code</p><p attribs="{'xml:space': 'preserve'}" id="_00945" smilref="Title.smil#_00945"> declaration to associate variable with object reference</p><p attribs="{'xml:space': 'preserve'}" id="_00946" smilref="Title.smil#_00946"> invoke constructor to create an object</p><p attribs="{'xml:space': 'preserve'}" id="_00947" smilref="Title.smil#_00947"> Counter heads = new Counter("heads");</p><p attribs="{'xml:space': 'preserve'}" id="_00948" smilref="Title.smil#_00948"> Creating an object</p><p attribs="{'xml:space': 'preserve'}" id="_00949" smilref="Title.smil#_00949"> Counter heads = new Counter("heads"); Counter tails = new Counter("tails");</p><p attribs="{'xml:space': 'preserve'}" id="_00950" smilref="Title.smil#_00950"> creates two different Counter objects. In an abstract data type, details of the representation of the value are hidden from client code. You might assume that the value associated with each Counter object is a String name and an int tally, but you cannot write code that depends on any specific representation (or even know whether that assumption is true&#8212;perhaps the tally is a long value). Invoking instance methods. The purpose of an instance method is to operate on datatype values, so the Java language includes a special mechanism to invoke instance methods that emphasizes a connection to an object. Speci&#64257; cally, we invoke an instance method by writing a variable name that refers to an object, followed by a period, followed by an instance method name, followed by 0 or more arguments, enclosed in parentheses and separated by commas. An instance method might change the data-type value or just examine the data-type value. Instance methods have all of the properties of static methods that we considered on page 24&#8212;arguments are passed by value, method names can be overloaded, they may have a return value, and they may cause side effects&#8212;but they have an additional property that characterizes them: each invocation is associated with an object. For example, the code</p><p attribs="{'xml:space': 'preserve'}" id="_00951" smilref="Title.smil#_00951"> invoke an instance method that changes the object&#8217;s value</p><p attribs="{'xml:space': 'preserve'}" id="_00952" smilref="Title.smil#_00952"> invoke a constructor (create an object)</p><p attribs="{'xml:space': 'preserve'}" id="_00953" smilref="Title.smil#_00953"> as a statement (void return value)</p><p attribs="{'xml:space': 'preserve'}" id="_00954" smilref="Title.smil#_00954"> heads.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_00955" smilref="Title.smil#_00955"> object name</p><p attribs="{'xml:space': 'preserve'}" id="_00956" smilref="Title.smil#_00956"> as an expression</p><p attribs="{'xml:space': 'preserve'}" id="_00957" smilref="Title.smil#_00957"> Counter heads;</p><p attribs="{'xml:space': 'preserve'}" id="_00958" smilref="Title.smil#_00958"> declaration</p><p attribs="{'xml:space': 'preserve'}" id="_00959" smilref="Title.smil#_00959"> with new (constructor)</p><p attribs="{'xml:space': 'preserve'}" id="_00960" smilref="Title.smil#_00960"> heads = new Counter ("heads");</p><p attribs="{'xml:space': 'preserve'}" id="_00961" smilref="Title.smil#_00961"> heads.tally() - tails.tally()</p><p attribs="{'xml:space': 'preserve'}" id="_00962" smilref="Title.smil#_00962"> heads.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_00963" smilref="Title.smil#_00963"> object name</p><p attribs="{'xml:space': 'preserve'}" id="_00964" smilref="Title.smil#_00964"> invoke an instance method that accesses the object&#8217;s value</p><p attribs="{'xml:space': 'preserve'}" id="_00965" smilref="Title.smil#_00965"> via automatic type conversion (toString())</p><p attribs="{'xml:space': 'preserve'}" id="_00966" smilref="Title.smil#_00966"> StdOut.println( heads );</p><p attribs="{'xml:space': 'preserve'}" id="_00967" smilref="Title.smil#_00967"> invoke heads.toString()</p><p attribs="{'xml:space': 'preserve'}" id="_00968" smilref="Title.smil#_00968"> Invoking instance methods</p><p attribs="{'xml:space': 'preserve'}" id="_00969" smilref="Title.smil#_00969"> invokes the instance method increment() to operate on the Counter object heads (in this case the operation involves incrementing the tally), and the code</p><p attribs="{'xml:space': 'preserve'}" id="_00970" smilref="Title.smil#_00970"> heads.tally() - tails.tally();</p><p attribs="{'xml:space': 'preserve'}" id="_00971" smilref="Title.smil#_00971"> invokes the instance method tally() twice, first to operate on the Counter object heads and then to operate on the Counter object tails (in this case the</p><p attribs="{'xml:space': 'preserve'}" id="_00972" smilref="Title.smil#_00972" /><pagenum id="p82" page="normal" smilref="Title.smil#p82" /><p attribs="{'xml:space': 'preserve'}" id="_00973" smilref="Title.smil#_00973"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_00974" smilref="Title.smil#_00974"> 69</p><p attribs="{'xml:space': 'preserve'}" id="_00975" smilref="Title.smil#_00975"> operation involves returning the tally as an int value). As these examples illustrate, you can use calls on instance methods in client code in the same way as you use calls on static methods&#8212;as statements (void methods) or values in expressions (methods that return a value). The primary purpose of static methods is to implement functions; the primary purpose of non-static (instance) methods is to implement data-type opera- tions. Either type of method may appear in client code, but you can easily distinguish between them, because a static method call starts with a class name (uppercase, by convention) and a non-static method call always starts with an object name (lower- case, by convention). These differences are summarized in the table at right.</p><p attribs="{'xml:space': 'preserve'}" id="_00976" smilref="Title.smil#_00976"> examine or change object value</p><p attribs="{'xml:space': 'preserve'}" id="_00977" smilref="Title.smil#_00977"> reference to object and argument(s)</p><p attribs="{'xml:space': 'preserve'}" id="_00978" smilref="Title.smil#_00978"> primary purpose</p><p attribs="{'xml:space': 'preserve'}" id="_00979" smilref="Title.smil#_00979"> Instance methods versus static methods</p><p attribs="{'xml:space': 'preserve'}" id="_00980" smilref="Title.smil#_00980"> parameters</p><p attribs="{'xml:space': 'preserve'}" id="_00981" smilref="Title.smil#_00981"> invoked with</p><p attribs="{'xml:space': 'preserve'}" id="_00982" smilref="Title.smil#_00982"> object name</p><p attribs="{'xml:space': 'preserve'}" id="_00983" smilref="Title.smil#_00983"> class name</p><p attribs="{'xml:space': 'preserve'}" id="_00984" smilref="Title.smil#_00984"> argument(s)</p><p attribs="{'xml:space': 'preserve'}" id="_00985" smilref="Title.smil#_00985"> compute return value</p><p attribs="{'xml:space': 'preserve'}" id="_00986" smilref="Title.smil#_00986"> instance method</p><p attribs="{'xml:space': 'preserve'}" id="_00987" smilref="Title.smil#_00987"> static method</p><p attribs="{'xml:space': 'preserve'}" id="_00988" smilref="Title.smil#_00988"> sample call</p><p attribs="{'xml:space': 'preserve'}" id="_00989" smilref="Title.smil#_00989"> head.increment()</p><p attribs="{'xml:space': 'preserve'}" id="_00990" smilref="Title.smil#_00990"> Math.sqrt(2.0)</p><p attribs="{'xml:space': 'preserve'}" id="_00991" smilref="Title.smil#_00991"> Using objects. Declarations give us variable names for objects that we can use in code not just to create objects and invoke instance methods, but also in the same way as we use variable names for integers, fl oating-point numbers, and other primitive types. To develop client code for a given data type, we: </p><p attribs="{'xml:space': 'preserve'}" id="_00992" smilref="Title.smil#_00992"> Assignment statements. An assignment statement with a reference type creates a copy of the reference. The assignment statement does not create a new object, just another reference to an existing object. This situation is known as aliasing: both variables refer to the same object. The effect of aliasing is a bit unexpected, because it is different for variables holding values of a primitive type. Be sure that you understand the difference.</p><p attribs="{'xml:space': 'preserve'}" id="_00993" smilref="Title.smil#_00993" /><pagenum id="p83" page="normal" smilref="Title.smil#p83" /><p attribs="{'xml:space': 'preserve'}" id="_00994" smilref="Title.smil#_00994"> 70</p><p attribs="{'xml:space': 'preserve'}" id="_00995" smilref="Title.smil#_00995"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_00996" smilref="Title.smil#_00996"> public class Flips { public static void main(String[] args) { int T = Integer.parseInt(args[0]); Counter heads = new Counter("heads"); Counter tails = new Counter("tails"); for (int t = 0; t &lt; T; t++) if (StdRandom.bernoulli(0.5)) heads.increment(); else tails.increment(); StdOut.println(heads); StdOut.println(tails); int d = heads.tally() - tails.tally(); StdOut.println("delta: " + Math.abs(d)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_00997" smilref="Title.smil#_00997"> Counter client that simulates T coin f lips</p><p attribs="{'xml:space': 'preserve'}" id="_00998" smilref="Title.smil#_00998"> If x and y are variables of a primitive type, then the assignment x = y copies the value of y to x. For reference types, the reference is copied (not the value). Aliasing is a common source of bugs in Java programs, as illustrated by the following example:</p><p attribs="{'xml:space': 'preserve'}" id="_00999" smilref="Title.smil#_00999"> Counter c1 = new Counter("ones"); c1.increment(); Counter c2 = c1; c2.increment(); StdOut.println(c1);</p><p attribs="{'xml:space': 'preserve'}" id="_01000" smilref="Title.smil#_01000"> With a typical toString() implementation this code would print the string "2 ones" which may or may not be what was intended and is counterintuitive at fi rst. Such bugs are common in programs written by people without much experience in using objects (that may be you, so pay attention here!). Changing the state of an object impacts all code involving aliased variables referencing that ob- ject. We are used to thinking of two different variables of primitive types as being independent, but that intuition does not carry over to variables of reference types.</p><p attribs="{'xml:space': 'preserve'}" id="_01001" smilref="Title.smil#_01001"> % java Flips 10 5 heads 5 tails delta: 0</p><p attribs="{'xml:space': 'preserve'}" id="_01002" smilref="Title.smil#_01002"> % java Flips 10 8 heads 2 tails delta: 6</p><p attribs="{'xml:space': 'preserve'}" id="_01003" smilref="Title.smil#_01003"> % java Flips 1000000 499710 heads 500290 tails delta: 580</p><p attribs="{'xml:space': 'preserve'}" id="_01004" smilref="Title.smil#_01004"> Counter c1; c1 = new Counter("ones"); c1.increment(); Counter c2 = c1; c2.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_01005" smilref="Title.smil#_01005"> c1 811 c2 811</p><p attribs="{'xml:space': 'preserve'}" id="_01006" smilref="Title.smil#_01006"> references to same object</p><p attribs="{'xml:space': 'preserve'}" id="_01007" smilref="Title.smil#_01007"> 811 2</p><p attribs="{'xml:space': 'preserve'}" id="_01008" smilref="Title.smil#_01008"> reference to "ones"</p><p attribs="{'xml:space': 'preserve'}" id="_01009" smilref="Title.smil#_01009"> Aliasing</p><p attribs="{'xml:space': 'preserve'}" id="_01010" smilref="Title.smil#_01010" /><pagenum id="p84" page="normal" smilref="Title.smil#p84" /><p attribs="{'xml:space': 'preserve'}" id="_01011" smilref="Title.smil#_01011"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01012" smilref="Title.smil#_01012"> 71</p><p attribs="{'xml:space': 'preserve'}" id="_01013" smilref="Title.smil#_01013"> Objects as arguments. You can pass objects as arguments to methods. This ability typically simplifies client code. For example, when we use a Counter as an argument, we are essentially passing both a name and a tally, but need only specify one variable. When we call a method with arguments, the effect in Java is as if each argument value were to appear on the right-hand side of an assignment statement with the corresponding argument name on the left. That is, Java passes a copy of the argument value from the calling program to the method. This arrangement is known as pass by value (see page 24). One important consequence is that the method cannot change the value of a caller&#8217;s variable. For primitive types, this policy is what we expect (the two variables are inde- pendent), but each time that we use a reference type as a method argument we create an alias, so we must be cautious. In other words, the convention is to pass the reference by value (make a copy of it) but to pass the object by reference. For example, if we pass a reference to an object of type Counter, the method cannot change the original reference (make it point to a different Counter), but it can change the value of the object, for example by using the reference to call increment().</p><p attribs="{'xml:space': 'preserve'}" id="_01014" smilref="Title.smil#_01014"> Objects as return values. Naturally, you can also use an object as a return value from a method. The method might return an object passed to it as an argument, as in the example below, or it might create an object and return a reference to it. This capability is important because Java methods allow only one return value&#8212;using objects enables us to write code that, in effect, returns multiple values.</p><p attribs="{'xml:space': 'preserve'}" id="_01015" smilref="Title.smil#_01015"> public class FlipsMax { public static Counter max(Counter x, Counter y) { if (x.tally() &gt; y.tally()) return x; else return y; }</p><p attribs="{'xml:space': 'preserve'}" id="_01016" smilref="Title.smil#_01016"> % java FlipsMax 1000000 500281 tails wins</p><p attribs="{'xml:space': 'preserve'}" id="_01017" smilref="Title.smil#_01017"> public static void main(String[] args) { int T = Integer.parseInt(args[0]); Counter heads = new Counter("heads"); Counter tails = new Counter("tails"); for (int t = 0; t &lt; T; t++) if (StdRandom.bernoulli(0.5)) heads.increment(); else tails.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_01018" smilref="Title.smil#_01018"> if (heads.tally() == tails.tally()) StdOut.println("Tie"); else StdOut.println(max(heads, tails) + " wins"); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01019" smilref="Title.smil#_01019"> Example of a static method with object arguments and return values</p><p attribs="{'xml:space': 'preserve'}" id="_01020" smilref="Title.smil#_01020" /><pagenum id="p85" page="normal" smilref="Title.smil#p85" /><p attribs="{'xml:space': 'preserve'}" id="_01021" smilref="Title.smil#_01021"> 72</p><p attribs="{'xml:space': 'preserve'}" id="_01022" smilref="Title.smil#_01022"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01023" smilref="Title.smil#_01023"> Arrays are objects. In Java, every value of any nonprimitive type is an object. In par- ticular, arrays are objects. As with strings, there is special language support for certain operations on arrays: declarations, initialization, and indexing. As with any other ob- ject, when we pass an array to a method or use an array variable on the right hand side of an assignment statement, we are making a copy of the array reference, not a copy of the array. This convention is appropriate for the typical case where we expect the method to be able to modify the array, by rearranging its entries, as, for example, in java.util.Arrays.sort() or the shuffle() method that we considered on page 32.</p><p attribs="{'xml:space': 'preserve'}" id="_01024" smilref="Title.smil#_01024"> Arrays of objects. Array entries can be of any type, as we have already seen: args[] in our main() implementations is an array of String objects. When we create an array of objects, we do so in two steps: </p><p attribs="{'xml:space': 'preserve'}" id="_01025" smilref="Title.smil#_01025"> public class Rolls { public static void main(String[] args) { int T = Integer.parseInt(args[0]); int SIDES = 6; Counter[] rolls = new Counter[SIDES+1]; for (int i = 1; i &lt;= SIDES; i++) rolls[i] = new Counter(i + "'s");</p><p attribs="{'xml:space': 'preserve'}" id="_01026" smilref="Title.smil#_01026"> for (int t = 0; t &lt; T; t++) { int result = StdRandom.uniform(1, SIDES+1); rolls[result].increment(); } for (int i = 1; i &lt;= SIDES; i++) StdOut.println(rolls[i]); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01027" smilref="Title.smil#_01027"> Counter client that simulates T rolls of a die</p><p attribs="{'xml:space': 'preserve'}" id="_01028" smilref="Title.smil#_01028"> % java Rolls 1000000 167308 1's 166540 2's 166087 3's 167051 4's 166422 5's 166592 6's</p><p attribs="{'xml:space': 'preserve'}" id="_01029" smilref="Title.smil#_01029" /><pagenum id="p86" page="normal" smilref="Title.smil#p86" /><p attribs="{'xml:space': 'preserve'}" id="_01030" smilref="Title.smil#_01030"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01031" smilref="Title.smil#_01031"> 73</p><p attribs="{'xml:space': 'preserve'}" id="_01032" smilref="Title.smil#_01032"> With this focus on objects, writing code that embraces data abstraction (de&#64257; ning and using data types, with data-type values held in objects) is widely referred to as object-oriented programming. The basic concepts that we have just covered are the starting point for object-oriented programming, so it is worthwhile to briefly summarize them. A data type is a set of values and a set of operations defined on those values. We implement data types in independent Java class modules and write client programs that use them. An object is an entity that can take on a data-type value or an instance of a data type. Objects are characterized by three essential properties: state, identity, and behavior. A data-type implementation supports clients of the data type as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_01033" smilref="Title.smil#_01033" /><pagenum id="p87" page="normal" smilref="Title.smil#p87" /><p attribs="{'xml:space': 'preserve'}" id="_01034" smilref="Title.smil#_01034"> 74</p><p attribs="{'xml:space': 'preserve'}" id="_01035" smilref="Title.smil#_01035"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01036" smilref="Title.smil#_01036"> Examples of abstract data types The Java language has thousands of built-in ADTs, and we have defined many other ADTs to facilitate the study of algorithms. In- deed, every Java program that we write is a data-type implementation (or a library of static methods). To control complexity, we will specifically cite APIs for any ADT that we use in this book (not many, actually). In this section, we introduce as examples several data types, with some examples of client code. In some cases, we present excerpts of APIs that may contain dozens of instance methods or more. We articulate these APIs to present real-world examples, to specify the instance methods that we will use in the book, and to emphasize that you do not need to know the details of an ADT implementation in order to be able to use it. For reference, the data types that we use and develop in this book are shown on the facing page. These fall into several different categories: </p><p attribs="{'xml:space': 'preserve'}" id="_01037" smilref="Title.smil#_01037"> to StdIn and StdOut.</p><p attribs="{'xml:space': 'preserve'}" id="_01038" smilref="Title.smil#_01038"> </p><p attribs="{'xml:space': 'preserve'}" id="_01039" smilref="Title.smil#_01039"> Section 1.4 and Section 1.5.</p><p attribs="{'xml:space': 'preserve'}" id="_01040" smilref="Title.smil#_01040"> </p><p attribs="{'xml:space': 'preserve'}" id="_01041" smilref="Title.smil#_01041" /><pagenum id="p88" page="normal" smilref="Title.smil#p88" /><p attribs="{'xml:space': 'preserve'}" id="_01042" smilref="Title.smil#_01042"> standard Java system types in java.lang</p><p attribs="{'xml:space': 'preserve'}" id="_01043" smilref="Title.smil#_01043"> Integer</p><p attribs="{'xml:space': 'preserve'}" id="_01044" smilref="Title.smil#_01044"> int wrapper double wrapper indexed chars</p><p attribs="{'xml:space': 'preserve'}" id="_01045" smilref="Title.smil#_01045"> Double</p><p attribs="{'xml:space': 'preserve'}" id="_01046" smilref="Title.smil#_01046"> String</p><p attribs="{'xml:space': 'preserve'}" id="_01047" smilref="Title.smil#_01047"> StringBuilder</p><p attribs="{'xml:space': 'preserve'}" id="_01048" smilref="Title.smil#_01048"> builder for strings</p><p attribs="{'xml:space': 'preserve'}" id="_01049" smilref="Title.smil#_01049"> other Java types</p><p attribs="{'xml:space': 'preserve'}" id="_01050" smilref="Title.smil#_01050"> java.awt.Color</p><p attribs="{'xml:space': 'preserve'}" id="_01051" smilref="Title.smil#_01051"> colors</p><p attribs="{'xml:space': 'preserve'}" id="_01052" smilref="Title.smil#_01052"> java.awt.Font</p><p attribs="{'xml:space': 'preserve'}" id="_01053" smilref="Title.smil#_01053"> fonts</p><p attribs="{'xml:space': 'preserve'}" id="_01054" smilref="Title.smil#_01054"> java.net.URL</p><p attribs="{'xml:space': 'preserve'}" id="_01055" smilref="Title.smil#_01055"> URLs</p><p attribs="{'xml:space': 'preserve'}" id="_01056" smilref="Title.smil#_01056"> java.io.File</p><p attribs="{'xml:space': 'preserve'}" id="_01057" smilref="Title.smil#_01057"> files</p><p attribs="{'xml:space': 'preserve'}" id="_01058" smilref="Title.smil#_01058"> our standard I/O types</p><p attribs="{'xml:space': 'preserve'}" id="_01059" smilref="Title.smil#_01059"> In</p><p attribs="{'xml:space': 'preserve'}" id="_01060" smilref="Title.smil#_01060"> input stream</p><p attribs="{'xml:space': 'preserve'}" id="_01061" smilref="Title.smil#_01061"> Out</p><p attribs="{'xml:space': 'preserve'}" id="_01062" smilref="Title.smil#_01062"> output stream</p><p attribs="{'xml:space': 'preserve'}" id="_01063" smilref="Title.smil#_01063"> Draw</p><p attribs="{'xml:space': 'preserve'}" id="_01064" smilref="Title.smil#_01064"> drawing</p><p attribs="{'xml:space': 'preserve'}" id="_01065" smilref="Title.smil#_01065"> data-oriented types for client examples</p><p attribs="{'xml:space': 'preserve'}" id="_01066" smilref="Title.smil#_01066"> Point2D</p><p attribs="{'xml:space': 'preserve'}" id="_01067" smilref="Title.smil#_01067"> point in the plane</p><p attribs="{'xml:space': 'preserve'}" id="_01068" smilref="Title.smil#_01068"> Interval1D</p><p attribs="{'xml:space': 'preserve'}" id="_01069" smilref="Title.smil#_01069"> 1D interval</p><p attribs="{'xml:space': 'preserve'}" id="_01070" smilref="Title.smil#_01070"> Interval2D</p><p attribs="{'xml:space': 'preserve'}" id="_01071" smilref="Title.smil#_01071"> 2D interval</p><p attribs="{'xml:space': 'preserve'}" id="_01072" smilref="Title.smil#_01072"> Date</p><p attribs="{'xml:space': 'preserve'}" id="_01073" smilref="Title.smil#_01073"> date</p><p attribs="{'xml:space': 'preserve'}" id="_01074" smilref="Title.smil#_01074"> Transaction</p><p attribs="{'xml:space': 'preserve'}" id="_01075" smilref="Title.smil#_01075"> transaction</p><p attribs="{'xml:space': 'preserve'}" id="_01076" smilref="Title.smil#_01076"> types for the analysis of algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_01077" smilref="Title.smil#_01077"> Counter</p><p attribs="{'xml:space': 'preserve'}" id="_01078" smilref="Title.smil#_01078"> counter</p><p attribs="{'xml:space': 'preserve'}" id="_01079" smilref="Title.smil#_01079"> Accumulator</p><p attribs="{'xml:space': 'preserve'}" id="_01080" smilref="Title.smil#_01080"> accumulator</p><p attribs="{'xml:space': 'preserve'}" id="_01081" smilref="Title.smil#_01081"> VisualAccumulator</p><p attribs="{'xml:space': 'preserve'}" id="_01082" smilref="Title.smil#_01082"> visual version</p><p attribs="{'xml:space': 'preserve'}" id="_01083" smilref="Title.smil#_01083"> Stopwatch</p><p attribs="{'xml:space': 'preserve'}" id="_01084" smilref="Title.smil#_01084"> stopwatch</p><p attribs="{'xml:space': 'preserve'}" id="_01085" smilref="Title.smil#_01085"> collection types</p><p attribs="{'xml:space': 'preserve'}" id="_01086" smilref="Title.smil#_01086"> Stack</p><p attribs="{'xml:space': 'preserve'}" id="_01087" smilref="Title.smil#_01087"> pushdown stack</p><p attribs="{'xml:space': 'preserve'}" id="_01088" smilref="Title.smil#_01088"> Queue</p><p attribs="{'xml:space': 'preserve'}" id="_01089" smilref="Title.smil#_01089"> FIFO queue</p><p attribs="{'xml:space': 'preserve'}" id="_01090" smilref="Title.smil#_01090"> Bag</p><p attribs="{'xml:space': 'preserve'}" id="_01091" smilref="Title.smil#_01091"> bag</p><p attribs="{'xml:space': 'preserve'}" id="_01092" smilref="Title.smil#_01092"> MinPQ MaxPQ</p><p attribs="{'xml:space': 'preserve'}" id="_01093" smilref="Title.smil#_01093"> priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_01094" smilref="Title.smil#_01094"> IndexMinPQ IndexMinPQ</p><p attribs="{'xml:space': 'preserve'}" id="_01095" smilref="Title.smil#_01095"> priority queue (indexed )</p><p attribs="{'xml:space': 'preserve'}" id="_01096" smilref="Title.smil#_01096"> ST</p><p attribs="{'xml:space': 'preserve'}" id="_01097" smilref="Title.smil#_01097"> symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_01098" smilref="Title.smil#_01098"> SET</p><p attribs="{'xml:space': 'preserve'}" id="_01099" smilref="Title.smil#_01099"> set</p><p attribs="{'xml:space': 'preserve'}" id="_01100" smilref="Title.smil#_01100"> StringST</p><p attribs="{'xml:space': 'preserve'}" id="_01101" smilref="Title.smil#_01101"> symbol table (string keys )</p><p attribs="{'xml:space': 'preserve'}" id="_01102" smilref="Title.smil#_01102"> data-oriented graph types</p><p attribs="{'xml:space': 'preserve'}" id="_01103" smilref="Title.smil#_01103"> Graph</p><p attribs="{'xml:space': 'preserve'}" id="_01104" smilref="Title.smil#_01104"> graph</p><p attribs="{'xml:space': 'preserve'}" id="_01105" smilref="Title.smil#_01105"> Digraph</p><p attribs="{'xml:space': 'preserve'}" id="_01106" smilref="Title.smil#_01106"> directed graph</p><p attribs="{'xml:space': 'preserve'}" id="_01107" smilref="Title.smil#_01107"> Edge</p><p attribs="{'xml:space': 'preserve'}" id="_01108" smilref="Title.smil#_01108"> edge (weighted )</p><p attribs="{'xml:space': 'preserve'}" id="_01109" smilref="Title.smil#_01109"> EdgeWeightedGraph</p><p attribs="{'xml:space': 'preserve'}" id="_01110" smilref="Title.smil#_01110"> graph (weighted )</p><p attribs="{'xml:space': 'preserve'}" id="_01111" smilref="Title.smil#_01111"> DirectedEdge</p><p attribs="{'xml:space': 'preserve'}" id="_01112" smilref="Title.smil#_01112"> edge (directed, weighted )</p><p attribs="{'xml:space': 'preserve'}" id="_01113" smilref="Title.smil#_01113"> EdgeWeightedDigraph</p><p attribs="{'xml:space': 'preserve'}" id="_01114" smilref="Title.smil#_01114"> graph (directed, weighted )</p><p attribs="{'xml:space': 'preserve'}" id="_01115" smilref="Title.smil#_01115"> operations-oriented graph types</p><p attribs="{'xml:space': 'preserve'}" id="_01116" smilref="Title.smil#_01116"> UF</p><p attribs="{'xml:space': 'preserve'}" id="_01117" smilref="Title.smil#_01117"> dynamic connectivity</p><p attribs="{'xml:space': 'preserve'}" id="_01118" smilref="Title.smil#_01118"> DepthFirstPaths</p><p attribs="{'xml:space': 'preserve'}" id="_01119" smilref="Title.smil#_01119"> DFS path searcher</p><p attribs="{'xml:space': 'preserve'}" id="_01120" smilref="Title.smil#_01120"> CC</p><p attribs="{'xml:space': 'preserve'}" id="_01121" smilref="Title.smil#_01121"> connected components</p><p attribs="{'xml:space': 'preserve'}" id="_01122" smilref="Title.smil#_01122"> BreadthFirstPaths</p><p attribs="{'xml:space': 'preserve'}" id="_01123" smilref="Title.smil#_01123"> BFS path search</p><p attribs="{'xml:space': 'preserve'}" id="_01124" smilref="Title.smil#_01124"> DirectedDFS</p><p attribs="{'xml:space': 'preserve'}" id="_01125" smilref="Title.smil#_01125"> DFS digraph path search</p><p attribs="{'xml:space': 'preserve'}" id="_01126" smilref="Title.smil#_01126"> DirectedBFS</p><p attribs="{'xml:space': 'preserve'}" id="_01127" smilref="Title.smil#_01127"> BFS digraph path search</p><p attribs="{'xml:space': 'preserve'}" id="_01128" smilref="Title.smil#_01128"> TransitiveClosure</p><p attribs="{'xml:space': 'preserve'}" id="_01129" smilref="Title.smil#_01129"> all paths</p><p attribs="{'xml:space': 'preserve'}" id="_01130" smilref="Title.smil#_01130"> Topological</p><p attribs="{'xml:space': 'preserve'}" id="_01131" smilref="Title.smil#_01131"> topological order</p><p attribs="{'xml:space': 'preserve'}" id="_01132" smilref="Title.smil#_01132"> DepthFirstOrder</p><p attribs="{'xml:space': 'preserve'}" id="_01133" smilref="Title.smil#_01133"> DFS order</p><p attribs="{'xml:space': 'preserve'}" id="_01134" smilref="Title.smil#_01134"> DirectedCycle</p><p attribs="{'xml:space': 'preserve'}" id="_01135" smilref="Title.smil#_01135"> cycle search</p><p attribs="{'xml:space': 'preserve'}" id="_01136" smilref="Title.smil#_01136"> SCC</p><p attribs="{'xml:space': 'preserve'}" id="_01137" smilref="Title.smil#_01137"> strong components</p><p attribs="{'xml:space': 'preserve'}" id="_01138" smilref="Title.smil#_01138"> MST</p><p attribs="{'xml:space': 'preserve'}" id="_01139" smilref="Title.smil#_01139"> minimum spanning tree</p><p attribs="{'xml:space': 'preserve'}" id="_01140" smilref="Title.smil#_01140"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_01141" smilref="Title.smil#_01141"> shortest paths</p><p attribs="{'xml:space': 'preserve'}" id="_01142" smilref="Title.smil#_01142"> Selected ADTs used in this book</p><p attribs="{'xml:space': 'preserve'}" id="_01143" smilref="Title.smil#_01143"> 75</p><p attribs="{'xml:space': 'preserve'}" id="_01144" smilref="Title.smil#_01144"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01145" smilref="Title.smil#_01145" /><pagenum id="p89" page="normal" smilref="Title.smil#p89" /><p attribs="{'xml:space': 'preserve'}" id="_01146" smilref="Title.smil#_01146"> 76</p><p attribs="{'xml:space': 'preserve'}" id="_01147" smilref="Title.smil#_01147"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01148" smilref="Title.smil#_01148"> public static void main(String[] args) { double xlo = Double.parseDouble(args[0]); double xhi = Double.parseDouble(args[1]); double ylo = Double.parseDouble(args[2]); double yhi = Double.parseDouble(args[3]); int T = Integer.parseInt(args[4]);</p><p attribs="{'xml:space': 'preserve'}" id="_01149" smilref="Title.smil#_01149"> Interval1D xint = new Interval1D(xlo, xhi); Interval1D yint = new Interval1D(ylo, yhi); Interval2D box = new Interval2D(xint, yint); box.draw();</p><p attribs="{'xml:space': 'preserve'}" id="_01150" smilref="Title.smil#_01150"> Counter c = new Counter(&#8220;hits&#8221;); for (int t = 0; t &lt; T; t++) { double x = StdRandom.random(); double y = StdRandom.random(); Point2D p = new Point2D(x, y); if (box.contains(p)) c.increment(); else p.draw(); }</p><p attribs="{'xml:space': 'preserve'}" id="_01151" smilref="Title.smil#_01151"> Geometric objects. A natural example of object-oriented programming is designing data types for geometric objects. For example, the APIs on the facing page define abstract data types for three familiar geometric objects: Point2D (points in the plane), Interval1D (intervals on the line), and Interval2D (two- dimensional intervals in the plane, or axis-aligned rectangles). As usual, the APIs are essentially self-docu- menting and lead immediately to easily understood client code such as the example at left, which reads the boundaries of an Interval2D and an integer T from the command line, generates T random points in the unit square, and counts the number of points that fall in the interval (an estimate of the area of the rectangle). For dramatic effect, the client also draws the interval and the points that fall outside the interval. This computation is a model for a method that reduces the problem of computing the area and volume of geometric shapes to the problem of determining whether a point falls within the shape or not (a less dif- fi cult but not trivial problem). Of course, we can define APIs for other geometric objects such as line segments, triangles, polygons, circles, and so forth, though implementing operations on them can be challenging. Several examples are addressed in the exercises at the end of this section.</p><p attribs="{'xml:space': 'preserve'}" id="_01152" smilref="Title.smil#_01152"> StdOut.println(c); StdOut.printf("area = %.2f\n", box.area()); }</p><p attribs="{'xml:space': 'preserve'}" id="_01153" smilref="Title.smil#_01153"> Interval2D test client</p><p attribs="{'xml:space': 'preserve'}" id="_01154" smilref="Title.smil#_01154"> % java Interval2D .2 .5 .5 .6 10000 297 hits area = .03</p><p attribs="{'xml:space': 'preserve'}" id="_01155" smilref="Title.smil#_01155"> Programs that process geometric objects have wide</p><p attribs="{'xml:space': 'preserve'}" id="_01156" smilref="Title.smil#_01156"> application in computing with models of the natural world, in scientific computing, video games, movies, and many other applications. The development and study of such programs and applications has blossomed into a far-reaching field of study known as computational geometry, which is a</p><p attribs="{'xml:space': 'preserve'}" id="_01157" smilref="Title.smil#_01157" /><pagenum id="p90" page="normal" smilref="Title.smil#p90" /><p attribs="{'xml:space': 'preserve'}" id="_01158" smilref="Title.smil#_01158"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01159" smilref="Title.smil#_01159"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_01160" smilref="Title.smil#_01160"> public class Point2D</p><p attribs="{'xml:space': 'preserve'}" id="_01161" smilref="Title.smil#_01161"> Point2D(double x, double y)</p><p attribs="{'xml:space': 'preserve'}" id="_01162" smilref="Title.smil#_01162"> double x()</p><p attribs="{'xml:space': 'preserve'}" id="_01163" smilref="Title.smil#_01163"> double y()</p><p attribs="{'xml:space': 'preserve'}" id="_01164" smilref="Title.smil#_01164"> double r()</p><p attribs="{'xml:space': 'preserve'}" id="_01165" smilref="Title.smil#_01165"> double theta()</p><p attribs="{'xml:space': 'preserve'}" id="_01166" smilref="Title.smil#_01166"> double distanceTo(Point2D that)</p><p attribs="{'xml:space': 'preserve'}" id="_01167" smilref="Title.smil#_01167"> void draw()</p><p attribs="{'xml:space': 'preserve'}" id="_01168" smilref="Title.smil#_01168"> create a point</p><p attribs="{'xml:space': 'preserve'}" id="_01169" smilref="Title.smil#_01169"> x coordinate</p><p attribs="{'xml:space': 'preserve'}" id="_01170" smilref="Title.smil#_01170"> y coordinate</p><p attribs="{'xml:space': 'preserve'}" id="_01171" smilref="Title.smil#_01171"> radius ( polar coordinates)</p><p attribs="{'xml:space': 'preserve'}" id="_01172" smilref="Title.smil#_01172"> angle (polar coordinates) Euclidean distance from this point to that draw the point on StdDraw</p><p attribs="{'xml:space': 'preserve'}" id="_01173" smilref="Title.smil#_01173"> An API for points in the plane</p><p attribs="{'xml:space': 'preserve'}" id="_01174" smilref="Title.smil#_01174"> public class Interval1D</p><p attribs="{'xml:space': 'preserve'}" id="_01175" smilref="Title.smil#_01175"> Interval1D(double left, double right)</p><p attribs="{'xml:space': 'preserve'}" id="_01176" smilref="Title.smil#_01176"> double left()</p><p attribs="{'xml:space': 'preserve'}" id="_01177" smilref="Title.smil#_01177"> double right()</p><p attribs="{'xml:space': 'preserve'}" id="_01178" smilref="Title.smil#_01178"> double length()</p><p attribs="{'xml:space': 'preserve'}" id="_01179" smilref="Title.smil#_01179"> boolean contains(double x)</p><p attribs="{'xml:space': 'preserve'}" id="_01180" smilref="Title.smil#_01180"> boolean intersects(Interval1D that)</p><p attribs="{'xml:space': 'preserve'}" id="_01181" smilref="Title.smil#_01181"> create an interval</p><p attribs="{'xml:space': 'preserve'}" id="_01182" smilref="Title.smil#_01182"> left endpoint</p><p attribs="{'xml:space': 'preserve'}" id="_01183" smilref="Title.smil#_01183"> right endpoint</p><p attribs="{'xml:space': 'preserve'}" id="_01184" smilref="Title.smil#_01184"> length of the interval does the interval contain x? does the interval intersect that?</p><p attribs="{'xml:space': 'preserve'}" id="_01185" smilref="Title.smil#_01185"> An API for intervals on the line</p><p attribs="{'xml:space': 'preserve'}" id="_01186" smilref="Title.smil#_01186"> public class Interval2D</p><p attribs="{'xml:space': 'preserve'}" id="_01187" smilref="Title.smil#_01187"> Interval2D(Interval1D x, Interval1D y)</p><p attribs="{'xml:space': 'preserve'}" id="_01188" smilref="Title.smil#_01188"> create a 2D interval</p><p attribs="{'xml:space': 'preserve'}" id="_01189" smilref="Title.smil#_01189"> double area()</p><p attribs="{'xml:space': 'preserve'}" id="_01190" smilref="Title.smil#_01190"> boolean contains(Point2D p)</p><p attribs="{'xml:space': 'preserve'}" id="_01191" smilref="Title.smil#_01191"> boolean intersects(Interval2D that)</p><p attribs="{'xml:space': 'preserve'}" id="_01192" smilref="Title.smil#_01192"> void draw()</p><p attribs="{'xml:space': 'preserve'}" id="_01193" smilref="Title.smil#_01193"> area of the 2D interval does the 2D interval contain p? does the 2D interval intersect that? draw the 2D interval on StdDraw</p><p attribs="{'xml:space': 'preserve'}" id="_01194" smilref="Title.smil#_01194"> An API for two dimensional intervals in the plane</p><p attribs="{'xml:space': 'preserve'}" id="_01195" smilref="Title.smil#_01195"> fertile area of examples for the application of the algorithms that we address in this book, as you will see in examples throughout the book. In the present context, our interest is to suggest that abstract data types that directly represent geometric abstractions are not difficult to define and can lead to simple and clear client code. This idea is reinforced in several exercises at the end of this section and on the booksite.</p><p attribs="{'xml:space': 'preserve'}" id="_01196" smilref="Title.smil#_01196" /><pagenum id="p91" page="normal" smilref="Title.smil#p91" /><p attribs="{'xml:space': 'preserve'}" id="_01197" smilref="Title.smil#_01197"> 78</p><p attribs="{'xml:space': 'preserve'}" id="_01198" smilref="Title.smil#_01198"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01199" smilref="Title.smil#_01199"> Information processing. Whether it be a bank processing millions of credit card transactions or a web analytics company processing billions of touchpad taps or a scien- ti&#64257; c research group processing millions of experimental observations, a great many applications are centered around processing and organizing information. Abstract data types provide a natural mechanism for organizing the information. Without getting into details, the two APIs on the facing page suggest a typical approach for a commercial application. The idea is to define data types that allow us to keep information in objects that correspond to things in the real world. A date is a day, a month, and a year and a transaction is a customer, a date, and an amount. These two are just examples: we might also define data types that can hold detailed information for customers, times, locations, goods and services, or whatever. Each data type consists of constructors that create objects containing the data and methods for use by client code to access it. To simplify client code, we provide two constructors for each type, one that presents the data in its appropriate type and another that parses a string to get the data (see Exer- cise 1.2.19 for details). As usual, there is no reason for client code to know the representation of the data. Most often, the reason to organize the data in this way is to treat the data associated with an object as a single entity : we can maintain arrays of Transaction values, use Date values as a argument or a return value for a method, and so forth. The focus of such data types is on encapsulating the data, while at the same time enabling the development of client code that does not depend on the representation of the data. We do not dwell on organizing information in this way, except to take note that doing so and including the inherited methods toString(), compareTo(), equals(), and hashCode() allows us to take advantage of algorithm implementations that can process any type of data. We will discuss inherited methods in more detail on page 100. For example, we have already noted Java&#8217;s convention that enables clients to print a string representation of every value if we include toString() implementation in a data type. We consider conventions corresponding to the other inherited</p><p attribs="{'xml:space': 'preserve'}" id="_01200" smilref="Title.smil#_01200"> methods in Section 1.3, Section 2.5, Section 3.4, and Section 3.5, using Date and</p><p attribs="{'xml:space': 'preserve'}" id="_01201" smilref="Title.smil#_01201"> Transaction as examples. Section 1.3 gives classic examples of data types and a Java language mechanism known as parameterized types, or generics, that takes advantage of these conventions, and Chapter 2 and Chapter 3 are also devoted to taking advantage of generic types and inherited methods to develop implementations of sorting and searching algorithms that are effective for any type of data.</p><p attribs="{'xml:space': 'preserve'}" id="_01202" smilref="Title.smil#_01202"> Whenever you have data of different types that logically belong together, it is</p><p attribs="{'xml:space': 'preserve'}" id="_01203" smilref="Title.smil#_01203"> worthwhile to contemplate defining an ADT as in these examples. The ability to do so helps to organize the data, can greatly simplify client code in typical applications, and is an important step on the road to data abstraction.</p><p attribs="{'xml:space': 'preserve'}" id="_01204" smilref="Title.smil#_01204" /><pagenum id="p92" page="normal" smilref="Title.smil#p92" /><p attribs="{'xml:space': 'preserve'}" id="_01205" smilref="Title.smil#_01205"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01206" smilref="Title.smil#_01206"> 79</p><p attribs="{'xml:space': 'preserve'}" id="_01207" smilref="Title.smil#_01207"> public class Date implements Comparable&lt;Date&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_01208" smilref="Title.smil#_01208"> Date(int month, int day, int year) create a date Date(String date) int month()</p><p attribs="{'xml:space': 'preserve'}" id="_01209" smilref="Title.smil#_01209"> create a date (parse constructor) month</p><p attribs="{'xml:space': 'preserve'}" id="_01210" smilref="Title.smil#_01210"> int day()</p><p attribs="{'xml:space': 'preserve'}" id="_01211" smilref="Title.smil#_01211"> int year()</p><p attribs="{'xml:space': 'preserve'}" id="_01212" smilref="Title.smil#_01212"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01213" smilref="Title.smil#_01213"> boolean equals(Object that)</p><p attribs="{'xml:space': 'preserve'}" id="_01214" smilref="Title.smil#_01214"> int compareTo(Date that)</p><p attribs="{'xml:space': 'preserve'}" id="_01215" smilref="Title.smil#_01215"> int hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_01216" smilref="Title.smil#_01216"> day</p><p attribs="{'xml:space': 'preserve'}" id="_01217" smilref="Title.smil#_01217"> year</p><p attribs="{'xml:space': 'preserve'}" id="_01218" smilref="Title.smil#_01218"> string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01219" smilref="Title.smil#_01219"> is this the same date as that?</p><p attribs="{'xml:space': 'preserve'}" id="_01220" smilref="Title.smil#_01220"> compare this date to that</p><p attribs="{'xml:space': 'preserve'}" id="_01221" smilref="Title.smil#_01221"> hash code</p><p attribs="{'xml:space': 'preserve'}" id="_01222" smilref="Title.smil#_01222"> public class Transaction implements Comparable&lt;Transaction&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_01223" smilref="Title.smil#_01223"> Transaction(String who, Date when, double amount)</p><p attribs="{'xml:space': 'preserve'}" id="_01224" smilref="Title.smil#_01224"> Transaction(String transaction)</p><p attribs="{'xml:space': 'preserve'}" id="_01225" smilref="Title.smil#_01225"> create a transaction (parse constructor)</p><p attribs="{'xml:space': 'preserve'}" id="_01226" smilref="Title.smil#_01226"> String who()</p><p attribs="{'xml:space': 'preserve'}" id="_01227" smilref="Title.smil#_01227"> Date when()</p><p attribs="{'xml:space': 'preserve'}" id="_01228" smilref="Title.smil#_01228"> double amount()</p><p attribs="{'xml:space': 'preserve'}" id="_01229" smilref="Title.smil#_01229"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01230" smilref="Title.smil#_01230"> boolean equals(Object that)</p><p attribs="{'xml:space': 'preserve'}" id="_01231" smilref="Title.smil#_01231"> int compareTo(Transaction that) int hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_01232" smilref="Title.smil#_01232"> customer name</p><p attribs="{'xml:space': 'preserve'}" id="_01233" smilref="Title.smil#_01233"> date</p><p attribs="{'xml:space': 'preserve'}" id="_01234" smilref="Title.smil#_01234"> amount</p><p attribs="{'xml:space': 'preserve'}" id="_01235" smilref="Title.smil#_01235"> string representation is this the same transaction as that? compare this transaction to that hash code</p><p attribs="{'xml:space': 'preserve'}" id="_01236" smilref="Title.smil#_01236"> Sample APIs for commercial applications (dates and transactions)</p><p attribs="{'xml:space': 'preserve'}" id="_01237" smilref="Title.smil#_01237" /><pagenum id="p93" page="normal" smilref="Title.smil#p93" /><p attribs="{'xml:space': 'preserve'}" id="_01238" smilref="Title.smil#_01238"> 80</p><p attribs="{'xml:space': 'preserve'}" id="_01239" smilref="Title.smil#_01239"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01240" smilref="Title.smil#_01240"> Strings. Java&#8217;s String is an important and useful ADT. A String is an indexed sequence of char values. String has dozens of instance methods, including the following:</p><p attribs="{'xml:space': 'preserve'}" id="_01241" smilref="Title.smil#_01241"> public class String</p><p attribs="{'xml:space': 'preserve'}" id="_01242" smilref="Title.smil#_01242"> String()</p><p attribs="{'xml:space': 'preserve'}" id="_01243" smilref="Title.smil#_01243"> int length()</p><p attribs="{'xml:space': 'preserve'}" id="_01244" smilref="Title.smil#_01244"> int charAt(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_01245" smilref="Title.smil#_01245"> int indexOf(String p)</p><p attribs="{'xml:space': 'preserve'}" id="_01246" smilref="Title.smil#_01246"> int indexOf(String p, int i)</p><p attribs="{'xml:space': 'preserve'}" id="_01247" smilref="Title.smil#_01247"> String concat(String t)</p><p attribs="{'xml:space': 'preserve'}" id="_01248" smilref="Title.smil#_01248"> String substring(int i, int j)</p><p attribs="{'xml:space': 'preserve'}" id="_01249" smilref="Title.smil#_01249"> String[] split(String delim)</p><p attribs="{'xml:space': 'preserve'}" id="_01250" smilref="Title.smil#_01250"> int compareTo(String t)</p><p attribs="{'xml:space': 'preserve'}" id="_01251" smilref="Title.smil#_01251"> boolean equals(String t)</p><p attribs="{'xml:space': 'preserve'}" id="_01252" smilref="Title.smil#_01252"> int hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_01253" smilref="Title.smil#_01253"> create an empty string length of the string ith character fi rst occurrence of p (-1 if none) fi rst occurrence of p aft er i (-1 if none) this string with t appended substring of this string (ith to j-1st chars) strings between occurrences of delim string comparison is this string&#8217;s value the same as t&#8217;s ? hash code</p><p attribs="{'xml:space': 'preserve'}" id="_01254" smilref="Title.smil#_01254"> Java String API (partial list of methods)</p><p attribs="{'xml:space': 'preserve'}" id="_01255" smilref="Title.smil#_01255"> String values are similar to arrays of characters, but the two are not the same. Ar- rays have built-in Java language syntax for accessing a character; String has instance methods for indexed access, length, and many other operations. On the other hand, String has special language support for initialization and concatenation: instead of creating and initializing a string with a constructor, we can use a string literal; instead of invoking the method concat() we can use the + operator. We do not need to consider the details of the implementation, though understanding performance characteristics of some of the methods is important when developing string-processing algorithms, as you will see in Chapter 5. Why not just use arrays of characters instead of String values? The answer to this question is the same as for any ADT: to simplify and clarify client code. With String, we can write clear and simple client code that uses numerous convenient instance methods without regard to the way in which strings are represented (see facing page). Even this short list contains powerful operations that require advanced algorithms such</p><p attribs="{'xml:space': 'preserve'}" id="_01256" smilref="Title.smil#_01256"> call a.length() a.charAt(4) a.concat(c) a.indexOf("is") a.substring(2, 5) a.split(" ")[0] a.split(" ")[1] b.equals(c)</p><p attribs="{'xml:space': 'preserve'}" id="_01257" smilref="Title.smil#_01257"> String a = "now is "; String b = "the time "; String c = "to"</p><p attribs="{'xml:space': 'preserve'}" id="_01258" smilref="Title.smil#_01258"> value 7 i "now is to" 4 "w i" "now" "is" false</p><p attribs="{'xml:space': 'preserve'}" id="_01259" smilref="Title.smil#_01259"> Examples of string operations</p><p attribs="{'xml:space': 'preserve'}" id="_01260" smilref="Title.smil#_01260" /><pagenum id="p94" page="normal" smilref="Title.smil#p94" /><p attribs="{'xml:space': 'preserve'}" id="_01261" smilref="Title.smil#_01261"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01262" smilref="Title.smil#_01262"> 81</p><p attribs="{'xml:space': 'preserve'}" id="_01263" smilref="Title.smil#_01263"> task</p><p attribs="{'xml:space': 'preserve'}" id="_01264" smilref="Title.smil#_01264"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01265" smilref="Title.smil#_01265"> is the string a palindrome?</p><p attribs="{'xml:space': 'preserve'}" id="_01266" smilref="Title.smil#_01266"> public static boolean isPalindrome(String s) { int N = s.length(); for (int i = 0; i &lt; N/2; i++) if (s.charAt(i) != s.charAt(N-1-i)) return false; return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_01267" smilref="Title.smil#_01267"> extract file name and extension from a command-line argument</p><p attribs="{'xml:space': 'preserve'}" id="_01268" smilref="Title.smil#_01268"> String s = args[0]; int dot = s.indexOf("."); String base = s.substring(0, dot); String extension = s.substring(dot + 1, s.length());</p><p attribs="{'xml:space': 'preserve'}" id="_01269" smilref="Title.smil#_01269"> print all lines in standard input that contain a string specified on the command line</p><p attribs="{'xml:space': 'preserve'}" id="_01270" smilref="Title.smil#_01270"> String query = args[0]; while (!StdIn.isEmpty()) { String s = StdIn.readLine(); if (s.contains(query)) StdOut.println(s); }</p><p attribs="{'xml:space': 'preserve'}" id="_01271" smilref="Title.smil#_01271"> create an array of the strings on StdIn delimited by whitespace</p><p attribs="{'xml:space': 'preserve'}" id="_01272" smilref="Title.smil#_01272"> String input = StdIn.readAll(); String[] words = input.split("\\s+");</p><p attribs="{'xml:space': 'preserve'}" id="_01273" smilref="Title.smil#_01273"> check whether an array of strings is in alphabetical order</p><p attribs="{'xml:space': 'preserve'}" id="_01274" smilref="Title.smil#_01274"> public boolean isSorted(String[] a) { for (int i = 1; i &lt; a.length; i++) { if (a[i-1].compareTo(a[i]) &gt; 0) return false; } return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_01275" smilref="Title.smil#_01275"> Typical string-processing code</p><p attribs="{'xml:space': 'preserve'}" id="_01276" smilref="Title.smil#_01276" /><pagenum id="p95" page="normal" smilref="Title.smil#p95" /><p attribs="{'xml:space': 'preserve'}" id="_01277" smilref="Title.smil#_01277"> 82</p><p attribs="{'xml:space': 'preserve'}" id="_01278" smilref="Title.smil#_01278"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01279" smilref="Title.smil#_01279"> as those considered in Chapter 5. For example, the argument of split() can be a regular expression (see Section 5.4)&#8212;the split() example on page 81 uses the argument "\\s+", which means &#8220;one or more tabs, spaces, newlines, or returns.&#8221;</p><p attribs="{'xml:space': 'preserve'}" id="_01280" smilref="Title.smil#_01280"> Input and output revisited. A disadvantage of the StdIn, StdOut, and StdDraw standard libraries of Section 1.1 is that they restrict us to working with just one input fi le, one output fi le, and one drawing for any given program. With object-oriented pro- gramming, we can define similar mechanisms that allow us to work with multiple input streams, output streams, and drawings within one program. Speci&#64257; cally, our standard libary includes the data types In, Out, and Draw with the APIs shown on the facing page, When invoked with a constructor having a String argument, In and Out will first try to find a file in the current directory of your computer that has that name. If it cannot do so, it will assume the argument to be a website name and will try to connect to that web- site (if no such website exists, it will issue a runtime exception). In either case, the specified file or website becomes the source/ target of the input/output for the stream object thus created,</p><p attribs="{'xml:space': 'preserve'}" id="_01281" smilref="Title.smil#_01281"> public class Cat { public static void main(String[] args) { // Copy input files to out (last argument). Out out = new Out(args[args.length-1]); for (int i = 0; i &lt; args.length - 1; i++) { // Copy input file named on ith arg to out. In in = new In(args[i]); String s = in.readAll(); out.println(s); in.close(); } out.close(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01282" smilref="Title.smil#_01282"> and the read*() and print*()</p><p attribs="{'xml:space': 'preserve'}" id="_01283" smilref="Title.smil#_01283"> A sample In and Out client</p><p attribs="{'xml:space': 'preserve'}" id="_01284" smilref="Title.smil#_01284"> % more in1.txt This is</p><p attribs="{'xml:space': 'preserve'}" id="_01285" smilref="Title.smil#_01285"> % more in2.txt a tiny test.</p><p attribs="{'xml:space': 'preserve'}" id="_01286" smilref="Title.smil#_01286"> % java Cat in1.txt in2.txt out.txt</p><p attribs="{'xml:space': 'preserve'}" id="_01287" smilref="Title.smil#_01287"> % more out.txt This is a tiny test.</p><p attribs="{'xml:space': 'preserve'}" id="_01288" smilref="Title.smil#_01288"> methods will refer to that file or website. (If you use the no-argu- ment constructor, then you obtain the standard streams.) This arrangement makes it possible for a single program to process multiple files and drawings. You also can assign such objects to variables, pass them as arguments or return values from methods, create arrays of them, and manipulate them just as you manipulate objects of any type. The program Cat shown at left is a sample client of In and Out that uses multiple input streams to concatenate several input files into a single output fi le. The In and Out classes also contain static methods for reading files containing values that are all int, double, or String types into an array (see</p><p attribs="{'xml:space': 'preserve'}" id="_01289" smilref="Title.smil#_01289"> page 126 and Exercise 1.2.15).</p><p attribs="{'xml:space': 'preserve'}" id="_01290" smilref="Title.smil#_01290" /><pagenum id="p96" page="normal" smilref="Title.smil#p96" /><p attribs="{'xml:space': 'preserve'}" id="_01291" smilref="Title.smil#_01291"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01292" smilref="Title.smil#_01292"> 83</p><p attribs="{'xml:space': 'preserve'}" id="_01293" smilref="Title.smil#_01293"> public class In</p><p attribs="{'xml:space': 'preserve'}" id="_01294" smilref="Title.smil#_01294"> In()</p><p attribs="{'xml:space': 'preserve'}" id="_01295" smilref="Title.smil#_01295"> create an input stream from standard input</p><p attribs="{'xml:space': 'preserve'}" id="_01296" smilref="Title.smil#_01296"> In(String name)</p><p attribs="{'xml:space': 'preserve'}" id="_01297" smilref="Title.smil#_01297"> create an input stream from a file or website</p><p attribs="{'xml:space': 'preserve'}" id="_01298" smilref="Title.smil#_01298"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_01299" smilref="Title.smil#_01299"> int readInt()</p><p attribs="{'xml:space': 'preserve'}" id="_01300" smilref="Title.smil#_01300"> double readDouble()</p><p attribs="{'xml:space': 'preserve'}" id="_01301" smilref="Title.smil#_01301"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_01302" smilref="Title.smil#_01302"> void close()</p><p attribs="{'xml:space': 'preserve'}" id="_01303" smilref="Title.smil#_01303"> true if no more input, false otherwise</p><p attribs="{'xml:space': 'preserve'}" id="_01304" smilref="Title.smil#_01304"> read a value of type int</p><p attribs="{'xml:space': 'preserve'}" id="_01305" smilref="Title.smil#_01305"> read a value of type double</p><p attribs="{'xml:space': 'preserve'}" id="_01306" smilref="Title.smil#_01306"> close the input stream</p><p attribs="{'xml:space': 'preserve'}" id="_01307" smilref="Title.smil#_01307"> Note: all operations supported by StdIn are also supported for In objects.</p><p attribs="{'xml:space': 'preserve'}" id="_01308" smilref="Title.smil#_01308"> API for our data type for input streams</p><p attribs="{'xml:space': 'preserve'}" id="_01309" smilref="Title.smil#_01309"> public class Out</p><p attribs="{'xml:space': 'preserve'}" id="_01310" smilref="Title.smil#_01310"> Out()</p><p attribs="{'xml:space': 'preserve'}" id="_01311" smilref="Title.smil#_01311"> create an output stream to standard output</p><p attribs="{'xml:space': 'preserve'}" id="_01312" smilref="Title.smil#_01312"> Out(String name)</p><p attribs="{'xml:space': 'preserve'}" id="_01313" smilref="Title.smil#_01313"> void print(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_01314" smilref="Title.smil#_01314"> void println(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_01315" smilref="Title.smil#_01315"> create an output stream to a file</p><p attribs="{'xml:space': 'preserve'}" id="_01316" smilref="Title.smil#_01316"> append s to the output stream</p><p attribs="{'xml:space': 'preserve'}" id="_01317" smilref="Title.smil#_01317"> append s and a newline to the output stream</p><p attribs="{'xml:space': 'preserve'}" id="_01318" smilref="Title.smil#_01318"> void println()</p><p attribs="{'xml:space': 'preserve'}" id="_01319" smilref="Title.smil#_01319"> append a newline to the output stream</p><p attribs="{'xml:space': 'preserve'}" id="_01320" smilref="Title.smil#_01320"> void printf(String f, ...)</p><p attribs="{'xml:space': 'preserve'}" id="_01321" smilref="Title.smil#_01321"> formatted print to the output steam</p><p attribs="{'xml:space': 'preserve'}" id="_01322" smilref="Title.smil#_01322"> void close()</p><p attribs="{'xml:space': 'preserve'}" id="_01323" smilref="Title.smil#_01323"> close the output stream</p><p attribs="{'xml:space': 'preserve'}" id="_01324" smilref="Title.smil#_01324"> Note: all operations supported by StdOut are also supported for Out objects.</p><p attribs="{'xml:space': 'preserve'}" id="_01325" smilref="Title.smil#_01325"> API for our data type for output streams</p><p attribs="{'xml:space': 'preserve'}" id="_01326" smilref="Title.smil#_01326"> public class Draw</p><p attribs="{'xml:space': 'preserve'}" id="_01327" smilref="Title.smil#_01327"> Draw()</p><p attribs="{'xml:space': 'preserve'}" id="_01328" smilref="Title.smil#_01328"> void line(double x0, double y0, double x1, double y1)</p><p attribs="{'xml:space': 'preserve'}" id="_01329" smilref="Title.smil#_01329"> void point(double x, double y)</p><p attribs="{'xml:space': 'preserve'}" id="_01330" smilref="Title.smil#_01330"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_01331" smilref="Title.smil#_01331"> Note: all operations supported by StdDraw are also supported for Draw objects.</p><p attribs="{'xml:space': 'preserve'}" id="_01332" smilref="Title.smil#_01332"> API for our data type for drawings</p><p attribs="{'xml:space': 'preserve'}" id="_01333" smilref="Title.smil#_01333" /></level3><level3 id="_00010"><h3 id="ch1-s2-ss11" smilref="Title.smil#ch1-s2-ss11" xml:space="preserve">Abstract data types</h3><pagenum id="p97" page="normal" smilref="Title.smil#p97" /><p attribs="{'xml:space': 'preserve'}" id="_01334" smilref="Title.smil#_01334"> 84</p><p attribs="{'xml:space': 'preserve'}" id="_01335" smilref="Title.smil#_01335"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01336" smilref="Title.smil#_01336"> Instance variables. To define data-type</p><p attribs="{'xml:space': 'preserve'}" id="_01337" smilref="Title.smil#_01337"> instance variable declarations</p><p attribs="{'xml:space': 'preserve'}" id="_01338" smilref="Title.smil#_01338"> Implementing abstract data types As with libraries of static methods, we implement ADTs with a Java class, putting the code in a file with the same name as the class, followed by the .java extension. The first statements in the file declare instance variables that define the data-type values. Following the instance variables are the constructor and the instance methods that implement operations on data-type values. In- stance methods may be public (speci&#64257; ed in the API) or private (used to organize the computation and not available to clients). A data-type definition may have multiple constructors and may also include definitions of static methods. In particular, a unit- test client main() is normally useful for testing and debugging. As a first example, we consider an implementation of the Counter ADT that we defined on page 65. A full annotated implementation is shown on the facing page, for reference as we discuss its constituent parts. Every ADT implementation that you will develop has the same basic ingredients as this simple example.</p><p attribs="{'xml:space': 'preserve'}" id="_01339" smilref="Title.smil#_01339"> public class Counter { private final String name; private int count; ... } Instance variables in ADTs are private</p><p attribs="{'xml:space': 'preserve'}" id="_01340" smilref="Title.smil#_01340"> values (the state of each object), we declare instance variables in much the same way as we declare local variables. There is a critical distinction between instance variables and the local variables within a static method or a block that you are accustomed to: there is just one value corresponding to each local variable at a given time, but there are numerous values corresponding to each instance variable (one for each object that is an instance of the data type). There is no ambiguity with this arrangement, because each time that we access an instance variable, we do so with an object name&#8212;that object is the one whose value we are accessing. Also, each declaration is qualified by a visibility modi&#64257; er. In ADT implementations, we use private, using a Java language mechansim to enforce the idea that the representation of an ADT is to be hidden from the client, and also final, if the value is not to be changed once it is initialized. Counter has two instance variables: a String value name and an int value count. If we were to use public instance variables (allowed in Java) the data type would, by defi nition, not be abstract, so we do not do so.</p><p attribs="{'xml:space': 'preserve'}" id="_01341" smilref="Title.smil#_01341"> Constructors. Every Java class has at least one constructor that establishes an object&#8217;s identity. A constructor is like a static method, but it can refer directly to instance variables and has no return value. Generally, the purpose of a constructor is to initialize the instance variables. Every constructor creates an object and provides to the client a reference to that object. Constructors always share the same name as the class. We can overload the name and have multiple constructors with different signatures, just as with methods. If no other constructor is defi ned, a default no-argument constructor is</p><p attribs="{'xml:space': 'preserve'}" id="_01342" smilref="Title.smil#_01342" /><pagenum id="p98" page="normal" smilref="Title.smil#p98" /><p attribs="{'xml:space': 'preserve'}" id="_01343" smilref="Title.smil#_01343"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01344" smilref="Title.smil#_01344"> 85</p><p attribs="{'xml:space': 'preserve'}" id="_01345" smilref="Title.smil#_01345"> public class Counter { private final String name; private int count;</p><p attribs="{'xml:space': 'preserve'}" id="_01346" smilref="Title.smil#_01346"> instance variables</p><p attribs="{'xml:space': 'preserve'}" id="_01347" smilref="Title.smil#_01347"> class name</p><p attribs="{'xml:space': 'preserve'}" id="_01348" smilref="Title.smil#_01348"> constructor</p><p attribs="{'xml:space': 'preserve'}" id="_01349" smilref="Title.smil#_01349"> public Counter(String id) { name = id; }</p><p attribs="{'xml:space': 'preserve'}" id="_01350" smilref="Title.smil#_01350"> public void increment() { count++; }</p><p attribs="{'xml:space': 'preserve'}" id="_01351" smilref="Title.smil#_01351"> instance methods</p><p attribs="{'xml:space': 'preserve'}" id="_01352" smilref="Title.smil#_01352"> public int tally() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_01353" smilref="Title.smil#_01353"> public String toString() { return count + " " + name; }</p><p attribs="{'xml:space': 'preserve'}" id="_01354" smilref="Title.smil#_01354"> instance variable name</p><p attribs="{'xml:space': 'preserve'}" id="_01355" smilref="Title.smil#_01355"> test client</p><p attribs="{'xml:space': 'preserve'}" id="_01356" smilref="Title.smil#_01356"> create and initialize objects</p><p attribs="{'xml:space': 'preserve'}" id="_01357" smilref="Title.smil#_01357"> public static void main(String[] args) { Counter heads = new Counter("heads"); Counter tails = new Counter("tails");</p><p attribs="{'xml:space': 'preserve'}" id="_01358" smilref="Title.smil#_01358"> heads.increment(); heads.increment(); tails.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_01359" smilref="Title.smil#_01359"> invoke constructor</p><p attribs="{'xml:space': 'preserve'}" id="_01360" smilref="Title.smil#_01360"> automatically invoke</p><p attribs="{'xml:space': 'preserve'}" id="_01361" smilref="Title.smil#_01361"> toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01362" smilref="Title.smil#_01362"> object name</p><p attribs="{'xml:space': 'preserve'}" id="_01363" smilref="Title.smil#_01363"> StdOut.println(heads + " " + tails); StdOut.println(heads.tally() - tails.tally() ); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01364" smilref="Title.smil#_01364"> invoke method</p><p attribs="{'xml:space': 'preserve'}" id="_01365" smilref="Title.smil#_01365"> Anatomy of a class that defines a data type</p><p attribs="{'xml:space': 'preserve'}" id="_01366" smilref="Title.smil#_01366" /><pagenum id="p99" page="normal" smilref="Title.smil#p99" /><p attribs="{'xml:space': 'preserve'}" id="_01367" smilref="Title.smil#_01367"> 86</p><p attribs="{'xml:space': 'preserve'}" id="_01368" smilref="Title.smil#_01368"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01369" smilref="Title.smil#_01369"> public class Counter { private final String name; private int count; ...</p><p attribs="{'xml:space': 'preserve'}" id="_01370" smilref="Title.smil#_01370"> implicit, has no arguments, and initializes instance values to default values. The default values of instance variables are 0 for primitive numeric types, false for boolean, and null for reference types. These defaults may be changed by using initializing declarations for instance variables. Java automatically invokes a constructor when a client program uses the keyword new. Overloaded constructors are typically used to initialize instance variables to client-supplied values other than the defaults. For example, Counter has a one-argument constructor that initializes the name instance variable to the value given as argument (leaving the count instance variable to be initialized to the default value 0).</p><p attribs="{'xml:space': 'preserve'}" id="_01371" smilref="Title.smil#_01371"> public Counter ( String id ) { name = id; }</p><p attribs="{'xml:space': 'preserve'}" id="_01372" smilref="Title.smil#_01372"> code to initialize instance variables (count initialized to 0 by default)</p><p attribs="{'xml:space': 'preserve'}" id="_01373" smilref="Title.smil#_01373"> constructor name (same as class name)</p><p attribs="{'xml:space': 'preserve'}" id="_01374" smilref="Title.smil#_01374"> Anatomy of a constructor</p><p attribs="{'xml:space': 'preserve'}" id="_01375" smilref="Title.smil#_01375"> ... }</p><p attribs="{'xml:space': 'preserve'}" id="_01376" smilref="Title.smil#_01376"> parameter variable</p><p attribs="{'xml:space': 'preserve'}" id="_01377" smilref="Title.smil#_01377"> signature</p><p attribs="{'xml:space': 'preserve'}" id="_01378" smilref="Title.smil#_01378"> visibility modifier</p><p attribs="{'xml:space': 'preserve'}" id="_01379" smilref="Title.smil#_01379"> NO return type</p><p attribs="{'xml:space': 'preserve'}" id="_01380" smilref="Title.smil#_01380"> return type</p><p attribs="{'xml:space': 'preserve'}" id="_01381" smilref="Title.smil#_01381"> method name</p><p attribs="{'xml:space': 'preserve'}" id="_01382" smilref="Title.smil#_01382"> visibility modifier</p><p attribs="{'xml:space': 'preserve'}" id="_01383" smilref="Title.smil#_01383"> Instance methods. To implement data-type operations (the behavior of each object), we implement instance methods with code that is precisely like the code that you learned in Section 1.1 to implement static methods (functions). Each instance method has a return type, a signature (which specifies its name and the types and names of its parameter variables), and a body (which consists of a sequence of statements, including a return statement that provides a value of the return type back to the client). When a client invokes a method, the parameter values (if any) are initialized with client values, the statements are executed until a return value is computed, and the value is returned to the client, with the same effect as if the method invocation in the client were replaced with that value. All of this action is the same as for static methods, but there is one critical distinction for instance methods: they can access and perform operations on instance variables. How do we specify which object&#8217;s instance variables we want to use? If you think about this question for a moment, you will see the logical answer: a reference to a variable in an instance method refers to the value for the object that was used to invoke the method. When we say heads.increment() the code in increment() is referring to the instance variables for heads. In other words,</p><p attribs="{'xml:space': 'preserve'}" id="_01384" smilref="Title.smil#_01384"> public void increment() { count++; }</p><p attribs="{'xml:space': 'preserve'}" id="_01385" smilref="Title.smil#_01385"> Anatomy of an instance method</p><p attribs="{'xml:space': 'preserve'}" id="_01386" smilref="Title.smil#_01386"> instance variable name</p><p attribs="{'xml:space': 'preserve'}" id="_01387" smilref="Title.smil#_01387"> signature</p><p attribs="{'xml:space': 'preserve'}" id="_01388" smilref="Title.smil#_01388" /><pagenum id="p100" page="normal" smilref="Title.smil#p100" /><p attribs="{'xml:space': 'preserve'}" id="_01389" smilref="Title.smil#_01389"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01390" smilref="Title.smil#_01390"> 87</p><p attribs="{'xml:space': 'preserve'}" id="_01391" smilref="Title.smil#_01391"> object-oriented programming adds one critically important additional way to use variables in a Java program: </p><p attribs="{'xml:space': 'preserve'}" id="_01392" smilref="Title.smil#_01392"> Scope. In summary, the Java code that we write to implement instance methods uses three kinds of variables: </p><p attribs="{'xml:space': 'preserve'}" id="_01393" smilref="Title.smil#_01393"> public class Example { private int var; ...</p><p attribs="{'xml:space': 'preserve'}" id="_01394" smilref="Title.smil#_01394"> instance variable</p><p attribs="{'xml:space': 'preserve'}" id="_01395" smilref="Title.smil#_01395"> private void method1() { int var;</p><p attribs="{'xml:space': 'preserve'}" id="_01396" smilref="Title.smil#_01396"> local variable</p><p attribs="{'xml:space': 'preserve'}" id="_01397" smilref="Title.smil#_01397"> refers to local variable, NOT instance variable</p><p attribs="{'xml:space': 'preserve'}" id="_01398" smilref="Title.smil#_01398"> ... var ... ... this.var ...</p><p attribs="{'xml:space': 'preserve'}" id="_01399" smilref="Title.smil#_01399"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01400" smilref="Title.smil#_01400"> refers to instance variable</p><p attribs="{'xml:space': 'preserve'}" id="_01401" smilref="Title.smil#_01401"> private void method2() { ... var ... } ... }</p><p attribs="{'xml:space': 'preserve'}" id="_01402" smilref="Title.smil#_01402"> refers to instance variable</p><p attribs="{'xml:space': 'preserve'}" id="_01403" smilref="Title.smil#_01403"> Scope of instance and local variables in an instance method</p><p attribs="{'xml:space': 'preserve'}" id="_01404" smilref="Title.smil#_01404" /><pagenum id="p101" page="normal" smilref="Title.smil#p101" /><p attribs="{'xml:space': 'preserve'}" id="_01405" smilref="Title.smil#_01405"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_01406" smilref="Title.smil#_01406"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01407" smilref="Title.smil#_01407"> API, clients, and implementations. These are the basic components that you need to understand to be able to build and use abstract data types in Java. Every ADT implementation that we will consider will be a Java class with private instance variables, constructors, instance methods, and a client. To fully understand a data type, we need the API, typical client code, and an implementation, summarized for Counter on the facing page. To emphasize the separation of client and implementation, we normally present each client as a separate class containing a static method main() and reserve test client&#8217;s main() in the data-type definition for minimal unit testing and development (calling each instance method at least once). In each data type that we develop, we go through the same steps. Rather than thinking about what action we need to take next to accomplish a computational goal (as we did when first learning to program), we think about the needs of a client, then accommodate them in an ADT, following these three steps: </p><p attribs="{'xml:space': 'preserve'}" id="_01408" smilref="Title.smil#_01408" /><pagenum id="p102" page="normal" smilref="Title.smil#p102" /><p attribs="{'xml:space': 'preserve'}" id="_01409" smilref="Title.smil#_01409"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01410" smilref="Title.smil#_01410"> 89</p><p attribs="{'xml:space': 'preserve'}" id="_01411" smilref="Title.smil#_01411"> API</p><p attribs="{'xml:space': 'preserve'}" id="_01412" smilref="Title.smil#_01412"> public class Counter</p><p attribs="{'xml:space': 'preserve'}" id="_01413" smilref="Title.smil#_01413"> Counter(String id) create a counter named id increment the counter number of increments since creation string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01414" smilref="Title.smil#_01414"> void increment() int tally() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01415" smilref="Title.smil#_01415"> typical client</p><p attribs="{'xml:space': 'preserve'}" id="_01416" smilref="Title.smil#_01416"> public class Flips { public static void main(String[] args) { int T = Integer.parseInt(args[0]);</p><p attribs="{'xml:space': 'preserve'}" id="_01417" smilref="Title.smil#_01417"> Counter heads = new Counter("heads"); Counter tails = new Counter("tails");</p><p attribs="{'xml:space': 'preserve'}" id="_01418" smilref="Title.smil#_01418"> for (int t = 0; t &lt; T; t++) if (StdRandom.bernoulli(0.5)) heads.increment(); else tails.increment();</p><p attribs="{'xml:space': 'preserve'}" id="_01419" smilref="Title.smil#_01419"> StdOut.println(heads); StdOut.println(tails); int d = heads.tally() - tails.tally(); StdOut.println("delta: " + Math.abs(d)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01420" smilref="Title.smil#_01420"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01421" smilref="Title.smil#_01421"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01422" smilref="Title.smil#_01422"> % java Flips 1000000 500172 heads 499828 tails delta: 344</p><p attribs="{'xml:space': 'preserve'}" id="_01423" smilref="Title.smil#_01423"> public class Counter { private final String name; private int count;</p><p attribs="{'xml:space': 'preserve'}" id="_01424" smilref="Title.smil#_01424"> public Counter(String id) { name = id; }</p><p attribs="{'xml:space': 'preserve'}" id="_01425" smilref="Title.smil#_01425"> public void increment() { count++; }</p><p attribs="{'xml:space': 'preserve'}" id="_01426" smilref="Title.smil#_01426"> public int tally() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_01427" smilref="Title.smil#_01427"> public String toString() { return count + " " + name; }</p><p attribs="{'xml:space': 'preserve'}" id="_01428" smilref="Title.smil#_01428"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01429" smilref="Title.smil#_01429"> An abstract data type for a simple counter</p><p attribs="{'xml:space': 'preserve'}" id="_01430" smilref="Title.smil#_01430" /></level3><level3 id="_00011"><h3 id="ch1-s2-ss12" smilref="Title.smil#ch1-s2-ss12" xml:space="preserve">Implementing ADTs</h3><pagenum id="p103" page="normal" smilref="Title.smil#p103" /><p attribs="{'xml:space': 'preserve'}" id="_01431" smilref="Title.smil#_01431"> 90</p><p attribs="{'xml:space': 'preserve'}" id="_01432" smilref="Title.smil#_01432"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01433" smilref="Title.smil#_01433"> More implementations of abstract data types As with any programming</p><p attribs="{'xml:space': 'preserve'}" id="_01434" smilref="Title.smil#_01434"> concept, the best way to understand the power and utility of ADTs is to consider carefully more examples and more implementations. There will be ample opportunity for you to do so, as much of this book is devoted to ADT implementations, but a few more simple examples will help us lay the groundwork for addressing them. Date. Shown on the facing page are two implementations of the Date ADT that we considered on page 79. To reduce clutter, we omit the parsing constructor (which is described in Exercise 1.2.19) and the inherited methods equals() (see page 103), compareTo() (see page 247), and hashCode() (see Exercise 3.4.22). The straightforward implementation on the left maintains the day, month, and year as instance variables, so that the instance methods can just return the appropriate value; the more space-ef&#64257; cient implementation on the right uses only a single int value to represent a date, using a mixed-radix number that represents the date with day d, month m, and year y as 512y + 32m + d. One way that a client might notice the difference between these implementations is by violating implicit assumptions: the second implementation depends for its correctness on the day being between 0 and 31, the month being between 0 and 15, and the year being positive (in practice, both implementations should check that months are between 1 and 12, days are between 1 and 31, and that dates such as June 31 and February 29, 2009, are illegal, though that requires a bit more work). This example highlights the idea that we rarely fully specify implementation requirements in an API (we normally do the best we can, and could do better here). Another way that a client might notice the difference between the two implementations is performance: the implementation on the right uses less space to hold data-type values at the cost of more time to provide them to the client in the agreed form (one or two arithmetic operations are needed). Such tradeoffs are common: one client may prefer one of the implementations and another client might prefer the other, so we need to accommodate both. Indeed, one of the recurring themes of this book is that we need to understand the space and time requirements of various implementations and their suitability for use by various clients. One of the key advantages of using data abstraction in our implementations is that we can normally change from one implementation to another without changing any client code.</p><p attribs="{'xml:space': 'preserve'}" id="_01435" smilref="Title.smil#_01435"> Maintaining multiple implementations. Multiple implementations of the same API can present maintainence and nomenclature issues. In some cases, we simply want to replace an old implementation with an improved one. In others, we may need to maintain two implementations, one suitable for some clients, the other suitable for others. Indeed, a prime goal of this book is to consider in depth several implementations of each of a number of fundamental ADTs, generally with different performance charac- teristics. In this book, we often compare the performance of a single client using two</p><p attribs="{'xml:space': 'preserve'}" id="_01436" smilref="Title.smil#_01436" /><pagenum id="p104" page="normal" smilref="Title.smil#p104" /><p attribs="{'xml:space': 'preserve'}" id="_01437" smilref="Title.smil#_01437"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01438" smilref="Title.smil#_01438"> 91</p><p attribs="{'xml:space': 'preserve'}" id="_01439" smilref="Title.smil#_01439"> API</p><p attribs="{'xml:space': 'preserve'}" id="_01440" smilref="Title.smil#_01440"> public class Date Date(int month, int day, int year) int month() int day() int year() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01441" smilref="Title.smil#_01441"> create a date month day year</p><p attribs="{'xml:space': 'preserve'}" id="_01442" smilref="Title.smil#_01442"> string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01443" smilref="Title.smil#_01443"> test client</p><p attribs="{'xml:space': 'preserve'}" id="_01444" smilref="Title.smil#_01444"> public static void main(String[] args) { int m = Integer.parseInt(args[0]); int d = Integer.parseInt(args[1]); int y = Integer.parseInt(args[2]); Date date = new Date(m, d, y); StdOut.println(date); }</p><p attribs="{'xml:space': 'preserve'}" id="_01445" smilref="Title.smil#_01445"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01446" smilref="Title.smil#_01446"> % java Date 12 31 1999 12/31/1999</p><p attribs="{'xml:space': 'preserve'}" id="_01447" smilref="Title.smil#_01447"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01448" smilref="Title.smil#_01448"> alternate implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01449" smilref="Title.smil#_01449"> public class Date { private final int month; private final int day; private final int year;</p><p attribs="{'xml:space': 'preserve'}" id="_01450" smilref="Title.smil#_01450"> public Date(int m, int d, int y) { month = m; day = d; year = y; }</p><p attribs="{'xml:space': 'preserve'}" id="_01451" smilref="Title.smil#_01451"> public int month() { return month; }</p><p attribs="{'xml:space': 'preserve'}" id="_01452" smilref="Title.smil#_01452"> public int day() { return day; }</p><p attribs="{'xml:space': 'preserve'}" id="_01453" smilref="Title.smil#_01453"> public int year() { return day; }</p><p attribs="{'xml:space': 'preserve'}" id="_01454" smilref="Title.smil#_01454"> public String toString() { return month() + "/" + day() + "/" + year(); }</p><p attribs="{'xml:space': 'preserve'}" id="_01455" smilref="Title.smil#_01455"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01456" smilref="Title.smil#_01456"> public class Date { private final int value;</p><p attribs="{'xml:space': 'preserve'}" id="_01457" smilref="Title.smil#_01457"> public Date(int m, int d, int y) { value = y*512 + m*32 + d; }</p><p attribs="{'xml:space': 'preserve'}" id="_01458" smilref="Title.smil#_01458"> public int month() { return (value / 32) % 16; }</p><p attribs="{'xml:space': 'preserve'}" id="_01459" smilref="Title.smil#_01459"> public int day() { return value % 32; }</p><p attribs="{'xml:space': 'preserve'}" id="_01460" smilref="Title.smil#_01460"> public int year() { return value / 512; }</p><p attribs="{'xml:space': 'preserve'}" id="_01461" smilref="Title.smil#_01461"> public String toString() { return month() + "/" + day() + "/" + year(); }</p><p attribs="{'xml:space': 'preserve'}" id="_01462" smilref="Title.smil#_01462"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01463" smilref="Title.smil#_01463"> An abstract data type to encapsulate dates, with two implementations</p><p attribs="{'xml:space': 'preserve'}" id="_01464" smilref="Title.smil#_01464" /><pagenum id="p105" page="normal" smilref="Title.smil#p105" /><p attribs="{'xml:space': 'preserve'}" id="_01465" smilref="Title.smil#_01465"> 92</p><p attribs="{'xml:space': 'preserve'}" id="_01466" smilref="Title.smil#_01466"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01467" smilref="Title.smil#_01467"> different implementations of the same API. For this reason, we generally adopt an informal naming convention where we: </p><p attribs="{'xml:space': 'preserve'}" id="_01468" smilref="Title.smil#_01468"> Accumulator. The accumulator API shown on the facing page defines an abstract data type that provides to clients the ability to maintain a running average of data values. For example, we use this data type frequently in this book to process experimental results (see Section 1.4). The implementation is straightforward: it maintains a int instance variable counts the number of data values seen so far and a double instance variable that keeps track of the sum of the values seen so far; to compute the average it divides the sum by the count. Note that the implementation does not save the data values&#8212;it could be used for a huge number of them (even on a device that is not capable of holding that many), or a huge number of accumulators could be used on a big system. This performance characteristic is subtle and might be specified in the API, because an implementation that does save the values might cause an application to run out of memory.</p><p attribs="{'xml:space': 'preserve'}" id="_01469" smilref="Title.smil#_01469" /><pagenum id="p106" page="normal" smilref="Title.smil#p106" /><p attribs="{'xml:space': 'preserve'}" id="_01470" smilref="Title.smil#_01470"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01471" smilref="Title.smil#_01471"> 93</p><p attribs="{'xml:space': 'preserve'}" id="_01472" smilref="Title.smil#_01472"> API</p><p attribs="{'xml:space': 'preserve'}" id="_01473" smilref="Title.smil#_01473"> public class Accumulator Accumulator() void addDataValue(double val) double mean() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01474" smilref="Title.smil#_01474"> create an accumulator add a new data value mean of all data values string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01475" smilref="Title.smil#_01475"> typical client</p><p attribs="{'xml:space': 'preserve'}" id="_01476" smilref="Title.smil#_01476"> public class TestAccumulator { public static void main(String[] args) { int T = Integer.parseInt(args[0]); Accumulator a = new Accumulator(); for (int t = 0; t &lt; T; t++) a.addDataValue(StdRandom.random()); StdOut.println(a); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01477" smilref="Title.smil#_01477"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01478" smilref="Title.smil#_01478"> % java TestAccumulator 1000 Mean (1000 values): 0.51829</p><p attribs="{'xml:space': 'preserve'}" id="_01479" smilref="Title.smil#_01479"> % java TestAccumulator 1000000 Mean (1000000 values): 0.49948</p><p attribs="{'xml:space': 'preserve'}" id="_01480" smilref="Title.smil#_01480"> % java TestAccumulator 1000000 Mean (1000000 values): 0.50014</p><p attribs="{'xml:space': 'preserve'}" id="_01481" smilref="Title.smil#_01481"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01482" smilref="Title.smil#_01482"> public class Accumulator { private double total; private int N;</p><p attribs="{'xml:space': 'preserve'}" id="_01483" smilref="Title.smil#_01483"> public void addDataValue(double val) { N++; total += val; }</p><p attribs="{'xml:space': 'preserve'}" id="_01484" smilref="Title.smil#_01484"> public double mean() { return total/N; }</p><p attribs="{'xml:space': 'preserve'}" id="_01485" smilref="Title.smil#_01485"> public String toString() { return "Mean (" + N + " values): " + String.format("%7.5f", mean()); }</p><p attribs="{'xml:space': 'preserve'}" id="_01486" smilref="Title.smil#_01486"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01487" smilref="Title.smil#_01487"> An abstract data type for accumulating data values</p><p attribs="{'xml:space': 'preserve'}" id="_01488" smilref="Title.smil#_01488" /><pagenum id="p107" page="normal" smilref="Title.smil#p107" /><p attribs="{'xml:space': 'preserve'}" id="_01489" smilref="Title.smil#_01489"> 94</p><p attribs="{'xml:space': 'preserve'}" id="_01490" smilref="Title.smil#_01490"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01491" smilref="Title.smil#_01491"> height of Nth red dot from the left is the average of the heights of the leftmost N gray dots</p><p attribs="{'xml:space': 'preserve'}" id="_01492" smilref="Title.smil#_01492"> Visual accumulator. The visual accumulator implementation shown on the facing page extends Accumulator to present a useful side effect: it draws on StdDraw all the data (in gray) and the running average (in red). The easiest way to do so is to add a constructor that provides the number of points to be plotted and the maximum value, for rescaling the plot. VisualAccumulator is not technically an implementation of the Accumulator API (its constructor has a different signature and it causes a different prescribed side effect). Generally, we are careful to fully specify APIs and are loath to make any changes in an API once articulated, as it might involve changing an unknown amount of client (and implementation) code, but adding a constructor to gain functionality can sometimes be defended because it involves changing the same line in client code that we change when changing a class name. In this example, if we have developed a client that uses an Accumulator and perhaps has many calls to addDataValue() and mean(), we can enjoy the benefits of VisualAccumulator by just changing one line of client code.</p><p attribs="{'xml:space': 'preserve'}" id="_01493" smilref="Title.smil#_01493"> height of gray dot is the data point value</p><p attribs="{'xml:space': 'preserve'}" id="_01494" smilref="Title.smil#_01494"> Visual accumulator plot</p><p attribs="{'xml:space': 'preserve'}" id="_01495" smilref="Title.smil#_01495"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01496" smilref="Title.smil#_01496"> % java TestVisualAccumulator 2000 Mean (2000 values): 0.509789</p><p attribs="{'xml:space': 'preserve'}" id="_01497" smilref="Title.smil#_01497" /><pagenum id="p108" page="normal" smilref="Title.smil#p108" /><p attribs="{'xml:space': 'preserve'}" id="_01498" smilref="Title.smil#_01498"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01499" smilref="Title.smil#_01499"> 95</p><p attribs="{'xml:space': 'preserve'}" id="_01500" smilref="Title.smil#_01500"> API</p><p attribs="{'xml:space': 'preserve'}" id="_01501" smilref="Title.smil#_01501"> public class VisualAccumulator VisualAccumulator(int trials, double max) void addDataValue(double val) double mean() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01502" smilref="Title.smil#_01502"> add a new data value mean of all data values string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01503" smilref="Title.smil#_01503"> typical client</p><p attribs="{'xml:space': 'preserve'}" id="_01504" smilref="Title.smil#_01504"> public class TestVisualAccumulator { public static void main(String[] args) { int T = Integer.parseInt(args[0]); VisualAccumulator a = new VisualAccumulator(T, 1.0); for (int t = 0; t &lt; T; t++) a.addDataValue(StdRandom.random()); StdOut.println(a); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01505" smilref="Title.smil#_01505"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01506" smilref="Title.smil#_01506"> public class VisualAccumulator { private double total; private int N;</p><p attribs="{'xml:space': 'preserve'}" id="_01507" smilref="Title.smil#_01507"> public VisualAccumulator(int trials, double max) { StdDraw.setXscale(0, trials); StdDraw.setYscale(0, max); StdDraw.setPenRadius(.005); }</p><p attribs="{'xml:space': 'preserve'}" id="_01508" smilref="Title.smil#_01508"> public void addDataValue(double val) { N++; total += val; StdDraw.setPenColor(StdDraw.DARK_GRAY); StdDraw.point(N, val); StdDraw.setPenColor(StdDraw.RED); StdDraw.point(N, mean()); }</p><p attribs="{'xml:space': 'preserve'}" id="_01509" smilref="Title.smil#_01509"> public double mean() public String toString() // Same as Accumulator.</p><p attribs="{'xml:space': 'preserve'}" id="_01510" smilref="Title.smil#_01510"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01511" smilref="Title.smil#_01511"> An abstract data type for accumulating data values (visual version)</p><p attribs="{'xml:space': 'preserve'}" id="_01512" smilref="Title.smil#_01512" /></level3><level3 id="_00012"><h3 id="ch1-s2-ss13" smilref="Title.smil#ch1-s2-ss13" xml:space="preserve">Designing ADTs</h3><pagenum id="p109" page="normal" smilref="Title.smil#p109" /><p attribs="{'xml:space': 'preserve'}" id="_01513" smilref="Title.smil#_01513"> 96</p><p attribs="{'xml:space': 'preserve'}" id="_01514" smilref="Title.smil#_01514"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01515" smilref="Title.smil#_01515"> Designing abstract data types An abstract data type is a data type whose representation is hidden from the client. This idea has had a powerful effect on modern pro- gramming. The various examples that we have considered give us the vocabulary to address advanced characteristics of ADTs and their implementation as Java classes. Many of these topics are, on the surface, tangential to the study of algorithms, so it is safe for you to skim this section and refer to it later in the context of specific implementation problems. Our goal is to put important information related to designing data types in one place for reference and to set the stage for implementations throughout this book.</p><p attribs="{'xml:space': 'preserve'}" id="_01516" smilref="Title.smil#_01516"> Encapsulation. A hallmark of object-oriented programming is that it enables us to encapsulate data types within their implementations, to facilitate separate development of clients and data type implementations. Encapsulation enables modular program- ming, allowing us to </p><p attribs="{'xml:space': 'preserve'}" id="_01517" smilref="Title.smil#_01517" /><pagenum id="p110" page="normal" smilref="Title.smil#p110" /><p attribs="{'xml:space': 'preserve'}" id="_01518" smilref="Title.smil#_01518"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01519" smilref="Title.smil#_01519"> 97</p><p attribs="{'xml:space': 'preserve'}" id="_01520" smilref="Title.smil#_01520"> Designing APIs. One of the most important and most challenging steps in building modern software is designing APIs. This task takes practice, careful deliberation, and many iterations, but any time spent designing a good API is certain to be repaid in time saved debugging or code reuse. Articulating an API might seem to be overkill when writing a small program, but you should consider writing every program as though you will need to reuse the code someday. Ideally, an API would clearly articulate behavior for all possible inputs, including side effects, and then we would have software to check that implementations meet the speci&#64257; cation. Unfortunately, a fundamental result from theoretical computer science known as the specification problem implies that this goal is actually impossible to achieve. Brie&#64258; y, such a specification would have to be written in a formal language like a programming language, and the problem of determining whether two programs perform the same computation is known, mathematically, to be undecidable. Therefore, our APIs are brief English-language descriptions of the set of values in the associated abstract data type along with a list of constructors and instance methods, again with brief English-language descriptions of their purpose, including side effects. To validate the design, we always include examples of client code in the text surrounding our APIs. Within this broad outline, there are numerous pitfalls that every API design is susceptible to: </p><p attribs="{'xml:space': 'preserve'}" id="_01521" smilref="Title.smil#_01521" /><pagenum id="p111" page="normal" smilref="Title.smil#p111" /><p attribs="{'xml:space': 'preserve'}" id="_01522" smilref="Title.smil#_01522"> 98</p><p attribs="{'xml:space': 'preserve'}" id="_01523" smilref="Title.smil#_01523"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01524" smilref="Title.smil#_01524"> Algorithms and abstract data types. Data abstraction is naturally suited to the study of algorithms, because it helps us provide a framework within which we can precisely specify both what an algorithm needs to accomplish and how a client can make use of an algorithm. Typically, in this book, an algorithm is an implementation of an instance method in an abstract data type. For example, our whitelisting example at the beginning of the chapter is naturally cast as an ADT client, based on the following operations: </p><p attribs="{'xml:space': 'preserve'}" id="_01525" smilref="Title.smil#_01525"> Every Java program is a set of</p><p attribs="{'xml:space': 'preserve'}" id="_01526" smilref="Title.smil#_01526"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01527" smilref="Title.smil#_01527"> % java Whitelist largeW.txt &lt; largeT.txt 499569 984875 295754 207807 140925 161828 ...</p><p attribs="{'xml:space': 'preserve'}" id="_01528" smilref="Title.smil#_01528"> static methods and/or a data type implementation. In this book, we focus primarily on abstract data type implementations such as StaticSETofInts, where the focus is on operations and the representation of the data is hidden from the client. As this example illustrates, data abstraction enables us to </p><p attribs="{'xml:space': 'preserve'}" id="_01529" smilref="Title.smil#_01529" /><pagenum id="p112" page="normal" smilref="Title.smil#p112" /><p attribs="{'xml:space': 'preserve'}" id="_01530" smilref="Title.smil#_01530"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01531" smilref="Title.smil#_01531"> 99</p><p attribs="{'xml:space': 'preserve'}" id="_01532" smilref="Title.smil#_01532"> API</p><p attribs="{'xml:space': 'preserve'}" id="_01533" smilref="Title.smil#_01533"> public class StaticSETofInts StaticSETofInts(int[] a) boolean contains(int key)</p><p attribs="{'xml:space': 'preserve'}" id="_01534" smilref="Title.smil#_01534"> create a set from the values in a[] is key in the set?</p><p attribs="{'xml:space': 'preserve'}" id="_01535" smilref="Title.smil#_01535"> typical client</p><p attribs="{'xml:space': 'preserve'}" id="_01536" smilref="Title.smil#_01536"> public class Whitelist { public static void main(String[] args) { int[] w = In.readInts(args[0]); StaticSETofInts set = new StaticSETofInts(w); while (!StdIn.isEmpty()) { // Read key, print if not in whitelist. int key = StdIn.readInt(); if (!set.contains(key)) StdOut.println(key); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_01537" smilref="Title.smil#_01537"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_01538" smilref="Title.smil#_01538"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_01539" smilref="Title.smil#_01539"> public class StaticSETofInts { private int[] a;</p><p attribs="{'xml:space': 'preserve'}" id="_01540" smilref="Title.smil#_01540"> public StaticSETofInts(int[] keys) { a = new int[keys.length]; for (int i = 0; i &lt; keys.length; i++) a[i] = keys[i]; // defensive copy Arrays.sort(a); }</p><p attribs="{'xml:space': 'preserve'}" id="_01541" smilref="Title.smil#_01541"> public boolean contains(int key) { return rank(key) != -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_01542" smilref="Title.smil#_01542"> private int rank(int key) { // Binary search. int lo = 0; int hi = a.length - 1; while (lo &lt;= hi) { // Key is in a[lo..hi] or not present. int mid = lo + (hi - lo) / 2; if (key &lt; a[mid]) hi = mid - 1; else if (key &gt; a[mid]) lo = mid + 1; else return mid; } return -1; } }</p><p attribs="{'xml:space': 'preserve'}" id="_01543" smilref="Title.smil#_01543"> Binary search recast as an object-oriented program (an ADT for search in a set of integers)</p><p attribs="{'xml:space': 'preserve'}" id="_01544" smilref="Title.smil#_01544" /><pagenum id="p113" page="normal" smilref="Title.smil#p113" /><p attribs="{'xml:space': 'preserve'}" id="_01545" smilref="Title.smil#_01545"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_01546" smilref="Title.smil#_01546"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01547" smilref="Title.smil#_01547"> Interface inheritance. Java provides language support for defining relationships among objects, known as inheritance. These mechanisms are widely used by software developers, so you will study them in detail if you take a course in software engineer- ing. The first inheritance mechanism that we consider is known as subtyping, which allows us to specify a relationship between otherwise unrelated classes by specifying in an interface a set of common methods that each implementing class must contain. An interface is nothing more than a list of instance methods. For example, instead of using our informal API, we might have articulated an interface for Date:</p><p attribs="{'xml:space': 'preserve'}" id="_01548" smilref="Title.smil#_01548"> public interface Datable { int month(); int day(); int year(); }</p><p attribs="{'xml:space': 'preserve'}" id="_01549" smilref="Title.smil#_01549"> and then referred to the interface in our implementation code</p><p attribs="{'xml:space': 'preserve'}" id="_01550" smilref="Title.smil#_01550"> public class Date implements Datable { // implementation code (same as before) }</p><p attribs="{'xml:space': 'preserve'}" id="_01551" smilref="Title.smil#_01551"> methods</p><p attribs="{'xml:space': 'preserve'}" id="_01552" smilref="Title.smil#_01552"> section</p><p attribs="{'xml:space': 'preserve'}" id="_01553" smilref="Title.smil#_01553"> java.lang.Comparable compareTo()</p><p attribs="{'xml:space': 'preserve'}" id="_01554" smilref="Title.smil#_01554"> so that the Java compiler will check that it matches the interface. Adding the code implements Datable to any class that implements month(), day(), and year() provides a guarantee to any client that an object of that class can invoke those methods. This arrangement is known as interface inheritance&#8212;an implementing class inherits the interface. Interface inheritance allows us to write client programs that can manipulate objects of any type that implements the interface (even a type to be created in the future), by invoking methods in the interface. We might have used interface inheritance in place of our more informal APIs, but chose not to do so to avoid dependence on specific high-level language mechanisms that are not critical to the understanding of algorithms and to avoid the extra baggage of interface fi les. But there are a few situations where Java conventions make</p><p attribs="{'xml:space': 'preserve'}" id="_01555" smilref="Title.smil#_01555"> hasNext() next() remove()</p><p attribs="{'xml:space': 'preserve'}" id="_01556" smilref="Title.smil#_01556"> java.util.Comparator</p><p attribs="{'xml:space': 'preserve'}" id="_01557" smilref="Title.smil#_01557"> compare()</p><p attribs="{'xml:space': 'preserve'}" id="_01558" smilref="Title.smil#_01558"> java.lang.Iterable</p><p attribs="{'xml:space': 'preserve'}" id="_01559" smilref="Title.smil#_01559"> iterator()</p><p attribs="{'xml:space': 'preserve'}" id="_01560" smilref="Title.smil#_01560"> Java interfaces used in this book</p><p attribs="{'xml:space': 'preserve'}" id="_01561" smilref="Title.smil#_01561"> java.util.Iterator</p><p attribs="{'xml:space': 'preserve'}" id="_01562" smilref="Title.smil#_01562"> 2.1</p><p attribs="{'xml:space': 'preserve'}" id="_01563" smilref="Title.smil#_01563"> 2.5</p><p attribs="{'xml:space': 'preserve'}" id="_01564" smilref="Title.smil#_01564"> 1.3</p><p attribs="{'xml:space': 'preserve'}" id="_01565" smilref="Title.smil#_01565"> 1.3</p><p attribs="{'xml:space': 'preserve'}" id="_01566" smilref="Title.smil#_01566"> interface</p><p attribs="{'xml:space': 'preserve'}" id="_01567" smilref="Title.smil#_01567"> compar ison</p><p attribs="{'xml:space': 'preserve'}" id="_01568" smilref="Title.smil#_01568"> iteration</p><p attribs="{'xml:space': 'preserve'}" id="_01569" smilref="Title.smil#_01569" /><pagenum id="p114" page="normal" smilref="Title.smil#p114" /><p attribs="{'xml:space': 'preserve'}" id="_01570" smilref="Title.smil#_01570"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01571" smilref="Title.smil#_01571"> 101</p><p attribs="{'xml:space': 'preserve'}" id="_01572" smilref="Title.smil#_01572"> it worthwhile for us to take advantage of interfaces: we use them for comparison and for iteration, as detailed in the table at the bottom of the previous page, and will consider them in more detail when we cover those concepts.</p><p attribs="{'xml:space': 'preserve'}" id="_01573" smilref="Title.smil#_01573"> Implementation inheritance. Java also supports another inheritence mechanism known as subclassing, which is a powerful technique that enables a programmer to change behavior and add functionality without rewriting an entire class from scratch. The idea is to define a new class ( subclass, or derived class) that inherits instance methods and instance variables from another class ( superclass, or base class). The subclass contains more methods than the superclass. Moreover, the subclass can redefine or override methods in the superclass. Subclassing is widely used by systems programmers to build so-called extensible libraries&#8212;one programmer (even you) can add methods to a library built by another programmer (or, perhaps, a team of systems programmers), effectively reusing the code in a potentially huge library. For example, this approach is widely used in the development of graphical user interfaces, so that the large amount of code required to provide all the facilities that users expect (drop-down menus, cut-and- paste, access to fi les, and so forth) can be reused. The use of subclassing is controversial among systems and applications programmers (its advantages over interface inheritance are debatable), and we avoid it in this book because it generally works against encapsulation. Certain vestiges of the approach are built in to Java and therefore un- avoidable: speci&#64257; cally, every class is a subtype of Java&#8217;s Object class. This structure enables the &#8220;convention&#8221; that every class includes an implementation of getClass(), toString(), equals(), hashCode(), and several other methods that we do not use in this book. Actually, every class inherits these methods from Object through subclassing, so any client can use them for any object. We usually override toString(), equals(), hashCode() in new classes because the default Object implementation generally does not lead to the desired behavior. We now will consider toString() and equals(); we discuss hashCode() in Section 3.4.</p><p attribs="{'xml:space': 'preserve'}" id="_01574" smilref="Title.smil#_01574"> method</p><p attribs="{'xml:space': 'preserve'}" id="_01575" smilref="Title.smil#_01575"> purpose</p><p attribs="{'xml:space': 'preserve'}" id="_01576" smilref="Title.smil#_01576"> section</p><p attribs="{'xml:space': 'preserve'}" id="_01577" smilref="Title.smil#_01577"> Class getClass()</p><p attribs="{'xml:space': 'preserve'}" id="_01578" smilref="Title.smil#_01578"> what class is this object ?</p><p attribs="{'xml:space': 'preserve'}" id="_01579" smilref="Title.smil#_01579"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01580" smilref="Title.smil#_01580"> string representation of this object</p><p attribs="{'xml:space': 'preserve'}" id="_01581" smilref="Title.smil#_01581"> boolean equals(Object that)</p><p attribs="{'xml:space': 'preserve'}" id="_01582" smilref="Title.smil#_01582"> is this object equal to that?</p><p attribs="{'xml:space': 'preserve'}" id="_01583" smilref="Title.smil#_01583"> int hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_01584" smilref="Title.smil#_01584"> hash code for this object</p><p attribs="{'xml:space': 'preserve'}" id="_01585" smilref="Title.smil#_01585"> 1.2 1.1 1.2 3.4</p><p attribs="{'xml:space': 'preserve'}" id="_01586" smilref="Title.smil#_01586"> Inherited methods from Object used in this book</p><p attribs="{'xml:space': 'preserve'}" id="_01587" smilref="Title.smil#_01587" /><pagenum id="p115" page="normal" smilref="Title.smil#p115" /><p attribs="{'xml:space': 'preserve'}" id="_01588" smilref="Title.smil#_01588"> 102</p><p attribs="{'xml:space': 'preserve'}" id="_01589" smilref="Title.smil#_01589"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01590" smilref="Title.smil#_01590"> String conversion. By convention, every Java type inherits toString() from Object, so any client can invoke toString() for any object. This convention is the basis for Ja- va&#8217;s automatic conversion of one operand of the concatenation operator + to a String whenever the other operand is a String. If an object&#8217;s data type does not include an implementation of toString(), then the default implementation in Object is invoked, which is normally not helpful, since it typically returns a string representation of the memory address of the object. Accordingly, we generally include implementations of toString() that override the default in every class that we develop, as highlighted for Date on the facing page. As illustrated in this code, toString() implementations are often quite simple, implicitly (through +) using toString() for each instance variable.</p><p attribs="{'xml:space': 'preserve'}" id="_01591" smilref="Title.smil#_01591"> Wrapper types. Java supplies built-in reference types known as wrapper types, one for each of the primitive types: Boolean, Byte, Character, Double, Float, Integer, Long,</p><p attribs="{'xml:space': 'preserve'}" id="_01592" smilref="Title.smil#_01592"> and Short correspond to boolean, byte, char, double, float, int, long, and short,</p><p attribs="{'xml:space': 'preserve'}" id="_01593" smilref="Title.smil#_01593"> respectively. These classes consist primarily of static methods such as parseInt() but they also include the inherited instance methods toString(), compareTo(), equals(), and hashCode(). Java automatically converts from primitive types to wrapper types when warranted, as described on page 122. For example, when an int value is concatenated with a String, it is converted to an Integer that can invoke toString().</p><p attribs="{'xml:space': 'preserve'}" id="_01594" smilref="Title.smil#_01594"> Equality. What does it mean for two objects to be equal? If we test equality with (a == b) where a and b are reference variables of the same type, we are testing whether they have the same identity : whether the references are equal. Typical clients would rather be able to test whether the data-type values (object state) are the same, or to implement some type-speci&#64257; c rule. Java gives us a head start by providing implementations both for standard types such as Integer, Double, and String and for more complicated types such as File and URL. When using these types of data, you can just use the built-in implementation. For example, if x and y are String values, then x.equals(y) is true if and only if x and y have the same length and are identical in each character position. When we define our own data types, such as Date or Transaction, we need to override equals(). Java&#8217;s convention is that equals() must be an equivalence rela- tion. It must be</p><p attribs="{'xml:space': 'preserve'}" id="_01595" smilref="Title.smil#_01595"> </p><p attribs="{'xml:space': 'preserve'}" id="_01596" smilref="Title.smil#_01596"> </p><p attribs="{'xml:space': 'preserve'}" id="_01597" smilref="Title.smil#_01597"> </p><p attribs="{'xml:space': 'preserve'}" id="_01598" smilref="Title.smil#_01598"> In addition, it must take an Object as argument and satisfy the following properties. </p><p attribs="{'xml:space': 'preserve'}" id="_01599" smilref="Title.smil#_01599"> </p><p attribs="{'xml:space': 'preserve'}" id="_01600" smilref="Title.smil#_01600" /><pagenum id="p116" page="normal" smilref="Title.smil#p116" /><p attribs="{'xml:space': 'preserve'}" id="_01601" smilref="Title.smil#_01601"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01602" smilref="Title.smil#_01602"> 103</p><p attribs="{'xml:space': 'preserve'}" id="_01603" smilref="Title.smil#_01603"> public class Date { private final int month; private final int day; private final int year;</p><p attribs="{'xml:space': 'preserve'}" id="_01604" smilref="Title.smil#_01604"> These are natural defi nitions, but ensuring that these properties hold, adhering to Java conventions, and avoiding unnecessary work in an implementation can be tricky, as illustrated for Date below. It takes the following step-by-step approach: </p><p attribs="{'xml:space': 'preserve'}" id="_01605" smilref="Title.smil#_01605"> public boolean equals(Object x) { if (this == x) return true; if (x == null) return false; if (this.getClass() != x.getClass()) return false; Date that = (Date) x; if (this.day != that.day) return false; if (this.month != that.month) return false; if (this.year != that.year) return false; return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_01606" smilref="Title.smil#_01606"> public String toString() { return month() + "/" + day() + "/" + year(); }</p><p attribs="{'xml:space': 'preserve'}" id="_01607" smilref="Title.smil#_01607"> public Date(int m, int d, int y) { month = m; day = d; year = y; }</p><p attribs="{'xml:space': 'preserve'}" id="_01608" smilref="Title.smil#_01608"> public int month() { return month; }</p><p attribs="{'xml:space': 'preserve'}" id="_01609" smilref="Title.smil#_01609"> public int day() { return day; }</p><p attribs="{'xml:space': 'preserve'}" id="_01610" smilref="Title.smil#_01610"> public int year() { return year; }</p><p attribs="{'xml:space': 'preserve'}" id="_01611" smilref="Title.smil#_01611"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01612" smilref="Title.smil#_01612"> Overriding toString() and equals() in a data-type def inition</p><p attribs="{'xml:space': 'preserve'}" id="_01613" smilref="Title.smil#_01613" /><pagenum id="p117" page="normal" smilref="Title.smil#p117" /><p attribs="{'xml:space': 'preserve'}" id="_01614" smilref="Title.smil#_01614"> 104</p><p attribs="{'xml:space': 'preserve'}" id="_01615" smilref="Title.smil#_01615"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01616" smilref="Title.smil#_01616"> Date a = new Date(12, 31, 1999); Date b = new Date( 1, 1, 2011); b = a;</p><p attribs="{'xml:space': 'preserve'}" id="_01617" smilref="Title.smil#_01617"> a 655 b 655</p><p attribs="{'xml:space': 'preserve'}" id="_01618" smilref="Title.smil#_01618"> 655 12 656 31 657 1999</p><p attribs="{'xml:space': 'preserve'}" id="_01619" smilref="Title.smil#_01619"> 811 1 812 1 813 2011</p><p attribs="{'xml:space': 'preserve'}" id="_01620" smilref="Title.smil#_01620"> orphaned object</p><p attribs="{'xml:space': 'preserve'}" id="_01621" smilref="Title.smil#_01621"> New Year&#8217;s Eve 1999</p><p attribs="{'xml:space': 'preserve'}" id="_01622" smilref="Title.smil#_01622"> references to same object</p><p attribs="{'xml:space': 'preserve'}" id="_01623" smilref="Title.smil#_01623"> Memory management. The ability to assign a new value to a reference variable creates the possibility that a program may have created an object that can no longer be referenced. For example, consider the three assignment statements in the figure at left. After the third assignment statement, not only do a and b refer to the same Date object (12/31/1999), but also there is no longer a reference to the Date object that was created and used to initialize b. The only reference to that object was in the variable b, and this reference was overwritten by the assignment, so there is no way to refer to the object again. Such an object is said to be orphaned. Objects are also orphaned when they go out of scope. Java programs tend to create huge numbers of objects (and variables that hold primitive data-type values), but only have a need for a small number of them at any given point in time. Accord- ingly, programming languages and systems need mechanisms to allocate memory for data-type values during the time they are needed and to free the memory when they are no longer needed (for an object, sometime after it is orphaned). Memory management turns out to be easier for primitive types because all of the information needed for memory allocation is known at compile time. Java (and most other systems) takes care of reserving space for variables when they are declared and freeing that space when they go out of scope. Memory management for objects is more complicated: the system can allocate memory for an object when it is created, but cannot know precisely when to free the memory associated with each object because the dynamics of a program in execution determines when objects are orphaned. In many languages (such as C and C++) the programmer is responsible for both allocating and freeing memory. Doing so is tedious and notoriously error-prone. One of Java&#8217;s most significant features is its ability to automatically manage memory. The idea is to free the programmers from the responsibility of managing memory by keeping track of orphaned objects and returning the memory they use to a pool of free memory. Reclaiming memory in this way is known as garbage collection. One of Java&#8217;s characteristic features is its policy that references cannot be modi&#64257; ed. This policy enables Java to do efficient automatic garbage collection. Programmers still debate whether the overhead of automatic garbage collection justifies the convenience of not having to worry about memory management.</p><p attribs="{'xml:space': 'preserve'}" id="_01624" smilref="Title.smil#_01624"> New Year&#8217;s Day 2011</p><p attribs="{'xml:space': 'preserve'}" id="_01625" smilref="Title.smil#_01625"> An orphaned object</p><p attribs="{'xml:space': 'preserve'}" id="_01626" smilref="Title.smil#_01626" /><pagenum id="p118" page="normal" smilref="Title.smil#p118" /><p attribs="{'xml:space': 'preserve'}" id="_01627" smilref="Title.smil#_01627"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01628" smilref="Title.smil#_01628"> 105</p><p attribs="{'xml:space': 'preserve'}" id="_01629" smilref="Title.smil#_01629"> Immutability. An immutable data type, such as Date, has the property that the value of an object never changes once constructed. By contrast, a mutable data type, such as Counter or Accumulator, manipulates object values that are intended to change. Java&#8217;s language support for helping to enforce immutability is the final modi&#64257; er. When you declare a variable to be final, you are promising to assign it a value only once, either in an initializer or in the constructor. Code that could modify the value of a final variable leads to a compile-time error. In our code, we use the modifier final with instance variables whose values never change. This policy serves as documentation that the value does not change, prevents accidental changes, and makes programs easier to debug. For example, you do not have to include a final value in a trace, since you know that its value never changes. A data type such as Date whose instance variables are all primitive and final is immutable (in code that does not use implementation inheritence, our convention). Whether to make a data type immutable is an important design decision and depends on the application at hand. For data types such as Date, the purpose of the abstraction is to encapsulate values that do not change so that we can use them in assignment statements and as arguments and return values from functions in the same way as we use primitive types (without having to worry about their values changing). A programmer implementing a Date client might reasonably expect to write the code d = d0 for two Date variables, in the same way as for double or int values. But if Date were mutable and the value of d were to change after the assignment d = d0, then the value of d0 would also change (they are both references to the same object)! On the other hand, for data types such as Counter and Accumulator, the very purpose of the abstraction is to encapsulate values as they change. You have already encountered this distinction as a client programmer, when using Java arrays (mutable) and Java&#8217;s String data type (immutable). When you pass a String to a method, you do not worry about that method changing the sequence of characters in the String, but when you pass an array to a method, the method is free to change the contents of the array. String objects are immutable because we generally do not want String values to change, and Java arrays are mutable because we generally do want array values to change. There are also situations where we want to have mutable strings (that is the purpose of Java&#8217;s StringBuilder class) and where we want to have immutable arrays (that is the purpose of the Vector class that we consider later in this section). Generally, immutable types are easier to use and harder to misuse than mutable types because the scope of code that can change their values is far smaller. It is easier to debug code that uses immutable types because it is easier to guarantee that variables in client code that uses them remain in a consistent state. When using mutable types,</p><p attribs="{'xml:space': 'preserve'}" id="_01630" smilref="Title.smil#_01630"> Java arrays</p><p attribs="{'xml:space': 'preserve'}" id="_01631" smilref="Title.smil#_01631"> Counter</p><p attribs="{'xml:space': 'preserve'}" id="_01632" smilref="Title.smil#_01632"> Date</p><p attribs="{'xml:space': 'preserve'}" id="_01633" smilref="Title.smil#_01633"> String</p><p attribs="{'xml:space': 'preserve'}" id="_01634" smilref="Title.smil#_01634"> mutable</p><p attribs="{'xml:space': 'preserve'}" id="_01635" smilref="Title.smil#_01635"> immutable</p><p attribs="{'xml:space': 'preserve'}" id="_01636" smilref="Title.smil#_01636"> Mutable/immutable examples</p><p attribs="{'xml:space': 'preserve'}" id="_01637" smilref="Title.smil#_01637" /><pagenum id="p119" page="normal" smilref="Title.smil#p119" /><p attribs="{'xml:space': 'preserve'}" id="_01638" smilref="Title.smil#_01638"> 106</p><p attribs="{'xml:space': 'preserve'}" id="_01639" smilref="Title.smil#_01639"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01640" smilref="Title.smil#_01640"> you must always be concerned about where and when their values change. The downside of immutability is that a new object must be created for every value. This expense is normally manageable because Java garbage collectors are typically optimized for such situations. Another downside of immutability stems from the fact that, unfortunately, final guarantees immutability only when instance variables are primitive types, not reference types. If an instance variable of a reference type has the final modi&#64257; er, the value of that instance variable (the reference to an object) will never change&#8212;it will always refer to the same object&#8212;but the value of the object itself can change. For ex- ample, this code does not implement an immutable type:</p><p attribs="{'xml:space': 'preserve'}" id="_01641" smilref="Title.smil#_01641"> public class Vector { private final double[] coords;</p><p attribs="{'xml:space': 'preserve'}" id="_01642" smilref="Title.smil#_01642"> public Vector(double[] a) { coords = a; } ... }</p><p attribs="{'xml:space': 'preserve'}" id="_01643" smilref="Title.smil#_01643"> A client program could create a Vector by specifying the entries in an array, and then (bypassing the API) change the elements of the Vector after construction:</p><p attribs="{'xml:space': 'preserve'}" id="_01644" smilref="Title.smil#_01644"> double[] a = { 3.0, 4.0 }; Vector vector = new Vector(a); a[0] = 0.0; // Bypasses the public API.</p><p attribs="{'xml:space': 'preserve'}" id="_01645" smilref="Title.smil#_01645"> The instance variable coords[] is private and final, but Vector is mutable because the client holds a reference to the data. Immutability needs to be taken into account in any data-type design, and whether a data type is immutable should be specified in the API, so that clients know that object values will not change. In this book, our primary interest in immutability is for use in certifying the correctness of our algorithms. For example, if the type of data used for a binary search algorithm were mutable, then clients could invalidate our assumption that the array is sorted for binary search.</p><p attribs="{'xml:space': 'preserve'}" id="_01646" smilref="Title.smil#_01646" /><pagenum id="p120" page="normal" smilref="Title.smil#p120" /><p attribs="{'xml:space': 'preserve'}" id="_01647" smilref="Title.smil#_01647"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01648" smilref="Title.smil#_01648"> 107</p><p attribs="{'xml:space': 'preserve'}" id="_01649" smilref="Title.smil#_01649"> Design by contract. To conclude, we briefly discuss Java language mechanisms that enables you to verify assumptions about your program as it is running. We use two Java language mechanisms for this purpose: </p><p attribs="{'xml:space': 'preserve'}" id="_01650" smilref="Title.smil#_01650"> Exceptions and errors. Exceptions and errors are disruptive events that occur while a program is running, often to signal an error. The action taken is known as throwing an exception or throwing an error. We have already encountered exceptions thrown by Java system methods in the course of learning basic features of Java: StackOverflowError,</p><p attribs="{'xml:space': 'preserve'}" id="_01651" smilref="Title.smil#_01651"> ArithmeticException,</p><p attribs="{'xml:space': 'preserve'}" id="_01652" smilref="Title.smil#_01652"> ArrayIndexOutOfBoundsException,</p><p attribs="{'xml:space': 'preserve'}" id="_01653" smilref="Title.smil#_01653"> OutOfMemoryError,</p><p attribs="{'xml:space': 'preserve'}" id="_01654" smilref="Title.smil#_01654"> and NullPointerException are typical examples. You can also create your own ex- ceptions. The simplest kind is a RuntimeException that terminates execution of the program and prints an error message</p><p attribs="{'xml:space': 'preserve'}" id="_01655" smilref="Title.smil#_01655"> throw new RuntimeException("Error message here.");</p><p attribs="{'xml:space': 'preserve'}" id="_01656" smilref="Title.smil#_01656"> A general practice known as fail fast programming suggests that an error is more easily pinpointed if an exception is thrown as soon as an error is discovered (as opposed to ignoring the error and deferring the exception to sometime in the future). Assertions. An assertion is a boolean expression that you are affirming is true at that point in the program. If the expression is false, the program will terminate and report an error message. We use assertions both to gain confidence in the correctness of programs and to document intent. For example, suppose that you have a computed value that you might use to index into an array. If this value were negative, it would cause an ArrayIndexOutOfBoundsException sometime later. But if you write the code assert index &gt;= 0; you can pinpoint the place where the error occurred. You can also add an optional detail message such as</p><p attribs="{'xml:space': 'preserve'}" id="_01657" smilref="Title.smil#_01657"> assert index &gt;= 0 : "Negative index in method X";</p><p attribs="{'xml:space': 'preserve'}" id="_01658" smilref="Title.smil#_01658"> to help you locate the bug. By default, assertions are disabled. You can enable them from the command line by using the -enableassertions flag (-ea for short). Assertions are for debugging: your program should not rely on assertions for normal operation since they may be disabled. When you take a course in systems programming, you will learn</p><p attribs="{'xml:space': 'preserve'}" id="_01659" smilref="Title.smil#_01659" /><pagenum id="p121" page="normal" smilref="Title.smil#p121" /><p attribs="{'xml:space': 'preserve'}" id="_01660" smilref="Title.smil#_01660"> 108</p><p attribs="{'xml:space': 'preserve'}" id="_01661" smilref="Title.smil#_01661"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01662" smilref="Title.smil#_01662"> to use assertions to ensure that your code never terminates in a system error or goes into an infinite loop. One model, known as the design-by-contract model of programming expresses the idea. The designer of a data type expresses a precondition (the condition that the client promises to satisfy when calling a method), a postcondition (the condition that the implementation promises to achieve when returning from a method), and side effects (any other change in state that the method could cause). During develop- ment, these conditions can be tested with assertions.</p><p attribs="{'xml:space': 'preserve'}" id="_01663" smilref="Title.smil#_01663"> Summary. The language mechanisms discussed throughout this section illustrate that effective data-type design leads to nontrivial issues that are not easy to resolve. Ex- perts are still debating the best ways to support some of the design ideas that we are discussing. Why does Java not allow functions as arguments? Why does Matlab copy arrays passed as arguments to functions? As mentioned early in Chapter 1, it is a slippery slope from complaining about features in a programming language to becoming a programming-language designer. If you do not plan to do so, your best strategy is to use widely available languages. Most systems have extensive libraries that you certainly should use when appropriate, but you often can simplify your client code and protect yourself by building abstractions that can easily transport to other languages. Your main goal is to develop data types so that most of your work is done at a level of abstraction that is appropriate to the problem at hand. The table on the facing page summarizes the various kinds of Java classes that we have considered.</p><p attribs="{'xml:space': 'preserve'}" id="_01664" smilref="Title.smil#_01664" /><pagenum id="p122" page="normal" smilref="Title.smil#p122" /><p attribs="{'xml:space': 'preserve'}" id="_01665" smilref="Title.smil#_01665"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01666" smilref="Title.smil#_01666"> 109</p><p attribs="{'xml:space': 'preserve'}" id="_01667" smilref="Title.smil#_01667"> kind of class</p><p attribs="{'xml:space': 'preserve'}" id="_01668" smilref="Title.smil#_01668"> examples</p><p attribs="{'xml:space': 'preserve'}" id="_01669" smilref="Title.smil#_01669"> characteristics</p><p attribs="{'xml:space': 'preserve'}" id="_01670" smilref="Title.smil#_01670"> static methods</p><p attribs="{'xml:space': 'preserve'}" id="_01671" smilref="Title.smil#_01671"> Math StdIn StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_01672" smilref="Title.smil#_01672"> no instance variables</p><p attribs="{'xml:space': 'preserve'}" id="_01673" smilref="Title.smil#_01673"> immutable abstract data type</p><p attribs="{'xml:space': 'preserve'}" id="_01674" smilref="Title.smil#_01674"> Date Transaction String Integer</p><p attribs="{'xml:space': 'preserve'}" id="_01675" smilref="Title.smil#_01675"> instance variables all private instance variables all final defensive copy for reference types</p><p attribs="{'xml:space': 'preserve'}" id="_01676" smilref="Title.smil#_01676"> Note: these are necessary but not suf&#64257; cient.</p><p attribs="{'xml:space': 'preserve'}" id="_01677" smilref="Title.smil#_01677"> mutable abstract data type</p><p attribs="{'xml:space': 'preserve'}" id="_01678" smilref="Title.smil#_01678"> Counter Accumulator</p><p attribs="{'xml:space': 'preserve'}" id="_01679" smilref="Title.smil#_01679"> instance variables all private not all instance variables final</p><p attribs="{'xml:space': 'preserve'}" id="_01680" smilref="Title.smil#_01680"> abstract data type with I/O side eff ects</p><p attribs="{'xml:space': 'preserve'}" id="_01681" smilref="Title.smil#_01681"> VisualAccumulator In Out Draw</p><p attribs="{'xml:space': 'preserve'}" id="_01682" smilref="Title.smil#_01682"> instance variables all private instance methods do I/O</p><p attribs="{'xml:space': 'preserve'}" id="_01683" smilref="Title.smil#_01683"> Java classes (data-type implementations)</p><p attribs="{'xml:space': 'preserve'}" id="_01684" smilref="Title.smil#_01684" /><pagenum id="p123" page="normal" smilref="Title.smil#p123" /><p attribs="{'xml:space': 'preserve'}" id="_01685" smilref="Title.smil#_01685"> 110</p><p attribs="{'xml:space': 'preserve'}" id="_01686" smilref="Title.smil#_01686"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01687" smilref="Title.smil#_01687"> Q &amp; A</p><p attribs="{'xml:space': 'preserve'}" id="_01688" smilref="Title.smil#_01688"> Q. Why bother with data abstraction? A. It helps us produce reliable and correct code. For example, in the 2000 presidential election, Al Gore received &#8211;16,022 votes on an electronic voting machine in Volusia County, Florida&#8212;the tally was clearly not properly encapsulated in the voting machine software! Q. Why the distinction between primitive and reference types? Why not just have reference types? A. Performance. Java provides the reference types Integer, Double, and so forth that correspond to primitive types that can be used by programmers who prefer to ignore the distinction. Primitive types are closer to the types of data that are supported by computer hardware, so programs that use them usually run faster than programs that use corresponding reference types. Q. Do data types have to be abstract? A. No. Java also allows public and protected to allow some clients to refer directly to instance variables. As described in the text, the advantages of allowing client code to directly refer to data are greatly outweighed by the disadvantages of dependence on a particular representation, so all instance variables are private in our code. We also occasionally use private instance methods to share code among public methods. Q. What happens if I forget to use new when creating an object? A. To Java, it looks as though you want to call a static method with a return value of the object type. Since you have not defined such a method, the error message is the same as anytime you refer to an undefined symbol. If you compile the code</p><p attribs="{'xml:space': 'preserve'}" id="_01689" smilref="Title.smil#_01689"> Counter c = Counter("test");</p><p attribs="{'xml:space': 'preserve'}" id="_01690" smilref="Title.smil#_01690"> you get this error message:</p><p attribs="{'xml:space': 'preserve'}" id="_01691" smilref="Title.smil#_01691"> cannot find symbol symbol : method Counter(String)</p><p attribs="{'xml:space': 'preserve'}" id="_01692" smilref="Title.smil#_01692"> You get the same kind of error message if you provide the wrong number of arguments to a constructor.</p><p attribs="{'xml:space': 'preserve'}" id="_01693" smilref="Title.smil#_01693" /><pagenum id="p124" page="normal" smilref="Title.smil#p124" /><p attribs="{'xml:space': 'preserve'}" id="_01694" smilref="Title.smil#_01694"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01695" smilref="Title.smil#_01695"> 111</p><p attribs="{'xml:space': 'preserve'}" id="_01696" smilref="Title.smil#_01696"> Q. What happens if I forget to use new when creating an array of objects? A. You need to use new for each object that you create, so when you create an array of N objects, you need to use new N+1 times: once for the array and once for each of the objects. If you forget to create the array :</p><p attribs="{'xml:space': 'preserve'}" id="_01697" smilref="Title.smil#_01697"> Counter[] a; a[0] = new Counter("test");</p><p attribs="{'xml:space': 'preserve'}" id="_01698" smilref="Title.smil#_01698"> you get the same error message that you would get when trying to assign a value to any uninitialized variable:</p><p attribs="{'xml:space': 'preserve'}" id="_01699" smilref="Title.smil#_01699"> variable a might not have been initialized a[0] = new Counter("test"); ^</p><p attribs="{'xml:space': 'preserve'}" id="_01700" smilref="Title.smil#_01700"> but if you forget to use new when creating an object within the array and then try to use it to invoke a method:</p><p attribs="{'xml:space': 'preserve'}" id="_01701" smilref="Title.smil#_01701"> Counter[] a = new Counter[2]; a[0].increment();</p><p attribs="{'xml:space': 'preserve'}" id="_01702" smilref="Title.smil#_01702"> you get a NullPointerException.</p><p attribs="{'xml:space': 'preserve'}" id="_01703" smilref="Title.smil#_01703"> Q. Why not write StdOut.println(x.toString()) to print objects? A. That code works fi ne, but Java saves us the trouble of writing it by automatically invoking the toString() method for any object, since println() has a method that takes an Object as argument. Q. What is a pointer ? A. Good question. Perhaps that should be NullReferenceException. Like a Java ref- erence, you can think of a pointer as a machine address. In many programming lan- guages, the pointer is a primitive data type that programmers can manipulate in many ways. But programming with pointers is notoriously error-prone, so operations provided for pointers need to be carefully designed to help programmers avoid errors. Java takes this point of view to an extreme (that is favored by many modern program- ming-language designers). In Java, there is only one way to create a reference (new) and only one way to change a reference (with an assignment statement). That is, the only things that a programmer can do with references are to create them and copy them. In</p><p attribs="{'xml:space': 'preserve'}" id="_01704" smilref="Title.smil#_01704" /><pagenum id="p125" page="normal" smilref="Title.smil#p125" /><p attribs="{'xml:space': 'preserve'}" id="_01705" smilref="Title.smil#_01705"> 112</p><p attribs="{'xml:space': 'preserve'}" id="_01706" smilref="Title.smil#_01706"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01707" smilref="Title.smil#_01707"> Q &amp; A (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_01708" smilref="Title.smil#_01708"> programming-language jargon, Java references are known as safe pointers, because Java can guarantee that each reference points to an object of the specified type (and it can determine which objects are not in use, for garbage collection). Programmers used to writing code that directly manipulates pointers think of Java as having no pointers at all, but people still debate whether it is really desirable to have unsafe pointers. Q. Where can I find more details on how Java implements references and does garbage collection? A. One Java system might differ completely from another. For example, one natural scheme is to use a pointer (machine address); another is to use a handle (a pointer to a pointer). The former gives faster access to data; the latter provides for better garbage collection. Q. What exactly does it mean to import a name? A. Not much: it just saves some typing. You could type java.util.Arrays instead of Arrays everywhere in your code instead of using the import statement. Q. What is the problem with implementation inheritance? A. Subtyping makes modular programming more difficult for two reasons. First, any change in the superclass affects all subclasses. The subclass cannot be developed independently of the superclass; indeed, it is completely dependent on the superclass. This problem is known as the fragile base class problem. Second, the subclass code, having access to instance variables, can subvert the intention of the superclass code. For example, the designer of a class like Counter for a voting system may take great care to make it so that Counter can only increment the tally by one (remember Al Gore&#8217;s problem). But a subclass, with full access to the instance variable, can change it to any value whatever. Q. How do I make a class immutable? A. To ensure immutability of a data type that includes an instance variable of a mutable type, we need to make a local copy, known as a defensive copy. And that may not be enough. Making the copy is one challenge; ensuring that none of the instance methods change values is another. Q. What is null?</p><p attribs="{'xml:space': 'preserve'}" id="_01709" smilref="Title.smil#_01709" /><pagenum id="p126" page="normal" smilref="Title.smil#p126" /><p attribs="{'xml:space': 'preserve'}" id="_01710" smilref="Title.smil#_01710"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01711" smilref="Title.smil#_01711"> 113</p><p attribs="{'xml:space': 'preserve'}" id="_01712" smilref="Title.smil#_01712"> A. It is a literal value that refers to no object. Invoking a method using the null reference is meaningless and results in a NullPointerException. If you get this error message, check to make sure that your constructor properly initializes all of its instance variables. Q. Can I have a static method in a class that implements a data type? A. Of course. For example, all of our classes have main(). Also, it is natural to consider adding static methods for operations that involve multiple objects where none of them naturally suggests itself as the one that should invoke the method. For example, we might define a static method like the following within Point:</p><p attribs="{'xml:space': 'preserve'}" id="_01713" smilref="Title.smil#_01713"> public static double distance(Point a, Point b) { return a.distTo(b); }</p><p attribs="{'xml:space': 'preserve'}" id="_01714" smilref="Title.smil#_01714"> Often, including such methods can serve to clarify client code.</p><p attribs="{'xml:space': 'preserve'}" id="_01715" smilref="Title.smil#_01715"> Q. Are there other kinds of variables besides parameter, local, and instance variables? A. If you include the keyword static in a class declaration (outside of any type) it creates a completely different type of variable, known as a static variable. Like instance variables, static variables are accessible to every method in the class; however, they are not associated with any object. In older programming languages, such variables are known as global variables, because of their global scope. In modern programming, we focus on limiting scope and therefore rarely use such variables. When we do, we will call attention to them. Q. What is a deprecated method? A. A method that is no longer fully supported, but kept in an API to maintain compat- ibility. For example, Java once included a method Character.isSpace(), and programmers wrote programs that relied on using that method&#8217;s behavior. When the designers of Java later wanted to support additional Unicode whitespace characters, they could not change the behavior of isSpace() without breaking client programs, so, instead, they added a new method, Character.isWhiteSpace(), and deprecated the old method. As time wears on, this practice certainly complicates APIs. Sometimes, entire classes are deprecated. For example, Java deprecated its java.util.Date in order to better support internationalization.</p><p attribs="{'xml:space': 'preserve'}" id="_01716" smilref="Title.smil#_01716" /><pagenum id="p127" page="normal" smilref="Title.smil#p127" /><p attribs="{'xml:space': 'preserve'}" id="_01717" smilref="Title.smil#_01717"> 114</p><p attribs="{'xml:space': 'preserve'}" id="_01718" smilref="Title.smil#_01718"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01719" smilref="Title.smil#_01719"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_01720" smilref="Title.smil#_01720"> 1.2.1 Write a Point2D client that takes an integer value N from the command line, generates N random points in the unit square, and computes the distance separating the closest pair of points. 1.2.2 Write an Interval1D client that takes an int value N as command-line argu- ment, reads N intervals (each defined by a pair of double values) from standard input, and prints all pairs that intersect. 1.2.3 Write an Interval2D client that takes command-line arguments N, min, and max and generates N random 2D intervals whose width and height are uniformly distributed between min and max in the unit square. Draw them on StdDraw and print the number of pairs of intervals that intersect and the number of intervals that are contained in one another. 1.2.4 What does the following code fragment print?</p><p attribs="{'xml:space': 'preserve'}" id="_01721" smilref="Title.smil#_01721"> String string1 = "hello"; String string2 = string1; string1 = "world"; StdOut.println(string1); StdOut.println(string2);</p><p attribs="{'xml:space': 'preserve'}" id="_01722" smilref="Title.smil#_01722"> 1.2.5 What does the following code fragment print?</p><p attribs="{'xml:space': 'preserve'}" id="_01723" smilref="Title.smil#_01723"> String s = "Hello World"; s.toUpperCase(); s.substring(6, 11); StdOut.println(s);</p><p attribs="{'xml:space': 'preserve'}" id="_01724" smilref="Title.smil#_01724"> Answer : "Hello World". String objects are immutable&#8212;string methods return a new String object with the appropriate value (but they do not change the value of the object that was used to invoke them). This code ignores the objects returned and just prints the original string. To print "WORLD", use s = s.toUpperCase() and</p><p attribs="{'xml:space': 'preserve'}" id="_01725" smilref="Title.smil#_01725"> s = s.substring(6, 11).</p><p attribs="{'xml:space': 'preserve'}" id="_01726" smilref="Title.smil#_01726"> 1.2.6 A string s is a circular rotation of a string t if it matches when the characters are circularly shifted by any number of positions; e.g., ACTGACG is a circular shift of TGACGAC, and vice versa. Detecting this condition is important in the study of genomic sequences. Write a program that checks whether two given strings s and t are circular</p><p attribs="{'xml:space': 'preserve'}" id="_01727" smilref="Title.smil#_01727" /><pagenum id="p128" page="normal" smilref="Title.smil#p128" /><p attribs="{'xml:space': 'preserve'}" id="_01728" smilref="Title.smil#_01728"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01729" smilref="Title.smil#_01729"> 115</p><p attribs="{'xml:space': 'preserve'}" id="_01730" smilref="Title.smil#_01730"> shifts of one another. Hint : The solution is a one-liner with indexOf(), length(), and string concatenation. 1.2.7 What does the following recursive function return?</p><p attribs="{'xml:space': 'preserve'}" id="_01731" smilref="Title.smil#_01731"> public static String mystery(String s) { int N = s.length(); if (N &lt;= 1) return s; String a = s.substring(0, N/2); String b = s.substring(N/2, N); return mystery(b) + mystery(a); }</p><p attribs="{'xml:space': 'preserve'}" id="_01732" smilref="Title.smil#_01732"> 1.2.8 Suppose that a[] and b[] are each integer arrays consisting of millions of inte- gers. What does the follow code do? Is it reasonably ef&#64257; cient?</p><p attribs="{'xml:space': 'preserve'}" id="_01733" smilref="Title.smil#_01733"> int[] t = a; a = b; b = t;</p><p attribs="{'xml:space': 'preserve'}" id="_01734" smilref="Title.smil#_01734"> Answer. It swaps them. It could hardly be more efficient because it does so by copying references, so that it is not necessary to copy millions of elements.</p><p attribs="{'xml:space': 'preserve'}" id="_01735" smilref="Title.smil#_01735"> 1.2.9 Instrument BinarySearch (page 47) to use a Counter to count the total number of keys examined during all searches and then print the total after all searches are com- plete. Hint : Create a Counter in main() and pass it as an argument to rank(). 1.2.10 Develop a class VisualCounter that allows both increment and decrement operations. Take two arguments N and max in the constructor, where N specifies the maximum number of operations and max specifies the maximum absolute value for the counter. As a side effect, create a plot showing the value of the counter each time its tally changes. 1.2.11 Develop an implementation SmartDate of our Date API that raises an exception if the date is not legal. 1.2.12 Add a method dayOfTheWeek() to SmartDate that returns a String value</p><p attribs="{'xml:space': 'preserve'}" id="_01736" smilref="Title.smil#_01736"> Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, or Sunday, giving the ap-</p><p attribs="{'xml:space': 'preserve'}" id="_01737" smilref="Title.smil#_01737"> propriate day of the week for the date. You may assume that the date is in the 21st century.</p><p attribs="{'xml:space': 'preserve'}" id="_01738" smilref="Title.smil#_01738" /><pagenum id="p129" page="normal" smilref="Title.smil#p129" /><p attribs="{'xml:space': 'preserve'}" id="_01739" smilref="Title.smil#_01739"> 116</p><p attribs="{'xml:space': 'preserve'}" id="_01740" smilref="Title.smil#_01740"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01741" smilref="Title.smil#_01741"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_01742" smilref="Title.smil#_01742"> 1.2.13 Using our implementation of Date as a model (page 91), develop an implementa-</p><p attribs="{'xml:space': 'preserve'}" id="_01743" smilref="Title.smil#_01743"> tion of Transaction.</p><p attribs="{'xml:space': 'preserve'}" id="_01744" smilref="Title.smil#_01744"> 1.2.14 Using our implementation of equals() in Date as a model (page 103), develop an implementation of equals() for Transaction.</p><p attribs="{'xml:space': 'preserve'}" id="_01745" smilref="Title.smil#_01745" /><pagenum id="p130" page="normal" smilref="Title.smil#p130" /><p attribs="{'xml:space': 'preserve'}" id="_01746" smilref="Title.smil#_01746"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01747" smilref="Title.smil#_01747"> 117</p><p attribs="{'xml:space': 'preserve'}" id="_01748" smilref="Title.smil#_01748"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_01749" smilref="Title.smil#_01749"> 1.2.15 File input. Develop a possible implementation of the static readInts() method from In (which we use for various test clients, such as binary search on page 47) that is based on the split() method in String.</p><p attribs="{'xml:space': 'preserve'}" id="_01750" smilref="Title.smil#_01750"> Solution:</p><p attribs="{'xml:space': 'preserve'}" id="_01751" smilref="Title.smil#_01751"> public static int[] readInts(String name) { In in = new In(name); String input = StdIn.readAll(); String[] words = input.split("\\s+"); int[] ints = new int[words.length]; for int i = 0; i &lt; word.length; i++) ints[i] = Integer.parseInt(words[i]); return ints; }</p><p attribs="{'xml:space': 'preserve'}" id="_01752" smilref="Title.smil#_01752"> We will consider a different implementation in Section 1.3 (see page 126). 1.2.16 Rational numbers. Implement an immutable data type Rational for rational numbers that supports addition, subtraction, multiplication, and division.</p><p attribs="{'xml:space': 'preserve'}" id="_01753" smilref="Title.smil#_01753"> public class Rational</p><p attribs="{'xml:space': 'preserve'}" id="_01754" smilref="Title.smil#_01754"> Rational(int numerator, int denominator)</p><p attribs="{'xml:space': 'preserve'}" id="_01755" smilref="Title.smil#_01755"> Rational plus(Rational b)</p><p attribs="{'xml:space': 'preserve'}" id="_01756" smilref="Title.smil#_01756"> sum of this number and b</p><p attribs="{'xml:space': 'preserve'}" id="_01757" smilref="Title.smil#_01757"> Rational minus(Rational b)</p><p attribs="{'xml:space': 'preserve'}" id="_01758" smilref="Title.smil#_01758"> difference of this number and b</p><p attribs="{'xml:space': 'preserve'}" id="_01759" smilref="Title.smil#_01759"> Rational times(Rational b)</p><p attribs="{'xml:space': 'preserve'}" id="_01760" smilref="Title.smil#_01760"> product of this number and b</p><p attribs="{'xml:space': 'preserve'}" id="_01761" smilref="Title.smil#_01761"> Rational divides(Rational b)</p><p attribs="{'xml:space': 'preserve'}" id="_01762" smilref="Title.smil#_01762"> boolean equals(Rational that)</p><p attribs="{'xml:space': 'preserve'}" id="_01763" smilref="Title.smil#_01763"> quotient of this number and b is this number equal to that ?</p><p attribs="{'xml:space': 'preserve'}" id="_01764" smilref="Title.smil#_01764"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_01765" smilref="Title.smil#_01765"> string representation</p><p attribs="{'xml:space': 'preserve'}" id="_01766" smilref="Title.smil#_01766"> You do not have to worry about testing for overflow (see Exercise 1.2.17), but use as instance variables two long values that represent the numerator and denominator to limit the possibility of over&#64258; ow. Use Euclid&#8217;s algorithm (see page 4) to ensure that the numerator and denominator never have any common factors. Include a test client that exercises all of your methods.</p><p attribs="{'xml:space': 'preserve'}" id="_01767" smilref="Title.smil#_01767" /><pagenum id="p131" page="normal" smilref="Title.smil#p131" /><p attribs="{'xml:space': 'preserve'}" id="_01768" smilref="Title.smil#_01768"> 118</p><p attribs="{'xml:space': 'preserve'}" id="_01769" smilref="Title.smil#_01769"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01770" smilref="Title.smil#_01770"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_01771" smilref="Title.smil#_01771"> 1.2.17 Robust implementation of rational numbers. Use assertions to develop an implementation of Rational (see Exercise 1.2.16) that is immune to over&#64258; ow. 1.2.18 Variance for accumulator. Validate that the following code, which adds the methods var() and stddev() to Accumulator, computes both the mean and variance of the numbers presented as arguments to addDataValue():</p><p attribs="{'xml:space': 'preserve'}" id="_01772" smilref="Title.smil#_01772"> public class Accumulator { private double m; private double s; private int N;</p><p attribs="{'xml:space': 'preserve'}" id="_01773" smilref="Title.smil#_01773"> public void addDataValue(double x) { N++; s = s + 1.0 * (N-1) / N * (x - m) * (x - m); m = m + (x - m) / N; }</p><p attribs="{'xml:space': 'preserve'}" id="_01774" smilref="Title.smil#_01774"> public double mean() { return m; }</p><p attribs="{'xml:space': 'preserve'}" id="_01775" smilref="Title.smil#_01775"> public double var() { return s/(N - 1); }</p><p attribs="{'xml:space': 'preserve'}" id="_01776" smilref="Title.smil#_01776"> public double stddev() { return Math.sqrt(this.var()); }</p><p attribs="{'xml:space': 'preserve'}" id="_01777" smilref="Title.smil#_01777"> }</p><p attribs="{'xml:space': 'preserve'}" id="_01778" smilref="Title.smil#_01778"> This implementation is less susceptible to roundoff error than the straightforward implementation based on saving the sum of the squares of the numbers.</p><p attribs="{'xml:space': 'preserve'}" id="_01779" smilref="Title.smil#_01779" /><pagenum id="p132" page="normal" smilref="Title.smil#p132" /><p attribs="{'xml:space': 'preserve'}" id="_01780" smilref="Title.smil#_01780"> 1.2 </p><p attribs="{'xml:space': 'preserve'}" id="_01781" smilref="Title.smil#_01781"> 119</p><p attribs="{'xml:space': 'preserve'}" id="_01782" smilref="Title.smil#_01782"> 1.2.19 Parsing. Develop the parse constructors for your Date and Transaction implementations of Exercise 1.2.13 that take a single String argument to specify the initialization values, using the formats given in the table below.</p><p attribs="{'xml:space': 'preserve'}" id="_01783" smilref="Title.smil#_01783"> Partial solution:</p><p attribs="{'xml:space': 'preserve'}" id="_01784" smilref="Title.smil#_01784"> public Date(String date) { String[] fields = date.split("/"); month = Integer.parseInt(fields[0]); day = Integer.parseInt(fields[1]); year = Integer.parseInt(fields[2]); }</p><p attribs="{'xml:space': 'preserve'}" id="_01785" smilref="Title.smil#_01785"> type</p><p attribs="{'xml:space': 'preserve'}" id="_01786" smilref="Title.smil#_01786"> Date</p><p attribs="{'xml:space': 'preserve'}" id="_01787" smilref="Title.smil#_01787"> format</p><p attribs="{'xml:space': 'preserve'}" id="_01788" smilref="Title.smil#_01788"> integers separated by slashes</p><p attribs="{'xml:space': 'preserve'}" id="_01789" smilref="Title.smil#_01789"> example</p><p attribs="{'xml:space': 'preserve'}" id="_01790" smilref="Title.smil#_01790"> 5/22/1939</p><p attribs="{'xml:space': 'preserve'}" id="_01791" smilref="Title.smil#_01791"> Transaction customer, date, and amount, separated by whitespace</p><p attribs="{'xml:space': 'preserve'}" id="_01792" smilref="Title.smil#_01792"> Turing 5/22/1939 11.99</p><p attribs="{'xml:space': 'preserve'}" id="_01793" smilref="Title.smil#_01793"> Formats for parsing</p><p attribs="{'xml:space': 'preserve'}" id="_01794" smilref="Title.smil#_01794" /></level3><level3 id="_00013"><h3 id="ch1-s3-ss14" smilref="Title.smil#ch1-s3-ss14" xml:space="preserve">APIs</h3><pagenum id="p134" page="normal" smilref="Title.smil#p134" /><p attribs="{'xml:space': 'preserve'}" id="_01795" smilref="Title.smil#_01795"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01796" smilref="Title.smil#_01796"> 121</p><p attribs="{'xml:space': 'preserve'}" id="_01797" smilref="Title.smil#_01797"> APIs As usual, we begin our discussion of abstract data types for collections by defining their APIs, shown below. Each contains a no-argument constructor, a method to add an item to the collection, a method to test whether the collection is empty, and a method that returns the size of the collection. Stack and Queue each have a method to remove a particular item from the collection. Beyond these basics, these APIs reflect two Java features that we will describe on the next few pages: generics and iterable collections.</p><p attribs="{'xml:space': 'preserve'}" id="_01798" smilref="Title.smil#_01798"> Bag</p><p attribs="{'xml:space': 'preserve'}" id="_01799" smilref="Title.smil#_01799"> public class Bag&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_01800" smilref="Title.smil#_01800"> Bag() void add(Item item) boolean isEmpty() int size()</p><p attribs="{'xml:space': 'preserve'}" id="_01801" smilref="Title.smil#_01801"> create an empty bag add an item is the bag empty? number of items in the bag</p><p attribs="{'xml:space': 'preserve'}" id="_01802" smilref="Title.smil#_01802"> FIFO queue</p><p attribs="{'xml:space': 'preserve'}" id="_01803" smilref="Title.smil#_01803"> public class Queue&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_01804" smilref="Title.smil#_01804"> Queue() void enqueue(Item item) Item dequeue() boolean isEmpty() int size()</p><p attribs="{'xml:space': 'preserve'}" id="_01805" smilref="Title.smil#_01805"> create an empty queue add an item remove the least recently added item is the queue empty? number of items in the queue</p><p attribs="{'xml:space': 'preserve'}" id="_01806" smilref="Title.smil#_01806"> Pushdown (LIFO) stack</p><p attribs="{'xml:space': 'preserve'}" id="_01807" smilref="Title.smil#_01807"> public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_01808" smilref="Title.smil#_01808"> Stack() void push(Item item) Item pop() boolean isEmpty() int size()</p><p attribs="{'xml:space': 'preserve'}" id="_01809" smilref="Title.smil#_01809"> create an empty stack add an item remove the most recently added item is the stack empty? number of items in the stack</p><p attribs="{'xml:space': 'preserve'}" id="_01810" smilref="Title.smil#_01810"> APIs for fundamental generic iterable collections</p><p attribs="{'xml:space': 'preserve'}" id="_01811" smilref="Title.smil#_01811" /><pagenum id="p135" page="normal" smilref="Title.smil#p135" /><p attribs="{'xml:space': 'preserve'}" id="_01812" smilref="Title.smil#_01812"> 122</p><p attribs="{'xml:space': 'preserve'}" id="_01813" smilref="Title.smil#_01813"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01814" smilref="Title.smil#_01814"> Generics. An essential characteristic of collection ADTs is that we should be able to use them for any type of data. A specific Java mechanism known as generics, also known as parameterized types, enables this capability. The impact of generics on the programming language is sufficiently deep that they are not found in many languages (including early versions of Java), but our use of them in the present context involves just a small bit of extra Java syntax and is easy to understand. The notation &lt;Item&gt; after the class name in each of our APIs defines the name Item as a type parameter, a symbolic placeholder for some concrete type to be used by the client. You can read Stack&lt;Item&gt; as &#8220;stack of items.&#8221; When implementing Stack, we do not know the concrete type of Item, but a client can use our stack for any type of data, including one defined long after we develop our implementation. The client code provides a concrete type when the stack is created: we can replace Item with the name of any reference data type (consistently, everywhere it appears). This provides exactly the capability that we need. For example, you can write code such as</p><p attribs="{'xml:space': 'preserve'}" id="_01815" smilref="Title.smil#_01815"> Stack&lt;String&gt; stack = new Stack&lt;String&gt;(); stack.push("Test"); ... String next = stack.pop();</p><p attribs="{'xml:space': 'preserve'}" id="_01816" smilref="Title.smil#_01816"> to use a stack for String objects and code such as</p><p attribs="{'xml:space': 'preserve'}" id="_01817" smilref="Title.smil#_01817"> Queue&lt;Date&gt; queue = new Queue&lt;Date&gt;(); queue.enqueue(new Date(12, 31, 1999)); ... Date next = queue.dequeue();</p><p attribs="{'xml:space': 'preserve'}" id="_01818" smilref="Title.smil#_01818"> to use a queue for Date objects. If you try to add a Date (or data of any other type than String) to stack or a String (or data of any other type than Date) to queue, you will get a compile-time error. Without generics, we would have to define (and implement) different APIs for each type of data we might need to collect; with generics, we can use one API (and one implementation) for all types of data, even types that are implemented in the future. As you will soon see, generic types lead to clear client code that is easy to understand and debug, so we use them throughout this book.</p><p attribs="{'xml:space': 'preserve'}" id="_01819" smilref="Title.smil#_01819"> Autoboxing. Type parameters have to be instantiated as reference types, so Java has special mechanisms to allow generic code to be used with primitive types. Recall that Java&#8217;s wrapper types are reference types that correspond to primitive types: Boolean,</p><p attribs="{'xml:space': 'preserve'}" id="_01820" smilref="Title.smil#_01820"> Byte, Character, Double, Float, Integer, Long, and Short correspond to boolean,</p><p attribs="{'xml:space': 'preserve'}" id="_01821" smilref="Title.smil#_01821"> byte, char, double, float, int, long, and short, respectively. Java automatically converts between these reference types and the corresponding primitive types&#8212;in assign- ments, method arguments, and arithmetic/logic expressions. In the present context,</p><p attribs="{'xml:space': 'preserve'}" id="_01822" smilref="Title.smil#_01822" /><pagenum id="p136" page="normal" smilref="Title.smil#p136" /><p attribs="{'xml:space': 'preserve'}" id="_01823" smilref="Title.smil#_01823"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01824" smilref="Title.smil#_01824"> 123</p><p attribs="{'xml:space': 'preserve'}" id="_01825" smilref="Title.smil#_01825"> this conversion is helpful because it enables us to use generics with primitive types, as in the following code:</p><p attribs="{'xml:space': 'preserve'}" id="_01826" smilref="Title.smil#_01826"> Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); stack.push(17); // auto-boxing (int -&gt; Integer) int i = stack.pop(); // auto-unboxing (Integer -&gt; int)</p><p attribs="{'xml:space': 'preserve'}" id="_01827" smilref="Title.smil#_01827"> Automatically casting a primitive type to a wrapper type is known as autoboxing, and automatically casting a wrapper type to a primitive type is known as auto-unboxing. In this example, Java automatically casts (autoboxes) the primitive value 17 to be of type Integer when we pass it to the push() method. The pop() method returns an Integer, which Java casts (auto-unboxes) to an int before assigning it to the variable i.</p><p attribs="{'xml:space': 'preserve'}" id="_01828" smilref="Title.smil#_01828"> Iterable collections. For many applications, the client&#8217;s requirement is just to process each of the items in some way, or to iterate through the items in the collection. This paradigm is so important that it has achieved fi rst-class status in Java and many other modern languages (the programming language itself has specific mechanisms to support it, not just the libraries). With it, we can write clear and compact code that is free from dependence on the details of a collection&#8217;s implementation. For example, suppose that a client maintains a collection of transactions in a Queue, as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_01829" smilref="Title.smil#_01829"> Queue&lt;Transaction&gt; collection = new Queue&lt;Transaction&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_01830" smilref="Title.smil#_01830"> If the collection is iterable, the client can print a transaction list with a single statement:</p><p attribs="{'xml:space': 'preserve'}" id="_01831" smilref="Title.smil#_01831"> for (Transaction t : collection) { StdOut.println(t); }</p><p attribs="{'xml:space': 'preserve'}" id="_01832" smilref="Title.smil#_01832"> This construct is known as the foreach statement: you can read the for statement as for each transaction t in the collection, execute the following block of code. This client code does not need to know anything about the representation or the implementation of the collection; it just wants to process each of the items in the collection. The same for loop would work with a Bag of transactions or any other iterable collection. We could hardly imagine client code that is more clear and compact. As you will see, supporting this capability requires extra effort in the implementation, but this effort is well worthwhile.</p><p attribs="{'xml:space': 'preserve'}" id="_01833" smilref="Title.smil#_01833"> It is interesting to note that the only differences between the APIs for Stack and Queue are their names and the names of the methods. This observation highlights the idea that we cannot easily specify all of the characteristics of a data type in a list of method signatures. In this case, the true specification has to do with the English-lan- guage descriptions that specify the rules by which an item is chosen to be removed (or to be processed next in the foreach statement). Differences in these rules are profound, part of the API, and certainly of critical importance in developing client code.</p><p attribs="{'xml:space': 'preserve'}" id="_01834" smilref="Title.smil#_01834" /><pagenum id="p137" page="normal" smilref="Title.smil#p137" /><p attribs="{'xml:space': 'preserve'}" id="_01835" smilref="Title.smil#_01835"> 124</p><p attribs="{'xml:space': 'preserve'}" id="_01836" smilref="Title.smil#_01836"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01837" smilref="Title.smil#_01837"> a bag of marbles</p><p attribs="{'xml:space': 'preserve'}" id="_01838" smilref="Title.smil#_01838"> Bags. A bag is a collection where removing items is not supported&#8212;its purpose is to provide clients with the ability to collect items and then to iterate through the collected items (the client can also test if a bag is empty and find its number of items). The order of iteration is unspecified and should be immaterial to the client. To appreciate the con- cept, consider the idea of an avid marble collector, who might put marbles in a bag, one at a time, and periodically process all the marbles to look for one having some particular characteristic. With our Bag API, a client can add items to a bag and process them all with a foreach statement whenever needed. Such a client could use a stack or a queue, but one way to emphasize that the order in which items are processed is immaterial is to use a Bag. The class Stats at right illustrates a typical Bag client. The task is simply to compute the average and the sample standard deviation of the double values on standard input. If there are N numbers on standard in- put, their average is computed by adding the numbers and dividing by N; their sample standard deviation is computed by adding the squares of the difference between each number and the average, dividing by N&#8211;1, and taking the square root. The order in which the numbers are considered is not relevant for either of these calculations, so we save them in a Bag and use the foreach construct to compute each sum. Note : It is possible to compute the standard deviation without saving all the numbers (as we did for the average in Accumulator&#8212;see Exercise 1.2.18). Keeping the all numbers in a Bag is required for more complicated statistics.</p><p attribs="{'xml:space': 'preserve'}" id="_01839" smilref="Title.smil#_01839"> for (Marble m : bag)</p><p attribs="{'xml:space': 'preserve'}" id="_01840" smilref="Title.smil#_01840"> add( )</p><p attribs="{'xml:space': 'preserve'}" id="_01841" smilref="Title.smil#_01841"> add( )</p><p attribs="{'xml:space': 'preserve'}" id="_01842" smilref="Title.smil#_01842"> process each marble m (in any order)</p><p attribs="{'xml:space': 'preserve'}" id="_01843" smilref="Title.smil#_01843"> Operations on a bag</p><p attribs="{'xml:space': 'preserve'}" id="_01844" smilref="Title.smil#_01844" /><pagenum id="p138" page="normal" smilref="Title.smil#p138" /><p attribs="{'xml:space': 'preserve'}" id="_01845" smilref="Title.smil#_01845"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01846" smilref="Title.smil#_01846"> 125</p><p attribs="{'xml:space': 'preserve'}" id="_01847" smilref="Title.smil#_01847"> typical Bag client</p><p attribs="{'xml:space': 'preserve'}" id="_01848" smilref="Title.smil#_01848"> public class Stats { public static void main(String[] args) { Bag&lt;Double&gt; numbers = new Bag&lt;Double&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_01849" smilref="Title.smil#_01849"> while (!StdIn.isEmpty()) numbers.add(StdIn.readDouble()); int N = numbers.size();</p><p attribs="{'xml:space': 'preserve'}" id="_01850" smilref="Title.smil#_01850"> double sum = 0.0; for (double x : numbers) sum += x; double mean = sum/N;</p><p attribs="{'xml:space': 'preserve'}" id="_01851" smilref="Title.smil#_01851"> sum = 0.0; for (double x : numbers) sum += (x - mean)*(x - mean); double std = Math.sqrt(sum/(N-1));</p><p attribs="{'xml:space': 'preserve'}" id="_01852" smilref="Title.smil#_01852"> StdOut.printf("Mean: %.2f\n", mean); StdOut.printf("Std dev: %.2f\n", std);</p><p attribs="{'xml:space': 'preserve'}" id="_01853" smilref="Title.smil#_01853"> application</p><p attribs="{'xml:space': 'preserve'}" id="_01854" smilref="Title.smil#_01854"> } }</p><p attribs="{'xml:space': 'preserve'}" id="_01855" smilref="Title.smil#_01855"> % java Stats 100 99 101 120 98 107 109 81 101 90</p><p attribs="{'xml:space': 'preserve'}" id="_01856" smilref="Title.smil#_01856"> Mean: 100.60 Std dev: 10.51</p><p attribs="{'xml:space': 'preserve'}" id="_01857" smilref="Title.smil#_01857" /><pagenum id="p139" page="normal" smilref="Title.smil#p139" /><p attribs="{'xml:space': 'preserve'}" id="_01858" smilref="Title.smil#_01858"> 126</p><p attribs="{'xml:space': 'preserve'}" id="_01859" smilref="Title.smil#_01859"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01860" smilref="Title.smil#_01860"> enqueue</p><p attribs="{'xml:space': 'preserve'}" id="_01861" smilref="Title.smil#_01861"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01862" smilref="Title.smil#_01862"> enqueue</p><p attribs="{'xml:space': 'preserve'}" id="_01863" smilref="Title.smil#_01863"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_01864" smilref="Title.smil#_01864"> dequeue</p><p attribs="{'xml:space': 'preserve'}" id="_01865" smilref="Title.smil#_01865"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01866" smilref="Title.smil#_01866"> dequeue</p><p attribs="{'xml:space': 'preserve'}" id="_01867" smilref="Title.smil#_01867"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01868" smilref="Title.smil#_01868"> first in line leaves queue</p><p attribs="{'xml:space': 'preserve'}" id="_01869" smilref="Title.smil#_01869"> next in line leaves queue</p><p attribs="{'xml:space': 'preserve'}" id="_01870" smilref="Title.smil#_01870"> server</p><p attribs="{'xml:space': 'preserve'}" id="_01871" smilref="Title.smil#_01871"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01872" smilref="Title.smil#_01872"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01873" smilref="Title.smil#_01873"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_01874" smilref="Title.smil#_01874"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01875" smilref="Title.smil#_01875"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01876" smilref="Title.smil#_01876"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01877" smilref="Title.smil#_01877"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_01878" smilref="Title.smil#_01878"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01879" smilref="Title.smil#_01879"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01880" smilref="Title.smil#_01880"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01881" smilref="Title.smil#_01881"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01882" smilref="Title.smil#_01882"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01883" smilref="Title.smil#_01883"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01884" smilref="Title.smil#_01884"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01885" smilref="Title.smil#_01885"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01886" smilref="Title.smil#_01886"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01887" smilref="Title.smil#_01887"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01888" smilref="Title.smil#_01888"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01889" smilref="Title.smil#_01889"> queue of customers</p><p attribs="{'xml:space': 'preserve'}" id="_01890" smilref="Title.smil#_01890"> new arrival at the end</p><p attribs="{'xml:space': 'preserve'}" id="_01891" smilref="Title.smil#_01891"> new arrival at the end</p><p attribs="{'xml:space': 'preserve'}" id="_01892" smilref="Title.smil#_01892"> FIFO queues. A FIFO queue (or just a queue) is a collection that is based on the fi rst- in-&#64257; rst-out (FIFO) policy. The policy of doing tasks in the same order that they arrive is one that we encounter frequently in everyday life: from people waiting in line at a theater, to cars waiting in line at a toll booth, to tasks waiting to be serviced by an application on your computer. One bedrock principle of any service policy is the perception of fairness. The first idea that comes to mind when most people think about fairness is that whoever has been waiting the longest should be served fi rst. That is precisely the FIFO discipline. Queues are a natural model for many everyday phenomena, and they play a central role in numerous applications. When a client iterates through the items in a queue with the foreach construct, the items are processed in the order they were added to the queue. A typical reason to use a queue in an application is to save items in a collection while at the same time preserving their relative order : they come out in the same order in which they were put in. For example, the client below is a possible implementation of the readInts() static method from our In class. The problem that this method solves for the client is that the client can get numbers from a file into an array without knowing the file size ahead of time. We enqueue the numbers from the fi le, use the size() method from Queue to find the size needed for the array, create the array, and then dequeue the numbers to move them to the array. A queue is appropriate because it puts the numbers into the array in the order in which they appear in the file (we might use a Bag if that order is immaterial). This code uses autoboxing and auto-unboxing to convert between the client&#8217;s int primitive type and the queue&#8217;s Integer wrapper type.</p><p attribs="{'xml:space': 'preserve'}" id="_01893" smilref="Title.smil#_01893"> public static int[] readInts(String name) { In in = new In(name); Queue&lt;Integer&gt; q = new Queue&lt;Integer&gt;(); while (!in.isEmpty()) q.enqueue(in.readInt());</p><p attribs="{'xml:space': 'preserve'}" id="_01894" smilref="Title.smil#_01894"> int N = q.size(); int[] a = new int[N]; for (int i = 0; i &lt; N; i++) a[i] = q.dequeue(); return a; }</p><p attribs="{'xml:space': 'preserve'}" id="_01895" smilref="Title.smil#_01895"> A typical FIFO queue</p><p attribs="{'xml:space': 'preserve'}" id="_01896" smilref="Title.smil#_01896"> Sample Queue client</p><p attribs="{'xml:space': 'preserve'}" id="_01897" smilref="Title.smil#_01897"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01898" smilref="Title.smil#_01898"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01899" smilref="Title.smil#_01899"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_01900" smilref="Title.smil#_01900" /><pagenum id="p140" page="normal" smilref="Title.smil#p140" /><p attribs="{'xml:space': 'preserve'}" id="_01901" smilref="Title.smil#_01901"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01902" smilref="Title.smil#_01902"> 127</p><p attribs="{'xml:space': 'preserve'}" id="_01903" smilref="Title.smil#_01903"> a stack of documents</p><p attribs="{'xml:space': 'preserve'}" id="_01904" smilref="Title.smil#_01904"> push( )</p><p attribs="{'xml:space': 'preserve'}" id="_01905" smilref="Title.smil#_01905"> new (gray) one goes on top</p><p attribs="{'xml:space': 'preserve'}" id="_01906" smilref="Title.smil#_01906"> push( )</p><p attribs="{'xml:space': 'preserve'}" id="_01907" smilref="Title.smil#_01907"> new (black) one goes on top</p><p attribs="{'xml:space': 'preserve'}" id="_01908" smilref="Title.smil#_01908"> = pop()</p><p attribs="{'xml:space': 'preserve'}" id="_01909" smilref="Title.smil#_01909"> = pop()</p><p attribs="{'xml:space': 'preserve'}" id="_01910" smilref="Title.smil#_01910"> remove the black one from the top</p><p attribs="{'xml:space': 'preserve'}" id="_01911" smilref="Title.smil#_01911"> remove the gray one from the top</p><p attribs="{'xml:space': 'preserve'}" id="_01912" smilref="Title.smil#_01912"> Operations on a pushdown stack</p><p attribs="{'xml:space': 'preserve'}" id="_01913" smilref="Title.smil#_01913"> public class Reverse { public static void main(String[] args) { Stack&lt;Integer&gt; stack; stack = new Stack&lt;Integer&gt;(); while (!StdIn.isEmpty()) stack.push(StdIn.readInt());</p><p attribs="{'xml:space': 'preserve'}" id="_01914" smilref="Title.smil#_01914"> Pushdown stacks. A pushdown stack (or just a stack) is a collection that is based on the last-in-&#64257; rst-out (LIFO) policy. When you keep your mail in a pile on your desk, you are using a stack. You pile pieces of new mail on the top when they arrive and take each piece of mail from the top when you are ready to read it. People do not process as many papers as they did in the past, but the same organizing principle underlies several of the applications that you use regularly on your computer. For example, many people organize their email as a stack&#8212; they push messages on the top when they are received and pop them from the top when they read them, with most recently received first (last in, first out). The advantage of this strategy is that we see interesting email as soon as possible; the disadvantage is that some old email might never get read if we never empty the stack. You have likely encountered another common example of a stack when surfing the web. When you click a hyperlink, your browser displays the new page (and pushes onto a stack). You can keep clicking on hyperlinks to visit new pages, but you can always revisit the previous page by clicking the back button (popping it from the stack). The LIFO policy offered by a stack provides just the behavior that you expect. When a client iterates through the items in a stack with the foreach construct, the items are processed in the reverse of the order in which they were added. A typical reason to use a stack iterator in an application is to save items in a collection while at the same time reversing their relative order . For example, the client Reverse at right reverses the order of the integers on standard input, again without having to know ahead of time how many there are. The importance of stacks in computing is fundamental and profound, as indicated in the detailed example that we consider next.</p><p attribs="{'xml:space': 'preserve'}" id="_01915" smilref="Title.smil#_01915"> for (int i : stack) StdOut.println(i); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01916" smilref="Title.smil#_01916"> Sample Stack client</p><p attribs="{'xml:space': 'preserve'}" id="_01917" smilref="Title.smil#_01917" /></level3><level3 id="_00014"><h3 id="ch1-s3-ss15" smilref="Title.smil#ch1-s3-ss15" xml:space="preserve">Arithmetic expression evaluation</h3><pagenum id="p141" page="normal" smilref="Title.smil#p141" /><p attribs="{'xml:space': 'preserve'}" id="_01918" smilref="Title.smil#_01918"> 128</p><p attribs="{'xml:space': 'preserve'}" id="_01919" smilref="Title.smil#_01919"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01920" smilref="Title.smil#_01920"> Arithmetic expression evaluation. As another example of a stack client, we consider a classic example that also demonstrates the utility of generics. Some of the first programs that we considered in Section 1.1 involved computing the value of arithmetic expressions like this one:</p><p attribs="{'xml:space': 'preserve'}" id="_01921" smilref="Title.smil#_01921"> ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01922" smilref="Title.smil#_01922"> If you multiply 4 by 5, add 3 to 2, multiply the result, and then add 1, you get the value 101. But how does the Java system do this calculation? Without going into the details of how the Java system is built, we can address the essential ideas by writing a Java program that can take a string as input (the expression) and produce the number represented by the expression as output. For simplicity, we begin with the following explicit recursive defi nition: an arithmetic expression is either a number, or a left parenthesis followed by an arithmetic expression followed by an operator followed by another arithmetic expression followed by a right parenthesis. For simplicity, this definition is for fully parenthesized arithmetic expressions, which specify precisely which operators apply to which operands&#8212;you are a bit more familiar with expressions such as 1 + 2 * 3, where we often rely on precedence rules instead of parentheses. The same basic mechanisms that we consider can handle precedence rules, but we avoid that complication. For speci- fi city, we support the familiar binary operators *, +, -, and /, as well as a square-root operator sqrt that takes just one argument. We could easily allow more operators and more kinds of operators to embrace a large class of familiar mathematical expressions, involving trigonometric, exponential, and logarithmic functions. Our focus is on understanding how to interpret the string of parentheses, operators, and numbers to enable performing in the proper order the low-level arithmetic operations that are available on any computer. Precisely how can we convert an arithmetic expression&#8212;a string of characters&#8212;to the value that it represents? A remarkably simple algorithm that was developed by E. W. Dijkstra in the 1960s uses two stacks (one for operands and one for operators) to do this job. An expression consists of parentheses, operators, and operands (numbers). Proceeding from left to right and taking these entities one at a time, we manipulate the stacks according to four possible cases, as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_01923" smilref="Title.smil#_01923" /><pagenum id="p142" page="normal" smilref="Title.smil#p142" /><p attribs="{'xml:space': 'preserve'}" id="_01924" smilref="Title.smil#_01924"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01925" smilref="Title.smil#_01925"> 129</p><p attribs="{'xml:space': 'preserve'}" id="_01926" smilref="Title.smil#_01926"> Dijkstra&#8217;s Two-Stack Algorithm for Expression Evaluation</p><p attribs="{'xml:space': 'preserve'}" id="_01927" smilref="Title.smil#_01927"> public class Evaluate { public static void main(String[] args) { Stack&lt;String&gt; ops = new Stack&lt;String&gt;(); Stack&lt;Double&gt; vals = new Stack&lt;Double&gt;(); while (!StdIn.isEmpty()) { // Read token, push if operator. String s = StdIn.readString(); if (s.equals("(")) ; else if (s.equals("+")) ops.push(s); else if (s.equals("-")) ops.push(s); else if (s.equals("*")) ops.push(s); else if (s.equals("/")) ops.push(s); else if (s.equals("sqrt")) ops.push(s); else if (s.equals(")")) { // Pop, evaluate, and push result if token is ")". String op = ops.pop(); double v = vals.pop(); if (op.equals("+")) v = vals.pop() + v; else if (op.equals("-")) v = vals.pop() - v; else if (op.equals("*")) v = vals.pop() * v; else if (op.equals("/")) v = vals.pop() / v; else if (op.equals("sqrt")) v = Math.sqrt(v); vals.push(v); } // Token not operator or paren: push double value. else vals.push(Double.parseDouble(s)); } StdOut.println(vals.pop()); } }</p><p attribs="{'xml:space': 'preserve'}" id="_01928" smilref="Title.smil#_01928"> This Stack client uses two stacks to evaluate arithmetic expressions, illustrating an essential computational process: interpreting a string as a program and executing that program to compute the desired result. With generics, we can use the code in a single Stack implementation to implement one stack of String values and another stack of Double values. For simplicity, this code assumes that the expression is fully parenthesized, with numbers and characters separated by whitespace.</p><p attribs="{'xml:space': 'preserve'}" id="_01929" smilref="Title.smil#_01929"> % java Evaluate ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) ) 101.0</p><p attribs="{'xml:space': 'preserve'}" id="_01930" smilref="Title.smil#_01930"> % java Evaluate ( ( 1 + sqrt ( 5.0 ) ) / 2.0 ) 1.618033988749895</p><p attribs="{'xml:space': 'preserve'}" id="_01931" smilref="Title.smil#_01931" /><pagenum id="p143" page="normal" smilref="Title.smil#p143" /><p attribs="{'xml:space': 'preserve'}" id="_01932" smilref="Title.smil#_01932"> 130</p><p attribs="{'xml:space': 'preserve'}" id="_01933" smilref="Title.smil#_01933"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01934" smilref="Title.smil#_01934"> is easy to convince yourself that it computes the proper value: any time the algorithm encounters a subexpression consisting of two operands separated by an operator, all surrounded by parentheses, it leaves the result of performing that operation on those operands on the operand stack. The result is the same as if that value had appeared in the input instead of the subexpression, so we can think of replacing the subexpression by the value to get an expression that would yield the same result. We can apply this argument again and again until we get a single value. For example, the algorithm computes the same value for all of these expressions:</p><p attribs="{'xml:space': 'preserve'}" id="_01935" smilref="Title.smil#_01935"> ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) ) ( 1 + ( 5 * ( 4 * 5 ) ) ) ( 1 + ( 5 * 20 ) ) ( 1 + 100 ) 101</p><p attribs="{'xml:space': 'preserve'}" id="_01936" smilref="Title.smil#_01936"> Evaluate on the previous page is an implementation of this algorithm. This code is a simple example of an interpreter: a program that interprets the computation specified by a given string and performs the computation to arrive at the result.</p><p attribs="{'xml:space': 'preserve'}" id="_01937" smilref="Title.smil#_01937" /><pagenum id="p144" page="normal" smilref="Title.smil#p144" /><p attribs="{'xml:space': 'preserve'}" id="_01938" smilref="Title.smil#_01938"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_01939" smilref="Title.smil#_01939"> 131</p><p attribs="{'xml:space': 'preserve'}" id="_01940" smilref="Title.smil#_01940"> left parenthesis: ignore</p><p attribs="{'xml:space': 'preserve'}" id="_01941" smilref="Title.smil#_01941"> ( 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01942" smilref="Title.smil#_01942"> operand: push onto operand stack</p><p attribs="{'xml:space': 'preserve'}" id="_01943" smilref="Title.smil#_01943"> 1 + ( ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01944" smilref="Title.smil#_01944"> operator: push onto operator stack</p><p attribs="{'xml:space': 'preserve'}" id="_01945" smilref="Title.smil#_01945"> + ( ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01946" smilref="Title.smil#_01946"> ( ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01947" smilref="Title.smil#_01947"> ( 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01948" smilref="Title.smil#_01948"> 2 + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01949" smilref="Title.smil#_01949"> + 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01950" smilref="Title.smil#_01950"> 3 ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01951" smilref="Title.smil#_01951"> right parenthesis: pop operator and operands and push result</p><p attribs="{'xml:space': 'preserve'}" id="_01952" smilref="Title.smil#_01952"> ) * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01953" smilref="Title.smil#_01953"> * ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01954" smilref="Title.smil#_01954"> ( 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01955" smilref="Title.smil#_01955"> 4 * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01956" smilref="Title.smil#_01956"> * 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01957" smilref="Title.smil#_01957"> 5 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01958" smilref="Title.smil#_01958"> ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01959" smilref="Title.smil#_01959"> ) )</p><p attribs="{'xml:space': 'preserve'}" id="_01960" smilref="Title.smil#_01960"> )</p><p attribs="{'xml:space': 'preserve'}" id="_01961" smilref="Title.smil#_01961"> operand stack</p><p attribs="{'xml:space': 'preserve'}" id="_01962" smilref="Title.smil#_01962"> operator stack</p><p attribs="{'xml:space': 'preserve'}" id="_01963" smilref="Title.smil#_01963"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01964" smilref="Title.smil#_01964"> 1 +</p><p attribs="{'xml:space': 'preserve'}" id="_01965" smilref="Title.smil#_01965"> 1 +</p><p attribs="{'xml:space': 'preserve'}" id="_01966" smilref="Title.smil#_01966"> 1 +</p><p attribs="{'xml:space': 'preserve'}" id="_01967" smilref="Title.smil#_01967"> 1 2 +</p><p attribs="{'xml:space': 'preserve'}" id="_01968" smilref="Title.smil#_01968"> 1 2 + +</p><p attribs="{'xml:space': 'preserve'}" id="_01969" smilref="Title.smil#_01969"> 1 2 3 + +</p><p attribs="{'xml:space': 'preserve'}" id="_01970" smilref="Title.smil#_01970"> 1 5 +</p><p attribs="{'xml:space': 'preserve'}" id="_01971" smilref="Title.smil#_01971"> 1 5 + *</p><p attribs="{'xml:space': 'preserve'}" id="_01972" smilref="Title.smil#_01972"> 1 5 + *</p><p attribs="{'xml:space': 'preserve'}" id="_01973" smilref="Title.smil#_01973"> 1 5 4 + *</p><p attribs="{'xml:space': 'preserve'}" id="_01974" smilref="Title.smil#_01974"> 1 5 4 + * *</p><p attribs="{'xml:space': 'preserve'}" id="_01975" smilref="Title.smil#_01975"> 1 5 4 5 + * *</p><p attribs="{'xml:space': 'preserve'}" id="_01976" smilref="Title.smil#_01976"> 1 5 20 + *</p><p attribs="{'xml:space': 'preserve'}" id="_01977" smilref="Title.smil#_01977"> 1 100 +</p><p attribs="{'xml:space': 'preserve'}" id="_01978" smilref="Title.smil#_01978"> 101</p><p attribs="{'xml:space': 'preserve'}" id="_01979" smilref="Title.smil#_01979"> Trace of Dijkstra&#8217;s two-stack arithmetic expression-evaluation algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_01980" smilref="Title.smil#_01980" /><pagenum id="p145" page="normal" smilref="Title.smil#p145" /><p attribs="{'xml:space': 'preserve'}" id="_01981" smilref="Title.smil#_01981"> 132</p><p attribs="{'xml:space': 'preserve'}" id="_01982" smilref="Title.smil#_01982"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_01983" smilref="Title.smil#_01983"> Implementing collections To address the issue of implementing Bag, Stack and Queue, we begin with a simple classic implementation, then address improvements that lead us to implementations of the APIs articulated on page 121.</p><p attribs="{'xml:space': 'preserve'}" id="_01984" smilref="Title.smil#_01984"> Fixed-capacity stack. As a strawman, we consider an abstract data type for a fi xed- capacity stack of strings, shown on the opposite page. The API differs from our Stack API: it works only for String values, it requires the client to specify a capacity, and it does not support iteration. The primary choice in developing an API implementation is to choose a representation for the data. For FixedCapacityStackOfStrings, an obvious choice is to use an array of String values. Pursuing this choice leads to the implementation shown at the bottom on the opposite page, which could hardly be simpler (each method is a one-liner). The instance variables are an array a[] that holds the items in the stack and an integer N that counts the number of items in the stack. To remove an item, we decrement N and then return a[N]; to insert a new item, we set a[N] equal to the new item and then increment N. These operations preserve the following properties: </p><p attribs="{'xml:space': 'preserve'}" id="_01985" smilref="Title.smil#_01985"> or or not or not to or not to or not be or not be or not be or that be or that be or that be or that be or not to</p><p attribs="{'xml:space': 'preserve'}" id="_01986" smilref="Title.smil#_01986"> to to to to to to to to to to to to to to</p><p attribs="{'xml:space': 'preserve'}" id="_01987" smilref="Title.smil#_01987"> be be be be be be be be be be be be is</p><p attribs="{'xml:space': 'preserve'}" id="_01988" smilref="Title.smil#_01988"> N</p><p attribs="{'xml:space': 'preserve'}" id="_01989" smilref="Title.smil#_01989"> 0 1 2 3 4 5 4 5 4 3 4 3 2 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_01990" smilref="Title.smil#_01990"> a[]</p><p attribs="{'xml:space': 'preserve'}" id="_01991" smilref="Title.smil#_01991"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_01992" smilref="Title.smil#_01992"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_01993" smilref="Title.smil#_01993"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_01994" smilref="Title.smil#_01994"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_01995" smilref="Title.smil#_01995"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_01996" smilref="Title.smil#_01996"> StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_01997" smilref="Title.smil#_01997"> (pop)</p><p attribs="{'xml:space': 'preserve'}" id="_01998" smilref="Title.smil#_01998"> Trace of FixedCapacityStackOfStrings test client</p><p attribs="{'xml:space': 'preserve'}" id="_01999" smilref="Title.smil#_01999"> StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_02000" smilref="Title.smil#_02000"> (push)</p><p attribs="{'xml:space': 'preserve'}" id="_02001" smilref="Title.smil#_02001"> to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02002" smilref="Title.smil#_02002"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02003" smilref="Title.smil#_02003"> be not</p><p attribs="{'xml:space': 'preserve'}" id="_02004" smilref="Title.smil#_02004"> that or be</p><p attribs="{'xml:space': 'preserve'}" id="_02005" smilref="Title.smil#_02005" /><pagenum id="p146" page="normal" smilref="Title.smil#p146" /><p attribs="{'xml:space': 'preserve'}" id="_02006" smilref="Title.smil#_02006"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02007" smilref="Title.smil#_02007"> 133</p><p attribs="{'xml:space': 'preserve'}" id="_02008" smilref="Title.smil#_02008"> public class FixedCapacityStackOfStrings FixedCapacityStackOfStrings(int cap) create an empty stack of capacity cap void push(String item)</p><p attribs="{'xml:space': 'preserve'}" id="_02009" smilref="Title.smil#_02009"> add a string remove the most recently added string is the stack empty? number of strings on the stack</p><p attribs="{'xml:space': 'preserve'}" id="_02010" smilref="Title.smil#_02010"> API</p><p attribs="{'xml:space': 'preserve'}" id="_02011" smilref="Title.smil#_02011"> test client</p><p attribs="{'xml:space': 'preserve'}" id="_02012" smilref="Title.smil#_02012"> String pop()</p><p attribs="{'xml:space': 'preserve'}" id="_02013" smilref="Title.smil#_02013"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_02014" smilref="Title.smil#_02014"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_02015" smilref="Title.smil#_02015"> public static void main(String[] args) { FixedCapacityStackOfStrings s; s = new FixedCapacityStackOfStrings(100); while (!StdIn.isEmpty()) { String item = StdIn.readString(); if (!item.equals("-")) s.push(item); else if (!s.isEmpty()) StdOut.print(s.pop() + " "); }</p><p attribs="{'xml:space': 'preserve'}" id="_02016" smilref="Title.smil#_02016"> StdOut.println("(" + s.size() + " left on stack)"); }</p><p attribs="{'xml:space': 'preserve'}" id="_02017" smilref="Title.smil#_02017"> application</p><p attribs="{'xml:space': 'preserve'}" id="_02018" smilref="Title.smil#_02018"> % more tobe.txt to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02019" smilref="Title.smil#_02019"> % java FixedCapacityStackOfStrings &lt; tobe.txt to be not that or be (2 left on stack)</p><p attribs="{'xml:space': 'preserve'}" id="_02020" smilref="Title.smil#_02020"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_02021" smilref="Title.smil#_02021"> public class FixedCapacityStackOfStrings { private String[] a; // stack entries private int N; // size</p><p attribs="{'xml:space': 'preserve'}" id="_02022" smilref="Title.smil#_02022"> public FixedCapacityStackOfStrings(int cap) { a = new String[cap]; }</p><p attribs="{'xml:space': 'preserve'}" id="_02023" smilref="Title.smil#_02023"> public boolean isEmpty() { return N == 0; } public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_02024" smilref="Title.smil#_02024"> public void push(String item) { a[N++] = item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02025" smilref="Title.smil#_02025"> public String pop() { return a[--N]; }</p><p attribs="{'xml:space': 'preserve'}" id="_02026" smilref="Title.smil#_02026"> }</p><p attribs="{'xml:space': 'preserve'}" id="_02027" smilref="Title.smil#_02027"> An abstract data type for a fixed-capacity stack of strings</p><p attribs="{'xml:space': 'preserve'}" id="_02028" smilref="Title.smil#_02028" /></level3><level3 id="_00015"><h3 id="ch1-s3-ss16" smilref="Title.smil#ch1-s3-ss16" xml:space="preserve">Generics</h3><pagenum id="p147" page="normal" smilref="Title.smil#p147" /><p attribs="{'xml:space': 'preserve'}" id="_02029" smilref="Title.smil#_02029"> 134</p><p attribs="{'xml:space': 'preserve'}" id="_02030" smilref="Title.smil#_02030"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02031" smilref="Title.smil#_02031"> Generics. The first drawback of FixedCapacityStackOfStrings is that it works only for String objects. If we want a stack of double values, we would need to develop another class with similar code, essentially replacing String with double everywhere. This is easy enough but becomes burdensome when we consider building a stack of Transaction values or a queue of Date values, and so forth. As discussed on page 122, Java&#8217;s parameterized types (generics) are specifically designed to address this situation, and we saw several examples of client code (on pages 125, 126, 127, and 129). But how do we implement a generic stack? The code on the facing page shows the details. It imple-</p><p attribs="{'xml:space': 'preserve'}" id="_02032" smilref="Title.smil#_02032"> ments a class FixedCapacityStack that differs from FixedCapacityStackOfStrings</p><p attribs="{'xml:space': 'preserve'}" id="_02033" smilref="Title.smil#_02033"> only in the code highlighted in red&#8212;we replace every occurrence of String with Item (with one exception, discussed below) and declare the class with the following first line of code:</p><p attribs="{'xml:space': 'preserve'}" id="_02034" smilref="Title.smil#_02034"> public class FixedCapacityStack&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02035" smilref="Title.smil#_02035"> The name Item is a type parameter, a symbolic placeholder for some concrete type to be used by the client. You can read FixedCapacityStack&lt;Item&gt; as stack of items, which is precisely what we want. When implementing FixedCapacityStack, we do not know the actual type of Item, but a client can use our stack for any type of data by providing a concrete type when the stack is created. Concrete types must be reference types, but clients can depend on autoboxing to convert primitive types to their corresponding wrapper types. Java uses the type parameter Item to check for type mismatch errors&#8212;even though no concrete type is yet known, variables of type Item must be assigned values of type Item, and so forth. But there is one significant hitch in this story : We would like to implement the constructor in FixedCapacityStack with the code</p><p attribs="{'xml:space': 'preserve'}" id="_02036" smilref="Title.smil#_02036"> a = new Item[cap];</p><p attribs="{'xml:space': 'preserve'}" id="_02037" smilref="Title.smil#_02037"> which calls for creation of a generic array. For historical and technical reasons beyond our scope, generic array creation is disallowed in Java. Instead, we need to use a cast:</p><p attribs="{'xml:space': 'preserve'}" id="_02038" smilref="Title.smil#_02038"> a = (Item[]) new Object[cap];</p><p attribs="{'xml:space': 'preserve'}" id="_02039" smilref="Title.smil#_02039"> This code produces the desired effect (though the Java compiler gives a warning, which we can safely ignore), and we use this idiom throughout the book (the Java system library implementations of similar abstract data types use the same idiom).</p><p attribs="{'xml:space': 'preserve'}" id="_02040" smilref="Title.smil#_02040" /><pagenum id="p148" page="normal" smilref="Title.smil#p148" /><p attribs="{'xml:space': 'preserve'}" id="_02041" smilref="Title.smil#_02041"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02042" smilref="Title.smil#_02042"> 135</p><p attribs="{'xml:space': 'preserve'}" id="_02043" smilref="Title.smil#_02043"> API</p><p attribs="{'xml:space': 'preserve'}" id="_02044" smilref="Title.smil#_02044"> public class FixedCapacityStack&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02045" smilref="Title.smil#_02045"> FixedCapacityStack(int cap)</p><p attribs="{'xml:space': 'preserve'}" id="_02046" smilref="Title.smil#_02046"> void push(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_02047" smilref="Title.smil#_02047"> Item pop()</p><p attribs="{'xml:space': 'preserve'}" id="_02048" smilref="Title.smil#_02048"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_02049" smilref="Title.smil#_02049"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_02050" smilref="Title.smil#_02050"> create an empty stack of capacity cap add an item remove the most recently added item is the stack empty? number of items on the stack</p><p attribs="{'xml:space': 'preserve'}" id="_02051" smilref="Title.smil#_02051"> test client</p><p attribs="{'xml:space': 'preserve'}" id="_02052" smilref="Title.smil#_02052"> public static void main(String[] args) { FixedCapacityStack&lt;String&gt; s; s = new FixedCapacityStack&lt;String&gt;(100); while (!StdIn.isEmpty()) { String item = StdIn.readString(); if (!item.equals("-")) s.push(item); else if (!s.isEmpty()) StdOut.print(s.pop() + " "); }</p><p attribs="{'xml:space': 'preserve'}" id="_02053" smilref="Title.smil#_02053"> StdOut.println("(" + s.size() + " left on stack)"); }</p><p attribs="{'xml:space': 'preserve'}" id="_02054" smilref="Title.smil#_02054"> application</p><p attribs="{'xml:space': 'preserve'}" id="_02055" smilref="Title.smil#_02055"> % more tobe.txt to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02056" smilref="Title.smil#_02056"> % java FixedCapacityStack &lt; tobe.txt to be not that or be (2 left on stack)</p><p attribs="{'xml:space': 'preserve'}" id="_02057" smilref="Title.smil#_02057"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_02058" smilref="Title.smil#_02058"> public class FixedCapacityStack&lt;Item&gt; { private Item[] a; // stack entries private int N; // size</p><p attribs="{'xml:space': 'preserve'}" id="_02059" smilref="Title.smil#_02059"> public FixedCapacityStack(int cap) { a = (Item[]) new Object[cap]; }</p><p attribs="{'xml:space': 'preserve'}" id="_02060" smilref="Title.smil#_02060"> public boolean isEmpty() { return N == 0; } public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_02061" smilref="Title.smil#_02061"> public void push(Item item) { a[N++] = item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02062" smilref="Title.smil#_02062"> public Item pop() { return a[--N]; }</p><p attribs="{'xml:space': 'preserve'}" id="_02063" smilref="Title.smil#_02063"> }</p><p attribs="{'xml:space': 'preserve'}" id="_02064" smilref="Title.smil#_02064"> An abstract data type for a fixed-capacity generic stack</p><p attribs="{'xml:space': 'preserve'}" id="_02065" smilref="Title.smil#_02065" /></level3><level3 id="_00016"><h3 id="ch1-s3-ss17" smilref="Title.smil#ch1-s3-ss17" xml:space="preserve">Resizing arrays</h3><pagenum id="p149" page="normal" smilref="Title.smil#p149" /><p attribs="{'xml:space': 'preserve'}" id="_02066" smilref="Title.smil#_02066"> 136</p><p attribs="{'xml:space': 'preserve'}" id="_02067" smilref="Title.smil#_02067"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02068" smilref="Title.smil#_02068"> Array resizing. Choosing an array to represent the stack contents implies that clients must estimate the maximum size of the stack ahead of time. In Java, we cannot change the size of an array once created, so the stack always uses space proportional to that maximum. A client that chooses a large capacity risks wasting a large amount of memory at times when the collection is empty or nearly empty. For example, a transaction system might involve billions of items and thousands of collections of them. Such a client would have to allow for the possibility that each of those collections could hold all of those items, even though a typical constraint in such systems is that each item can appear in only one collection. Moreover, every client risks overflow if the collection grows larger than the array. For this reason, push() needs code to test for a full stack ,and we should have an isFull() method in the API to allow clients to test for that condition. We omit that code, because our desire is to relieve the client from having to deal with the concept of a full stack, as articulated in our original Stack API. Instead, we modify the array implementation to dynamically adjust the size of the array a[] so that it is both sufficiently large to hold all of the items and not so large as to waste an excessive amount of space. Achieving these goals turns out to be remarkably easy. First, we implement a method that moves a stack into an array of a different size:</p><p attribs="{'xml:space': 'preserve'}" id="_02069" smilref="Title.smil#_02069"> private void resize(int max) { // Move stack of size N &lt;= max to a new array of size max. Item[] temp = (Item[]) new Object[max]; for (int i = 0; i &lt; N; i++) temp[i] = a[i]; a = temp; }</p><p attribs="{'xml:space': 'preserve'}" id="_02070" smilref="Title.smil#_02070"> Now, in push(), we check whether the array is too small. In particular, we check whether there is room for the new item in the array by checking whether the stack size N is equal to the array size a.length. If there is no room, we double the size of the array. Then we simply insert the new item with the code a[N++] = item, as before:</p><p attribs="{'xml:space': 'preserve'}" id="_02071" smilref="Title.smil#_02071"> public void push(String item) { // Add item to top of stack. if (N == a.length) resize(2*a.length); a[N++] = item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02072" smilref="Title.smil#_02072"> Similarly, in pop(), we begin by deleting the item, then we halve the array size if it is too large. If you think a bit about the situation, you will see that the appropriate test is whether the stack size is less than one-fourth the array size. After the array is halved, it will be about half full and can accommodate a substantial number of push() and pop() operations before having to change the size of the array again.</p><p attribs="{'xml:space': 'preserve'}" id="_02073" smilref="Title.smil#_02073" /><pagenum id="p150" page="normal" smilref="Title.smil#p150" /><p attribs="{'xml:space': 'preserve'}" id="_02074" smilref="Title.smil#_02074"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02075" smilref="Title.smil#_02075"> 137</p><p attribs="{'xml:space': 'preserve'}" id="_02076" smilref="Title.smil#_02076"> public String pop() { // Remove item from top of stack. String item = a[--N]; a[N] = null; // Avoid loitering (see text). if (N &gt; 0 &amp;&amp; N == a.length/4) resize(a.length/2); return item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02077" smilref="Title.smil#_02077"> With this implementation, the stack never overflows and never becomes less than one- quarter full (unless the stack is empty, when the array size is 1). We will address the performance analysis of this approach in more detail in Section 1.4. Loitering. Java&#8217;s garbage collection policy is to reclaim the memory associated with any objects that can no longer be accessed. In our pop() implementations, the reference to the popped item remains in the array. The item is effectively an orphan&#8212;it will be never be accessed again&#8212;but the Java garbage collector has no way to know this until it is overwritten. Even when the client is done with the item, the reference in the array may keep it alive. This condition (holding a reference to an item that is no longer needed) is known as loitering. In this case, loitering is easy to avoid, by setting the array entry corresponding to the popped item to null, thus overwriting the unused reference and making it possible for the system to reclaim the memory associated with the popped item when the client is finished with it.</p><p attribs="{'xml:space': 'preserve'}" id="_02078" smilref="Title.smil#_02078"> push() pop()</p><p attribs="{'xml:space': 'preserve'}" id="_02079" smilref="Title.smil#_02079"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02080" smilref="Title.smil#_02080"> a.length</p><p attribs="{'xml:space': 'preserve'}" id="_02081" smilref="Title.smil#_02081"> to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02082" smilref="Title.smil#_02082"> 0 1 2 3 4 5 4 5 4 3 4 3 2 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_02083" smilref="Title.smil#_02083"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02084" smilref="Title.smil#_02084"> be not</p><p attribs="{'xml:space': 'preserve'}" id="_02085" smilref="Title.smil#_02085"> that or be</p><p attribs="{'xml:space': 'preserve'}" id="_02086" smilref="Title.smil#_02086"> 1 1 2 4 4 8 8 8 8 8 8 8 4 2 2</p><p attribs="{'xml:space': 'preserve'}" id="_02087" smilref="Title.smil#_02087"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_02088" smilref="Title.smil#_02088"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02089" smilref="Title.smil#_02089"> to to to to to to to to to to to to to to</p><p attribs="{'xml:space': 'preserve'}" id="_02090" smilref="Title.smil#_02090"> a[]</p><p attribs="{'xml:space': 'preserve'}" id="_02091" smilref="Title.smil#_02091"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_02092" smilref="Title.smil#_02092"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_02093" smilref="Title.smil#_02093"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_02094" smilref="Title.smil#_02094"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_02095" smilref="Title.smil#_02095"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02096" smilref="Title.smil#_02096"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_02097" smilref="Title.smil#_02097"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_02098" smilref="Title.smil#_02098"> or or or or or or or or or</p><p attribs="{'xml:space': 'preserve'}" id="_02099" smilref="Title.smil#_02099"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02100" smilref="Title.smil#_02100"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02101" smilref="Title.smil#_02101"> not not not not not</p><p attribs="{'xml:space': 'preserve'}" id="_02102" smilref="Title.smil#_02102"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02103" smilref="Title.smil#_02103"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02104" smilref="Title.smil#_02104"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02105" smilref="Title.smil#_02105"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02106" smilref="Title.smil#_02106"> be be be be be be be be be be be</p><p attribs="{'xml:space': 'preserve'}" id="_02107" smilref="Title.smil#_02107"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02108" smilref="Title.smil#_02108"> is</p><p attribs="{'xml:space': 'preserve'}" id="_02109" smilref="Title.smil#_02109"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02110" smilref="Title.smil#_02110"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02111" smilref="Title.smil#_02111"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02112" smilref="Title.smil#_02112"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02113" smilref="Title.smil#_02113"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02114" smilref="Title.smil#_02114"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02115" smilref="Title.smil#_02115"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02116" smilref="Title.smil#_02116"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02117" smilref="Title.smil#_02117"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02118" smilref="Title.smil#_02118"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02119" smilref="Title.smil#_02119"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02120" smilref="Title.smil#_02120"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02121" smilref="Title.smil#_02121"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02122" smilref="Title.smil#_02122"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02123" smilref="Title.smil#_02123"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02124" smilref="Title.smil#_02124"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02125" smilref="Title.smil#_02125"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02126" smilref="Title.smil#_02126"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02127" smilref="Title.smil#_02127"> null null</p><p attribs="{'xml:space': 'preserve'}" id="_02128" smilref="Title.smil#_02128"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02129" smilref="Title.smil#_02129"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02130" smilref="Title.smil#_02130"> Trace of array resizing during a sequence of push() and pop() operations</p><p attribs="{'xml:space': 'preserve'}" id="_02131" smilref="Title.smil#_02131" /></level3><level3 id="_00017"><h3 id="ch1-s3-ss18" smilref="Title.smil#ch1-s3-ss18" xml:space="preserve">Iterators</h3><pagenum id="p151" page="normal" smilref="Title.smil#p151" /><p attribs="{'xml:space': 'preserve'}" id="_02132" smilref="Title.smil#_02132"> 138</p><p attribs="{'xml:space': 'preserve'}" id="_02133" smilref="Title.smil#_02133"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02134" smilref="Title.smil#_02134"> Iteration. As mentioned earlier in this section, one of the fundamental operations on collections is to process each item by iterating through the collection using Java&#8217;s foreach statement. This paradigm leads to clear and compact code that is free from dependence on the details of a collection&#8217;s implementation. To consider the task of implementing iteration, we start with a snippet of client code that prints all of the items in a collection of strings, one per line:</p><p attribs="{'xml:space': 'preserve'}" id="_02135" smilref="Title.smil#_02135"> Stack&lt;String&gt; collection = new Stack&lt;String&gt;(); ... for (String s : collection) StdOut.println(s); ...</p><p attribs="{'xml:space': 'preserve'}" id="_02136" smilref="Title.smil#_02136"> Now, this foreach statement is shorthand for a while construct (just like the for statement itself ). It is essentially equivalent to the following while statement:</p><p attribs="{'xml:space': 'preserve'}" id="_02137" smilref="Title.smil#_02137"> Iterator&lt;String&gt; i = collection.iterator(); while (i.hasNext()) { String s = i.next(); StdOut.println(s); }</p><p attribs="{'xml:space': 'preserve'}" id="_02138" smilref="Title.smil#_02138"> This code exposes the ingredients that we need to implement in any iterable collection: </p><p attribs="{'xml:space': 'preserve'}" id="_02139" smilref="Title.smil#_02139"> public interface Iterable&lt;Item&gt; { Iterator&lt;Item&gt; iterator(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02140" smilref="Title.smil#_02140"> (which is in java.lang.Iterable), and to add a method iterator() to the class that returns an Iterator&lt;Item&gt;. Iterators are generic, so we can use our parameterized type Item to allow clients to iterate through objects of whatever type is provided by our client. For the array representation that we have been using, we need to iterate through</p><p attribs="{'xml:space': 'preserve'}" id="_02141" smilref="Title.smil#_02141" /><pagenum id="p152" page="normal" smilref="Title.smil#p152" /><p attribs="{'xml:space': 'preserve'}" id="_02142" smilref="Title.smil#_02142"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02143" smilref="Title.smil#_02143"> 139</p><p attribs="{'xml:space': 'preserve'}" id="_02144" smilref="Title.smil#_02144"> an array in reverse order, so we name the iterator ReverseArrayIterator and add this method:</p><p attribs="{'xml:space': 'preserve'}" id="_02145" smilref="Title.smil#_02145"> public Iterator&lt;Item&gt; iterator() { return new ReverseArrayIterator(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02146" smilref="Title.smil#_02146"> What is an iterator? An object from a class that implements the methods hasNext() and next(), as defined in the following interface (which is in java.util.Iterator):</p><p attribs="{'xml:space': 'preserve'}" id="_02147" smilref="Title.smil#_02147"> public interface Iterator&lt;Item&gt; { boolean hasNext(); Item next(); void remove(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02148" smilref="Title.smil#_02148"> Although the interface specifies a remove() method, we always use an empty method for remove() in this book, because interleaving iteration with operations that modify the data structure is best avoided. For ReverseArrayIterator, these methods are all one-liners, implemented in a nested class within our stack class:</p><p attribs="{'xml:space': 'preserve'}" id="_02149" smilref="Title.smil#_02149"> private class ReverseArrayIterator implements Iterator&lt;Item&gt; { private int i = N;</p><p attribs="{'xml:space': 'preserve'}" id="_02150" smilref="Title.smil#_02150"> public boolean hasNext() { return i &gt; 0; } public Item next() { return a[--i]; } public void remove() { } }</p><p attribs="{'xml:space': 'preserve'}" id="_02151" smilref="Title.smil#_02151"> Note that this nested class can access the instance variables of the enclosing class, in this case a[] and N (this ability is the main reason we use nested classes for iterators). Technically, to conform to the Iterator speci&#64257; cation, we should throw exceptions in two cases: an UnsupportedOperationException if a client calls remove() and a NoSuchElementException if a client calls next() when i is 0. Since we only use iterators in the foreach construction where these conditions do not arise, we omit this code. One crucial detail remains: we have to include</p><p attribs="{'xml:space': 'preserve'}" id="_02152" smilref="Title.smil#_02152"> import java.util.Iterator;</p><p attribs="{'xml:space': 'preserve'}" id="_02153" smilref="Title.smil#_02153"> at the beginning of the program because (for historical reasons) Iterator is not part of java.lang (even though Iterable is part of java.lang). Now a client using the foreach statement for this class will get behavior equivalent to the common for loop for arrays, but does not need to be aware of the array representation (an implementation</p><p attribs="{'xml:space': 'preserve'}" id="_02154" smilref="Title.smil#_02154" /><pagenum id="p153" page="normal" smilref="Title.smil#p153" /><p attribs="{'xml:space': 'preserve'}" id="_02155" smilref="Title.smil#_02155"> 140</p><p attribs="{'xml:space': 'preserve'}" id="_02156" smilref="Title.smil#_02156"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02157" smilref="Title.smil#_02157"> detail). This arrangement is of critical importance for implementations of fundamental data types like the collections that we consider in this book and those included in Java libraries. For example, it frees us to switch to a totally different representation without having to change any client code. More important, taking the client&#8217;s point of view, it allows clients to use iteration without having to know any details of the class implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_02158" smilref="Title.smil#_02158"> Algorithm 1.1 is an implementation of our Stack API that resizes the array, allows clients to make stacks for any type of data, and supports client use of foreach to iterate through the stack items in LIFO order. This implementation is based on Java language nuances involving Iterator and Iterable, but there is no need to study those nuances in detail, as the code itself is not complicated and can be used as a template for other collection implementations. For example, we can implement the Queue API by maintaining two indices as instance variables, a variable head for the beginning of the queue and a variable tail for the end of the queue. To remove an item, use head to access it and then increment head; to insert an item, use tail to store it, and then increment tail. If incrementing an index brings it past the end of the array, reset it to 0. Developing the details of checking when the queue is empty and when the array is full and needs resizing is an interesting and worthwhile programming exercise (see Exercise 1.3.14).</p><p attribs="{'xml:space': 'preserve'}" id="_02159" smilref="Title.smil#_02159"> StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_02160" smilref="Title.smil#_02160"> StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_02161" smilref="Title.smil#_02161"> (enqueue)</p><p attribs="{'xml:space': 'preserve'}" id="_02162" smilref="Title.smil#_02162"> (dequeue)</p><p attribs="{'xml:space': 'preserve'}" id="_02163" smilref="Title.smil#_02163"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02164" smilref="Title.smil#_02164"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02165" smilref="Title.smil#_02165"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02166" smilref="Title.smil#_02166"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02167" smilref="Title.smil#_02167"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02168" smilref="Title.smil#_02168"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02169" smilref="Title.smil#_02169"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02170" smilref="Title.smil#_02170"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02171" smilref="Title.smil#_02171"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02172" smilref="Title.smil#_02172"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_02173" smilref="Title.smil#_02173"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02174" smilref="Title.smil#_02174"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_02175" smilref="Title.smil#_02175"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_02176" smilref="Title.smil#_02176"> head</p><p attribs="{'xml:space': 'preserve'}" id="_02177" smilref="Title.smil#_02177"> tail</p><p attribs="{'xml:space': 'preserve'}" id="_02178" smilref="Title.smil#_02178"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_02179" smilref="Title.smil#_02179"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_02180" smilref="Title.smil#_02180"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_02181" smilref="Title.smil#_02181"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_02182" smilref="Title.smil#_02182"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_02183" smilref="Title.smil#_02183"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02184" smilref="Title.smil#_02184"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02185" smilref="Title.smil#_02185"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_02186" smilref="Title.smil#_02186"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_02187" smilref="Title.smil#_02187"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_02188" smilref="Title.smil#_02188"> 0 to</p><p attribs="{'xml:space': 'preserve'}" id="_02189" smilref="Title.smil#_02189"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02190" smilref="Title.smil#_02190"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02191" smilref="Title.smil#_02191"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02192" smilref="Title.smil#_02192"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02193" smilref="Title.smil#_02193"> 1 be</p><p attribs="{'xml:space': 'preserve'}" id="_02194" smilref="Title.smil#_02194"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02195" smilref="Title.smil#_02195"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02196" smilref="Title.smil#_02196"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02197" smilref="Title.smil#_02197"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02198" smilref="Title.smil#_02198"> a[]</p><p attribs="{'xml:space': 'preserve'}" id="_02199" smilref="Title.smil#_02199"> 2 or</p><p attribs="{'xml:space': 'preserve'}" id="_02200" smilref="Title.smil#_02200"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02201" smilref="Title.smil#_02201"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02202" smilref="Title.smil#_02202"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02203" smilref="Title.smil#_02203"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02204" smilref="Title.smil#_02204"> 3 not</p><p attribs="{'xml:space': 'preserve'}" id="_02205" smilref="Title.smil#_02205"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02206" smilref="Title.smil#_02206"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02207" smilref="Title.smil#_02207"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02208" smilref="Title.smil#_02208"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02209" smilref="Title.smil#_02209"> 4 to</p><p attribs="{'xml:space': 'preserve'}" id="_02210" smilref="Title.smil#_02210"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02211" smilref="Title.smil#_02211"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02212" smilref="Title.smil#_02212"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02213" smilref="Title.smil#_02213"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02214" smilref="Title.smil#_02214"> Trace of ResizingArrayQueue test client</p><p attribs="{'xml:space': 'preserve'}" id="_02215" smilref="Title.smil#_02215"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_02216" smilref="Title.smil#_02216"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_02217" smilref="Title.smil#_02217"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_02218" smilref="Title.smil#_02218"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02219" smilref="Title.smil#_02219"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02220" smilref="Title.smil#_02220"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02221" smilref="Title.smil#_02221"> In the context of the study of algorithms, Algorithm 1.1 is significant because it almost (but not quite) achieves optimum performance goals for any collection implementation: </p><p attribs="{'xml:space': 'preserve'}" id="_02222" smilref="Title.smil#_02222" /><pagenum id="p154" page="normal" smilref="Title.smil#p154" /><p attribs="{'xml:space': 'preserve'}" id="_02223" smilref="Title.smil#_02223"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02224" smilref="Title.smil#_02224"> 141</p><p attribs="{'xml:space': 'preserve'}" id="_02225" smilref="Title.smil#_02225"> ALGORITHM 1.1 Pushdown (LIFO) stack (resizing array implementation)</p><p attribs="{'xml:space': 'preserve'}" id="_02226" smilref="Title.smil#_02226"> import java.util.Iterator; public class ResizingArrayStack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Item[] a = (Item[]) new Object[1]; // stack items private int N = 0; // number of items</p><p attribs="{'xml:space': 'preserve'}" id="_02227" smilref="Title.smil#_02227"> public boolean isEmpty() { return N == 0; } public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_02228" smilref="Title.smil#_02228"> private void resize(int max) { // Move stack to a new array of size max. Item[] temp = (Item[]) new Object[max]; for (int i = 0; i &lt; N; i++) temp[i] = a[i]; a = temp; }</p><p attribs="{'xml:space': 'preserve'}" id="_02229" smilref="Title.smil#_02229"> public void push(Item item) { // Add item to top of stack. if (N == a.length) resize(2*a.length); a[N++] = item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02230" smilref="Title.smil#_02230"> public Item pop() { // Remove item from top of stack. Item item = a[--N]; a[N] = null; // Avoid loitering (see text). if (N &gt; 0 &amp;&amp; N == a.length/4) resize(a.length/2); return item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02231" smilref="Title.smil#_02231"> public Iterator&lt;Item&gt; iterator() { return new ReverseArrayIterator(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02232" smilref="Title.smil#_02232"> private class ReverseArrayIterator implements Iterator&lt;Item&gt; { // Support LIFO iteration. private int i = N; public boolean hasNext() { return i &gt; 0; } public Item next() { return a[--i]; } public void remove() { } } }</p><p attribs="{'xml:space': 'preserve'}" id="_02233" smilref="Title.smil#_02233"> This generic, iterable implementation of our Stack API is a model for collection ADTs that keep items in an array. It resizes the array to keep the array size within a constant factor of the stack size.</p><p attribs="{'xml:space': 'preserve'}" id="_02234" smilref="Title.smil#_02234" /></level3><level3 id="_00018"><h3 id="ch1-s3-ss19" smilref="Title.smil#ch1-s3-ss19" xml:space="preserve">Linked lists</h3><pagenum id="p155" page="normal" smilref="Title.smil#p155" /><p attribs="{'xml:space': 'preserve'}" id="_02235" smilref="Title.smil#_02235"> 142</p><p attribs="{'xml:space': 'preserve'}" id="_02236" smilref="Title.smil#_02236"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02237" smilref="Title.smil#_02237"> Linked lists Now we consider the use of a fundamental data structure that is an appropriate choice for representing the data in a collection ADT implementation. This is our first example of building a data structure that is not directly supported by the Java language. Our implementation serves as a model for the code that we use for building more complex data structures throughout the book, so you should read this section carefully, even if you have experience working with linked lists.</p><p attribs="{'xml:space': 'preserve'}" id="_02238" smilref="Title.smil#_02238"> Definition. A linked list is a recursive data structure that is either empty (null) or a reference to a node having a generic item and a reference to a linked list.</p><p attribs="{'xml:space': 'preserve'}" id="_02239" smilref="Title.smil#_02239"> The node in this definition is an abstract entity that might hold any kind of data, in addition to the node reference that characterizes its role in building linked lists. As with a recursive program, the concept of a recursive data structure can be a bit mindbending at fi rst, but is of great value because of its simplicity.</p><p attribs="{'xml:space': 'preserve'}" id="_02240" smilref="Title.smil#_02240"> Node record. With object-oriented programming, implementing linked lists is not dif- fi cult. We start with a nested class that defines the node abstraction:</p><p attribs="{'xml:space': 'preserve'}" id="_02241" smilref="Title.smil#_02241"> private class Node { Item item; Node next; }</p><p attribs="{'xml:space': 'preserve'}" id="_02242" smilref="Title.smil#_02242"> A Node has two instance variables: an Item (a parameterized type) and a Node. We define Node within the class where we want to use it, and make it private because it is not for use by clients. As with any data type, we create an object of type Node by invoking the (no-argument) constructor with new Node(). The result is a reference to a Node object whose instance variables are both initialized to the value null. The Item is a placeholder for any data that we might want to structure with a linked list (we will use Java&#8217;s generic mechanism so that it can represent any reference type); the instance variable of type Node characterizes the linked nature of the data structure. To emphasize that we are just using the Node class to structure the data, we define no methods and we refer directly to the instance variables in code: if first is a variable associated with an object of type Node, we can refer to the instance variables with the code first.item and first.next. Classes of this kind are sometimes called records. They do not implement abstract data types because we refer directly to instance variables. However, Node and its client code are in the same class in all of our implementations and not accessible by clients of that class, so we still enjoy the benefits of data abstraction.</p><p attribs="{'xml:space': 'preserve'}" id="_02243" smilref="Title.smil#_02243" /><pagenum id="p156" page="normal" smilref="Title.smil#p156" /><p attribs="{'xml:space': 'preserve'}" id="_02244" smilref="Title.smil#_02244"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02245" smilref="Title.smil#_02245"> 143</p><p attribs="{'xml:space': 'preserve'}" id="_02246" smilref="Title.smil#_02246"> Building a linked list. Now, from the recursive defi nition, we can represent a linked list with a variable of type Node simply by ensuring that its value is either null or a reference to a Node whose next field is a reference to a linked list. For example, to build a linked list that contains the items to, be, and or, we create a Node for each item:</p><p attribs="{'xml:space': 'preserve'}" id="_02247" smilref="Title.smil#_02247"> Node first = new Node(); Node second = new Node(); Node third = new Node();</p><p attribs="{'xml:space': 'preserve'}" id="_02248" smilref="Title.smil#_02248"> and set the item field in each of the nodes to the desired value (for simplicity, these examples assume that Item is String):</p><p attribs="{'xml:space': 'preserve'}" id="_02249" smilref="Title.smil#_02249"> first.item = "to"; second.item = "be"; third.item = "or";</p><p attribs="{'xml:space': 'preserve'}" id="_02250" smilref="Title.smil#_02250"> and set the next fields to build the linked list:</p><p attribs="{'xml:space': 'preserve'}" id="_02251" smilref="Title.smil#_02251"> first.next = second; second.next = third;</p><p attribs="{'xml:space': 'preserve'}" id="_02252" smilref="Title.smil#_02252"> (Note that third.next remains null, the value it was initialized to at the time of creation.)As a result, third is a linked list (it is a reference to a node that has a reference to null, which is the null reference to an empty linked list), and second is a linked list (it is a reference to a node that has a reference to third, which is a linked list), and first is a linked list (it is a reference to a node that has a reference to second, which is a linked list). The code that we will examine does these assignment statements in a different order, depicted in the diagram on this page.</p><p attribs="{'xml:space': 'preserve'}" id="_02253" smilref="Title.smil#_02253"> Node first = new Node(); first.item = "to";</p><p attribs="{'xml:space': 'preserve'}" id="_02254" smilref="Title.smil#_02254"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02255" smilref="Title.smil#_02255"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02256" smilref="Title.smil#_02256"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02257" smilref="Title.smil#_02257"> Node second = new Node(); second.item = "be"; first.next = second;</p><p attribs="{'xml:space': 'preserve'}" id="_02258" smilref="Title.smil#_02258"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02259" smilref="Title.smil#_02259"> second</p><p attribs="{'xml:space': 'preserve'}" id="_02260" smilref="Title.smil#_02260"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02261" smilref="Title.smil#_02261"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02262" smilref="Title.smil#_02262"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02263" smilref="Title.smil#_02263"> Node third = new Node(); third.item = "or"; second.next = third;</p><p attribs="{'xml:space': 'preserve'}" id="_02264" smilref="Title.smil#_02264"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02265" smilref="Title.smil#_02265"> second</p><p attribs="{'xml:space': 'preserve'}" id="_02266" smilref="Title.smil#_02266"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02267" smilref="Title.smil#_02267"> third</p><p attribs="{'xml:space': 'preserve'}" id="_02268" smilref="Title.smil#_02268"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02269" smilref="Title.smil#_02269"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02270" smilref="Title.smil#_02270"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02271" smilref="Title.smil#_02271"> Linking together a list</p><p attribs="{'xml:space': 'preserve'}" id="_02272" smilref="Title.smil#_02272"> A linked list represents a sequence of items. In the example just considered, first represents the sequence to be or. We can also use an array to represent a sequence of items. For example, we could use</p><p attribs="{'xml:space': 'preserve'}" id="_02273" smilref="Title.smil#_02273"> String[] s = { "to", "be", "or" };</p><p attribs="{'xml:space': 'preserve'}" id="_02274" smilref="Title.smil#_02274"> to represent the same sequence of strings. The difference is that it is easier to insert items into the sequence and to remove items from the sequence with linked lists. Next, we consider code to accomplish these tasks.</p><p attribs="{'xml:space': 'preserve'}" id="_02275" smilref="Title.smil#_02275" /><pagenum id="p157" page="normal" smilref="Title.smil#p157" /><p attribs="{'xml:space': 'preserve'}" id="_02276" smilref="Title.smil#_02276"> 144</p><p attribs="{'xml:space': 'preserve'}" id="_02277" smilref="Title.smil#_02277"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02278" smilref="Title.smil#_02278"> When tracing code that uses linked lists and other linked structures, we use a visual representation where </p><p attribs="{'xml:space': 'preserve'}" id="_02279" smilref="Title.smil#_02279"> Insert at the beginning. First, suppose that you want to insert a new node into a linked list. The easiest place to do so is at the beginning of the list. For example, to insert the string not at the beginning of a given linked list whose first node is first, we save first in oldfirst, assign to first a new Node, and assign its item field to not and its next field to oldfirst. This code for inserting a node at the beginning of a linked list involves just a few assignment statements, so the amount of time that it takes is independent of the length of the list.</p><p attribs="{'xml:space': 'preserve'}" id="_02280" smilref="Title.smil#_02280"> save a link to the list</p><p attribs="{'xml:space': 'preserve'}" id="_02281" smilref="Title.smil#_02281"> Node oldfirst = first;</p><p attribs="{'xml:space': 'preserve'}" id="_02282" smilref="Title.smil#_02282"> oldfirst</p><p attribs="{'xml:space': 'preserve'}" id="_02283" smilref="Title.smil#_02283"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02284" smilref="Title.smil#_02284"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02285" smilref="Title.smil#_02285"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02286" smilref="Title.smil#_02286"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02287" smilref="Title.smil#_02287"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02288" smilref="Title.smil#_02288"> create a new node for the beginning</p><p attribs="{'xml:space': 'preserve'}" id="_02289" smilref="Title.smil#_02289"> first = new Node();</p><p attribs="{'xml:space': 'preserve'}" id="_02290" smilref="Title.smil#_02290"> oldfirst</p><p attribs="{'xml:space': 'preserve'}" id="_02291" smilref="Title.smil#_02291"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02292" smilref="Title.smil#_02292"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02293" smilref="Title.smil#_02293"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02294" smilref="Title.smil#_02294"> set the instance variables in the new node</p><p attribs="{'xml:space': 'preserve'}" id="_02295" smilref="Title.smil#_02295"> first.item = "not"; first.next = oldfirst;</p><p attribs="{'xml:space': 'preserve'}" id="_02296" smilref="Title.smil#_02296"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02297" smilref="Title.smil#_02297"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02298" smilref="Title.smil#_02298"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02299" smilref="Title.smil#_02299"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02300" smilref="Title.smil#_02300"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02301" smilref="Title.smil#_02301"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02302" smilref="Title.smil#_02302"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02303" smilref="Title.smil#_02303"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02304" smilref="Title.smil#_02304"> Inserting a new node at the beginning of a linked list</p><p attribs="{'xml:space': 'preserve'}" id="_02305" smilref="Title.smil#_02305" /><pagenum id="p158" page="normal" smilref="Title.smil#p158" /><p attribs="{'xml:space': 'preserve'}" id="_02306" smilref="Title.smil#_02306"> Remove from the beginning. Next, suppose that you</p><p attribs="{'xml:space': 'preserve'}" id="_02307" smilref="Title.smil#_02307"> first = first.next;</p><p attribs="{'xml:space': 'preserve'}" id="_02308" smilref="Title.smil#_02308"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02309" smilref="Title.smil#_02309"> 145</p><p attribs="{'xml:space': 'preserve'}" id="_02310" smilref="Title.smil#_02310"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02311" smilref="Title.smil#_02311"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02312" smilref="Title.smil#_02312"> want to remove the first node from a list. This operation is even easier: simply assign to first the value first.next. Normally, you would retrieve the value of the item (by assigning it to some variable of type Item) before doing this assignment, because once you change the value of first, you may not have any access to the node to which it was referring. Typically, the node object becomes an orphan, and the Java memory management system eventually reclaims the memory it occupies. Again, this operation just involves one assignment statement, so its running time is independent of the length of the list.</p><p attribs="{'xml:space': 'preserve'}" id="_02313" smilref="Title.smil#_02313"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02314" smilref="Title.smil#_02314"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02315" smilref="Title.smil#_02315"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02316" smilref="Title.smil#_02316"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02317" smilref="Title.smil#_02317"> Removing the first node in a linked list</p><p attribs="{'xml:space': 'preserve'}" id="_02318" smilref="Title.smil#_02318"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02319" smilref="Title.smil#_02319"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02320" smilref="Title.smil#_02320"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02321" smilref="Title.smil#_02321"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02322" smilref="Title.smil#_02322"> Insert at the end. How do we add a node to the end of a linked list? To do so, we need a link to the last node in the list, because that node&#8217;s link has to be changed to reference a new node containing the item to be inserted. Maintaining an extra link is not something that should be taken lightly in linked-list code, because every method that modifies the list needs code to check whether that variable needs to be modified (and to make the necessary modi&#64257; cations). For example, the code that we just examined for removing the first node in the list might involve changing the reference to the last node in the list, since when there is only one node in the list, it is both the first one and the last one! Also, this code does not work (it follows a null link) in the case that the list is empty. Details like these make linked-list code notoriously difficult to debug.</p><p attribs="{'xml:space': 'preserve'}" id="_02323" smilref="Title.smil#_02323"> Node last = new Node(); last.item = "not";</p><p attribs="{'xml:space': 'preserve'}" id="_02324" smilref="Title.smil#_02324"> Node oldlast = last;</p><p attribs="{'xml:space': 'preserve'}" id="_02325" smilref="Title.smil#_02325"> create a new node for the end</p><p attribs="{'xml:space': 'preserve'}" id="_02326" smilref="Title.smil#_02326"> save a link to the last node</p><p attribs="{'xml:space': 'preserve'}" id="_02327" smilref="Title.smil#_02327"> oldlast</p><p attribs="{'xml:space': 'preserve'}" id="_02328" smilref="Title.smil#_02328"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02329" smilref="Title.smil#_02329"> last</p><p attribs="{'xml:space': 'preserve'}" id="_02330" smilref="Title.smil#_02330"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02331" smilref="Title.smil#_02331"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02332" smilref="Title.smil#_02332"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02333" smilref="Title.smil#_02333"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02334" smilref="Title.smil#_02334"> Insert/remove at other positions. In sum-</p><p attribs="{'xml:space': 'preserve'}" id="_02335" smilref="Title.smil#_02335"> mary, we have shown that we can implement the following operations on linked lists with just a few instructions, provided that we have access to both a link first to the first element in the list and a link last to the last element in the list: </p><p attribs="{'xml:space': 'preserve'}" id="_02336" smilref="Title.smil#_02336"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02337" smilref="Title.smil#_02337"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02338" smilref="Title.smil#_02338"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02339" smilref="Title.smil#_02339"> oldlast</p><p attribs="{'xml:space': 'preserve'}" id="_02340" smilref="Title.smil#_02340"> last</p><p attribs="{'xml:space': 'preserve'}" id="_02341" smilref="Title.smil#_02341"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02342" smilref="Title.smil#_02342"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02343" smilref="Title.smil#_02343"> link the new node to the end of the list</p><p attribs="{'xml:space': 'preserve'}" id="_02344" smilref="Title.smil#_02344"> oldlast.next = last;</p><p attribs="{'xml:space': 'preserve'}" id="_02345" smilref="Title.smil#_02345"> first</p><p attribs="{'xml:space': 'preserve'}" id="_02346" smilref="Title.smil#_02346"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02347" smilref="Title.smil#_02347"> oldlast</p><p attribs="{'xml:space': 'preserve'}" id="_02348" smilref="Title.smil#_02348"> last</p><p attribs="{'xml:space': 'preserve'}" id="_02349" smilref="Title.smil#_02349"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02350" smilref="Title.smil#_02350"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02351" smilref="Title.smil#_02351"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02352" smilref="Title.smil#_02352"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02353" smilref="Title.smil#_02353"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02354" smilref="Title.smil#_02354"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02355" smilref="Title.smil#_02355"> Inserting a new node at the end of a linked list</p><p attribs="{'xml:space': 'preserve'}" id="_02356" smilref="Title.smil#_02356" /><pagenum id="p159" page="normal" smilref="Title.smil#p159" /><p attribs="{'xml:space': 'preserve'}" id="_02357" smilref="Title.smil#_02357"> 146</p><p attribs="{'xml:space': 'preserve'}" id="_02358" smilref="Title.smil#_02358"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02359" smilref="Title.smil#_02359"> Other operations, such as the following, are not so easily handled: </p><p attribs="{'xml:space': 'preserve'}" id="_02360" smilref="Title.smil#_02360"> Traversal. To examine every item in an array, we use familiar code like the following loop for processing the items in an array a[]:</p><p attribs="{'xml:space': 'preserve'}" id="_02361" smilref="Title.smil#_02361"> for (int i = 0; i &lt; N; i++) { // Process a[i]. }</p><p attribs="{'xml:space': 'preserve'}" id="_02362" smilref="Title.smil#_02362"> There is a corresponding idiom for examining the items in a linked list: We initialize a loop index variable x to reference the first Node of the linked list. Then we find the item associated with x by accessing x.item, and then update x to refer to the next Node in the linked list, assigning to it the value of x.next and repeating this process until x is null (which indicates that we have reached the end of the linked list). This process is known as traversing the list and is succinctly expressed in code like the following loop for processing the items in a linked list whose first item is associated with the variable first:</p><p attribs="{'xml:space': 'preserve'}" id="_02363" smilref="Title.smil#_02363"> for (Node x = first; x != null; x = x.next) { // Process x.item. }</p><p attribs="{'xml:space': 'preserve'}" id="_02364" smilref="Title.smil#_02364"> This idiom is as natural as the standard idiom for iterating through the items in an ar- ray. In our implementations, we use it as the basis for iterators for providing client code the capability of iterating through the items, without having to know the details of the linked-list implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_02365" smilref="Title.smil#_02365" /><pagenum id="p160" page="normal" smilref="Title.smil#p160" /><p attribs="{'xml:space': 'preserve'}" id="_02366" smilref="Title.smil#_02366"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02367" smilref="Title.smil#_02367"> 147</p><p attribs="{'xml:space': 'preserve'}" id="_02368" smilref="Title.smil#_02368"> Stack implementation. Given these preliminaries, developing an implementation for our Stack API is straightforward, as shown in Algorithm 1.2 on page 149. It maintains the stack as a linked list, with the top of the stack at the beginning, referenced by an instance variable first. Thus, to push() an item, we add it to the beginning of the list, using the code discussed on page 144 and to pop() an item, we remove it from the beginning of the list, using the code discussed on page 145. To implement size(), we keep track of the number of items in an instance variable N, incrementing N when we push and decrementing N when we pop. To implement isEmpty() we check whether first is null (alternatively, we could check whether N is 0). The implementation uses the generic type Item&#8212;you can think of the code &lt;Item&gt; after the class name as meaning that any occurrence of Item in the implementation will be replaced by a client-supplied data-type name (see page 134). For now, we omit the code to support iteration, which we consider on page 155. A trace for the test client that we have been using is shown on the next page. This use of linked lists achieves our optimum design goals: </p><p attribs="{'xml:space': 'preserve'}" id="_02369" smilref="Title.smil#_02369"> public static void main(String[] args) { // Create a stack and push/pop strings as directed on StdIn.</p><p attribs="{'xml:space': 'preserve'}" id="_02370" smilref="Title.smil#_02370"> Stack&lt;String&gt; s = new Stack&lt;String&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_02371" smilref="Title.smil#_02371"> while (!StdIn.isEmpty()) { String item = StdIn.readString(); if (!item.equals("-")) s.push(item); else if (!s.isEmpty()) StdOut.print(s.pop() + " "); }</p><p attribs="{'xml:space': 'preserve'}" id="_02372" smilref="Title.smil#_02372"> StdOut.println("(" + s.size() + " left on stack)"); }</p><p attribs="{'xml:space': 'preserve'}" id="_02373" smilref="Title.smil#_02373"> Test client for Stack</p><p attribs="{'xml:space': 'preserve'}" id="_02374" smilref="Title.smil#_02374" /><pagenum id="p161" page="normal" smilref="Title.smil#p161" /><p attribs="{'xml:space': 'preserve'}" id="_02375" smilref="Title.smil#_02375"> 148</p><p attribs="{'xml:space': 'preserve'}" id="_02376" smilref="Title.smil#_02376"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02377" smilref="Title.smil#_02377"> StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_02378" smilref="Title.smil#_02378"> StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_02379" smilref="Title.smil#_02379"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02380" smilref="Title.smil#_02380"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02381" smilref="Title.smil#_02381"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02382" smilref="Title.smil#_02382"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02383" smilref="Title.smil#_02383"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02384" smilref="Title.smil#_02384"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02385" smilref="Title.smil#_02385"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02386" smilref="Title.smil#_02386"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02387" smilref="Title.smil#_02387"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02388" smilref="Title.smil#_02388"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02389" smilref="Title.smil#_02389"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02390" smilref="Title.smil#_02390"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02391" smilref="Title.smil#_02391"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02392" smilref="Title.smil#_02392"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02393" smilref="Title.smil#_02393"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02394" smilref="Title.smil#_02394"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02395" smilref="Title.smil#_02395"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02396" smilref="Title.smil#_02396"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02397" smilref="Title.smil#_02397"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02398" smilref="Title.smil#_02398"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02399" smilref="Title.smil#_02399"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02400" smilref="Title.smil#_02400"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02401" smilref="Title.smil#_02401"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02402" smilref="Title.smil#_02402"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02403" smilref="Title.smil#_02403"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02404" smilref="Title.smil#_02404"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02405" smilref="Title.smil#_02405"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02406" smilref="Title.smil#_02406"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02407" smilref="Title.smil#_02407"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02408" smilref="Title.smil#_02408"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02409" smilref="Title.smil#_02409"> is</p><p attribs="{'xml:space': 'preserve'}" id="_02410" smilref="Title.smil#_02410"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02411" smilref="Title.smil#_02411"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02412" smilref="Title.smil#_02412"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02413" smilref="Title.smil#_02413"> is</p><p attribs="{'xml:space': 'preserve'}" id="_02414" smilref="Title.smil#_02414"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02415" smilref="Title.smil#_02415"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02416" smilref="Title.smil#_02416"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02417" smilref="Title.smil#_02417"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02418" smilref="Title.smil#_02418"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02419" smilref="Title.smil#_02419"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02420" smilref="Title.smil#_02420"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02421" smilref="Title.smil#_02421"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02422" smilref="Title.smil#_02422"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02423" smilref="Title.smil#_02423"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02424" smilref="Title.smil#_02424"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02425" smilref="Title.smil#_02425"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02426" smilref="Title.smil#_02426"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02427" smilref="Title.smil#_02427"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02428" smilref="Title.smil#_02428"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02429" smilref="Title.smil#_02429"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02430" smilref="Title.smil#_02430"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02431" smilref="Title.smil#_02431"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02432" smilref="Title.smil#_02432"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02433" smilref="Title.smil#_02433"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02434" smilref="Title.smil#_02434"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02435" smilref="Title.smil#_02435"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02436" smilref="Title.smil#_02436"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02437" smilref="Title.smil#_02437"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02438" smilref="Title.smil#_02438"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02439" smilref="Title.smil#_02439"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02440" smilref="Title.smil#_02440"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02441" smilref="Title.smil#_02441"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02442" smilref="Title.smil#_02442"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02443" smilref="Title.smil#_02443"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02444" smilref="Title.smil#_02444"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02445" smilref="Title.smil#_02445"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02446" smilref="Title.smil#_02446"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02447" smilref="Title.smil#_02447"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02448" smilref="Title.smil#_02448"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02449" smilref="Title.smil#_02449"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02450" smilref="Title.smil#_02450"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02451" smilref="Title.smil#_02451"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02452" smilref="Title.smil#_02452"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02453" smilref="Title.smil#_02453"> Trace of Stack development client</p><p attribs="{'xml:space': 'preserve'}" id="_02454" smilref="Title.smil#_02454" /><pagenum id="p162" page="normal" smilref="Title.smil#p162" /><p attribs="{'xml:space': 'preserve'}" id="_02455" smilref="Title.smil#_02455"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02456" smilref="Title.smil#_02456"> 149</p><p attribs="{'xml:space': 'preserve'}" id="_02457" smilref="Title.smil#_02457"> ALGORITHM 1.2 Pushdown stack (linked-list implementation)</p><p attribs="{'xml:space': 'preserve'}" id="_02458" smilref="Title.smil#_02458"> public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt; { private Node first; // top of stack (most recently added node) private int N; // number of items</p><p attribs="{'xml:space': 'preserve'}" id="_02459" smilref="Title.smil#_02459"> private class Node { // nested class to define nodes Item item; Node next; }</p><p attribs="{'xml:space': 'preserve'}" id="_02460" smilref="Title.smil#_02460"> public boolean isEmpty() { return first == null; } public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_02461" smilref="Title.smil#_02461"> public void push(Item item) { // Add item to top of stack. Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; N++; }</p><p attribs="{'xml:space': 'preserve'}" id="_02462" smilref="Title.smil#_02462"> public Item pop() { // Remove item from top of stack. Item item = first.item; first = first.next; N--; return item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02463" smilref="Title.smil#_02463"> // See page 155 for iterator() implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_02464" smilref="Title.smil#_02464"> // See page 147 for test client main().</p><p attribs="{'xml:space': 'preserve'}" id="_02465" smilref="Title.smil#_02465"> }</p><p attribs="{'xml:space': 'preserve'}" id="_02466" smilref="Title.smil#_02466"> This generic Stack implementation is based on a linked-list data structure. It can be used to create stacks containing any type of data. To support iteration, add the highlighted code described for Bag on page 155.</p><p attribs="{'xml:space': 'preserve'}" id="_02467" smilref="Title.smil#_02467"> % more tobe.txt to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02468" smilref="Title.smil#_02468"> % java Stack &lt; tobe.txt to be not that or be (2 left on stack)</p><p attribs="{'xml:space': 'preserve'}" id="_02469" smilref="Title.smil#_02469" /><pagenum id="p163" page="normal" smilref="Title.smil#p163" /><p attribs="{'xml:space': 'preserve'}" id="_02470" smilref="Title.smil#_02470"> 150</p><p attribs="{'xml:space': 'preserve'}" id="_02471" smilref="Title.smil#_02471"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02472" smilref="Title.smil#_02472"> Queue implementation. An implementation of our Queue API based on the linked- list data structure is also straightforward, as shown in Algorithm 1.3 on the facing page. It maintains the queue as a linked list in order from least recently to most recently added items, with the beginning of the queue referenced by an instance variable first and the end of the queue referenced by an instance variable last. Thus, to enqueue() an item, we add it to the end of the list (using the code discussed on page 145, augmented to set both first and last to refer to the new node when the list is empty) and to dequeue() an item, we remove it from the beginning of the list (using the same code as for pop() in Stack, augmented to update last when the list becomes empty). The implementations of size() and isEmpty() are the same as for Stack. As with Stack the implementation uses the generic type parameter Item, and we omit the code to support iteration, which we consider in our Bag implementation on page 155. A development client similar to the one we used for Stack is shown below, and the trace for this client is shown on the following page. This implementation uses the same data structure as does Stack&#8212;a linked list&#8212;but it implements different algorithms for adding and removing items, which make the difference between LIFO and FIFO for the client. Again, the use of linked lists achieves our optimum design goals: it can be used for any type of data, the space required is proportional to the number of items in the collection, and the time required per operation is always independent of the size of the collection.</p><p attribs="{'xml:space': 'preserve'}" id="_02473" smilref="Title.smil#_02473"> public static void main(String[] args) { // Create a queue and enqueue/dequeue strings.</p><p attribs="{'xml:space': 'preserve'}" id="_02474" smilref="Title.smil#_02474"> Queue&lt;String&gt; q = new Queue&lt;String&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_02475" smilref="Title.smil#_02475"> while (!StdIn.isEmpty()) { String item = StdIn.readString(); if (!item.equals("-")) q.enqueue(item); else if (!q.isEmpty()) StdOut.print(q.dequeue() + " "); }</p><p attribs="{'xml:space': 'preserve'}" id="_02476" smilref="Title.smil#_02476"> StdOut.println("(" + q.size() + " left on queue)"); }</p><p attribs="{'xml:space': 'preserve'}" id="_02477" smilref="Title.smil#_02477"> Test client for Queue</p><p attribs="{'xml:space': 'preserve'}" id="_02478" smilref="Title.smil#_02478"> % more tobe.txt to be or not to be - that - - is</p><p attribs="{'xml:space': 'preserve'}" id="_02479" smilref="Title.smil#_02479"> % java Queue &lt; tobe.txt to be or not to be (2 left on queue)</p><p attribs="{'xml:space': 'preserve'}" id="_02480" smilref="Title.smil#_02480" /><pagenum id="p164" page="normal" smilref="Title.smil#p164" /><p attribs="{'xml:space': 'preserve'}" id="_02481" smilref="Title.smil#_02481"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02482" smilref="Title.smil#_02482"> 151</p><p attribs="{'xml:space': 'preserve'}" id="_02483" smilref="Title.smil#_02483"> ALGORITHM 1.3 FIFO queue</p><p attribs="{'xml:space': 'preserve'}" id="_02484" smilref="Title.smil#_02484"> public class Queue&lt;Item&gt; implements Iterable&lt;Item&gt; { private Node first; // link to least recently added node private Node last; // link to most recently added node private int N; // number of items on the queue</p><p attribs="{'xml:space': 'preserve'}" id="_02485" smilref="Title.smil#_02485"> private class Node { // nested class to define nodes Item item; Node next; }</p><p attribs="{'xml:space': 'preserve'}" id="_02486" smilref="Title.smil#_02486"> public boolean isEmpty() { return first == null; } public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_02487" smilref="Title.smil#_02487"> public void enqueue(Item item) { // Add item to the end of the list. Node oldlast = last; last = new Node(); last.item = item; last.next = null; if (isEmpty()) first = last; else oldlast.next = last; N++; }</p><p attribs="{'xml:space': 'preserve'}" id="_02488" smilref="Title.smil#_02488"> public Item dequeue() { // Remove item from the beginning of the list. Item item = first.item; first = first.next; N--; if (isEmpty()) last = null; return item; }</p><p attribs="{'xml:space': 'preserve'}" id="_02489" smilref="Title.smil#_02489"> // See page 155 for iterator() implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_02490" smilref="Title.smil#_02490"> // See page 150 for test client main().</p><p attribs="{'xml:space': 'preserve'}" id="_02491" smilref="Title.smil#_02491"> }</p><p attribs="{'xml:space': 'preserve'}" id="_02492" smilref="Title.smil#_02492"> This generic Queue implementation is based on a linked-list data structure. It can be used to create queues containing any type of data. To support iteration, add the highlighted code described for Bag on page 155.</p><p attribs="{'xml:space': 'preserve'}" id="_02493" smilref="Title.smil#_02493" /><pagenum id="p165" page="normal" smilref="Title.smil#p165" /><p attribs="{'xml:space': 'preserve'}" id="_02494" smilref="Title.smil#_02494"> 152</p><p attribs="{'xml:space': 'preserve'}" id="_02495" smilref="Title.smil#_02495"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02496" smilref="Title.smil#_02496"> StdIn</p><p attribs="{'xml:space': 'preserve'}" id="_02497" smilref="Title.smil#_02497"> StdOut</p><p attribs="{'xml:space': 'preserve'}" id="_02498" smilref="Title.smil#_02498"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02499" smilref="Title.smil#_02499"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02500" smilref="Title.smil#_02500"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02501" smilref="Title.smil#_02501"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02502" smilref="Title.smil#_02502"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02503" smilref="Title.smil#_02503"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02504" smilref="Title.smil#_02504"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02505" smilref="Title.smil#_02505"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02506" smilref="Title.smil#_02506"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02507" smilref="Title.smil#_02507"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02508" smilref="Title.smil#_02508"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02509" smilref="Title.smil#_02509"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02510" smilref="Title.smil#_02510"> -</p><p attribs="{'xml:space': 'preserve'}" id="_02511" smilref="Title.smil#_02511"> is</p><p attribs="{'xml:space': 'preserve'}" id="_02512" smilref="Title.smil#_02512"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02513" smilref="Title.smil#_02513"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02514" smilref="Title.smil#_02514"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02515" smilref="Title.smil#_02515"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02516" smilref="Title.smil#_02516"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02517" smilref="Title.smil#_02517"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02518" smilref="Title.smil#_02518"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02519" smilref="Title.smil#_02519"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02520" smilref="Title.smil#_02520"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02521" smilref="Title.smil#_02521"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02522" smilref="Title.smil#_02522"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02523" smilref="Title.smil#_02523"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02524" smilref="Title.smil#_02524"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02525" smilref="Title.smil#_02525"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02526" smilref="Title.smil#_02526"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02527" smilref="Title.smil#_02527"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02528" smilref="Title.smil#_02528"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02529" smilref="Title.smil#_02529"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02530" smilref="Title.smil#_02530"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02531" smilref="Title.smil#_02531"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02532" smilref="Title.smil#_02532"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02533" smilref="Title.smil#_02533"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02534" smilref="Title.smil#_02534"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02535" smilref="Title.smil#_02535"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02536" smilref="Title.smil#_02536"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02537" smilref="Title.smil#_02537"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02538" smilref="Title.smil#_02538"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02539" smilref="Title.smil#_02539"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02540" smilref="Title.smil#_02540"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02541" smilref="Title.smil#_02541"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02542" smilref="Title.smil#_02542"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02543" smilref="Title.smil#_02543"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02544" smilref="Title.smil#_02544"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02545" smilref="Title.smil#_02545"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02546" smilref="Title.smil#_02546"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02547" smilref="Title.smil#_02547"> is</p><p attribs="{'xml:space': 'preserve'}" id="_02548" smilref="Title.smil#_02548"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02549" smilref="Title.smil#_02549"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02550" smilref="Title.smil#_02550"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02551" smilref="Title.smil#_02551"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02552" smilref="Title.smil#_02552"> or</p><p attribs="{'xml:space': 'preserve'}" id="_02553" smilref="Title.smil#_02553"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02554" smilref="Title.smil#_02554"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02555" smilref="Title.smil#_02555"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02556" smilref="Title.smil#_02556"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02557" smilref="Title.smil#_02557"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02558" smilref="Title.smil#_02558"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02559" smilref="Title.smil#_02559"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02560" smilref="Title.smil#_02560"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02561" smilref="Title.smil#_02561"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02562" smilref="Title.smil#_02562"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02563" smilref="Title.smil#_02563"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02564" smilref="Title.smil#_02564"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02565" smilref="Title.smil#_02565"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02566" smilref="Title.smil#_02566"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02567" smilref="Title.smil#_02567"> not</p><p attribs="{'xml:space': 'preserve'}" id="_02568" smilref="Title.smil#_02568"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02569" smilref="Title.smil#_02569"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02570" smilref="Title.smil#_02570"> to</p><p attribs="{'xml:space': 'preserve'}" id="_02571" smilref="Title.smil#_02571"> be</p><p attribs="{'xml:space': 'preserve'}" id="_02572" smilref="Title.smil#_02572"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02573" smilref="Title.smil#_02573"> that</p><p attribs="{'xml:space': 'preserve'}" id="_02574" smilref="Title.smil#_02574"> null</p><p attribs="{'xml:space': 'preserve'}" id="_02575" smilref="Title.smil#_02575"> Trace of Queue development client</p><p attribs="{'xml:space': 'preserve'}" id="_02576" smilref="Title.smil#_02576" /><pagenum id="p166" page="normal" smilref="Title.smil#p166" /><p attribs="{'xml:space': 'preserve'}" id="_02577" smilref="Title.smil#_02577"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02578" smilref="Title.smil#_02578"> 153</p><p attribs="{'xml:space': 'preserve'}" id="_02579" smilref="Title.smil#_02579"> Linked lists are a fundamental alternative to arrays for structuring a collection</p><p attribs="{'xml:space': 'preserve'}" id="_02580" smilref="Title.smil#_02580"> of data. From a historical perspective, this alternative has been available to programmers for many decades. Indeed, a landmark in the history of programming languages was the development of LISP by John McCarthy in the 1950s, where linked lists are the primary structure for programs and data. Programming with linked lists presents all sorts of challenges and is notoriously difficult to debug, as you can see in the exercises. In modern code, the use of safe pointers, automatic garbage collection (see page 111), and ADTs allows us to encapsulate list-processing code in just a few classes such as the ones presented here.</p><p attribs="{'xml:space': 'preserve'}" id="_02581" smilref="Title.smil#_02581" /><pagenum id="p167" page="normal" smilref="Title.smil#p167" /><p attribs="{'xml:space': 'preserve'}" id="_02582" smilref="Title.smil#_02582"> 154</p><p attribs="{'xml:space': 'preserve'}" id="_02583" smilref="Title.smil#_02583"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02584" smilref="Title.smil#_02584"> Bag implementation. Implementing our Bag API using a linked-list data structure is simply a matter of changing the name of push() in Stack to add() and removing the implementation of pop(), as shown in Algorithm 1.4 on the facing page (doing the same for Queue would also be effective but requires a bit more code). This implementation also highlights the code needed to make Stack, Queue, and Bag all iterable, by traversing the list. For Stack the list is in LIFO order; for Queue it is in FIFO order; and for Bag it happens to be in LIFO order, but the order is not relevant. As detailed in the highlighted code in Algorithm 1.4, to implement iteration in a collection, the first step is to include</p><p attribs="{'xml:space': 'preserve'}" id="_02585" smilref="Title.smil#_02585"> import java.util.Iterator;</p><p attribs="{'xml:space': 'preserve'}" id="_02586" smilref="Title.smil#_02586"> so that our code can refer to Java&#8217;s Iterator interface. The second step is to add</p><p attribs="{'xml:space': 'preserve'}" id="_02587" smilref="Title.smil#_02587"> implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02588" smilref="Title.smil#_02588"> to the class declaration, a promise to provide an iterator() method. The iterator() method itself simply returns an object from a class that implements the Iterator interface:</p><p attribs="{'xml:space': 'preserve'}" id="_02589" smilref="Title.smil#_02589"> public Iterator&lt;Item&gt; iterator() { return new ListIterator(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02590" smilref="Title.smil#_02590"> This code is a promise to implement a class that implements the hasNext(), next(), and remove() methods that are called when a client uses the foreach construct. To implement these methods, the nested class ListIterator in Algorithm 1.4 maintains an instance variable current that keeps track of the current node on the list. Then the hasNext() method tests if current is null, and the next() method saves a reference to the current item, updates current to refer to the next node on the list, and returns the saved reference.</p><p attribs="{'xml:space': 'preserve'}" id="_02591" smilref="Title.smil#_02591" /><pagenum id="p168" page="normal" smilref="Title.smil#p168" /><p attribs="{'xml:space': 'preserve'}" id="_02592" smilref="Title.smil#_02592"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02593" smilref="Title.smil#_02593"> 155</p><p attribs="{'xml:space': 'preserve'}" id="_02594" smilref="Title.smil#_02594"> ALGORITHM 1.4 Bag</p><p attribs="{'xml:space': 'preserve'}" id="_02595" smilref="Title.smil#_02595"> import java.util.Iterator;</p><p attribs="{'xml:space': 'preserve'}" id="_02596" smilref="Title.smil#_02596"> public class Bag&lt;Item&gt; implements Iterable&lt;Item&gt; { private Node first; // first node in list</p><p attribs="{'xml:space': 'preserve'}" id="_02597" smilref="Title.smil#_02597"> private class Node { Item item; Node next; } public void add(Item item) { // same as push() in Stack Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; } public Iterator&lt;Item&gt; iterator() { return new ListIterator(); } private class ListIterator implements Iterator&lt;Item&gt; { private Node current = first;</p><p attribs="{'xml:space': 'preserve'}" id="_02598" smilref="Title.smil#_02598"> public boolean hasNext() { return current != null; } public void remove() { } public Item next() { Item item = current.item; current = current.next; return item; } } }</p><p attribs="{'xml:space': 'preserve'}" id="_02599" smilref="Title.smil#_02599"> This Bag implementation maintains a linked list of the items provided in calls to add(). Code for isEmpty() and size() is the same as in Stack and is omitted. The iterator traverses the list, maintaining the current node in current. We can make Stack and Queue iterable by adding the code highlighted in red to Algorithms 1.1 and 1.2, because they use the same underlying data structure and Stack and Queue maintain the list in LIFO and FIFO order, respectively.</p><p attribs="{'xml:space': 'preserve'}" id="_02600" smilref="Title.smil#_02600" /><pagenum id="p169" page="normal" smilref="Title.smil#p169" /><p attribs="{'xml:space': 'preserve'}" id="_02601" smilref="Title.smil#_02601"> 156</p><p attribs="{'xml:space': 'preserve'}" id="_02602" smilref="Title.smil#_02602"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02603" smilref="Title.smil#_02603"> Overview The implementations of bags, queues, and stacks that support generics and iteration that we have considered in this section provide a level of abstraction that allows us to write compact client programs that manipulate collections of objects. De- tailed understanding of these ADTs is important as an introduction to the study of algorithms and data structures for three reasons. First, we use these data types as building blocks in higher-level data structures throughout this book. Second, they illustrate the interplay between data structures and algorithms and the challenge of simultaneously achieving natural performance goals that may con&#64258; ict. Third, the focus of several of our implementations is on ADTs that support more powerful operations on collections of objects, and we use the implementations here as starting points.</p><p attribs="{'xml:space': 'preserve'}" id="_02604" smilref="Title.smil#_02604"> data structure</p><p attribs="{'xml:space': 'preserve'}" id="_02605" smilref="Title.smil#_02605"> advantage</p><p attribs="{'xml:space': 'preserve'}" id="_02606" smilref="Title.smil#_02606"> disadvantage</p><p attribs="{'xml:space': 'preserve'}" id="_02607" smilref="Title.smil#_02607"> array</p><p attribs="{'xml:space': 'preserve'}" id="_02608" smilref="Title.smil#_02608"> linked list</p><p attribs="{'xml:space': 'preserve'}" id="_02609" smilref="Title.smil#_02609"> Data structures. We now have two ways to represent collections of objects, arrays and linked lists. Arrays are built in to Java; linked lists are easy to build with standard Java records. These two alternatives, often referred to as sequential allocation and linked al- location, are fundamental. Later in the book, we develop ADT implementations that combine and extend these basic structures in numerous ways. One important extension is to data structures with multiple links. For example, our focus in Sections 3.2 and 3.3 is on data structures known as binary trees that are built from nodes that each have two links. Another important extension is to compose data structures: we can have a bag of stacks, a queue of ar- rays, and so forth. For example, our focus in Chapter 4 is on graphs, which we represent as arrays of bags. It is very easy to define data structures of arbitrary complexity in this way : one important reason for our focus on abstract data types is an attempt to control such complexity.</p><p attribs="{'xml:space': 'preserve'}" id="_02610" smilref="Title.smil#_02610"> index provides immediate access to any item uses space proportional to size</p><p attribs="{'xml:space': 'preserve'}" id="_02611" smilref="Title.smil#_02611"> need to know size on initialization</p><p attribs="{'xml:space': 'preserve'}" id="_02612" smilref="Title.smil#_02612"> need reference to access an item</p><p attribs="{'xml:space': 'preserve'}" id="_02613" smilref="Title.smil#_02613"> Fundamental data structures</p><p attribs="{'xml:space': 'preserve'}" id="_02614" smilref="Title.smil#_02614" /><pagenum id="p170" page="normal" smilref="Title.smil#p170" /><p attribs="{'xml:space': 'preserve'}" id="_02615" smilref="Title.smil#_02615"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02616" smilref="Title.smil#_02616"> 157</p><p attribs="{'xml:space': 'preserve'}" id="_02617" smilref="Title.smil#_02617"> Our treatment of BAGS, queues, and STACKS in this section is a prototypical ex-</p><p attribs="{'xml:space': 'preserve'}" id="_02618" smilref="Title.smil#_02618"> ample of the approach that we use throughout this book to describe data structures and algorithms. In approaching a new applications domain, we identify computational challenges and use data abstraction to address them, proceeding as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_02619" smilref="Title.smil#_02619"> data structure</p><p attribs="{'xml:space': 'preserve'}" id="_02620" smilref="Title.smil#_02620"> section</p><p attribs="{'xml:space': 'preserve'}" id="_02621" smilref="Title.smil#_02621"> ADT</p><p attribs="{'xml:space': 'preserve'}" id="_02622" smilref="Title.smil#_02622"> representation</p><p attribs="{'xml:space': 'preserve'}" id="_02623" smilref="Title.smil#_02623"> parent-link tree</p><p attribs="{'xml:space': 'preserve'}" id="_02624" smilref="Title.smil#_02624"> 1.5</p><p attribs="{'xml:space': 'preserve'}" id="_02625" smilref="Title.smil#_02625"> UnionFind</p><p attribs="{'xml:space': 'preserve'}" id="_02626" smilref="Title.smil#_02626"> array of integers</p><p attribs="{'xml:space': 'preserve'}" id="_02627" smilref="Title.smil#_02627"> binary search tree</p><p attribs="{'xml:space': 'preserve'}" id="_02628" smilref="Title.smil#_02628"> 3.2, 3.3</p><p attribs="{'xml:space': 'preserve'}" id="_02629" smilref="Title.smil#_02629"> string</p><p attribs="{'xml:space': 'preserve'}" id="_02630" smilref="Title.smil#_02630"> binary heap</p><p attribs="{'xml:space': 'preserve'}" id="_02631" smilref="Title.smil#_02631"> hash table (separate chaining) hash table (linear probing)</p><p attribs="{'xml:space': 'preserve'}" id="_02632" smilref="Title.smil#_02632"> 5.1</p><p attribs="{'xml:space': 'preserve'}" id="_02633" smilref="Title.smil#_02633"> 2.4</p><p attribs="{'xml:space': 'preserve'}" id="_02634" smilref="Title.smil#_02634"> 3.4</p><p attribs="{'xml:space': 'preserve'}" id="_02635" smilref="Title.smil#_02635"> 3.4</p><p attribs="{'xml:space': 'preserve'}" id="_02636" smilref="Title.smil#_02636"> graph adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_02637" smilref="Title.smil#_02637"> 4.1, 4.2</p><p attribs="{'xml:space': 'preserve'}" id="_02638" smilref="Title.smil#_02638"> trie</p><p attribs="{'xml:space': 'preserve'}" id="_02639" smilref="Title.smil#_02639"> ternary search trie</p><p attribs="{'xml:space': 'preserve'}" id="_02640" smilref="Title.smil#_02640"> 5.2</p><p attribs="{'xml:space': 'preserve'}" id="_02641" smilref="Title.smil#_02641"> 5.3</p><p attribs="{'xml:space': 'preserve'}" id="_02642" smilref="Title.smil#_02642"> BST</p><p attribs="{'xml:space': 'preserve'}" id="_02643" smilref="Title.smil#_02643"> String</p><p attribs="{'xml:space': 'preserve'}" id="_02644" smilref="Title.smil#_02644"> PQ</p><p attribs="{'xml:space': 'preserve'}" id="_02645" smilref="Title.smil#_02645"> two links per node</p><p attribs="{'xml:space': 'preserve'}" id="_02646" smilref="Title.smil#_02646"> array, off set, and length</p><p attribs="{'xml:space': 'preserve'}" id="_02647" smilref="Title.smil#_02647"> array of objects</p><p attribs="{'xml:space': 'preserve'}" id="_02648" smilref="Title.smil#_02648"> SeparateChainingHashST</p><p attribs="{'xml:space': 'preserve'}" id="_02649" smilref="Title.smil#_02649"> arrays of linked lists</p><p attribs="{'xml:space': 'preserve'}" id="_02650" smilref="Title.smil#_02650"> LinearProbingHashST</p><p attribs="{'xml:space': 'preserve'}" id="_02651" smilref="Title.smil#_02651"> two arrays of objects</p><p attribs="{'xml:space': 'preserve'}" id="_02652" smilref="Title.smil#_02652"> Graph</p><p attribs="{'xml:space': 'preserve'}" id="_02653" smilref="Title.smil#_02653"> TrieST</p><p attribs="{'xml:space': 'preserve'}" id="_02654" smilref="Title.smil#_02654"> TST</p><p attribs="{'xml:space': 'preserve'}" id="_02655" smilref="Title.smil#_02655"> array of Bag objects</p><p attribs="{'xml:space': 'preserve'}" id="_02656" smilref="Title.smil#_02656"> node with array of links</p><p attribs="{'xml:space': 'preserve'}" id="_02657" smilref="Title.smil#_02657"> three links per node</p><p attribs="{'xml:space': 'preserve'}" id="_02658" smilref="Title.smil#_02658"> Examples of data structures developed in this book</p><p attribs="{'xml:space': 'preserve'}" id="_02659" smilref="Title.smil#_02659" /><pagenum id="p171" page="normal" smilref="Title.smil#p171" /><p attribs="{'xml:space': 'preserve'}" id="_02660" smilref="Title.smil#_02660"> 158</p><p attribs="{'xml:space': 'preserve'}" id="_02661" smilref="Title.smil#_02661"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02662" smilref="Title.smil#_02662"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_02663" smilref="Title.smil#_02663"> Q. Not all programming languages have generics, even early versions of Java. What are the alternatives? A. One alternative is to maintain a different implementation for each type of data, as mentioned in the text. Another is to build a stack of Object values, then cast to the desired type in client code for pop(). The problem with this approach is that type mismatch errors cannot be detected until run time. But with generics, if you write code to push an object of the wrong type on the stack, like this:</p><p attribs="{'xml:space': 'preserve'}" id="_02664" smilref="Title.smil#_02664"> Stack&lt;Apple&gt; stack = new Stack&lt;Apple&gt;(); Apple a = new Apple(); ... Orange b = new Orange(); ... stack.push(a); ... stack.push(b); // compile-time error</p><p attribs="{'xml:space': 'preserve'}" id="_02665" smilref="Title.smil#_02665"> you will get a compile-time error:</p><p attribs="{'xml:space': 'preserve'}" id="_02666" smilref="Title.smil#_02666"> push(Apple) in Stack&lt;Apple&gt; cannot be applied to (Orange)</p><p attribs="{'xml:space': 'preserve'}" id="_02667" smilref="Title.smil#_02667"> This ability to discover such errors at compile time is reason enough to use generics. Q. Why does Java disallow generic arrays? A. Experts still debate this point. You might need to become one to understand it! For starters, learn about covariant arrays and type erasure. Q. How do I create an array of stacks of strings? A. Use a cast, such as the following:</p><p attribs="{'xml:space': 'preserve'}" id="_02668" smilref="Title.smil#_02668"> Stack&lt;String&gt;[] a = (Stack&lt;String&gt;[]) new Stack[N];</p><p attribs="{'xml:space': 'preserve'}" id="_02669" smilref="Title.smil#_02669"> Warning : This cast, in client code, is different from the one described on page 134. You might have expected to use Object instead of Stack. When using generics, Java checks for type safety at compile time, but throws away that information at run time, so it is left with Stack&lt;Object&gt;[] or just Stack[], for short, which we must cast to</p><p attribs="{'xml:space': 'preserve'}" id="_02670" smilref="Title.smil#_02670"> Stack&lt;String&gt;[].</p><p attribs="{'xml:space': 'preserve'}" id="_02671" smilref="Title.smil#_02671"> Q. What happens if my program calls pop() for an empty stack?</p><p attribs="{'xml:space': 'preserve'}" id="_02672" smilref="Title.smil#_02672" /><pagenum id="p172" page="normal" smilref="Title.smil#p172" /><p attribs="{'xml:space': 'preserve'}" id="_02673" smilref="Title.smil#_02673"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02674" smilref="Title.smil#_02674"> 159</p><p attribs="{'xml:space': 'preserve'}" id="_02675" smilref="Title.smil#_02675"> A. It depends on the implementation. For our implementation on page 149, you will get a NullPointerException. In our implementations on the booksite, we throw a runtime exception to help users pinpoint the error. Generally, including as many such checks as possible is wise in code that is likely to be used by many people. Q. Why do we care about resizing arrays, when we have linked lists? A. We will see several examples of ADT implementations that need to use arrays to perform other operations that are not easily supported with linked lists. ResizingArrayStack is a model for keeping their memory usage under control. Q. Why declare Node as a nested class? Why private? A. By declaring the nested class Node to be private, we restrict access to methods and instance variables within the enclosing class. One characteristic of a private nested class is that its instance variables can be directly accessed from within the enclosing class but nowhere else, so there is no need to declare the instance variables public or private. Note for experts : A nested class that is not static is known as an inner class, so technically our Node classes are inner classes, though the ones that are not generic could be static. Q. When I type javac Stack.java to run Algorithm 1.2 and similar programs, I find Stack.class and a file Stack$Node.class. What is the purpose of that second one? A. That file is for the inner class Node. Java&#8217;s naming convention is to use $ to separate the name of the outer class from the inner class. Q. Are there Java libraries for stacks and queues? A. Yes and no. Java has a built-in library called java.util.Stack, but you should avoid using it when you want a stack. It has several additional operations that are not normally associated with a stack, e.g., getting the ith element. It also allows adding an element to the bottom of the stack (instead of the top), so it can implement a queue! Although having such extra operations may appear to be a bonus, it is actually a curse. We use data types not just as libraries of all the operations we can imagine, but also as a mechanism to precisely specify the operations we need. The prime benefit of doing so is that the system can prevent us from performing operations that we do not actually</p><p attribs="{'xml:space': 'preserve'}" id="_02676" smilref="Title.smil#_02676" /><pagenum id="p173" page="normal" smilref="Title.smil#p173" /><p attribs="{'xml:space': 'preserve'}" id="_02677" smilref="Title.smil#_02677"> 160</p><p attribs="{'xml:space': 'preserve'}" id="_02678" smilref="Title.smil#_02678"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02679" smilref="Title.smil#_02679"> Q &amp; A (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_02680" smilref="Title.smil#_02680"> want. The java.util.Stack API is an example of a wide interface, which we generally strive to avoid. Q. Should a client be allowed to insert null items onto a stack or queue? A. This question arises frequently when implementing collections in Java. Our implementation (and Java&#8217;s stack and queue libraries) do permit the insertion of null values. Q. What should the Stack iterator do if the client calls push() or pop() during iterator? A. Throw a java.util.ConcurrentModificationException to make it a fail-fast it- erator. See 1.3.50. Q. Can I use a foreach loop with arrays? A. Yes (even though arrays do not implement the Iterable interface). The following one-liner prints out the command-line arguments:</p><p attribs="{'xml:space': 'preserve'}" id="_02681" smilref="Title.smil#_02681"> public static void main(String[] args) { for (String s : args) StdOut.println(s); }</p><p attribs="{'xml:space': 'preserve'}" id="_02682" smilref="Title.smil#_02682"> Q. Can I use a foreach loop with strings? A. No. String does not implement Iterable. Q. Why not have a single Collection data type that implements methods to add items, remove the most recently inserted, remove the least recently inserted, remove random, iterate, return the number of items in the collection, and whatever other operations we might desire? Then we could get them all implemented in a single class that could be used by many clients. A. Again, this is an example of a wide interface. Java has such implementations in its java.util.ArrayList and java.util.LinkedList classes. One reason to avoid them is that it there is no assurance that all operations are implemented ef&#64257; ciently. Through- out this book, we use APIs as starting points for designing efficient algorithms and data structures, which is certainly easier to do for interfaces with just a few operations as opposed to an interface with many operations. Another reason to insist on narrow interfaces is that they enforce a certain discipline on client programs, which makes client code much easier to understand. If one client uses Stack&lt;String&gt; and another uses Queue&lt;Transaction&gt;, we have a good idea that the LIFO discipline is important to the first and the FIFO discipline is important to the second.</p><p attribs="{'xml:space': 'preserve'}" id="_02683" smilref="Title.smil#_02683" /><pagenum id="p174" page="normal" smilref="Title.smil#p174" /><p attribs="{'xml:space': 'preserve'}" id="_02684" smilref="Title.smil#_02684"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02685" smilref="Title.smil#_02685"> 161</p><p attribs="{'xml:space': 'preserve'}" id="_02686" smilref="Title.smil#_02686"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_02687" smilref="Title.smil#_02687"> 1.3.1 Add a method isFull() to FixedCapacityStackOfStrings.</p><p attribs="{'xml:space': 'preserve'}" id="_02688" smilref="Title.smil#_02688"> 1.3.2 Give the output printed by java Stack for the input</p><p attribs="{'xml:space': 'preserve'}" id="_02689" smilref="Title.smil#_02689"> it was the best of times - - it was the - -</p><p attribs="{'xml:space': 'preserve'}" id="_02690" smilref="Title.smil#_02690"> 1.3.3 Suppose that a client performs an intermixed sequence of (stack) push and pop operations. The push operations put the integers 0 through 9 in order onto the stack; the pop operations print out the return values. Which of the following sequence(s) could not occur?</p><p attribs="{'xml:space': 'preserve'}" id="_02691" smilref="Title.smil#_02691"> a. 4 3 2 1 0 9 8 7 6 5 b. 4 6 8 7 5 3 2 9 0 1 c. 2 5 6 7 4 8 9 3 1 0 d. 4 3 2 1 0 5 6 7 8 9 e. 1 2 3 4 5 6 9 8 7 0 f. 0 4 6 5 3 8 1 7 2 9 g. 1 4 7 9 8 6 5 3 0 2 h. 2 1 4 3 6 5 8 7 9 0</p><p attribs="{'xml:space': 'preserve'}" id="_02692" smilref="Title.smil#_02692"> 1.3.4 Write a stack client Parentheses that reads in a text stream from standard input and uses a stack to determine whether its parentheses are properly balanced. For ex- ample, your program should print true for [()]{}{[()()]()} and false for [(]). 1.3.5 What does the following code fragment print when N is 50? Give a high-level description of what it does when presented with a positive integer N.</p><p attribs="{'xml:space': 'preserve'}" id="_02693" smilref="Title.smil#_02693"> Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); while (N &gt; 0) { stack.push(N % 2); N = N / 2; } for (int d : stack) StdOut.print(d); StdOut.println();</p><p attribs="{'xml:space': 'preserve'}" id="_02694" smilref="Title.smil#_02694"> Answer : Prints the binary representation of N (110010 when N is 50).</p><p attribs="{'xml:space': 'preserve'}" id="_02695" smilref="Title.smil#_02695" /><pagenum id="p175" page="normal" smilref="Title.smil#p175" /><p attribs="{'xml:space': 'preserve'}" id="_02696" smilref="Title.smil#_02696"> 162</p><p attribs="{'xml:space': 'preserve'}" id="_02697" smilref="Title.smil#_02697"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02698" smilref="Title.smil#_02698"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_02699" smilref="Title.smil#_02699"> 1.3.6 What does the following code fragment do to the queue q?</p><p attribs="{'xml:space': 'preserve'}" id="_02700" smilref="Title.smil#_02700"> Stack&lt;String&gt; stack = new Stack&lt;String&gt;(); while (!q.isEmpty()) stack.push(q.dequeue()); while (!stack.isEmpty()) q.enqueue(stack.pop());</p><p attribs="{'xml:space': 'preserve'}" id="_02701" smilref="Title.smil#_02701"> 1.3.7 Add a method peek() to Stack that returns the most recently inserted item on the stack (without popping it). 1.3.8 Give the contents and size of the array for DoublingStackOfStrings with the input</p><p attribs="{'xml:space': 'preserve'}" id="_02702" smilref="Title.smil#_02702"> it was the best of times - - it was the - -</p><p attribs="{'xml:space': 'preserve'}" id="_02703" smilref="Title.smil#_02703"> 1.3.9 Write a program that takes from standard input an expression without left parentheses and prints the equivalent infix expression with the parentheses inserted. For example, given the input:</p><p attribs="{'xml:space': 'preserve'}" id="_02704" smilref="Title.smil#_02704"> 1 + 2 ) * 3 - 4 ) * 5 - 6 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_02705" smilref="Title.smil#_02705"> your program should print</p><p attribs="{'xml:space': 'preserve'}" id="_02706" smilref="Title.smil#_02706"> ( ( 1 + 2 ) * ( ( 3 - 4 ) * ( 5 - 6 ) ) )</p><p attribs="{'xml:space': 'preserve'}" id="_02707" smilref="Title.smil#_02707"> 1.3.10 Write a filter InfixToPostfix that converts an arithmetic expression from infix to post&#64257; x. 1.3.11 Write a program EvaluatePostfix that takes a postfix expression from standard input, evaluates it, and prints the value. (Piping the output of your program from the previous exercise to this program gives equivalent behavior to Evaluate.) 1.3.12 Write an iterable Stack client that has a static method copy() that takes a stack of strings as argument and returns a copy of the stack. Note : This ability is a prime example of the value of having an iterator, because it allows development of such functionality without changing the basic API. 1.3.13 Suppose that a client performs an intermixed sequence of (queue) enqueue and dequeue operations. The enqueue operations put the integers 0 through 9 in order onto</p><p attribs="{'xml:space': 'preserve'}" id="_02708" smilref="Title.smil#_02708" /><pagenum id="p176" page="normal" smilref="Title.smil#p176" /><p attribs="{'xml:space': 'preserve'}" id="_02709" smilref="Title.smil#_02709"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02710" smilref="Title.smil#_02710"> 163</p><p attribs="{'xml:space': 'preserve'}" id="_02711" smilref="Title.smil#_02711"> the queue; the dequeue operations print out the return value. Which of the following sequence(s) could not occur?</p><p attribs="{'xml:space': 'preserve'}" id="_02712" smilref="Title.smil#_02712"> a. 0 1 2 3 4 5 6 7 8 9 b. 4 6 8 7 5 3 2 9 0 1 c. 2 5 6 7 4 8 9 3 1 0 d. 4 3 2 1 0 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_02713" smilref="Title.smil#_02713"> 1.3.14 Develop a class ResizingArrayQueueOfStrings that implements the queue abstraction with a fi xed-size array, and then extend your implementation to use array resizing to remove the size restriction. 1.3.15 Write a Queue client that takes a command-line argument k and prints the kth from the last string found on standard input (assuming that standard input has k or more strings). 1.3.16 Using readInts() on page 126 as a model, write a static method readDates() for Date that reads dates from standard input in the format specified in the table on page 119 and returns an array containing them.</p><p attribs="{'xml:space': 'preserve'}" id="_02714" smilref="Title.smil#_02714"> 1.3.17 Do Exercise 1.3.16 for Transaction.</p><p attribs="{'xml:space': 'preserve'}" id="_02715" smilref="Title.smil#_02715" /><pagenum id="p177" page="normal" smilref="Title.smil#p177" /><p attribs="{'xml:space': 'preserve'}" id="_02716" smilref="Title.smil#_02716"> 164</p><p attribs="{'xml:space': 'preserve'}" id="_02717" smilref="Title.smil#_02717"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02718" smilref="Title.smil#_02718"> LINKED -LIST EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_02719" smilref="Title.smil#_02719"> This list of exercises is intended to give you experience in working with linked lists. Sugges- tion: make drawings using the visual representation described in the text.</p><p attribs="{'xml:space': 'preserve'}" id="_02720" smilref="Title.smil#_02720"> 1.3.18 Suppose x is a linked-list node and not the last node on the list. What is the effect of the following code fragment?</p><p attribs="{'xml:space': 'preserve'}" id="_02721" smilref="Title.smil#_02721"> x.next = x.next.next;</p><p attribs="{'xml:space': 'preserve'}" id="_02722" smilref="Title.smil#_02722"> Answer : Deletes from the list the node immediately following x.</p><p attribs="{'xml:space': 'preserve'}" id="_02723" smilref="Title.smil#_02723"> 1.3.19 Give a code fragment that removes the last node in a linked list whose first node</p><p attribs="{'xml:space': 'preserve'}" id="_02724" smilref="Title.smil#_02724"> is first.</p><p attribs="{'xml:space': 'preserve'}" id="_02725" smilref="Title.smil#_02725"> 1.3.20 Write a method delete() that takes an int argument k and deletes the kth element in a linked list, if it exists. 1.3.21 Write a method find() that takes a linked list and a string key as arguments and returns true if some node in the list has key as its item fi eld, false otherwise. 1.3.22 Suppose that x is a linked list Node. What does the following code fragment do?</p><p attribs="{'xml:space': 'preserve'}" id="_02726" smilref="Title.smil#_02726"> t.next = x.next; x.next = t;</p><p attribs="{'xml:space': 'preserve'}" id="_02727" smilref="Title.smil#_02727"> Answer : Inserts node t immediately after node x. 1.3.23 Why does the following code fragment not do the same thing as in the previous question?</p><p attribs="{'xml:space': 'preserve'}" id="_02728" smilref="Title.smil#_02728"> x.next = t; t.next = x.next;</p><p attribs="{'xml:space': 'preserve'}" id="_02729" smilref="Title.smil#_02729"> Answer : When it comes time to update t.next, x.next is no longer the original node following x, but is instead t itself!</p><p attribs="{'xml:space': 'preserve'}" id="_02730" smilref="Title.smil#_02730"> 1.3.24 Write a method removeAfter() that takes a linked-list Node as argument and removes the node following the given one (and does nothing if the argument or the next field in the argument node is null). 1.3.25 Write a method insertAfter() that takes two linked-list Node arguments and inserts the second after the first on its list (and does nothing if either argument is null).</p><p attribs="{'xml:space': 'preserve'}" id="_02731" smilref="Title.smil#_02731" /><pagenum id="p178" page="normal" smilref="Title.smil#p178" /><p attribs="{'xml:space': 'preserve'}" id="_02732" smilref="Title.smil#_02732"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02733" smilref="Title.smil#_02733"> 165</p><p attribs="{'xml:space': 'preserve'}" id="_02734" smilref="Title.smil#_02734"> 1.3.26 Write a method remove() that takes a linked list and a string key as arguments and removes all of the nodes in the list that have key as its item fi eld. 1.3.27 Write a method max() that takes a reference to the first node in a linked list as argument and returns the value of the maximum key in the list. Assume that all keys are positive integers, and return 0 if the list is empty. 1.3.28 Develop a recursive solution to the previous question. 1.3.29 Write a Queue implementation that uses a circular linked list, which is the same as a linked list except that no links are null and the value of last.next is first whenever the list is not empty. Keep only one Node instance variable (last). 1.3.30 Write a function that takes the first Node in a linked list as argument and (de- structively) reverses the list, returning the first Node in the result.</p><p attribs="{'xml:space': 'preserve'}" id="_02735" smilref="Title.smil#_02735"> Iterative solution : To accomplish this task, we maintain references to three consecutive nodes in the linked list, reverse, first, and second. At each iteration, we extract the node first from the original linked list and insert it at the beginning of the reversed list. We maintain the invariant that first is the first node of what&#8217;s left of the original list, second is the second node of what&#8217;s left of the original list, and reverse is the first node of the resulting reversed list.</p><p attribs="{'xml:space': 'preserve'}" id="_02736" smilref="Title.smil#_02736"> public Node reverse(Node x) { Node first = x; Node reverse = null; while (first != null) { Node second = first.next; first.next = reverse; reverse = first; first = second; } return reverse; }</p><p attribs="{'xml:space': 'preserve'}" id="_02737" smilref="Title.smil#_02737"> When writing code involving linked lists, we must always be careful to properly handle the exceptional cases (when the linked list is empty, when the list has only one or two</p><p attribs="{'xml:space': 'preserve'}" id="_02738" smilref="Title.smil#_02738" /><pagenum id="p179" page="normal" smilref="Title.smil#p179" /><p attribs="{'xml:space': 'preserve'}" id="_02739" smilref="Title.smil#_02739"> 166</p><p attribs="{'xml:space': 'preserve'}" id="_02740" smilref="Title.smil#_02740"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02741" smilref="Title.smil#_02741"> LINKED -LIST EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_02742" smilref="Title.smil#_02742"> nodes) and the boundary cases (dealing with the first or last items). This is usually much trickier than handling the normal cases.</p><p attribs="{'xml:space': 'preserve'}" id="_02743" smilref="Title.smil#_02743"> Recursive solution : Assuming the linked list has N nodes, we recursively reverse the last N &#8211; 1 nodes, and then carefully append the first node to the end.</p><p attribs="{'xml:space': 'preserve'}" id="_02744" smilref="Title.smil#_02744"> public Node reverse(Node first) { if (first == null) return null; if (first.next == null) return first; Node second = first.next; Node rest = reverse(second); second.next = first; first.next = null; return rest; }</p><p attribs="{'xml:space': 'preserve'}" id="_02745" smilref="Title.smil#_02745"> 1.3.31 Implement a nested class DoubleNode for building doubly-linked lists, where each node contains a reference to the item preceding it and the item following it in the list (null if there is no such item). Then implement static methods for the following tasks: insert at the beginning, insert at the end, remove from the beginning, remove from the end, insert before a given node, insert after a given node, and remove a given node.</p><p attribs="{'xml:space': 'preserve'}" id="_02746" smilref="Title.smil#_02746" /><pagenum id="p180" page="normal" smilref="Title.smil#p180" /><p attribs="{'xml:space': 'preserve'}" id="_02747" smilref="Title.smil#_02747"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02748" smilref="Title.smil#_02748"> 167</p><p attribs="{'xml:space': 'preserve'}" id="_02749" smilref="Title.smil#_02749"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_02750" smilref="Title.smil#_02750"> 1.3.32 Steque. A stack-ended queue or steque is a data type that supports push, pop, and enqueue. Articulate an API for this ADT. Develop a linked-list-based implementation. 1.3.33 Deque. A double-ended queue or deque (pronounced &#8220;deck&#8221;) is like a stack or a queue but supports adding and removing items at both ends. A deque stores a collection of items and supports the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_02751" smilref="Title.smil#_02751"> public class Deque&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02752" smilref="Title.smil#_02752"> Deque()</p><p attribs="{'xml:space': 'preserve'}" id="_02753" smilref="Title.smil#_02753"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_02754" smilref="Title.smil#_02754"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_02755" smilref="Title.smil#_02755"> create an empty deque</p><p attribs="{'xml:space': 'preserve'}" id="_02756" smilref="Title.smil#_02756"> is the deque empty?</p><p attribs="{'xml:space': 'preserve'}" id="_02757" smilref="Title.smil#_02757"> number of items in the deque</p><p attribs="{'xml:space': 'preserve'}" id="_02758" smilref="Title.smil#_02758"> void pushLeft(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_02759" smilref="Title.smil#_02759"> add an item to the left end</p><p attribs="{'xml:space': 'preserve'}" id="_02760" smilref="Title.smil#_02760"> void pushRight(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_02761" smilref="Title.smil#_02761"> add an item to the right end</p><p attribs="{'xml:space': 'preserve'}" id="_02762" smilref="Title.smil#_02762"> Item popLeft()</p><p attribs="{'xml:space': 'preserve'}" id="_02763" smilref="Title.smil#_02763"> Item popRight()</p><p attribs="{'xml:space': 'preserve'}" id="_02764" smilref="Title.smil#_02764"> remove an item from the left end</p><p attribs="{'xml:space': 'preserve'}" id="_02765" smilref="Title.smil#_02765"> remove an item from the right end</p><p attribs="{'xml:space': 'preserve'}" id="_02766" smilref="Title.smil#_02766"> API for a generic double-ended queue</p><p attribs="{'xml:space': 'preserve'}" id="_02767" smilref="Title.smil#_02767"> Write a class Deque that uses a doubly-linked list to implement this API and a class ResizingArrayDeque that uses a resizing array.</p><p attribs="{'xml:space': 'preserve'}" id="_02768" smilref="Title.smil#_02768"> 1.3.34 Random bag. A random bag stores a collection of items and supports the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_02769" smilref="Title.smil#_02769"> public class RandomBag&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02770" smilref="Title.smil#_02770"> RandomBag() boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_02771" smilref="Title.smil#_02771"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_02772" smilref="Title.smil#_02772"> create an empty random bag</p><p attribs="{'xml:space': 'preserve'}" id="_02773" smilref="Title.smil#_02773"> is the bag empty?</p><p attribs="{'xml:space': 'preserve'}" id="_02774" smilref="Title.smil#_02774"> number of items in the bag</p><p attribs="{'xml:space': 'preserve'}" id="_02775" smilref="Title.smil#_02775"> void add(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_02776" smilref="Title.smil#_02776"> add an item</p><p attribs="{'xml:space': 'preserve'}" id="_02777" smilref="Title.smil#_02777"> API for a generic random bag</p><p attribs="{'xml:space': 'preserve'}" id="_02778" smilref="Title.smil#_02778"> Write a class RandomBag that implements this API. Note that this API is the same as for Bag, except for the adjective random, which indicates that the iteration should provide</p><p attribs="{'xml:space': 'preserve'}" id="_02779" smilref="Title.smil#_02779" /><pagenum id="p181" page="normal" smilref="Title.smil#p181" /><p attribs="{'xml:space': 'preserve'}" id="_02780" smilref="Title.smil#_02780"> 168</p><p attribs="{'xml:space': 'preserve'}" id="_02781" smilref="Title.smil#_02781"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02782" smilref="Title.smil#_02782"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_02783" smilref="Title.smil#_02783"> the items in random order (all N ! permutations equally likely, for each iterator). Hint : Put the items in an array and randomize their order in the iterator&#8217;s constructor.</p><p attribs="{'xml:space': 'preserve'}" id="_02784" smilref="Title.smil#_02784"> 1.3.35 Random queue. A random queue stores a collection of items and supports the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_02785" smilref="Title.smil#_02785"> public class RandomQueue&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02786" smilref="Title.smil#_02786"> RandomQueue()</p><p attribs="{'xml:space': 'preserve'}" id="_02787" smilref="Title.smil#_02787"> create an empty random queue</p><p attribs="{'xml:space': 'preserve'}" id="_02788" smilref="Title.smil#_02788"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_02789" smilref="Title.smil#_02789"> void enqueue(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_02790" smilref="Title.smil#_02790"> is the queue empty?</p><p attribs="{'xml:space': 'preserve'}" id="_02791" smilref="Title.smil#_02791"> add an item</p><p attribs="{'xml:space': 'preserve'}" id="_02792" smilref="Title.smil#_02792"> Item dequeue()</p><p attribs="{'xml:space': 'preserve'}" id="_02793" smilref="Title.smil#_02793"> Item sample()</p><p attribs="{'xml:space': 'preserve'}" id="_02794" smilref="Title.smil#_02794"> remove and return a random item (sample without replacement)</p><p attribs="{'xml:space': 'preserve'}" id="_02795" smilref="Title.smil#_02795"> return a random item, but do not remove (sample with replacement)</p><p attribs="{'xml:space': 'preserve'}" id="_02796" smilref="Title.smil#_02796"> API for a generic random queue</p><p attribs="{'xml:space': 'preserve'}" id="_02797" smilref="Title.smil#_02797"> Write a class RandomQueue that implements this API. Hint : Use an array representation (with resizing). To remove an item, swap one at a random position (indexed 0 through N-1) with the one at the last position (index N-1). Then delete and return the last ob- ject, as in ResizingArrayStack. Write a client that deals bridge hands (13 cards each)</p><p attribs="{'xml:space': 'preserve'}" id="_02798" smilref="Title.smil#_02798"> using RandomQueue&lt;Card&gt;.</p><p attribs="{'xml:space': 'preserve'}" id="_02799" smilref="Title.smil#_02799"> 1.3.36 Random iterator. Write an iterator for RandomQueue&lt;Item&gt; from the previous exercise that returns the items in random order. 1.3.37 Josephus problem. In the Josephus problem from antiquity, N people are in dire straits and agree to the following strategy to reduce the population. They arrange themselves in a circle (at positions numbered from 0 to N&#8211;1) and proceed around the circle, eliminating every Mth person until only one person is left. Legend has it that Josephus figured out where to sit to avoid being eliminated. Write a Queue client Josephus that takes M and N from the command line and prints out the order in which people are eliminated (and thus would show Josephus where to sit in the circle).</p><p attribs="{'xml:space': 'preserve'}" id="_02800" smilref="Title.smil#_02800"> % java Josephus 2 7 1 3 5 0 4 2 6</p><p attribs="{'xml:space': 'preserve'}" id="_02801" smilref="Title.smil#_02801" /><pagenum id="p182" page="normal" smilref="Title.smil#p182" /><p attribs="{'xml:space': 'preserve'}" id="_02802" smilref="Title.smil#_02802"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02803" smilref="Title.smil#_02803"> 169</p><p attribs="{'xml:space': 'preserve'}" id="_02804" smilref="Title.smil#_02804"> 1.3.38 Delete kth element. Implement a class that supports the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_02805" smilref="Title.smil#_02805"> public class GeneralizedQueue&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_02806" smilref="Title.smil#_02806"> GeneralizedQueue() boolean isEmpty() void insert(Item x) Item delete(int k) API for a generic generalized queue</p><p attribs="{'xml:space': 'preserve'}" id="_02807" smilref="Title.smil#_02807"> is the queue empty?</p><p attribs="{'xml:space': 'preserve'}" id="_02808" smilref="Title.smil#_02808"> delete and return the kth least recently inserted item</p><p attribs="{'xml:space': 'preserve'}" id="_02809" smilref="Title.smil#_02809"> create an empty queue</p><p attribs="{'xml:space': 'preserve'}" id="_02810" smilref="Title.smil#_02810"> add an item</p><p attribs="{'xml:space': 'preserve'}" id="_02811" smilref="Title.smil#_02811"> First, develop an implementation that uses an array implementation, and then develop one that uses a linked-list implementation. Note : the algorithms and data structures that we introduce in Chapter 3 make it possible to develop an implementation that can guarantee that both insert() and delete() take time prortional to the logarithm of the number of items in the queue&#8212;see Exercise 3.5.27.</p><p attribs="{'xml:space': 'preserve'}" id="_02812" smilref="Title.smil#_02812"> 1.3.39 Ring buffer. A ring buffer, or circular queue, is a FIFO data structure of a fixed size N. It is useful for transferring data between asynchronous processes or for storing log fi les. When the buffer is empty, the consumer waits until data is deposited; when the buffer is full, the producer waits to deposit data. Develop an API for a RingBuffer and an implementation that uses an array representation (with circular wrap-around). 1.3.40 Move-to-front. Read in a sequence of characters from standard input and maintain the characters in a linked list with no duplicates. When you read in a previously unseen character, insert it at the front of the list. When you read in a duplicate character, delete it from the list and reinsert it at the beginning. Name your program MoveToFront: it implements the well-known move-to-front strategy, which is useful for caching, data compression, and many other applications where items that have been recently accessed are more likely to be reaccessed. 1.3.41 Copy a queue. Create a new constructor so that</p><p attribs="{'xml:space': 'preserve'}" id="_02813" smilref="Title.smil#_02813"> Queue&lt;Item&gt; r = new Queue&lt;Item&gt;(q);</p><p attribs="{'xml:space': 'preserve'}" id="_02814" smilref="Title.smil#_02814"> makes r a reference to a new and independent copy of the queue q. You should be able to push and pop from either q or r without influencing the other. Hint : Delete all of the elements from q and add these elements to both q and r.</p><p attribs="{'xml:space': 'preserve'}" id="_02815" smilref="Title.smil#_02815" /><pagenum id="p183" page="normal" smilref="Title.smil#p183" /><p attribs="{'xml:space': 'preserve'}" id="_02816" smilref="Title.smil#_02816"> 170</p><p attribs="{'xml:space': 'preserve'}" id="_02817" smilref="Title.smil#_02817"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02818" smilref="Title.smil#_02818"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_02819" smilref="Title.smil#_02819"> 1.3.42 Copy a stack. Create a new constructor for the linked-list implementation of Stack so that</p><p attribs="{'xml:space': 'preserve'}" id="_02820" smilref="Title.smil#_02820"> Stack&lt;Item&gt; t = new Stack&lt;Item&gt;(s);</p><p attribs="{'xml:space': 'preserve'}" id="_02821" smilref="Title.smil#_02821"> makes t a reference to a new and independent copy of the stack s.</p><p attribs="{'xml:space': 'preserve'}" id="_02822" smilref="Title.smil#_02822"> 1.3.43 Listing fi les. A folder is a list of files and folders. Write a program that takes the name of a folder as a command-line argument and prints out all of the files contained in that folder, with the contents of each folder recursively listed (indented) under that folder&#8217;s name. Hint : Use a queue, and see java.io.File. 1.3.44 Text editor buffer. Develop a data type for a buffer in a text editor that implements the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_02823" smilref="Title.smil#_02823"> public class Buffer</p><p attribs="{'xml:space': 'preserve'}" id="_02824" smilref="Title.smil#_02824"> Buffer() void insert(char c)</p><p attribs="{'xml:space': 'preserve'}" id="_02825" smilref="Title.smil#_02825"> char get()</p><p attribs="{'xml:space': 'preserve'}" id="_02826" smilref="Title.smil#_02826"> char delete()</p><p attribs="{'xml:space': 'preserve'}" id="_02827" smilref="Title.smil#_02827"> void left(int k)</p><p attribs="{'xml:space': 'preserve'}" id="_02828" smilref="Title.smil#_02828"> void right(int k)</p><p attribs="{'xml:space': 'preserve'}" id="_02829" smilref="Title.smil#_02829"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_02830" smilref="Title.smil#_02830"> create an empty buffer</p><p attribs="{'xml:space': 'preserve'}" id="_02831" smilref="Title.smil#_02831"> insert c at the cursor position</p><p attribs="{'xml:space': 'preserve'}" id="_02832" smilref="Title.smil#_02832"> character at the cursor position</p><p attribs="{'xml:space': 'preserve'}" id="_02833" smilref="Title.smil#_02833"> delete and return the character at the cursor</p><p attribs="{'xml:space': 'preserve'}" id="_02834" smilref="Title.smil#_02834"> move the cursor k positions to the left</p><p attribs="{'xml:space': 'preserve'}" id="_02835" smilref="Title.smil#_02835"> move the cursor k positions to the right</p><p attribs="{'xml:space': 'preserve'}" id="_02836" smilref="Title.smil#_02836"> number of characters in the buffer</p><p attribs="{'xml:space': 'preserve'}" id="_02837" smilref="Title.smil#_02837"> API for a text buffer </p><p attribs="{'xml:space': 'preserve'}" id="_02838" smilref="Title.smil#_02838"> Hint : Use two stacks.</p><p attribs="{'xml:space': 'preserve'}" id="_02839" smilref="Title.smil#_02839"> 1.3.45 Stack generability. Suppose that we have a sequence of intermixed push and pop operations as with our test stack client, where the integers 0, 1, ..., N-1 in that order (push directives) are intermixed with N minus signs (pop directives). Devise an algorithm that determines whether the intermixed sequence causes the stack to under- fl ow. (You may use only an amount of space independent of N&#8212;you cannot store the integers in a data structure.) Devise a linear-time algorithm that determines whether a given permutation can be generated as output by our test client (depending on where the pop directives occur).</p><p attribs="{'xml:space': 'preserve'}" id="_02840" smilref="Title.smil#_02840" /><pagenum id="p184" page="normal" smilref="Title.smil#p184" /><p attribs="{'xml:space': 'preserve'}" id="_02841" smilref="Title.smil#_02841"> 1.3 </p><p attribs="{'xml:space': 'preserve'}" id="_02842" smilref="Title.smil#_02842"> 171</p><p attribs="{'xml:space': 'preserve'}" id="_02843" smilref="Title.smil#_02843"> Solution: The stack does not overflow unless there exists an integer k such that the first k pop operations occur before the first k push operations. If a given permutation can be generated, it is uniquely generated as follows: if the next integer in the output permutation is in the top of the stack, pop it; otherwise, push it onto the stack.</p><p attribs="{'xml:space': 'preserve'}" id="_02844" smilref="Title.smil#_02844"> 1.3.46 Forbidden triple for stack generability. Prove that a permutation can be generated by a stack (as in the previous question) if and only if it has no forbidden triple (a, b, c) such that a &lt; b &lt; c with cfi rst, a second, and b third (possibly with other intervening integers between c and a and between a and b).</p><p attribs="{'xml:space': 'preserve'}" id="_02845" smilref="Title.smil#_02845"> Partial solution: Suppose that there is a forbidden triple (a, b, c). Item c is popped before a and b, but a and b are pushed before c. Thus, when c is pushed, both a and b are on the stack. Therefore, a cannot be popped before b.</p><p attribs="{'xml:space': 'preserve'}" id="_02846" smilref="Title.smil#_02846"> 1.3.47 Catenable queues, stacks, or steques. Add an extra operation catenation that (de- structively) concatenates two queues, stacks, or steques (see Exercise 1.3.32). Hint : Use a circular linked list, maintaining a pointer to the last item. 1.3.48 Two stacks with a deque. Implement two stacks with a single deque so that each operation takes a constant number of deque operations (see Exercise 1.3.33). 1.3.49 Queue with a constant number of stacks. Implement a queue with a constant number of stacks so that each queue operation takes a constant (worst-case) number of stack operations. Warning : high degree of dif&#64257; culty. 1.3.50 Fail-fast iterator. Modify the iterator code in Stack to immediately throw a</p><p attribs="{'xml:space': 'preserve'}" id="_02847" smilref="Title.smil#_02847"> java.util.ConcurrentModificationException if the client modifies the collection</p><p attribs="{'xml:space': 'preserve'}" id="_02848" smilref="Title.smil#_02848"> (via push() or pop()) during iteration?</p><p attribs="{'xml:space': 'preserve'}" id="_02849" smilref="Title.smil#_02849"> Solution: Maintain a counter that counts the number of push() and pop() operations. When creating an iterator, store this value as an Iterator instance variable. Before each call to hasNext() and next(), check that this value has not changed since construction of the iterator; if it has, throw the exception.</p><p attribs="{'xml:space': 'preserve'}" id="_02850" smilref="Title.smil#_02850" /><pagenum id="p186" page="normal" smilref="Title.smil#p186" /><p attribs="{'xml:space': 'preserve'}" id="_02851" smilref="Title.smil#_02851"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_02852" smilref="Title.smil#_02852"> 173</p><p attribs="{'xml:space': 'preserve'}" id="_02853" smilref="Title.smil#_02853"> Observations Our first challenge is to determine how to make quantitative measurements of the running time of our programs. This task is far easier than in the natural sciences. We do not have to send a rocket to Mars or kill laboratory animals or split an atom&#8212;we can simply run the program. Indeed, every time you run a program, you are performing a scientific experiment that relates the program to the natural world and answers one of our core questions: How long will my program take? Our first qualitative observation about most programs is that there is a problem size that characterizes the difficulty of the computational task. Normally, the problem size is either the size of the input or the value of a command-line argument. Intuitively, the running time should increase with problem size, but the question of by how much it increases naturally comes up every time we develop and run a program. Another qualitative observation for many programs is that the running time is relatively insensitive to the input itself; it depends primarily on the problem size. If this relationship does not hold, we need to take steps to better understand and perhaps better control the running time&#8217;s sensitivity to the input. But it does often hold, so we now focus on the goal of better quantifying the relationship between problem size and running time.</p><p attribs="{'xml:space': 'preserve'}" id="_02854" smilref="Title.smil#_02854"> Example. As a running example, we will work with the program ThreeSum shown here, which counts the number of triples in a file of N integers that sum to 0 (assum- ing that overflow plays no role). This computation may seem contrived to you, but it is deeply related to numerous fundamental computational tasks (for exam- ple, see Exercise 1.4.26). As a test input, consider the file 1Mints.txt from the booksite, which contains 1 million randomly generated int values. The second, eighth, and tenth entries in 1Mints.txt sum to 0. How many more such triples are there in the fi le? ThreeSum can tell us, but can it do so in a reasonable amount of time? What is the relationship between the problem size N and running time for ThreeSum? As a first experiment, try running ThreeSum on your computer for the files 1Kints.txt, 2Kints.txt,</p><p attribs="{'xml:space': 'preserve'}" id="_02855" smilref="Title.smil#_02855"> public class ThreeSum { public static int count(int[] a) { // Count triples that sum to 0. int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++) for (int j = i+1; j &lt; N; j++) for (int k = j+1; k &lt; N; k++) if (a[i] + a[j] + a[k] == 0) cnt++; return cnt; }</p><p attribs="{'xml:space': 'preserve'}" id="_02856" smilref="Title.smil#_02856"> public static void main(String[] args) { int[] a = In.readInts(args[0]); StdOut.println(count(a)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_02857" smilref="Title.smil#_02857"> 4Kints.txt, and 8Kints.txt on the</p><p attribs="{'xml:space': 'preserve'}" id="_02858" smilref="Title.smil#_02858"> Given N, how long will this program take?</p><p attribs="{'xml:space': 'preserve'}" id="_02859" smilref="Title.smil#_02859" /><pagenum id="p187" page="normal" smilref="Title.smil#p187" /><p attribs="{'xml:space': 'preserve'}" id="_02860" smilref="Title.smil#_02860"> 174</p><p attribs="{'xml:space': 'preserve'}" id="_02861" smilref="Title.smil#_02861"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02862" smilref="Title.smil#_02862"> % more 1Mints.txt 324110 -442472 626686 -157678 508681 123414 -77867 155091 129801 287381 604242 686904 -247109 77867 982455 -210707 -922943 -738817 85168 855430 ...</p><p attribs="{'xml:space': 'preserve'}" id="_02863" smilref="Title.smil#_02863"> booksite that contain the first 1,000, 2,000, 4,000, and 8,000 integers from 1Mints.txt, respectively. You can quickly determine that there are 70 triples that sum to 0 in 1Kints.txt and that there are 528 triples that sum to 0 in 2Kints.txt. The program takes substantially more time to determine that there are 4,039 triples that sum to 0 in 4Kints.txt, and as you wait for the program to finish for 8Kints.txt, you will find yourself asking the question How long will my program take ? As you will see, answering this question for this program turns out to be easy. In- deed, you can often come up with a fairly accurate prediction while the program is running.</p><p attribs="{'xml:space': 'preserve'}" id="_02864" smilref="Title.smil#_02864"> % java ThreeSum 1000 1Kints.txt</p><p attribs="{'xml:space': 'preserve'}" id="_02865" smilref="Title.smil#_02865"> Stopwatch. Reliably measuring the exact running time of a given program can be dif&#64257; cult. Fortu- nately, we are usually happy with estimates. We want to be able to distinguish programs that will finish in a few seconds or a few minutes from those that might require a few days or a few months or more, and we want to know when one program is twice as fast as another for the same task. Still, we need accurate measurements to generate experimental data that we can use to formulate and to check the validity of hypotheses about the relationship between running time and problem size. For this purpose, we use the Stopwatch data type shown on the facing page. Its elapsedTime() method returns the elapsed time since it was created, in seconds. The implementation is based on using the Java system&#8217;s currentTimeMillis() method, which gives the current time in milliseconds, to save the time when the constructor is invoked, then uses it again to compute the elapsed time when elapsedTime() is invoked.</p><p attribs="{'xml:space': 'preserve'}" id="_02866" smilref="Title.smil#_02866"> tick tick tick</p><p attribs="{'xml:space': 'preserve'}" id="_02867" smilref="Title.smil#_02867"> 70 % java ThreeSum 2000 2Kints.txt</p><p attribs="{'xml:space': 'preserve'}" id="_02868" smilref="Title.smil#_02868"> tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick</p><p attribs="{'xml:space': 'preserve'}" id="_02869" smilref="Title.smil#_02869"> 528 % java ThreeSum 4000 4Kints.txt</p><p attribs="{'xml:space': 'preserve'}" id="_02870" smilref="Title.smil#_02870"> tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick tick</p><p attribs="{'xml:space': 'preserve'}" id="_02871" smilref="Title.smil#_02871"> 4039</p><p attribs="{'xml:space': 'preserve'}" id="_02872" smilref="Title.smil#_02872"> Observing the running time of a program</p><p attribs="{'xml:space': 'preserve'}" id="_02873" smilref="Title.smil#_02873" /><pagenum id="p188" page="normal" smilref="Title.smil#p188" /><p attribs="{'xml:space': 'preserve'}" id="_02874" smilref="Title.smil#_02874"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_02875" smilref="Title.smil#_02875"> 175</p><p attribs="{'xml:space': 'preserve'}" id="_02876" smilref="Title.smil#_02876"> API</p><p attribs="{'xml:space': 'preserve'}" id="_02877" smilref="Title.smil#_02877"> public class Stopwatch</p><p attribs="{'xml:space': 'preserve'}" id="_02878" smilref="Title.smil#_02878"> Stopwatch()</p><p attribs="{'xml:space': 'preserve'}" id="_02879" smilref="Title.smil#_02879"> create a stopwatch</p><p attribs="{'xml:space': 'preserve'}" id="_02880" smilref="Title.smil#_02880"> double elapsedTime()</p><p attribs="{'xml:space': 'preserve'}" id="_02881" smilref="Title.smil#_02881"> return elapsed time since creation</p><p attribs="{'xml:space': 'preserve'}" id="_02882" smilref="Title.smil#_02882"> typical client</p><p attribs="{'xml:space': 'preserve'}" id="_02883" smilref="Title.smil#_02883"> public static void main(String[] args) { int N = Integer.parseInt(args[0]); int[] a = new int[N]; for (int i = 0; i &lt; N; i++) a[i] = StdRandom.uniform(-1000000, 1000000); Stopwatch timer = new Stopwatch(); int cnt = ThreeSum.count(a); double time = timer.elapsedTime(); StdOut.println(cnt + " triples " + time); }</p><p attribs="{'xml:space': 'preserve'}" id="_02884" smilref="Title.smil#_02884"> application</p><p attribs="{'xml:space': 'preserve'}" id="_02885" smilref="Title.smil#_02885"> % java Stopwatch 1000 51 triples 0.488 seconds</p><p attribs="{'xml:space': 'preserve'}" id="_02886" smilref="Title.smil#_02886"> % java Stopwatch 2000 516 triples 3.855 seconds</p><p attribs="{'xml:space': 'preserve'}" id="_02887" smilref="Title.smil#_02887"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_02888" smilref="Title.smil#_02888"> public class Stopwatch { private final long start;</p><p attribs="{'xml:space': 'preserve'}" id="_02889" smilref="Title.smil#_02889"> public Stopwatch() { start = System.currentTimeMillis(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02890" smilref="Title.smil#_02890"> public double elapsedTime() { long now = System.currentTimeMillis(); return (now - start) / 1000.0; }</p><p attribs="{'xml:space': 'preserve'}" id="_02891" smilref="Title.smil#_02891"> }</p><p attribs="{'xml:space': 'preserve'}" id="_02892" smilref="Title.smil#_02892"> An abstract data type for a stopwatch</p><p attribs="{'xml:space': 'preserve'}" id="_02893" smilref="Title.smil#_02893" /><pagenum id="p189" page="normal" smilref="Title.smil#p189" /><p attribs="{'xml:space': 'preserve'}" id="_02894" smilref="Title.smil#_02894"> 176</p><p attribs="{'xml:space': 'preserve'}" id="_02895" smilref="Title.smil#_02895"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02896" smilref="Title.smil#_02896"> Analysis of experimental data. The program DoublingTest on the facing page is a more sophisticated Stopwatch client that produces experimental data for ThreeSum. It generates a sequence of random input arrays, doubling the array size at each step, and prints the running times of ThreeSum.count() for each input size. These experiments are certainly reproducible&#8212;you can also run them on your own computer, as many times as you like. When you run DoublingTest, you will find yourself in a prediction- verification cycle: it prints several lines very quickly, but then slows down considerably. Each time it prints a line, you find yourself wondering how long it will be until it prints the next line. Of course, since you have a different computer from ours, the actual running times that you get are likely to be different from those shown for our computer. Indeed, if your computer is twice as fast as ours, your running times will be about half ours, which leads immediately to the well-founded hypothesis that running times on different computers are likely to differ by a constant factor. Still, you will find yourself asking the more detailed question How long will my program take, as a function of the input size? To help answer this question, we plot the data. The diagrams at the bottom of the facing page show the result of plotting the data, both on a normal and on a log-log scale, with the problem size N on the x-axis and the running time T(N ) on the y-axis. The log-log plot immediately leads to a hypothesis about the running time&#8212;the data fits a straight line of slope 3 on the log-log plot. The equation of such a line is</p><p attribs="{'xml:space': 'preserve'}" id="_02897" smilref="Title.smil#_02897"> lg(T(N )) = 3 lg N + lg a</p><p attribs="{'xml:space': 'preserve'}" id="_02898" smilref="Title.smil#_02898"> (where a is a constant) which is equivalent to</p><p attribs="{'xml:space': 'preserve'}" id="_02899" smilref="Title.smil#_02899"> T(N ) = a N 3</p><p attribs="{'xml:space': 'preserve'}" id="_02900" smilref="Title.smil#_02900"> the running time, as a function of the input size, as desired. We can use one of our data points to solve for a&#8212;for example, T(8000) = 51.1 = a 8000 3, so a = 9.98&#11003;10 &#8211;11&#8212;and then use the equation</p><p attribs="{'xml:space': 'preserve'}" id="_02901" smilref="Title.smil#_02901"> T(N ) = 9.98&#11003;10 &#8211;11 N 3</p><p attribs="{'xml:space': 'preserve'}" id="_02902" smilref="Title.smil#_02902"> to predict running times for large N. Informally, we are checking the hypothesis that the data points on the log-log plot fall close to this line. Statistical methods are available for doing a more careful analysis to find estimates of a and the exponent b, but our quick calculations suffice to estimate running time for most purposes. For example, we can estimate the running time on our computer for N = 16,000 to be about 9.98&#11003;10 &#8211;11 16000 3 = 408.8 seconds, or about 6.8 minutes (the actual time was 409.3 seconds). While waiting for your computer to print the line for N = 16,000 in DoublingTest, you might use this method to predict when it will fi nish, then check the result by waiting to see if your prediction is true.</p><p attribs="{'xml:space': 'preserve'}" id="_02903" smilref="Title.smil#_02903" /><pagenum id="p190" page="normal" smilref="Title.smil#p190" /><p attribs="{'xml:space': 'preserve'}" id="_02904" smilref="Title.smil#_02904"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_02905" smilref="Title.smil#_02905"> 177</p><p attribs="{'xml:space': 'preserve'}" id="_02906" smilref="Title.smil#_02906"> results of experiments</p><p attribs="{'xml:space': 'preserve'}" id="_02907" smilref="Title.smil#_02907"> % java DoublingTest 250 0.0 500 0.0 1000 0.1 2000 0.8 4000 6.4 8000 51.1 ...</p><p attribs="{'xml:space': 'preserve'}" id="_02908" smilref="Title.smil#_02908"> program to per form experiments</p><p attribs="{'xml:space': 'preserve'}" id="_02909" smilref="Title.smil#_02909"> public class DoublingTest { public static double timeTrial(int N) { // Time ThreeSum.count() for N random 6-digit ints. int MAX = 1000000; int[] a = new int[N]; for (int i = 0; i &lt; N; i++) a[i] = StdRandom.uniform(-MAX, MAX); Stopwatch timer = new Stopwatch(); int cnt = ThreeSum.count(a); return timer.elapsedTime(); }</p><p attribs="{'xml:space': 'preserve'}" id="_02910" smilref="Title.smil#_02910"> public static void main(String[] args) { // Print table of running times. for (int N = 250; true; N += N) { // Print time for problem size N. double time = timeTrial(N); StdOut.printf("%7d %5.1f\n", N, time); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_02911" smilref="Title.smil#_02911"> standard plot</p><p attribs="{'xml:space': 'preserve'}" id="_02912" smilref="Title.smil#_02912"> )</p><p attribs="{'xml:space': 'preserve'}" id="_02913" smilref="Title.smil#_02913"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02914" smilref="Title.smil#_02914"> (</p><p attribs="{'xml:space': 'preserve'}" id="_02915" smilref="Title.smil#_02915"> T e</p><p attribs="{'xml:space': 'preserve'}" id="_02916" smilref="Title.smil#_02916"> m</p><p attribs="{'xml:space': 'preserve'}" id="_02917" smilref="Title.smil#_02917"> i</p><p attribs="{'xml:space': 'preserve'}" id="_02918" smilref="Title.smil#_02918"> t</p><p attribs="{'xml:space': 'preserve'}" id="_02919" smilref="Title.smil#_02919"> i</p><p attribs="{'xml:space': 'preserve'}" id="_02920" smilref="Title.smil#_02920"> g n n n u</p><p attribs="{'xml:space': 'preserve'}" id="_02921" smilref="Title.smil#_02921"> r</p><p attribs="{'xml:space': 'preserve'}" id="_02922" smilref="Title.smil#_02922"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_02923" smilref="Title.smil#_02923"> 40</p><p attribs="{'xml:space': 'preserve'}" id="_02924" smilref="Title.smil#_02924"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_02925" smilref="Title.smil#_02925"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_02926" smilref="Title.smil#_02926"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_02927" smilref="Title.smil#_02927"> straight line of slope 3</p><p attribs="{'xml:space': 'preserve'}" id="_02928" smilref="Title.smil#_02928"> log-log plot</p><p attribs="{'xml:space': 'preserve'}" id="_02929" smilref="Title.smil#_02929"> ) )</p><p attribs="{'xml:space': 'preserve'}" id="_02930" smilref="Title.smil#_02930"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02931" smilref="Title.smil#_02931"> (</p><p attribs="{'xml:space': 'preserve'}" id="_02932" smilref="Title.smil#_02932"> T</p><p attribs="{'xml:space': 'preserve'}" id="_02933" smilref="Title.smil#_02933"> (</p><p attribs="{'xml:space': 'preserve'}" id="_02934" smilref="Title.smil#_02934"> g</p><p attribs="{'xml:space': 'preserve'}" id="_02935" smilref="Title.smil#_02935"> l</p><p attribs="{'xml:space': 'preserve'}" id="_02936" smilref="Title.smil#_02936"> 51.2</p><p attribs="{'xml:space': 'preserve'}" id="_02937" smilref="Title.smil#_02937"> 25.6</p><p attribs="{'xml:space': 'preserve'}" id="_02938" smilref="Title.smil#_02938"> 12.8</p><p attribs="{'xml:space': 'preserve'}" id="_02939" smilref="Title.smil#_02939"> 6.4</p><p attribs="{'xml:space': 'preserve'}" id="_02940" smilref="Title.smil#_02940"> 3.2</p><p attribs="{'xml:space': 'preserve'}" id="_02941" smilref="Title.smil#_02941"> 1.6</p><p attribs="{'xml:space': 'preserve'}" id="_02942" smilref="Title.smil#_02942"> .8</p><p attribs="{'xml:space': 'preserve'}" id="_02943" smilref="Title.smil#_02943"> .4</p><p attribs="{'xml:space': 'preserve'}" id="_02944" smilref="Title.smil#_02944"> .2</p><p attribs="{'xml:space': 'preserve'}" id="_02945" smilref="Title.smil#_02945"> .1</p><p attribs="{'xml:space': 'preserve'}" id="_02946" smilref="Title.smil#_02946"> 1K</p><p attribs="{'xml:space': 'preserve'}" id="_02947" smilref="Title.smil#_02947"> 2K</p><p attribs="{'xml:space': 'preserve'}" id="_02948" smilref="Title.smil#_02948"> 4K</p><p attribs="{'xml:space': 'preserve'}" id="_02949" smilref="Title.smil#_02949"> problem size N</p><p attribs="{'xml:space': 'preserve'}" id="_02950" smilref="Title.smil#_02950"> 8K</p><p attribs="{'xml:space': 'preserve'}" id="_02951" smilref="Title.smil#_02951"> 1K</p><p attribs="{'xml:space': 'preserve'}" id="_02952" smilref="Title.smil#_02952"> 2K 4K 8K</p><p attribs="{'xml:space': 'preserve'}" id="_02953" smilref="Title.smil#_02953"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_02954" smilref="Title.smil#_02954"> Analysis of experimental data (the running time of ThreeSum.count())</p><p attribs="{'xml:space': 'preserve'}" id="_02955" smilref="Title.smil#_02955" /></level3><level3 id="_00019"><h3 id="ch1-s4-ss20" smilref="Title.smil#ch1-s4-ss20" xml:space="preserve">Tilde notation</h3><pagenum id="p191" page="normal" smilref="Title.smil#p191" /><p attribs="{'xml:space': 'preserve'}" id="_02956" smilref="Title.smil#_02956"> 178</p><p attribs="{'xml:space': 'preserve'}" id="_02957" smilref="Title.smil#_02957"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_02958" smilref="Title.smil#_02958"> So far, this process mirrors the process scientists use when trying to understand properties of the real world. A straight line in a log-log plot is equivalent to the hypothesis that the data fits the equation T(N ) = a N b . Such a fit is known as a power law. A great many natural and synthetic phenomena are described by power laws, and it is reasonable to hypothesize that the running time of a program does, as well. Indeed, for the analysis of algorithms, we have mathematical models that strongly support this and similar hypotheses, to which we now turn.</p><p attribs="{'xml:space': 'preserve'}" id="_02959" smilref="Title.smil#_02959"> Mathematical models</p><p attribs="{'xml:space': 'preserve'}" id="_02960" smilref="Title.smil#_02960"> In the early days of computer science, D. E. Knuth postulated that, despite all of the complicating factors in understanding the running times of our programs, it is possible, in principle, to build a mathematical model to describe the running time of any program. Knuth&#8217;s basic insight is simple: the total running time of a program is determined by two primary factors: </p><p attribs="{'xml:space': 'preserve'}" id="_02961" smilref="Title.smil#_02961"> times (the number of ways to pick three different numbers from the input array&#8212;see Exercise 1.4.1). Others depend on the input data: for example the number of times the instruction cnt++ in ThreeSum.count() is executed is precisely the number of triples that sum to 0 in the input, which could range from 0 of them to all of them. In the case of DoublingTest, where we generate the numbers randomly, it is possible to do a probabilistic analysis to determine the expected value of this quantity (see Exercise 1.4.40). Tilde approximations. Frequency analyses of this sort can lead to complicated and lengthy mathematical expressions. For example, consider the count just considered of the number of times the if statement in ThreeSum is executed: N (N&#11002;1)(N&#11002;2)/6 = N 3/6 &#11002; N 2/2 &#11001; N/3</p><p attribs="{'xml:space': 'preserve'}" id="_02962" smilref="Title.smil#_02962" /><pagenum id="p192" page="normal" smilref="Title.smil#p192" /><p attribs="{'xml:space': 'preserve'}" id="_02963" smilref="Title.smil#_02963"> As is typical in such expressions, the terms after the leading term are relatively small (for exam- ple, when N = 1,000 the value of &#11002; N 2/2 &#11001; N/3 &#11015; &#11002;499,667 is certainly insignificant by comparison with N 3/6 &#11015; 166,666,667). To allow us to ignore insignificant terms and therefore substantially simplify the mathematical formulas that we work with, we often use a mathematical device known as the tilde notation (~). This notation allows us to work with tilde approxi- mations, where we throw away low-order terms that complicate formulas and represent a negligible contribution to values of interest:</p><p attribs="{'xml:space': 'preserve'}" id="_02964" smilref="Title.smil#_02964"> Definition. We write ~f (N ) to represent any function that, when divided by f (N ), approaches 1 as N grows, and we write g(N ) ~ f (N ) to indicate that g(N )/f (N ) approaches 1 as N grows.</p><p attribs="{'xml:space': 'preserve'}" id="_02965" smilref="Title.smil#_02965"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_02966" smilref="Title.smil#_02966"> 179</p><p attribs="{'xml:space': 'preserve'}" id="_02967" smilref="Title.smil#_02967"> N 3/6</p><p attribs="{'xml:space': 'preserve'}" id="_02968" smilref="Title.smil#_02968"> 166,666,667</p><p attribs="{'xml:space': 'preserve'}" id="_02969" smilref="Title.smil#_02969"> N (N&#11002; 1)(N&#11002; 2)/6</p><p attribs="{'xml:space': 'preserve'}" id="_02970" smilref="Title.smil#_02970"> 166,167,000</p><p attribs="{'xml:space': 'preserve'}" id="_02971" smilref="Title.smil#_02971"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02972" smilref="Title.smil#_02972"> 1,000</p><p attribs="{'xml:space': 'preserve'}" id="_02973" smilref="Title.smil#_02973"> Leading-term approximation</p><p attribs="{'xml:space': 'preserve'}" id="_02974" smilref="Title.smil#_02974"> function</p><p attribs="{'xml:space': 'preserve'}" id="_02975" smilref="Title.smil#_02975"> tilde approximation</p><p attribs="{'xml:space': 'preserve'}" id="_02976" smilref="Title.smil#_02976"> order of growth</p><p attribs="{'xml:space': 'preserve'}" id="_02977" smilref="Title.smil#_02977"> N 3/6 &#11002; N 2/2 &#11001; N/3 N 2/2 &#11002; N/2 lg N + 1</p><p attribs="{'xml:space': 'preserve'}" id="_02978" smilref="Title.smil#_02978"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_02979" smilref="Title.smil#_02979"> ~ N 3/6</p><p attribs="{'xml:space': 'preserve'}" id="_02980" smilref="Title.smil#_02980"> ~ N 2/2</p><p attribs="{'xml:space': 'preserve'}" id="_02981" smilref="Title.smil#_02981"> ~ lg N</p><p attribs="{'xml:space': 'preserve'}" id="_02982" smilref="Title.smil#_02982"> ~ 3</p><p attribs="{'xml:space': 'preserve'}" id="_02983" smilref="Title.smil#_02983"> N 3</p><p attribs="{'xml:space': 'preserve'}" id="_02984" smilref="Title.smil#_02984"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_02985" smilref="Title.smil#_02985"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_02986" smilref="Title.smil#_02986"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_02987" smilref="Title.smil#_02987"> Typical tilde approximations</p><p attribs="{'xml:space': 'preserve'}" id="_02988" smilref="Title.smil#_02988"> order of growth</p><p attribs="{'xml:space': 'preserve'}" id="_02989" smilref="Title.smil#_02989"> description</p><p attribs="{'xml:space': 'preserve'}" id="_02990" smilref="Title.smil#_02990"> function</p><p attribs="{'xml:space': 'preserve'}" id="_02991" smilref="Title.smil#_02991"> constant</p><p attribs="{'xml:space': 'preserve'}" id="_02992" smilref="Title.smil#_02992"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_02993" smilref="Title.smil#_02993"> logarithmic</p><p attribs="{'xml:space': 'preserve'}" id="_02994" smilref="Title.smil#_02994"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_02995" smilref="Title.smil#_02995"> linear</p><p attribs="{'xml:space': 'preserve'}" id="_02996" smilref="Title.smil#_02996"> N</p><p attribs="{'xml:space': 'preserve'}" id="_02997" smilref="Title.smil#_02997"> linearithmic N log N</p><p attribs="{'xml:space': 'preserve'}" id="_02998" smilref="Title.smil#_02998"> quadratic</p><p attribs="{'xml:space': 'preserve'}" id="_02999" smilref="Title.smil#_02999"> cubic</p><p attribs="{'xml:space': 'preserve'}" id="_03000" smilref="Title.smil#_03000"> exponential</p><p attribs="{'xml:space': 'preserve'}" id="_03001" smilref="Title.smil#_03001"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_03002" smilref="Title.smil#_03002"> N 3</p><p attribs="{'xml:space': 'preserve'}" id="_03003" smilref="Title.smil#_03003"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03004" smilref="Title.smil#_03004"> Commonly encountered order-of-growth functions</p><p attribs="{'xml:space': 'preserve'}" id="_03005" smilref="Title.smil#_03005"> For example, we use the approximation ~N 3/6 to describe the number of times the if statement in ThreeSum is executed, since N 3/6 &#11002; N 2/2 &#11001; N/3 divided by N 3/6 approaches 1 as N grows. Most of- ten, we work with tilde approximations of the form g (N) ~af (N ) where f (N ) = N b (log N ) c with a, b, and c constants and refer to f (N ) as the order of growth of g (N ). When using the logarithm in the order of growth, we generally do not specify the base, since the constant a can absorb that detail. This usage covers the relatively few functions that are commonly encountered in studying the order of growth of a program&#8217;s running time shown in the table at left (with the exception of the exponential, which we defer to CONTEXT). We will describe these functions in more detail and briefly discuss why they appear in the analysis of algorithms after we complete our treatment of ThreeSum.</p><p attribs="{'xml:space': 'preserve'}" id="_03006" smilref="Title.smil#_03006" /></level3><level3 id="_00020"><h3 id="ch1-s4-ss21" smilref="Title.smil#ch1-s4-ss21" xml:space="preserve">Running time</h3><pagenum id="p193" page="normal" smilref="Title.smil#p193" /><p attribs="{'xml:space': 'preserve'}" id="_03007" smilref="Title.smil#_03007"> 180</p><p attribs="{'xml:space': 'preserve'}" id="_03008" smilref="Title.smil#_03008"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03009" smilref="Title.smil#_03009"> Approximate running time. To follow through on Knuth&#8217;s approach to develop a mathematical expression for the total running time of a Java program, we can (in prin- ciple) study our Java compiler to find the number of machine instructions corresponding to each Java instruction and study our machine specifications to find the time of execution of each of the machine instructions, to produce a grand total. This process, for ThreeSum, is briefly summarized on the facing page. We classify blocks of Java statements by their frequency of execution, develop leading-term approximations for the frequencies, determine the cost of each statement, and then compute a total. Note that some frequencies may depend on the input. In this case, the number of times cnt++ is executed certainly depends on the input&#8212;it is the number of triples that sum to 0, and could range from 0 to ~N 3/6. We stop short of exhibiting the details (values of the constants) for any particular system, except to highlight that by using constant values t0, t1, t2, ... for the time taken by the blocks of statements, we are assuming that each block of Java statements corresponds to machine instructions that require a specified fixed amount of time. A key observation from this exercise is to note that only the instructions that are executed the most frequently play a role in the final total&#8212;we refer to these instructions as the inner loop of the program. For ThreeSum, the inner loop is the statements that increment k and test that it is less than N and the statements that test whether the sum of three given numbers is 0 (and possibly the statement that implements the count, depending on the input). This behavior is typical: the running times of a great many programs depend only on a small subset of their instructions.</p><p attribs="{'xml:space': 'preserve'}" id="_03010" smilref="Title.smil#_03010"> Order-of-growth hypothesis. In summary, the experiments on page 177 and the mathematical model on page 181 both support the following hypothesis:</p><p attribs="{'xml:space': 'preserve'}" id="_03011" smilref="Title.smil#_03011"> Property A. The order of growth of the running time of ThreeSum (to compute the number of triples that sum to 0 among N numbers) is N 3.</p><p attribs="{'xml:space': 'preserve'}" id="_03012" smilref="Title.smil#_03012"> Evidence: Let T(N ) be the running time of ThreeSum for N numbers. The mathematical model just described suggests that T(N ) ~ aN 3 for some machine-de- pendent constant a; experiments on many computers (including yours and ours) validate that approximation.</p><p attribs="{'xml:space': 'preserve'}" id="_03013" smilref="Title.smil#_03013"> Throughout this book, we use the term property to refer to a hypothesis that needs to be validated through experimentation. The end result of our mathematical analysis is precisely the same as the end result of our experimental analysis&#8212;the running time of ThreeSum is ~ a N 3 for a machine-dependent constant a. This match validates both the experiments and the mathematical model and also exhibits more insight about the</p><p attribs="{'xml:space': 'preserve'}" id="_03014" smilref="Title.smil#_03014" /><pagenum id="p194" page="normal" smilref="Title.smil#p194" /><p attribs="{'xml:space': 'preserve'}" id="_03015" smilref="Title.smil#_03015"> public class ThreeSum { public static int count(int[] a) { int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++ ) for (int j = i+1; j &lt; N; j++ ) for (int k = j+1; k &lt; N; k++ ) if (a[i] + a[j] + a[k] == 0) cnt++;</p><p attribs="{'xml:space': 'preserve'}" id="_03016" smilref="Title.smil#_03016"> A</p><p attribs="{'xml:space': 'preserve'}" id="_03017" smilref="Title.smil#_03017"> B C D E</p><p attribs="{'xml:space': 'preserve'}" id="_03018" smilref="Title.smil#_03018"> s t</p><p attribs="{'xml:space': 'preserve'}" id="_03019" smilref="Title.smil#_03019"> n</p><p attribs="{'xml:space': 'preserve'}" id="_03020" smilref="Title.smil#_03020"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03021" smilref="Title.smil#_03021"> m</p><p attribs="{'xml:space': 'preserve'}" id="_03022" smilref="Title.smil#_03022"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03023" smilref="Title.smil#_03023"> t</p><p attribs="{'xml:space': 'preserve'}" id="_03024" smilref="Title.smil#_03024"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03025" smilref="Title.smil#_03025"> t s</p><p attribs="{'xml:space': 'preserve'}" id="_03026" smilref="Title.smil#_03026"> f</p><p attribs="{'xml:space': 'preserve'}" id="_03027" smilref="Title.smil#_03027"> o</p><p attribs="{'xml:space': 'preserve'}" id="_03028" smilref="Title.smil#_03028"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03029" smilref="Title.smil#_03029"> k</p><p attribs="{'xml:space': 'preserve'}" id="_03030" smilref="Title.smil#_03030"> c</p><p attribs="{'xml:space': 'preserve'}" id="_03031" smilref="Title.smil#_03031"> o</p><p attribs="{'xml:space': 'preserve'}" id="_03032" smilref="Title.smil#_03032"> l</p><p attribs="{'xml:space': 'preserve'}" id="_03033" smilref="Title.smil#_03033"> b</p><p attribs="{'xml:space': 'preserve'}" id="_03034" smilref="Title.smil#_03034"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03035" smilref="Title.smil#_03035"> 181</p><p attribs="{'xml:space': 'preserve'}" id="_03036" smilref="Title.smil#_03036"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03037" smilref="Title.smil#_03037"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03038" smilref="Title.smil#_03038"> ~N 2/ 2 ~N 3/ 6 x</p><p attribs="{'xml:space': 'preserve'}" id="_03039" smilref="Title.smil#_03039"> f</p><p attribs="{'xml:space': 'preserve'}" id="_03040" smilref="Title.smil#_03040"> r e</p><p attribs="{'xml:space': 'preserve'}" id="_03041" smilref="Title.smil#_03041"> q u</p><p attribs="{'xml:space': 'preserve'}" id="_03042" smilref="Title.smil#_03042"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03043" smilref="Title.smil#_03043"> n</p><p attribs="{'xml:space': 'preserve'}" id="_03044" smilref="Title.smil#_03044"> c</p><p attribs="{'xml:space': 'preserve'}" id="_03045" smilref="Title.smil#_03045"> i</p><p attribs="{'xml:space': 'preserve'}" id="_03046" smilref="Title.smil#_03046"> e s</p><p attribs="{'xml:space': 'preserve'}" id="_03047" smilref="Title.smil#_03047"> o</p><p attribs="{'xml:space': 'preserve'}" id="_03048" smilref="Title.smil#_03048"> f</p><p attribs="{'xml:space': 'preserve'}" id="_03049" smilref="Title.smil#_03049"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03050" smilref="Title.smil#_03050"> x</p><p attribs="{'xml:space': 'preserve'}" id="_03051" smilref="Title.smil#_03051"> e c</p><p attribs="{'xml:space': 'preserve'}" id="_03052" smilref="Title.smil#_03052"> u</p><p attribs="{'xml:space': 'preserve'}" id="_03053" smilref="Title.smil#_03053"> t i</p><p attribs="{'xml:space': 'preserve'}" id="_03054" smilref="Title.smil#_03054"> o n</p><p attribs="{'xml:space': 'preserve'}" id="_03055" smilref="Title.smil#_03055"> return cnt; }</p><p attribs="{'xml:space': 'preserve'}" id="_03056" smilref="Title.smil#_03056"> public static void main(String[] args) { int[] a = In.readInts(args[0]); StdOut.println(count(a)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_03057" smilref="Title.smil#_03057"> inner loop</p><p attribs="{'xml:space': 'preserve'}" id="_03058" smilref="Title.smil#_03058"> Anatomy of a program&#8217;s statement execution frequencies</p><p attribs="{'xml:space': 'preserve'}" id="_03059" smilref="Title.smil#_03059"> statement block</p><p attribs="{'xml:space': 'preserve'}" id="_03060" smilref="Title.smil#_03060"> time in seconds</p><p attribs="{'xml:space': 'preserve'}" id="_03061" smilref="Title.smil#_03061"> frequency</p><p attribs="{'xml:space': 'preserve'}" id="_03062" smilref="Title.smil#_03062"> E</p><p attribs="{'xml:space': 'preserve'}" id="_03063" smilref="Title.smil#_03063"> D</p><p attribs="{'xml:space': 'preserve'}" id="_03064" smilref="Title.smil#_03064"> C</p><p attribs="{'xml:space': 'preserve'}" id="_03065" smilref="Title.smil#_03065"> B</p><p attribs="{'xml:space': 'preserve'}" id="_03066" smilref="Title.smil#_03066"> A</p><p attribs="{'xml:space': 'preserve'}" id="_03067" smilref="Title.smil#_03067"> t0</p><p attribs="{'xml:space': 'preserve'}" id="_03068" smilref="Title.smil#_03068"> t1 t2 t3 t4</p><p attribs="{'xml:space': 'preserve'}" id="_03069" smilref="Title.smil#_03069"> x (depends on input)</p><p attribs="{'xml:space': 'preserve'}" id="_03070" smilref="Title.smil#_03070"> N 3/6 &#11002; N 2/2 &#11001; N/3 N 2/2 &#11002; N/2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03071" smilref="Title.smil#_03071"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03072" smilref="Title.smil#_03072"> total time</p><p attribs="{'xml:space': 'preserve'}" id="_03073" smilref="Title.smil#_03073"> t0 x t1 (N 3/6 &#11002; N 2/2 &#11001; N/3) t2 (N 2/2 &#11002; N/2) N</p><p attribs="{'xml:space': 'preserve'}" id="_03074" smilref="Title.smil#_03074"> t3 t4</p><p attribs="{'xml:space': 'preserve'}" id="_03075" smilref="Title.smil#_03075"> grand total</p><p attribs="{'xml:space': 'preserve'}" id="_03076" smilref="Title.smil#_03076"> (t1/6) N 3 &#11001; (t2/2 &#11002; t1/2) N 2 &#11001; (t1/3 &#11002; t2/2 &#11001; t3) N</p><p attribs="{'xml:space': 'preserve'}" id="_03077" smilref="Title.smil#_03077"> &#11001; t4 &#11001; t0 x</p><p attribs="{'xml:space': 'preserve'}" id="_03078" smilref="Title.smil#_03078"> tilde approximation</p><p attribs="{'xml:space': 'preserve'}" id="_03079" smilref="Title.smil#_03079"> order of growth</p><p attribs="{'xml:space': 'preserve'}" id="_03080" smilref="Title.smil#_03080"> ~ (t1 / 6) N 3 (assuming x is small) N 3</p><p attribs="{'xml:space': 'preserve'}" id="_03081" smilref="Title.smil#_03081"> Analyzing the running time of a program (example)</p><p attribs="{'xml:space': 'preserve'}" id="_03082" smilref="Title.smil#_03082" /><pagenum id="p195" page="normal" smilref="Title.smil#p195" /><p attribs="{'xml:space': 'preserve'}" id="_03083" smilref="Title.smil#_03083"> 182</p><p attribs="{'xml:space': 'preserve'}" id="_03084" smilref="Title.smil#_03084"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03085" smilref="Title.smil#_03085"> program because it does not require experimentation to determine the exponent. With some effort, we could validate the value of a on a particular system as well, though that activity is generally reserved for experts in situations where performance is critical. Analysis of algorithms. Hypotheses such as Property A are significant because they relate the abstract world of a Java program to the real world of a computer running it. Working with the order of growth allows us to take one further step: to separate a program from the algorithm it implements. The idea that the order of growth of the running time of ThreeSum is N 3 does not depend on the fact that it is implemented in Java or that it is running on your laptop or someone else&#8217;s cellphone or a supercomputer; it depends primarily on the fact that it examines all the different triples of numbers in the input. The algorithm that you are using (and sometimes the input model) determines the order of growth. Separating the algorithm from the implementation on a particular computer is a powerful concept because it allows us to develop knowledge about the performance of algorithms and then apply that knowledge to any computer. For ex- ample, we might say that ThreeSum is an implementation of the brute-force algorithm &#8220;compute the sum of all different triples, counting those that sum to 0&#8221;&#8212;we expect that an implementation of this algorithm in any programming language on any computer will lead to a running time that is proportional to N 3. In fact, much of the knowledge about the performance of classic algorithms was developed decades ago, but that knowledge is still relevant to today&#8217;s computers.</p><p attribs="{'xml:space': 'preserve'}" id="_03086" smilref="Title.smil#_03086"> 3-sum cost model. When</p><p attribs="{'xml:space': 'preserve'}" id="_03087" smilref="Title.smil#_03087"> studying algorithms to solve the 3-sum problem, we count array accesses (the number of times an array entry is accessed, for read or write).</p><p attribs="{'xml:space': 'preserve'}" id="_03088" smilref="Title.smil#_03088"> Cost model. We focus attention on properties of algorithms by articulating a cost model that defines the basic operations used by the algorithms we are studying to solve the problem at hand. For example, an appropriate cost model for the 3-sum problem, shown at right, is the number of times we access an array entry. With this cost model, we can make precise mathematical statements about properties of an algorithm, not just a particular implementation, as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_03089" smilref="Title.smil#_03089"> Proposition B. The brute-force 3-sum algorithm uses ~N 3/2 array accesses to compute the number of triples that sum to 0 among N numbers.</p><p attribs="{'xml:space': 'preserve'}" id="_03090" smilref="Title.smil#_03090"> Proof : The algorithm accesses each of the 3 numbers for each of the ~N 3/6 triples.</p><p attribs="{'xml:space': 'preserve'}" id="_03091" smilref="Title.smil#_03091"> We use the term proposition to refer to mathematical truths about algorithms in terms of a cost model. Throughout this book, we study the algorithms that we consider within</p><p attribs="{'xml:space': 'preserve'}" id="_03092" smilref="Title.smil#_03092" /><pagenum id="p196" page="normal" smilref="Title.smil#p196" /><p attribs="{'xml:space': 'preserve'}" id="_03093" smilref="Title.smil#_03093"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03094" smilref="Title.smil#_03094"> 183</p><p attribs="{'xml:space': 'preserve'}" id="_03095" smilref="Title.smil#_03095"> the framework of a specific cost model. Our intent is to articulate cost models such that the order of growth of the running time for a given implementation is the same as the order of growth of the cost of the underlying algorithm (in other words, the cost model should include operations that fall within the inner loop). We seek precise mathematical results about algorithms (propositions) and also hypotheses about performance of implementations (properties) that you can check through experimentation. In this case, Proposition B is a mathematical truth that supports the hypothesis stated in Property A, which we have validated with experiments, in accordance with the scien- ti&#64257; c method.</p><p attribs="{'xml:space': 'preserve'}" id="_03096" smilref="Title.smil#_03096" /><pagenum id="p197" page="normal" smilref="Title.smil#p197" /><p attribs="{'xml:space': 'preserve'}" id="_03097" smilref="Title.smil#_03097"> 184</p><p attribs="{'xml:space': 'preserve'}" id="_03098" smilref="Title.smil#_03098"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03099" smilref="Title.smil#_03099"> Summary. For many programs, developing a mathematical model of running time reduces to the following steps: </p><p attribs="{'xml:space': 'preserve'}" id="_03100" smilref="Title.smil#_03100"> BinarySearch.</p><p attribs="{'xml:space': 'preserve'}" id="_03101" smilref="Title.smil#_03101"> Binary search. The input model is the array a[] of size N; the inner loop is the statements in the single while loop; the cost model is the compare operation (compare the values of two array entries); and the analysis, discussed in Section 1.1 and given in full detail in Proposition B in Section 3.1, shows that the number of compares is at most lg N &#11001; 1.</p><p attribs="{'xml:space': 'preserve'}" id="_03102" smilref="Title.smil#_03102"> Whitelist. The input model is the N numbers in the whitelist and the M numbers on standard input where we assume M &gt;&gt; N; the inner loop is the statements in the single while loop; the cost model is the compare operation (inherited from binary search); and the analysis is immediate given the analysis of binary search&#8212; the number of compares is at most M (lg N &#11001; 1). Thus, we draw the conclusion that the order of growth of the running time of the whitelist computation is at most M lg N , subject to the following considerations: </p><p attribs="{'xml:space': 'preserve'}" id="_03103" smilref="Title.smil#_03103" /><pagenum id="p198" page="normal" smilref="Title.smil#p198" /><p attribs="{'xml:space': 'preserve'}" id="_03104" smilref="Title.smil#_03104"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03105" smilref="Title.smil#_03105"> 185</p><p attribs="{'xml:space': 'preserve'}" id="_03106" smilref="Title.smil#_03106"> Developing MATHEMATICal models for the analysis of algorithms is a fruitful area of research that is somewhat beyond the scope of this book. Still, as you will see with binary search, mergesort, and many other algorithms, understanding certain mathematical models is critical to understanding the efficiency of fundamental algorithms, so we often present details and/or quote the results of classic studies. When doing so, we encounter various functions and approximations that are widely used in mathematical analysis. For reference, we summarize some of this information in the tables below.</p><p attribs="{'xml:space': 'preserve'}" id="_03107" smilref="Title.smil#_03107"> description</p><p attribs="{'xml:space': 'preserve'}" id="_03108" smilref="Title.smil#_03108"> notation</p><p attribs="{'xml:space': 'preserve'}" id="_03109" smilref="Title.smil#_03109"> definition</p><p attribs="{'xml:space': 'preserve'}" id="_03110" smilref="Title.smil#_03110"> floor</p><p attribs="{'xml:space': 'preserve'}" id="_03111" smilref="Title.smil#_03111"> ceiling</p><p attribs="{'xml:space': 'preserve'}" id="_03112" smilref="Title.smil#_03112"> natural logarithm</p><p attribs="{'xml:space': 'preserve'}" id="_03113" smilref="Title.smil#_03113"> binary logarithm</p><p attribs="{'xml:space': 'preserve'}" id="_03114" smilref="Title.smil#_03114"> integer binary logarithm</p><p attribs="{'xml:space': 'preserve'}" id="_03115" smilref="Title.smil#_03115"> harmonic numbers</p><p attribs="{'xml:space': 'preserve'}" id="_03116" smilref="Title.smil#_03116"> factorial</p><p attribs="{'xml:space': 'preserve'}" id="_03117" smilref="Title.smil#_03117"> &#9123;x&#9126;</p><p attribs="{'xml:space': 'preserve'}" id="_03118" smilref="Title.smil#_03118"> &#9121;x&#9124;</p><p attribs="{'xml:space': 'preserve'}" id="_03119" smilref="Title.smil#_03119"> ln N</p><p attribs="{'xml:space': 'preserve'}" id="_03120" smilref="Title.smil#_03120"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_03121" smilref="Title.smil#_03121"> &#9123;lg N&#9126;</p><p attribs="{'xml:space': 'preserve'}" id="_03122" smilref="Title.smil#_03122"> HN</p><p attribs="{'xml:space': 'preserve'}" id="_03123" smilref="Title.smil#_03123"> N !</p><p attribs="{'xml:space': 'preserve'}" id="_03124" smilref="Title.smil#_03124"> largest integer not greater than x</p><p attribs="{'xml:space': 'preserve'}" id="_03125" smilref="Title.smil#_03125"> smallest integer not smaller than x</p><p attribs="{'xml:space': 'preserve'}" id="_03126" smilref="Title.smil#_03126"> log e N (x such that e x = N)</p><p attribs="{'xml:space': 'preserve'}" id="_03127" smilref="Title.smil#_03127"> log 2 N (x such that 2x = N)</p><p attribs="{'xml:space': 'preserve'}" id="_03128" smilref="Title.smil#_03128"> largest integer not greater than lg N (# bits in binary representation of N ) &#8211; 1 1 &#11001; 1/2 &#11001; 1/3 &#11001; 1/4 &#11001; . . . &#11001; 1/N</p><p attribs="{'xml:space': 'preserve'}" id="_03129" smilref="Title.smil#_03129"> 1 &#11003; 2 &#11003; 3 &#11003; 4 &#11003; . . . &#11003; N</p><p attribs="{'xml:space': 'preserve'}" id="_03130" smilref="Title.smil#_03130"> Commonly encountered functions in the analysis of algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_03131" smilref="Title.smil#_03131"> description</p><p attribs="{'xml:space': 'preserve'}" id="_03132" smilref="Title.smil#_03132"> harmonic sum</p><p attribs="{'xml:space': 'preserve'}" id="_03133" smilref="Title.smil#_03133"> triangular sum</p><p attribs="{'xml:space': 'preserve'}" id="_03134" smilref="Title.smil#_03134"> approximation</p><p attribs="{'xml:space': 'preserve'}" id="_03135" smilref="Title.smil#_03135"> HN = 1 &#11001; 1/2 &#11001; 1/3 &#11001; 1/4 &#11001; . . . &#11001; 1/N ~ ln N 1 &#11001; 2 &#11001; 3 &#11001; 4 &#11001; . . . &#11001; N ~ N 2/2</p><p attribs="{'xml:space': 'preserve'}" id="_03136" smilref="Title.smil#_03136"> geometric sum</p><p attribs="{'xml:space': 'preserve'}" id="_03137" smilref="Title.smil#_03137"> 1 &#11001; 2 &#11001; 4 &#11001; 8 &#11001; . . . &#11001; N = 2N &#8211; 1 ~ 2N when N = 2n</p><p attribs="{'xml:space': 'preserve'}" id="_03138" smilref="Title.smil#_03138"> Stirling&#8217;s approximation</p><p attribs="{'xml:space': 'preserve'}" id="_03139" smilref="Title.smil#_03139"> binomial coefficients</p><p attribs="{'xml:space': 'preserve'}" id="_03140" smilref="Title.smil#_03140"> exponential</p><p attribs="{'xml:space': 'preserve'}" id="_03141" smilref="Title.smil#_03141"> lg N ! = lg 1 &#11001; lg 2 &#11001; lg 3 &#11001; lg 4 &#11001; . . . &#11001; lg N ~ N lg N k ) ~ N k/k! when k is a small constant (1 &#8211; 1/x) x ~ 1/e</p><p attribs="{'xml:space': 'preserve'}" id="_03142" smilref="Title.smil#_03142"> ( N</p><p attribs="{'xml:space': 'preserve'}" id="_03143" smilref="Title.smil#_03143"> Useful approximations for the analysis of algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_03144" smilref="Title.smil#_03144" /></level3><level3 id="_00021"><h3 id="ch1-s4-ss22" smilref="Title.smil#ch1-s4-ss22" xml:space="preserve">Order-of growth classifications</h3><pagenum id="p199" page="normal" smilref="Title.smil#p199" /><p attribs="{'xml:space': 'preserve'}" id="_03145" smilref="Title.smil#_03145"> 186</p><p attribs="{'xml:space': 'preserve'}" id="_03146" smilref="Title.smil#_03146"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03147" smilref="Title.smil#_03147"> Order-of-growth classifications We use just a few structural primitives (state- ments, conditionals, loops, nesting, and method calls) to implement algorithms, so very often the order of growth of the cost is one of just a few functions of the problem size N. These functions are summarized in the table on the facing page, along with the names that we use to refer to them, typical code that leads to each function, and examples. Constant. A program whose running time&#8217;s order of growth is constant executes a fixed number of operations to finish its job; consequently its running time does not depend on N. Most Java operations take constant time. Logarithmic. A program whose running time&#8217;s order of growth is logarithmic is barely slower than a constant-time program. The classic example of a program whose running time is logarithmic in the problem size is binary search (see BinarySearch on page 47). The base of the logarithm is not relevant with respect to the order of growth (since all logarithms with a constant base are related by a constant factor), so we use log N when referring to order of growth. Linear. Programs that spend a constant amount of time processing each piece of input data, or that are based on a single for loop, are quite common. The order of growth of such a program is said to be linear &#8212;its running time is proportional to N. Linearithmic. We use the term linearithmic to describe programs whose running time for a problem of size N has order of growth N log N. Again, the base of the logarithm is not relevant with respect to the order of growth. The prototypical examples of lin- earithmic algorithms are Merge.sort() (see Algorithm 2.4) and Quick.sort() (see</p><p attribs="{'xml:space': 'preserve'}" id="_03148" smilref="Title.smil#_03148"> Algorithm 2.5).</p><p attribs="{'xml:space': 'preserve'}" id="_03149" smilref="Title.smil#_03149"> Quadratic. A typical program whose running time has order of growth N 2 has two nested for loops, used for some calculation involving all pairs of N elements. The elementary sorting algorithms Selection.sort() (see Algorithm 2.1) and Insertion.sort() (see Algorithm 2.2) are prototypes of the programs in this classi&#64257; cation. Cubic. A typical program whose running time has order of growth N 3 has three nested for loops, used for some calculation involving all triples of N elements. Our example for this section, ThreeSum, is a prototype. Exponential. In ChAPter 6 (but not until then!) we will consider programs whose running times are proportional to 2N or higher. Generally, we use the term exponential to refer to algorithms whose order of growth is b N for any constant b &gt; 1, even though different values of b lead to vastly different running times. Exponential algorithms are extremely slow&#8212;you will never run one of them to completion for a large problem. Still, exponential algorithms play a critical role in the theory of algorithms because</p><p attribs="{'xml:space': 'preserve'}" id="_03150" smilref="Title.smil#_03150" /><pagenum id="p200" page="normal" smilref="Title.smil#p200" /><p attribs="{'xml:space': 'preserve'}" id="_03151" smilref="Title.smil#_03151"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03152" smilref="Title.smil#_03152"> 187</p><p attribs="{'xml:space': 'preserve'}" id="_03153" smilref="Title.smil#_03153"> description</p><p attribs="{'xml:space': 'preserve'}" id="_03154" smilref="Title.smil#_03154"> order of growth</p><p attribs="{'xml:space': 'preserve'}" id="_03155" smilref="Title.smil#_03155"> typical code framework</p><p attribs="{'xml:space': 'preserve'}" id="_03156" smilref="Title.smil#_03156"> description</p><p attribs="{'xml:space': 'preserve'}" id="_03157" smilref="Title.smil#_03157"> example</p><p attribs="{'xml:space': 'preserve'}" id="_03158" smilref="Title.smil#_03158"> constant</p><p attribs="{'xml:space': 'preserve'}" id="_03159" smilref="Title.smil#_03159"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03160" smilref="Title.smil#_03160"> a = b + c;</p><p attribs="{'xml:space': 'preserve'}" id="_03161" smilref="Title.smil#_03161"> logarithmic</p><p attribs="{'xml:space': 'preserve'}" id="_03162" smilref="Title.smil#_03162"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_03163" smilref="Title.smil#_03163"> [ see page 47 ]</p><p attribs="{'xml:space': 'preserve'}" id="_03164" smilref="Title.smil#_03164"> statement</p><p attribs="{'xml:space': 'preserve'}" id="_03165" smilref="Title.smil#_03165"> add two numbers</p><p attribs="{'xml:space': 'preserve'}" id="_03166" smilref="Title.smil#_03166"> divide in half</p><p attribs="{'xml:space': 'preserve'}" id="_03167" smilref="Title.smil#_03167"> binary search</p><p attribs="{'xml:space': 'preserve'}" id="_03168" smilref="Title.smil#_03168"> linear</p><p attribs="{'xml:space': 'preserve'}" id="_03169" smilref="Title.smil#_03169"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03170" smilref="Title.smil#_03170"> double max = a[0]; for (int i = 1; i &lt; N; i++) if (a[i] &gt; max) max = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_03171" smilref="Title.smil#_03171"> loop</p><p attribs="{'xml:space': 'preserve'}" id="_03172" smilref="Title.smil#_03172"> find the maximum</p><p attribs="{'xml:space': 'preserve'}" id="_03173" smilref="Title.smil#_03173"> linearithmic N log N</p><p attribs="{'xml:space': 'preserve'}" id="_03174" smilref="Title.smil#_03174"> [ see Algorithm 2.4 ]</p><p attribs="{'xml:space': 'preserve'}" id="_03175" smilref="Title.smil#_03175"> divide and conquer</p><p attribs="{'xml:space': 'preserve'}" id="_03176" smilref="Title.smil#_03176"> mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_03177" smilref="Title.smil#_03177"> quadratic</p><p attribs="{'xml:space': 'preserve'}" id="_03178" smilref="Title.smil#_03178"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_03179" smilref="Title.smil#_03179"> for (int i = 0; i &lt; N; i++) for (int j = i+1; j &lt; N; j++) if (a[i] + a[j] == 0) cnt++;</p><p attribs="{'xml:space': 'preserve'}" id="_03180" smilref="Title.smil#_03180"> double loop</p><p attribs="{'xml:space': 'preserve'}" id="_03181" smilref="Title.smil#_03181"> check all pairs</p><p attribs="{'xml:space': 'preserve'}" id="_03182" smilref="Title.smil#_03182"> cubic</p><p attribs="{'xml:space': 'preserve'}" id="_03183" smilref="Title.smil#_03183"> N 3</p><p attribs="{'xml:space': 'preserve'}" id="_03184" smilref="Title.smil#_03184"> for (int i = 0; i &lt; N; i++) for (int j = i+1; j &lt; N; j++) for (int k = j+1; k &lt; N; k++) if (a[i] + a[j] + a[k] == 0) cnt++;</p><p attribs="{'xml:space': 'preserve'}" id="_03185" smilref="Title.smil#_03185"> exponential</p><p attribs="{'xml:space': 'preserve'}" id="_03186" smilref="Title.smil#_03186"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03187" smilref="Title.smil#_03187"> [ see chapter 6 ]</p><p attribs="{'xml:space': 'preserve'}" id="_03188" smilref="Title.smil#_03188"> triple loop</p><p attribs="{'xml:space': 'preserve'}" id="_03189" smilref="Title.smil#_03189"> check all triples</p><p attribs="{'xml:space': 'preserve'}" id="_03190" smilref="Title.smil#_03190"> exhasutive search</p><p attribs="{'xml:space': 'preserve'}" id="_03191" smilref="Title.smil#_03191"> check all subsets</p><p attribs="{'xml:space': 'preserve'}" id="_03192" smilref="Title.smil#_03192"> Summary of common order-of-growth hypotheses</p><p attribs="{'xml:space': 'preserve'}" id="_03193" smilref="Title.smil#_03193" /><pagenum id="p201" page="normal" smilref="Title.smil#p201" /><p attribs="{'xml:space': 'preserve'}" id="_03194" smilref="Title.smil#_03194"> 188</p><p attribs="{'xml:space': 'preserve'}" id="_03195" smilref="Title.smil#_03195"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03196" smilref="Title.smil#_03196"> there exists a large class of problems for which it seems that an exponential algorithm is the best possible choice.</p><p attribs="{'xml:space': 'preserve'}" id="_03197" smilref="Title.smil#_03197"> These classifications are the most common, but certainly not a complete set. The</p><p attribs="{'xml:space': 'preserve'}" id="_03198" smilref="Title.smil#_03198"> exponential cubic quadratic</p><p attribs="{'xml:space': 'preserve'}" id="_03199" smilref="Title.smil#_03199"> logarithmic constant</p><p attribs="{'xml:space': 'preserve'}" id="_03200" smilref="Title.smil#_03200"> linearith mic linear</p><p attribs="{'xml:space': 'preserve'}" id="_03201" smilref="Title.smil#_03201"> order of growth of an algorithm&#8217;s cost might be N 2 log N or N 3/2 or some similar func- tion. Indeed, the detailed analysis of algorithms can require the full gamut of mathematical tools that have been developed over the centuries. A great many of the algorithms that we consider have straightforward performance characteristics that can be accurately described by one of the orders of growth that we have considered. Accordingly, we can usually work with specific propositions with a cost model, such as mergesort uses between &#189; N lg N and N lg N compares that immediately imply hypotheses (properties) such as the order of growth of mergesort&#8217;s running time is linearithmic. For economy, we abbreviate such a statement to just say mergesort is linearithmic. The plots at left indicate the importance of the order of growth in practice. The x-axis is the problem size; the y-axis is the running time. These charts make plain that quadratic and cubic algorithms are not feasible for use on large prob- lems. As it turns out, several important problems have natural solutions that are quadratic but clever algorithms that are linearithmic. Such algorithms (including mergesort) are critically important in practice because they enable us to address problem sizes far larger than could be addressed with quadratic solutions. Naturally, we therefore focus in this book on developing loga- rithmic, linear, and linearithmic algorithms for fundamental problems.</p><p attribs="{'xml:space': 'preserve'}" id="_03202" smilref="Title.smil#_03202"> linearith mic linear</p><p attribs="{'xml:space': 'preserve'}" id="_03203" smilref="Title.smil#_03203"> quadratic</p><p attribs="{'xml:space': 'preserve'}" id="_03204" smilref="Title.smil#_03204"> bic c</p><p attribs="{'xml:space': 'preserve'}" id="_03205" smilref="Title.smil#_03205"> u</p><p attribs="{'xml:space': 'preserve'}" id="_03206" smilref="Title.smil#_03206"> 100K</p><p attribs="{'xml:space': 'preserve'}" id="_03207" smilref="Title.smil#_03207"> 200K</p><p attribs="{'xml:space': 'preserve'}" id="_03208" smilref="Title.smil#_03208"> problem size</p><p attribs="{'xml:space': 'preserve'}" id="_03209" smilref="Title.smil#_03209"> 500K</p><p attribs="{'xml:space': 'preserve'}" id="_03210" smilref="Title.smil#_03210"> standard plot</p><p attribs="{'xml:space': 'preserve'}" id="_03211" smilref="Title.smil#_03211"> 500T</p><p attribs="{'xml:space': 'preserve'}" id="_03212" smilref="Title.smil#_03212"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03213" smilref="Title.smil#_03213"> m</p><p attribs="{'xml:space': 'preserve'}" id="_03214" smilref="Title.smil#_03214"> i</p><p attribs="{'xml:space': 'preserve'}" id="_03215" smilref="Title.smil#_03215"> t</p><p attribs="{'xml:space': 'preserve'}" id="_03216" smilref="Title.smil#_03216"> 200T</p><p attribs="{'xml:space': 'preserve'}" id="_03217" smilref="Title.smil#_03217"> 100T</p><p attribs="{'xml:space': 'preserve'}" id="_03218" smilref="Title.smil#_03218"> log-log plot</p><p attribs="{'xml:space': 'preserve'}" id="_03219" smilref="Title.smil#_03219"> l</p><p attribs="{'xml:space': 'preserve'}" id="_03220" smilref="Title.smil#_03220"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03221" smilref="Title.smil#_03221"> i t</p><p attribs="{'xml:space': 'preserve'}" id="_03222" smilref="Title.smil#_03222"> n</p><p attribs="{'xml:space': 'preserve'}" id="_03223" smilref="Title.smil#_03223"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03224" smilref="Title.smil#_03224"> n</p><p attribs="{'xml:space': 'preserve'}" id="_03225" smilref="Title.smil#_03225"> o p x</p><p attribs="{'xml:space': 'preserve'}" id="_03226" smilref="Title.smil#_03226"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03227" smilref="Title.smil#_03227"> 512T</p><p attribs="{'xml:space': 'preserve'}" id="_03228" smilref="Title.smil#_03228"> 64T</p><p attribs="{'xml:space': 'preserve'}" id="_03229" smilref="Title.smil#_03229"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03230" smilref="Title.smil#_03230"> m</p><p attribs="{'xml:space': 'preserve'}" id="_03231" smilref="Title.smil#_03231"> i</p><p attribs="{'xml:space': 'preserve'}" id="_03232" smilref="Title.smil#_03232"> t</p><p attribs="{'xml:space': 'preserve'}" id="_03233" smilref="Title.smil#_03233"> 8T</p><p attribs="{'xml:space': 'preserve'}" id="_03234" smilref="Title.smil#_03234"> 4T</p><p attribs="{'xml:space': 'preserve'}" id="_03235" smilref="Title.smil#_03235"> 2T</p><p attribs="{'xml:space': 'preserve'}" id="_03236" smilref="Title.smil#_03236"> T</p><p attribs="{'xml:space': 'preserve'}" id="_03237" smilref="Title.smil#_03237"> logarithmic</p><p attribs="{'xml:space': 'preserve'}" id="_03238" smilref="Title.smil#_03238"> constant</p><p attribs="{'xml:space': 'preserve'}" id="_03239" smilref="Title.smil#_03239"> 1K</p><p attribs="{'xml:space': 'preserve'}" id="_03240" smilref="Title.smil#_03240"> 2K 4K 8K</p><p attribs="{'xml:space': 'preserve'}" id="_03241" smilref="Title.smil#_03241"> problem size</p><p attribs="{'xml:space': 'preserve'}" id="_03242" smilref="Title.smil#_03242"> Typical orders of growth</p><p attribs="{'xml:space': 'preserve'}" id="_03243" smilref="Title.smil#_03243"> 512K</p><p attribs="{'xml:space': 'preserve'}" id="_03244" smilref="Title.smil#_03244" /><pagenum id="p202" page="normal" smilref="Title.smil#p202" /><p attribs="{'xml:space': 'preserve'}" id="_03245" smilref="Title.smil#_03245"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03246" smilref="Title.smil#_03246"> 189</p><p attribs="{'xml:space': 'preserve'}" id="_03247" smilref="Title.smil#_03247"> Designing faster algorithms One of the primary reasons to study the order of growth of a program is to help design a faster algorithm to solve the same problem. To illustrate this point, we consider next a faster algorithm for the 3-sum problem. How can we devise a faster algorithm, before even embarking on the study of algorithms? The answer to this question is that we have discussed and used two classic algorithms, mergesort and binary search, have introduced the facts that the mergesort is linearith- mic and binary search is logarithmic. How can we take advantage of these algorithms to solve the 3-sum problem?</p><p attribs="{'xml:space': 'preserve'}" id="_03248" smilref="Title.smil#_03248"> Warmup: 2-sum. Consider the easier problem of determining the number of pairs of integers in an inputfile that sum to 0. To simplify the discussion, assume also that the integers are distinct. This problem is easily solved in quadratic time by deleting the k loop and a[k] from ThreeSum.count(), leaving a double loop that examines all pairs, as shown in the quadratic entry in the table on page 187 (we refer to such an implementation as TwoSum). The implementation below shows how mergesort and binary search (see page 47) can serve as a basis for a linearithmic solution to the 2-sum problem. The improved algorithm is based on the fact that an entry a[i] is one of a pair that sums to 0 if and only if the value -a[i] is in the array (and a[i] is not zero). To solve the prob- lem, we sort the array (to enable binary search) and then, for every entry a[i] in the ar- ray, do a binary search for -a[i] with rank() in BinarySearch. If the result is an index j with j &gt; i, we increment the count. This succinct test covers three cases: </p><p attribs="{'xml:space': 'preserve'}" id="_03249" smilref="Title.smil#_03249"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_03250" smilref="Title.smil#_03250"> public class TwoSumFast { public static int count(int[] a) { // Count pairs that sum to 0. Arrays.sort(a); int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++) if (BinarySearch.rank(-a[i], a) &gt; i) cnt++; return cnt; }</p><p attribs="{'xml:space': 'preserve'}" id="_03251" smilref="Title.smil#_03251"> public static void main(String[] args) { int[] a = In.readInts(args[0]); StdOut.println(count(a)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_03252" smilref="Title.smil#_03252"> Linearithmic solution to the 2-sum problem</p><p attribs="{'xml:space': 'preserve'}" id="_03253" smilref="Title.smil#_03253"> a[i] + a[j] = 0, so we incre-</p><p attribs="{'xml:space': 'preserve'}" id="_03254" smilref="Title.smil#_03254"> ment the count. </p><p attribs="{'xml:space': 'preserve'}" id="_03255" smilref="Title.smil#_03255"> a[i] + a[j] = 0 but do not</p><p attribs="{'xml:space': 'preserve'}" id="_03256" smilref="Title.smil#_03256"> increment the count, to avoid double counting. The result of the computation is precisely the same as the result of the quadratic algorithm, but it takes much less time. The running time of the mergesort is</p><p attribs="{'xml:space': 'preserve'}" id="_03257" smilref="Title.smil#_03257" /><pagenum id="p203" page="normal" smilref="Title.smil#p203" /><p attribs="{'xml:space': 'preserve'}" id="_03258" smilref="Title.smil#_03258"> 190</p><p attribs="{'xml:space': 'preserve'}" id="_03259" smilref="Title.smil#_03259"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03260" smilref="Title.smil#_03260"> proportional to N log N, and the N binary searches each take time proportional to log N, so the running time of the whole algorithm is proportional to N log N. Developing a faster algorithm like this is not merely an academic exercise&#8212;the faster algorithm enables us to address much larger problems. For example, you are likely to be able to solve the 2-sum problem for 1 million integers (1Mints.txt) in a reasonable amount of time on your computer, but you would have to wait quite a long time to do it with the quadratic algorithm (see Exercise 1.4.41). Fast algorithm for 3-sum. The very same idea is effective for the 3-sum problem. Again, assume also that the integers are distinct. A pair a[i] and a[j] is part of a triple that sums to 0 if and only if the value -(a[i] + a[j]) is in the array (and not a[i] or a[j]). The code below sorts the array, then does N (N&#11002;1)/ 2 binary searches that each take time proportional to log N, for a total running time proportional to N 2 log N. Note that in this case the cost of the sort is insigni&#64257; cant. Again, this solution enables us to address much larger problems (see Exercise 1.4.42). The plots in the figure at the bottom of the next page show the disparity in costs among these four algorithms for problem sizes in the range we have considered. Such differences certainly motivate the search for faster algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_03261" smilref="Title.smil#_03261"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_03262" smilref="Title.smil#_03262"> public class ThreeSumFast { public static int count(int[] a) { // Count triples that sum to 0. Arrays.sort(a); int N = a.length; int cnt = 0; for (int i = 0; i &lt; N; i++) for (int j = i+1; j &lt; N; j++) if (BinarySearch.rank(-a[i]-a[j], a) &gt; j) cnt++; return cnt; }</p><p attribs="{'xml:space': 'preserve'}" id="_03263" smilref="Title.smil#_03263"> Lower bounds. The table on page 191 summarizes the discussion of this section. An interesting question immediately arises: Can we find algorithms for the 2-sum and 3-sum problems that are substantially faster than TwoSumFast and ThreeSumFast? Is there a linear algorithm for 2-sum or a linea- rithmic algorithm for 3-sum? The answer to this question is no for 2-sum (under a model that counts and allows only comparisons of linear or quadratic functions of the numbers) and no one knows for 3-sum, though experts believe that the best possible algorithm for 3-sum is quadratic. The idea of a lower bound on the order of growth of the worst-case running time for all possible algorithms to solve a problem is a very powerful one, which we will</p><p attribs="{'xml:space': 'preserve'}" id="_03264" smilref="Title.smil#_03264"> public static void main(String[] args) { int[] a = In.readInts(args[0]); StdOut.println(count(a)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_03265" smilref="Title.smil#_03265"> N 2 lg N solution to the 3-sum problem</p><p attribs="{'xml:space': 'preserve'}" id="_03266" smilref="Title.smil#_03266" /><pagenum id="p204" page="normal" smilref="Title.smil#p204" /><p attribs="{'xml:space': 'preserve'}" id="_03267" smilref="Title.smil#_03267"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03268" smilref="Title.smil#_03268"> 191</p><p attribs="{'xml:space': 'preserve'}" id="_03269" smilref="Title.smil#_03269"> revisit in detail in Section 2.2 in the context of sorting. Non- trivial lower bounds are difficult to establish, but very helpful in guiding our search for efficient algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_03270" smilref="Title.smil#_03270"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_03271" smilref="Title.smil#_03271"> TwoSum</p><p attribs="{'xml:space': 'preserve'}" id="_03272" smilref="Title.smil#_03272"> The examples in this section set the stage for our treat-</p><p attribs="{'xml:space': 'preserve'}" id="_03273" smilref="Title.smil#_03273"> TwoSumFast</p><p attribs="{'xml:space': 'preserve'}" id="_03274" smilref="Title.smil#_03274"> ment of algorithms in this book. Throughout the book, our strategy for addressing new problems is the following: </p><p attribs="{'xml:space': 'preserve'}" id="_03275" smilref="Title.smil#_03275"> ThreeSumFast</p><p attribs="{'xml:space': 'preserve'}" id="_03276" smilref="Title.smil#_03276"> ThreeSum</p><p attribs="{'xml:space': 'preserve'}" id="_03277" smilref="Title.smil#_03277"> order of growth of running time</p><p attribs="{'xml:space': 'preserve'}" id="_03278" smilref="Title.smil#_03278"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_03279" smilref="Title.smil#_03279"> N log N</p><p attribs="{'xml:space': 'preserve'}" id="_03280" smilref="Title.smil#_03280"> N 3</p><p attribs="{'xml:space': 'preserve'}" id="_03281" smilref="Title.smil#_03281"> N 2 log N</p><p attribs="{'xml:space': 'preserve'}" id="_03282" smilref="Title.smil#_03282"> Summary of running times</p><p attribs="{'xml:space': 'preserve'}" id="_03283" smilref="Title.smil#_03283"> ThreeSumFast.</p><p attribs="{'xml:space': 'preserve'}" id="_03284" smilref="Title.smil#_03284"> </p><p attribs="{'xml:space': 'preserve'}" id="_03285" smilref="Title.smil#_03285"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_03286" smilref="Title.smil#_03286"> 80</p><p attribs="{'xml:space': 'preserve'}" id="_03287" smilref="Title.smil#_03287"> 60</p><p attribs="{'xml:space': 'preserve'}" id="_03288" smilref="Title.smil#_03288"> 40</p><p attribs="{'xml:space': 'preserve'}" id="_03289" smilref="Title.smil#_03289"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_03290" smilref="Title.smil#_03290"> )</p><p attribs="{'xml:space': 'preserve'}" id="_03291" smilref="Title.smil#_03291"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03292" smilref="Title.smil#_03292"> d n a</p><p attribs="{'xml:space': 'preserve'}" id="_03293" smilref="Title.smil#_03293"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03294" smilref="Title.smil#_03294"> u o h</p><p attribs="{'xml:space': 'preserve'}" id="_03295" smilref="Title.smil#_03295"> t (</p><p attribs="{'xml:space': 'preserve'}" id="_03296" smilref="Title.smil#_03296"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03297" smilref="Title.smil#_03297"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03298" smilref="Title.smil#_03298"> s s</p><p attribs="{'xml:space': 'preserve'}" id="_03299" smilref="Title.smil#_03299"> e c c a y a</p><p attribs="{'xml:space': 'preserve'}" id="_03300" smilref="Title.smil#_03300"> r r</p><p attribs="{'xml:space': 'preserve'}" id="_03301" smilref="Title.smil#_03301"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03302" smilref="Title.smil#_03302"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03303" smilref="Title.smil#_03303"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03304" smilref="Title.smil#_03304"> 1000</p><p attribs="{'xml:space': 'preserve'}" id="_03305" smilref="Title.smil#_03305"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03306" smilref="Title.smil#_03306"> 3/2</p><p attribs="{'xml:space': 'preserve'}" id="_03307" smilref="Title.smil#_03307"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03308" smilref="Title.smil#_03308"> 2 lgN</p><p attribs="{'xml:space': 'preserve'}" id="_03309" smilref="Title.smil#_03309"> ThreeSum</p><p attribs="{'xml:space': 'preserve'}" id="_03310" smilref="Title.smil#_03310"> )</p><p attribs="{'xml:space': 'preserve'}" id="_03311" smilref="Title.smil#_03311"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03312" smilref="Title.smil#_03312"> n o</p><p attribs="{'xml:space': 'preserve'}" id="_03313" smilref="Title.smil#_03313"> i l l i</p><p attribs="{'xml:space': 'preserve'}" id="_03314" smilref="Title.smil#_03314"> m</p><p attribs="{'xml:space': 'preserve'}" id="_03315" smilref="Title.smil#_03315"> (</p><p attribs="{'xml:space': 'preserve'}" id="_03316" smilref="Title.smil#_03316"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03317" smilref="Title.smil#_03317"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03318" smilref="Title.smil#_03318"> s s</p><p attribs="{'xml:space': 'preserve'}" id="_03319" smilref="Title.smil#_03319"> e c c a y a</p><p attribs="{'xml:space': 'preserve'}" id="_03320" smilref="Title.smil#_03320"> r r</p><p attribs="{'xml:space': 'preserve'}" id="_03321" smilref="Title.smil#_03321"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03322" smilref="Title.smil#_03322"> 800</p><p attribs="{'xml:space': 'preserve'}" id="_03323" smilref="Title.smil#_03323"> 600</p><p attribs="{'xml:space': 'preserve'}" id="_03324" smilref="Title.smil#_03324"> 400</p><p attribs="{'xml:space': 'preserve'}" id="_03325" smilref="Title.smil#_03325"> 200</p><p attribs="{'xml:space': 'preserve'}" id="_03326" smilref="Title.smil#_03326"> ThreeSumFast</p><p attribs="{'xml:space': 'preserve'}" id="_03327" smilref="Title.smil#_03327"> TwoSum</p><p attribs="{'xml:space': 'preserve'}" id="_03328" smilref="Title.smil#_03328"> TwoSumFast</p><p attribs="{'xml:space': 'preserve'}" id="_03329" smilref="Title.smil#_03329"> 4N</p><p attribs="{'xml:space': 'preserve'}" id="_03330" smilref="Title.smil#_03330"> lgN</p><p attribs="{'xml:space': 'preserve'}" id="_03331" smilref="Title.smil#_03331"> 1K</p><p attribs="{'xml:space': 'preserve'}" id="_03332" smilref="Title.smil#_03332"> 2K</p><p attribs="{'xml:space': 'preserve'}" id="_03333" smilref="Title.smil#_03333"> 4K</p><p attribs="{'xml:space': 'preserve'}" id="_03334" smilref="Title.smil#_03334"> problem size N</p><p attribs="{'xml:space': 'preserve'}" id="_03335" smilref="Title.smil#_03335"> 8K</p><p attribs="{'xml:space': 'preserve'}" id="_03336" smilref="Title.smil#_03336"> 1K</p><p attribs="{'xml:space': 'preserve'}" id="_03337" smilref="Title.smil#_03337"> 2K</p><p attribs="{'xml:space': 'preserve'}" id="_03338" smilref="Title.smil#_03338"> 4K</p><p attribs="{'xml:space': 'preserve'}" id="_03339" smilref="Title.smil#_03339"> problem size N</p><p attribs="{'xml:space': 'preserve'}" id="_03340" smilref="Title.smil#_03340"> 8K</p><p attribs="{'xml:space': 'preserve'}" id="_03341" smilref="Title.smil#_03341"> Costs of algorithms to solve the 2-sum and 3-sum problems</p><p attribs="{'xml:space': 'preserve'}" id="_03342" smilref="Title.smil#_03342" /></level3><level3 id="_00022"><h3 id="ch1-s4-ss23" smilref="Title.smil#ch1-s4-ss23" xml:space="preserve">Computational experiments</h3><pagenum id="p205" page="normal" smilref="Title.smil#p205" /><p attribs="{'xml:space': 'preserve'}" id="_03343" smilref="Title.smil#_03343"> 192</p><p attribs="{'xml:space': 'preserve'}" id="_03344" smilref="Title.smil#_03344"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03345" smilref="Title.smil#_03345"> Doubling ratio experiments The following is a simple and effective shortcut for predicting performance and for determining the approximate order of growth of the running time of any program: </p><p attribs="{'xml:space': 'preserve'}" id="_03346" smilref="Title.smil#_03346"> 1.4.9).</p><p attribs="{'xml:space': 'preserve'}" id="_03347" smilref="Title.smil#_03347"> As illustrated below, the ratio for ThreeSum is about 8 and we can predict the running times for N = 16,000, 32,000, 64,000 to be 408.8, 3270.4, 26163.2 seconds, respectively, just by successively multiplying the last time for 8,000 (51.1) by 8.</p><p attribs="{'xml:space': 'preserve'}" id="_03348" smilref="Title.smil#_03348"> program to per form experiments</p><p attribs="{'xml:space': 'preserve'}" id="_03349" smilref="Title.smil#_03349"> public class DoublingRatio { public static double timeTrial(int N) // same as for DoublingTest (page 177)</p><p attribs="{'xml:space': 'preserve'}" id="_03350" smilref="Title.smil#_03350"> public static void main(String[] args) { double prev = timeTrial(125); for (int N = 250; true; N += N) { double time = timeTrial(N); StdOut.printf("%6d %7.1f ", N, time); StdOut.printf("%5.1f\n", time/prev); prev = time; } } }</p><p attribs="{'xml:space': 'preserve'}" id="_03351" smilref="Title.smil#_03351"> results of experiments</p><p attribs="{'xml:space': 'preserve'}" id="_03352" smilref="Title.smil#_03352"> % java DoublingRatio 250 0.0 2.7 500 0.0 4.8 1000 0.1 6.9 2000 0.8 7.7 4000 6.4 8.0 8000 51.1 8.0</p><p attribs="{'xml:space': 'preserve'}" id="_03353" smilref="Title.smil#_03353"> predictions</p><p attribs="{'xml:space': 'preserve'}" id="_03354" smilref="Title.smil#_03354"> 16000 408.8 8.0 32000 3270.4 8.0 64000 26163.2 8.0</p><p attribs="{'xml:space': 'preserve'}" id="_03355" smilref="Title.smil#_03355" /><pagenum id="p206" page="normal" smilref="Title.smil#p206" /><p attribs="{'xml:space': 'preserve'}" id="_03356" smilref="Title.smil#_03356"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03357" smilref="Title.smil#_03357"> 193</p><p attribs="{'xml:space': 'preserve'}" id="_03358" smilref="Title.smil#_03358"> This test is roughly equivalent to the process described on page 176 (run experiments, plot values on a log-log plot to develop the hypothesis that the running time is aN b, determine the value of b from the slope of the line, then solve for a), but it is simpler to apply. Indeed, you can accurately predict preformance by hand when you run DoublingRatio. As the ratio approaches a limit, just multiply by that ratio to fill in later values in the table. Your approximate model of the order of growth is a power law with the binary logarithm of that ratio as the power. Why does the ratio approach a constant? A simple mathematical calculation shows that to be the case for all of the common orders of growth just discussed (except exponential):</p><p attribs="{'xml:space': 'preserve'}" id="_03359" smilref="Title.smil#_03359"> Proposition C. (Doubling ratio) If T(N) ~ a N b lg N then T(2N)/T(N) ~ 2b .</p><p attribs="{'xml:space': 'preserve'}" id="_03360" smilref="Title.smil#_03360"> Proof : Immediate from the following calculation: T(2N)/T(N) = a (2N )b lg (2N ) / a N b lg N</p><p attribs="{'xml:space': 'preserve'}" id="_03361" smilref="Title.smil#_03361"> = 2b (1 + lg 2 / lg N )</p><p attribs="{'xml:space': 'preserve'}" id="_03362" smilref="Title.smil#_03362"> ~ 2b</p><p attribs="{'xml:space': 'preserve'}" id="_03363" smilref="Title.smil#_03363"> Generally, the logarithmic factor cannot be ignored when developing a mathematical model, but it plays a less important role in predicting performance with a doubling hypothesis.</p><p attribs="{'xml:space': 'preserve'}" id="_03364" smilref="Title.smil#_03364"> You should consider running doubling ratio experiments for every program that you write where performance matters&#8212;doing so is a very simple way to estimate the order of growth of the running time, perhaps revealing a performance bug where a program may turn out to be not as efficient as you might think. More generally, we can use hypotheses about the order of growth of the running time of programs to predict performance in one of the following ways:</p><p attribs="{'xml:space': 'preserve'}" id="_03365" smilref="Title.smil#_03365"> Estimating the feasibility of solving large problems. You need to be able to answer</p><p attribs="{'xml:space': 'preserve'}" id="_03366" smilref="Title.smil#_03366"> this basic question for every program that you write: Will the program be able to process this given input data in a reasonable amount of time? To address such questions for a large amount of data, we extrapolate by a much larger factor than for doubling, say 10, as shown in the fourth column in the table at the bottom of the next page. Whether it is an investment banker running daily financial models or a scientist running a program to analyze experimental data or an engineer running simulations to test a design, it is not unusual for people to regularly run programs that take several hours to complete,</p><p attribs="{'xml:space': 'preserve'}" id="_03367" smilref="Title.smil#_03367" /><pagenum id="p207" page="normal" smilref="Title.smil#p207" /><p attribs="{'xml:space': 'preserve'}" id="_03368" smilref="Title.smil#_03368"> 194</p><p attribs="{'xml:space': 'preserve'}" id="_03369" smilref="Title.smil#_03369"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03370" smilref="Title.smil#_03370"> so the table focuses on that situation. Knowing the order of growth of the running time of an algorithm provides precisely the information that you need to understand limitations on the size of the problems that you can solve. Developing such understanding is the most important reason to study performance. Without it, you are likely have no idea how much time a program will consume; with it, you can make a back-of-the-envelope calculation to estimate costs and proceed accordingly.</p><p attribs="{'xml:space': 'preserve'}" id="_03371" smilref="Title.smil#_03371"> Estimating the value of using a faster computer. You also may be faced with this basic</p><p attribs="{'xml:space': 'preserve'}" id="_03372" smilref="Title.smil#_03372"> question, periodically : How much faster can I solve the problem if I get a faster computer? Generally, if the new computer is x times faster than the old one, you can improve your running time by a factor of x. But it is usually the case that you can address larger problems with your new computer. How will that change affect the running time? Again, the order of growth is precisely the information needed to answer that question.</p><p attribs="{'xml:space': 'preserve'}" id="_03373" smilref="Title.smil#_03373"> A famous rule of thumb known as Moore&#8217;s Law implies that you can expect to have a computer with about double the speed and double the memory 18 months from now, or a computer with about 10 times the speed and 10 times the memory in about 5 years. The table below demonstrates that you cannot keep pace with Moore&#8217;s Law if you are using a quadratic or a cubic algorithm, and you can quickly determine whether that is the case by doing a doubling ratio test and checking that the ratio of running times as the input size doubles approaches 2, not 4 or 8.</p><p attribs="{'xml:space': 'preserve'}" id="_03374" smilref="Title.smil#_03374"> order of growth of time</p><p attribs="{'xml:space': 'preserve'}" id="_03375" smilref="Title.smil#_03375"> for a program that takes a few hours for input of size N</p><p attribs="{'xml:space': 'preserve'}" id="_03376" smilref="Title.smil#_03376"> description</p><p attribs="{'xml:space': 'preserve'}" id="_03377" smilref="Title.smil#_03377"> function</p><p attribs="{'xml:space': 'preserve'}" id="_03378" smilref="Title.smil#_03378"> 2x factor</p><p attribs="{'xml:space': 'preserve'}" id="_03379" smilref="Title.smil#_03379"> 10x factor</p><p attribs="{'xml:space': 'preserve'}" id="_03380" smilref="Title.smil#_03380"> predicted time for 10N</p><p attribs="{'xml:space': 'preserve'}" id="_03381" smilref="Title.smil#_03381"> predicted time for10N on a 10x faster computer</p><p attribs="{'xml:space': 'preserve'}" id="_03382" smilref="Title.smil#_03382"> linear</p><p attribs="{'xml:space': 'preserve'}" id="_03383" smilref="Title.smil#_03383"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03384" smilref="Title.smil#_03384"> linearithmic N log N</p><p attribs="{'xml:space': 'preserve'}" id="_03385" smilref="Title.smil#_03385"> quadratic</p><p attribs="{'xml:space': 'preserve'}" id="_03386" smilref="Title.smil#_03386"> cubic</p><p attribs="{'xml:space': 'preserve'}" id="_03387" smilref="Title.smil#_03387"> exponential</p><p attribs="{'xml:space': 'preserve'}" id="_03388" smilref="Title.smil#_03388"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_03389" smilref="Title.smil#_03389"> N 3</p><p attribs="{'xml:space': 'preserve'}" id="_03390" smilref="Title.smil#_03390"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03391" smilref="Title.smil#_03391"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03392" smilref="Title.smil#_03392"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03393" smilref="Title.smil#_03393"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03394" smilref="Title.smil#_03394"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_03395" smilref="Title.smil#_03395"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_03396" smilref="Title.smil#_03396"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_03397" smilref="Title.smil#_03397"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_03398" smilref="Title.smil#_03398"> a day</p><p attribs="{'xml:space': 'preserve'}" id="_03399" smilref="Title.smil#_03399"> a day</p><p attribs="{'xml:space': 'preserve'}" id="_03400" smilref="Title.smil#_03400"> a few hours</p><p attribs="{'xml:space': 'preserve'}" id="_03401" smilref="Title.smil#_03401"> a few hours</p><p attribs="{'xml:space': 'preserve'}" id="_03402" smilref="Title.smil#_03402"> a few weeks</p><p attribs="{'xml:space': 'preserve'}" id="_03403" smilref="Title.smil#_03403"> a day</p><p attribs="{'xml:space': 'preserve'}" id="_03404" smilref="Title.smil#_03404"> 1,000</p><p attribs="{'xml:space': 'preserve'}" id="_03405" smilref="Title.smil#_03405"> several months</p><p attribs="{'xml:space': 'preserve'}" id="_03406" smilref="Title.smil#_03406"> a few weeks</p><p attribs="{'xml:space': 'preserve'}" id="_03407" smilref="Title.smil#_03407"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03408" smilref="Title.smil#_03408"> 2 9N</p><p attribs="{'xml:space': 'preserve'}" id="_03409" smilref="Title.smil#_03409"> never</p><p attribs="{'xml:space': 'preserve'}" id="_03410" smilref="Title.smil#_03410"> never</p><p attribs="{'xml:space': 'preserve'}" id="_03411" smilref="Title.smil#_03411"> Predictions on the basis of order-of-growth function</p><p attribs="{'xml:space': 'preserve'}" id="_03412" smilref="Title.smil#_03412" /><pagenum id="p208" page="normal" smilref="Title.smil#p208" /><p attribs="{'xml:space': 'preserve'}" id="_03413" smilref="Title.smil#_03413"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03414" smilref="Title.smil#_03414"> 195</p><p attribs="{'xml:space': 'preserve'}" id="_03415" smilref="Title.smil#_03415"> Caveats There are many reasons that you might get inconsistent or misleading results when trying to analyze program performance in detail. All of them have to do with the idea that one or more of the basic assumptions underlying our hypotheses might be not quite correct. We can develop new hypotheses based on new assumptions, but the more details that we need to take into account, the more care is required in the analysis.</p><p attribs="{'xml:space': 'preserve'}" id="_03416" smilref="Title.smil#_03416"> Large constants. With leading-term approximations, we ignore constant coefficients in lower-order terms, which may not be justifed. For example, when we approximate the function 2 N 2 + c N by ~2 N 2, we are assuming that c is small. If that is not the case (suppose that c is 10 3 or 10 6) the approximation is misleading. Thus, we have to be sensitive to the possibility of large constants.</p><p attribs="{'xml:space': 'preserve'}" id="_03417" smilref="Title.smil#_03417"> Nondominant inner loop. The assumption that the inner loop dominates may not always be correct. The cost model might miss the true inner loop, or the problem size N might not be sufficiently large to make the leading term in the mathematical description of the frequency of execution of instructions in the inner loop so much larger than lower-order terms that we can ignore them. Some programs have a significant amount of code outside the inner loop that needs to be taken into consideration. In other words, the cost model may need to be re&#64257; ned.</p><p attribs="{'xml:space': 'preserve'}" id="_03418" smilref="Title.smil#_03418"> Instruction time. The assumption that each instruction always takes the same amount of time is not always correct. For example, most modern computer systems use a technique known as caching to organize memory, in which case accessing elements in huge arrays can take much longer if they are not close together in the array. You might observe the effect of caching for ThreeSum by letting DoublingTest run for a while. After seeming to converge to 8, the ratio of running times may jump to a larger value for large arrays because of caching.</p><p attribs="{'xml:space': 'preserve'}" id="_03419" smilref="Title.smil#_03419"> System considerations. Typically, there are many, many things going on in your com- puter. Java is one application of many competing for resources, and Java itself has many options and controls that significantly affect performance. A garbage collector or a just- in-time compiler or a download from the internet might drastically affect the results of experiments. Such considerations can interfere with the bedrock principle of the scientific method that experiments should be reproducible, since what is happening at this moment in your computer will never be reproduced again. Whatever else is going on in your system should in principle be negligible or possible to control.</p><p attribs="{'xml:space': 'preserve'}" id="_03420" smilref="Title.smil#_03420"> Too close to call. Often, when we compare two different programs for the same task, one might be faster in some situations, and slower in others. One or more of the considerations just mentioned could make the difference. There is a natural tendency among</p><p attribs="{'xml:space': 'preserve'}" id="_03421" smilref="Title.smil#_03421" /><pagenum id="p209" page="normal" smilref="Title.smil#p209" /><p attribs="{'xml:space': 'preserve'}" id="_03422" smilref="Title.smil#_03422"> 196</p><p attribs="{'xml:space': 'preserve'}" id="_03423" smilref="Title.smil#_03423"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03424" smilref="Title.smil#_03424"> some programmers (and some students) to devote an extreme amount of energy running races to find the &#8220;best&#8221; implementation, but such work is best left for experts.</p><p attribs="{'xml:space': 'preserve'}" id="_03425" smilref="Title.smil#_03425"> Strong dependence on inputs. One of the first assumptions that we made in order to determine the order of growth of the program&#8217;s running time of a program was that the running time should be relatively insensitive to the inputs. When that is not the case, we may get inconsistent results or be unable to validate our hypotheses. For example, suppose that we modify ThreeSum to answer the question Does the input have a triple that sums to 0 ? by changing it to return a boolean value, replacing cnt++ by return true and adding return false as the last statement. The order of growth of the running time of this program is constant if the first three integers sum to 0 and cubic if there are no such triples in the input.</p><p attribs="{'xml:space': 'preserve'}" id="_03426" smilref="Title.smil#_03426"> Multiple problem parameters. We have been focusing on measuring performance as a function of a single parameter, generally the value of a command-line argument or the size of the input. However, it is not unusual to have several parameters. A typical example arises when an algorithm involves building a data structure and then performing a sequence of operations that use that data structure. Both the size of the data structure and the number of operations are parameters for such applications. We have already seen an example of this in our analysis of the problem of whitelisting using binary search, where we have N numbers in the whitelist and M numbers on standard input and a typical running time proportional to M log N.</p><p attribs="{'xml:space': 'preserve'}" id="_03427" smilref="Title.smil#_03427"> Despite all these caveats, understanding the order of growth of the running time of each program is valuable knowledge for any programmer, and the methods that we have described are powerful and broadly applicable. Knuth&#8217;s insight was that we can carry these methods through to the last detail in principle to make detailed, accurate predictions. Typical computer systems are extremely complex and close analysis is best left for experts, but the same methods are effective for developing approximate estimates of the running time of any program. A rocket scientist needs to have some idea of whether a test flight will land in the ocean or in a city ; a medical researcher needs to know whether a drug trial will kill or cure all the subjects; and any scientist or engineer using a computer program needs to have some idea of whether it will run for a second or for a year.</p><p attribs="{'xml:space': 'preserve'}" id="_03428" smilref="Title.smil#_03428" /><pagenum id="p210" page="normal" smilref="Title.smil#p210" /><p attribs="{'xml:space': 'preserve'}" id="_03429" smilref="Title.smil#_03429"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03430" smilref="Title.smil#_03430"> 197</p><p attribs="{'xml:space': 'preserve'}" id="_03431" smilref="Title.smil#_03431"> Coping with dependence on inputs For many problems, one of the most sig- ni&#64257; cant of the caveats just mentioned is the dependence on inputs, because running times can vary widely. The running time of the modification of ThreeSum mentioned on the facing page ranges from constant to cubic, depending on the input, so a closer analysis is required if we want to predict performance. We briefly consider here some of the approaches that are effective and that we will consider for specific algorithms later in the book.</p><p attribs="{'xml:space': 'preserve'}" id="_03432" smilref="Title.smil#_03432"> Input models. One approach is to more carefully model the kind of input to be processed in the problems that we need to solve. For example, we might assume that the numbers in the input to ThreeSum are random int values. This approach is challenging for two reasons: </p><p attribs="{'xml:space': 'preserve'}" id="_03433" smilref="Title.smil#_03433"> Worst-case performance guarantees. Some applications demand that the running time of a program be less than a certain bound, no matter what the input. To provide such performance guarantees, theoreticians take an extremely pessimistic view of the performance of algorithms: what would the running time be in the worst case? For example, such a conservative approach might be appropriate for the software that runs a nuclear reactor or a pacemaker or the brakes in your car. We want to guarantee that such software completes its job within the bounds that we set because the result could be catastrophic if it does not. Scientists normally do not contemplate the worst case when studying the natural world: in biology, the worst case might be the extinction of the human race; in physics, the worst case might be the end of the universe. But the worst case can be a very real concern in computer systems, where the input may be generated by another (potentially malicious) user, rather than by nature. For example, websites that do not use algorithms with performance guarantees are subject to denial- of-service attacks, where hackers flood them with pathological requests that make them</p><p attribs="{'xml:space': 'preserve'}" id="_03434" smilref="Title.smil#_03434" /></level3><level3 id="_00023"><h3 id="ch1-s4-ss24" smilref="Title.smil#ch1-s4-ss24" xml:space="preserve">Amortized analysis</h3><pagenum id="p211" page="normal" smilref="Title.smil#p211" /><p attribs="{'xml:space': 'preserve'}" id="_03435" smilref="Title.smil#_03435"> 198</p><p attribs="{'xml:space': 'preserve'}" id="_03436" smilref="Title.smil#_03436"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03437" smilref="Title.smil#_03437"> run much more slowly than planned. Accordingly, many of our algorithms are designed to provide performance guarantees, such as the following:</p><p attribs="{'xml:space': 'preserve'}" id="_03438" smilref="Title.smil#_03438"> Proposition D. In the linked-list implementations of Bag (Algorithm 1.4), Stack (Algorithm 1.2), and Queue (Algorithm 1.3), all operations take constant time in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_03439" smilref="Title.smil#_03439"> Proof : Immediate from the code. The number of instructions executed for each operation is bounded by a small constant. Caveat : This argument depends upon the (reasonable) assumption that the Java system creates a new Node in constant time.</p><p attribs="{'xml:space': 'preserve'}" id="_03440" smilref="Title.smil#_03440"> Randomized algorithms. One important way to provide a performance guarantee is to introduce randomness. For example, the quicksort algorithm for sorting that we study in Section 2.3 (perhaps the most widely used sorting algorithm) is quadratic in the worst case, but randomly ordering the input gives a probabilistic guarantee that its running time is linearithmic. Every time you run the algorithm, it will take a different amount of time, but the chance that the time will not be linearithmic is so small as to be negligible. Similarly, the hashing algorithms for symbol tables that we study in Section 3.4 (again, perhaps the most widely used approach) are linear-time in the worst case, but constant-time under a probabilistic guarantee. These guarantees are not absolute, but the chance that they are invalid is less than the chance your computer will be struck by lightning. Thus, such guarantees are as useful in practice as worst-case guarantees.</p><p attribs="{'xml:space': 'preserve'}" id="_03441" smilref="Title.smil#_03441"> Sequences of operations. For many applications, the algorithm &#8220;input&#8221; might be not just data, but the sequence of operations performed by the client. For example, a pushdown stack where the client pushes N values, then pops them all, may have quite different performance characteristics from one where the client issues an alternating sequence N of push and pop operations. Our analysis has to take both situations into account (or to include a reasonable model of the sequence of operations).</p><p attribs="{'xml:space': 'preserve'}" id="_03442" smilref="Title.smil#_03442"> Amortized analysis. Accordingly, another way to provide a performance guarantee is to amortize the cost, by keeping track of the total cost of all operations, divided by the number of operations. In this setting, we can allow some expensive operations, while keeping the average cost of operations low. The prototypical example of this type of analysis is the study of the resizing array data structure for Stack that we considered in Section 1.3 (Algorithm 1.1 on page 141). For simplicity, suppose that N is a power of 2. Starting with an empty structure, how many array entries are accessed for N consecutive calls to push()? This quantity is easy to calculate: the number of array accesses is</p><p attribs="{'xml:space': 'preserve'}" id="_03443" smilref="Title.smil#_03443" /><pagenum id="p212" page="normal" smilref="Title.smil#p212" /><p attribs="{'xml:space': 'preserve'}" id="_03444" smilref="Title.smil#_03444"> N + 4 + 8 + 16 + ... + 2N = 5N &#11002; 4</p><p attribs="{'xml:space': 'preserve'}" id="_03445" smilref="Title.smil#_03445"> 256</p><p attribs="{'xml:space': 'preserve'}" id="_03446" smilref="Title.smil#_03446"> )</p><p attribs="{'xml:space': 'preserve'}" id="_03447" smilref="Title.smil#_03447"> s</p><p attribs="{'xml:space': 'preserve'}" id="_03448" smilref="Title.smil#_03448"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03449" smilref="Title.smil#_03449"> 199</p><p attribs="{'xml:space': 'preserve'}" id="_03450" smilref="Title.smil#_03450"> e c</p><p attribs="{'xml:space': 'preserve'}" id="_03451" smilref="Title.smil#_03451"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03452" smilref="Title.smil#_03452"> (</p><p attribs="{'xml:space': 'preserve'}" id="_03453" smilref="Title.smil#_03453"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03454" smilref="Title.smil#_03454"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03455" smilref="Title.smil#_03455"> f</p><p attribs="{'xml:space': 'preserve'}" id="_03456" smilref="Title.smil#_03456"> e</p><p attribs="{'xml:space': 'preserve'}" id="_03457" smilref="Title.smil#_03457"> r</p><p attribs="{'xml:space': 'preserve'}" id="_03458" smilref="Title.smil#_03458"> 64</p><p attribs="{'xml:space': 'preserve'}" id="_03459" smilref="Title.smil#_03459"> n e</p><p attribs="{'xml:space': 'preserve'}" id="_03460" smilref="Title.smil#_03460"> r</p><p attribs="{'xml:space': 'preserve'}" id="_03461" smilref="Title.smil#_03461"> y a</p><p attribs="{'xml:space': 'preserve'}" id="_03462" smilref="Title.smil#_03462"> r r</p><p attribs="{'xml:space': 'preserve'}" id="_03463" smilref="Title.smil#_03463"> 128</p><p attribs="{'xml:space': 'preserve'}" id="_03464" smilref="Title.smil#_03464"> one gray dot for each operation</p><p attribs="{'xml:space': 'preserve'}" id="_03465" smilref="Title.smil#_03465"> The first term accounts for the array access within each of the N calls to push(); the subsequent terms account for the array accesses to initialize the data structure each time it doubles in size. Thus the average number of array accesses per operation is constant, even though the last operation takes linear time. This is known as an &#8220; amortized&#8221; analysis because we spread the cost of the few expensive operations, by assigning a portion of it to each of a large number of inexpensive operations. Amortized analysis provides a worst case guarantee on any sequence of operations, starting from an empty data structure. VisualAccumulator provides illustrates the process, shown above.</p><p attribs="{'xml:space': 'preserve'}" id="_03466" smilref="Title.smil#_03466"> Amortized cost of adding to a RandomBag</p><p attribs="{'xml:space': 'preserve'}" id="_03467" smilref="Title.smil#_03467"> number of add() operations</p><p attribs="{'xml:space': 'preserve'}" id="_03468" smilref="Title.smil#_03468"> t s</p><p attribs="{'xml:space': 'preserve'}" id="_03469" smilref="Title.smil#_03469"> o</p><p attribs="{'xml:space': 'preserve'}" id="_03470" smilref="Title.smil#_03470"> c</p><p attribs="{'xml:space': 'preserve'}" id="_03471" smilref="Title.smil#_03471"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03472" smilref="Title.smil#_03472"> red dots give cumulative average</p><p attribs="{'xml:space': 'preserve'}" id="_03473" smilref="Title.smil#_03473"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_03474" smilref="Title.smil#_03474"> 128</p><p attribs="{'xml:space': 'preserve'}" id="_03475" smilref="Title.smil#_03475"> Proposition E. In the resizing array implementation of Stack (Algorithm 1.1), the average number of array accesses for any sequence of push and pop operations starting from an empty data structure is constant in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_03476" smilref="Title.smil#_03476"> Proof sketch: For each push operation that causes the array to grow (say from size N to size 2N), consider the N/2 &#11002; 1 push operations that most recently caused the stack size to grow to k, for k from N/2 + 2 to N. Averaging the 4N array accesses to grow the array with N/2 array accesses (one for each push), we get an average cost of 9 array accesses for each of these N/2 &#11002; 1 push operations. Establishing this proposition for any sequence of push and pop operations is more intricate (see</p><p attribs="{'xml:space': 'preserve'}" id="_03477" smilref="Title.smil#_03477"> Exercise 1.4.32)</p><p attribs="{'xml:space': 'preserve'}" id="_03478" smilref="Title.smil#_03478"> This kind of analysis is widely applicable. In particular, we use resizing arrays as the underlying data structure for several algorithms that we consider later in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_03479" smilref="Title.smil#_03479"> It is the task of the algorithm analyst to discover as much relevant information about an algorithm as possible, and it is the task of the applications programmer to apply that knowledge to develop programs that effectively solve the problems at hand. Ideally, we want algorithms that lead to clear and compact code that provides both a good guarantee and good performance on input values of interest. Many of the classic algorithms that we consider in this chapter are important for a broad variety of applications precisely because they have these properties. Using them as models, you can develop good solutions yourself for typical problems that you face while programming.</p><p attribs="{'xml:space': 'preserve'}" id="_03480" smilref="Title.smil#_03480" /></level3><level3 id="_00024"><h3 id="ch1-s4-ss25" smilref="Title.smil#ch1-s4-ss25" xml:space="preserve">Memory usage</h3><pagenum id="p213" page="normal" smilref="Title.smil#p213" /><p attribs="{'xml:space': 'preserve'}" id="_03481" smilref="Title.smil#_03481"> 200</p><p attribs="{'xml:space': 'preserve'}" id="_03482" smilref="Title.smil#_03482"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03483" smilref="Title.smil#_03483"> type</p><p attribs="{'xml:space': 'preserve'}" id="_03484" smilref="Title.smil#_03484"> boolean</p><p attribs="{'xml:space': 'preserve'}" id="_03485" smilref="Title.smil#_03485"> double</p><p attribs="{'xml:space': 'preserve'}" id="_03486" smilref="Title.smil#_03486"> char</p><p attribs="{'xml:space': 'preserve'}" id="_03487" smilref="Title.smil#_03487"> int</p><p attribs="{'xml:space': 'preserve'}" id="_03488" smilref="Title.smil#_03488"> byte</p><p attribs="{'xml:space': 'preserve'}" id="_03489" smilref="Title.smil#_03489"> float</p><p attribs="{'xml:space': 'preserve'}" id="_03490" smilref="Title.smil#_03490"> 1 1 2 4 4 8 8 Typical memory requirements for primitive types</p><p attribs="{'xml:space': 'preserve'}" id="_03491" smilref="Title.smil#_03491"> long</p><p attribs="{'xml:space': 'preserve'}" id="_03492" smilref="Title.smil#_03492"> bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03493" smilref="Title.smil#_03493"> Memory As with running time, a program&#8217;s memory usage connects directly to the physical world: a substantial amount of your computer&#8217;s circuitry enables your program to store values and later retrieve them. The more values you need to have stored at any given instant, the more circuitry you need. You probably are aware of limits on memory usage on your computer (even more so than for time) because you probably have paid extra money to get more memory. Memory usage is well-de&#64257; ned for Java on your computer (every value requires precisely the same amount of memory each time that you run your program), but Java is implemented on a very wide range of computational devices, and memory consumption is implementation-dependent. For economy, we use the word typical to signal that values are subject to machine dependencies. One of Java&#8217;s most significant features is its memory allocation system, which is supposed to relieve you from having to worry about memory. Certainly, you are well-advised to take advantage of this feature when ap- propriate. Still, it is your responsibility to know, at least approximately, when a program&#8217;s memory requirements will prevent you from solving a given problem. Analyzing memory usage is much easier than analyzing running time, primarily because not as many program statements are involved (just dec- larations) and because the analysis reduces complex objects to the primitive types, whose memory usage is well-de&#64257; ned and simple to understand: we can count up the number of variables and weight them by the number of bytes according to their type. For example, since the Java int data type is the set of integer values between&#11002;2,147,483,648 and 2,147,483,647, a grand total of 232 different values, typical Java implementations use 32 bits to represent int values. Similar considerations hold for other primitive types: typical Java implementations use 8-bit bytes, representing each char value with 2 bytes (16 bits), each int value with 4 bytes (32 bits), each double and each long value with 8 bytes (64 bits), and each boolean value with 1 byte (since computers typically access memory one byte at a time). Combined with knowledge of the amount of memory available, you can calculate limitations from these values. For example, if you have 1GB of memory on your computer (1 billion bytes), you cannot fit more than about 32 million int values or 16 million double values in memory at any one time. On the other hand, analyzing memory usage is subject to various differences in machine hardware and in Java implementations, so you should consider the specific examples that we give as indicative of how you might go about determining memory usage when warranted, not the final word for your computer. For example, many data structures involve representation of machine addresses, and the amount of memory</p><p attribs="{'xml:space': 'preserve'}" id="_03494" smilref="Title.smil#_03494" /><pagenum id="p214" page="normal" smilref="Title.smil#p214" /><p attribs="{'xml:space': 'preserve'}" id="_03495" smilref="Title.smil#_03495"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03496" smilref="Title.smil#_03496"> 201</p><p attribs="{'xml:space': 'preserve'}" id="_03497" smilref="Title.smil#_03497"> needed for a machine address varies from machine to machine. For consistency, we assume that 8 bytes are needed to represent addresses, as is typical for 64-bit architectures that are now widely used, recognizing that many older machines use a 32-bit architecture that would involve just 4 bytes per machine address.</p><p attribs="{'xml:space': 'preserve'}" id="_03498" smilref="Title.smil#_03498"> Objects. To determine the memory usage of an object, we add the amount of memory used by each instance variable to the overhead associated with each object, typically 16 bytes. The overhead includes a reference to the object&#8217;s class, garbage collection information, and synchronization information. Moreover, the memory usage is typically padded to be a multiple of 8 bytes (machine words, on a 64-bit machine). For example, an Integer object uses 24 bytes (16 bytes of overhead, 4 bytes for its int instance variable, and 4 bytes of padding). Similarly, a Date (page 91) object also uses 32 bytes: 16 bytes of overhead, 4 bytes for each of its three int instance variables, and 4 bytes of padding. A reference to an object typically is a memory address and thus uses 8 bytes of memory. For example, a Counter (page 89) object uses 32 bytes: 16 bytes of overhead, 8 bytes for its String instance variable (a reference), 4 bytes for its int instance variable, and 4 bytes of pad- ding. When we account for the memory for a reference, we account separately for the memory for the object itself, so this total does not count the memory for the String value.</p><p attribs="{'xml:space': 'preserve'}" id="_03499" smilref="Title.smil#_03499"> integer wrapper object public class Integer { private int x; ... }</p><p attribs="{'xml:space': 'preserve'}" id="_03500" smilref="Title.smil#_03500"> date object public class Date { private int day; private int month; private int year; ... }</p><p attribs="{'xml:space': 'preserve'}" id="_03501" smilref="Title.smil#_03501"> counter object public class Counter { private String name; private int count; ... }</p><p attribs="{'xml:space': 'preserve'}" id="_03502" smilref="Title.smil#_03502"> node object (inner class) private class Node { Item item; Node next; ... }</p><p attribs="{'xml:space': 'preserve'}" id="_03503" smilref="Title.smil#_03503"> 24 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03504" smilref="Title.smil#_03504"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03505" smilref="Title.smil#_03505"> x</p><p attribs="{'xml:space': 'preserve'}" id="_03506" smilref="Title.smil#_03506"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03507" smilref="Title.smil#_03507"> 32 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03508" smilref="Title.smil#_03508"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03509" smilref="Title.smil#_03509"> day month year</p><p attribs="{'xml:space': 'preserve'}" id="_03510" smilref="Title.smil#_03510"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03511" smilref="Title.smil#_03511"> 32 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03512" smilref="Title.smil#_03512"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03513" smilref="Title.smil#_03513"> name</p><p attribs="{'xml:space': 'preserve'}" id="_03514" smilref="Title.smil#_03514"> count</p><p attribs="{'xml:space': 'preserve'}" id="_03515" smilref="Title.smil#_03515"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03516" smilref="Title.smil#_03516"> 40 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03517" smilref="Title.smil#_03517"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03518" smilref="Title.smil#_03518"> extra overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03519" smilref="Title.smil#_03519"> item</p><p attribs="{'xml:space': 'preserve'}" id="_03520" smilref="Title.smil#_03520"> next</p><p attribs="{'xml:space': 'preserve'}" id="_03521" smilref="Title.smil#_03521"> int value</p><p attribs="{'xml:space': 'preserve'}" id="_03522" smilref="Title.smil#_03522"> int values</p><p attribs="{'xml:space': 'preserve'}" id="_03523" smilref="Title.smil#_03523"> String reference</p><p attribs="{'xml:space': 'preserve'}" id="_03524" smilref="Title.smil#_03524"> int value</p><p attribs="{'xml:space': 'preserve'}" id="_03525" smilref="Title.smil#_03525"> references</p><p attribs="{'xml:space': 'preserve'}" id="_03526" smilref="Title.smil#_03526"> Typical object memory requirements</p><p attribs="{'xml:space': 'preserve'}" id="_03527" smilref="Title.smil#_03527"> Linked lists. A nested non-static (inner) class such as our Node class (page 142) requires an extra 8 bytes of overhead (for a reference to the enclosing instance). Thus, a Node object uses 40 bytes (16 bytes of object overhead, 8 bytes each for the references to the Item and Node ob- jects, and 8 bytes for the extra overhead). Thus, since an Integer object uses 24 bytes, a stack with N integers built with a linked-list representation (Algorithm 1.2) uses 32 + 64N bytes, the usual 16 for object overhead for Stack, 8 for its reference instance vari- able, 4 for its int instance variable, 4 for padding, and 64 for each entry, 40 for a Node and 24 for an Integer.</p><p attribs="{'xml:space': 'preserve'}" id="_03528" smilref="Title.smil#_03528" /><pagenum id="p215" page="normal" smilref="Title.smil#p215" /><p attribs="{'xml:space': 'preserve'}" id="_03529" smilref="Title.smil#_03529"> 202</p><p attribs="{'xml:space': 'preserve'}" id="_03530" smilref="Title.smil#_03530"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03531" smilref="Title.smil#_03531"> Arrays. Typical memory requirements for various types of arrays in Java are summarized in the diagrams on the facing page. Arrays in Java are implemented as objects, typically with extra overhead for the length. An array of primitive-type values typically requires 24 bytes of header information (16 bytes of object overhead, 4 bytes for the length, and 4 bytes of padding) plus the memory needed to store the values. For ex- ample, an array of N int values uses 24 &#11001; 4N bytes (rounded up to be a multiple of 8), and an array of N double values uses 24 &#11001; 8N bytes. An array of objects is an array of references to the objects, so we need to add the space for the references to the space required for the objects. For example, an array of N Date objects (page 91) uses 24 bytes (array overhead) plus 8N bytes (references) plus 32 bytes for each object, for a grand total of 24 + 40N bytes. A two-dimensional array is an array of arrays (each array is an object). For example, a two-dimensional M-by-N array of double values uses 24 bytes (overhead for the array of arrays) plus 8 M bytes (references to the row arrays) plus M times 24 bytes (overhead from the row arrays) plus M times N times 8 bytes (for the N double values in each of the M rows) for a grand total of 8NM &#11001; 32M &#11001; 24 ~ 8NM bytes. When array entries are objects, a similar accounting leads to a total of 8NM &#11001; 32M &#11001; 24 ~ 8NM bytes for the array of arrays filled with references to objects, plus the memory for the objects themselves. String objects. We account for memory in Java&#8217;s String objects in the same way as for any other object, except that aliasing is common for strings. The standard String implementation has four instance variables: a reference to a character array (8 bytes) and three int values (4 bytes each). The first int value is an offset into the character array ; the second is a count (the string length). In terms of the instance variable names in the drawing on the facing page, the string that is represented consists of the characters</p><p attribs="{'xml:space': 'preserve'}" id="_03532" smilref="Title.smil#_03532"> value[offset] through value[offset + count - 1]. The third int value in String</p><p attribs="{'xml:space': 'preserve'}" id="_03533" smilref="Title.smil#_03533"> objects is a hash code that saves recomputation in certain circumstances that need not concern us now. Therefore, each String object uses a total of 40 bytes (16 bytes for object overhead plus 4 bytes for each of the three int instance variables plus 8 bytes for the array reference plus 4 bytes of padding). This space requirement is in addition to the space needed for the characters themselves, which are in the array. The space needed for the characters is accounted for separately because the char array is often shared among strings. Since String objects are immutable, this arrangement allows the implementation to save memory when String objects have the same underlying value[]. String values and substrings. A String of length N typically uses 40 bytes (for the String object) plus 24 &#11001; 2N bytes (for the array that contains the characters) for a total of 64 + 2N bytes. But it is typical in string processing to work with substrings, and Java&#8217;s representation is meant to allow us to do so without having to make copies of</p><p attribs="{'xml:space': 'preserve'}" id="_03534" smilref="Title.smil#_03534" /><pagenum id="p216" page="normal" smilref="Title.smil#p216" /><p attribs="{'xml:space': 'preserve'}" id="_03535" smilref="Title.smil#_03535"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03536" smilref="Title.smil#_03536"> 203</p><p attribs="{'xml:space': 'preserve'}" id="_03537" smilref="Title.smil#_03537"> array of int values</p><p attribs="{'xml:space': 'preserve'}" id="_03538" smilref="Title.smil#_03538"> int[] a = new int[N];</p><p attribs="{'xml:space': 'preserve'}" id="_03539" smilref="Title.smil#_03539"> array of double values</p><p attribs="{'xml:space': 'preserve'}" id="_03540" smilref="Title.smil#_03540"> double[] c = new double[N];</p><p attribs="{'xml:space': 'preserve'}" id="_03541" smilref="Title.smil#_03541"> a</p><p attribs="{'xml:space': 'preserve'}" id="_03542" smilref="Title.smil#_03542"> c</p><p attribs="{'xml:space': 'preserve'}" id="_03543" smilref="Title.smil#_03543"> 16 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03544" smilref="Title.smil#_03544"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03545" smilref="Title.smil#_03545"> 16 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03546" smilref="Title.smil#_03546"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03547" smilref="Title.smil#_03547"> int value N (4 bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03548" smilref="Title.smil#_03548"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03549" smilref="Title.smil#_03549"> int value N (4 bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03550" smilref="Title.smil#_03550"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03551" smilref="Title.smil#_03551"> N int values (4N bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03552" smilref="Title.smil#_03552"> Total: 24 + 4N (N even)</p><p attribs="{'xml:space': 'preserve'}" id="_03553" smilref="Title.smil#_03553"> Total: 24 + 8N</p><p attribs="{'xml:space': 'preserve'}" id="_03554" smilref="Title.smil#_03554"> N double values (8N bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03555" smilref="Title.smil#_03555"> 24 + 8N bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03556" smilref="Title.smil#_03556"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03557" smilref="Title.smil#_03557"> 16 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03558" smilref="Title.smil#_03558"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03559" smilref="Title.smil#_03559"> 4 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03560" smilref="Title.smil#_03560"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03561" smilref="Title.smil#_03561"> array of objects</p><p attribs="{'xml:space': 'preserve'}" id="_03562" smilref="Title.smil#_03562"> 32 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03563" smilref="Title.smil#_03563"> array of arrays (two-dimensional array)</p><p attribs="{'xml:space': 'preserve'}" id="_03564" smilref="Title.smil#_03564"> double[][] t; t = new double[M][N];</p><p attribs="{'xml:space': 'preserve'}" id="_03565" smilref="Title.smil#_03565"> t</p><p attribs="{'xml:space': 'preserve'}" id="_03566" smilref="Title.smil#_03566"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03567" smilref="Title.smil#_03567"> 16 bytes int value M (4 bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03568" smilref="Title.smil#_03568"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03569" smilref="Title.smil#_03569"> M references (8M bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03570" smilref="Title.smil#_03570"> N double values (8N bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03571" smilref="Title.smil#_03571"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03572" smilref="Title.smil#_03572"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03573" smilref="Title.smil#_03573"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03574" smilref="Title.smil#_03574"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_03575" smilref="Title.smil#_03575"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03576" smilref="Title.smil#_03576"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03577" smilref="Title.smil#_03577"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03578" smilref="Title.smil#_03578"> Date[] d; d = new Date[N]; for (int k = 0; k &lt; N; k++) { ... a[k] = new Date (...); }</p><p attribs="{'xml:space': 'preserve'}" id="_03579" smilref="Title.smil#_03579"> d</p><p attribs="{'xml:space': 'preserve'}" id="_03580" smilref="Title.smil#_03580"> 16 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03581" smilref="Title.smil#_03581"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03582" smilref="Title.smil#_03582"> int value length (4 bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03583" smilref="Title.smil#_03583"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03584" smilref="Title.smil#_03584"> N references (8N bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03585" smilref="Title.smil#_03585"> Total: 24 + 8N + N&#11003;32 = 24 + 40N</p><p attribs="{'xml:space': 'preserve'}" id="_03586" smilref="Title.smil#_03586"> summary</p><p attribs="{'xml:space': 'preserve'}" id="_03587" smilref="Title.smil#_03587"> type</p><p attribs="{'xml:space': 'preserve'}" id="_03588" smilref="Title.smil#_03588"> int[]</p><p attribs="{'xml:space': 'preserve'}" id="_03589" smilref="Title.smil#_03589"> double[]</p><p attribs="{'xml:space': 'preserve'}" id="_03590" smilref="Title.smil#_03590"> Date[]</p><p attribs="{'xml:space': 'preserve'}" id="_03591" smilref="Title.smil#_03591"> double[][]</p><p attribs="{'xml:space': 'preserve'}" id="_03592" smilref="Title.smil#_03592"> bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03593" smilref="Title.smil#_03593"> ~4N ~8N ~40N ~8NM</p><p attribs="{'xml:space': 'preserve'}" id="_03594" smilref="Title.smil#_03594"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03595" smilref="Title.smil#_03595"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03596" smilref="Title.smil#_03596"> day month year</p><p attribs="{'xml:space': 'preserve'}" id="_03597" smilref="Title.smil#_03597"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03598" smilref="Title.smil#_03598"> Total: 24 + 8M + M&#11003;(24 + 8N ) = 24 + 32M + 8MN</p><p attribs="{'xml:space': 'preserve'}" id="_03599" smilref="Title.smil#_03599"> Typical memory requirements for arrays of int values, double values, objects, and arrays</p><p attribs="{'xml:space': 'preserve'}" id="_03600" smilref="Title.smil#_03600" /><pagenum id="p217" page="normal" smilref="Title.smil#p217" /><p attribs="{'xml:space': 'preserve'}" id="_03601" smilref="Title.smil#_03601"> 204</p><p attribs="{'xml:space': 'preserve'}" id="_03602" smilref="Title.smil#_03602"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03603" smilref="Title.smil#_03603"> String object (Java library)</p><p attribs="{'xml:space': 'preserve'}" id="_03604" smilref="Title.smil#_03604"> 40 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03605" smilref="Title.smil#_03605"> public class String { private char[] value; private int offset; private int count; private int hash; value ... }</p><p attribs="{'xml:space': 'preserve'}" id="_03606" smilref="Title.smil#_03606"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03607" smilref="Title.smil#_03607"> offset count hash</p><p attribs="{'xml:space': 'preserve'}" id="_03608" smilref="Title.smil#_03608"> reference</p><p attribs="{'xml:space': 'preserve'}" id="_03609" smilref="Title.smil#_03609"> int values</p><p attribs="{'xml:space': 'preserve'}" id="_03610" smilref="Title.smil#_03610"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03611" smilref="Title.smil#_03611"> substring example</p><p attribs="{'xml:space': 'preserve'}" id="_03612" smilref="Title.smil#_03612"> String genome = "CGCCTGGCGTCTGTAC"; String codon = genome.substring(6, 9);</p><p attribs="{'xml:space': 'preserve'}" id="_03613" smilref="Title.smil#_03613"> genome</p><p attribs="{'xml:space': 'preserve'}" id="_03614" smilref="Title.smil#_03614"> 40 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03615" smilref="Title.smil#_03615"> the string&#8217;s characters. When you use the substring() method, you create a new String object (40 bytes) but reuse the same value[] array, so a substring of an existing string takes just 40 bytes. The character array containing the original string is aliased in the object for the substring; the offset and length fields identify the substring. In other words, a substring takes constant extra memory and forming a substring takes constant time, even when the lengths of the string and the substring are huge. A naive representation that requires copying characters to make substrings would take linear time and space. The ability to create a substring using space (and time) independent of its length is the key to ef&#64257; - ciency in many basic string-processing algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_03616" smilref="Title.smil#_03616"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03617" smilref="Title.smil#_03617"> value</p><p attribs="{'xml:space': 'preserve'}" id="_03618" smilref="Title.smil#_03618"> 0 16</p><p attribs="{'xml:space': 'preserve'}" id="_03619" smilref="Title.smil#_03619"> hash padding</p><p attribs="{'xml:space': 'preserve'}" id="_03620" smilref="Title.smil#_03620"> codon</p><p attribs="{'xml:space': 'preserve'}" id="_03621" smilref="Title.smil#_03621"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03622" smilref="Title.smil#_03622"> value</p><p attribs="{'xml:space': 'preserve'}" id="_03623" smilref="Title.smil#_03623"> 6 3</p><p attribs="{'xml:space': 'preserve'}" id="_03624" smilref="Title.smil#_03624"> hash padding</p><p attribs="{'xml:space': 'preserve'}" id="_03625" smilref="Title.smil#_03625"> object overhead</p><p attribs="{'xml:space': 'preserve'}" id="_03626" smilref="Title.smil#_03626"> These basic mechanisms are effective for esti-</p><p attribs="{'xml:space': 'preserve'}" id="_03627" smilref="Title.smil#_03627"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03628" smilref="Title.smil#_03628"> 56 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03629" smilref="Title.smil#_03629"> 40 bytes</p><p attribs="{'xml:space': 'preserve'}" id="_03630" smilref="Title.smil#_03630"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_03631" smilref="Title.smil#_03631"> padding</p><p attribs="{'xml:space': 'preserve'}" id="_03632" smilref="Title.smil#_03632"> char values</p><p attribs="{'xml:space': 'preserve'}" id="_03633" smilref="Title.smil#_03633"> C G C C T G G C G T C T G T A C</p><p attribs="{'xml:space': 'preserve'}" id="_03634" smilref="Title.smil#_03634"> mating the memory usage of a great many programs, but there are numerous complicating factors that can make the task significantly more dif&#64257; cult. We have already noted the potential effect of aliasing. More- over, memory consumption is a complicated dynamic process when function calls are involved because the system memory allocation mechanism plays a more important role, with more system dependencies. For example, when your program calls a method, the system allocates the memory needed for the method (for its local variables) from a special area of memory called the stack (a system pushdown stack), and when the method returns to the caller, the memory is returned to the stack. For this reason, creating arrays or other large objects in recursive programs is dangerous, since each recursive call implies significant memory usage. When you create an object with new, the system allocates the memory needed for the object from another special area of memory known as the heap (not the same as the binary heap data structure we consider in Section 2.4), and you must remember that every object lives until no references to it remain, at which point a system process known as garbage collection reclaims its memory for the heap. Such dynamics can make the task of precisely estimating memory usage of a program challenging.</p><p attribs="{'xml:space': 'preserve'}" id="_03635" smilref="Title.smil#_03635"> A String and a substring</p><p attribs="{'xml:space': 'preserve'}" id="_03636" smilref="Title.smil#_03636" /><pagenum id="p218" page="normal" smilref="Title.smil#p218" /><p attribs="{'xml:space': 'preserve'}" id="_03637" smilref="Title.smil#_03637"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03638" smilref="Title.smil#_03638"> 205</p><p attribs="{'xml:space': 'preserve'}" id="_03639" smilref="Title.smil#_03639"> Perspective Good performance is important. An impossibly slow program is almost as useless as an incorrect one, so it is certainly worthwhile to pay attention to the cost at the outset, to have some idea of which kinds of problems you might feasibly address. In particular, it is always wise to have some idea of which code constitutes the inner loop of your programs. Perhaps the most common mistake made in programming is to pay too much attention to performance characteristics. Your first priority is to make your code clear and correct. Modifying a program for the sole purpose of speeding it up is best left for experts. Indeed, doing so is often counterproductive, as it tends to create code that is complicated and difficult to understand. C. A. R. Hoare (the inventor of quicksort and a leading proponent of writing clear and correct code) once summarized this idea by saying that &#8220;premature optimization is the root of all evil, &#8221; to which Knuth added the qualifier &#8220;(or at least most of it) in programming.&#8221; Beyond that, improving the running time is not worthwhile if the available cost benefits are insigni&#64257; cant. For example, improving the running time of a program by a factor of 10 is inconsequential if the running time is only an instant. Even when a program takes a few minutes to run, the total time required to implement and debug an improved algorithm might be substantially more than the time required simply to run a slightly slower one&#8212;you may as well let the computer do the work. Worse, you might spend a considerable amount of time and effort implementing ideas that should in theory improve a program but do not do so in practice. Perhaps the second most common mistake made in programming is to ignore performance characteristics. Faster algorithms are often more complicated than brute- force ones, so you might be tempted to accept a slower algorithm to avoid having to deal with more complicated code. However, you can sometimes reap huge savings with just a few lines of good code. Users of a surprising number of computer systems lose substantial time unknowingly waiting for brute-force quadratic algorithms to finish solving a problem, when linear or linearithmic algorithms are available that could solve the problem in a fraction of the time. When we are dealing with huge problem sizes, we often have no choice but to seek better algorithms. We generally take as implicit the methodology described in this section to estimate memory usage and to develop an order-of-growth hypothesis of the running time from a tilde approximation resulting from a mathematical analysis within a cost model, and to check those hypotheses with experiments. Improving a program to make it more clear, ef&#64257; cient, and elegant should be your goal every time that you work on it. If you pay attention to the cost all the way through the development of a program, you will reap the benefits every time you use it.</p><p attribs="{'xml:space': 'preserve'}" id="_03640" smilref="Title.smil#_03640" /><pagenum id="p219" page="normal" smilref="Title.smil#p219" /><p attribs="{'xml:space': 'preserve'}" id="_03641" smilref="Title.smil#_03641"> 206</p><p attribs="{'xml:space': 'preserve'}" id="_03642" smilref="Title.smil#_03642"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03643" smilref="Title.smil#_03643"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_03644" smilref="Title.smil#_03644"> Q. Why not use StdRandom to generate random values instead of maintaining the file</p><p attribs="{'xml:space': 'preserve'}" id="_03645" smilref="Title.smil#_03645"> 1Mints.txt ?</p><p attribs="{'xml:space': 'preserve'}" id="_03646" smilref="Title.smil#_03646"> A. It is easier to debug code in development and to reproduce experiments. StdRandom produces different values each time it is called, so running a program after fixing a bug may not test the fi x! You could use the initialize() method in StdRandom to address this problem, but a reference file such as 1Mints.txt makes it easier to add test cases while debugging. Also, different programmers can compare performance on different computers, without worrying about the input model. Once you have debugged a program and have a good idea of how it performs, it is certainly worthwhile to test it on random data. For example, DoublingTest and DoublingRatio take this approach. Q. I ran DoublingRatio on my computer, but the results were not as consistent as in the book. Some of the ratios were not close to 8. Why? A. That is why we discussed &#8220;caveats&#8221; on page 195. Most likely, your computer&#8217;s operating system decided to do something else during the experiment. One way to mitigate such problems is to invest more time in more experiments. For example, you could change DoublingTest to run the experiments 1,000 times for each N, giving a much more accurate estimate for the running time for each size (see Exercise 1.4.39). Q. What, exactly, does &#8220;as N grows&#8221; mean in the definition of the tilde notation? A. The formal definition of f(N) ~ g(N) is limN&#8594;&#8734; f (N )/g (N ) = 1. Q. I&#8217;ve seen other notations for describing order of growth. What&#8217;s the story? A. The &#8220; big-Oh&#8221; notation is widely used: we say that f (N ) is O(g (N )) if there exist constants c and N0 such that | f (N )| &lt; c g (N ) for all N &gt; N0. This notation is very useful in providing asymptotic upper bounds on the performance of algorithms, which is important in the theory of algorithms. But it is not useful for predicting performance or for comparing algorithms. Q. Why not? A. The primary reason is that it describes only an upper bound on the running time. Actual performance might be much better. The running time of an algorithm might be both O (N 2) and ~ a N log N. As a result, it cannot be used to justify tests like our doubling ratio test (see Proposition C on page 193).</p><p attribs="{'xml:space': 'preserve'}" id="_03647" smilref="Title.smil#_03647" /><pagenum id="p220" page="normal" smilref="Title.smil#p220" /><p attribs="{'xml:space': 'preserve'}" id="_03648" smilref="Title.smil#_03648"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03649" smilref="Title.smil#_03649"> 207</p><p attribs="{'xml:space': 'preserve'}" id="_03650" smilref="Title.smil#_03650"> Q. So why is the big-Oh notation so widely used? A. It facilitates development of bounds on the order of growth, even for complicated algorithms for which more precise analysis might not be feasible. Moreover, it is compatible with the &#8220; big-Omega&#8221; and &#8220; big-Theta&#8221; notations that theoretical computer scientists use to classify algorithms by bounding their worst-case performance. We say that f (N ) is &#9024;(g (N )) if there exist constants c and N0 such that | f (N )| &gt; c g (N ) for N &gt; N0; and if f (N ) is O(g (N )) and &#9024;(g (N )), we say that f (N ) is &#9008;(g (N )). The &#8220;big- Omega&#8221; notation is typically used to describe a lower bound on the worst case, and the &#8220;big-Theta&#8221; notation is typically used to describe the performance of algorithms that are optimal in the sense that no algorithm can have better asymptotic worst-case order of growth. Optimal algorithms are certainly worth considering in practical applica- tions, but there are many other considerations, as you will see. Q. Aren&#8217;t upper bounds on asymptotic performance important? A. Yes, but we prefer to discuss precise results in terms of frequency of statement ex- ceution with respect to cost models, because they provide more information about algorithm performance and because deriving such results is feasible for the algorithms that we discuss. For example, we say &#8220;ThreeSum uses ~N 3/2 array accesses&#8221; and &#8220;the number of times cnt++ is executed in ThreeSum is ~N 3/6 in the worst case,&#8221; which is a bit more verbose but much more informative than the statement &#8220;the running time of ThreeSum is O (N 3).&#8221; Q. When the order of growth of the running time of an algorithm is N log N, the doubling test will lead to the hypothesis that the running time is ~ a N for a constant a. Isn&#8217;t that a problem? A. We have to be careful not to try to infer that the experimental data implies a particular mathematical model, but when we are just predicting performance, this is not really a problem. For example, when N is between 16,000 and 32,000, the plots of 14N and N lg N are very close to one another. The data fits both curves. As N increases, the curves become closer together. It actually requires some care to experimentally check the hypothesis that an algorithm&#8217;s running time is linearithmic but not linear. Q. Does int[] a = new int[N] count as N array accesses (to initialize entries to 0)? A. Most likely yes, so we make that assumption in this book, though a sophisticated compiler implementation might try to avoid this cost for huge sparse arrays.</p><p attribs="{'xml:space': 'preserve'}" id="_03651" smilref="Title.smil#_03651" /><pagenum id="p221" page="normal" smilref="Title.smil#p221" /><p attribs="{'xml:space': 'preserve'}" id="_03652" smilref="Title.smil#_03652"> 208</p><p attribs="{'xml:space': 'preserve'}" id="_03653" smilref="Title.smil#_03653"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03654" smilref="Title.smil#_03654"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_03655" smilref="Title.smil#_03655"> 1.4.1 Show that the number of different triples that can be chosen from N items is precisely N (N&#11002;1)(N&#11002;2)/6. Hint : Use mathematical induction. 1.4.2 Modify ThreeSum to work properly even when the int values are so large that adding two of them might cause over&#64258; ow. 1.4.3 Modify DoublingTest to use StdDraw to produce plots like the standard and log-log plots in the text, rescaling as necessary so that the plot always fills a substantial portion of the window. 1.4.4 Develop a table like the one on page 181 for TwoSum. 1.4.5 Give tilde approximations for the following quantities:</p><p attribs="{'xml:space': 'preserve'}" id="_03656" smilref="Title.smil#_03656"> a. N &#11001; 1 b. 1 &#11001; 1/N (1 &#11001; 1/N )(1 &#11001; 2/N ) c. d. 2N 3&#11002; 15 N 2 &#11001; N e. lg(2N )/lg N f. lg(N 2 + 1) / lg N g. N 100 / 2N</p><p attribs="{'xml:space': 'preserve'}" id="_03657" smilref="Title.smil#_03657"> 1.4.6 Give the order of growth (as a function of N ) of the running times of each of the following code fragments:</p><p attribs="{'xml:space': 'preserve'}" id="_03658" smilref="Title.smil#_03658"> a.</p><p attribs="{'xml:space': 'preserve'}" id="_03659" smilref="Title.smil#_03659"> int sum = 0; for (int n = N; n &gt; 0; n /= 2) for(int i = 0; i &lt; n; i++) sum++;</p><p attribs="{'xml:space': 'preserve'}" id="_03660" smilref="Title.smil#_03660"> b.</p><p attribs="{'xml:space': 'preserve'}" id="_03661" smilref="Title.smil#_03661"> int sum = 0; for (int i = 1 i &lt; N; i *= 2) for (int j = 0; j &lt; i; j++) sum++;</p><p attribs="{'xml:space': 'preserve'}" id="_03662" smilref="Title.smil#_03662" /><pagenum id="p222" page="normal" smilref="Title.smil#p222" /><p attribs="{'xml:space': 'preserve'}" id="_03663" smilref="Title.smil#_03663"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03664" smilref="Title.smil#_03664"> 209</p><p attribs="{'xml:space': 'preserve'}" id="_03665" smilref="Title.smil#_03665"> c.</p><p attribs="{'xml:space': 'preserve'}" id="_03666" smilref="Title.smil#_03666"> int sum = 0; for (int i = 1 i &lt; N; i *= 2) for (int j = 0; j &lt; N; j++) sum++;</p><p attribs="{'xml:space': 'preserve'}" id="_03667" smilref="Title.smil#_03667"> 1.4.7 Analyze ThreeSum under a cost model that counts arithmetic operations (and comparisons) involving the input numbers. 1.4.8 Write a program to determine the number pairs of values in an inputfile that are equal. If your first try is quadratic, think again and use Arrays.sort() to develop a linearithmic solution. 1.4.9 Give a formula to predict the running time of a program for a problem of size N when doubling experiments have shown that the doubling factor is 2b and the running time for problems of size N0 is T. 1.4.10 Modify binary search so that it always returns the element with the smallest index that matches the search element (and still guarantees logarithmic running time). 1.4.11 Add an instance method howMany() to StaticSETofInts (page 99) that finds the number of occurrences of a given key in time proportional to log N in the worst case. 1.4.12 Write a program that, given two sorted arrays of N int values, prints all elements that appear in both arrays, in sorted order. The running time of your program should be proportional to N in the worst case. 1.4.13 Using the assumptions developed in the text, give the amount of memory needed to represent an object of each of the following types:</p><p attribs="{'xml:space': 'preserve'}" id="_03668" smilref="Title.smil#_03668"> a. Accumulator b. Transaction</p><p attribs="{'xml:space': 'preserve'}" id="_03669" smilref="Title.smil#_03669"> c. FixedCapacityStackOfStrings with capacity C and N entries</p><p attribs="{'xml:space': 'preserve'}" id="_03670" smilref="Title.smil#_03670"> d. Point2D e. Interval1D f. Interval2D g. Double</p><p attribs="{'xml:space': 'preserve'}" id="_03671" smilref="Title.smil#_03671" /><pagenum id="p223" page="normal" smilref="Title.smil#p223" /><p attribs="{'xml:space': 'preserve'}" id="_03672" smilref="Title.smil#_03672"> 210</p><p attribs="{'xml:space': 'preserve'}" id="_03673" smilref="Title.smil#_03673"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03674" smilref="Title.smil#_03674"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_03675" smilref="Title.smil#_03675"> 1.4.14 4-sum. Develop an algorithm for the 4-sum problem. 1.4.15 Faster 3-sum. As a warmup, develop an implementation TwoSumFaster that uses a linear algorithm to count the pairs that sum to zero after the array is sorted (in- stead of the binary-search-based linearithmic algorithm). Then apply a similar idea to develop a quadratic algorithm for the 3-sum problem. 1.4.16 Closest pair (in one dimension). Write a program that, given an array a[] of N double values, finds a closest pair : two values whose difference is no greater than the the difference of any other pair (in absolute value). The running time of your program should be linearithmic in the worst case. 1.4.17 Farthest pair (in one dimension). Write a program that, given an array a[] of N double values, finds a farthest pair : two values whose difference is no smaller than the the difference of any other pair (in absolute value). The running time of your program should be linear in the worst case. 1.4.18 Local minimum of an array. Write a program that, given an array a[] of N distinct integers, finds a local minimum: an index i such that a[i] &lt; a[i-1] and a[i] &lt; a[i+1]. Your program should use ~2lg N compares in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_03676" smilref="Title.smil#_03676"> Answer : Examine the middle value a[N/2] and its two neighbors a[N/2 - 1] and a[N/2 + 1]. If a[N/2] is a local minimum, stop; otherwise search in the half with the smaller neighbor.</p><p attribs="{'xml:space': 'preserve'}" id="_03677" smilref="Title.smil#_03677"> 1.4.19 Local minimum of a matrix. Given an N-by-N array a[] of N 2 distinct inte- gers, design an algorithm that runs in time proportional to N to find a local minimum:</p><p attribs="{'xml:space': 'preserve'}" id="_03678" smilref="Title.smil#_03678"> a pair of indices i and j such that a[i][j] &lt; a[i+1][j], a[i][j] &lt; a[i][j+1], a[i][j] &lt; a[i-1][j], and a[i][j] &lt; a[i][j-1]. The running time of your pro-</p><p attribs="{'xml:space': 'preserve'}" id="_03679" smilref="Title.smil#_03679"> gram should be proportional to N in the worst case. 1.4.20 Bitonic search. An array is bitonic if it is comprised of an increasing sequence of integers followed immediately by a decreasing sequence of integers. Write a program that, given a bitonic array of N distinct int values, determines whether a given integer is in the array. Your program should use ~3lg N compares in the worst case. 1.4.21 Binary search on distinct values. Develop an implementation of binary search for StaticSETofInts (see page 98) where the running time of contains() is guaranteed</p><p attribs="{'xml:space': 'preserve'}" id="_03680" smilref="Title.smil#_03680" /><pagenum id="p224" page="normal" smilref="Title.smil#p224" /><p attribs="{'xml:space': 'preserve'}" id="_03681" smilref="Title.smil#_03681"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03682" smilref="Title.smil#_03682"> 211</p><p attribs="{'xml:space': 'preserve'}" id="_03683" smilref="Title.smil#_03683"> to be ~ lg R, where R is the number of different integers in the array given as argument to the constructor. 1.4.22 Binary search with only addition and subtraction. [Mihai Patrascu] Write a program that, given an array of N distinct int values in ascending order, determines whether a given integer is in the array. You may use only additions and subtractions and a constant amount of extra memory. The running time of your program should be proportional to log N in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_03684" smilref="Title.smil#_03684"> Answer : Instead of searching based on powers of two (binary search), use Fibonacci numbers (which also grow exponentially). Maintain the current search range to be the interval [i, i + F k] and keep F k and F k&#8211;1 in two variables. At each step compute Fk&#8211;2 via subtraction, check element i + Fk&#8211;2 , and update the current range to either [i, i + Fk&#8211;2] or [i + Fk&#8211;2, i + Fk&#8211;2 + Fk&#8211;1].</p><p attribs="{'xml:space': 'preserve'}" id="_03685" smilref="Title.smil#_03685"> 1.4.23 Binary search for a fraction. Devise a method that uses a logarithmic number of queries of the form Is the number less than x? to find a rational number p/q such that 0 &lt; p &lt; q &lt; N. Hint : Two fractions with denominators less than N cannot differ by more than 1/N 2. 1.4.24 Throwing eggs from a building. Suppose that you have an N-story building and plenty of eggs. Suppose also that an egg is broken if it is thrown off floor F or higher, and unhurt otherwise. First, devise a strategy to determine the value of F such that the number of broken eggs is ~lg N when using ~lg N throws, then find a way to reduce the cost to ~2lg F. 1.4.25 Throwing two eggs from a building. Consider the previous question, but now suppose you only have two eggs, and your cost model is the number of throws. Devise a strategy to determine F such that the number of throws is at most 2&#8730;N, then find a way to reduce the cost to ~c &#8730;F. This is analogous to a situation where search hits (egg intact) are much cheaper than misses (egg broken). 1.4.26 3-collinearity. Suppose that you have an algorithm that takes as input N distinct points in the plane and can return the number of triples that fall on the same line. Show that you can use this algorithm to solve the 3-sum problem. Strong hint : Use algebra to show that (a, a3), (b, b3), and (c, c3) are collinear if and only if a + b + c = 0. 1.4.27 Queue with two stacks. Implement a queue with two stacks so that each queue</p><p attribs="{'xml:space': 'preserve'}" id="_03686" smilref="Title.smil#_03686" /><pagenum id="p225" page="normal" smilref="Title.smil#p225" /><p attribs="{'xml:space': 'preserve'}" id="_03687" smilref="Title.smil#_03687"> 212</p><p attribs="{'xml:space': 'preserve'}" id="_03688" smilref="Title.smil#_03688"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03689" smilref="Title.smil#_03689"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_03690" smilref="Title.smil#_03690"> operation takes a constant amortized number of stack operations. Hint : If you push elements onto a stack and then pop them all, they appear in reverse order. If you repeat this process, they&#8217;re now back in order. 1.4.28 Stack with a queue. Implement a stack with a single queue so that each stack operations takes a linear number of queue operations. Hint : To delete an item, get all of the elements on the queue one at a time, and put them at the end, except for the last one which you should delete and return. (This solution is admittedly very inef&#64257; cient.) 1.4.29 Steque with two stacks. Implement a steque with two stacks so that each steque operation (see Exercise 1.3.32) takes a constant amortized number of stack operations. 1.4.30 Deque with a stack and a steque. Implement a deque with a stack and a steque (see Exercise 1.3.32) so that each deque operation takes a constant amortized number of stack and steque operations. 1.4.31 Deque with three stacks. Implement a deque with three stacks so that each deque operation takes a constant amortized number of stack operations. 1.4.32 Amortized analysis. Prove that, starting from an empty stack, the number of array accesses used by any sequence of M operations in the resizing array implementation of Stack is proportional to M. 1.4.33 Memory requirements on a 32-bit machine. Give the memory requirements</p><p attribs="{'xml:space': 'preserve'}" id="_03691" smilref="Title.smil#_03691"> for Integer, Date, Counter, int[], double[], double[][], String, Node, and Stack</p><p attribs="{'xml:space': 'preserve'}" id="_03692" smilref="Title.smil#_03692"> (linked-list representation) for a 32-bit machine. Assume that references are 4 bytes, object overhead is 8 bytes, and padding is to a multiple of 4 bytes. 1.4.34 Hot or cold. Your goal is to guess a secret integer between 1 and N. You repeatedly guess integers between 1 and N. After each guess you learn if your guess equals the secret integer (and the game stops). Otherwise, you learn if the guess is hotter (closer to) or colder (farther from) the secret number than your previous guess. Design an algorithm that finds the secret number in at most ~2 lg N guesses. Then design an algorithm that finds the secret number in at most ~ 1 lg N guesses.</p><p attribs="{'xml:space': 'preserve'}" id="_03693" smilref="Title.smil#_03693" /><pagenum id="p226" page="normal" smilref="Title.smil#p226" /><p attribs="{'xml:space': 'preserve'}" id="_03694" smilref="Title.smil#_03694"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03695" smilref="Title.smil#_03695"> 213</p><p attribs="{'xml:space': 'preserve'}" id="_03696" smilref="Title.smil#_03696"> 1.4.35 Time costs for pushdown stacks. Justify the entries in the table below, which shows typical time costs for various pushdown stack implementations, using a cost model that counts both data references (references to data pushed onto the stack, either an array reference or a reference to an object&#8217;s instance variable) and objects created.</p><p attribs="{'xml:space': 'preserve'}" id="_03697" smilref="Title.smil#_03697"> data structure</p><p attribs="{'xml:space': 'preserve'}" id="_03698" smilref="Title.smil#_03698"> item type</p><p attribs="{'xml:space': 'preserve'}" id="_03699" smilref="Title.smil#_03699"> cost to push N int values</p><p attribs="{'xml:space': 'preserve'}" id="_03700" smilref="Title.smil#_03700"> data references</p><p attribs="{'xml:space': 'preserve'}" id="_03701" smilref="Title.smil#_03701"> objects created</p><p attribs="{'xml:space': 'preserve'}" id="_03702" smilref="Title.smil#_03702"> linked list</p><p attribs="{'xml:space': 'preserve'}" id="_03703" smilref="Title.smil#_03703"> resizing array</p><p attribs="{'xml:space': 'preserve'}" id="_03704" smilref="Title.smil#_03704"> int</p><p attribs="{'xml:space': 'preserve'}" id="_03705" smilref="Title.smil#_03705"> Integer</p><p attribs="{'xml:space': 'preserve'}" id="_03706" smilref="Title.smil#_03706"> int</p><p attribs="{'xml:space': 'preserve'}" id="_03707" smilref="Title.smil#_03707"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_03708" smilref="Title.smil#_03708"> 3 N</p><p attribs="{'xml:space': 'preserve'}" id="_03709" smilref="Title.smil#_03709"> ~5 N</p><p attribs="{'xml:space': 'preserve'}" id="_03710" smilref="Title.smil#_03710"> N</p><p attribs="{'xml:space': 'preserve'}" id="_03711" smilref="Title.smil#_03711"> 2N</p><p attribs="{'xml:space': 'preserve'}" id="_03712" smilref="Title.smil#_03712"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_03713" smilref="Title.smil#_03713"> Integer</p><p attribs="{'xml:space': 'preserve'}" id="_03714" smilref="Title.smil#_03714"> ~5 N ~N Time costs for pushdown stacks (various implementations)</p><p attribs="{'xml:space': 'preserve'}" id="_03715" smilref="Title.smil#_03715"> 1.4.36 Space usage for pushdown stacks. Justify the entries in the table below, which shows typical space usage for various pushdown stack implementations. Use a static nested class for linked-list nodes to avoid the non-static nested class overhead.</p><p attribs="{'xml:space': 'preserve'}" id="_03716" smilref="Title.smil#_03716"> data structure</p><p attribs="{'xml:space': 'preserve'}" id="_03717" smilref="Title.smil#_03717"> item type</p><p attribs="{'xml:space': 'preserve'}" id="_03718" smilref="Title.smil#_03718"> space usage for N int values (bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_03719" smilref="Title.smil#_03719"> linked list</p><p attribs="{'xml:space': 'preserve'}" id="_03720" smilref="Title.smil#_03720"> int</p><p attribs="{'xml:space': 'preserve'}" id="_03721" smilref="Title.smil#_03721"> Integer</p><p attribs="{'xml:space': 'preserve'}" id="_03722" smilref="Title.smil#_03722"> ~ 32 N</p><p attribs="{'xml:space': 'preserve'}" id="_03723" smilref="Title.smil#_03723"> ~ 56 N</p><p attribs="{'xml:space': 'preserve'}" id="_03724" smilref="Title.smil#_03724"> resizing array</p><p attribs="{'xml:space': 'preserve'}" id="_03725" smilref="Title.smil#_03725"> int</p><p attribs="{'xml:space': 'preserve'}" id="_03726" smilref="Title.smil#_03726"> between ~4 N and ~16 N between ~32 N and ~56 N Space usage in pushdown stacks (various implementations)</p><p attribs="{'xml:space': 'preserve'}" id="_03727" smilref="Title.smil#_03727"> Integer</p><p attribs="{'xml:space': 'preserve'}" id="_03728" smilref="Title.smil#_03728" /><pagenum id="p227" page="normal" smilref="Title.smil#p227" /><p attribs="{'xml:space': 'preserve'}" id="_03729" smilref="Title.smil#_03729"> 214</p><p attribs="{'xml:space': 'preserve'}" id="_03730" smilref="Title.smil#_03730"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03731" smilref="Title.smil#_03731"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_03732" smilref="Title.smil#_03732"> 1.4.37 Autoboxing performance penalty. Run experiments to determine the performance penalty on your machine for using autoboxing and auto-unboxing. Develop an implementation FixedCapacityStackOfInts and use a client such as DoublingRatio to compare its performance with the generic FixedCapacityStack&lt;Integer&gt;, for a large number of push() and pop() operations. 1.4.38 Naive 3-sum implementation. Run experiments to evaluate the following implementation of the inner loop of ThreeSum:</p><p attribs="{'xml:space': 'preserve'}" id="_03733" smilref="Title.smil#_03733"> for (int i = 0; i &lt; N; i++) for (int j = 0; j &lt; N; j++) for (int k = 0; k &lt; N; k++) if (i &lt; j &amp;&amp; j &lt; k) if (a[i] + a[j] + a[k] == 0) cnt++;</p><p attribs="{'xml:space': 'preserve'}" id="_03734" smilref="Title.smil#_03734"> Do so by developing a version of DoublingTest that computes the ratio of the running times of this program and ThreeSum. 1.4.39 Improved accuracy for doubling test. Modify DoublingRatio to take a second command-line argument that specifies the number of calls to make to timeTrial() for each value of N. Run your program for 10, 100, and 1,000 trials and comment on the precision of the results. 1.4.40 3-sum for random values. Formulate and validate a hypothesis describing the number of triples of N random int values that sum to 0. If you are skilled in mathematical analysis, develop an appropriate mathematical model for this problem, where the values are uniformly distributed between &#8211;M and M, where M is not small. 1.4.41 Running times. Estimate the amount of time it would take to run TwoSumFast, TwoSum, ThreeSumFast and ThreeSum on your computer to solve the problems for a file of 1 million numbers. Use DoublingRatio to do so. 1.4.42 Problem sizes. Estimate the size of the largest value of P for which you can run TwoSumFast, TwoSum, ThreeSumFast, and ThreeSum on your computer to solve the problems for a file of 2P thousand numbers. Use DoublingRatio to do so. 1.4.43 Resizing arrays versus linked lists. Run experiments to validate the hypothesis that resizing arrays are faster than linked lists for stacks (see Exercise 1.4.35 and Exer- cise 1.4.36). Do so by developing a version of DoublingRatio that computes the ratio</p><p attribs="{'xml:space': 'preserve'}" id="_03735" smilref="Title.smil#_03735" /><pagenum id="p228" page="normal" smilref="Title.smil#p228" /><p attribs="{'xml:space': 'preserve'}" id="_03736" smilref="Title.smil#_03736"> 1.4 </p><p attribs="{'xml:space': 'preserve'}" id="_03737" smilref="Title.smil#_03737"> 215</p><p attribs="{'xml:space': 'preserve'}" id="_03738" smilref="Title.smil#_03738"> of the running times of the two programs. 1.4.44 Birthday problem. Write a program that takes an integer N from the command line and uses StdRandom.uniform() to generate a random sequence of integers between 0 and N &#8211; 1. Run experiments to validate the hypothesis that the number of integers generated before the first repeated value is found is ~&#8730;&#9266;N/2. 1.4.45 Coupon collector problem. Generating random integers as in the previous exer- cise, run experiments to validate the hypothesis that the number of integers generated before all possible values are generated is ~N HN.</p><p attribs="{'xml:space': 'preserve'}" id="_03739" smilref="Title.smil#_03739" /></level3><level3 id="_00025"><h3 id="ch1-s5-ss26" smilref="Title.smil#ch1-s5-ss26" xml:space="preserve">Dynamic connectivity</h3><p attribs="{'xml:space': 'preserve'}" id="_03740" smilref="Title.smil#_03740"> 1.5</p><p attribs="{'xml:space': 'preserve'}" id="_03741" smilref="Title.smil#_03741"> CASE STUDY: UNION-FIND</p><p attribs="{'xml:space': 'preserve'}" id="_03742" smilref="Title.smil#_03742"> To illustrate our basic approach to developing and analyzing algorithms, we now consider a detailed example. Our purpose is to emphasize the following themes. </p><p attribs="{'xml:space': 'preserve'}" id="_03743" smilref="Title.smil#_03743"> </p><p attribs="{'xml:space': 'preserve'}" id="_03744" smilref="Title.smil#_03744"> Dynamic connectivity We start with the following problem speci&#64257; cation: The input is a sequence of pairs of integers, where each integer represents an object of some type and we are to interpret the pair p q as meaning &#8220;p is connected to q.&#8221; We assume that &#8220;is connected to&#8221; is an equivalence relation, which means that it is </p><p attribs="{'xml:space': 'preserve'}" id="_03745" smilref="Title.smil#_03745"> 216</p><p attribs="{'xml:space': 'preserve'}" id="_03746" smilref="Title.smil#_03746" /><p attribs="{'xml:space': 'preserve'}" id="_03747" smilref="Title.smil#_03747"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03748" smilref="Title.smil#_03748"> 217</p><p attribs="{'xml:space': 'preserve'}" id="_03749" smilref="Title.smil#_03749"> information about the pairs it has seen to be able to decide whether or not a new pair of objects is connected. Informally, we refer to the task of designing such a method as the dynamic connectivity problem. This problem arises applications such as the following:</p><p attribs="{'xml:space': 'preserve'}" id="_03750" smilref="Title.smil#_03750"> Networks. The integers might represent computers in a large network, and the pairs might represent connections in the network. Then, our program determines whether we need to establish a new direct connection for p and q to be able to communicate or whether we can use existing connections to set up a communications path. Or, the integers might represent contact sites in an electrical circuit, and the pairs might represent wires connecting the sites. Or, the integers might represent people in a social network, and the pairs might represent friendships. In such applications, we might need to process millions of objects and billions of connections.</p><p attribs="{'xml:space': 'preserve'}" id="_03751" smilref="Title.smil#_03751"> 4 3</p><p attribs="{'xml:space': 'preserve'}" id="_03752" smilref="Title.smil#_03752"> 3 8</p><p attribs="{'xml:space': 'preserve'}" id="_03753" smilref="Title.smil#_03753"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03754" smilref="Title.smil#_03754"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03755" smilref="Title.smil#_03755"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_03756" smilref="Title.smil#_03756"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03757" smilref="Title.smil#_03757"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_03758" smilref="Title.smil#_03758"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03759" smilref="Title.smil#_03759"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_03760" smilref="Title.smil#_03760"> 6 5</p><p attribs="{'xml:space': 'preserve'}" id="_03761" smilref="Title.smil#_03761"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_03762" smilref="Title.smil#_03762"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03763" smilref="Title.smil#_03763"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_03764" smilref="Title.smil#_03764"> Variable-name equivalence. In certain programming environ- ments, it is possible to declare two variable names as being equivalent (references to the same object). After a sequence of such dec- larations, the system needs to be able to determine whether two given names are equivalent. This application is an early one (for the FORTRAN programming language) that motivated the development of the algorithms that we are about to consider.</p><p attribs="{'xml:space': 'preserve'}" id="_03765" smilref="Title.smil#_03765"> Mathematical sets. On a more abstract level, you can think of the integers as belonging to mathematical sets. When we process a pair p q, we are asking whether they belong to the same set. If not, we unite p&#8217;s set and q&#8217;s set, putting them in the same set.</p><p attribs="{'xml:space': 'preserve'}" id="_03766" smilref="Title.smil#_03766"> 9 4</p><p attribs="{'xml:space': 'preserve'}" id="_03767" smilref="Title.smil#_03767"> 2 1</p><p attribs="{'xml:space': 'preserve'}" id="_03768" smilref="Title.smil#_03768"> 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03769" smilref="Title.smil#_03769"> 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_03770" smilref="Title.smil#_03770"> 7 2</p><p attribs="{'xml:space': 'preserve'}" id="_03771" smilref="Title.smil#_03771"> 6 1</p><p attribs="{'xml:space': 'preserve'}" id="_03772" smilref="Title.smil#_03772"> 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_03773" smilref="Title.smil#_03773"> don&#8217;t print pairs that are already connected</p><p attribs="{'xml:space': 'preserve'}" id="_03774" smilref="Title.smil#_03774"> 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_03775" smilref="Title.smil#_03775"> To fix ideas, we will use networking terminology for the rest of this section and refer to the objects as sites, the pairs as connec- tions, and the equivalence classes as connected components, or just components for short. For simplicity, we assume that we have N sites with integer names, from 0 to N-1. We do so without loss of generality because we shall be considering a host of algorithms in Chapter 3 that can associate arbitrary names with such integer identifiers in an efficient manner. A larger example that gives some indication of the difficulty of the connectivity problem is depicted in the figure at the top of the next page. You can quickly identify the component consisting of a single site in the left middle of the diagram and the</p><p attribs="{'xml:space': 'preserve'}" id="_03776" smilref="Title.smil#_03776"> 2 components</p><p attribs="{'xml:space': 'preserve'}" id="_03777" smilref="Title.smil#_03777"> Dynamic connectivity example</p><p attribs="{'xml:space': 'preserve'}" id="_03778" smilref="Title.smil#_03778" /><p attribs="{'xml:space': 'preserve'}" id="_03779" smilref="Title.smil#_03779"> 218</p><p attribs="{'xml:space': 'preserve'}" id="_03780" smilref="Title.smil#_03780"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03781" smilref="Title.smil#_03781"> connected component</p><p attribs="{'xml:space': 'preserve'}" id="_03782" smilref="Title.smil#_03782"> Medium connectivity example (625 sites, 900 edges, 3 connected components)</p><p attribs="{'xml:space': 'preserve'}" id="_03783" smilref="Title.smil#_03783"> component consisting of five sites at the bottom left, but you might have difficulty verifying that all of the other sites are connected to one another. For a program, the task is even more dif&#64257; cult, because it has to work just with site names and connections and has no access to the geometric placement of sites in the diagram. How can we tell quickly whether or not any given two sites in such a network are connected? The first task that we face in developing an algorithm is to specify the problem in a precise manner. The more we require of an algorithm, the more time and space we may expect it to need to finish the job. It is impossible to quantify this relationship a priori, and we often modify a problem specification on finding that it is difficult or expensive to solve or, in happy circumstances, on finding that an algorithm can provide information more useful than what was called for in the original speci&#64257; cation. For example, our</p><p attribs="{'xml:space': 'preserve'}" id="_03784" smilref="Title.smil#_03784" /><p attribs="{'xml:space': 'preserve'}" id="_03785" smilref="Title.smil#_03785"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03786" smilref="Title.smil#_03786"> 219</p><p attribs="{'xml:space': 'preserve'}" id="_03787" smilref="Title.smil#_03787"> connectivity problem specification requires only that our program be able to determine whether or not any given pair p q is connected, and not that it be able to demonstrate a set of connections that connect that pair. Such a requirement makes the problem more difficult and leads us to a different family of algorithms, which we consider in Section</p><p attribs="{'xml:space': 'preserve'}" id="_03788" smilref="Title.smil#_03788"> 4.1.</p><p attribs="{'xml:space': 'preserve'}" id="_03789" smilref="Title.smil#_03789"> To specify the problem, we develop an API that encapsulates the basic operations that we need: initialize, add a connection between two sites, identify the component containing a site, determine whether two sites are in the same component, and count the number of components. Thus, we articulate the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_03790" smilref="Title.smil#_03790"> public class UF</p><p attribs="{'xml:space': 'preserve'}" id="_03791" smilref="Title.smil#_03791"> UF(int N)</p><p attribs="{'xml:space': 'preserve'}" id="_03792" smilref="Title.smil#_03792"> void union(int p, int q)</p><p attribs="{'xml:space': 'preserve'}" id="_03793" smilref="Title.smil#_03793"> initialize N sites with integer names (0 to N-1) add connection between p and q component identifier  for p (0 to N-1) boolean connected(int p, int q) return true if p and q are in the same component number of components</p><p attribs="{'xml:space': 'preserve'}" id="_03794" smilref="Title.smil#_03794"> int find(int p)</p><p attribs="{'xml:space': 'preserve'}" id="_03795" smilref="Title.smil#_03795"> int count()</p><p attribs="{'xml:space': 'preserve'}" id="_03796" smilref="Title.smil#_03796"> Union-f ind API</p><p attribs="{'xml:space': 'preserve'}" id="_03797" smilref="Title.smil#_03797"> The union() operation merges two components if the two sites are in different com- ponents, the find() operation returns an integer component identifier for a given site, the connected() operation determines whether two sites are in the same component, and the count() method returns the number of components. We start with N compo- nents, and each union() that merges two different components decrements the number of components by 1. As we shall soon see, the development of an algorithmic solution for dynamic connectivity thus reduces to the task of developing an implementation of this API. Every implementation has to </p><p attribs="{'xml:space': 'preserve'}" id="_03798" smilref="Title.smil#_03798" /><p attribs="{'xml:space': 'preserve'}" id="_03799" smilref="Title.smil#_03799"> 220</p><p attribs="{'xml:space': 'preserve'}" id="_03800" smilref="Title.smil#_03800"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03801" smilref="Title.smil#_03801"> data structure to represent the components. We always use the name of one of the sites in a component as the component identi&#64257; er, so you can think of each component as being represented by one of its sites. Initially, we start with N components, each site in its own component, so we initialize id[i] to i for all i from 0 to N-1. For each site i, we keep the information needed by find() to determine the component containing i in id[i], using various algorithm-dependent strategies. All of our implementations use a one-line implementation of connected() that returns the boolean value</p><p attribs="{'xml:space': 'preserve'}" id="_03802" smilref="Title.smil#_03802"> find(p) == find(q).</p><p attribs="{'xml:space': 'preserve'}" id="_03803" smilref="Title.smil#_03803"> % more tinyUF.txt 10 4 3 3 8 6 5 9 4 2 1 8 9 5 0 7 2 6 1 1 0 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_03804" smilref="Title.smil#_03804"> % more mediumUF.txt 625 528 503 548 523 ... [900 connections]</p><p attribs="{'xml:space': 'preserve'}" id="_03805" smilref="Title.smil#_03805"> % more largeUF.txt 1000000 786321 134521 696834 98245 ... [2000000 connections]</p><p attribs="{'xml:space': 'preserve'}" id="_03806" smilref="Title.smil#_03806"> In summary, our starting point is Algorithm 1.5 on the facing page. We maintain two instance variables, the count of components and the array id[]. Implementations of find() and union() are the topic of the remainder of this section. To test the utility of the API and to provide a basis for develop- ment, we include a client in main() that uses it to solve the dynamic connectivity problem. It reads the value of N followed by a sequence of pairs of integers (each in the range 0 to N-1), calling find() for each pair: If the two sites in the pair are already con- nected, it moves on to the next pair; if they are not, it calls union() and prints the pair. Before considering implementations, we also prepare test data: the file tinyUF.txt contains the 11 connections among 10 sites used in the small example illustrated on page 217, the file mediumUF.txt contains the 900 connections among 625 sites illustrated on page 218, and the file largeUF.txt is an example with 2 million connections among 1 millions sites. Our goal is to be able to handle inputs such as largeUF.txt in a reasonable amount of time. To analyze the algorithms, we focus on the number of times each algorithm accesses an array entry. By doing so, we are implicitly formulating the hypothesis that the running times of the algorithms on a particular machine are within a constant factor of this quantity. This hypothesis is immediate from the code, is not difficult to validate through ex- perimentation, and provides a useful starting point for comparing algorithms, as we will see.</p><p attribs="{'xml:space': 'preserve'}" id="_03807" smilref="Title.smil#_03807"> studying algorithms to implement the union-&#64257; nd API, we count array accesses (the number of times an array entry is accessed, for read or write).</p><p attribs="{'xml:space': 'preserve'}" id="_03808" smilref="Title.smil#_03808"> Union-find cost model. When</p><p attribs="{'xml:space': 'preserve'}" id="_03809" smilref="Title.smil#_03809" /><p attribs="{'xml:space': 'preserve'}" id="_03810" smilref="Title.smil#_03810"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03811" smilref="Title.smil#_03811"> 221</p><p attribs="{'xml:space': 'preserve'}" id="_03812" smilref="Title.smil#_03812"> ALGORITHM 1.5 Union-find implementation</p><p attribs="{'xml:space': 'preserve'}" id="_03813" smilref="Title.smil#_03813"> public class UF { private int[] id; // access to component id (site indexed) private int count; // number of components</p><p attribs="{'xml:space': 'preserve'}" id="_03814" smilref="Title.smil#_03814"> public UF(int N) { // Initialize component id array. count = N; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; }</p><p attribs="{'xml:space': 'preserve'}" id="_03815" smilref="Title.smil#_03815"> public int count() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_03816" smilref="Title.smil#_03816"> public boolean connected(int p, int q) { return find(p) == find(q); }</p><p attribs="{'xml:space': 'preserve'}" id="_03817" smilref="Title.smil#_03817"> % java UF &lt; tinyUF.txt 4 3 3 8 6 5 9 4 2 1 5 0 7 2 6 1 2 components</p><p attribs="{'xml:space': 'preserve'}" id="_03818" smilref="Title.smil#_03818"> public int find(int p) public void union(int p, int q) // See page 222 (quick-find),page 224 (quick-union) andpage 228 (weighted).</p><p attribs="{'xml:space': 'preserve'}" id="_03819" smilref="Title.smil#_03819"> public static void main(String[] args) { // Solve dynamic connectivity problem on StdIn. int N = StdIn.readInt(); // Read number of sites. UF uf = new UF(N); // Initialize N components. while (!StdIn.isEmpty()) { int p = StdIn.readInt(); int q = StdIn.readInt(); // Read pair to connect. if (uf.connected(p, q)) continue; // Ignore if connected. uf.union(p, q); // Combine components StdOut.println(p + " " + q); // and print connection. } StdOut.println(uf.count() + " components"); }</p><p attribs="{'xml:space': 'preserve'}" id="_03820" smilref="Title.smil#_03820"> }</p><p attribs="{'xml:space': 'preserve'}" id="_03821" smilref="Title.smil#_03821"> Our UF implementations are based on this code, which maintains an array of integers id[] such that the find() method returns the same integer for every site in each connected component. The union() method must maintain this invariant.</p><p attribs="{'xml:space': 'preserve'}" id="_03822" smilref="Title.smil#_03822" /><p attribs="{'xml:space': 'preserve'}" id="_03823" smilref="Title.smil#_03823"> 222</p><p attribs="{'xml:space': 'preserve'}" id="_03824" smilref="Title.smil#_03824"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03825" smilref="Title.smil#_03825"> Implementations We shall consider three different implementations, all based on using the site-indexed id[] array, to determine whether two sites are in the same connected component.</p><p attribs="{'xml:space': 'preserve'}" id="_03826" smilref="Title.smil#_03826"> find examines id[5] and id[9]</p><p attribs="{'xml:space': 'preserve'}" id="_03827" smilref="Title.smil#_03827"> p q 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03828" smilref="Title.smil#_03828"> 5 9 1 1 1 8 8 1 1 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03829" smilref="Title.smil#_03829"> union has to change all 1s to 8s</p><p attribs="{'xml:space': 'preserve'}" id="_03830" smilref="Title.smil#_03830"> Quick-&#64257; nd. One approach is to maintain the invariant that p and q are connected if and only if id[p] is equal to id[q]. In other words, all sites in a component must have the same value in id[]. This method is called quick-&#64257; nd because find(p) just returns id[p], which immediately implies that connected(p, q) reduces to just the test id[p] == id[q] and returns true if and only if p and q are in the same component. To maintain the invariant for the call union(p, q), we first check whether they are already in the same component, in which case there is nothing to do. Otherwise, we are faced with the situation that all of the id[] entries corresponding to sites in the same component as p have one value and all of the id[] entries corresponding to sites in the same component as q have another value. To combine the two components into one, we have to make all of the id[] entries corresponding to both sets of sites the same value, as shown in the example at right. To do so, we go through the array, changing all the entries with values equal to id[p] to the value id[q]. We could have decided to change all the entries equal to id[q] to the value id[p]&#8212;the choice between these two alternatives is arbitrary. The code for find() and union() based on these descriptions, given at left, is straightforward. A full trace for our development client with our sample test data tinyUF.txt is shown on the next page.</p><p attribs="{'xml:space': 'preserve'}" id="_03831" smilref="Title.smil#_03831"> 5 9 1 1 1 8 8 1 1 1 8 8 8 8 8 8 8 8 8 8 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03832" smilref="Title.smil#_03832"> p q 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03833" smilref="Title.smil#_03833"> Quick-find overview</p><p attribs="{'xml:space': 'preserve'}" id="_03834" smilref="Title.smil#_03834"> public int find(int p) { return id[p]; }</p><p attribs="{'xml:space': 'preserve'}" id="_03835" smilref="Title.smil#_03835"> public void union(int p, int q) { // Put p and q into the same component. int pID = find(p); int qID = find(q);</p><p attribs="{'xml:space': 'preserve'}" id="_03836" smilref="Title.smil#_03836"> // Nothing to do if p and q are already in the same component. if (pID == qID) return;</p><p attribs="{'xml:space': 'preserve'}" id="_03837" smilref="Title.smil#_03837"> // Rename p&#8217;s component to q&#8217;s name. for (int i = 0; i &lt; id.length; i++) if (id[i] == pID) id[i] = qID; count--; }</p><p attribs="{'xml:space': 'preserve'}" id="_03838" smilref="Title.smil#_03838"> Quick-f ind</p><p attribs="{'xml:space': 'preserve'}" id="_03839" smilref="Title.smil#_03839" /></level3><level3 id="_00026"><h3 id="ch1-s5-ss27" smilref="Title.smil#ch1-s5-ss27" xml:space="preserve">Quick find</h3><pagenum id="p236" page="normal" smilref="Title.smil#p236" /><p attribs="{'xml:space': 'preserve'}" id="_03840" smilref="Title.smil#_03840"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03841" smilref="Title.smil#_03841"> 223</p><p attribs="{'xml:space': 'preserve'}" id="_03842" smilref="Title.smil#_03842"> Quick-&#64257; nd analysis. The find() operation is certainly quick, as it only accesses the id[] array once in order to complete the operation. But quick-&#64257; nd is typically not useful for large problems because union() needs to scan through the whole id[] array for each input pair.</p><p attribs="{'xml:space': 'preserve'}" id="_03843" smilref="Title.smil#_03843"> Proposition F. The quick-&#64257; nd algorithm uses one array access for each call to find() and between N + 3 and 2N + 1 array accesses for each call to union() that combines two components.</p><p attribs="{'xml:space': 'preserve'}" id="_03844" smilref="Title.smil#_03844"> Proof : Immediate from the code. Each call to connected() tests two entries in the id[] array, one for each of the two calls to find(). Each call to union() that combines two components does so by making two calls to find(), testing each of the N entries in the id[] array, and changing between 1 and N &#11002; 1 of them.</p><p attribs="{'xml:space': 'preserve'}" id="_03845" smilref="Title.smil#_03845"> id[] p q 0 1 2 3 4 5 6 7 8 9 4 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 3 5 6 7 8 9 3 8 0 1 2 3 3 5 6 7 8 9 0 1 2 8 8 5 6 7 8 9 6 5 0 1 2 8 8 5 6 7 8 9 0 1 2 8 8 5 5 7 8 9 9 4 0 1 2 8 8 5 5 7 8 9 0 1 2 8 8 5 5 7 8 8 2 1 0 1 2 8 8 5 5 7 8 8 0 1 1 8 8 5 5 7 8 8 8 9 0 1 1 8 8 5 5 7 8 8 5 0 0 1 1 8 8 5 5 7 8 8 0 1 1 8 8 0 0 7 8 8 7 2 0 1 1 8 8 0 0 7 8 8 0 1 1 8 8 0 0 1 8 8 6 1 0 1 1 8 8 0 0 1 8 8 1 1 1 8 8 1 1 1 8 8 1 0 1 1 1 8 8 1 1 1 8 8 6 7 1 1 1 8 8 1 1 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03846" smilref="Title.smil#_03846"> id[p] and id[q] differ, so union() changes entries equal to id[p] to id[q] (in red)</p><p attribs="{'xml:space': 'preserve'}" id="_03847" smilref="Title.smil#_03847"> id[p] and id[q]</p><p attribs="{'xml:space': 'preserve'}" id="_03848" smilref="Title.smil#_03848"> match, so no change</p><p attribs="{'xml:space': 'preserve'}" id="_03849" smilref="Title.smil#_03849"> Quick-find trace</p><p attribs="{'xml:space': 'preserve'}" id="_03850" smilref="Title.smil#_03850"> In particular, suppose that we use quick-&#64257; nd for the dynamic connectivity problem and wind up with a single component. This requires at least N&#11002;1 calls to union(), and, consequently, at least (N&#11001;3)(N&#11002;1) ~ N 2 array accesses&#8212;we are led immediately to the hypothesis that dynamic connectivity with quick-&#64257; nd can be a quadratic-time process. This analysis generalizes to say that quick-&#64257; nd is quadratic for typical applications where we end up with a small number of components. You can easily validate this hypothesis on your computer with a doubling test (see Exercise 1.5.23 for an instructive example). Modern computers can execute hundreds of millions or billions of instructions per second, so this cost is not noticeable if N is small, but we also might find ourselves with millions or billions of sites and connections to process in a modern application, as represented by our test file largeUF.txt. If you are still not convinced and feel that you have a particularly fast computer, try using quick-&#64257; nd to determine the number of components implied by the pairs in largeUF.txt. The inescapable conclusion is that we cannot feasibly solve such a problem using the quick-&#64257; nd algorithm, so we seek better algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_03851" smilref="Title.smil#_03851" /></level3><level3 id="_00027"><h3 id="ch1-s5-ss28" smilref="Title.smil#ch1-s5-ss28" xml:space="preserve">Quick union</h3><pagenum id="p237" page="normal" smilref="Title.smil#p237" /><p attribs="{'xml:space': 'preserve'}" id="_03852" smilref="Title.smil#_03852"> 224</p><p attribs="{'xml:space': 'preserve'}" id="_03853" smilref="Title.smil#_03853"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03854" smilref="Title.smil#_03854"> id[i] = j;</p><p attribs="{'xml:space': 'preserve'}" id="_03855" smilref="Title.smil#_03855"> public int find(int p) { // Find component name. while (p != id[p]) p = id[p]; return p; }</p><p attribs="{'xml:space': 'preserve'}" id="_03856" smilref="Title.smil#_03856"> public void union(int p, int q) { // Give p and q the same root. int i = find(p); int j = find(q); if (i == j) return;</p><p attribs="{'xml:space': 'preserve'}" id="_03857" smilref="Title.smil#_03857"> Quick-union. The next algorithm that we consider is a complementary method that concentrates on speeding up the union() operation. It is based on the same data structure&#8212;the site-indexed id[] ar- ray&#8212;but we interpret the values dif- ferently, to define more complicated structures. Speci&#64257; cally, the id[] entry for each site is the name of another site in the same component (possibly itself )&#8212;we refer to this connection as a link. To implement find(), we start at the given site, follow its link to another site, follow that site&#8217;s link to yet another site, and so forth, following links until reaching a root, a site that has a link to itself (which is guaranteed to happen, as you will see). Two sites are in the same component if and only if this process leads them to the same root. To validate this process, we need union(p, q) to maintain this invariant, which is easily arranged: we follow links to find the roots associated with p and q, then rename one of the components by linking one of these roots to the other; hence the name quick-union. Again, we have an arbitrary choice of whether to rename the component containing p or the component containing q; the implementation above renames the one containing p. The figure on the next page shows a trace of the quick-union algorithm for tinyUF.txt. This trace is best understood in terms of the graphical representation depicted at left, which we consider next.</p><p attribs="{'xml:space': 'preserve'}" id="_03858" smilref="Title.smil#_03858"> 5 9 1 1 1 8 3 0 5 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03859" smilref="Title.smil#_03859"> p q 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03860" smilref="Title.smil#_03860"> count--; }</p><p attribs="{'xml:space': 'preserve'}" id="_03861" smilref="Title.smil#_03861"> find has to follow links to the root</p><p attribs="{'xml:space': 'preserve'}" id="_03862" smilref="Title.smil#_03862"> find(5) is id[id[id[5]]]</p><p attribs="{'xml:space': 'preserve'}" id="_03863" smilref="Title.smil#_03863"> find(9) is id[id[9]]</p><p attribs="{'xml:space': 'preserve'}" id="_03864" smilref="Title.smil#_03864"> Quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_03865" smilref="Title.smil#_03865"> id[] is parent-link representation of a forest of trees</p><p attribs="{'xml:space': 'preserve'}" id="_03866" smilref="Title.smil#_03866"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03867" smilref="Title.smil#_03867"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03868" smilref="Title.smil#_03868"> root</p><p attribs="{'xml:space': 'preserve'}" id="_03869" smilref="Title.smil#_03869"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03870" smilref="Title.smil#_03870"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_03871" smilref="Title.smil#_03871"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_03872" smilref="Title.smil#_03872"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_03873" smilref="Title.smil#_03873"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_03874" smilref="Title.smil#_03874"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03875" smilref="Title.smil#_03875"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03876" smilref="Title.smil#_03876"> 6 8 becomes parent of 1</p><p attribs="{'xml:space': 'preserve'}" id="_03877" smilref="Title.smil#_03877"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03878" smilref="Title.smil#_03878"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03879" smilref="Title.smil#_03879"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_03880" smilref="Title.smil#_03880"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03881" smilref="Title.smil#_03881"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03882" smilref="Title.smil#_03882"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_03883" smilref="Title.smil#_03883"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_03884" smilref="Title.smil#_03884"> union changes just one link</p><p attribs="{'xml:space': 'preserve'}" id="_03885" smilref="Title.smil#_03885"> p q 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03886" smilref="Title.smil#_03886"> 5 9 1 1 1 8 3 0 5 1 8 8 1 8 1 8 3 0 5 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03887" smilref="Title.smil#_03887"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03888" smilref="Title.smil#_03888"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_03889" smilref="Title.smil#_03889"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_03890" smilref="Title.smil#_03890"> Quick-union overview</p><p attribs="{'xml:space': 'preserve'}" id="_03891" smilref="Title.smil#_03891" /><pagenum id="p238" page="normal" smilref="Title.smil#p238" /><p attribs="{'xml:space': 'preserve'}" id="_03892" smilref="Title.smil#_03892"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03893" smilref="Title.smil#_03893"> 225</p><p attribs="{'xml:space': 'preserve'}" id="_03894" smilref="Title.smil#_03894"> 6 5 0 1 2 8 3 5 6 7 8 9 0 1 2 8 3 5 5 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03895" smilref="Title.smil#_03895"> id[] p q 0 1 2 3 4 5 6 7 8 9 4 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 3 5 6 7 8 9 3 8 0 1 2 3 3 5 6 7 8 9 0 1 2 8 3 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_03896" smilref="Title.smil#_03896"> Forest-of-trees representation. The code for quick-union is compact, but a bit opaque. Representing sites as nodes (labeled circles) and links as arrows from one node to another gives a graphical representation of the data structure that makes it relatively easy to understand the operation of the algorithm. The resulting structures are trees&#8212;in technical terms, our id[] array is a parent-link representation of a forest (set) of trees. To simplify the diagrams, we often omit both the arrowheads in the links (because they all point upwards) and the self-links in the roots of the trees. The forests corresponding to the id[] array for tinyUF.txt are shown at right. When we start at the node corresponding to any site and follow links, we eventually end up at the root of the tree containing that node. We can prove this property to be true by induction: It is true after the array is initialized to have every node link to itself, and if it is true before a given union() operation, it is certainly true afterward. Thus, the find() method on page 224 returns the name of the site at the root (so that connected() checks whether two sites are in the same tree). This representation is useful for this problem because the nodes corresponding to two sites are in the same tree if and only if the sites are in the same component. Moreover, the trees are not difficult to build: the union() implementation on page 224 combines two trees into one in a single statement, by making the root of one the parent of the other.</p><p attribs="{'xml:space': 'preserve'}" id="_03897" smilref="Title.smil#_03897"> 7 2 0 1 1 8 3 0 5 7 8 8 0 1 1 8 3 0 5 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03898" smilref="Title.smil#_03898"> 9 4 0 1 2 8 3 5 5 7 8 9 0 1 2 8 3 5 5 7 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03899" smilref="Title.smil#_03899"> 2 1 0 1 2 8 3 5 5 7 8 8 0 1 1 8 3 5 5 7 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03900" smilref="Title.smil#_03900"> 8 9 0 1 1 8 3 5 5 7 8 8 5 0 0 1 1 8 3 5 5 7 8 8 0 1 1 8 3 0 5 7 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03901" smilref="Title.smil#_03901"> 6 1 0 1 1 8 3 0 5 1 8 8 1 1 1 8 3 0 5 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03902" smilref="Title.smil#_03902"> 1 0 1 1 1 8 3 0 5 1 8 8 6 7 1 1 1 8 3 0 5 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_03903" smilref="Title.smil#_03903"> Quick-union trace (with corresponding forests of trees)</p><p attribs="{'xml:space': 'preserve'}" id="_03904" smilref="Title.smil#_03904" /><pagenum id="p239" page="normal" smilref="Title.smil#p239" /><p attribs="{'xml:space': 'preserve'}" id="_03905" smilref="Title.smil#_03905"> 226</p><p attribs="{'xml:space': 'preserve'}" id="_03906" smilref="Title.smil#_03906"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_03907" smilref="Title.smil#_03907"> id[] p q 0 1 2 3 4 ... 0 1 0 1 2 3 4 ... 1 1 2 3 4 ... 0 2 0 1 2 3 4 ... 1 2 2 3 4 ...</p><p attribs="{'xml:space': 'preserve'}" id="_03908" smilref="Title.smil#_03908"> 0 3 0 1 2 3 4 ... 1 2 3 3 4 ...</p><p attribs="{'xml:space': 'preserve'}" id="_03909" smilref="Title.smil#_03909"> 0 4 0 1 2 3 4 ... 1 2 3 4 4 ... . . .</p><p attribs="{'xml:space': 'preserve'}" id="_03910" smilref="Title.smil#_03910"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03911" smilref="Title.smil#_03911"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03912" smilref="Title.smil#_03912"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03913" smilref="Title.smil#_03913"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03914" smilref="Title.smil#_03914"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03915" smilref="Title.smil#_03915"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03916" smilref="Title.smil#_03916"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03917" smilref="Title.smil#_03917"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03918" smilref="Title.smil#_03918"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03919" smilref="Title.smil#_03919"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03920" smilref="Title.smil#_03920"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03921" smilref="Title.smil#_03921"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03922" smilref="Title.smil#_03922"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03923" smilref="Title.smil#_03923"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03924" smilref="Title.smil#_03924"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03925" smilref="Title.smil#_03925"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03926" smilref="Title.smil#_03926"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03927" smilref="Title.smil#_03927"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03928" smilref="Title.smil#_03928"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03929" smilref="Title.smil#_03929"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03930" smilref="Title.smil#_03930"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03931" smilref="Title.smil#_03931"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03932" smilref="Title.smil#_03932"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03933" smilref="Title.smil#_03933"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03934" smilref="Title.smil#_03934"> Quick-union analysis. The quick-union algorithm would seem to be faster than the quick-&#64257; nd algorithm, because it does not have to go through the entire array for each input pair; but how much faster is it? Analyzing the cost of quick-union is more difficult than it was for quick-&#64257; nd, because the cost is more dependent on the nature of the input. In the best case, find() just needs one array access to find the identifier associated with a site, as in quick-&#64257; nd; in the worst case, it needs 2N &#11002; 1 array accesses, as for 0 in the example at left (this count is conservative since compiled code will typically not do an array access for the second reference to id[p] in the while loop). Ac- cordingly, it is not difficult to construct a best-case input for which the running time of our dynamic connectivity client is linear; on the other hand it is also not difficult to construct a worst-case input for which the running time is quadratic (see the diagram at left and Proposition G below). Fortunate- ly, we do not need to face the problem of analyzing quick union and we will not dwell on comparative performance of quick-&#64257; nd and quick-union because we will next examine another variant that is far more efficient than either. For the moment, you can regard quick-union as an improvement over quick-&#64257; nd because it removes quick-&#64257; nd&#8217;s main liability (that union() always takes linear time). This difference certainly represents an improvement for typical data, but quick-union still has the liability that we cannot guarantee it to be substantially faster than quick-&#64257; nd in every case (for certain input data, quick-union is no faster than quick-&#64257; nd).</p><p attribs="{'xml:space': 'preserve'}" id="_03935" smilref="Title.smil#_03935"> Quick-union worst case</p><p attribs="{'xml:space': 'preserve'}" id="_03936" smilref="Title.smil#_03936"> depth 4</p><p attribs="{'xml:space': 'preserve'}" id="_03937" smilref="Title.smil#_03937"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_03938" smilref="Title.smil#_03938"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_03939" smilref="Title.smil#_03939"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_03940" smilref="Title.smil#_03940"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_03941" smilref="Title.smil#_03941"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_03942" smilref="Title.smil#_03942"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_03943" smilref="Title.smil#_03943"> Definition. The size of a tree is its number of nodes. The depth of a node in a tree is the number of links on the path from it to the root. The height of a tree is the maximum depth among its nodes.</p><p attribs="{'xml:space': 'preserve'}" id="_03944" smilref="Title.smil#_03944"> Proposition G. The number of array accesses used by find() in quick-union is 1 plus the twice the depth of the node corresponding to the given site. The number of array accesses used by union() and connected() is the cost of the two find() operations (plus 1 for union() if the given sites are in different trees).</p><p attribs="{'xml:space': 'preserve'}" id="_03945" smilref="Title.smil#_03945"> Proof : Immediate from the code.</p><p attribs="{'xml:space': 'preserve'}" id="_03946" smilref="Title.smil#_03946" /></level3><level3 id="_00028"><h3 id="ch1-s5-ss29" smilref="Title.smil#ch1-s5-ss29" xml:space="preserve">Weighted quick union</h3><pagenum id="p240" page="normal" smilref="Title.smil#p240" /><p attribs="{'xml:space': 'preserve'}" id="_03947" smilref="Title.smil#_03947"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03948" smilref="Title.smil#_03948"> 227</p><p attribs="{'xml:space': 'preserve'}" id="_03949" smilref="Title.smil#_03949"> Again, suppose that we use quick-union for the dynamic connectivity problem and wind up with a single component. An immediate implication of Proposition G is that the running time is quadratic, in the worst case. Suppose that the input pairs come in the order 0-1, then 0-2, then 0-3, and so forth. After N &#11002; 1 such pairs, we have N sites all in the same set, and the tree that is formed by the quick-union algorithm has height N &#11002; 1, with 0 linking to 1, which links to 2, which links to 3, and so forth (see the diagram on the facing page). By Proposition G, the number of array accesses for the union() operation for the pair 0 i is exactly 2i + 2 (site 0 is at depth i and site i at depth 0). Thus, the total number of array accesses for the find() operations for these N pairs is 2 (1 + 2 + . . . + N ) ~N 2.</p><p attribs="{'xml:space': 'preserve'}" id="_03950" smilref="Title.smil#_03950"> quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_03951" smilref="Title.smil#_03951"> Weighted quick-union. Fortunately, there is an</p><p attribs="{'xml:space': 'preserve'}" id="_03952" smilref="Title.smil#_03952"> q</p><p attribs="{'xml:space': 'preserve'}" id="_03953" smilref="Title.smil#_03953"> smaller tree</p><p attribs="{'xml:space': 'preserve'}" id="_03954" smilref="Title.smil#_03954"> p</p><p attribs="{'xml:space': 'preserve'}" id="_03955" smilref="Title.smil#_03955"> p</p><p attribs="{'xml:space': 'preserve'}" id="_03956" smilref="Title.smil#_03956"> larger tree</p><p attribs="{'xml:space': 'preserve'}" id="_03957" smilref="Title.smil#_03957"> might put the larger tree lower</p><p attribs="{'xml:space': 'preserve'}" id="_03958" smilref="Title.smil#_03958"> easy modification to quick-union that allows us to guarantee that bad cases such as this one do not occur. Rather than arbitrarily connecting the second tree to the first for union(), we keep track of the size of each tree and always connect the smaller tree to the larger. This change requires slightly more code and another array to hold the node counts, as shown on page 228, but it leads to substantial improvements in ef&#64257; ciency. We refer to this algorithm as the weighted quick-union al- gorithm. The forest of trees constructed by this algorithm for tinyUF.txt is shown in the figure at left on the top of page 229. Even for this small example, the tree height is substantially smaller than the height for the unweighted version.</p><p attribs="{'xml:space': 'preserve'}" id="_03959" smilref="Title.smil#_03959"> always chooses the better alternative</p><p attribs="{'xml:space': 'preserve'}" id="_03960" smilref="Title.smil#_03960"> Weighted quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_03961" smilref="Title.smil#_03961"> q</p><p attribs="{'xml:space': 'preserve'}" id="_03962" smilref="Title.smil#_03962"> smaller tree</p><p attribs="{'xml:space': 'preserve'}" id="_03963" smilref="Title.smil#_03963"> larger tree</p><p attribs="{'xml:space': 'preserve'}" id="_03964" smilref="Title.smil#_03964"> weighted</p><p attribs="{'xml:space': 'preserve'}" id="_03965" smilref="Title.smil#_03965"> q</p><p attribs="{'xml:space': 'preserve'}" id="_03966" smilref="Title.smil#_03966"> smaller tree</p><p attribs="{'xml:space': 'preserve'}" id="_03967" smilref="Title.smil#_03967"> q</p><p attribs="{'xml:space': 'preserve'}" id="_03968" smilref="Title.smil#_03968"> smaller tree</p><p attribs="{'xml:space': 'preserve'}" id="_03969" smilref="Title.smil#_03969"> p</p><p attribs="{'xml:space': 'preserve'}" id="_03970" smilref="Title.smil#_03970"> larger tree</p><p attribs="{'xml:space': 'preserve'}" id="_03971" smilref="Title.smil#_03971"> p</p><p attribs="{'xml:space': 'preserve'}" id="_03972" smilref="Title.smil#_03972"> larger tree</p><p attribs="{'xml:space': 'preserve'}" id="_03973" smilref="Title.smil#_03973"> Weighted quick-union analysis. The figure at right on the top of page 229 illustrates the worst case for weighted quick union, when the sizes of the trees to be merged by union() are always equal (and a power of 2). These tree structures look complex, but they have the simple property that the height of a tree of 2n nodes is n. Fur- thermore, when we merge two trees of 2n nodes, we get a tree of 2n&#11001;1 nodes, and we increase the height of the tree to n&#11001;1. This observation generalizes to provide a proof that the weighted algorithm can guarantee logarithmic performance.</p><p attribs="{'xml:space': 'preserve'}" id="_03974" smilref="Title.smil#_03974"> % java WeightedQuickUnionUF &lt; largeUF.txt 786321 134521 696834 98245 ... 6 components</p><p attribs="{'xml:space': 'preserve'}" id="_03975" smilref="Title.smil#_03975"> % java WeightedQuickUnionUF &lt; mediumUF.txt 528 503 548 523 ... 3 components</p><p attribs="{'xml:space': 'preserve'}" id="_03976" smilref="Title.smil#_03976" /><pagenum id="p241" page="normal" smilref="Title.smil#p241" /><p attribs="{'xml:space': 'preserve'}" id="_03977" smilref="Title.smil#_03977"> 228</p><p attribs="{'xml:space': 'preserve'}" id="_03978" smilref="Title.smil#_03978"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_03979" smilref="Title.smil#_03979"> ALGORITHM 1.5 (continued) Union-find implementation (weighted quick-union)</p><p attribs="{'xml:space': 'preserve'}" id="_03980" smilref="Title.smil#_03980"> public class WeightedQuickUnionUF { private int[] id; // parent link (site indexed) private int[] sz; // size of component for roots (site indexed) private int count; // number of components</p><p attribs="{'xml:space': 'preserve'}" id="_03981" smilref="Title.smil#_03981"> public WeightedQuickUnionUF(int N) { count = N; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; sz = new int[N]; for (int i = 0; i &lt; N; i++) sz[i] = 1;</p><p attribs="{'xml:space': 'preserve'}" id="_03982" smilref="Title.smil#_03982"> }</p><p attribs="{'xml:space': 'preserve'}" id="_03983" smilref="Title.smil#_03983"> public int count() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_03984" smilref="Title.smil#_03984"> public boolean connected(int p, int q) { return find(p) == find(q); }</p><p attribs="{'xml:space': 'preserve'}" id="_03985" smilref="Title.smil#_03985"> private int find(int p) { // Follow links to find a root. while (p != id[p]) p = id[p]; return p; }</p><p attribs="{'xml:space': 'preserve'}" id="_03986" smilref="Title.smil#_03986"> public void union(int p, int q) { int i = find(p); int j = find(q); if (i == j) return;</p><p attribs="{'xml:space': 'preserve'}" id="_03987" smilref="Title.smil#_03987"> // Make smaller root point to larger one. if (sz[i] &lt; sz[j]) { id[i] = j; sz[j] += sz[i]; } else { id[j] = i; sz[i] += sz[j]; } count--; } }</p><p attribs="{'xml:space': 'preserve'}" id="_03988" smilref="Title.smil#_03988"> This code is best understood in terms of the forest-of-trees representation described in the text. We add a site-indexed array sz[] as an instance variable so that union() can link the root of the smaller tree to the root of the larger tree. This addition makes it feasible to address large problems.</p><p attribs="{'xml:space': 'preserve'}" id="_03989" smilref="Title.smil#_03989" /><pagenum id="p242" page="normal" smilref="Title.smil#p242" /><p attribs="{'xml:space': 'preserve'}" id="_03990" smilref="Title.smil#_03990"> reference input</p><p attribs="{'xml:space': 'preserve'}" id="_03991" smilref="Title.smil#_03991"> worst-case input</p><p attribs="{'xml:space': 'preserve'}" id="_03992" smilref="Title.smil#_03992"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_03993" smilref="Title.smil#_03993"> 229</p><p attribs="{'xml:space': 'preserve'}" id="_03994" smilref="Title.smil#_03994"> p q 4 3</p><p attribs="{'xml:space': 'preserve'}" id="_03995" smilref="Title.smil#_03995"> 3 8</p><p attribs="{'xml:space': 'preserve'}" id="_03996" smilref="Title.smil#_03996"> 6 5</p><p attribs="{'xml:space': 'preserve'}" id="_03997" smilref="Title.smil#_03997"> 9 4</p><p attribs="{'xml:space': 'preserve'}" id="_03998" smilref="Title.smil#_03998"> 2 1</p><p attribs="{'xml:space': 'preserve'}" id="_03999" smilref="Title.smil#_03999"> 8 9 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_04000" smilref="Title.smil#_04000"> 7 2</p><p attribs="{'xml:space': 'preserve'}" id="_04001" smilref="Title.smil#_04001"> 6 1 1 0 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_04002" smilref="Title.smil#_04002"> p q 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_04003" smilref="Title.smil#_04003"> 2 3</p><p attribs="{'xml:space': 'preserve'}" id="_04004" smilref="Title.smil#_04004"> 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_04005" smilref="Title.smil#_04005"> 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_04006" smilref="Title.smil#_04006"> 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_04007" smilref="Title.smil#_04007"> 4 6</p><p attribs="{'xml:space': 'preserve'}" id="_04008" smilref="Title.smil#_04008"> 0 4</p><p attribs="{'xml:space': 'preserve'}" id="_04009" smilref="Title.smil#_04009"> Weighted quick-union traces (forests of trees)</p><p attribs="{'xml:space': 'preserve'}" id="_04010" smilref="Title.smil#_04010"> Proposition H. The depth of any node in a forest built by weighted quick-union for N sites is at most lg N.</p><p attribs="{'xml:space': 'preserve'}" id="_04011" smilref="Title.smil#_04011"> Proof : We prove a stronger fact by (strong) induction: The height of every tree of size k in the forest is at most lg k. The base case follows from the fact that the tree height is 0 when k is 1. By the inductive hypothesis, assume that the tree height of a tree of size i is at most lg i for all i &lt; k. When we combine a tree of size i with a tree of size j with i &#11349; j and i &#11001; j = k, we increase the depth of each node in the smaller set by 1, but they are now in a tree of size i &#11001; j = k, so the property is preserved because 1+ lg i = lg(i &#11001; i ) &#11349; lg(i &#11001; j ) = lg k.</p><p attribs="{'xml:space': 'preserve'}" id="_04012" smilref="Title.smil#_04012" /><pagenum id="p243" page="normal" smilref="Title.smil#p243" /><p attribs="{'xml:space': 'preserve'}" id="_04013" smilref="Title.smil#_04013"> 230</p><p attribs="{'xml:space': 'preserve'}" id="_04014" smilref="Title.smil#_04014"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04015" smilref="Title.smil#_04015"> quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_04016" smilref="Title.smil#_04016"> weighted</p><p attribs="{'xml:space': 'preserve'}" id="_04017" smilref="Title.smil#_04017"> average depth: 5.11</p><p attribs="{'xml:space': 'preserve'}" id="_04018" smilref="Title.smil#_04018"> average depth: 1.52</p><p attribs="{'xml:space': 'preserve'}" id="_04019" smilref="Title.smil#_04019"> Quick-union and weighted quick-union (100 sites, 88 union() operations)</p><p attribs="{'xml:space': 'preserve'}" id="_04020" smilref="Title.smil#_04020"> Corollary. For weighted quick-union with N sites, the worst-case order of growth of the cost of find(), connected(), and union() is log N.</p><p attribs="{'xml:space': 'preserve'}" id="_04021" smilref="Title.smil#_04021"> Proof. Each operation does at most a constant number of array accesses for each node on the path from a node to a root in the forest.</p><p attribs="{'xml:space': 'preserve'}" id="_04022" smilref="Title.smil#_04022"> For dynamic connectivity, the practical implication of Proposition H and its corollary is that weighted quick-union is the only one of the three algorithms that can feasibly be used for huge practical problems. The weighted quick-union algorithm uses at most c M lg N array accesses to process M connections among N sites for a small constant c. This result is in stark contrast to our finding that quick-&#64257; nd always (and quick-union sometimes) uses at least MN array accesses. Thus, with weighted quick-union, we can guarantee that we can solve huge practical dynamic connectivity problems in a reasonable amount of time. For the price of a few extra lines of code, we get a program that can be millions of times faster than the simpler algorithms for the huge dynamic connectivity problems that we might encounter in practical applications. A 100-site example is shown on the top of this page. It is evident from this diagram that relatively few nodes fall far from the root with weighted quick-union. Indeed it is frequently the case that a 1-node tree is merged with a larger tree, which puts the node just one link from the root. Empirical studies on huge problems tell us that weighted quick-union typically solves practical problems in constant time per operation. We could hardly expect to find a more efficient algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_04023" smilref="Title.smil#_04023" /><pagenum id="p244" page="normal" smilref="Title.smil#p244" /><p attribs="{'xml:space': 'preserve'}" id="_04024" smilref="Title.smil#_04024"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_04025" smilref="Title.smil#_04025"> 231</p><p attribs="{'xml:space': 'preserve'}" id="_04026" smilref="Title.smil#_04026"> order of growth for N sites (worst case)</p><p attribs="{'xml:space': 'preserve'}" id="_04027" smilref="Title.smil#_04027"> constructor</p><p attribs="{'xml:space': 'preserve'}" id="_04028" smilref="Title.smil#_04028"> union</p><p attribs="{'xml:space': 'preserve'}" id="_04029" smilref="Title.smil#_04029"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04030" smilref="Title.smil#_04030"> find</p><p attribs="{'xml:space': 'preserve'}" id="_04031" smilref="Title.smil#_04031"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04032" smilref="Title.smil#_04032"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_04033" smilref="Title.smil#_04033"> quick-fi nd</p><p attribs="{'xml:space': 'preserve'}" id="_04034" smilref="Title.smil#_04034"> quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_04035" smilref="Title.smil#_04035"> weighted quick-union weighted quick-union with path compresson impossible</p><p attribs="{'xml:space': 'preserve'}" id="_04036" smilref="Title.smil#_04036"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04037" smilref="Title.smil#_04037"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04038" smilref="Title.smil#_04038"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04039" smilref="Title.smil#_04039"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04040" smilref="Title.smil#_04040"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04041" smilref="Title.smil#_04041"> tree height</p><p attribs="{'xml:space': 'preserve'}" id="_04042" smilref="Title.smil#_04042"> tree height</p><p attribs="{'xml:space': 'preserve'}" id="_04043" smilref="Title.smil#_04043"> lg N lg N very, very nearly, but not quite 1 (amortized ) (see Exercise 1.5.13) 1</p><p attribs="{'xml:space': 'preserve'}" id="_04044" smilref="Title.smil#_04044"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04045" smilref="Title.smil#_04045"> Performance characteristics of union-f ind algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_04046" smilref="Title.smil#_04046"> Optimal algorithms. Can we find an algorithm that has guaranteed constant-time- per-operation performance? This question is an extremely difficult one that plagued researchers for many years. In pursuit of an answer, a number of variations of quick- union and weighted quick-union have been studied. For example, the following meth- od, known as path compression, is easy to implement. Ideally, we would like every node to link directly to the root of its tree, but we do not want to pay the price of changing a large number of links, as we did in the quick-&#64257; nd algorithm. We can approach the ideal simply by making all the nodes that we do examine directly link to the root. This step seems drastic at first blush, but it is easy to implement, and there is nothing sacrosanct about the structure of these trees: if we can modify them to make the algorithm more ef&#64257; cient, we should do so. To implement path compression, we just add another loop to find() that sets the id[] entry corresponding to each node encountered along the way to link directly to the root. The net result is to flatten the trees almost completely, approximating the ideal achieved by the quick-&#64257; nd algorithm. The method is simple and effective, but you are not likely to be able to discern any improvement over weighted quick-union in a practical situation (see Exercise 1.5.24). Theoretical results about the situation are extremely complicated and quite remarkable. Weighted quick union with path compression is optimal but not quite constant-time per operation. That is, not only is weighted quick-union with path compression not constant-time per operation in the worst case ( amortized), but also there exists no algorithm that can guarantee to perform each union-&#64257; nd operation in amortized constant time (under the very general &#8220;cell probe&#8221; model of computation). Weighted quick-union with path compression is very close to the best that we can do for this problem.</p><p attribs="{'xml:space': 'preserve'}" id="_04047" smilref="Title.smil#_04047" /><pagenum id="p245" page="normal" smilref="Title.smil#p245" /><p attribs="{'xml:space': 'preserve'}" id="_04048" smilref="Title.smil#_04048"> 232</p><p attribs="{'xml:space': 'preserve'}" id="_04049" smilref="Title.smil#_04049"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04050" smilref="Title.smil#_04050"> union() operations use at least 625 references</p><p attribs="{'xml:space': 'preserve'}" id="_04051" smilref="Title.smil#_04051"> quick-find</p><p attribs="{'xml:space': 'preserve'}" id="_04052" smilref="Title.smil#_04052"> 1300</p><p attribs="{'xml:space': 'preserve'}" id="_04053" smilref="Title.smil#_04053"> s</p><p attribs="{'xml:space': 'preserve'}" id="_04054" smilref="Title.smil#_04054"> e c</p><p attribs="{'xml:space': 'preserve'}" id="_04055" smilref="Title.smil#_04055"> n e</p><p attribs="{'xml:space': 'preserve'}" id="_04056" smilref="Title.smil#_04056"> r</p><p attribs="{'xml:space': 'preserve'}" id="_04057" smilref="Title.smil#_04057"> e</p><p attribs="{'xml:space': 'preserve'}" id="_04058" smilref="Title.smil#_04058"> f</p><p attribs="{'xml:space': 'preserve'}" id="_04059" smilref="Title.smil#_04059"> e</p><p attribs="{'xml:space': 'preserve'}" id="_04060" smilref="Title.smil#_04060"> r</p><p attribs="{'xml:space': 'preserve'}" id="_04061" smilref="Title.smil#_04061"> y a</p><p attribs="{'xml:space': 'preserve'}" id="_04062" smilref="Title.smil#_04062"> r r</p><p attribs="{'xml:space': 'preserve'}" id="_04063" smilref="Title.smil#_04063"> a</p><p attribs="{'xml:space': 'preserve'}" id="_04064" smilref="Title.smil#_04064"> f</p><p attribs="{'xml:space': 'preserve'}" id="_04065" smilref="Title.smil#_04065"> o</p><p attribs="{'xml:space': 'preserve'}" id="_04066" smilref="Title.smil#_04066"> r</p><p attribs="{'xml:space': 'preserve'}" id="_04067" smilref="Title.smil#_04067"> e b</p><p attribs="{'xml:space': 'preserve'}" id="_04068" smilref="Title.smil#_04068"> m</p><p attribs="{'xml:space': 'preserve'}" id="_04069" smilref="Title.smil#_04069"> u n</p><p attribs="{'xml:space': 'preserve'}" id="_04070" smilref="Title.smil#_04070"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_04071" smilref="Title.smil#_04071"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_04072" smilref="Title.smil#_04072"> quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_04073" smilref="Title.smil#_04073"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_04074" smilref="Title.smil#_04074"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_04075" smilref="Title.smil#_04075"> weighted quick-union</p><p attribs="{'xml:space': 'preserve'}" id="_04076" smilref="Title.smil#_04076"> 20 0</p><p attribs="{'xml:space': 'preserve'}" id="_04077" smilref="Title.smil#_04077"> red dots give cumulative average</p><p attribs="{'xml:space': 'preserve'}" id="_04078" smilref="Title.smil#_04078"> one gray dot for each connection processed by client</p><p attribs="{'xml:space': 'preserve'}" id="_04079" smilref="Title.smil#_04079"> Amortized cost plots. As with any data type implementation, it is worthwhile to run experiments to test the validity of our performance hypotheses for typical clients, as discussion in Section 1.4. The figure at left shows details of the performance of the algorithms for our dynamic connectivity development client when solving our 625-site connectivity example (mediumUF.txt). Such diagrams are easy to produce (see Exercise 1.5.16): For the i th connection processed, we maintain a variable cost that counts the number of array accesses (to id[] or sz[]) and a variable total that is the sum of the total number of array accesses so far. Then we plot a gray dot at (i, cost) and a red dot at (i, total/i). The red dots are the average cost per operation, or amortized cost. These plots provide good insights into algorithm be- havior. For quick-&#64257; nd, every union() operation uses at least 625 accesses (plus 1 for each component merged, up to another 625) and every connected() operation uses 2 accesses. Initially, most of the connections lead to a call on union(), so the cumulative average hovers around 625; later, most connections are calls to connected() that cause the call to union() to be skipped, so the cumulative average decreas- es, but still remains relatively high. (Inputs that lead to a large number of connected() calls that cause union() to be skipped will exhibit signi&#64257; - cantly better performance&#8212;see Exercise 1.5.23 for an example). For quick-union, all operations initially require only a few array accesses; eventu- ally, the height of the trees becomes a significant factor and the amortized cost grows noticably. For weighted quick-union, the tree height stays small, none of the operations are expensive, and the amortized cost is low. These experiments validate our conclusion that weighted quick-union is certainly worth implementing and that there is not much further room for improvement for practical problems.</p><p attribs="{'xml:space': 'preserve'}" id="_04080" smilref="Title.smil#_04080"> connected() operations use exactly 2 array accesses</p><p attribs="{'xml:space': 'preserve'}" id="_04081" smilref="Title.smil#_04081"> Cost of all operations (625 sites)</p><p attribs="{'xml:space': 'preserve'}" id="_04082" smilref="Title.smil#_04082"> find() operations become expensive</p><p attribs="{'xml:space': 'preserve'}" id="_04083" smilref="Title.smil#_04083"> number of connections</p><p attribs="{'xml:space': 'preserve'}" id="_04084" smilref="Title.smil#_04084"> 900</p><p attribs="{'xml:space': 'preserve'}" id="_04085" smilref="Title.smil#_04085"> no expensive operations</p><p attribs="{'xml:space': 'preserve'}" id="_04086" smilref="Title.smil#_04086"> 458</p><p attribs="{'xml:space': 'preserve'}" id="_04087" smilref="Title.smil#_04087"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_04088" smilref="Title.smil#_04088"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_04089" smilref="Title.smil#_04089" /><pagenum id="p246" page="normal" smilref="Title.smil#p246" /><p attribs="{'xml:space': 'preserve'}" id="_04090" smilref="Title.smil#_04090"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_04091" smilref="Title.smil#_04091"> 233</p><p attribs="{'xml:space': 'preserve'}" id="_04092" smilref="Title.smil#_04092"> Perspective Each of the UF implementations that we considered is an improvement over the previous in some intuitive sense, but the process is artificially smooth because we have the benefit of hindsight in looking over the development of the algorithms as they were studied by researchers over the years. The implementations are simple and the problem is well speci&#64257; ed, so we can evaluate the various algorithms directly by running empirical studies. Furthermore, we can use these studies to validate mathematical results that quantify the performance of these algorithms. When possible, we follow the same basic steps for fundamental problems throughout the book that we have taken for union&#8211;&#64257; nd algorithms in this section, some of which are highlighted in this list: </p><p attribs="{'xml:space': 'preserve'}" id="_04093" smilref="Title.smil#_04093" /><pagenum id="p247" page="normal" smilref="Title.smil#p247" /><p attribs="{'xml:space': 'preserve'}" id="_04094" smilref="Title.smil#_04094"> 234</p><p attribs="{'xml:space': 'preserve'}" id="_04095" smilref="Title.smil#_04095"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04096" smilref="Title.smil#_04096"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_04097" smilref="Title.smil#_04097"> Q. I&#8217;d like to add a delete() method to the API that allows clients to delete connec- tions. Any advice on how to proceed? A. No one has devised an algorithm as simple and efficient as the ones in this section that can handle deletions. This theme recurs throughout this book. Several of the data structures that we consider have the property that deleting something is much more difficult than adding something. Q. What is the cell-probe model? A. A model of computation where we only count accesses to a random-access memory large enough to hold the input and consider all other operations to be free.</p><p attribs="{'xml:space': 'preserve'}" id="_04098" smilref="Title.smil#_04098" /><pagenum id="p248" page="normal" smilref="Title.smil#p248" /><p attribs="{'xml:space': 'preserve'}" id="_04099" smilref="Title.smil#_04099"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_04100" smilref="Title.smil#_04100"> 235</p><p attribs="{'xml:space': 'preserve'}" id="_04101" smilref="Title.smil#_04101"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_04102" smilref="Title.smil#_04102"> 1.5.1 Show the contents of the id[] array and the number of times the array is accessed for each input pair when you use quick-&#64257; nd for the sequence</p><p attribs="{'xml:space': 'preserve'}" id="_04103" smilref="Title.smil#_04103"> 9-0 3-4 5-8 7-2 2-1 5-7 0-3 4-2.</p><p attribs="{'xml:space': 'preserve'}" id="_04104" smilref="Title.smil#_04104"> 1.5.2 Do Exercise 1.5.1, but use quick-union (page 224). In addition, draw the forest of trees represented by the id[] array after each input pair is processed. 1.5.3 Do Exercise 1.5.1, but use weighted quick-union (page 228). 1.5.4 Show the contents of the sz[] and id[] arrays and the number of array accesses for each input pair corresponding to the weighted quick-union examples in the text (both the reference input and the worst-case input). 1.5.5 Estimate the minimum amount of time (in days) that would be required for quick-&#64257; nd to solve a dynamic connectivity problem with 109 sites and 106 input pairs, on a computer capable of executing 109 instructions per second. Assume that each iteration of the inner for loop requires 10 machine instructions. 1.5.6 Repeat Exercise 1.5.5 for weighted quick-union. 1.5.7 Develop classes QuickUnionUF and QuickFindUF that implement quick-union and quick-&#64257; nd, respectively. 1.5.8 Give a counterexample that shows why this intuitive implementation of union() for quick-&#64257; nd is not correct:</p><p attribs="{'xml:space': 'preserve'}" id="_04105" smilref="Title.smil#_04105"> public void union(int p, int q) { if (connected(p, q)) return;</p><p attribs="{'xml:space': 'preserve'}" id="_04106" smilref="Title.smil#_04106"> // Rename p&#8217;s component to q&#8217;s name. for (int i = 0; i &lt; id.length; i++) if (id[i] == id[p]) id[i] = id[q]; count--; }</p><p attribs="{'xml:space': 'preserve'}" id="_04107" smilref="Title.smil#_04107"> 1.5.9 Draw the tree corresponding to the id[] array depicted at right. Can this be the result of running weighted quick-union? Explain why this is impossible or give a sequence of operations that results in this array.</p><p attribs="{'xml:space': 'preserve'}" id="_04108" smilref="Title.smil#_04108"> i 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_04109" smilref="Title.smil#_04109"> id[i] 1 1 3 1 5 6 1 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_04110" smilref="Title.smil#_04110" /><pagenum id="p249" page="normal" smilref="Title.smil#p249" /><p attribs="{'xml:space': 'preserve'}" id="_04111" smilref="Title.smil#_04111"> 236</p><p attribs="{'xml:space': 'preserve'}" id="_04112" smilref="Title.smil#_04112"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04113" smilref="Title.smil#_04113"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04114" smilref="Title.smil#_04114"> 1.5.10 In the weighted quick-union algorithm, suppose that we set id[find(p)] to q instead of to id[find(q)]. Would the resulting algorithm be correct?</p><p attribs="{'xml:space': 'preserve'}" id="_04115" smilref="Title.smil#_04115"> Answer : Yes, but it would increase the tree height, so the performance guarantee would be invalid.</p><p attribs="{'xml:space': 'preserve'}" id="_04116" smilref="Title.smil#_04116"> 1.5.11 Implement weighted quick-&#64257; nd, where you always change the id[] entries of the smaller component to the identifier of the larger component. How does this change affect performance?</p><p attribs="{'xml:space': 'preserve'}" id="_04117" smilref="Title.smil#_04117" /><pagenum id="p250" page="normal" smilref="Title.smil#p250" /><p attribs="{'xml:space': 'preserve'}" id="_04118" smilref="Title.smil#_04118"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_04119" smilref="Title.smil#_04119"> 237</p><p attribs="{'xml:space': 'preserve'}" id="_04120" smilref="Title.smil#_04120"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_04121" smilref="Title.smil#_04121"> 1.5.12 Quick-union with path compression. Modify quick-union (page 224) to include path compression, by adding a loop to union() that links every site on the paths from p and q to the roots of their trees to the root of the new tree. Give a sequence of input pairs that causes this method to produce a path of length 4. Note : The amortized cost per operation for this algorithm is known to be logarithmic. 1.5.13 Weighted quick-union with path compression. Modify weighted quick-union (Algorithm 1.5) to implement path compression, as described in Exercise 1.5.12. Give a sequence of input pairs that causes this method to produce a tree of height 4. Note : The amortized cost per operation for this algorithm is known to be bounded by a function known as the inverse Ackermann function and is less than 5 for any conceivable practical value of N. 1.5.14 Weighted quick-union by height. Develop a UF implementation that uses the same basic strategy as weighted quick-union but keeps track of tree height and always links the shorter tree to the taller one. Prove a logarithmic upper bound on the height of the trees for N sites with your algorithm. 1.5.15 Binomial trees. Show that the number of nodes at each level in the worst-case trees for weighted quick-union are binomial coef&#64257; cients. Compute the average depth of a node in a worst-case tree with N = 2n nodes. 1.5.16 Amortized costs plots. Instrument your implementations from Exercise 1.5.7 to make amortized costs plots like those in the text. 1.5.17 Random connections. Develop a UF client ErdosRenyi that takes an integer value N from the command line, generates random pairs of integers between 0 and N-1, calling connected() to determine if they are connected and then union() if not (as in our development client), looping until all sites are connected, and printing the number of connections generated. Package your program as a static method count() that takes N as argument and returns the number of connections and a main() that takes N from the command line, calls count(), and prints the returned value. 1.5.18 Random grid generator. Write a program RandomGrid that takes an int value N from the command line, generates all the connections in an N-by-N grid, puts them in random order, randomly orients them (so that p q and q p are equally likely to oc- cur), and prints the result to standard output. To randomly order the connections, use a RandomBag (see Exercise 1.3.34 on page 167). To encapsulate p and q in a single object,</p><p attribs="{'xml:space': 'preserve'}" id="_04122" smilref="Title.smil#_04122" /><pagenum id="p251" page="normal" smilref="Title.smil#p251" /><p attribs="{'xml:space': 'preserve'}" id="_04123" smilref="Title.smil#_04123"> 238</p><p attribs="{'xml:space': 'preserve'}" id="_04124" smilref="Title.smil#_04124"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04125" smilref="Title.smil#_04125"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04126" smilref="Title.smil#_04126"> use the Connection nested class shown below. Package your program as two static methods: generate(), which takes N as argument and returns an array of connec- tions, and main(), which takes N from the command line, calls generate(), and iterates through the returned array to print the connections. 1.5.19 Animation. Write a RandomGrid client (see Exercise 1.5.18) that uses UnionFind as in our development client to check connectivity and uses StdDraw to draw the connections as they are processed. 1.5.20 Dynamic growth. Using linked lists or a resizing array, develop a weighted quick-union implementation that removes the restriction on needing the number of objects ahead of time. Add a method newSite() to the API, which returns an int identi&#64257; er.</p><p attribs="{'xml:space': 'preserve'}" id="_04127" smilref="Title.smil#_04127"> private class Connection { int p; int q;</p><p attribs="{'xml:space': 'preserve'}" id="_04128" smilref="Title.smil#_04128"> public Connection(int p, int q) { this.p = p; this.q = q; } }</p><p attribs="{'xml:space': 'preserve'}" id="_04129" smilref="Title.smil#_04129"> Record to encapsulate connections</p><p attribs="{'xml:space': 'preserve'}" id="_04130" smilref="Title.smil#_04130" /><pagenum id="p252" page="normal" smilref="Title.smil#p252" /><p attribs="{'xml:space': 'preserve'}" id="_04131" smilref="Title.smil#_04131"> 1.5 </p><p attribs="{'xml:space': 'preserve'}" id="_04132" smilref="Title.smil#_04132"> 239</p><p attribs="{'xml:space': 'preserve'}" id="_04133" smilref="Title.smil#_04133"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_04134" smilref="Title.smil#_04134"> 1.5.21 Erd&#246;s-Renyi model. Use your client from Exercise 1.5.17 to test the hypothesis that the number of pairs generated to get one component is ~ &#189;N ln N. 1.5.22 Doubling test for Erd&#246;s-Renyi model. Develop a performance-testing client that takes an int value T from the command line and performs T trials of the following ex- periment: Use your client from Exercise 1.5.17 to generate random connections, using UnionFind to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N, the average number of connections processed, and the ratio of the running time to the previous. Use your program to validate the hypotheses in the text that the running times for quick-&#64257; nd and quick-union are quadratic and weighted quick-union is near-linear. 1.5.23 Compare quick-&#64257; nd with quick-union for Erd&#246;s-Renyi model. Develop a perfor- mance-testing client that takes an int value T from the command line and performs T trials of the following experiment: Use your client from Exercise 1.5.17 to generate random connections. Save the connections, so that you can use both quick-union and quick-&#64257; nd to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N and the ratio of the two running times. 1.5.24 Fast algorithms for Erd&#246;s-Renyi model. Add weighted quick-union and weighted quick-union with path compression to your tests from Exercise 1.5.23 . Can you discern a difference between these two algorithms? 1.5.25 Doubling test for random grids. Develop a performance-testing client that takes an int value T from the command line and performs T trials of the following experie- ment: Use your client from Exercise 1.5.18 to generate the connections in an N-by-N square grid, randomly oriented and in random order, then use UnionFind to determine connectivity as in our development client, looping until all sites are connected. For each N, print the value of N, the average number of connections processed, and the ratio of the running time to the previous. Use your program to validate the hypotheses in the text that the running times for quick-&#64257; nd and quick-union are quadratic and weighted quick-union is near-linear. Note : As N doubles, the number of sites in the grid increases by a factor of 4, so expect a doubling factor of 16 for quadratic and 4 for linear.</p><p attribs="{'xml:space': 'preserve'}" id="_04135" smilref="Title.smil#_04135" /><pagenum id="p253" page="normal" smilref="Title.smil#p253" /><p attribs="{'xml:space': 'preserve'}" id="_04136" smilref="Title.smil#_04136"> 240</p><p attribs="{'xml:space': 'preserve'}" id="_04137" smilref="Title.smil#_04137"> CHAPTER 1 </p><p attribs="{'xml:space': 'preserve'}" id="_04138" smilref="Title.smil#_04138"> EXPERIMENTS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04139" smilref="Title.smil#_04139"> 1.5.26 Amortized plot for Erd&#246;s-Renyi. Develop a client that takes an int value N from the command line and does an amortized plot of the cost of all operations in the style of the plots in the text for the process of generating random pairs of integers between 0 and N-1, calling connected() to determine if they are connected and then union() if not (as in our development client), looping until all sites are connected.</p><p attribs="{'xml:space': 'preserve'}" id="_04140" smilref="Title.smil#_04140" /><pagenum id="p254" page="normal" smilref="Title.smil#p254" /><p attribs="{'xml:space': 'preserve'}" id="_04141" smilref="Title.smil#_04141"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_04142" smilref="Title.smil#_04142" /></level3></level1><level1 id="ch2"><section epub:type="chapter" id="section_00001"><header id="header_00001"><pagenum epub:type="pagebreak" id="p255" page="normal" smilref="Title.smil#p255" /><h1 id="ch2-start" smilref="Title.smil#ch2-start" xml:space="preserve">2 Sorting</h1></header></section><pagenum id="p255" page="normal" smilref="Title.smil#p255" /><p attribs="{'xml:space': 'preserve'}" id="_04143" smilref="Title.smil#_04143"> T WO</p><p attribs="{'xml:space': 'preserve'}" id="_04144" smilref="Title.smil#_04144"> Sorting</p><p attribs="{'xml:space': 'preserve'}" id="_04145" smilref="Title.smil#_04145"> 2.1 Elementary Sorts . . . . . . . . . . . . . 244 2.2 Mergesort . . . . . . . . . . . . . . . . . 270 2.3 Quicksort . . . . . . . . . . . . . . . . . 288 2.4 Priority Queues . . . . . . . . . . . . . . 308 2.5 Applications . . . . . . . . . . . . . . . . 336</p><p attribs="{'xml:space': 'preserve'}" id="_04146" smilref="Title.smil#_04146" /><pagenum id="p256" page="normal" smilref="Title.smil#p256" /><p attribs="{'xml:space': 'preserve'}" id="_04147" smilref="Title.smil#_04147"> Sorting is the process of rearranging a sequence of objects so as to put them in some logical order. For example, your credit card bill presents transactions in order by date&#8212;they were likely put into that order by a sorting algorithm. In the early days of computing, the common wisdom was that up to 30 percent of all computing cycles was spent sorting. If that fraction is lower today, one likely reason is that sorting algorithms are relatively ef&#64257; cient, not that sorting has diminished in relative importance. Indeed, the ubiquity of computer usage has put us awash in data, and the first step to organizing data is often to sort it. All computer systems have implementations of sorting algorithms, for use by the system and by users. There are three practical reasons for you to study sorting algorithms, even though you might just use a system sort: </p><p attribs="{'xml:space': 'preserve'}" id="_04148" smilref="Title.smil#_04148"> 243</p><p attribs="{'xml:space': 'preserve'}" id="_04149" smilref="Title.smil#_04149" /><level3 id="_00029"><h3 id="ch2-s1-ss1" smilref="Title.smil#ch2-s1-ss1" xml:space="preserve">Rules of the game</h3><p attribs="{'xml:space': 'preserve'}" id="_04150" smilref="Title.smil#_04150"> 2.1</p><p attribs="{'xml:space': 'preserve'}" id="_04151" smilref="Title.smil#_04151"> ELEMENTARY SORTS</p><p attribs="{'xml:space': 'preserve'}" id="_04152" smilref="Title.smil#_04152"> For our first excursion into the area of sorting algorithms, we shall study two elementary sorting methods and a variation of one of them. Among the reasons for studying these relatively simple algorithms in detail are the following: First, they provide context in which we can learn terminology and basic mechanisms. Second, these simple algorithms are more effective in some applications than the sophisticated algorithms that we shall discuss later. Third, they are useful in improving the efficiency of more sophisticated algorithms, as we will see.</p><p attribs="{'xml:space': 'preserve'}" id="_04153" smilref="Title.smil#_04153"> Rules of the game Our primary concern is algorithms for rearranging arrays of items where each item contains a key. The objective of the sorting algorithm is to rearrange the items such that their keys are ordered according to some well-de&#64257; ned ordering rule (usually numerical or alphabetical order). We want to rearrange the array so that each entry&#8217;s key is no smaller than the key in each entry with a lower index and no larger than the key in each entry with a larger index. Speci&#64257; c characteristics of the keys and the items can vary widely across applications. In Java, items are just objects, and the abstract notion of a key is captured in a built-in mechanism&#8212;the Comparable interface&#8212;that is described on page 247. The class Example on the facing page illustrates the conventions that we shall use: we put our sort code in a sort() method within a single class along with private helper functions less() and exch() (and perhaps some others) and a sample client main(). Example also illustrates code that might be useful for initial debugging: its test client main() sorts strings from standard input using the private method show() to print the contents of the array. Later in this chapter, we will examine various test clients for comparing algorithms and for studying their performance. To differentiate sorting meth- ods, we give our various sort classes different names. Clients can call different implementations by name: Insertion.sort(), Merge.sort(), Quick.sort(), and so forth. With but a few exceptions, our sort code refers to the data only through two opera- tions: the method less() that compares items and the method exch() that exchanges them. The exch() method is easy to implement, and the Comparable interface makes it easy to implement less(). Restricting data access to these two operations makes our code readable and portable, and makes it easier for us certify that algorithms are cor- rect, to study performance and to compare algorithms. Before proceeding to consider sort implementations, we discuss a number of important issues that need to be carefully considered for every sort.</p><p attribs="{'xml:space': 'preserve'}" id="_04154" smilref="Title.smil#_04154"> 244</p><p attribs="{'xml:space': 'preserve'}" id="_04155" smilref="Title.smil#_04155" /><p attribs="{'xml:space': 'preserve'}" id="_04156" smilref="Title.smil#_04156"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04157" smilref="Title.smil#_04157"> 245</p><p attribs="{'xml:space': 'preserve'}" id="_04158" smilref="Title.smil#_04158"> Template for sort classes</p><p attribs="{'xml:space': 'preserve'}" id="_04159" smilref="Title.smil#_04159"> public class Example { public static void sort(Comparable[] a) { /* See Algorithms 2.1, 2.2, 2.3, 2.4, 2.5, or 2.7. */ }</p><p attribs="{'xml:space': 'preserve'}" id="_04160" smilref="Title.smil#_04160"> private static boolean less(Comparable v, Comparable w) { return v.compareTo(w) &lt; 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_04161" smilref="Title.smil#_04161"> private static void exch(Comparable[] a, int i, int j) { Comparable t = a[i]; a[i] = a[j]; a[j] = t; }</p><p attribs="{'xml:space': 'preserve'}" id="_04162" smilref="Title.smil#_04162"> private static void show(Comparable[] a) { // Print the array, on a single line. for (int i = 0; i &lt; a.length; i++) StdOut.print(a[i] + " "); StdOut.println(); }</p><p attribs="{'xml:space': 'preserve'}" id="_04163" smilref="Title.smil#_04163"> public static boolean isSorted(Comparable[] a) { // Test whether the array entries are in order. for (int i = 1; i &lt; a.length; i++) if (less(a[i], a[i-1])) return false; return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_04164" smilref="Title.smil#_04164"> public static void main(String[] args) { // Read strings from standard input, sort them, and print. String[] a = In.readStrings(); sort(a); assert isSorted(a); show(a); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04165" smilref="Title.smil#_04165"> % more tiny.txt S O R T E X A M P L E</p><p attribs="{'xml:space': 'preserve'}" id="_04166" smilref="Title.smil#_04166"> This class illustrates our conventions for implementing array sorts. For each sorting algorithm that we consider, we present a sort() method for a class like this with Example changed to a name that corresponds to the algorithm. The test client sorts strings taken from standard input, but, with this code, our sort methods are effective for any type of data that implements Comparable.</p><p attribs="{'xml:space': 'preserve'}" id="_04167" smilref="Title.smil#_04167"> % java Example &lt; tiny.txt A E E L M O P R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04168" smilref="Title.smil#_04168"> % more words3.txt bed bug dad yes zoo ... all bad yet</p><p attribs="{'xml:space': 'preserve'}" id="_04169" smilref="Title.smil#_04169"> % java Example &lt; words3.txt all bad bed bug dad ... yes yet zoo</p><p attribs="{'xml:space': 'preserve'}" id="_04170" smilref="Title.smil#_04170" /><p attribs="{'xml:space': 'preserve'}" id="_04171" smilref="Title.smil#_04171"> 246</p><p attribs="{'xml:space': 'preserve'}" id="_04172" smilref="Title.smil#_04172"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04173" smilref="Title.smil#_04173"> Certi&#64257; cation. Does the sort implementation always put the array in order, no matter what the initial order? As a conservative practice, we include the statement assert isSorted(a); in our test client to certify that array entries are in order after the sort. It is reasonable to include this statement in every sort implementation, even though we normally test our code and develop mathematical arguments that our algorithms are correct. Note that this test is sufficient only if we use exch() exclusively to change array entries. When we use code that stores values into the array directly, we do not have full assurance (for example, code that destroys the original input array by setting all values to be the same would pass this test).</p><p attribs="{'xml:space': 'preserve'}" id="_04174" smilref="Title.smil#_04174"> Sorting cost model.</p><p attribs="{'xml:space': 'preserve'}" id="_04175" smilref="Title.smil#_04175"> When studying sorting algorithms, we count compares and exchanges. For algorithms that do not use exchanges, we count array accesses.</p><p attribs="{'xml:space': 'preserve'}" id="_04176" smilref="Title.smil#_04176"> Running time. We also test algorithm performance. We start by proving facts about the number of basic operations (compares and exchanges, or perhaps the number of times the array is ac- cessed, for read or write) that the various sorting algorithms perform for various natural input models. Then we use these facts to develop hypotheses about the comparative performance of the algorithms and present tools that you can use to experimentally check the validity of such hypotheses. We use a consistent coding style to facilitate the development of valid hypotheses about performance that will hold true for typical implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_04177" smilref="Title.smil#_04177"> Extra memory. The amount of extra memory used by a sorting algorithm is often as important a factor as running time. The sorting algorithms divide into two basic types: those that sort in place and use no extra memory except perhaps for a small function- call stack or a constant number of instance variables, and those that need enough extra memory to hold another copy of the array to be sorted.</p><p attribs="{'xml:space': 'preserve'}" id="_04178" smilref="Title.smil#_04178"> Types of data. Our sort code is effective for any item type that implements the Comparable interface. Adhering to Java&#8217;s convention in this way is convenient because many of the types of data that you might want to sort implement Comparable. For example, Java&#8217;s numeric wrapper types such as Integer and Double implement Comparable, as do String and various advanced types such as File or URL. Thus, you can just call one of our sort methods with an array of any of these types as argu- ment. For example, the code at right uses quicksort (see Section 2.3) to sort N random Double values. When we create types of our own, we can enable client code to sort that type of data by implementing the Comparable in- terface. To do so, we just need to implement a compareTo() method that defines an ordering on objects of that type known as the natural</p><p attribs="{'xml:space': 'preserve'}" id="_04179" smilref="Title.smil#_04179"> Double a[] = new Double[N]; for (int i = 0; i &lt; N; i++) a[i] = StdRandom.uniform(); Quick.sort(a);</p><p attribs="{'xml:space': 'preserve'}" id="_04180" smilref="Title.smil#_04180"> Sorting an array of random values</p><p attribs="{'xml:space': 'preserve'}" id="_04181" smilref="Title.smil#_04181" /><p attribs="{'xml:space': 'preserve'}" id="_04182" smilref="Title.smil#_04182"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04183" smilref="Title.smil#_04183"> 247</p><p attribs="{'xml:space': 'preserve'}" id="_04184" smilref="Title.smil#_04184"> order for that type, as shown here for our Date data type (see page 91). Java&#8217;s convention is that the call v.compareTo(w) returns an integer that is negative, zero, or positive (usually -1, 0, or +1) when v &lt; w, v = w, or v &gt; w, respectively. For economy, we use standard notation like v&gt;w as shorthand for code like v.compareTo(w)&gt;0 for the remainder of this paragraph. By convention, v.compareTo(w) throws an exception if v and w are incompatible types or either is null. Furthermore, compareTo() must implement a total order: it must be Re&#64258; exive (for all v, v = v) </p><p attribs="{'xml:space': 'preserve'}" id="_04185" smilref="Title.smil#_04185"> public class Date implements Comparable&lt;Date&gt; { private final int day; private final int month; private final int year;</p><p attribs="{'xml:space': 'preserve'}" id="_04186" smilref="Title.smil#_04186"> public int day() { return day; } public int month() { return month; } public int year() { return year; }</p><p attribs="{'xml:space': 'preserve'}" id="_04187" smilref="Title.smil#_04187"> public Date(int d, int m, int y) { day = d; month = m; year = y; }</p><p attribs="{'xml:space': 'preserve'}" id="_04188" smilref="Title.smil#_04188"> public int compareTo(Date that) { if (this.year &gt; that.year ) return +1; if (this.year &lt; that.year ) return -1; if (this.month &gt; that.month) return +1; if (this.month &lt; that.month) return -1; if (this.day &gt; that.day ) return +1; if (this.day &lt; that.day ) return -1; return 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_04189" smilref="Title.smil#_04189"> </p><p attribs="{'xml:space': 'preserve'}" id="_04190" smilref="Title.smil#_04190"> w = v)</p><p attribs="{'xml:space': 'preserve'}" id="_04191" smilref="Title.smil#_04191"> </p><p attribs="{'xml:space': 'preserve'}" id="_04192" smilref="Title.smil#_04192"> v &lt;= w and w &lt;= x then v &lt;=x )</p><p attribs="{'xml:space': 'preserve'}" id="_04193" smilref="Title.smil#_04193"> These rules are intuitive and standard in mathematics&#8212;you will have little difficulty adhering to them. In short, compareTo() implements our key ab- straction&#8212;it defines the ordering of the items (objects) to be sorted, which can be any type of data that implements Comparable. Note that compareTo() need not use all of the instance variables. Indeed, the key might be a small part of each item.</p><p attribs="{'xml:space': 'preserve'}" id="_04194" smilref="Title.smil#_04194"> public String toString() { return month + "/" + day + "/" + year; } }</p><p attribs="{'xml:space': 'preserve'}" id="_04195" smilref="Title.smil#_04195"> Def ining a comparable type</p><p attribs="{'xml:space': 'preserve'}" id="_04196" smilref="Title.smil#_04196"> For the remainder of this chapter, we shall address numerous algorithms for sorting arrays of objects having a natural order. To compare and contrast the algorithms, we shall examine a number of their properties, including the number of compares and exchanges that they use for various types of inputs and the amount of extra memory that they use. These properties lead to the development of hypotheses about performance properties, many of which have been validated on countless computers over the past several decades. Speci&#64257; c implementations always need to be checked, so we also consider tools for doing so. After considering the classic selection sort, insertion sort, shellsort, mergesort, quicksort, and heapsort algorithms, we will consider practical issues and applications, in Section 2.5.</p><p attribs="{'xml:space': 'preserve'}" id="_04197" smilref="Title.smil#_04197" /></level3><level3 id="_00030"><h3 id="ch2-s1-ss2" smilref="Title.smil#ch2-s1-ss2" xml:space="preserve">Selection sort</h3><pagenum id="p261" page="normal" smilref="Title.smil#p261" /><p attribs="{'xml:space': 'preserve'}" id="_04198" smilref="Title.smil#_04198"> 248</p><p attribs="{'xml:space': 'preserve'}" id="_04199" smilref="Title.smil#_04199"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04200" smilref="Title.smil#_04200"> Selection sort One of the simplest sorting algorithms works as follows: First, find the smallest item in the array and exchange it with the first entry (itself if the first entry is already the smallest). Then, find the next smallest item and exchange it with the second entry. Continue in this way until the entire array is sorted. This method is called selection sort because it works by repeatedly selecting the smallest remaining item. As you can see from the implementation in Algorithm 2.1, the inner loop of selection sort is just a compare to test a current item against the smallest item found so far (plus the code necessary to increment the current index and to check that it does not exceed the array bounds); it could hardly be simpler. The work of moving the items around falls outside the inner loop: each exchange puts an item into its final position, so the number of exchanges is N. Thus, the running time is dominated by the number of compares.</p><p attribs="{'xml:space': 'preserve'}" id="_04201" smilref="Title.smil#_04201"> Proposition A. Selection sort uses &#11011;N 2/2 compares and N exchanges to sort an array of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_04202" smilref="Title.smil#_04202"> Proof : You can prove this fact by examining the trace, which is an N-by-N table in which unshaded letters correspond to compares. About one-half of the entries in the table are unshaded&#8212;those on and above the diagonal. The entries on the diagonal each correspond to an exchange. More precisely, examination of the code reveals that, for each i from 0 to N &#11002; 1, there is one exchange and N &#11002; 1 &#11002; i com- pares, so the totals are N exchanges and (N &#11002; 1) + (N &#11002; 2) + . . . + 2 + 1+ 0 = N(N &#11002; 1) / 2 &#11011; N 2 / 2 compares.</p><p attribs="{'xml:space': 'preserve'}" id="_04203" smilref="Title.smil#_04203"> In summary, selection sort is a simple sorting method that is easy to understand and to implement and is characterized by the following two signature properties: Running time is insensitive to input. The process of finding the smallest item on one pass through the array does not give much information about where the smallest item might be on the next pass. This property can be disadvantageous in some situations. For example, the person using the sort client might be surprised to realize that it takes about as long to run selection sort for an array that is already in order or for an array with all keys equal as it does for a randomly-ordered array! As we shall see, other algorithms are better able to take advantage of initial order in the input. Data movement is minimal. Each of the N exchanges changes the value of two array entries, so selection sort uses N exchanges&#8212;the number of array accesses is a linear function of the array size. None of the other sorting algorithms that we consider have this property (most involve linearithmic or quadratic growth).</p><p attribs="{'xml:space': 'preserve'}" id="_04204" smilref="Title.smil#_04204" /><pagenum id="p262" page="normal" smilref="Title.smil#p262" /><p attribs="{'xml:space': 'preserve'}" id="_04205" smilref="Title.smil#_04205"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04206" smilref="Title.smil#_04206"> 249</p><p attribs="{'xml:space': 'preserve'}" id="_04207" smilref="Title.smil#_04207"> ALGORITHM 2.1 Selection sort</p><p attribs="{'xml:space': 'preserve'}" id="_04208" smilref="Title.smil#_04208"> public class Selection { public static void sort(Comparable[] a) { // Sort a[] into increasing order. int N = a.length; // array length for (int i = 0; i &lt; N; i++) { // Exchange a[i] with smallest entry in a[i+1...N). int min = i; // index of minimal entr. for (int j = i+1; j &lt; N; j++) if (less(a[j], a[min])) min = j; exch(a, i, min); } } // See page 245 for less(), exch(), isSorted(), and main(). }</p><p attribs="{'xml:space': 'preserve'}" id="_04209" smilref="Title.smil#_04209"> For each i, this implementation puts the ith smallest item in a[i]. The entries to the left of position i are the i smallest items in the array and are not examined again.</p><p attribs="{'xml:space': 'preserve'}" id="_04210" smilref="Title.smil#_04210"> a[] i min 0 1 2 3 4 5 6 7 8 9 10 S O R T E X A M P L E 0 6 S O R T E X A M P L E 1 4 A O R T E X S M P L E 2 10 A E R T O X S M P L E 3 9 A E E T O X S M P L R 4 7 A E E L O X S M P T R 5 7 A E E L M X S O P T R 6 8 A E E L M O S X P T R 7 10 A E E L M O P X S T R 8 8 A E E L M O P R S T X 9 9 A E E L M O P R S T X 10 10 A E E L M O P R S T X A E E L M O P R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04211" smilref="Title.smil#_04211"> Trace of selection sort (array contents just after each exchange)</p><p attribs="{'xml:space': 'preserve'}" id="_04212" smilref="Title.smil#_04212"> entries in black are examined to find the minimum</p><p attribs="{'xml:space': 'preserve'}" id="_04213" smilref="Title.smil#_04213"> entries in red</p><p attribs="{'xml:space': 'preserve'}" id="_04214" smilref="Title.smil#_04214"> are a[min]</p><p attribs="{'xml:space': 'preserve'}" id="_04215" smilref="Title.smil#_04215"> entries in gray are in final position</p><p attribs="{'xml:space': 'preserve'}" id="_04216" smilref="Title.smil#_04216" /></level3><level3 id="_00031"><h3 id="ch2-s1-ss3" smilref="Title.smil#ch2-s1-ss3" xml:space="preserve">Insertion sort</h3><pagenum id="p263" page="normal" smilref="Title.smil#p263" /><p attribs="{'xml:space': 'preserve'}" id="_04217" smilref="Title.smil#_04217"> 250</p><p attribs="{'xml:space': 'preserve'}" id="_04218" smilref="Title.smil#_04218"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04219" smilref="Title.smil#_04219"> Insertion sort The algorithm that people often use to sort bridge hands is to consider the cards one at a time, inserting each into its proper place among those already considered (keeping them sorted). In a computer implementation, we need to make space to insert the current item by moving larger items one position to the right, before inserting the current item into the vacated position. Algorithm 2.2 is an implementation of this method, which is called insertion sort. As in selection sort, the items to the left of the current index are in sorted order during the sort, but they are not in their final position, as they may have to be moved to make room for smaller items encountered later. The array is, however, fully sorted when the index reaches the right end. Unlike that of selection sort, the running time of insertion sort depends on the initial order of the items in the input. For example, if the array is large and its entries are already in order (or nearly in order), then insertion sort is much, much faster than if the entries are randomly ordered or in reverse order.</p><p attribs="{'xml:space': 'preserve'}" id="_04220" smilref="Title.smil#_04220"> Proposition B. Insertion sort uses &#11011;N 2/4 compares and &#11011;N 2/4 exchanges to sort a randomly ordered array of length N with distinct keys, on the average. The worst case is &#11011;N 2/2 compares and &#11011;N 2/2 exchanges and the best case is N &#11002; 1 compares and 0 exchanges. Proof : Just as for Proposition A, the number of compares and exchanges is easy to visualize in the N-by-N diagram that we use to illustrate the sort. We count entries below the diagonal&#8212;all of them, in the worst case, and none of them, in the best case. For randomly ordered arrays, we expect each item to go about halfway back, on the average, so we count one-half of the entries below the diagonal. The number of compares is the number of exchanges plus an additional term equal to N minus the number of times the item inserted is the smallest so far. In the worst case (array in reverse order), this term is negligible in relation to the total; in the best case (array in order) it is equal to N &#11002; 1.</p><p attribs="{'xml:space': 'preserve'}" id="_04221" smilref="Title.smil#_04221"> Insertion sort works well for certain types of nonrandom arrays that often arise in practice, even if they are huge. For example, as just mentioned, consider what happens when you use insertion sort on an array that is already sorted. Each item is immediately determined to be in its proper place in the array, and the total running time is linear. (The running time of selection sort is quadratic for such an array.) The same is true for arrays whose keys are all equal (hence the condition in Proposition B that the keys must be distinct).</p><p attribs="{'xml:space': 'preserve'}" id="_04222" smilref="Title.smil#_04222" /><pagenum id="p264" page="normal" smilref="Title.smil#p264" /><p attribs="{'xml:space': 'preserve'}" id="_04223" smilref="Title.smil#_04223"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04224" smilref="Title.smil#_04224"> 251</p><p attribs="{'xml:space': 'preserve'}" id="_04225" smilref="Title.smil#_04225"> ALGORITHM 2.2</p><p attribs="{'xml:space': 'preserve'}" id="_04226" smilref="Title.smil#_04226"> Insertion sort</p><p attribs="{'xml:space': 'preserve'}" id="_04227" smilref="Title.smil#_04227"> public class Insertion { public static void sort(Comparable[] a) { // Sort a[] into increasing order. int N = a.length; for (int i = 1; i &lt; N; i++) { // Insert a[i] among a[i-1], a[i-2], a[i-3]... .. for (int j = i; j &gt; 0 &amp;&amp; less(a[j], a[j-1]); j--) exch(a, j, j-1); } } // See page 245 for less(), exch(), isSorted(), and main(). }</p><p attribs="{'xml:space': 'preserve'}" id="_04228" smilref="Title.smil#_04228"> For each i from 0 to N-1, exchange a[i] with the entries that are smaller in a[0] through a[i-1]. As the index i travels from left to right, the entries to its left are in sorted order in the array, so the array is fully sorted when i reaches the right end.</p><p attribs="{'xml:space': 'preserve'}" id="_04229" smilref="Title.smil#_04229"> a[] i j 0 1 2 3 4 5 6 7 8 9 10 S O R T E X A M P L E 1 0 O S R T E X A M P L E 2 1 O R S T E X A M P L E 3 3 O R S T E X A M P L E 4 0 E O R S T X A M P L E 5 5 E O R S T X A M P L E 6 0 A E O R S T X M P L E 7 2 A E M O R S T X P L E 8 4 A E M O P R S T X L E 9 2 A E L M O P R S T X E 10 2 A E E L M O P R S T X A E E L M O P R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04230" smilref="Title.smil#_04230"> Trace of insertion sort (array contents just after each insertion)</p><p attribs="{'xml:space': 'preserve'}" id="_04231" smilref="Title.smil#_04231"> entries in gray do not move</p><p attribs="{'xml:space': 'preserve'}" id="_04232" smilref="Title.smil#_04232"> entry in red</p><p attribs="{'xml:space': 'preserve'}" id="_04233" smilref="Title.smil#_04233"> is a[j]</p><p attribs="{'xml:space': 'preserve'}" id="_04234" smilref="Title.smil#_04234"> entries in black moved one position right for insertion</p><p attribs="{'xml:space': 'preserve'}" id="_04235" smilref="Title.smil#_04235" /><pagenum id="p265" page="normal" smilref="Title.smil#p265" /><p attribs="{'xml:space': 'preserve'}" id="_04236" smilref="Title.smil#_04236"> 252</p><p attribs="{'xml:space': 'preserve'}" id="_04237" smilref="Title.smil#_04237"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04238" smilref="Title.smil#_04238"> More generally, we consider the concept of a partially sorted array, as follows: An inversion is a pair of entries that are out of order in the array. For instance, E X A M P L E has 11 inversions: E-A, X-A, X-M, X-P, X-L, X-E, M-L, M-E, P-L, P-E, and L-E. If the number of inversions in an array is less than a constant multiple of the array size, we say that the array is partially sorted. Typical examples of partially sorted arrays are the following: </p><p attribs="{'xml:space': 'preserve'}" id="_04239" smilref="Title.smil#_04239"> Proposition C. The number of exchanges used by insertion sort is equal to the number of inversions in the array, and the number of compares is at least equal to the number of inversions and at most equal to the number of inversions plus the array size minus 1.</p><p attribs="{'xml:space': 'preserve'}" id="_04240" smilref="Title.smil#_04240"> Proof : Every exchange involves two inverted adjacent entries and thus reduces the number of inversions by one, and the array is sorted when the number of inversions reaches zero. Every exchange corresponds to a compare, and an additional compare might happen for each value of i from 1 to N-1 (when a[i] does not reach the left end of the array).</p><p attribs="{'xml:space': 'preserve'}" id="_04241" smilref="Title.smil#_04241"> It is not difficult to speed up insertion sort substantially, by shortening its inner loop to move the larger entries to the right one position rather than doing full exchanges (thus cutting the number of array accesses in half ). We leave this improvement for an exercise</p><p attribs="{'xml:space': 'preserve'}" id="_04242" smilref="Title.smil#_04242"> (see Exercise 2.1.25).</p><p attribs="{'xml:space': 'preserve'}" id="_04243" smilref="Title.smil#_04243"> In summary, insertion sort is an excellent method for partially sorted arrays and is also a fine method for tiny arrays. These facts are important not just because such arrays frequently arise in practice, but also because both types of arrays arise in intermediate stages of advanced sorting algorithms, so we will be considering insertion sort again in relation to such algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_04244" smilref="Title.smil#_04244" /><pagenum id="p266" page="normal" smilref="Title.smil#p266" /><p attribs="{'xml:space': 'preserve'}" id="_04245" smilref="Title.smil#_04245"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04246" smilref="Title.smil#_04246"> 253</p><p attribs="{'xml:space': 'preserve'}" id="_04247" smilref="Title.smil#_04247"> gray entries are untouched</p><p attribs="{'xml:space': 'preserve'}" id="_04248" smilref="Title.smil#_04248"> Visualizing sorting algorithms Throughout this chapter, we will be using a simple visual representation to help describe the properties of sorting algorithms. Rather than tracing the progress of a sort with key values such as letters, numbers, or words, we use vertical bars, to be sorted by their heights. The advantage of such a representation is that it can give insights into the behavior of a sorting method. For example, you can see at a glance on the visual traces at right that insertion sort does not touch entries to the right of the scan pointer and selection sort does not touch entries to the left of the scan pointer. Moreover, it is clear from the visual traces that, since insertion sort also does not touch entries smaller than the inserted item, it uses about half the number of compares as selection sort, on the average. With our StdDraw library, developing a visual trace is not much more difficult than doing a standard trace. We sort Double values, instrument the algorithm to call show() as appropriate (just as we do for a standard trace), and develop a version of show() that uses StdDraw to draw the bars instead of printing the results. The most complicated task is setting the scale for the y-axis so that the lines of the trace appear in the expected order. You are encouraged to work Exercise 2.1.18 in order to gain a better appreciation of the value of visual traces and the ease of creating them. An even simpler task is to animate the trace so that you can see the array dynamically evolve to the sorted result. Developing an animated trace involves essentially the same process described in the previous paragraph, but without having to worry about the y-axis (just clear the window and redraw the bars each time). Though we cannot make the case on the printed page, such animated representations are also effective in gaining insight into how an algorithm works. You are also encouraged to work Exercise 2.1.17 to see for yourself.</p><p attribs="{'xml:space': 'preserve'}" id="_04249" smilref="Title.smil#_04249"> black entries are involved in compares</p><p attribs="{'xml:space': 'preserve'}" id="_04250" smilref="Title.smil#_04250"> insertion sort</p><p attribs="{'xml:space': 'preserve'}" id="_04251" smilref="Title.smil#_04251"> selection sort</p><p attribs="{'xml:space': 'preserve'}" id="_04252" smilref="Title.smil#_04252"> Visual traces of elementary sorting algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_04253" smilref="Title.smil#_04253" /><pagenum id="p267" page="normal" smilref="Title.smil#p267" /><p attribs="{'xml:space': 'preserve'}" id="_04254" smilref="Title.smil#_04254"> 254</p><p attribs="{'xml:space': 'preserve'}" id="_04255" smilref="Title.smil#_04255"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04256" smilref="Title.smil#_04256"> Comparing two sorting algorithms Now that we have two implementations, we are naturally interested in knowing which one is faster: selection sort (Algorithm 2.1) or insertion sort (Algorithm 2.2). Questions like this arise again and again and again in the study of algorithms and are a major focus throughout this book. We have discussed some fundamental ideas in Chapter 1, but we use this first case in point to illustrate our basic approach to answering such questions. Generally, following the approach introduced in Section 1.4, we compare algorithms by </p><p attribs="{'xml:space': 'preserve'}" id="_04257" smilref="Title.smil#_04257" /><pagenum id="p268" page="normal" smilref="Title.smil#p268" /><p attribs="{'xml:space': 'preserve'}" id="_04258" smilref="Title.smil#_04258"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04259" smilref="Title.smil#_04259"> 255</p><p attribs="{'xml:space': 'preserve'}" id="_04260" smilref="Title.smil#_04260"> to assume that these costs are similar (though we will see a few significant exceptions). The following hypothesis follows directly :</p><p attribs="{'xml:space': 'preserve'}" id="_04261" smilref="Title.smil#_04261"> Property D. The running times of insertion sort and selection sort are quadratic and within a small constant factor of one another for randomly ordered arrays of distinct values.</p><p attribs="{'xml:space': 'preserve'}" id="_04262" smilref="Title.smil#_04262"> Evidence: This statement has been validated on many different computers over the past half-century. Insertion sort was about twice as fast as selection sort when the first edition of this book was written in 1980 and it still is today, even though it took several hours to sort 100,000 items with these algorithms then and just several seconds today. Is insertion sort a bit faster than selection sort on your computer? To find out, you can use the class SortCompare on the next page, which uses the sort() methods in the classes named as command-line arguments to perform the given number of experiments (sorting arrays of the given size) and prints the ratio of the observed running times of the algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_04263" smilref="Title.smil#_04263"> To validate this hypothesis, we use SortCompare (see page 256) to perform the experi- ments. As usual, we use Stopwatch to compute the running time. The implementation of time() shown here does the job for the basic sorts in this chapter. The &#8220;randomly or- dered&#8221; input model is embedded in the timeRandomInput() method in SortCompare, which generates random Double values, sorts them, and returns the total measured time of the sort for the given number of trials. Using random Double values between 0.0 and 1.0 is much simpler than the alternative of using a library function such as and is effective because equal key values are very unlikely</p><p attribs="{'xml:space': 'preserve'}" id="_04264" smilref="Title.smil#_04264"> public static double time(String alg, Comparable[] a) { Stopwatch timer = new Stopwatch(); if (alg.equals("Insertion")) Insertion.sort(a); if (alg.equals("Selection")) Selection.sort(a); if (alg.equals("Shell")) Shell.sort(a); if (alg.equals("Merge")) Merge.sort(a); if (alg.equals("Quick")) Quick.sort(a); if (alg.equals("Heap")) Heap.sort(a); return timer.elapsedTime(); }</p><p attribs="{'xml:space': 'preserve'}" id="_04265" smilref="Title.smil#_04265"> StdRandom.shuffle()</p><p attribs="{'xml:space': 'preserve'}" id="_04266" smilref="Title.smil#_04266"> (see Exercise 2.5.31). As</p><p attribs="{'xml:space': 'preserve'}" id="_04267" smilref="Title.smil#_04267"> Timing one of the sort algorithms in this chapter on a given input</p><p attribs="{'xml:space': 'preserve'}" id="_04268" smilref="Title.smil#_04268"> discussed in Chapter 1, the number of trials is taken as an argument both to take advantage of the law of large numbers (the more trials, the total running time divided by the number of trials is a more accurate estimate of the true average running time) and to help damp out system effects. You are encouraged to experiment with SortCompare</p><p attribs="{'xml:space': 'preserve'}" id="_04269" smilref="Title.smil#_04269" /><pagenum id="p269" page="normal" smilref="Title.smil#p269" /><p attribs="{'xml:space': 'preserve'}" id="_04270" smilref="Title.smil#_04270"> 256</p><p attribs="{'xml:space': 'preserve'}" id="_04271" smilref="Title.smil#_04271"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04272" smilref="Title.smil#_04272"> Comparing two sorting algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_04273" smilref="Title.smil#_04273"> public class SortCompare { public static double time(String alg, Double[] a) { /* See text. */ }</p><p attribs="{'xml:space': 'preserve'}" id="_04274" smilref="Title.smil#_04274"> public static double timeRandomInput(String alg, int N, int T) { // Use alg to sort T random arrays of length N. double total = 0.0; Double[] a = new Double[N]; for (int t = 0; t &lt; T; t++) { // Perform one experiment (generate and sort an array). for (int i = 0; i &lt; N; i++) a[i] = StdRandom.uniform(); total += time(alg, a); } return total; }</p><p attribs="{'xml:space': 'preserve'}" id="_04275" smilref="Title.smil#_04275"> public static void main(String[] args) { String alg1 = args[0]; String alg2 = args[1]; int N = Integer.parseInt(args[2]); int T = Integer.parseInt(args[3]); double t1 = timeRandomInput(alg1, N, T); // total for alg1 double t2 = timeRandomInput(alg2, N, T); // total for alg2 StdOut.printf("For %d random Doubles\n %s is", N, alg1); StdOut.printf(" %.1f times faster than %s\n", t2/t1, alg2); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04276" smilref="Title.smil#_04276"> This client runs the two sorts named in the first two command-line arguments on arrays of N (the third command-line argument) random Double values between 0.0 and 1.0, repeating the experiment T (the fourth command-line argument) times, then prints the ratio of the total running times.</p><p attribs="{'xml:space': 'preserve'}" id="_04277" smilref="Title.smil#_04277"> % java SortCompare Insertion Selection 1000 100 For 1000 random Doubles Insertion is 1.7 times faster than Selection</p><p attribs="{'xml:space': 'preserve'}" id="_04278" smilref="Title.smil#_04278" /><pagenum id="p270" page="normal" smilref="Title.smil#p270" /><p attribs="{'xml:space': 'preserve'}" id="_04279" smilref="Title.smil#_04279"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04280" smilref="Title.smil#_04280"> 257</p><p attribs="{'xml:space': 'preserve'}" id="_04281" smilref="Title.smil#_04281"> on your computer to learn the extent to which its conclusion about insertion sort and selection sort is robust.</p><p attribs="{'xml:space': 'preserve'}" id="_04282" smilref="Title.smil#_04282"> Property D is intentionally a bit vague&#8212;the value of the small constant factor is left unstated and the assumption that the costs of compares and exchanges are similar is left unstated&#8212;so that it can apply in a broad variety of situations. When possible, we try to capture essential aspects of the performance of each of the algorithms that we study in statements like this. As discussed in Chapter 1, each Property that we consider needs to be tested scientifically in a given situation, perhaps supplemented with a more refined hypothesis based upon a related Proposition (mathematical truth). For practical applications, there is one further step, which is crucial: run experiments to validate the hypothesis on the data at hand. We defer consideration of this step to Section 2.5 and the exercises. In this case, if your sort keys are not distinct and/or not randomly ordered, Property D might not hold. You can randomly order an array with StdRandom.shuffle(), but applications with significant numbers of equal keys involve more careful analysis. Our discussions of the analyses of algorithms are intended to be starting points, not final conclusions. If some other question about performance of the algorithms comes to mind, you can study it with a tool like SortCompare. Many opportunities to do so are presented in the exercises.</p><p attribs="{'xml:space': 'preserve'}" id="_04283" smilref="Title.smil#_04283"> We do not dwell further on the comparative performance of insertion sort and selection sort because we are much more interested in algorithms that can run a hundred or a thousand or a million times faster than either. Still, understanding these elementary algorithms is worthwhile for several reasons: </p><p attribs="{'xml:space': 'preserve'}" id="_04284" smilref="Title.smil#_04284" /></level3><level3 id="_00032"><h3 id="ch2-s1-ss4" smilref="Title.smil#ch2-s1-ss4" xml:space="preserve">Shellsort</h3><pagenum id="p271" page="normal" smilref="Title.smil#p271" /><p attribs="{'xml:space': 'preserve'}" id="_04285" smilref="Title.smil#_04285"> 258</p><p attribs="{'xml:space': 'preserve'}" id="_04286" smilref="Title.smil#_04286"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04287" smilref="Title.smil#_04287"> L E E A M H L E P S O L T S X R L M P T E H S S E L O X A E L R</p><p attribs="{'xml:space': 'preserve'}" id="_04288" smilref="Title.smil#_04288"> An h-sorted sequence is h interleaved sorted subsequences</p><p attribs="{'xml:space': 'preserve'}" id="_04289" smilref="Title.smil#_04289"> h = 4</p><p attribs="{'xml:space': 'preserve'}" id="_04290" smilref="Title.smil#_04290"> Shellsort To exhibit the value of knowing properties of elementary sorts, we next consider a fast algorithm based on insertion sort. Insertion sort is slow for large unordered arrays because the only exchanges it does involve adjacent entries, so items can move through the array only one place at a time. For example, if the item with the smallest key happens to be at the end of the array, N&#11002;1 exchanges are needed to get that one item where it belongs. Shellsort is a simple extension of insertion sort that gains speed by allowing exchanges of array entries that are far apart, to produce partially sorted arrays that can be efficiently sorted, eventually by insertion sort. The idea is to rearrange the array to give it the property that taking every hth entry (starting anywhere) yields a sorted subsequence. Such an array is said to be h-sorted. Put another way, an h-sorted array is h independent sorted subsequences, interleaved together. By h-sorting for some large values of h, we can move items in the array long distances and thus make it easier to h-sort for smaller values of h. Using such a procedure for any sequence of values of h that ends in 1 will produce a sorted array : that is shellsort. The implementation in Algorithm 2.3 on the facing page uses the sequence of decreasing values &#189;(3k&#11002;1), starting at the largest increment less than N/3 and decreasing to 1. We refer to such a sequence as an increment sequence. Algorithm 2.3 computes its increment sequence; another alternative is to store an increment sequence in an array. One way to implement shellsort would be, for each h, to use insertion sort independently on each of the h subsequences. Because the subsequences are independent, we can use an even simpler approach: when h-sorting the array, we insert each item among the previous items in its h-subsequence by exchanging it with those that have larger keys (moving them each one position to the right in the subsequence). We accomplish this task by using the insertion-sort code, but modified to decrement by h instead of 1 when moving through the array. This observation reduces the shellsort implementation to an insertion-sort-like pass through the array for each increment. Shellsort gains efficiency by making a tradeoff between size and partial order in the subsequences. At the beginning, the subsequences are short; later in the sort, the subsequences are partially sorted. In both cases, insertion sort is the method of choice. The extent to which the subsequences are partially sorted is a variable factor that depends strongly on the increment sequence. Understanding shellsort&#8217;s performance is a chal- lenge. Indeed, Algorithm 2.3 is the only sorting method we consider whose performance on randomly ordered arrays has not been precisely characterized.</p><p attribs="{'xml:space': 'preserve'}" id="_04291" smilref="Title.smil#_04291" /><pagenum id="p272" page="normal" smilref="Title.smil#p272" /><p attribs="{'xml:space': 'preserve'}" id="_04292" smilref="Title.smil#_04292"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04293" smilref="Title.smil#_04293"> 259</p><p attribs="{'xml:space': 'preserve'}" id="_04294" smilref="Title.smil#_04294"> ALGORITHM 2.3 Shellsort</p><p attribs="{'xml:space': 'preserve'}" id="_04295" smilref="Title.smil#_04295"> public class Shell { public static void sort(Comparable[] a) { // Sort a[] into increasing order. int N = a.length; int h = 1; while (h &lt; N/3) h = 3*h + 1; // 1, 4, 13, 40, 121, 364, 1093, ... while (h &gt;= 1) { // h-sort the array. for (int i = h; i &lt; N; i++) { // Insert a[i] among a[i-h], a[i-2*h], a[i-3*h]... . for (int j = i; j &gt;= h &amp;&amp; less(a[j], a[j-h]); j -= h) exch(a, j, j-h); } h = h/3; } }</p><p attribs="{'xml:space': 'preserve'}" id="_04296" smilref="Title.smil#_04296"> // See page 245 for less(), exch(), isSorted(), and main().</p><p attribs="{'xml:space': 'preserve'}" id="_04297" smilref="Title.smil#_04297"> }</p><p attribs="{'xml:space': 'preserve'}" id="_04298" smilref="Title.smil#_04298"> If we modify insertion sort (Algorithm 2.2) to h-sort the array and add an outer loop to decrease h through a sequence of increments starting at an increment as large as a constant fraction of the array length and ending at 1, we are led to this compact shellsort implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_04299" smilref="Title.smil#_04299"> % java SortCompare Shell Insertion 100000 100 For 100000 random Doubles Shell is 600 times faster than Insertion</p><p attribs="{'xml:space': 'preserve'}" id="_04300" smilref="Title.smil#_04300"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04301" smilref="Title.smil#_04301"> 13-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04302" smilref="Title.smil#_04302"> S H E L L S O R T E X A M P L E</p><p attribs="{'xml:space': 'preserve'}" id="_04303" smilref="Title.smil#_04303"> P H E L L S O R T E X A M S L E</p><p attribs="{'xml:space': 'preserve'}" id="_04304" smilref="Title.smil#_04304"> 4-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04305" smilref="Title.smil#_04305"> L E E A M H L E P S O L T S X R</p><p attribs="{'xml:space': 'preserve'}" id="_04306" smilref="Title.smil#_04306"> 1-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04307" smilref="Title.smil#_04307"> A E E E H L L L M O P R S S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04308" smilref="Title.smil#_04308"> Shellsort trace (array contents after each pass)</p><p attribs="{'xml:space': 'preserve'}" id="_04309" smilref="Title.smil#_04309" /><pagenum id="p273" page="normal" smilref="Title.smil#p273" /><p attribs="{'xml:space': 'preserve'}" id="_04310" smilref="Title.smil#_04310"> 260</p><p attribs="{'xml:space': 'preserve'}" id="_04311" smilref="Title.smil#_04311"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04312" smilref="Title.smil#_04312"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04313" smilref="Title.smil#_04313"> 13-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04314" smilref="Title.smil#_04314"> 4-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04315" smilref="Title.smil#_04315"> 1-sort</p><p attribs="{'xml:space': 'preserve'}" id="_04316" smilref="Title.smil#_04316"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04317" smilref="Title.smil#_04317"> S H E L L S O R T E X A M P L E</p><p attribs="{'xml:space': 'preserve'}" id="_04318" smilref="Title.smil#_04318"> P H E L L S O R T E X A M S L E P H E L L S O R T E X A M S L E P H E L L S O R T E X A M S L E</p><p attribs="{'xml:space': 'preserve'}" id="_04319" smilref="Title.smil#_04319"> L H E L P S O R T E X A M S L E L H E L P S O R T E X A M S L E L H E L P S O R T E X A M S L E L H E L P S O R T E X A M S L E L H E L P S O R T E X A M S L E L E E L P H O R T S X A M S L E L E E L P H O R T S X A M S L E L E E A P H O L T S X R M S L E L E E A M H O L P S X R T S L E L E E A M H O L P S X R T S L E L E E A M H L L P S O R T S X E L E E A M H L E P S O L T S X R</p><p attribs="{'xml:space': 'preserve'}" id="_04320" smilref="Title.smil#_04320"> How do we decide what increment sequence to use? In general, this question is a dif- fi cult one to answer. The performance of the algorithm depends not just on the number of increments, but also on arithmetical interactions among the increments such as the size of their common divisors and other properties. Many different increment sequences have been studied in the lit- erature, but no provably best sequence has been found. The increment sequence that is used in Algorithm 2.3 is easy to compute and use, and performs nearly as well as more sophisticated increment sequences that have been discovered that have provably better worst-case per- formance. Increment sequences that are substantially better still may be waiting to be discovered. Shellsort is useful even for large arrays, particularly by contrast with selection sort and insertion sort. It also performs well on arrays that are in arbitrary order (not necessarily ran- dom). Indeed, constructing an array for which shellsort runs slowly for a particular increment sequence is usually a challenging exercise. As you can learn with SortCompare, shellsort is much faster than insertion sort and selection sort, and its speed advantage increases with the array size. Before reading further, try using SortCompare to compare shellsort with insertion sort and selection sort for array sizes that are increasing powers of 2 on your computer (see Exercise 2.1.27). You will see that shellsort makes it possible to address sorting</p><p attribs="{'xml:space': 'preserve'}" id="_04321" smilref="Title.smil#_04321"> E L E A M H L E P S O L T S X R E E L A M H L E P S O L T S X R A E E L M H L E P S O L T S X R A E E L M H L E P S O L T S X R A E E H L M L E P S O L T S X R A E E H L L M E P S O L T S X R A E E E H L L M P S O L T S X R A E E E H L L M P S O L T S X R A E E E H L L M P S O L T S X R A E E E H L L M O P S L T S X R A E E E H L L L M O P S T S X R A E E E H L L L M O P S T S X R A E E E H L L L M O P S S T X R A E E E H L L L M O P S S T X R A E E E H L L L M O P R S S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04322" smilref="Title.smil#_04322"> A E E E H L L L M O P R S S T X Detailed trace of shellsort (insertions)</p><p attribs="{'xml:space': 'preserve'}" id="_04323" smilref="Title.smil#_04323" /><pagenum id="p274" page="normal" smilref="Title.smil#p274" /><p attribs="{'xml:space': 'preserve'}" id="_04324" smilref="Title.smil#_04324"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04325" smilref="Title.smil#_04325"> 261</p><p attribs="{'xml:space': 'preserve'}" id="_04326" smilref="Title.smil#_04326"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04327" smilref="Title.smil#_04327"> 40-sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04328" smilref="Title.smil#_04328"> 13-sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04329" smilref="Title.smil#_04329"> 4-sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04330" smilref="Title.smil#_04330"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04331" smilref="Title.smil#_04331"> Visual trace of shellsort</p><p attribs="{'xml:space': 'preserve'}" id="_04332" smilref="Title.smil#_04332"> problems that could not be addressed with the more elementary algorithms. This example is our first practical illustration of an important principle that pervades this book: achieving speedups that enable the solution of problems that could not otherwise be solved is one of the prime reasons to study algorithm performance and design. The study of the performance characteristics of shellsort requires mathematical arguments that are beyond the scope of this book. If you want to be convinced, start by thinking about how you would prove the following fact: when an h-sorted array is k-sorted, it remains h-sorted. As for the performance of Algorithm 2.3, the most important result in the present context is the knowledge that the running time of shellsort is not necessarily quadratic&#8212;for example, it is known that the worst-case number of compares for Algorithm 2.3 is proportional to N 3/2. That such a simple modification</p><p attribs="{'xml:space': 'preserve'}" id="_04333" smilref="Title.smil#_04333" /><pagenum id="p275" page="normal" smilref="Title.smil#p275" /><p attribs="{'xml:space': 'preserve'}" id="_04334" smilref="Title.smil#_04334"> 262</p><p attribs="{'xml:space': 'preserve'}" id="_04335" smilref="Title.smil#_04335"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04336" smilref="Title.smil#_04336"> can break the quadratic-running-time barrier is quite interesting, as doing so is a prime goal for many algorithm design problems. No mathematical results are available about the average-case number of compares for shellsort for randomly ordered input. Increment sequences have been devised that drive the asymptotic growth of the worst-case number of compares down to N 4/3, N 5/4, N 6/5, . . . , but many of these results are primarily of academic interest because these functions are hard to distinguish from one another (and from a constant factor of N ) for practical values of N. In practice, you can safely take advantage of the past scientific study of shellsort just by using the increment sequence in Algorithm 2.3 (or one of the increment sequences in the exercises at the end of this section, which may improve performance by 20 to 40 percent). Moreover, you can easily validate the following hypothesis:</p><p attribs="{'xml:space': 'preserve'}" id="_04337" smilref="Title.smil#_04337"> Property E. The number of compares used by shellsort with the increments 1, 4, 13, 40, 121, 364, . . . is bounded by a small multiple of N times the number of increments used. Evidence: Instrumenting Algorithm 2.3 to count compares and divide by the number of increments used is a straightforward exercise (see Exercise 2.1.12). Ex- tensive experiments suggest that the average number of compares per increment might be N 1/5, but it is quite difficult to discern the growth in that function unless N is huge. This property also seems to be rather insensitive to the input model.</p><p attribs="{'xml:space': 'preserve'}" id="_04338" smilref="Title.smil#_04338"> Experienced programmers sometimes choose shellsort because it has acceptable running time even for moderately large arrays; it requires a small amount of code; and it uses no extra space. In the next few sections, we shall see methods that are more ef- fi cient, but they are perhaps only twice as fast (if that much) except for very large N, and they are more complicated. If you need a solution to a sorting problem, and are working in a situation where a system sort may not be available (for example, code destined for hardware or an embedded system), you can safely use shellsort, then determine sometime later whether it will be worthwhile to replace it with a more sophisticated method.</p><p attribs="{'xml:space': 'preserve'}" id="_04339" smilref="Title.smil#_04339" /><pagenum id="p276" page="normal" smilref="Title.smil#p276" /><p attribs="{'xml:space': 'preserve'}" id="_04340" smilref="Title.smil#_04340"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04341" smilref="Title.smil#_04341"> 263</p><p attribs="{'xml:space': 'preserve'}" id="_04342" smilref="Title.smil#_04342"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_04343" smilref="Title.smil#_04343"> Q. Sorting seems like a toy problem. Aren&#8217;t many of the other things that we do with computers much more interesting? A. Perhaps, but many of those interesting things are made possible by fast sorting al- gorithms. You will find many examples in Section 2.5 and throughout the rest of the book. Sorting is worth studying now because the problem is easy to understand, and you can appreciate the ingenuity behind the faster algorithms. Q. Why so many sorting algorithms? A. One reason is that the performance of many algorithms depends on the input val- ues, so different algorithms might be appropriate for different applications having different kinds of input. For example, insertion sort is the method of choice for partially sorted or tiny arrays. Other constraints, such as space and treatment of equal keys, also come into play. We will revisit this question in Section 2.5. Q. Why bother using the tiny helper methods less() and exch()? A. They are basic abstract operations needed by any sort algorithm, and the code is easier to understand in terms of these abstractions. Moreover, they make the code directly portable to other settings. For example, much of the code in Algorithms 2.1 and 2.2 is legal code in several other programming languages. Even in Java, we can use this code as the basis for sorting primitive types (which are not Comparable): simply implement less() with the code v &lt; w. Q. When I run SortCompare, I get different values each time that I run it (and those are different from the values in the book). Why? A. For starters, you have a different computer from the one we used, not to mention a different operating system, Java runtime, and so forth. All of these differences might lead to slight differences in the machine code for the algorithms. Differences each time that you run it on your computer might be due to other applications that you are running or various other conditions. Running a very large number of trials should dampen the effect. The lesson is that small differences in algorithm performance are difficult to notice nowadays. That is a primary reason that we focus on large ones!</p><p attribs="{'xml:space': 'preserve'}" id="_04344" smilref="Title.smil#_04344" /><pagenum id="p277" page="normal" smilref="Title.smil#p277" /><p attribs="{'xml:space': 'preserve'}" id="_04345" smilref="Title.smil#_04345"> 264</p><p attribs="{'xml:space': 'preserve'}" id="_04346" smilref="Title.smil#_04346"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04347" smilref="Title.smil#_04347"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_04348" smilref="Title.smil#_04348"> 2.1.1 Show, in the style of the example trace with Algorithm 2.1, how selection sort</p><p attribs="{'xml:space': 'preserve'}" id="_04349" smilref="Title.smil#_04349"> sorts the array E A S Y Q U E S T I O N.</p><p attribs="{'xml:space': 'preserve'}" id="_04350" smilref="Title.smil#_04350"> 2.1.2 What is the maximum number of exchanges involving any particular item during selection sort? What is the average number of exchanges involving an item? 2.1.3 Give an example of an array of N items that maximizes the number of times the test a[j] &lt; a[min] succeeds (and, therefore, min gets updated) during the operation of selection sort (Algorithm 2.1). 2.1.4 Show, in the style of the example trace with Algorithm 2.2, how insertion sort</p><p attribs="{'xml:space': 'preserve'}" id="_04351" smilref="Title.smil#_04351"> sorts the array E A S Y Q U E S T I O N.</p><p attribs="{'xml:space': 'preserve'}" id="_04352" smilref="Title.smil#_04352"> 2.1.5 For each of the two conditions in the inner for loop in insertion sort (Algo- rithm 2.2), describe an array of N items where that condition is always false when the loop terminates. 2.1.6 Which method runs faster for an array with all keys identical, selection sort or insertion sort? 2.1.7 Which method runs faster for an array in reverse order, selection sort or insertion sort? 2.1.8 Suppose that we use insertion sort on a randomly ordered array where items have only one of three values. Is the running time linear, quadratic, or something in between? 2.1.9 Show, in the style of the example trace with Algorithm 2.3, how shellsort sorts</p><p attribs="{'xml:space': 'preserve'}" id="_04353" smilref="Title.smil#_04353"> the array E A S Y S H E L L S O R T Q U E S T I O N.</p><p attribs="{'xml:space': 'preserve'}" id="_04354" smilref="Title.smil#_04354"> 2.1.10 Why not use selection sort for h-sorting in shellsort? 2.1.11 Implement a version of shellsort that keeps the increment sequence in an array, rather than computing it. 2.1.12 Instrument shellsort to print the number of compares divided by the array size for each increment. Write a test client that tests the hypothesis that this number is a small constant, by sorting arrays of random Double values, using array sizes that are increasing powers of 10, starting at 100.</p><p attribs="{'xml:space': 'preserve'}" id="_04355" smilref="Title.smil#_04355" /><pagenum id="p278" page="normal" smilref="Title.smil#p278" /><p attribs="{'xml:space': 'preserve'}" id="_04356" smilref="Title.smil#_04356"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04357" smilref="Title.smil#_04357"> 265</p><p attribs="{'xml:space': 'preserve'}" id="_04358" smilref="Title.smil#_04358"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_04359" smilref="Title.smil#_04359"> 2.1.13 Deck sort. Explain how you would put a deck of cards in order by suit (in the order spades, hearts, clubs, diamonds) and by rank within each suit, with the restriction that the cards must be laid out face down in a row, and the only allowed operations are to check the values of two cards and to exchange two cards (keeping them face down). 2.1.14 Dequeue sort. Explain how you would sort a deck of cards, with the restriction that the only allowed operations are to look at the values of the top two cards, to exchange the top two cards, and to move the top card to the bottom of the deck. 2.1.15 Expensive exchange. A clerk at a shipping company is charged with the task of rearranging a number of large crates in order of the time they are to be shipped out. Thus, the cost of compares is very low (just look at the labels) relative to the cost of exchanges (move the crates). The warehouse is nearly full&#8212;there is extra space sufficient to hold any one of the crates, but not two. What sorting method should the clerk use? 2.1.16 Certi&#64257; cation. Write a check() method that calls sort() for a given array and returns true if sort() puts the array in order and leaves the same set of objects in the array as were there initially, false otherwise. Do not assume that sort() is restricted to move data only with exch(). You may use Arrays.sort() and assume that it is correct. 2.1.17 Animation. Add code to Insertion and Selection to make them draw the array contents as vertical bars like the visual traces in this section, redrawing the bars after each pass, to produce an animated effect, ending in a &#8220;sorted&#8221; picture where the bars appear in order of their height. Hint : Use a client like the one in the text that generates random Double values, insert calls to show() as appropriate in the sort code, and implement a show() method that clears the canvas and draws the bars. 2.1.18 Visual trace. Modify your solution to the previous exercise to make Insertion and Selection produce visual traces such as those depicted in this section. Hint : Judi- cious use of setYscale() makes this problem easy. Extra credit : Add the code necessary to produce red and gray color accents such as those in our fi gures. 2.1.19 Shellsort worst case. Construct an array of 100 elements containing the numbers 1 through 100 for which shellsort, with the increments 1 4 13 40, uses as large a number of compares as you can fi nd. 2.1.20 Shellsort best case. What is the best case for shellsort? Justify your answer.</p><p attribs="{'xml:space': 'preserve'}" id="_04360" smilref="Title.smil#_04360" /><pagenum id="p279" page="normal" smilref="Title.smil#p279" /><p attribs="{'xml:space': 'preserve'}" id="_04361" smilref="Title.smil#_04361"> 266</p><p attribs="{'xml:space': 'preserve'}" id="_04362" smilref="Title.smil#_04362"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04363" smilref="Title.smil#_04363"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04364" smilref="Title.smil#_04364"> 2.1.21 Comparable transactions. Using our code for Date (page 247) as a model, expand your implementation of Transaction (Exercise 1.2.13) so that it implements Comparable, such that transactions are kept in order by amount.</p><p attribs="{'xml:space': 'preserve'}" id="_04365" smilref="Title.smil#_04365"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_04366" smilref="Title.smil#_04366"> public class Transaction implements Comparable&lt;Transaction&gt; { ... private final double amount; ... public int compareTo(Transaction that) { if (this.amount &gt; that.amount) return +1; if (this.amount &lt; that.amount) return -1; return 0; } ... }</p><p attribs="{'xml:space': 'preserve'}" id="_04367" smilref="Title.smil#_04367"> 2.1.22 Transaction sort test client. Write a class SortTransactions that consists of a static method main() that reads a sequence of transactions from standard input, sorts them, and prints the result on standard output (see Exercise 1.3.17).</p><p attribs="{'xml:space': 'preserve'}" id="_04368" smilref="Title.smil#_04368"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_04369" smilref="Title.smil#_04369"> public class SortTransactions { public static Transaction[] readTransactions() { // See Exercise 1.3.17 }</p><p attribs="{'xml:space': 'preserve'}" id="_04370" smilref="Title.smil#_04370"> public static void main(String[] args) { Transaction[] transactions = readTransactions(); Shell.sort(transactions); for (Transaction t : transactions) StdOut.println(t); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04371" smilref="Title.smil#_04371" /><pagenum id="p280" page="normal" smilref="Title.smil#p280" /><p attribs="{'xml:space': 'preserve'}" id="_04372" smilref="Title.smil#_04372"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04373" smilref="Title.smil#_04373"> 267</p><p attribs="{'xml:space': 'preserve'}" id="_04374" smilref="Title.smil#_04374"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_04375" smilref="Title.smil#_04375"> 2.1.23 Deck sort. Ask a few friends to sort a deck of cards (see Exercise 2.1.13). Ob- serve them carefully and write down the method(s) that they use. 2.1.24 Insertion sort with sentinel. Develop an implementation of insertion sort that eliminates the j&gt;0 test in the inner loop by first putting the smallest item into position. Use SortCompare to evaluate the effectiveness of doing so. Note : It is often possible to avoid an index-out-of-bounds test in this way&#8212;the element that enables the test to be eliminated is known as a sentinel. 2.1.25 Insertion sort without exchanges. Develop an implementation of insertion sort that moves larger elements to the right one position with one array access per entry, rather than using exch(). Use SortCompare to evaluate the effectiveness of doing so. 2.1.26 Primitive types. Develop a version of insertion sort that sorts arrays of int values and compare its performance with the implementation given in the text (which sorts Integer values and implicitly uses autoboxing and auto-unboxing to convert). 2.1.27 Shellsort is subquadratic. Use SortCompare to compare shellsort with insertion sort and selection sort on your computer. Use array sizes that are increasing powers of 2, starting at 128. 2.1.28 Equal keys. Formulate and validate hypotheses about the running time of insertion sort and selection sort for arrays that contain just two key values, assuming that the values are equally likely to occur. 2.1.29 Shellsort increments. Run experiments to compare the increment sequence in Algorithm 2.3 with the sequence 1, 5, 19, 41, 109, 209, 505, 929, 2161, 3905, 8929, 16001, 36289, 64769, 146305, 260609 (which is formed by merging together the sequences 9&#183;4k &#11002;9&#183;2k &#11001;1 and 4k &#11002;3&#183;2k &#11001;1). See Exercise 2.1.11. 2.1.30 Geometric increments. Run experiments to determine a value of t that leads to the lowest running time of shellsort for random arrays for the increment sequence 1, &#9123;t&#9126;, &#9123;t 2&#9126;, &#9123;t 3&#9126;, &#9123;t 4&#9126;, . . . for N = 10 6. Give the values of t and the increment sequences for the best three values that you fi nd.</p><p attribs="{'xml:space': 'preserve'}" id="_04376" smilref="Title.smil#_04376" /><pagenum id="p281" page="normal" smilref="Title.smil#p281" /><p attribs="{'xml:space': 'preserve'}" id="_04377" smilref="Title.smil#_04377"> 268</p><p attribs="{'xml:space': 'preserve'}" id="_04378" smilref="Title.smil#_04378"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04379" smilref="Title.smil#_04379"> EXPERIMENTS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04380" smilref="Title.smil#_04380"> The following exercises describe various clients for helping to evaluate sorting methods. They are intended as starting points for helping to understand performance properties, using random data. In all of them, use time(), as in SortCompare, so that you can get more accurate results by specifying more trials in the second command-line argument. We refer back to these exercises in later sections when evaluating more sophisticated methods. 2.1.31 Doubling test. Write a client that performs a doubling test for sort algorithms. Start at N equal to 1000, and print N, the predicted number of seconds, the actual number of seconds, and the ratio as N doubles. Use your program to validate that insertion sort and selection sort are quadratic for random inputs, and formulate and test a hypothesis for shellsort. 2.1.32 Plot running times. Write a client that uses StdDraw to plot the average running times of the algorithm for random inputs and various values of the array size. You may add one or two more command-line arguments. Strive to design a useful tool. 2.1.33 Distribution. Write a client that enters into an infinite loop running sort() on arrays of the size given as the third command-line argument, measures the time taken for each run, and uses StdDraw to plot the average running times. A picture of the distribution of the running times should emerge. 2.1.34 Corner cases. Write a client that runs sort() on difficult or pathological cases that might turn up in practical applications. Examples include arrays that are already in order, arrays in reverse order, arrays where all keys are the same, arrays consisting of only two distinct values, and arrays of size 0 or 1. 2.1.35 Nonuniform distributions. Write a client that generates test data by randomly ordering objects using other distributions than uniform, including the following: </p><p attribs="{'xml:space': 'preserve'}" id="_04381" smilref="Title.smil#_04381" /><pagenum id="p282" page="normal" smilref="Title.smil#p282" /><p attribs="{'xml:space': 'preserve'}" id="_04382" smilref="Title.smil#_04382"> 2 .1 </p><p attribs="{'xml:space': 'preserve'}" id="_04383" smilref="Title.smil#_04383"> 269</p><p attribs="{'xml:space': 'preserve'}" id="_04384" smilref="Title.smil#_04384"> 2.1.36 Nonuniform data. Write a client that generates test data that is not uniform, including the following: </p><p attribs="{'xml:space': 'preserve'}" id="_04385" smilref="Title.smil#_04385"> 2.1.38 Various types of items. Write a client that generates arrays of items of various types with random key values, including the following: </p><p attribs="{'xml:space': 'preserve'}" id="_04386" smilref="Title.smil#_04386" /></level3><level3 id="_00033"><h3 id="ch2-s2-ss5" smilref="Title.smil#ch2-s2-ss5" xml:space="preserve">Abstract in-place merge</h3><p attribs="{'xml:space': 'preserve'}" id="_04387" smilref="Title.smil#_04387"> 2.2</p><p attribs="{'xml:space': 'preserve'}" id="_04388" smilref="Title.smil#_04388"> MERGESORT</p><p attribs="{'xml:space': 'preserve'}" id="_04389" smilref="Title.smil#_04389"> The algorithms that we consider in this section are based on a simple operation known as merging : combining two ordered arrays to make one larger ordered array. This operation immediately leads to a simple recursive sort method known as merge- sort : to sort an array, divide it into two halves, sort the two halves (recursively), and then merge the results. As you will see, one of mergesort&#8217;s most attractive properties is that it guarantees to sort any array of N items in time proportional to N log N. Its prime disadvantage is that it uses extra space proportional to N.</p><p attribs="{'xml:space': 'preserve'}" id="_04390" smilref="Title.smil#_04390"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04391" smilref="Title.smil#_04391"> sort left half</p><p attribs="{'xml:space': 'preserve'}" id="_04392" smilref="Title.smil#_04392"> sort right half</p><p attribs="{'xml:space': 'preserve'}" id="_04393" smilref="Title.smil#_04393"> merge results</p><p attribs="{'xml:space': 'preserve'}" id="_04394" smilref="Title.smil#_04394"> M E R G E S O R T E X A M P L E E E G M O R R S T E X A M P L E E E G M O R R S A E E L M P T X A E E E E G L M M O P R R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04395" smilref="Title.smil#_04395"> Mergesort overview</p><p attribs="{'xml:space': 'preserve'}" id="_04396" smilref="Title.smil#_04396"> Abstract in-place merge The straightforward approach to implementing merging is to design a method that merges two disjoint ordered arrays of Comparable objects into a third array. This strategy is easy to implement: create an output array of the requisite size and then choose successively the smallest remaining item from the two input arrays to be the next item added to the output array. However, when we mergesort a large array, we are doing a huge number of merges, so the cost of creating a new array to hold the output every time that we do a merge is problematic. It would be much more desirable to have an in-place method so that we could sort the first half of the array in place, then sort the second half of the array in place, then do the merge of the two halves by moving the items around within the ar- ray, without using a significant amount of other extra space. It is worthwhile to pause momentarily to consider how you might do that. At first blush, this problem seems to be one that must be simple to solve, but solutions that are known are quite complicated, especially by comparison to alternatives that use extra space. Still, the abstraction of an in-place merge is useful. Accordingly, we use the method signature merge(a, lo, mid, hi) to specify a merge method that puts the result of merging the subarrays a[lo..mid] with a[mid+1..hi] into a single ordered array, leaving the result in a[lo..hi]. The code on the next page implements this merge method in just a few lines by copying everything to an auxiliary array and then merging back to the original. Another approach is described in Exercise 2.2.10.</p><p attribs="{'xml:space': 'preserve'}" id="_04397" smilref="Title.smil#_04397"> 270</p><p attribs="{'xml:space': 'preserve'}" id="_04398" smilref="Title.smil#_04398" /><p attribs="{'xml:space': 'preserve'}" id="_04399" smilref="Title.smil#_04399"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04400" smilref="Title.smil#_04400"> 271</p><p attribs="{'xml:space': 'preserve'}" id="_04401" smilref="Title.smil#_04401"> Abstract in-place merge</p><p attribs="{'xml:space': 'preserve'}" id="_04402" smilref="Title.smil#_04402"> public static void merge(Comparable[] a, int lo, int mid, int hi) { // Merge a[lo..mid] with a[mid+1..hi]. int i = lo, j = mid+1;</p><p attribs="{'xml:space': 'preserve'}" id="_04403" smilref="Title.smil#_04403"> for (int k = lo; k &lt;= hi; k++) // Copy a[lo..hi] to aux[lo..hi]. aux[k] = a[k];</p><p attribs="{'xml:space': 'preserve'}" id="_04404" smilref="Title.smil#_04404"> for (int k = lo; k &lt;= hi; k++) // Merge back to a[lo..hi]. if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi ) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; }</p><p attribs="{'xml:space': 'preserve'}" id="_04405" smilref="Title.smil#_04405"> This method merges by first copying into the auxiliary array aux[] then merging back to a[]. In the merge (the second for loop), there are four conditions: left half exhausted (take from the right), right half exhausted (take from the left), current key on right less than current key on left (take from the right), and current key on right greater than or equal to current key on left (take from the left).</p><p attribs="{'xml:space': 'preserve'}" id="_04406" smilref="Title.smil#_04406"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04407" smilref="Title.smil#_04407"> copy</p><p attribs="{'xml:space': 'preserve'}" id="_04408" smilref="Title.smil#_04408"> merged result</p><p attribs="{'xml:space': 'preserve'}" id="_04409" smilref="Title.smil#_04409"> a[] aux[] k 0 1 2 3 4 5 6 7 8 9 i j 0 1 2 3 4 5 6 7 8 9 E E G M R A C E R T - - - - - - - - - - E E G M R A C E R T E E G M R A C E R T 0 5 0 A 0 6 E E G M R A C E R T 1 A C 0 7 E E G M R C E R T 2 A C E 1 7 E E G M R E R T 3 A C E E 2 7 E G M R E R T 4 A C E E E 2 8 G M R E R T 5 A C E E E G 3 8 G M R R T 6 A C E E E G M 4 8 M R R T 7 A C E E E G M R 5 8 R R T 8 A C E E E G M R R 5 9 R T 9 A C E E E G M R R T 6 10 T A C E E E G M R R T</p><p attribs="{'xml:space': 'preserve'}" id="_04410" smilref="Title.smil#_04410"> Abstract in-place merge trace</p><p attribs="{'xml:space': 'preserve'}" id="_04411" smilref="Title.smil#_04411" /></level3><level3 id="_00034"><h3 id="ch2-s2-ss6" smilref="Title.smil#ch2-s2-ss6" xml:space="preserve">Top-down mergesort</h3><pagenum id="p285" page="normal" smilref="Title.smil#p285" /><p attribs="{'xml:space': 'preserve'}" id="_04412" smilref="Title.smil#_04412"> 272</p><p attribs="{'xml:space': 'preserve'}" id="_04413" smilref="Title.smil#_04413"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04414" smilref="Title.smil#_04414"> Top-down mergesort Algorithm 2.4 is a recur-</p><p attribs="{'xml:space': 'preserve'}" id="_04415" smilref="Title.smil#_04415"> sive mergesort implementation based on this abstract in- place merge. It is one of the best-known examples of the utility of the divide-and-conquer paradigm for efficient algorithm design. This recursive code is the basis for an inductive proof that the algorithm sorts the array : if it sorts the two subarrays, it sorts the whole array, by merging together the subarrays. To understand mergesort, it is worthwhile to consider carefully the dynamics of the method calls, shown in the trace at right. To sort a[0..15], the sort() method calls itself to sort a[0..7] then calls itself to sort a[0..3] and a[0..1] before finally doing the first merge of a[0] with a[1] after calling itself to sort a[0] and then a[1] (for brevity, we omit the calls for the base-case 1-entry sorts in the trace). Then the next merge is a[2] with a[3] and then a[0..1] with a[2..3] and so forth. From this trace, we see that the sort code simply provides an organized way to sequence the calls to the merge() method. This insight will be useful later in this section. The recursive code also provides us with the basis for analyzing mergesort&#8217;s running time. Because mergesort is a prototype of the divide-and-conquer algorithm design paradigm, we will consider this analysis in detail.</p><p attribs="{'xml:space': 'preserve'}" id="_04416" smilref="Title.smil#_04416"> sort left half</p><p attribs="{'xml:space': 'preserve'}" id="_04417" smilref="Title.smil#_04417"> sort right half</p><p attribs="{'xml:space': 'preserve'}" id="_04418" smilref="Title.smil#_04418"> sort(a, 0, 15) sort(a, 0, 7) sort(a, 0, 3) sort(a, 0, 1) merge(a, 0, 0, 1) sort(a, 2, 3) merge(a, 2, 2, 3) merge(a, 0, 1, 3) sort(a, 4, 7) sort(a, 4, 5) merge(a, 4, 4, 5) sort(a, 6, 7) merge(a, 6, 6, 7) merge(a, 4, 5, 7) merge(a, 0, 3, 7) sort(a, 8, 15) sort(a, 8, 11) sort(a, 8, 9) merge(a, 8, 8, 9) sort(a, 10, 11) merge(a, 10, 10, 11) merge(a, 8, 9, 11) sort(a, 12, 15) sort(a, 12, 13) merge(a, 12, 12, 13) sort(a, 14, 15) merge(a, 14, 14,15) merge(a, 12, 13, 15) merge(a, 8, 11, 15) merge(a, 0, 7, 15)</p><p attribs="{'xml:space': 'preserve'}" id="_04419" smilref="Title.smil#_04419"> merge results</p><p attribs="{'xml:space': 'preserve'}" id="_04420" smilref="Title.smil#_04420"> Top-down mergesort call trace</p><p attribs="{'xml:space': 'preserve'}" id="_04421" smilref="Title.smil#_04421"> Proposition F. Top-down mergesort uses between &#189; N lg N and N lg N compares to sort any array of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_04422" smilref="Title.smil#_04422"> Proof : Let C(N) be the number of compares needed to sort an array of length N. We have C(0) = C(1) = 0 and for N &gt; 0 we can write a recurrence relationship that directly mirrors the recursive sort() method to establish an upper bound: C(N ) &#11349; C ((cid:149)N/2(cid:151)) &#11001; C ((cid:150)N/2(cid:152)) &#11001; N</p><p attribs="{'xml:space': 'preserve'}" id="_04423" smilref="Title.smil#_04423"> The first term on the right is the number of compares to sort the left half of the ar- ray, the second term is the number of compares to sort the right half, and the third</p><p attribs="{'xml:space': 'preserve'}" id="_04424" smilref="Title.smil#_04424" /><pagenum id="p286" page="normal" smilref="Title.smil#p286" /><p attribs="{'xml:space': 'preserve'}" id="_04425" smilref="Title.smil#_04425"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04426" smilref="Title.smil#_04426"> 273</p><p attribs="{'xml:space': 'preserve'}" id="_04427" smilref="Title.smil#_04427"> ALGORITHM 2.4 Top-down mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_04428" smilref="Title.smil#_04428"> public class Merge { private static Comparable[] aux; // auxiliary array for merges</p><p attribs="{'xml:space': 'preserve'}" id="_04429" smilref="Title.smil#_04429"> public static void sort(Comparable[] a) { aux = new Comparable[a.length]; // Allocate space just once. sort(a, 0, a.length - 1); }</p><p attribs="{'xml:space': 'preserve'}" id="_04430" smilref="Title.smil#_04430"> private static void sort(Comparable[] a, int lo, int hi) { // Sort a[lo..hi]. if (hi &lt;= lo) return; int mid = lo + (hi - lo)/2; sort(a, lo, mid); // Sort left half. sort(a, mid+1, hi); // Sort right half. merge(a, lo, mid, hi); // Merge results (code on page 271). } }</p><p attribs="{'xml:space': 'preserve'}" id="_04431" smilref="Title.smil#_04431"> To sort a subarray a[lo..hi] we divide it into two parts: a[lo..mid] and a[mid+1..hi], sort them independently (via recursive calls), and merge the resulting ordered subarrays to produce the result.</p><p attribs="{'xml:space': 'preserve'}" id="_04432" smilref="Title.smil#_04432"> a[] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 lo hi M E R G E S O R T E X A M P L E merge(a, 0, 0, 1) E M R G E S O R T E X A M P L E merge(a, 2, 2, 3) E M G R E S O R T E X A M P L E merge(a, 0, 1, 3) E G M R E S O R T E X A M P L E merge(a, 4, 4, 5) E G M R E S O R T E X A M P L E merge(a, 6, 6, 7) E G M R E S O R T E X A M P L E merge(a, 4, 5, 7) E G M R E O R S T E X A M P L E merge(a, 0, 3, 7) E E G M O R R S T E X A M P L E merge(a, 8, 8, 9) E E G M O R R S E T X A M P L E merge(a, 10, 10, 11) E E G M O R R S E T A X M P L E merge(a, 8, 9, 11) E E G M O R R S A E T X M P L E merge(a, 12, 12, 13) E E G M O R R S A E T X M P L E merge(a, 14, 14, 15) E E G M O R R S A E T X M P E L merge(a, 12, 13, 15) E E G M O R R S A E T X E L M P merge(a, 8, 11, 15) E E G M O R R S A E E L M P T X merge(a, 0, 7, 15) A E E E E G L M M O P R R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04433" smilref="Title.smil#_04433"> Trace of merge results for top-down mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_04434" smilref="Title.smil#_04434" /><pagenum id="p287" page="normal" smilref="Title.smil#p287" /><p attribs="{'xml:space': 'preserve'}" id="_04435" smilref="Title.smil#_04435"> 274</p><p attribs="{'xml:space': 'preserve'}" id="_04436" smilref="Title.smil#_04436"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04437" smilref="Title.smil#_04437"> term is the number of compares for the merge. The lower bound C(N ) &#11350; C ((cid:149)N/2(cid:151)) &#11001; C((cid:150)N/2(cid:152)) &#11001; (cid:150)N/2(cid:152) follows because the number of compares for the merge is at least (cid:150)N/2(cid:152) . We derive an exact solution to the recurrence when equality holds and N is a power of 2 (say N = 2n). First, since (cid:150)N/2(cid:152) = (cid:149)N/2(cid:151) = 2n&#11002;1, we have C(2n ) = 2C(2n&#11002;1) &#11001; 2n Dividing both sides by 2n gives C(2n )/2n = C(2n&#11002;1)/2n&#11002;1 &#11001; 1 Applying the same equation to the first term on the right, we have C(2n )/2n = C(2n&#11002;2)/2n&#11002;2 &#11001; 1 &#11001; 1 Repeating the previous step n &#11002; 1 additional times gives C(2n )/2n =C(20)/20 &#11001; n which, after multiplying both sides by 2n, leaves us with the solution C(N ) = C(2n ) = n 2n = N lg N Exact solutions for general N are more complicated, but it is not difficult to apply the same argument to the inequalities describing the bounds on the number of compares to prove the stated result for all values of N. This proof is valid no matter what the input values are and no matter in what order they appear.</p><p attribs="{'xml:space': 'preserve'}" id="_04438" smilref="Title.smil#_04438"> Another way to understand Proposition F is to examine the tree drawn below, where each node depicts a subarray for which sort() does a merge(). The tree has precisely n levels. For k from 0 to n &#11002; 1, the kth level from the top depicts 2k subarrays, each of length 2n&#11002;k, each of which thus requires at most 2n&#11002;k compares for the merge. Thus we have 2k &#183; 2n&#11002;k = 2n total cost for each of the n levels, for a total of n 2n = NlgN.</p><p attribs="{'xml:space': 'preserve'}" id="_04439" smilref="Title.smil#_04439"> a[0..15]</p><p attribs="{'xml:space': 'preserve'}" id="_04440" smilref="Title.smil#_04440"> a[0..7]</p><p attribs="{'xml:space': 'preserve'}" id="_04441" smilref="Title.smil#_04441"> a[8..15]</p><p attribs="{'xml:space': 'preserve'}" id="_04442" smilref="Title.smil#_04442"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_04443" smilref="Title.smil#_04443"> a[0..3]</p><p attribs="{'xml:space': 'preserve'}" id="_04444" smilref="Title.smil#_04444"> a[4..7]</p><p attribs="{'xml:space': 'preserve'}" id="_04445" smilref="Title.smil#_04445"> a[8..11]</p><p attribs="{'xml:space': 'preserve'}" id="_04446" smilref="Title.smil#_04446"> a[12..15]</p><p attribs="{'xml:space': 'preserve'}" id="_04447" smilref="Title.smil#_04447"> a[0..1]</p><p attribs="{'xml:space': 'preserve'}" id="_04448" smilref="Title.smil#_04448"> a[2..3]</p><p attribs="{'xml:space': 'preserve'}" id="_04449" smilref="Title.smil#_04449"> a[4..5]</p><p attribs="{'xml:space': 'preserve'}" id="_04450" smilref="Title.smil#_04450"> a[6..7]</p><p attribs="{'xml:space': 'preserve'}" id="_04451" smilref="Title.smil#_04451"> a[8..9]</p><p attribs="{'xml:space': 'preserve'}" id="_04452" smilref="Title.smil#_04452"> a[10..11] a[12..13] a[14..15]</p><p attribs="{'xml:space': 'preserve'}" id="_04453" smilref="Title.smil#_04453"> Mergesort subarray dependence tree for N = 16</p><p attribs="{'xml:space': 'preserve'}" id="_04454" smilref="Title.smil#_04454" /><pagenum id="p288" page="normal" smilref="Title.smil#p288" /><p attribs="{'xml:space': 'preserve'}" id="_04455" smilref="Title.smil#_04455"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04456" smilref="Title.smil#_04456"> 275</p><p attribs="{'xml:space': 'preserve'}" id="_04457" smilref="Title.smil#_04457"> Proposition G. Top-down mergesort uses at most 6N lg N array accesses to sort an array of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_04458" smilref="Title.smil#_04458"> Proof : Each merge uses at most 6N array accesses (2N for the copy, 2N for the move back, and at most 2N for compares). The result follows from the same argument as for Proposition F.</p><p attribs="{'xml:space': 'preserve'}" id="_04459" smilref="Title.smil#_04459"> PropositionS F and G tell us that we can expect the time required by mergesort to be proportional to N log N. That fact brings us to a different level from the elementary methods in Section 2.1 because it tells us that we can sort huge arrays using just a logarithmic factor more time than it takes to examine every entry. You can sort millions of items (or more) with mergesort, but not with insertion sort or selection sort. The primary drawback of mergesort is that it requires extra space proportional to N, for the auxiliary array for merging. If space is at a premium, we need to consider another method. On the other hand, we can cut the running time of mergesort substantially with some carefully considered modifications to the implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_04460" smilref="Title.smil#_04460"> Use insertion sort for small subarrays. We can improve most recursive algorithms by handling small cases differently, because the recursion guarantees that the method will be used often for small cases, so improvements in handling them lead to improvements in the whole algorithm. In the case of sorting, we know that insertion sort (or selection sort) is simple and therefore likely to be faster than mergesort for tiny subarrays. As usual, a visual trace provides insight into the operation of mergesort. The visual trace on the facing page shows the operation of a mergesort implementation with a cutoff for small subarrays. Switching to insertion sort for small subarrays (length 15 or less, say) will improve the running time of a typical mergesort implementation by 10 to 15</p><p attribs="{'xml:space': 'preserve'}" id="_04461" smilref="Title.smil#_04461"> percent (see Exercise 2.2.23).</p><p attribs="{'xml:space': 'preserve'}" id="_04462" smilref="Title.smil#_04462"> Test whether the array is already in order. We can reduce the running time to be</p><p attribs="{'xml:space': 'preserve'}" id="_04463" smilref="Title.smil#_04463"> linear for arrays that are already in order by adding a test to skip the call to merge() if a[mid] is less than or equal to a[mid+1]. With this change, we still do all the recursive calls, but the running time for any sorted subarray is linear (see Exercise 2.2.8). Eliminate the copy to the auxiliary array. It is possible to eliminate the time (but not the space) taken to copy to the auxiliary array used for merging. To do so, we use two invocations of the sort method: one takes its input from the given array and puts the sorted output in the auxiliary array ; the other takes its input from the auxiliary array and puts the sorted output in the given array. With this approach, in a bit of recursive trickery, we can arrange the recursive calls such that the computation switches the roles of the input array and the auxiliary array at each level (see Exercise 2.2.11).</p><p attribs="{'xml:space': 'preserve'}" id="_04464" smilref="Title.smil#_04464" /><pagenum id="p289" page="normal" smilref="Title.smil#p289" /><p attribs="{'xml:space': 'preserve'}" id="_04465" smilref="Title.smil#_04465"> 276</p><p attribs="{'xml:space': 'preserve'}" id="_04466" smilref="Title.smil#_04466"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04467" smilref="Title.smil#_04467"> first subarray</p><p attribs="{'xml:space': 'preserve'}" id="_04468" smilref="Title.smil#_04468"> second subarray</p><p attribs="{'xml:space': 'preserve'}" id="_04469" smilref="Title.smil#_04469"> first merge</p><p attribs="{'xml:space': 'preserve'}" id="_04470" smilref="Title.smil#_04470"> first half sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04471" smilref="Title.smil#_04471"> second half sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04472" smilref="Title.smil#_04472"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04473" smilref="Title.smil#_04473"> Visual trace of top-down mergesort with cutoff for small subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_04474" smilref="Title.smil#_04474" /></level3><level3 id="_00035"><h3 id="ch2-s2-ss7" smilref="Title.smil#ch2-s2-ss7" xml:space="preserve">Bottom-up mergesort</h3><pagenum id="p290" page="normal" smilref="Title.smil#p290" /><p attribs="{'xml:space': 'preserve'}" id="_04475" smilref="Title.smil#_04475"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04476" smilref="Title.smil#_04476"> 277</p><p attribs="{'xml:space': 'preserve'}" id="_04477" smilref="Title.smil#_04477"> It is appropriate to repeat here a point raised in Chapter 1 that is easily forgotten and needs reemphasis. Locally, we treat each algorithm in this book as if it were critical in some application. Globally, we try to reach general conclusions about which approach to recommend. Our discussion of such improvements is not necessarily a recommendation to always implement them, rather a warning not to draw absolute conclusions about performance from initial implementations. When addressing a new problem, your best bet is to use the simplest implementation with which you are comfortable and then refine it if it becomes a bottleneck. Addressing improvements that decrease running time just by a constant factor may not otherwise be worthwhile. You need to test the effectiveness of specific improvements by running experiments, as we indicate in exercises throughout. In the case of mergesort, the three improvements just listed are simple to implement and are of interest when mergesort is the method of choice&#8212;for example, in situations discussed at the end of this chapter.</p><p attribs="{'xml:space': 'preserve'}" id="_04478" smilref="Title.smil#_04478"> Bottom-up mergesort The recursive implementation of mergesort is prototypical of the divide-and-conquer algorithm design paradigm, where we solve a large problem by dividing it into pieces, solving the subproblems, then using the solutions for the pieces to solve the whole problem. Even though we are thinking in terms of merging together two large subarrays, the fact is that most merges are merging together tiny subarrays. Another way to implement mergesort is to organize the merges so that we do all the merges of tiny subarrays on one pass, then do a second pass to merge those sub- arrays in pairs, and so forth, continuing until we do a merge that encompasses the whole array. This method requires even less code than the standard recursive implementation. We start by doing a pass of 1-by-1 merges (considering individual items as subarrays of size 1), then a pass of 2-by-2 merges (merge subarrays of size 2 to make subarrays of size 4), then 4-by-4 merges, and so forth. The second subarray may be smaller than the first in the last merge on each pass (which is no problem for merge()), but otherwise all merges involve subar- rays of equal size, doubling the sorted subarray size for the next pass.</p><p attribs="{'xml:space': 'preserve'}" id="_04479" smilref="Title.smil#_04479"> sz = 1</p><p attribs="{'xml:space': 'preserve'}" id="_04480" smilref="Title.smil#_04480"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_04481" smilref="Title.smil#_04481"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_04482" smilref="Title.smil#_04482"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_04483" smilref="Title.smil#_04483"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_04484" smilref="Title.smil#_04484"> Visual trace of bottom-up mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_04485" smilref="Title.smil#_04485" /><pagenum id="p291" page="normal" smilref="Title.smil#p291" /><p attribs="{'xml:space': 'preserve'}" id="_04486" smilref="Title.smil#_04486"> 278</p><p attribs="{'xml:space': 'preserve'}" id="_04487" smilref="Title.smil#_04487"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04488" smilref="Title.smil#_04488"> Bottom-up mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_04489" smilref="Title.smil#_04489"> public class MergeBU { private static Comparable[] aux; // auxiliary array for merges</p><p attribs="{'xml:space': 'preserve'}" id="_04490" smilref="Title.smil#_04490"> // See page 271 for merge() code.</p><p attribs="{'xml:space': 'preserve'}" id="_04491" smilref="Title.smil#_04491"> public static void sort(Comparable[] a) { // Do lg N passes of pairwise merges. int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) // sz: subarray size for (int lo = 0; lo &lt; N-sz; lo += sz+sz) // lo: subarray index merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04492" smilref="Title.smil#_04492"> Bottom-up mergesort consists of a sequence of passes over the whole array, doing sz-by-sz merges, starting with sz equal to 1 and doubling sz on each pass. The final subarray is of size sz only when the array size is an even multiple of sz (otherwise it is less than sz).</p><p attribs="{'xml:space': 'preserve'}" id="_04493" smilref="Title.smil#_04493"> sz = 1</p><p attribs="{'xml:space': 'preserve'}" id="_04494" smilref="Title.smil#_04494"> a[i] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 M E R G E S O R T E X A M P L E merge(a, 0, 0, 1) E M R G E S O R T E X A M P L E merge(a, 2, 2, 3) E M G R E S O R T E X A M P L E merge(a, 4, 4, 5) E M G R E S O R T E X A M P L E merge(a, 6, 6, 7) E M G R E S O R T E X A M P L E merge(a, 8, 8, 9) E M G R E S O R E T X A M P L E merge(a, 10, 10, 11) E M G R E S O R E T A X M P L E merge(a, 12, 12, 13) E M G R E S O R E T A X M P L E merge(a, 14, 14, 15) E M G R E S O R E T A X M P E L</p><p attribs="{'xml:space': 'preserve'}" id="_04495" smilref="Title.smil#_04495"> sz = 2</p><p attribs="{'xml:space': 'preserve'}" id="_04496" smilref="Title.smil#_04496"> merge(a, 0, 1, 3) E G M R E S O R E T A X M P E L merge(a, 4, 5, 7) E G M R E O R S E T A X M P E L merge(a, 8, 9, 11) E G M R E O R S A E T X M P E L merge(a, 12, 13, 15) E G M R E O R S A E T X E L M P</p><p attribs="{'xml:space': 'preserve'}" id="_04497" smilref="Title.smil#_04497"> sz = 4</p><p attribs="{'xml:space': 'preserve'}" id="_04498" smilref="Title.smil#_04498"> merge(a, 0, 3, 7) E E G M O R R S A E T X E L M P merge(a, 8, 11, 15) E E G M O R R S A E E L M P T X</p><p attribs="{'xml:space': 'preserve'}" id="_04499" smilref="Title.smil#_04499"> sz = 8</p><p attribs="{'xml:space': 'preserve'}" id="_04500" smilref="Title.smil#_04500"> merge(a, 0, 7, 15) A E E E E G L M M O P R R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_04501" smilref="Title.smil#_04501"> Trace of merge results for bottom-up mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_04502" smilref="Title.smil#_04502" /></level3><level3 id="_00036"><h3 id="ch2-s2-ss8" smilref="Title.smil#ch2-s2-ss8" xml:space="preserve">N lg N lower bound for sorting</h3><pagenum id="p292" page="normal" smilref="Title.smil#p292" /><p attribs="{'xml:space': 'preserve'}" id="_04503" smilref="Title.smil#_04503"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04504" smilref="Title.smil#_04504"> 279</p><p attribs="{'xml:space': 'preserve'}" id="_04505" smilref="Title.smil#_04505"> Proposition H. Bottom-up mergesort uses between &#189; N lg N and N lg N compares and at most 6N lg N array accesses to sort an array of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_04506" smilref="Title.smil#_04506"> Proof : The number of passes through the array is precisely &#9123;lg N&#9126; (that is precisely the value of n such that 2n &#11349; N &lt; 2n&#11001;1). For each pass, the number of array accesses is exactly 6N and the number of compares is at most N and no less than N/ 2.</p><p attribs="{'xml:space': 'preserve'}" id="_04507" smilref="Title.smil#_04507"> When the array length is a power of 2, top-down and bottom-up mergesort perform precisely the same compares and array accesses, just in a different order. When the array length is not a power of 2, the sequence of compares and array accesses for the two algorithms will be different (see Exercise 2.2.5). A version of bottom-up mergesort is the method of choice for sorting data organized in a linked list. Consider the list to be sorted sublists of size 1, then pass through to make sorted subarrays of size 2 linked together, then size 4, and so forth. This method rearranges the links to sort the list in place (without creating any new list nodes). Both the top-down and bottom-up approaches to implementing a divide-and- conquer algorithm are intuitive. The lesson that you can take from mergesort is this: Whenever you encounter an algorithm based on one of these approaches, it is worth considering the other. Do you want to solve the problem by breaking it up into smaller problems (and solving them recursively) as in Merge.sort() or by building small solutions into larger ones as in MergeBU.sort()?</p><p attribs="{'xml:space': 'preserve'}" id="_04508" smilref="Title.smil#_04508"> The complexity of sorting One important reason to know about mergesort is that we use it as the basis for proving a fundamental result in the field of computational complexity that helps us understand the intrinsic difficulty of sorting. In general, computational complexity plays an important role in the design of algorithms, and this result in particular is directly relevant to the design of sorting algorithms, so we next consider it in detail. The first step in a study of complexity is to establish a model of computation. Gen- erally, researchers strive to understand the simplest model relevant to a problem. For sorting, we study the class of compare-based algorithms that make their decisions about items only on the basis of comparing keys. A compare-based algorithm can do an arbitrary amount of computation between compares, but cannot get any information about a key except by comparing it with another one. Because of our restriction to the Comparable API, all of the algorithms in this chapter are in this class (note that we are ignoring the cost of array accesses), as are many algorithms that we might imagine. In Chapter 5, we consider algorithms that are not restricted to Comparable items.</p><p attribs="{'xml:space': 'preserve'}" id="_04509" smilref="Title.smil#_04509" /><pagenum id="p293" page="normal" smilref="Title.smil#p293" /><p attribs="{'xml:space': 'preserve'}" id="_04510" smilref="Title.smil#_04510"> 280</p><p attribs="{'xml:space': 'preserve'}" id="_04511" smilref="Title.smil#_04511"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04512" smilref="Title.smil#_04512"> Proposition I. No compare-based sorting algorithm can guarantee to sort N items with fewer than lg(N !) ~ N lg N compares.</p><p attribs="{'xml:space': 'preserve'}" id="_04513" smilref="Title.smil#_04513"> Proof : First, we assume that the keys are all distinct, since any algorithm must be able to sort such inputs. Now, we use a binary tree to describe the sequence of com- pares. Each node in the tree is either a leaf i0 i1 i2 ... iN-1 that indicates that the sort is complete and has discovered that the original inputs were in the order a[i0], a[i1], ...a[iN-1], or an internal node i:j that corresponds to a compare operation between a[i] and a[j], with a left subtree corresponding to the sequence of compares in the case that a[i] is less than a[j], and a right subtree corresponding to what happens if a[i] is greater than a[j]. Each path from the root to a leaf corresponds to the sequence of compares that the algorithm uses to establish the ordering given in the leaf. For example, here is a compare tree for N = 3:</p><p attribs="{'xml:space': 'preserve'}" id="_04514" smilref="Title.smil#_04514"> 0:1</p><p attribs="{'xml:space': 'preserve'}" id="_04515" smilref="Title.smil#_04515"> 1:2</p><p attribs="{'xml:space': 'preserve'}" id="_04516" smilref="Title.smil#_04516"> 0:2</p><p attribs="{'xml:space': 'preserve'}" id="_04517" smilref="Title.smil#_04517"> 0 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_04518" smilref="Title.smil#_04518"> 0:2</p><p attribs="{'xml:space': 'preserve'}" id="_04519" smilref="Title.smil#_04519"> 1 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_04520" smilref="Title.smil#_04520"> 1:2</p><p attribs="{'xml:space': 'preserve'}" id="_04521" smilref="Title.smil#_04521"> 0 2 1</p><p attribs="{'xml:space': 'preserve'}" id="_04522" smilref="Title.smil#_04522"> 2 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_04523" smilref="Title.smil#_04523"> 1 2 0</p><p attribs="{'xml:space': 'preserve'}" id="_04524" smilref="Title.smil#_04524"> 2 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_04525" smilref="Title.smil#_04525"> We never explicitly construct such a tree&#8212;it is a mathematical device for describing the compares used by any algorithm. The first key observation in the proof is that the tree must have at least N ! leaves because there are N ! different permutations of N distinct keys. If there are fewer than N ! leaves, then some permutation is missing from the leaves, and the algorithm would fail for that permutation. The number of internal nodes on a path from the root to a leaf in the tree is the number of compares used by the algorithm for some input. We are interested in the length of the longest such path in the tree (known as the tree height) since it measures the worst-case number of compares used by the algorithm. Now, it is a basic combinatorial property of binary trees that a tree of height h has no more than 2h leaves&#8212;the tree of height h with the maximum number of leaves is perfectly bal- anced, or complete. An example for h = 4 is diagrammed on the next page.</p><p attribs="{'xml:space': 'preserve'}" id="_04526" smilref="Title.smil#_04526" /><pagenum id="p294" page="normal" smilref="Title.smil#p294" /><p attribs="{'xml:space': 'preserve'}" id="_04527" smilref="Title.smil#_04527"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04528" smilref="Title.smil#_04528"> 281</p><p attribs="{'xml:space': 'preserve'}" id="_04529" smilref="Title.smil#_04529"> complete tree of height 4 (gray) has 2 4 = 16 leaves</p><p attribs="{'xml:space': 'preserve'}" id="_04530" smilref="Title.smil#_04530"> any other tree of height 4 (black) has fewer than 16 leaves</p><p attribs="{'xml:space': 'preserve'}" id="_04531" smilref="Title.smil#_04531"> Combining the previous two paragraphs, we have shown that any compare-based sorting algorithm corresponds to a compare tree of height h with N ! &#11349; number of leaves &#11349; 2h</p><p attribs="{'xml:space': 'preserve'}" id="_04532" smilref="Title.smil#_04532"> h</p><p attribs="{'xml:space': 'preserve'}" id="_04533" smilref="Title.smil#_04533"> at least N! leaves</p><p attribs="{'xml:space': 'preserve'}" id="_04534" smilref="Title.smil#_04534"> no more than 2h leaves</p><p attribs="{'xml:space': 'preserve'}" id="_04535" smilref="Title.smil#_04535"> The value of h is precisely the worst-case number of compares, so we can take the logarithm (base 2) of both sides of this equation and conclude that the number of compares used by any algorithm must be at least lg N ! . The approximation lg N ! ~ N lg N follows immediately from Stirling&#8217;s approximation to the factorial function (see page 185).</p><p attribs="{'xml:space': 'preserve'}" id="_04536" smilref="Title.smil#_04536"> This result serves as a guide for us to know, when designing a sorting algorithm, how well we can expect to do. For example, without such a result, one might set out to try to design a compare-based sorting algorithm that uses half as many compares as does mergesort, in the worst case. The lower bound in Proposition I says that such an effort is futile&#8212;no such algorithm exists. It is an extremely strong statement that applies to any conceivable compare-based algorithm. Proposition H asserts that the number of compares used by mergesort in the worst case is ~ N lg N. This result is an upper bound on the difficulty of the sorting problem in the sense that a better algorithm would have to guarantee to use a smaller number of compares. Proposition I asserts that no sorting algorithm can guarantee to use fewer</p><p attribs="{'xml:space': 'preserve'}" id="_04537" smilref="Title.smil#_04537" /><pagenum id="p295" page="normal" smilref="Title.smil#p295" /><p attribs="{'xml:space': 'preserve'}" id="_04538" smilref="Title.smil#_04538"> 282</p><p attribs="{'xml:space': 'preserve'}" id="_04539" smilref="Title.smil#_04539"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04540" smilref="Title.smil#_04540"> than ~ N lg N compares. It is a lower bound on the difficulty of the sorting problem in the sense that even the best possible algorithm must use at least that many compares in the worst case. Together, they imply :</p><p attribs="{'xml:space': 'preserve'}" id="_04541" smilref="Title.smil#_04541"> Proposition J. Mergesort is an asymptotically optimal compare-based sorting algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_04542" smilref="Title.smil#_04542"> Proof : Precisely, we mean by this statement that both the number of compares used by mergesort in the worst case and the minimum number of compares that any com- pare-based sorting algorithm can guarantee are ~N lg N. Propositions H and I establish these facts.</p><p attribs="{'xml:space': 'preserve'}" id="_04543" smilref="Title.smil#_04543"> It is important to note that, like the model of computation, we need to precisely define what we mean by an optimal algorithm. For example, we might tighten the definition of optimality and insist that an optimal algorithm for sorting is one that uses precisely lg N! compares. We do not do so because we could not notice the difference between such an algorithm and (for example) mergesort for large N. Or, we might broaden the definition of optimality to include any sorting algorithm whose worst-case number of compares is within a constant factor of N lg N. We do not do so because we might very well notice the difference between such an algorithm and mergesort for large N.</p><p attribs="{'xml:space': 'preserve'}" id="_04544" smilref="Title.smil#_04544"> Computational complexity may seem rather abstract, but fundamental re-</p><p attribs="{'xml:space': 'preserve'}" id="_04545" smilref="Title.smil#_04545"> search on the intrinsic difficulty of solving computational problems hardly needs jus- ti&#64257; cation. Moreover, when it does apply, it is emphatically the case that computational complexity affects the development of good software. First, good upper bounds allow software engineers to provide performance guarantees; there are many documented instances where poor performance has been traced to someone using a quadratic sort instead of a linearithmic one. Second, good lower bounds spare us the effort of searching for performance improvements that are not attainable. But the optimality of mergesort is not the end of the story and should not be misused to indicate that we need not consider other methods for practical applications. That is not the case because the theory in this section has a number of limitations. For example: </p><p attribs="{'xml:space': 'preserve'}" id="_04546" smilref="Title.smil#_04546" /><pagenum id="p296" page="normal" smilref="Title.smil#p296" /><p attribs="{'xml:space': 'preserve'}" id="_04547" smilref="Title.smil#_04547"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04548" smilref="Title.smil#_04548"> 283</p><p attribs="{'xml:space': 'preserve'}" id="_04549" smilref="Title.smil#_04549"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_04550" smilref="Title.smil#_04550"> Q. Is mergesort faster than shellsort? A. In practice, their running times are within a small constant factor of one another (when shellsort is using a well-tested increment sequence like the one in Algorithm 2.3), so comparative performance depends on the implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_04551" smilref="Title.smil#_04551"> % java SortCompare Merge Shell 100000 For 100000 random Double values Merge is 1.2 times faster than Shell</p><p attribs="{'xml:space': 'preserve'}" id="_04552" smilref="Title.smil#_04552"> In theory, no one has been able to prove that shellsort is linearithmic for random data, so there remains the possibility that the asymptotic growth of the average-case performance of shellsort is higher. Such a gap has been proven for worst-case performance, but it is not relevant in practice. Q. Why not make the aux[] array local to merge()? A. To avoid the overhead of creating an array for every merge, even the tiny ones. This cost would dominate the running time of mergesort (see Exercise 2.2.26). A more proper solution (which we avoid in the text to reduce clutter in the code) is to make aux[] local to sort() and pass it as an argument to merge() (see Exercise 2.2.9). Q. How does mergesort fare when there are duplicate values in the array? A. If all the items have the same value, the running time is linear (with the extra test to skip the merge when the array is sorted), but if there is more than one duplicate value, this performance gain is not necessarily realized. For example, suppose that the input array consists of N items with one value in odd positions and N items with another value in even positions. The running time is linearithmic for such an array (it satisfies the same recurrence as for items with distinct values), not linear.</p><p attribs="{'xml:space': 'preserve'}" id="_04553" smilref="Title.smil#_04553" /><pagenum id="p297" page="normal" smilref="Title.smil#p297" /><p attribs="{'xml:space': 'preserve'}" id="_04554" smilref="Title.smil#_04554"> 284</p><p attribs="{'xml:space': 'preserve'}" id="_04555" smilref="Title.smil#_04555"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04556" smilref="Title.smil#_04556"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_04557" smilref="Title.smil#_04557"> 2.2.1 Give a trace, in the style of the trace given at the beginning of this section, showing how the keys A E Q S U Y E I N O S T are merged with the abstract in-place merge() method. 2.2.2 Give traces, in the style of the trace given with Algorithm 2.4, showing how the keys E A S Y Q U E S T I O N are sorted with top-down mergesort. 2.2.3 Answer Exercise 2.2.2 for bottom-up mergesort. 2.2.4 Does the abstract in-place merge produce proper output if and only if the two input subarrays are in sorted order? Prove your answer, or provide a counterexample. 2.2.5 Give the sequence of subarray sizes in the merges performed by both the top- down and the bottom-up mergesort algorithms, for N = 39. 2.2.6 Write a program to compute the exact value of the number of array accesses used by top-down mergesort and by bottom-up mergesort. Use your program to plot the values for N from 1 to 512, and to compare the exact values with the upper bound 6N lg N. 2.2.7 Show that the number of compares used by mergesort is monotonically increasing (C(N+1) &gt; C(N) for all N &gt; 0). 2.2.8 Suppose that Algorithm 2.4 is modified to skip the call on merge() whenever a[mid] &lt;= a[mid+1]. Prove that the number of compares used to mergesort a sorted array is linear. 2.2.9 Use of a static array like aux[] is inadvisable in library software because multiple clients might use the class concurrently. Give an implementation of Merge that does not use a static array. Do not make aux[] local to merge() (see the Q&amp;A for this section). Hint : Pass the auxiliary array as an argument to the recursive sort().</p><p attribs="{'xml:space': 'preserve'}" id="_04558" smilref="Title.smil#_04558" /><pagenum id="p298" page="normal" smilref="Title.smil#p298" /><p attribs="{'xml:space': 'preserve'}" id="_04559" smilref="Title.smil#_04559"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04560" smilref="Title.smil#_04560"> 285</p><p attribs="{'xml:space': 'preserve'}" id="_04561" smilref="Title.smil#_04561"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_04562" smilref="Title.smil#_04562"> 2.2.10 Faster merge. Implement a version of merge() that copies the second half of a[] to aux[] in decreasing order and then does the merge back to a[]. This change allows you to remove the code to test that each of the halves has been exhausted from the inner loop. Note: The resulting sort is not stable (see page 341). 2.2.11 Improvements. Implement the three improvements to mergesort that are described in the text on page 275: Add a cutoff for small subarrays, test whether the array is already in order, and avoid the copy by switching arguments in the recursive code. 2.2.12 Sublinear extra space. Develop a merge implementation that reduces the extra space requirement to max(M, N/M), based on the following idea: Divide the array into N/M blocks of size M (for simplicity in this description, assume that N is a multiple of M). Then, (i) considering the blocks as items with their first key as the sort key, sort them using selection sort; and (ii) run through the array merging the first block with the second, then the second block with the third, and so forth. 2.2.13 Lower bound for average case. Prove that the expected number of compares used by any compare-based sorting algorithm must be at least ~N lg N (assuming that all possible orderings of the input are equally likely). Hint: The expected number of compares is at least the external path length of the compare tree (the sum of the lengths of the paths from the root to all leaves), which is minimized when it is balanced. 2.2.14 Merging sorted queues. Develop a static method that takes two queues of sorted items as arguments and returns a queue that results from merging the queues into sorted order. 2.2.15 Bottom-up queue mergesort. Develop a bottom-up mergesort implementation based on the following approach: Given N items, create N queues, each containing one of the items. Create a queue of the N queues. Then repeatedly apply the merging operation of Exercise 2.2.14 to the first two queues and reinsert the merged queue at the end. Repeat until the queue of queues contains only one queue. 2.2.16 Natural mergesort. Write a version of bottom-up mergesort that takes advantage of order in the array by proceeding as follows each time it needs to find two arrays to merge: find a sorted subarray (by incrementing a pointer until finding an entry that is smaller than its predecessor in the array), then find the next, then merge them. Ana- lyze the running time of this algorithm in terms of the array size and the number of</p><p attribs="{'xml:space': 'preserve'}" id="_04563" smilref="Title.smil#_04563" /><pagenum id="p299" page="normal" smilref="Title.smil#p299" /><p attribs="{'xml:space': 'preserve'}" id="_04564" smilref="Title.smil#_04564"> 286</p><p attribs="{'xml:space': 'preserve'}" id="_04565" smilref="Title.smil#_04565"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04566" smilref="Title.smil#_04566"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04567" smilref="Title.smil#_04567"> maximal increasing sequences in the array. 2.2.17 Linked-list sort. Implement a natural mergesort for linked lists. (This is the method of choice for sorting linked lists because it uses no extra space and is guaranteed to be linearithmic.) 2.2.18 Shuf&#64258; ing a linked list. Develop and implement a divide-and-conquer algorithm that randomly shuffles a linked list in linearithmic time and logarithmic extra space. 2.2.19 Inversions. Develop and implement a linearithmic algorithm for computing the number of inversions in a given array (the number of exchanges that would be performed by insertion sort for that array&#8212;see Section 2.1). This quantity is related to the Kendall tau distance; see Section 2.5. 2.2.20 Index sort. Develop and implement a version of mergesort that does not rearrange the array, but returns an int[] array perm such that perm[i] is the index of the i th smallest entry in the array. 2.2.21 Triplicates. Given three lists of N names each, devise a linearithmic algorithm to determine if there is any name common to all three lists, and if so, return the first such name. 2.2.22 3-way mergesort. Suppose instead of dividing in half at each step, you divide into thirds, sort each third, and combine using a 3-way merge. What is the order of growth of the overall running time of this algorithm?</p><p attribs="{'xml:space': 'preserve'}" id="_04568" smilref="Title.smil#_04568" /><pagenum id="p300" page="normal" smilref="Title.smil#p300" /><p attribs="{'xml:space': 'preserve'}" id="_04569" smilref="Title.smil#_04569"> 2 .2 </p><p attribs="{'xml:space': 'preserve'}" id="_04570" smilref="Title.smil#_04570"> 287</p><p attribs="{'xml:space': 'preserve'}" id="_04571" smilref="Title.smil#_04571"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_04572" smilref="Title.smil#_04572"> 2.2.23 Improvements. Run empirical studies to evaluate the effectiveness of each of the three improvements to mergesort that are described in the text (see Exercise 2.2.11). Also, compare the performance of the merge implementation given in the text with the merge described in Exercise 2.2.10. In particular, empirically determine the best value of the parameter that decides when to switch to insertion sort for small subarrays. 2.2.24 Sort-test improvement. Run empirical studies for large randomly ordered arrays to study the effectiveness of the modification described in Exercise 2.2.8 for random data. In particular, develop a hypothesis about the average number of times the test (whether an array is sorted) succeeds, as a function of N (the original array size for the sort). 2.2.25 Multiway mergesort. Develop a mergesort implementation based on the idea of doing k-way merges (rather than 2-way merges). Analyze your algorithm, develop a hypothesis regarding the best value of k, and run experiments to validate your hypothesis. 2.2.26 Array creation. Use SortCompare to get a rough idea of the effect on performance on your machine of creating aux[] in merge() rather than in sort(). 2.2.27 Subarray lengths. Run mergesort for large random arrays, and make an empirical determination of the average length of the other subarray when the first subarray exhausts, as a function of N (the sum of the two subarray sizes for a given merge). 2.2.28 Top-down versus bottom-up. Use SortCompare to compare top-down and bot- tom-up mergesort for N=103, 104, 105, and 106. 2.2.29 Natural mergesort. Determine empirically the number of passes needed in a natural mergesort (see Exercise 2.2.16) for random Long keys with N=103, 106, and 109. Hint: You do not need to implement a sort (or even generate full 64-bit keys) to complete this exercise.</p><p attribs="{'xml:space': 'preserve'}" id="_04573" smilref="Title.smil#_04573" /><pagenum id="p302" page="normal" smilref="Title.smil#p302" /><p attribs="{'xml:space': 'preserve'}" id="_04574" smilref="Title.smil#_04574"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04575" smilref="Title.smil#_04575"> 289</p><p attribs="{'xml:space': 'preserve'}" id="_04576" smilref="Title.smil#_04576"> ALGORITHM 2.5</p><p attribs="{'xml:space': 'preserve'}" id="_04577" smilref="Title.smil#_04577"> Quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_04578" smilref="Title.smil#_04578"> public class Quick { public static void sort(Comparable[] a) { StdRandom.shuffle(a); sort(a, 0, a.length - 1); }</p><p attribs="{'xml:space': 'preserve'}" id="_04579" smilref="Title.smil#_04579"> // Eliminate dependence on input.</p><p attribs="{'xml:space': 'preserve'}" id="_04580" smilref="Title.smil#_04580"> private static void sort(Comparable[] a, int lo, int hi) { if (hi &lt;= lo) return; int j = partition(a, lo, hi); // Partition (see page 291). sort(a, lo, j-1); // Sort left part a[lo .. j-1]. sort(a, j+1, hi); // Sort right part a[j+1 .. hi]. } }</p><p attribs="{'xml:space': 'preserve'}" id="_04581" smilref="Title.smil#_04581"> Quicksort is a recursive program that sorts a subarray a[lo...hi] by using a partition() method that puts a[j] into position and arranges the rest of the entries such that the recursive calls finish the sort.</p><p attribs="{'xml:space': 'preserve'}" id="_04582" smilref="Title.smil#_04582"> initial values random shuffle</p><p attribs="{'xml:space': 'preserve'}" id="_04583" smilref="Title.smil#_04583"> no partition for subarrays of size 1</p><p attribs="{'xml:space': 'preserve'}" id="_04584" smilref="Title.smil#_04584"> lo j hi 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Q U I C K S O R T E X A M P L E K R A T E L E P U I M Q C X O S 0 5 15 E C A I E K L P U T M Q R X O S 0 3 4 E C A E I K L P U T M Q R X O S 0 2 2 A C E E I K L P U T M Q R X O S 0 0 1 A C E E I K L P U T M Q R X O S 1 1 A C E E I K L P U T M Q R X O S 4 4 A C E E I K L P U T M Q R X O S 6 6 15 A C E E I K L P U T M Q R X O S 7 9 15 A C E E I K L M O P T Q R X U S 7 7 8 A C E E I K L M O P T Q R X U S 8 8 A C E E I K L M O P T Q R X U S 10 13 15 A C E E I K L M O P S Q R T U X 10 12 12 A C E E I K L M O P R Q S T U X 10 11 11 A C E E I K L M O P Q R S T U X 10 10 A C E E I K L M O P Q R S T U X 14 14 15 A C E E I K L M O P Q R S T U X 15 15 A C E E I K L M O P Q R S T U X</p><p attribs="{'xml:space': 'preserve'}" id="_04585" smilref="Title.smil#_04585"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04586" smilref="Title.smil#_04586"> A C E E I K L M O P Q R S T U X</p><p attribs="{'xml:space': 'preserve'}" id="_04587" smilref="Title.smil#_04587" /><pagenum id="p303" page="normal" smilref="Title.smil#p303" /><p attribs="{'xml:space': 'preserve'}" id="_04588" smilref="Title.smil#_04588"> 290</p><p attribs="{'xml:space': 'preserve'}" id="_04589" smilref="Title.smil#_04589"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04590" smilref="Title.smil#_04590"> before</p><p attribs="{'xml:space': 'preserve'}" id="_04591" smilref="Title.smil#_04591"> during</p><p attribs="{'xml:space': 'preserve'}" id="_04592" smilref="Title.smil#_04592"> after</p><p attribs="{'xml:space': 'preserve'}" id="_04593" smilref="Title.smil#_04593"> v</p><p attribs="{'xml:space': 'preserve'}" id="_04594" smilref="Title.smil#_04594"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04595" smilref="Title.smil#_04595"> v</p><p attribs="{'xml:space': 'preserve'}" id="_04596" smilref="Title.smil#_04596"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04597" smilref="Title.smil#_04597"> The crux of the method is the partitioning process, which rearranges the array to make the following three conditions hold: </p><p attribs="{'xml:space': 'preserve'}" id="_04598" smilref="Title.smil#_04598"> &#11350; v</p><p attribs="{'xml:space': 'preserve'}" id="_04599" smilref="Title.smil#_04599"> &#11349; v</p><p attribs="{'xml:space': 'preserve'}" id="_04600" smilref="Title.smil#_04600"> v</p><p attribs="{'xml:space': 'preserve'}" id="_04601" smilref="Title.smil#_04601"> j</p><p attribs="{'xml:space': 'preserve'}" id="_04602" smilref="Title.smil#_04602"> i</p><p attribs="{'xml:space': 'preserve'}" id="_04603" smilref="Title.smil#_04603"> j</p><p attribs="{'xml:space': 'preserve'}" id="_04604" smilref="Title.smil#_04604"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04605" smilref="Title.smil#_04605"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04606" smilref="Title.smil#_04606"> &#11349; v</p><p attribs="{'xml:space': 'preserve'}" id="_04607" smilref="Title.smil#_04607"> &#11350; v</p><p attribs="{'xml:space': 'preserve'}" id="_04608" smilref="Title.smil#_04608"> Quicksort partitioning overview</p><p attribs="{'xml:space': 'preserve'}" id="_04609" smilref="Title.smil#_04609" /><pagenum id="p304" page="normal" smilref="Title.smil#p304" /><p attribs="{'xml:space': 'preserve'}" id="_04610" smilref="Title.smil#_04610"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04611" smilref="Title.smil#_04611"> 291</p><p attribs="{'xml:space': 'preserve'}" id="_04612" smilref="Title.smil#_04612"> Quicksort partitioning</p><p attribs="{'xml:space': 'preserve'}" id="_04613" smilref="Title.smil#_04613"> private static int partition(Comparable[] a, int lo, int hi) { // Partition into a[lo..i-1], a[i], a[i+1..hi]. int i = lo, j = hi+1; // left and right scan indices Comparable v = a[lo]; // partitioning item while (true) { // Scan right, scan left, check for scan complete, and exchange. while (less(a[++i], v)) if (i == hi) break; while (less(v, a[--j])) if (j == lo) break; if (i &gt;= j) break; exch(a, i, j); } exch(a, lo, j); // Put v = a[j] into position return j; // with a[lo..j-1] &lt;= a[j] &lt;= a[j+1..hi]. }</p><p attribs="{'xml:space': 'preserve'}" id="_04614" smilref="Title.smil#_04614"> This code partitions on the item v in a[lo]. The main loop exits when the scan indices i and j cross. Within the loop, we increment i while a[i] is less than v and decrement j while a[j] is greater than v, then do an exchange to maintain the invariant property that no entries to the left of i are greater than v and no entries to the right of j are smaller than v. Once the indices meet, we complete the partitioning by exchanging a[lo] with a[j] (thus leaving the partitioning value in a[j]).</p><p attribs="{'xml:space': 'preserve'}" id="_04615" smilref="Title.smil#_04615"> a[] v i j 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</p><p attribs="{'xml:space': 'preserve'}" id="_04616" smilref="Title.smil#_04616"> initial values</p><p attribs="{'xml:space': 'preserve'}" id="_04617" smilref="Title.smil#_04617"> 0 16 K R A T E L E P U I M Q C X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04618" smilref="Title.smil#_04618"> scan left, scan right</p><p attribs="{'xml:space': 'preserve'}" id="_04619" smilref="Title.smil#_04619"> 1 12 K R A T E L E P U I M Q C X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04620" smilref="Title.smil#_04620"> exchange</p><p attribs="{'xml:space': 'preserve'}" id="_04621" smilref="Title.smil#_04621"> 1 12 K C A T E L E P U I M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04622" smilref="Title.smil#_04622"> scan left, scan right</p><p attribs="{'xml:space': 'preserve'}" id="_04623" smilref="Title.smil#_04623"> 3 9 K C A T E L E P U I M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04624" smilref="Title.smil#_04624"> exchange</p><p attribs="{'xml:space': 'preserve'}" id="_04625" smilref="Title.smil#_04625"> 3 9 K C A I E L E P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04626" smilref="Title.smil#_04626"> scan left, scan right</p><p attribs="{'xml:space': 'preserve'}" id="_04627" smilref="Title.smil#_04627"> 5 6 K C A I E L E P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04628" smilref="Title.smil#_04628"> exchange</p><p attribs="{'xml:space': 'preserve'}" id="_04629" smilref="Title.smil#_04629"> 5 6 K C A I E E L P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04630" smilref="Title.smil#_04630"> scan left, scan right</p><p attribs="{'xml:space': 'preserve'}" id="_04631" smilref="Title.smil#_04631"> 6 5 K C A I E E L P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04632" smilref="Title.smil#_04632"> final exchange</p><p attribs="{'xml:space': 'preserve'}" id="_04633" smilref="Title.smil#_04633"> 6 5 E C A I E K L P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04634" smilref="Title.smil#_04634"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04635" smilref="Title.smil#_04635"> 5 E C A I E K L P U T M Q R X O S</p><p attribs="{'xml:space': 'preserve'}" id="_04636" smilref="Title.smil#_04636"> Partitioning trace (array contents before and after each exchange)</p><p attribs="{'xml:space': 'preserve'}" id="_04637" smilref="Title.smil#_04637" /></level3><level3 id="_00037"><h3 id="ch2-s3-ss9" smilref="Title.smil#ch2-s3-ss9" xml:space="preserve">In-place partitioning</h3><pagenum id="p305" page="normal" smilref="Title.smil#p305" /><p attribs="{'xml:space': 'preserve'}" id="_04638" smilref="Title.smil#_04638"> 292</p><p attribs="{'xml:space': 'preserve'}" id="_04639" smilref="Title.smil#_04639"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04640" smilref="Title.smil#_04640"> Partitioning in place. If we use an extra array, partitioning is easy to implement, but not so much easier that it is worth the extra cost of copying the partitioned version back into the original. A novice Java programmer might even create a new spare array within the recursive method, for each partition, which would drastically slow down the sort.</p><p attribs="{'xml:space': 'preserve'}" id="_04641" smilref="Title.smil#_04641"> Staying in bounds. If the smallest item or the largest item in the array is the partitioning item, we have to take care that the pointers do not run off the left or right ends of the array, respectively. Our partition() implementation has explicit tests to guard against this circumstance. The test (j == lo) is redundant, since the partitioning item is at a[lo] and not less than itself. With a similar technique on the right it is not dif- fi cult to eliminate both tests (see Exercise 2.3.17). Preserving randomness. The random shuffle puts the array in random order. Since it treats all items in the subarrays uniformly, Algorithm 2.5 has the property that its two subarrays are also in random order. This fact is crucial to the predictability of the algo- rithm&#8217;s running time. An alternate way to preserve randomness is to choose a random item for partitioning within partition().</p><p attribs="{'xml:space': 'preserve'}" id="_04642" smilref="Title.smil#_04642"> Terminating the loop. Experienced programmers know to take special care to ensure that any loop must always terminate, and the partitioning loop for quicksort is no ex- ception. Properly testing whether the pointers have crossed is a bit trickier than it might seem at first glance. A common error is to fail to take into account that the array might contain other items with the same key value as the partitioning item.</p><p attribs="{'xml:space': 'preserve'}" id="_04643" smilref="Title.smil#_04643"> Handling items with keys equal to the partitioning item&#8217;s key. It is best to stop the</p><p attribs="{'xml:space': 'preserve'}" id="_04644" smilref="Title.smil#_04644"> left scan for items with keys greater than or equal to the partitioning item&#8217;s key and the right scan for items with key less than or equal to the partitioning item&#8217;s key, as in Algorithm 2.5. Even though this policy might seem to create unnecessary exchanges involving items with keys equal to the partitioning item&#8217;s key, it is crucial to avoiding quadratic running time in certain typical applications (see Exercise 2.3.11). Later, we discuss a better strategy for the case when the array contains a large number of items with equal keys.</p><p attribs="{'xml:space': 'preserve'}" id="_04645" smilref="Title.smil#_04645"> Terminating the recursion. Experienced programmers also know to take special care to ensure that any recursive method must always terminate, and quicksort is again no exception. For instance, a common mistake in implementing quicksort involves not ensuring that one item is always put into position, then falling into an infinite recursive loop when the partitioning item happens to be the largest or smallest item in the array.</p><p attribs="{'xml:space': 'preserve'}" id="_04646" smilref="Title.smil#_04646" /></level3><level3 id="_00038"><h3 id="ch2-s3-ss10" smilref="Title.smil#ch2-s3-ss10" xml:space="preserve">Randomized quicksort</h3><p attribs="{'xml:space': 'preserve'}" id="_04647" smilref="Title.smil#_04647"> 292</p><p attribs="{'xml:space': 'preserve'}" id="_04648" smilref="Title.smil#_04648"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04649" smilref="Title.smil#_04649"> Partitioning in place. If we use an extra array, partitioning is easy to implement, but not so much easier that it is worth the extra cost of copying the partitioned version back into the original. A novice Java programmer might even create a new spare array within the recursive method, for each partition, which would drastically slow down the sort.</p><p attribs="{'xml:space': 'preserve'}" id="_04650" smilref="Title.smil#_04650"> Staying in bounds. If the smallest item or the largest item in the array is the partitioning item, we have to take care that the pointers do not run off the left or right ends of the array, respectively. Our partition() implementation has explicit tests to guard against this circumstance. The test (j == lo) is redundant, since the partitioning item is at a[lo] and not less than itself. With a similar technique on the right it is not dif- fi cult to eliminate both tests (see Exercise 2.3.17). Preserving randomness. The random shuffle puts the array in random order. Since it treats all items in the subarrays uniformly, Algorithm 2.5 has the property that its two subarrays are also in random order. This fact is crucial to the predictability of the algo- rithm&#8217;s running time. An alternate way to preserve randomness is to choose a random item for partitioning within partition().</p><p attribs="{'xml:space': 'preserve'}" id="_04651" smilref="Title.smil#_04651"> Terminating the loop. Experienced programmers know to take special care to ensure that any loop must always terminate, and the partitioning loop for quicksort is no ex- ception. Properly testing whether the pointers have crossed is a bit trickier than it might seem at first glance. A common error is to fail to take into account that the array might contain other items with the same key value as the partitioning item.</p><p attribs="{'xml:space': 'preserve'}" id="_04652" smilref="Title.smil#_04652"> Handling items with keys equal to the partitioning item&#8217;s key. It is best to stop the</p><p attribs="{'xml:space': 'preserve'}" id="_04653" smilref="Title.smil#_04653"> left scan for items with keys greater than or equal to the partitioning item&#8217;s key and the right scan for items with key less than or equal to the partitioning item&#8217;s key, as in Algorithm 2.5. Even though this policy might seem to create unnecessary exchanges involving items with keys equal to the partitioning item&#8217;s key, it is crucial to avoiding quadratic running time in certain typical applications (see Exercise 2.3.11). Later, we discuss a better strategy for the case when the array contains a large number of items with equal keys.</p><p attribs="{'xml:space': 'preserve'}" id="_04654" smilref="Title.smil#_04654"> Terminating the recursion. Experienced programmers also know to take special care to ensure that any recursive method must always terminate, and quicksort is again no exception. For instance, a common mistake in implementing quicksort involves not ensuring that one item is always put into position, then falling into an infinite recursive loop when the partitioning item happens to be the largest or smallest item in the array.</p><p attribs="{'xml:space': 'preserve'}" id="_04655" smilref="Title.smil#_04655" /><p attribs="{'xml:space': 'preserve'}" id="_04656" smilref="Title.smil#_04656"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04657" smilref="Title.smil#_04657"> 293</p><p attribs="{'xml:space': 'preserve'}" id="_04658" smilref="Title.smil#_04658"> Performance characteristics Quicksort has been subjected to very thorough mathematical analysis, so that we can make precise statements about its performance. The analysis has been validated through extensive empirical experience, and is a useful tool in tuning the algorithm for optimum performance. The inner loop of quicksort (in the partitioning method) increments an index and compares an array entry against a fixed value. This simplicity is one factor that makes quicksort quick: it is hard to envision a shorter inner loop in a sorting algorithm. For example, mergesort and shellshort are typically slower than quicksort because they also do data movement within their inner loops. The second factor that makes quicksort quick is that it uses few compares. Ulti- mately, the efficiency of the sort depends on how well the partitioning divides the array, which in turn depends on the value of the partitioning item&#8217;s key. Partitioning divides a large randomly ordered array into two smaller randomly ordered subarrays, but the actual split is equally likely (for distinct keys) to be anywhere in the array. Next, we consider the analysis of the algorithm, which allows us to see how this choice compares to the ideal choice. The best case for quicksort is when each partitioning stage divides the array exactly in half. This circumstance would make the number of compares used by quicksort satisfy the divide-and-conquer recurrence CN = 2CN/2 + N. The 2CN/2 term covers the cost of sorting the two subarrays; the N is the cost of examining each entry, using one partitioning index or the other. As in the proof of Proposition F for mergesort, we know that this recurrence has the solution CN ~ N lg N. Although things do not always go this well, it is true that the partition falls in the middle on the average. Taking into account the precise probability of each partition position makes the recurrence more complicated and more difficult to solve, but the final result is similar. The proof of this result is the basis for our confidence in quicksort. If you are not mathematically inclined, you may wish to skip (and trust) it; if you are mathematically inclined, you may find it intriguing.</p><p attribs="{'xml:space': 'preserve'}" id="_04659" smilref="Title.smil#_04659"> Proposition K. Quicksort uses ~ 2N ln N compares (and one-sixth that many ex- changes) on the average to sort an array of length N with distinct keys. Proof : Let CN be the average number of compares needed to sort N items with distinct values. We have C0 = C1 = 0 and for N &gt; 1 we can write a recurrence relationship that directly mirrors the recursive program:</p><p attribs="{'xml:space': 'preserve'}" id="_04660" smilref="Title.smil#_04660" /><p attribs="{'xml:space': 'preserve'}" id="_04661" smilref="Title.smil#_04661"> 294</p><p attribs="{'xml:space': 'preserve'}" id="_04662" smilref="Title.smil#_04662"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04663" smilref="Title.smil#_04663"> CN = N &#11001; 1 &#11001; (C0 &#11001; C1 &#11001;. . .&#11001; CN&#11002;2 &#11001; CN&#11002;1) / N + (CN&#11002;1 &#11001; CN&#11002;2 &#11001;. . .&#11001; C0 )/N The first term is the cost of partitioning (always N &#11001; 1), the second term is the average cost of sorting the left subarray (which is equally likely to be any size from 0 to N &#11002; 1), and the third term is the average cost for the right subarray (which is the same as for the left subarray). Multiplying by N and collecting terms transforms this equation to</p><p attribs="{'xml:space': 'preserve'}" id="_04664" smilref="Title.smil#_04664"> NCN = N(N &#11001; 1) + 2(C0 + C1+ . . .+CN&#11002;2+CN&#11002;1) Subtracting this from the same equation for N &#11002; 1 gives NCN &#11002; (N &#11002; 1)CN&#11002;1= 2N + 2CN&#11002;1 Rearranging terms and dividing by N(N &#11001; 1) leaves CN /(N &#11001; 1) = CN&#11002;1 /N &#11001; 2 /(N &#11001; 1) which telescopes to give the result CN ~ 2 (N &#11001; 1)(1/3 &#11001; 1/4 &#11001; . . . &#11001; 1/(N &#11001; 1) ) The parenthesized quantity is the discrete estimate of the area under the curve 2 /x from 3 to N, &#11001; 1 and CN ~ 2N lnN by integration. Note that 2N ln N &#33360; 1.39N lg N, so the average number of compares is only about 39 percent higher than in the best case. A similar (but much more complicated) analysis is needed to establish the stated result for exchanges .</p><p attribs="{'xml:space': 'preserve'}" id="_04665" smilref="Title.smil#_04665"> When keys may not be distinct, as is typical in practical applications, precise anaysis is considerably more complicated, but it is not difficult to show that the average number of compares is no greater than than CN , even when duplicate keys may be present (on page 296, we will look at a way to improve quicksort in this case). Despite its many assets, the basic quicksort program has one potential liability : it can be extremely inefficient if the partitions are unbalanced. For example, it could be the case that the first partition is on the smallest item, the second partition on the next smallest item, and so forth, so that the program will remove just one item for each call, leading to an excessive number of partitions of large subarrays. Avoiding this situation is the primary reason that we randomly shuffle the array before using quicksort. This action makes it so unlikely that bad partitions will happen consistently that we need not worry about the possibility.</p><p attribs="{'xml:space': 'preserve'}" id="_04666" smilref="Title.smil#_04666" /><p attribs="{'xml:space': 'preserve'}" id="_04667" smilref="Title.smil#_04667"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04668" smilref="Title.smil#_04668"> 295</p><p attribs="{'xml:space': 'preserve'}" id="_04669" smilref="Title.smil#_04669"> Proposition L. Quicksort uses ~ N 2/2 compares in the worst case, but random shuffling protects against this case.</p><p attribs="{'xml:space': 'preserve'}" id="_04670" smilref="Title.smil#_04670"> Proof : By the argument just given, the number of compares used when one of the subarrays is empty for every partition is N &#11001; (N &#11002; 1) + (N &#11002; 2) &#11001; . . . &#11001; 2 &#11001; 1 = (N &#11001; 1) N / 2</p><p attribs="{'xml:space': 'preserve'}" id="_04671" smilref="Title.smil#_04671"> This behavior means not only that the time required will be quadratic but also that the space required to handle the recursion will be linear, which is unacceptable for large arrays. But (with quite a bit more work) it is possible to extend the analysis that we did for the average to find that the standard deviation of the number of compares is about .65 N, so the running time tends to the average as N grows and is unlikely to be far from the average. For example, even the rough estimate provided by Chebyshev&#8217;s inequality says that the probability that the running time is more than ten times the average for an array with a million elements is less than .00001 (and the true probability is far smaller). The probability that the running time for a large array is close to quadratic is so remote that we can safely ignore the possibility (see Exercise 2.3.10). For example, the probability that quicksort will use as many compares as insertion sort or selection sort when sorting a large array on your computer is much less than the probability that your computer will be struck by lightning during the sort!</p><p attribs="{'xml:space': 'preserve'}" id="_04672" smilref="Title.smil#_04672"> In summary, you can be sure that the running time of Algorithm 2.5 will be within a constant factor of 1.39N lg N whenever it is used to sort N items. The same is true of mergesort, but quicksort is typically faster because (even though it does 39 percent more compares) it does much less data movement. This mathematical assurance is probabilistic, but you can certainly rely upon it.</p><p attribs="{'xml:space': 'preserve'}" id="_04673" smilref="Title.smil#_04673"> Algorithmic improvements Quicksort was invented in 1960 by C. A. R. Hoare, and many people have studied and refined it since that time. It is tempting to try to develop ways to improve quicksort: a faster sorting algorithm is computer science&#8217;s &#8220;better mousetrap,&#8221; and quicksort is a venerable method that seems to invite tinkering. Almost from the moment Hoare first published the algorithm, people began proposing ways to improve the algorithm. Not all of these ideas are fully successful, because the algorithm is so well-balanced that the effects of improvements can be more than offset by unexpected side effects, but a few of them, which we now consider, are quite effective.</p><p attribs="{'xml:space': 'preserve'}" id="_04674" smilref="Title.smil#_04674" /></level3><level3 id="_00039"><h3 id="ch2-s3-ss11" smilref="Title.smil#ch2-s3-ss11" xml:space="preserve">3-way partitioning</h3><pagenum id="p309" page="normal" smilref="Title.smil#p309" /><p attribs="{'xml:space': 'preserve'}" id="_04675" smilref="Title.smil#_04675"> 296</p><p attribs="{'xml:space': 'preserve'}" id="_04676" smilref="Title.smil#_04676"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04677" smilref="Title.smil#_04677"> If your sort code is to be used a great many times or to sort a huge array (or, in par- ticular, if it is to be used as a library sort that will be used to sort arrays of unknown characteristics), then it is worthwhile to consider the improvements that are discussed in the next few paragraphs. As noted, you need to run experiments to determine the effectiveness of these improvements and to determine the best choice of parameters for your implementation. Typically, improvements of 20 to 30 percent are available.</p><p attribs="{'xml:space': 'preserve'}" id="_04678" smilref="Title.smil#_04678"> Cutoff to insertion sort. As with most recursive algorithms, an easy way to improve the performance of quicksort is based on the following two observations: </p><p attribs="{'xml:space': 'preserve'}" id="_04679" smilref="Title.smil#_04679"> if (hi &lt;= lo) return;</p><p attribs="{'xml:space': 'preserve'}" id="_04680" smilref="Title.smil#_04680"> in sort() with a statement that invokes insertion sort for small subarrays:</p><p attribs="{'xml:space': 'preserve'}" id="_04681" smilref="Title.smil#_04681"> if (hi &lt;= lo + M) { Insertion.sort(a, lo, hi); return; }</p><p attribs="{'xml:space': 'preserve'}" id="_04682" smilref="Title.smil#_04682"> The optimum value of the cutoff M is system-dependent, but any value between 5 and 15 is likely to work well in most situations (see Exercise 2.3.25). Median-of-three partitioning. A second easy way to improve the performance of quicksort is to use the median of a small sample of items taken from the subarray as the partitioning item. Doing so will give a slightly better partition, but at the cost of computing the median. It turns out that most of the available improvement comes from choosing a sample of size 3 and then partitioning on the middle item (see Exercises 2.3.18 and 2.3.19). As a bonus, we can use the sample items as sentinels at the ends of the array and remove both array bounds tests in partition().</p><p attribs="{'xml:space': 'preserve'}" id="_04683" smilref="Title.smil#_04683"> Entropy-optimal sorting. Arrays with large numbers of duplicate keys arise frequently in applications. For example, we might wish to sort a large personnel file by year of birth, or perhaps to separate females from males. In such situations, the quicksort implementation that we have considered has acceptable performance, but it can be substantially improved. For example, a subarray that consists solely of items that are equal (just one key value) does not need to be processed further, but our implementation keeps partitioning down to small subarrays. In a situation where there are large numbers of duplicate keys in the input array, the recursive nature of quicksort ensures that subarrays consisting solely of items with keys that are equal will occur often. There is potential for significant improvement, from the linearithmic-time performance of the implementations seen so far to linear-time performance.</p><p attribs="{'xml:space': 'preserve'}" id="_04684" smilref="Title.smil#_04684" /><pagenum id="p310" page="normal" smilref="Title.smil#p310" /><p attribs="{'xml:space': 'preserve'}" id="_04685" smilref="Title.smil#_04685"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04686" smilref="Title.smil#_04686"> 297</p><p attribs="{'xml:space': 'preserve'}" id="_04687" smilref="Title.smil#_04687"> input</p><p attribs="{'xml:space': 'preserve'}" id="_04688" smilref="Title.smil#_04688"> result of first partition</p><p attribs="{'xml:space': 'preserve'}" id="_04689" smilref="Title.smil#_04689"> partitioning element</p><p attribs="{'xml:space': 'preserve'}" id="_04690" smilref="Title.smil#_04690"> left subarray partially sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04691" smilref="Title.smil#_04691"> both subarrays partially sorted</p><p attribs="{'xml:space': 'preserve'}" id="_04692" smilref="Title.smil#_04692"> result</p><p attribs="{'xml:space': 'preserve'}" id="_04693" smilref="Title.smil#_04693"> Quicksort with median-of-3 partitioning and cutoff for small subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_04694" smilref="Title.smil#_04694" /><pagenum id="p311" page="normal" smilref="Title.smil#p311" /><p attribs="{'xml:space': 'preserve'}" id="_04695" smilref="Title.smil#_04695"> 298</p><p attribs="{'xml:space': 'preserve'}" id="_04696" smilref="Title.smil#_04696"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04697" smilref="Title.smil#_04697"> One straightforward idea is to partition the array into three parts, one each for items with keys smaller than, equal to, and larger than the partitioning item&#8217;s key. Accomplishing this partitioning is more complicated than the 2-way partitioning that we have been using, and various different methods have been suggested for the task. It was a classical programming exercise popularized by E. W. Dijkstra as the Dutch National Flag problem, because it is like sorting an array with three possible key values, which might correspond to the three colors on the fl ag. Dijkstra&#8217;s solution to this problem leads to the remarkably simple partition code shown on the next page. It is based on a single left-to-right pass through the array that maintains a pointer lt such that a[lo..lt-1] is less than v, a pointer gt such that a[gt+1, hi] is greater than v, and a pointer i such that a[lt..i-1] are equal to v and a[i..gt] are not yet examined. Starting with i equal to lo, we process a[i] using the 3-way comparison given us by the Comparable interface (instead of using less()) to directly handle the three possible cases: </p><p attribs="{'xml:space': 'preserve'}" id="_04698" smilref="Title.smil#_04698"> 3-way partitioning overview</p><p attribs="{'xml:space': 'preserve'}" id="_04699" smilref="Title.smil#_04699"> during</p><p attribs="{'xml:space': 'preserve'}" id="_04700" smilref="Title.smil#_04700"> v</p><p attribs="{'xml:space': 'preserve'}" id="_04701" smilref="Title.smil#_04701"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04702" smilref="Title.smil#_04702"> lt</p><p attribs="{'xml:space': 'preserve'}" id="_04703" smilref="Title.smil#_04703"> i</p><p attribs="{'xml:space': 'preserve'}" id="_04704" smilref="Title.smil#_04704"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04705" smilref="Title.smil#_04705"> lt</p><p attribs="{'xml:space': 'preserve'}" id="_04706" smilref="Title.smil#_04706"> after</p><p attribs="{'xml:space': 'preserve'}" id="_04707" smilref="Title.smil#_04707"> &lt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04708" smilref="Title.smil#_04708"> &lt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04709" smilref="Title.smil#_04709"> =v</p><p attribs="{'xml:space': 'preserve'}" id="_04710" smilref="Title.smil#_04710"> gt</p><p attribs="{'xml:space': 'preserve'}" id="_04711" smilref="Title.smil#_04711"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04712" smilref="Title.smil#_04712"> before</p><p attribs="{'xml:space': 'preserve'}" id="_04713" smilref="Title.smil#_04713"> =v</p><p attribs="{'xml:space': 'preserve'}" id="_04714" smilref="Title.smil#_04714"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04715" smilref="Title.smil#_04715"> &gt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04716" smilref="Title.smil#_04716"> &gt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04717" smilref="Title.smil#_04717"> gt</p><p attribs="{'xml:space': 'preserve'}" id="_04718" smilref="Title.smil#_04718" /><pagenum id="p312" page="normal" smilref="Title.smil#p312" /><p attribs="{'xml:space': 'preserve'}" id="_04719" smilref="Title.smil#_04719"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04720" smilref="Title.smil#_04720"> 299</p><p attribs="{'xml:space': 'preserve'}" id="_04721" smilref="Title.smil#_04721"> Quicksort with 3-way partitioning</p><p attribs="{'xml:space': 'preserve'}" id="_04722" smilref="Title.smil#_04722"> public class Quick3way {</p><p attribs="{'xml:space': 'preserve'}" id="_04723" smilref="Title.smil#_04723"> private static void sort(Comparable[] a, int lo, int hi) { // See page 289 for public sort() that calls this method. if (hi &lt;= lo) return; int lt = lo, i = lo+1, gt = hi; Comparable v = a[lo]; while (i &lt;= gt) { int cmp = a[i].compareTo(v); if (cmp &lt; 0) exch(a, lt++, i++); else if (cmp &gt; 0) exch(a, i, gt--); else i++; } // Now a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]. sort(a, lo, lt - 1); sort(a, gt + 1, hi); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04724" smilref="Title.smil#_04724"> This sort code partitions to put keys equal to the partitioning element in place and thus does not have to include those keys in the subarrays for the recursive calls. It is far more efficient than the standard quicksort implementation for arrays with large numbers of duplicate keys (see text).</p><p attribs="{'xml:space': 'preserve'}" id="_04725" smilref="Title.smil#_04725"> a[] v lt i gt 0 1 2 3 4 5 6 7 8 9 10 11 0 0 11 R B W W R W B R R W B R 0 1 11 R B W W R W B R R W B R 1 2 11 B R W W R W B R R W B R 1 2 10 B R R W R W B R R W B W 1 3 10 B R R W R W B R R W B W 1 3 9 B R R B R W B R R W W W 2 4 9 B B R R R W B R R W W W 2 5 9 B B R R R W B R R W W W 2 5 8 B B R R R W B R R W W W 2 5 7 B B R R R R B R W W W W 2 6 7 B B R R R R B R W W W W 3 7 7 B B B R R R R R W W W W 3 8 7 B B B R R R R R W W W W 3 8 7 B B B R R R R R W W W W 3-way partitioning trace (array contents after each loop iteration)</p><p attribs="{'xml:space': 'preserve'}" id="_04726" smilref="Title.smil#_04726" /><pagenum id="p313" page="normal" smilref="Title.smil#p313" /><p attribs="{'xml:space': 'preserve'}" id="_04727" smilref="Title.smil#_04727"> 300</p><p attribs="{'xml:space': 'preserve'}" id="_04728" smilref="Title.smil#_04728"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04729" smilref="Title.smil#_04729"> equal to partitioning element</p><p attribs="{'xml:space': 'preserve'}" id="_04730" smilref="Title.smil#_04730"> Visual trace of quicksort with 3-way partitioning</p><p attribs="{'xml:space': 'preserve'}" id="_04731" smilref="Title.smil#_04731"> for example, mergesort is linearithmic for a randomly ordered array that has only a constant number of distinct key values, but quicksort with 3-way partitioning is linear for such an array. Indeed, by examining the visual trace above, you can see that N times the number of key values is a conservative bound on the running time. The analysis that makes these notions precise takes the distribution of key values into account. Given N keys with k distinct key values, for each i from 1 to k define fi to be frequency of occurrence of the i th key value and pi to be fi / N, the probability that the i th key value is found when a random entry of the array is sampled. The Shannon entropy of the keys (a classic measure of their information content) is defined as H = &#11002; ( p1 lg p1 &#11001; . . . &#11001; pk lg pk ) Given any array of items to be sorted, we can calculate its entropy by counting the frequency of each key value. Remarkably, we can also derive from the entropy both a lower bound on the number of compares and an upper bound on the number of compares used by quicksort with 3-way partitioning.</p><p attribs="{'xml:space': 'preserve'}" id="_04732" smilref="Title.smil#_04732"> &#11001; p2 lg p2</p><p attribs="{'xml:space': 'preserve'}" id="_04733" smilref="Title.smil#_04733"> Proposition M. No compare-based sorting algorithm can guarantee to sort N items with fewer than NH &#11002; N compares, where H is the Shannon entropy, defined from the frequencies of key values.</p><p attribs="{'xml:space': 'preserve'}" id="_04734" smilref="Title.smil#_04734"> Proof sketch: This result follows from a (relatively easy) generalization of the low-</p><p attribs="{'xml:space': 'preserve'}" id="_04735" smilref="Title.smil#_04735"> er bound proof of Proposition I in Section 2.2.</p><p attribs="{'xml:space': 'preserve'}" id="_04736" smilref="Title.smil#_04736" /><pagenum id="p314" page="normal" smilref="Title.smil#p314" /><p attribs="{'xml:space': 'preserve'}" id="_04737" smilref="Title.smil#_04737"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04738" smilref="Title.smil#_04738"> 301</p><p attribs="{'xml:space': 'preserve'}" id="_04739" smilref="Title.smil#_04739"> Proposition N. Quicksort with 3-way partitioning uses ~ (2ln 2) N H compares to sort N items, where H is the Shannon entropy, defined from the frequencies of key values.</p><p attribs="{'xml:space': 'preserve'}" id="_04740" smilref="Title.smil#_04740"> Proof sketch: This result follows from a (relatively dif&#64257; cult) generalization of the average-case analysis of quicksort in Proposition K. As with distinct keys, this costs about 39 percent more than the optimum (but within a constant factor) .</p><p attribs="{'xml:space': 'preserve'}" id="_04741" smilref="Title.smil#_04741"> Note that H = lg N when the keys are all distinct (all the probabilities are 1/N), which is consistent with Proposition I in Section 2.2 and Proposition K. The worst case for 3-way partitioning happens when the keys are distinct; when duplicate keys are present, it can do much better than mergesort. More important, these two properties together imply that quicksort with 3-way partitioning is entropy-optimal, in the sense that the average number of compares used by the best possible compare-based sorting algorithm and the average number of compares used by 3-way quicksort are within a constant factor of one another, for any given distribution of input key values. As with standard quicksort, the running time tends to the average as the array size grows, and large deviations from the average are extremely unlikely, so that you can depend on 3-way quicksort&#8217;s running time to be proportional to N times the entropy of the distribution of input key values. This property of the algorithm is important in practice because it reduces the time of the sort from linearithmic to linear for arrays with large numbers of duplicate keys. The order of the keys is immaterial, because the algorithm shuffles them to protect against the worst case. The distribution of keys defines the entropy and no compare-based algorithm can use fewer compares than defined by the entropy. This ability to adapt to duplicates in the input makes 3-way quicksort the algorithm of choice for a library sort&#8212;clients that sort arrays containing large numbers of duplicate keys are not unusual.</p><p attribs="{'xml:space': 'preserve'}" id="_04742" smilref="Title.smil#_04742"> A carefully tuned version of quicksort is likely to run significantly faster on most computers for most applications than will any other compare-based sorting method. Quicksort is widely used throughout today&#8217;s computational infrastructure because the mathematical models that we have discussed suggest that it will outperform other methods in practical applications, and extensive experiments and experience over the past several decades have validated that conclusion. We will see in Chapter 5 that this is not quite the end of the story in the development of sorting algorithms, because is it possible to develop algorithms that do not use compares at all! But a version of quicksort turns out to be best in that situation, as well.</p><p attribs="{'xml:space': 'preserve'}" id="_04743" smilref="Title.smil#_04743" /><pagenum id="p315" page="normal" smilref="Title.smil#p315" /><p attribs="{'xml:space': 'preserve'}" id="_04744" smilref="Title.smil#_04744"> 302</p><p attribs="{'xml:space': 'preserve'}" id="_04745" smilref="Title.smil#_04745"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04746" smilref="Title.smil#_04746"> Q &amp; A</p><p attribs="{'xml:space': 'preserve'}" id="_04747" smilref="Title.smil#_04747"> Q. Is there some way to just divide the array into two halves, rather than letting the partitioning element fall where it may? A. That is a question that stumped experts for over a decade. It is tantamount to fi nd- ing the median key value in the array and then partitioning on that value. We discuss the problem of finding the median on page 346. It is possible to do so in linear time, but the cost of doing so with known algorithms (which are based on quicksort partition- ing!) far exceeds the 39 percent savings available from splitting the array into equal parts. Q. Randomly shuffling the array seems to take a significant fraction of the total time for the sort. Is doing so really worthwhile? A. Yes. It protects against the worst case and makes the running time predictable. Hoare proposed this approach when he presented the algorithm in 1960&#8212;it is a prototypical (and among the fi rst) randomized algorithm. Q. Why all the focus on items with equal keys? A. The issue directly impacts performance in practical situations. It was overlooked by many for decades, with the result that some older implementations of quicksort take quadratic time for arrays with large numbers of items with equal keys, which certainly do arise in applications. Better implementations such as Algorithm 2.5 take linearith- mic time for such arrays, but improving that to linear-time as in the entropy-optimal sort at the end of this section is worthwhile in many situations.</p><p attribs="{'xml:space': 'preserve'}" id="_04748" smilref="Title.smil#_04748" /><pagenum id="p316" page="normal" smilref="Title.smil#p316" /><p attribs="{'xml:space': 'preserve'}" id="_04749" smilref="Title.smil#_04749"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04750" smilref="Title.smil#_04750"> 303</p><p attribs="{'xml:space': 'preserve'}" id="_04751" smilref="Title.smil#_04751"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_04752" smilref="Title.smil#_04752"> 2.3.1 Show, in the style of the trace given with partition(), how that method pati-</p><p attribs="{'xml:space': 'preserve'}" id="_04753" smilref="Title.smil#_04753"> tions the array E A S Y Q U E S T I O N.</p><p attribs="{'xml:space': 'preserve'}" id="_04754" smilref="Title.smil#_04754"> 2.3.2 Show, in the style of the quicksort trace given in this section, how quicksort sorts the array E A S Y Q U E S T I O N (for the purposes of this exercise, ignore the initial shuf&#64258; e). 2.3.3 What is the maximum number of times during the execution of Quick.sort() that the largest item can be exchanged, for an array of length N ? 2.3.4 Suppose that the initial random shuffle is omitted. Give six arrays of ten elements for which Quick.sort() uses the worst-case number of compares. 2.3.5 Give a code fragment that sorts an array that is known to consist of items having just two distinct keys. 2.3.6 Write a program to compute the exact value of CN, and compare the exact value with the approximation 2N ln N, for N = 100, 1,000, and 10,000. 2.3.7 Find the expected number of subarrays of size 0, 1, and 2 when quicksort is used to sort an array of N items with distinct keys. If you are mathematically inclined, do the math; if not, run some experiments to develop hypotheses. 2.3.8 About how many compares will Quick.sort() make when sorting an array of N items that are all equal? 2.3.9 Explain what happens when Quick.sort() is run on an array having items with just two distinct keys, and then explain what happens when it is run on an array having just three distinct keys. 2.3.10 Chebyshev&#8217;s inequality says that the probability that a random variable is more than k standard deviations away from the mean is less than 1/k 2. For N = 1 million, use Chebyshev&#8217;s inequality to bound the probability that the number of compares used by quicksort is more than 100 billion (.1 N 2). 2.3.11 Suppose that we scan over items with keys equal to the partitioning item&#8217;s key instead of stopping the scans when we encounter them. Show that the running time of this version of quicksort is quadratic for all arrays with just a constant number of distinct keys.</p><p attribs="{'xml:space': 'preserve'}" id="_04755" smilref="Title.smil#_04755" /><pagenum id="p317" page="normal" smilref="Title.smil#p317" /><p attribs="{'xml:space': 'preserve'}" id="_04756" smilref="Title.smil#_04756"> 304</p><p attribs="{'xml:space': 'preserve'}" id="_04757" smilref="Title.smil#_04757"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04758" smilref="Title.smil#_04758"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04759" smilref="Title.smil#_04759"> 2.3.12 Show, in the style of the trace given with the code, how the entropy-optimal sort</p><p attribs="{'xml:space': 'preserve'}" id="_04760" smilref="Title.smil#_04760"> first partitions the array B A B A B A B A C A D A B R A.</p><p attribs="{'xml:space': 'preserve'}" id="_04761" smilref="Title.smil#_04761"> 2.3.13 What is the recursive depth of quicksort, in the best, worst, and average cases? This is the size of the stack that the system needs to keep track of the recursive calls. See Exercise 2.3.20 for a way to guarantee that the recursive depth is logarithmic in the worst case. 2.3.14 Prove that when running quicksort on an array with N distinct items, the probability of comparing the i th and j th largest items is 2/(j &#11002; i). Then use this result to</p><p attribs="{'xml:space': 'preserve'}" id="_04762" smilref="Title.smil#_04762"> prove Proposition K.</p><p attribs="{'xml:space': 'preserve'}" id="_04763" smilref="Title.smil#_04763" /><pagenum id="p318" page="normal" smilref="Title.smil#p318" /><p attribs="{'xml:space': 'preserve'}" id="_04764" smilref="Title.smil#_04764"> 2 .3 </p><p attribs="{'xml:space': 'preserve'}" id="_04765" smilref="Title.smil#_04765"> 305</p><p attribs="{'xml:space': 'preserve'}" id="_04766" smilref="Title.smil#_04766"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_04767" smilref="Title.smil#_04767"> 2.3.15 Nuts and bolts. (G. J. E. Rawlins) You have a mixed pile of N nuts and N bolts and need to quickly find the corresponding pairs of nuts and bolts. Each nut matches exactly one bolt, and each bolt matches exactly one nut. By fitting a nut and bolt to- gether, you can see which is bigger, but it is not possible to directly compare two nuts or two bolts. Give an efficient method for solving the problem. 2.3.16 Best case. Write a program that produces a best-case array (with no duplicates) for sort() in Algorithm 2.5: an array of N items with distinct keys having the property that every partition will produce subarrays that differ in size by at most 1 (the same subarray sizes that would happen for an array of N equal keys). (For the purposes of this exercise, ignore the initial shuf&#64258; e.)</p><p attribs="{'xml:space': 'preserve'}" id="_04768" smilref="Title.smil#_04768"> The following exercises describe variants of quicksort. Each of them calls for an implementa- tion, but naturally you will also want to use SortCompare for experiments to evaluate the effectiveness of each suggested modi&#64257; cation. 2.3.17 Sentinels. Modify the code in Algorithm 2.5 to remove both bounds checks in the inner while loops. The test against the left end of the subarray is redundant since the partitioning item acts as a sentinel (v is never less than a[lo]). To enable removal of the other test, put an item whose key is the largest in the whole array into a[length-1] just after the shuf&#64258; e. This item will never move (except possibly to be swapped with an item having the same key) and will serve as a sentinel in all subarrays involving the end of the array. Note : When sorting interior subarrays, the leftmost entry in the subarray to the right serves as a sentinel for the right end of the subarray. 2.3.18 Median-of-3 partitioning. Add median-of-3 partitioning to quicksort, as described in the text (see page 296). Run doubling tests to determine the effectiveness of the change. 2.3.19 Median-of-5 partitioning. Implement a quicksort based on partitioning on the median of a random sample of five items from the subarray. Put the items of the sample at the appropriate ends of the array so that only the median participates in partitioning. Run doubling tests to determine the effectiveness of the change, in comparison both to the standard algorithm and to median-of-3 partitioning (see the previous exercise). Extra credit : Devise a median-of-5 algorithm that uses fewer than seven compares on any input.</p><p attribs="{'xml:space': 'preserve'}" id="_04769" smilref="Title.smil#_04769" /><pagenum id="p319" page="normal" smilref="Title.smil#p319" /><p attribs="{'xml:space': 'preserve'}" id="_04770" smilref="Title.smil#_04770"> 306</p><p attribs="{'xml:space': 'preserve'}" id="_04771" smilref="Title.smil#_04771"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04772" smilref="Title.smil#_04772"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_04773" smilref="Title.smil#_04773"> before</p><p attribs="{'xml:space': 'preserve'}" id="_04774" smilref="Title.smil#_04774"> during</p><p attribs="{'xml:space': 'preserve'}" id="_04775" smilref="Title.smil#_04775"> after</p><p attribs="{'xml:space': 'preserve'}" id="_04776" smilref="Title.smil#_04776"> v</p><p attribs="{'xml:space': 'preserve'}" id="_04777" smilref="Title.smil#_04777"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04778" smilref="Title.smil#_04778"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04779" smilref="Title.smil#_04779"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_04780" smilref="Title.smil#_04780"> =v</p><p attribs="{'xml:space': 'preserve'}" id="_04781" smilref="Title.smil#_04781"> &lt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04782" smilref="Title.smil#_04782"> &lt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04783" smilref="Title.smil#_04783"> j</p><p attribs="{'xml:space': 'preserve'}" id="_04784" smilref="Title.smil#_04784"> 2.3.20 Nonrecursive quicksort. Implement a nonrecursive version of quicksort based on a main loop where a subarray is popped from a stack to be partitioned, and the resulting subarrays are pushed onto the stack. Note : Push the larger of the subarrays onto the stack fi rst, which guarantees that the stack will have at most lg N entries. 2.3.21 Lower bound for sorting with equal keys. Complete the first part of the proof of Proposition M by following the logic in the proof of Proposition I and using the observation that there are N! / f1!f2! . . . fk! different ways to arrange keys with k different values, where the i th value appears with frequency fi (= Npi , in the notation of Proposi- tion M), with f1+. . . +fk = N. 2.3.22 Fast 3-way partitioning. ( J. Bentley and D. McIlroy) Implement an entropy- optimal sort based on keeping item's with equal keys at both the left and right ends of the subarray. Maintain indices p and q such that</p><p attribs="{'xml:space': 'preserve'}" id="_04785" smilref="Title.smil#_04785"> a[lo..p-1] and a[q+1..hi] are all equal to a[lo],</p><p attribs="{'xml:space': 'preserve'}" id="_04786" smilref="Title.smil#_04786"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04787" smilref="Title.smil#_04787"> i</p><p attribs="{'xml:space': 'preserve'}" id="_04788" smilref="Title.smil#_04788"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04789" smilref="Title.smil#_04789"> j</p><p attribs="{'xml:space': 'preserve'}" id="_04790" smilref="Title.smil#_04790"> q</p><p attribs="{'xml:space': 'preserve'}" id="_04791" smilref="Title.smil#_04791"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_04792" smilref="Title.smil#_04792"> &gt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04793" smilref="Title.smil#_04793"> p</p><p attribs="{'xml:space': 'preserve'}" id="_04794" smilref="Title.smil#_04794"> i</p><p attribs="{'xml:space': 'preserve'}" id="_04795" smilref="Title.smil#_04795"> =v</p><p attribs="{'xml:space': 'preserve'}" id="_04796" smilref="Title.smil#_04796"> &gt;v</p><p attribs="{'xml:space': 'preserve'}" id="_04797" smilref="Title.smil#_04797"> =v</p><p attribs="{'xml:space': 'preserve'}" id="_04798" smilref="Title.smil#_04798"> an index i such that a[p..i-1] are all less than a[lo], and an index j such that a[j+1..q] are all greater than a[lo]. Add to the inner partitioning loop code to swap a[i] with a[p] (and increment p) if it is equal to v and to swap a[j] with a[q] (and decrement q) if it is equal to v before the usual comparisons of a[i] and a[j] with v. After the partitioning loop has terminated, add code to swap the items with equal keys into position. Note : This code complements the code given in the text, in the sense that it does extra swaps for keys equal to the partitioning item&#8217;s key, while the code in the text does extra swaps for keys that are not equal to the partitioning item&#8217;s key. 2.3.23 Java system sort. Add to your implementation from Exercise 2.3.22 code to use the Tukey ninther to compute the partitioning item&#8212;choose three sets of three items, take the median of each, then use the median of the three medians as the partitioning item. Also, add a cutoff to insertion sort for small subarrays. 2.3.24 Samplesort. ( W. Frazer and A. McKellar) Implement a quicksort based on using a sample of size 2k &#11002; 1. First, sort the sample, then arrange to have the recursive routine partition on the median of the sample and to move the two halves of the rest of the sample to each subarray, such that they can be used in the subarrays, without having to be sorted again. This algorithm is called samplesort.</p><p attribs="{'xml:space': 'preserve'}" id="_04799" smilref="Title.smil#_04799"> Bentley-McIlroy 3-way partitioning</p><p attribs="{'xml:space': 'preserve'}" id="_04800" smilref="Title.smil#_04800" /><pagenum id="p320" page="normal" smilref="Title.smil#p320" /><p attribs="{'xml:space': 'preserve'}" id="_04801" smilref="Title.smil#_04801"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_04802" smilref="Title.smil#_04802"> 307</p><p attribs="{'xml:space': 'preserve'}" id="_04803" smilref="Title.smil#_04803"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_04804" smilref="Title.smil#_04804"> 2.3.25 Cutoff to insertion sort. Implement quicksort with a cutoff to insertion sort for subarrays with less than M elements, and empirically determine the value of M for which quicksort runs fastest in your computing environment to sort random arrays of N doubles, for N = 103, 104, 105, and 106. Plot average running times for M from 0 to 30 for each value of M. Note : You need to add a three-argument sort() method to Algorithm 2.2 for sorting subarrays such that the call Insertion.sort(a, lo, hi) sorts the subarray a[lo..hi]. 2.3.26 Subarray sizes. Write a program that plots a histogram of the subarray sizes left for insertion sort when you run quicksort for an array of size N with a cutoff for subar- rays of size less than M. Run your program for M=10, 20, and 50 and N = 105. 2.3.27 Ignore small subarrays. Run experiments to compare the following strategy for dealing with small subarrays with the approach described in Exercise 2.3.25: Simply ignore the small subarrays in quicksort, then run a single insertion sort after the quick- sort completes. Note : You may be able to estimate the size of your computer&#8217;s cache memory with these experiments, as the performance of this method is likely to degrade when the array does not fit in the cache. 2.3.28 Recursion depth. Run empirical studies to determine the average recursive depth used by quicksort with cutoff for arrays of size M, when sorting arrays of N distinct elements, for M=10, 20, and 50 and N = 103, 104, 105, and 106. 2.3.29 Randomization. Run empirical studies to compare the effectiveness of the strategy of choosing a random partitioning item with the strategy of initially randomizing the array (as in the text). Use a cutoff for arrays of size M, and sort arrays of N distinct elements, for M=10, 20, and 50 and N = 103, 104, 105, and 106. 2.3.30 Corner cases. Test quicksort on large nonrandom arrays of the kind described in Exercises 2.1.35 and 2.1.36 both with and without the initial random shuf&#64258; e. How does shuffling affect its performance for these arrays? 2.3.31 Histogram of running times. Write a program that takes command-line arguments N and T, does T trials of the experiment of running quicksort on an array of N random Double values, and plots a histogram of the observed running times. Run your program for N = 103, 104, 105, and 106, with T as large as you can afford to make the curves smooth. Your main challenge for this exercise is to appropriately scale the experimental results.</p><p attribs="{'xml:space': 'preserve'}" id="_04805" smilref="Title.smil#_04805" /></level3><level3 id="_00040"><h3 id="ch2-s4-ss12" smilref="Title.smil#ch2-s4-ss12" xml:space="preserve">Priority queue API</h3><pagenum id="p322" page="normal" smilref="Title.smil#p322" /><p attribs="{'xml:space': 'preserve'}" id="_04806" smilref="Title.smil#_04806"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_04807" smilref="Title.smil#_04807"> 309</p><p attribs="{'xml:space': 'preserve'}" id="_04808" smilref="Title.smil#_04808"> API The priority queue is a prototypical abstract data type (see Section 1.2): it represents a set of values and operations on those values, and it provides a convenient abstraction that allows us to separate application programs (clients) from various implementations that we will consider in this section. As in Section 1.2, we precisely define the operations by specifying an applications programming interface (API) that provides the information needed by clients. Priority queues are characterized by the remove the maximum and insert operations, so we shall focus on them. We use the method names delMax() for remove the maximum and insert() for insert. By convention, we will compare keys only with a helper less() method, as we have been doing for sorting. Thus, if items can have duplicate keys, maximum means any item with the largest key value. To complete the API, we also need to add constructors (like the ones we used for stacks and queues) and a test if empty operation. For fl exibility, we use a generic implementation with a parameterized type Key that implements the Comparable interface. This choice eliminates our distinction between items and keys and enables clearer and more compact descriptions of data structures and algorithms. For example, we refer to the &#8220;largest key&#8221; instead of the &#8220;largest item&#8221; or the &#8220;item with the largest key.&#8221; For convenience in client code, the API includes three constructors, which enable clients to build priority queues of an initial fixed size (perhaps initialized with a given array of keys). To clarify client code, we will use a separate class MinPQ whenever ap- propriate, which is the same as MaxPQ except that it has a delMin() method that deletes and returns an item with the smallest key in the queue. Any MaxPQ implementation is easily converted into a MinPQ implementation and vice versa, simply by reversing the sense of the comparison in less().</p><p attribs="{'xml:space': 'preserve'}" id="_04809" smilref="Title.smil#_04809"> public class MaxPQ&lt; Key extends Comparable&lt;Key&gt;&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_04810" smilref="Title.smil#_04810"> MaxPQ()</p><p attribs="{'xml:space': 'preserve'}" id="_04811" smilref="Title.smil#_04811"> create a priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_04812" smilref="Title.smil#_04812"> MaxPQ(int max) create a priority queue of initial capacity max</p><p attribs="{'xml:space': 'preserve'}" id="_04813" smilref="Title.smil#_04813"> Key max()</p><p attribs="{'xml:space': 'preserve'}" id="_04814" smilref="Title.smil#_04814"> Key delMax()</p><p attribs="{'xml:space': 'preserve'}" id="_04815" smilref="Title.smil#_04815"> MaxPQ(Key[] a) create a priority queue from the keys in a[] insert a key into the priority queue return the largest key return and remove the largest key is the priority queue empty? number of keys in the priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_04816" smilref="Title.smil#_04816"> void insert(Key v)</p><p attribs="{'xml:space': 'preserve'}" id="_04817" smilref="Title.smil#_04817"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_04818" smilref="Title.smil#_04818"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_04819" smilref="Title.smil#_04819"> API for a generic priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_04820" smilref="Title.smil#_04820" /></level3><level3 id="_00041"><h3 id="ch2-s4-ss13" smilref="Title.smil#ch2-s4-ss13" xml:space="preserve">Elementary implementations</h3><pagenum id="p323" page="normal" smilref="Title.smil#p323" /><p attribs="{'xml:space': 'preserve'}" id="_04821" smilref="Title.smil#_04821"> 310</p><p attribs="{'xml:space': 'preserve'}" id="_04822" smilref="Title.smil#_04822"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04823" smilref="Title.smil#_04823"> A priority-queue client. To appreciate the</p><p attribs="{'xml:space': 'preserve'}" id="_04824" smilref="Title.smil#_04824"> order of growth time space</p><p attribs="{'xml:space': 'preserve'}" id="_04825" smilref="Title.smil#_04825"> N log N</p><p attribs="{'xml:space': 'preserve'}" id="_04826" smilref="Title.smil#_04826"> NM</p><p attribs="{'xml:space': 'preserve'}" id="_04827" smilref="Title.smil#_04827"> Costs of f inding the largest M in a stream of N items</p><p attribs="{'xml:space': 'preserve'}" id="_04828" smilref="Title.smil#_04828"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04829" smilref="Title.smil#_04829"> M</p><p attribs="{'xml:space': 'preserve'}" id="_04830" smilref="Title.smil#_04830"> M</p><p attribs="{'xml:space': 'preserve'}" id="_04831" smilref="Title.smil#_04831"> client</p><p attribs="{'xml:space': 'preserve'}" id="_04832" smilref="Title.smil#_04832"> sort client PQ client using elementary implementation PQ client using heap-based implementation N log M</p><p attribs="{'xml:space': 'preserve'}" id="_04833" smilref="Title.smil#_04833"> value of the priority-queue abstraction, consider the following problem: You have a huge input stream of N strings and associated integer values, and your task is to find the largest or smallest M integers (and associated strings) in the input stream. You might imagine the stream to be financial transactions, where your interest is to find the big ones, or pesticide levels in an agricultural product, where your interest is to find the small ones, or requests for service, or results from a scientific experiment, or whatever. In some applications, the size of the input stream is so huge that it is best to consider it to be unbounded. One way to address this problem would be to sort the input stream and take the M largest keys from the result, but we have just stipulated that the input stream is too large for that. Another approach would be to compare each new key against the M largest seen so far, but that is also likely to be prohibitively expensive unless M is small. With priority queues, we can solve the problem with the MinPQ client TopM on the next page provided that we can develop efficient implementations of both insert() and delMin(). That is precisely our aim in this sec- tion. For the huge values of N that are likely to be encountered in our modern computational infrastructure, these implementations can make the difference between being able to address such a problem and not having the resources to do it at all.</p><p attribs="{'xml:space': 'preserve'}" id="_04834" smilref="Title.smil#_04834"> Elementary implementations The basic data structures that we discussed in Chapter 1 provide us with four immediate starting points for implementing priority queues. We can use an array or a linked list, kept in order or unordered. These implementations are useful for small priority queues, situations where one of the two operations are predominant, or situations where some assumptions can be made about the order of the keys involved in the operations. Since these implementations are elemen- tary, we will be content with brief descriptions here in the text and leave the code for exercises (see Exercise 2.4.3). Array representation (unordered). Perhaps the simplest priority-queue implementation is based on our code for pushdown stacks in Section 2.1. The code for insert in the priority queue is the same as for push in the stack. To implement remove the maximum, we can add code like the inner loop of selection sort to exchange the maximum item with the item at the end and then delete that one, as we did with pop() for stacks. As with stacks, we can add resizing-array code to ensure that the data structure is always at least one-quarter full and never over&#64258; ows.</p><p attribs="{'xml:space': 'preserve'}" id="_04835" smilref="Title.smil#_04835" /><pagenum id="p324" page="normal" smilref="Title.smil#p324" /><p attribs="{'xml:space': 'preserve'}" id="_04836" smilref="Title.smil#_04836"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_04837" smilref="Title.smil#_04837"> 311</p><p attribs="{'xml:space': 'preserve'}" id="_04838" smilref="Title.smil#_04838"> A priority-queue client</p><p attribs="{'xml:space': 'preserve'}" id="_04839" smilref="Title.smil#_04839"> public class TopM { public static void main(String[] args) { // Print the top M lines in the input stream. int M = Integer.parseInt(args[0]); MinPQ&lt;Transaction&gt; pq = new MinPQ&lt;Transaction&gt;(M+1); while (StdIn.hasNextLine()) { // Create an entry from the next line and put on the PQ. pq.insert(new Transaction(StdIn.readLine())); if (pq.size() &gt; M) pq.delMin(); // Remove minimum if M+1 entries on the PQ. } // Top M entries are on the PQ.</p><p attribs="{'xml:space': 'preserve'}" id="_04840" smilref="Title.smil#_04840"> Stack&lt;Transaction&gt; stack = new Stack&lt;Transaction&gt;(); while (!pq.isEmpty()) stack.push(pq.delMin()); for (Transaction t : stack) StdOut.println(t); } }</p><p attribs="{'xml:space': 'preserve'}" id="_04841" smilref="Title.smil#_04841"> Given an integer M from the command line and an input stream where each line contains a trans- action, this MinPQ client prints the M lines whose numbers are the highest. It does so by using our Transaction class (see page 79, Exercise 1.2.19, and Exercise 2.1.21) to build a priority queue using the numbers as keys, deleting the minimum after each insertion once the size of the priority queue reaches M. Once all the transactions have been processed, the top M come off the priority queue in increasing order, so this code puts them on a stack, then iterates through the stack to reverse the order and print them in decreasing order.</p><p attribs="{'xml:space': 'preserve'}" id="_04842" smilref="Title.smil#_04842"> % more tinyBatch.txt Turing 6/17/1990 644.08 vonNeumann 3/26/2002 4121.85 Dijkstra 8/22/2007 2678.40 vonNeumann 1/11/1999 4409.74 Dijkstra 11/18/1995 837.42 Hoare 5/10/1993 3229.27 vonNeumann 2/12/1994 4732.35 Hoare 8/18/1992 4381.21 Turing 1/11/2002 66.10 Thompson 2/27/2000 4747.08 Turing 2/11/1991 2156.86 Hoare 8/12/2003 1025.70 vonNeumann 10/13/1993 2520.97 Dijkstra 9/10/2000 708.95 Turing 10/12/1993 3532.36 Hoare 2/10/2005 4050.20</p><p attribs="{'xml:space': 'preserve'}" id="_04843" smilref="Title.smil#_04843"> % java TopM 5 &lt; tinyBatch.txt Thompson 2/27/2000 4747.08 vonNeumann 2/12/1994 4732.35 vonNeumann 1/11/1999 4409.74 Hoare 8/18/1992 4381.21 vonNeumann 3/26/2002 4121.85</p><p attribs="{'xml:space': 'preserve'}" id="_04844" smilref="Title.smil#_04844" /><pagenum id="p325" page="normal" smilref="Title.smil#p325" /><p attribs="{'xml:space': 'preserve'}" id="_04845" smilref="Title.smil#_04845"> 312</p><p attribs="{'xml:space': 'preserve'}" id="_04846" smilref="Title.smil#_04846"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04847" smilref="Title.smil#_04847"> Array representation (ordered). Another approach is to add code for insert to move larger entries one position to the right, thus keeping the keys in the array in order (as in insertion sort). Thus, the largest entry is always at the end, and the code for remove the maximum in the priority queue is the same as for pop in the stack.</p><p attribs="{'xml:space': 'preserve'}" id="_04848" smilref="Title.smil#_04848"> Linked-list representations. Similarly, we can start with our linked-list code for pushdown stacks, modifying either the code for pop() to find and return the maximum or the code for push() to keep keys in reverse order and the code for pop() to unlink and return the first (maximum) item on the list.</p><p attribs="{'xml:space': 'preserve'}" id="_04849" smilref="Title.smil#_04849"> data structure</p><p attribs="{'xml:space': 'preserve'}" id="_04850" smilref="Title.smil#_04850"> insert</p><p attribs="{'xml:space': 'preserve'}" id="_04851" smilref="Title.smil#_04851"> ordered array</p><p attribs="{'xml:space': 'preserve'}" id="_04852" smilref="Title.smil#_04852"> unordered array</p><p attribs="{'xml:space': 'preserve'}" id="_04853" smilref="Title.smil#_04853"> Order of growth of worst-case running time for priority-queue implementations</p><p attribs="{'xml:space': 'preserve'}" id="_04854" smilref="Title.smil#_04854"> heap</p><p attribs="{'xml:space': 'preserve'}" id="_04855" smilref="Title.smil#_04855"> impossible</p><p attribs="{'xml:space': 'preserve'}" id="_04856" smilref="Title.smil#_04856"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04857" smilref="Title.smil#_04857"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04858" smilref="Title.smil#_04858"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04859" smilref="Title.smil#_04859"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04860" smilref="Title.smil#_04860"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04861" smilref="Title.smil#_04861"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04862" smilref="Title.smil#_04862"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_04863" smilref="Title.smil#_04863"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_04864" smilref="Title.smil#_04864"> remove maximum</p><p attribs="{'xml:space': 'preserve'}" id="_04865" smilref="Title.smil#_04865"> Using unordered sequences is the prototypical lazy approach to this problem, where we defer doing work until necessary (to find the maximum); using ordered sequences is the prototypical eager approach to the problem, where we do as much work as we can up front (keep the list sorted on insertion) to make later operations ef&#64257; cient. The significant difference between implementing stacks or queues and implementing priority queues has to do with performance. For stacks and queues, we were able to develop implementations of all the operations that take constant time; for priority queues, all of the elementary implementations just discussed have the property that either the insert or the remove the maximum operation takes linear time in the worst case. The heap data structure that we consider next enables implementations where both operations are guaranteed to be fast.</p><p attribs="{'xml:space': 'preserve'}" id="_04866" smilref="Title.smil#_04866"> operation argument</p><p attribs="{'xml:space': 'preserve'}" id="_04867" smilref="Title.smil#_04867"> return value</p><p attribs="{'xml:space': 'preserve'}" id="_04868" smilref="Title.smil#_04868"> size</p><p attribs="{'xml:space': 'preserve'}" id="_04869" smilref="Title.smil#_04869"> contents (unordered)</p><p attribs="{'xml:space': 'preserve'}" id="_04870" smilref="Title.smil#_04870"> contents (ordered)</p><p attribs="{'xml:space': 'preserve'}" id="_04871" smilref="Title.smil#_04871"> insert insert insert remove max insert insert insert remove max insert insert insert remove max</p><p attribs="{'xml:space': 'preserve'}" id="_04872" smilref="Title.smil#_04872"> P 1 P P Q 2 P Q P Q E 3 P Q E E P Q Q 2 P E E P X 3 P E X E P X A 4 P E X A A E P X M 5 P E X A M A E M P X X 4 P E M A A E M P P 5 P E M A P A E M P P L 6 P E M A P L A E L M P P E 7 P E M A P L E A E E L M P P P 6 E E M A P L A E E L M P A sequence of operations on a priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_04873" smilref="Title.smil#_04873" /></level3><level3 id="_00042"><h3 id="ch2-s4-ss14" smilref="Title.smil#ch2-s4-ss14" xml:space="preserve">Binary heap</h3><pagenum id="p326" page="normal" smilref="Title.smil#p326" /><p attribs="{'xml:space': 'preserve'}" id="_04874" smilref="Title.smil#_04874"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_04875" smilref="Title.smil#_04875"> 313</p><p attribs="{'xml:space': 'preserve'}" id="_04876" smilref="Title.smil#_04876"> Heap definitions The binary heap is a data structure that can efficiently support the basic priority-queue operations. In a binary heap, the keys are stored in an array such that each key is guaranteed to be larger than (or equal to) the keys at two other specific positions. In turn, each of those keys must be larger than (or equal to) two additional keys, and so forth. This ordering is easy to see if we view the keys as being in a binary tree structure with edges from each key to the two keys known to be smaller.</p><p attribs="{'xml:space': 'preserve'}" id="_04877" smilref="Title.smil#_04877"> Definition. A binary tree is heap-ordered if the key in each node is larger than or equal to the keys in that node&#8217;s two children (if any).</p><p attribs="{'xml:space': 'preserve'}" id="_04878" smilref="Title.smil#_04878"> Equivalently, the key in each node of a heap-ordered binary tree is smaller than or equal to the key in that node&#8217;s parent (if any). Moving up from any node, we get a nondecreasing sequence of keys; moving down from any node, we get a nonincreasing sequence of keys. In particular:</p><p attribs="{'xml:space': 'preserve'}" id="_04879" smilref="Title.smil#_04879"> Proposition O. The largest key in a heap-ordered binary tree is found at the root.</p><p attribs="{'xml:space': 'preserve'}" id="_04880" smilref="Title.smil#_04880"> Proof : By induction on the size of the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_04881" smilref="Title.smil#_04881"> Binary heap representation. If we use a linked representation for heap-ordered binary trees, we would need to have three links associated with each key to allow travel up and down the tree (each node would have one pointer to its parent and one to each child). It is particularly convenient, instead, to use a complete binary tree like the one drawn at right. We draw such a structure by placing the root node and then proceeding down the page and from left to right, drawing and connecting two nodes beneath each node on the previous level until we have drawn N nodes. Complete trees provide the opportunity to use a compact array representation that does not involve explicit links. Speci&#64257; cally, we represent complete binary trees sequentially within an array by putting the nodes in level order, with the root at position 1, its children at positions 2 and 3, their children in positions 4, 5, 6, and 7, and so on.</p><p attribs="{'xml:space': 'preserve'}" id="_04882" smilref="Title.smil#_04882"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04883" smilref="Title.smil#_04883"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04884" smilref="Title.smil#_04884"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04885" smilref="Title.smil#_04885"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04886" smilref="Title.smil#_04886"> A heap-ordered complete binary tree</p><p attribs="{'xml:space': 'preserve'}" id="_04887" smilref="Title.smil#_04887"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04888" smilref="Title.smil#_04888"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04889" smilref="Title.smil#_04889"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04890" smilref="Title.smil#_04890"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04891" smilref="Title.smil#_04891"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04892" smilref="Title.smil#_04892"> H</p><p attribs="{'xml:space': 'preserve'}" id="_04893" smilref="Title.smil#_04893"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04894" smilref="Title.smil#_04894" /><pagenum id="p327" page="normal" smilref="Title.smil#p327" /><p attribs="{'xml:space': 'preserve'}" id="_04895" smilref="Title.smil#_04895"> 314</p><p attribs="{'xml:space': 'preserve'}" id="_04896" smilref="Title.smil#_04896"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04897" smilref="Title.smil#_04897"> Definition. A binary heap is a collection of keys arranged in a complete heap-or- dered binary tree, represented in level order in an array (not using the first entry).</p><p attribs="{'xml:space': 'preserve'}" id="_04898" smilref="Title.smil#_04898"> i 0 1 2 3 4 5 6 7 8 9 10 11 a[i] - T S R P N O A E I H G</p><p attribs="{'xml:space': 'preserve'}" id="_04899" smilref="Title.smil#_04899"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04900" smilref="Title.smil#_04900"> S R</p><p attribs="{'xml:space': 'preserve'}" id="_04901" smilref="Title.smil#_04901"> P N O A</p><p attribs="{'xml:space': 'preserve'}" id="_04902" smilref="Title.smil#_04902"> E I H G</p><p attribs="{'xml:space': 'preserve'}" id="_04903" smilref="Title.smil#_04903"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04904" smilref="Title.smil#_04904"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04905" smilref="Title.smil#_04905"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_04906" smilref="Title.smil#_04906"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04907" smilref="Title.smil#_04907"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_04908" smilref="Title.smil#_04908"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04909" smilref="Title.smil#_04909"> (For brevity, from now on we drop the &#8220;binary&#8221; modifier and use the term heap when referring to a binary heap.) In a heap, the parent of the node in position k is in position &#9123;k /2&#9126; and, con- versely, the two children of the node in position k are in positions 2k and 2k + 1. Instead of using explicit links (as in the binary tree structures that we will consider in Chapter 3), we can travel up and down by doing simple arithmetic on array indices: to move up the tree from a[k] we set k to k/2; to move down the tree we set k to 2*k or</p><p attribs="{'xml:space': 'preserve'}" id="_04910" smilref="Title.smil#_04910"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_04911" smilref="Title.smil#_04911"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04912" smilref="Title.smil#_04912"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_04913" smilref="Title.smil#_04913"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04914" smilref="Title.smil#_04914"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_04915" smilref="Title.smil#_04915"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04916" smilref="Title.smil#_04916"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_04917" smilref="Title.smil#_04917"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04918" smilref="Title.smil#_04918"> 2*k+1.</p><p attribs="{'xml:space': 'preserve'}" id="_04919" smilref="Title.smil#_04919"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_04920" smilref="Title.smil#_04920"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04921" smilref="Title.smil#_04921"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_04922" smilref="Title.smil#_04922"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04923" smilref="Title.smil#_04923"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_04924" smilref="Title.smil#_04924"> H</p><p attribs="{'xml:space': 'preserve'}" id="_04925" smilref="Title.smil#_04925"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04926" smilref="Title.smil#_04926"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_04927" smilref="Title.smil#_04927"> Heap representations</p><p attribs="{'xml:space': 'preserve'}" id="_04928" smilref="Title.smil#_04928"> Complete binary trees represented as arrays (heaps) are rigid structures, but they have just enough flexibility to allow us to implement ef&#64257; - cient priority-queue operations. Speci&#64257; cally, we will use them to develop logarithmic-time insert and remove the maximum implemen- tations. These algorithms take advantage of the capability to move up and down paths in the tree without pointers and have guaranteed logarithmic performance because of the following property of complete binary trees:</p><p attribs="{'xml:space': 'preserve'}" id="_04929" smilref="Title.smil#_04929"> Proposition P. The height of a complete binary tree of size N is &#9123; lg N &#9126; . Proof : The stated result is easy to prove by induction or by noting that the height increases by 1 when N is a power of 2.</p><p attribs="{'xml:space': 'preserve'}" id="_04930" smilref="Title.smil#_04930" /><pagenum id="p328" page="normal" smilref="Title.smil#p328" /><p attribs="{'xml:space': 'preserve'}" id="_04931" smilref="Title.smil#_04931"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_04932" smilref="Title.smil#_04932"> 315</p><p attribs="{'xml:space': 'preserve'}" id="_04933" smilref="Title.smil#_04933"> private void exch(int i, int j) { Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; }</p><p attribs="{'xml:space': 'preserve'}" id="_04934" smilref="Title.smil#_04934"> private boolean less(int i, int j) { return pq[i].compareTo(pq[j]) &lt; 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_04935" smilref="Title.smil#_04935"> Algorithms on heaps We represent a heap of size N in private array pq[] of length N + 1, with pq[0] unused and the heap in pq[1] through pq[N]. As for sorting algorithms, we access keys only through private helper functions less() and exch(), but since all items are in the instance variable pq[], we use the more compact implementations on the next page that do not involve passing the array name as a parameter. The heap operations that we consider work by first making a simple modification that could violate the heap condition, then traveling through the heap, modifying the heap as required to ensure that the heap condition is satisfied everywhere. We refer to this process as reheapifying, or restoring heap order. There are two cases. When the priority of some node is increased (or a new node is added at the bottom of a heap), we have to travel up the heap to restore the heap order. When the priority of some node is decreased (for example, if we replace the node at the root with a new node that has a smaller key), we have to travel down the heap to restore the heap order. First, we will consider how to implement these two basic auxiliary operations; then, we shall see how to use them to implement insert and remove the maximum.</p><p attribs="{'xml:space': 'preserve'}" id="_04936" smilref="Title.smil#_04936"> Compare and exchange methods for heap implementations</p><p attribs="{'xml:space': 'preserve'}" id="_04937" smilref="Title.smil#_04937"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04938" smilref="Title.smil#_04938"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04939" smilref="Title.smil#_04939"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04940" smilref="Title.smil#_04940"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04941" smilref="Title.smil#_04941"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_04942" smilref="Title.smil#_04942"> H</p><p attribs="{'xml:space': 'preserve'}" id="_04943" smilref="Title.smil#_04943"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04944" smilref="Title.smil#_04944"> Bottom-up reheapify ( swim). If the heap order is violated because a node&#8217;s key becomes larger than that node&#8217;s parent&#8217;s key, then we can make progress toward fixing the violation by exchanging the node with its parent. After the exchange, the node is larger than both its children (one is the old parent, and the other is smaller than the old parent because it was a child of that node) but the node may still be larger than its par- ent. We can fix that violation in the same way, and so forth, moving up the heap until we reach a node with a larger key, or the root. Coding this process is straightforward when you keep in mind that the parent of the node at position k in a heap is at position k/2. The loop in swim() preserves the invariant that the only place the heap</p><p attribs="{'xml:space': 'preserve'}" id="_04945" smilref="Title.smil#_04945"> violates heap order (larger key than parent)</p><p attribs="{'xml:space': 'preserve'}" id="_04946" smilref="Title.smil#_04946"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04947" smilref="Title.smil#_04947"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_04948" smilref="Title.smil#_04948"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04949" smilref="Title.smil#_04949"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_04950" smilref="Title.smil#_04950"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04951" smilref="Title.smil#_04951"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_04952" smilref="Title.smil#_04952"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04953" smilref="Title.smil#_04953"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04954" smilref="Title.smil#_04954"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04955" smilref="Title.smil#_04955"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04956" smilref="Title.smil#_04956"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04957" smilref="Title.smil#_04957"> H</p><p attribs="{'xml:space': 'preserve'}" id="_04958" smilref="Title.smil#_04958"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04959" smilref="Title.smil#_04959"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04960" smilref="Title.smil#_04960"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04961" smilref="Title.smil#_04961"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04962" smilref="Title.smil#_04962"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04963" smilref="Title.smil#_04963"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04964" smilref="Title.smil#_04964"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04965" smilref="Title.smil#_04965"> Bottom-up reheapify (swim)</p><p attribs="{'xml:space': 'preserve'}" id="_04966" smilref="Title.smil#_04966" /><pagenum id="p329" page="normal" smilref="Title.smil#p329" /><p attribs="{'xml:space': 'preserve'}" id="_04967" smilref="Title.smil#_04967"> 316</p><p attribs="{'xml:space': 'preserve'}" id="_04968" smilref="Title.smil#_04968"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_04969" smilref="Title.smil#_04969"> violates heap order (smaller than a child)</p><p attribs="{'xml:space': 'preserve'}" id="_04970" smilref="Title.smil#_04970"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04971" smilref="Title.smil#_04971"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_04972" smilref="Title.smil#_04972"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04973" smilref="Title.smil#_04973"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_04974" smilref="Title.smil#_04974"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04975" smilref="Title.smil#_04975"> P</p><p attribs="{'xml:space': 'preserve'}" id="_04976" smilref="Title.smil#_04976"> E</p><p attribs="{'xml:space': 'preserve'}" id="_04977" smilref="Title.smil#_04977"> I</p><p attribs="{'xml:space': 'preserve'}" id="_04978" smilref="Title.smil#_04978"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04979" smilref="Title.smil#_04979"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_04980" smilref="Title.smil#_04980"> Top-down reheapify (sink)</p><p attribs="{'xml:space': 'preserve'}" id="_04981" smilref="Title.smil#_04981"> order could be violated is when the node at position k might be larger than its parent. Therefore, when we get to a place where that node is not larger than its parent, we know that the heap order is satisfied throughout the heap. To justify the method&#8217;s name, we think of the new node, having too large a key, as having to swim to a higher level in the heap.</p><p attribs="{'xml:space': 'preserve'}" id="_04982" smilref="Title.smil#_04982"> private void swim(int k) { while (k &gt; 1 &amp;&amp; less(k/2, k)) { exch(k/2, k); k = k/2; } }</p><p attribs="{'xml:space': 'preserve'}" id="_04983" smilref="Title.smil#_04983"> Bottom-up reheapify (swim) implementation</p><p attribs="{'xml:space': 'preserve'}" id="_04984" smilref="Title.smil#_04984"> S</p><p attribs="{'xml:space': 'preserve'}" id="_04985" smilref="Title.smil#_04985"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04986" smilref="Title.smil#_04986"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04987" smilref="Title.smil#_04987"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04988" smilref="Title.smil#_04988"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04989" smilref="Title.smil#_04989"> H</p><p attribs="{'xml:space': 'preserve'}" id="_04990" smilref="Title.smil#_04990"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_04991" smilref="Title.smil#_04991"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04992" smilref="Title.smil#_04992"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04993" smilref="Title.smil#_04993"> A</p><p attribs="{'xml:space': 'preserve'}" id="_04994" smilref="Title.smil#_04994"> R</p><p attribs="{'xml:space': 'preserve'}" id="_04995" smilref="Title.smil#_04995"> O</p><p attribs="{'xml:space': 'preserve'}" id="_04996" smilref="Title.smil#_04996"> T</p><p attribs="{'xml:space': 'preserve'}" id="_04997" smilref="Title.smil#_04997"> G</p><p attribs="{'xml:space': 'preserve'}" id="_04998" smilref="Title.smil#_04998"> N</p><p attribs="{'xml:space': 'preserve'}" id="_04999" smilref="Title.smil#_04999"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05000" smilref="Title.smil#_05000"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_05001" smilref="Title.smil#_05001"> Top-down reheapify (sink). If the heap order is violated because a node&#8217;s key becomes smaller than one or both of that node&#8217;s children&#8217;s keys, then we can make progress toward fi x- ing the violation by exchanging the node with the larger of its two children. This switch may cause a violation at the child; we fix that violation in the same way, and so forth, moving down the heap until we reach a node with both children smaller (or equal), or the bottom. The code again follows directly from the fact that the children of the node at position k in a heap are at positions 2k and 2k+1. To justify the method&#8217;s name, we think about the node, having too small a key, as having to sink to a lower level in the heap.</p><p attribs="{'xml:space': 'preserve'}" id="_05002" smilref="Title.smil#_05002"> private void sink(int k) { while (2*k &lt;= N) { int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; } }</p><p attribs="{'xml:space': 'preserve'}" id="_05003" smilref="Title.smil#_05003"> If we imagine the heap to represent a cutthroat corporate hierarchy, with each of the children of a node representing subordinates (and the parent representing the immediate superior), then these operations have amusing interpreta- tions. The swim() operation corresponds to a promising new manager arriving on the scene, being promoted up the chain of command (by exchanging jobs with any lower- qualified boss) until the new person encounters a higher-quali&#64257; ed boss. The sink() operation is analogous to the situation when the president of the company resigns and is replaced by someone from the outside. If the president&#8217;s most powerful subordinate</p><p attribs="{'xml:space': 'preserve'}" id="_05004" smilref="Title.smil#_05004"> Top -down reheapify (sink) implementation</p><p attribs="{'xml:space': 'preserve'}" id="_05005" smilref="Title.smil#_05005" /><pagenum id="p330" page="normal" smilref="Title.smil#p330" /><p attribs="{'xml:space': 'preserve'}" id="_05006" smilref="Title.smil#_05006"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05007" smilref="Title.smil#_05007"> 317</p><p attribs="{'xml:space': 'preserve'}" id="_05008" smilref="Title.smil#_05008"> is stronger than the new person, they exchange jobs, and we move down the chain of command, demoting the new person and promoting others until the level of competence of the new person is reached, where there is no higher-quali&#64257; ed subordinate. These idealized scenarios may rarely be seen in the real world, but they may help you better understand basic operation on heaps. These sink() and swim() operations provide the basis for efficient implementation of the priority-queue API, as diagrammed below and implemented in Algorithm 2.6 on the next page.</p><p attribs="{'xml:space': 'preserve'}" id="_05009" smilref="Title.smil#_05009"> Insert. We add the new key at the end of the array, increment the size of the heap, and then swim up through the heap with that key to restore the heap condition.</p><p attribs="{'xml:space': 'preserve'}" id="_05010" smilref="Title.smil#_05010"> Remove the maximum. We take the largest item off the top, put the item from the end of the heap at the top, decrement the size of the heap, and then sink down through the heap with that key to restore the heap condition.</p><p attribs="{'xml:space': 'preserve'}" id="_05011" smilref="Title.smil#_05011"> Algorithm 2.6 solves the basic problem that we posed at the beginning of this section: it is a priority-queue API implementation for which both insert and delete the maximum are guaranteed to take time logarithmic in the size of the queue.</p><p attribs="{'xml:space': 'preserve'}" id="_05012" smilref="Title.smil#_05012"> insert</p><p attribs="{'xml:space': 'preserve'}" id="_05013" smilref="Title.smil#_05013"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05014" smilref="Title.smil#_05014"> remove the maximum</p><p attribs="{'xml:space': 'preserve'}" id="_05015" smilref="Title.smil#_05015"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05016" smilref="Title.smil#_05016"> key to remove</p><p attribs="{'xml:space': 'preserve'}" id="_05017" smilref="Title.smil#_05017"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05018" smilref="Title.smil#_05018"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05019" smilref="Title.smil#_05019"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05020" smilref="Title.smil#_05020"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05021" smilref="Title.smil#_05021"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05022" smilref="Title.smil#_05022"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05023" smilref="Title.smil#_05023"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05024" smilref="Title.smil#_05024"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05025" smilref="Title.smil#_05025"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05026" smilref="Title.smil#_05026"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05027" smilref="Title.smil#_05027"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05028" smilref="Title.smil#_05028"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05029" smilref="Title.smil#_05029"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05030" smilref="Title.smil#_05030"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05031" smilref="Title.smil#_05031"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05032" smilref="Title.smil#_05032"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05033" smilref="Title.smil#_05033"> key to insert</p><p attribs="{'xml:space': 'preserve'}" id="_05034" smilref="Title.smil#_05034"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05035" smilref="Title.smil#_05035"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05036" smilref="Title.smil#_05036"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05037" smilref="Title.smil#_05037"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05038" smilref="Title.smil#_05038"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05039" smilref="Title.smil#_05039"> exchange key with root</p><p attribs="{'xml:space': 'preserve'}" id="_05040" smilref="Title.smil#_05040"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05041" smilref="Title.smil#_05041"> violates heap order</p><p attribs="{'xml:space': 'preserve'}" id="_05042" smilref="Title.smil#_05042"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05043" smilref="Title.smil#_05043"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05044" smilref="Title.smil#_05044"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05045" smilref="Title.smil#_05045"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05046" smilref="Title.smil#_05046"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05047" smilref="Title.smil#_05047"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05048" smilref="Title.smil#_05048"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05049" smilref="Title.smil#_05049"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05050" smilref="Title.smil#_05050"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05051" smilref="Title.smil#_05051"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05052" smilref="Title.smil#_05052"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05053" smilref="Title.smil#_05053"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05054" smilref="Title.smil#_05054"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05055" smilref="Title.smil#_05055"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05056" smilref="Title.smil#_05056"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05057" smilref="Title.smil#_05057"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05058" smilref="Title.smil#_05058"> add key to heap violates heap order</p><p attribs="{'xml:space': 'preserve'}" id="_05059" smilref="Title.smil#_05059"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05060" smilref="Title.smil#_05060"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05061" smilref="Title.smil#_05061"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05062" smilref="Title.smil#_05062"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05063" smilref="Title.smil#_05063"> remove node from heap</p><p attribs="{'xml:space': 'preserve'}" id="_05064" smilref="Title.smil#_05064"> swim up</p><p attribs="{'xml:space': 'preserve'}" id="_05065" smilref="Title.smil#_05065"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05066" smilref="Title.smil#_05066"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05067" smilref="Title.smil#_05067"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05068" smilref="Title.smil#_05068"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05069" smilref="Title.smil#_05069"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05070" smilref="Title.smil#_05070"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05071" smilref="Title.smil#_05071"> sink down</p><p attribs="{'xml:space': 'preserve'}" id="_05072" smilref="Title.smil#_05072"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05073" smilref="Title.smil#_05073"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05074" smilref="Title.smil#_05074"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05075" smilref="Title.smil#_05075"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05076" smilref="Title.smil#_05076"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05077" smilref="Title.smil#_05077"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05078" smilref="Title.smil#_05078"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05079" smilref="Title.smil#_05079"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05080" smilref="Title.smil#_05080"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05081" smilref="Title.smil#_05081"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05082" smilref="Title.smil#_05082"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05083" smilref="Title.smil#_05083"> H</p><p attribs="{'xml:space': 'preserve'}" id="_05084" smilref="Title.smil#_05084"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05085" smilref="Title.smil#_05085"> I</p><p attribs="{'xml:space': 'preserve'}" id="_05086" smilref="Title.smil#_05086"> G</p><p attribs="{'xml:space': 'preserve'}" id="_05087" smilref="Title.smil#_05087"> Heap operations</p><p attribs="{'xml:space': 'preserve'}" id="_05088" smilref="Title.smil#_05088" /><pagenum id="p331" page="normal" smilref="Title.smil#p331" /><p attribs="{'xml:space': 'preserve'}" id="_05089" smilref="Title.smil#_05089"> 318</p><p attribs="{'xml:space': 'preserve'}" id="_05090" smilref="Title.smil#_05090"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05091" smilref="Title.smil#_05091"> ALGORITHM 2.6 Heap priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_05092" smilref="Title.smil#_05092"> public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt; { private Key[] pq; private int N = 0;</p><p attribs="{'xml:space': 'preserve'}" id="_05093" smilref="Title.smil#_05093"> // heap-ordered complete binary tree // in pq[1..N] with pq[0] unused</p><p attribs="{'xml:space': 'preserve'}" id="_05094" smilref="Title.smil#_05094"> public MaxPQ(int maxN) { pq = (Key[]) new Comparable[maxN+1]; }</p><p attribs="{'xml:space': 'preserve'}" id="_05095" smilref="Title.smil#_05095"> public boolean isEmpty() { return N == 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_05096" smilref="Title.smil#_05096"> public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_05097" smilref="Title.smil#_05097"> public void insert(Key v) { pq[++N] = v; swim(N); }</p><p attribs="{'xml:space': 'preserve'}" id="_05098" smilref="Title.smil#_05098"> public Key delMax() { Key max = pq[1]; exch(1, N--); pq[N+1] = null; sink(1); return max; }</p><p attribs="{'xml:space': 'preserve'}" id="_05099" smilref="Title.smil#_05099"> // Retrieve max key from top. // Exchange with last item. // Avoid loitering. // Restore heap property.</p><p attribs="{'xml:space': 'preserve'}" id="_05100" smilref="Title.smil#_05100"> // See pages 315-316 for implementations of these helper methods. private boolean less(int i, int j) private void exch(int i, int j) private void swim(int k) private void sink(int k) }</p><p attribs="{'xml:space': 'preserve'}" id="_05101" smilref="Title.smil#_05101"> The priority queue is maintained in a heap-ordered complete binary tree in the array pq[] with pq[0] unused and the N keys in the priority queue in pq[1] through pq[N]. To implement insert(), we increment N, add the new element at the end, then use swim() to restore the heap order. For delMax(), we take the value to be returned from pq[1], then move pq[N] to pq[1], decrement the size of the heap, and use sink() to restore the heap condition. We also set the now-unused position pq[N+1] to null to allow the system to reclaim the memory associated with it. Code for dynamic array resizing is omitted, as usual (see Section 1.3). See Exercise 2.4.19 for the other constructors.</p><p attribs="{'xml:space': 'preserve'}" id="_05102" smilref="Title.smil#_05102" /><pagenum id="p332" page="normal" smilref="Title.smil#p332" /><p attribs="{'xml:space': 'preserve'}" id="_05103" smilref="Title.smil#_05103"> Proposition Q. In an N-key priority queue, the heap algorithms require no more than 1 + lg N compares for insert and no more than 2 lg N compares for remove the maximum. Proof : By Proposition P, both operations involve moving along a path between the root and the bottom of the heap whose number of links is no more than lg N. The remove the maximum operation requires two compares for each node on the path (except at the bottom): one to find the child with the larger key, the other to decide whether that child needs to be promoted.</p><p attribs="{'xml:space': 'preserve'}" id="_05104" smilref="Title.smil#_05104"> For typical applications that require a large number of intermixed insert and remove the maximum operations in a large priority queue, Proposition Q represents an important performance breakthrough, summarized in the table shown on page 312. Where elementary implementations using an ordered array or an unordered array require linear time for one of the operations, a heap-based implementation provides a guarantee that both operations complete in logarithmic time. This improvement can make the difference between solving a problem and not being able to address it at all.</p><p attribs="{'xml:space': 'preserve'}" id="_05105" smilref="Title.smil#_05105"> Multiway heaps. It is not difficult to modify our code to build heaps based on an array representation of complete heap-ordered ternary trees, with an entry at position k larger than or equal to entries at positions 3k&#11002;1, 3k, and 3k&#11001;1 and smaller than or equal to entries at position &#9123;(k+1) &#11408; 3&#9126;, for all indices between 1 and N in an array of N items, and not much more difficult to use d-ary heaps for any given d. There is a tradeoff between the lower cost from the reduced tree height (log d N) and the higher cost of finding the largest of the d children at each node. This tradeoff is dependent on details of the implementation and the expected relative frequency of operations.</p><p attribs="{'xml:space': 'preserve'}" id="_05106" smilref="Title.smil#_05106"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05107" smilref="Title.smil#_05107"> 319</p><p attribs="{'xml:space': 'preserve'}" id="_05108" smilref="Title.smil#_05108"> insert P</p><p attribs="{'xml:space': 'preserve'}" id="_05109" smilref="Title.smil#_05109"> insert Q</p><p attribs="{'xml:space': 'preserve'}" id="_05110" smilref="Title.smil#_05110"> insert E</p><p attribs="{'xml:space': 'preserve'}" id="_05111" smilref="Title.smil#_05111"> remove max (Q)</p><p attribs="{'xml:space': 'preserve'}" id="_05112" smilref="Title.smil#_05112"> insert X</p><p attribs="{'xml:space': 'preserve'}" id="_05113" smilref="Title.smil#_05113"> insert A</p><p attribs="{'xml:space': 'preserve'}" id="_05114" smilref="Title.smil#_05114"> insert M</p><p attribs="{'xml:space': 'preserve'}" id="_05115" smilref="Title.smil#_05115"> remove max (X)</p><p attribs="{'xml:space': 'preserve'}" id="_05116" smilref="Title.smil#_05116"> insert P</p><p attribs="{'xml:space': 'preserve'}" id="_05117" smilref="Title.smil#_05117"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05118" smilref="Title.smil#_05118"> Q</p><p attribs="{'xml:space': 'preserve'}" id="_05119" smilref="Title.smil#_05119"> Q</p><p attribs="{'xml:space': 'preserve'}" id="_05120" smilref="Title.smil#_05120"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05121" smilref="Title.smil#_05121"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05122" smilref="Title.smil#_05122"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05123" smilref="Title.smil#_05123"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05124" smilref="Title.smil#_05124"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05125" smilref="Title.smil#_05125"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05126" smilref="Title.smil#_05126"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05127" smilref="Title.smil#_05127"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05128" smilref="Title.smil#_05128"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05129" smilref="Title.smil#_05129"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05130" smilref="Title.smil#_05130"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05131" smilref="Title.smil#_05131"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05132" smilref="Title.smil#_05132"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05133" smilref="Title.smil#_05133"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05134" smilref="Title.smil#_05134"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05135" smilref="Title.smil#_05135"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05136" smilref="Title.smil#_05136"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05137" smilref="Title.smil#_05137"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05138" smilref="Title.smil#_05138"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05139" smilref="Title.smil#_05139"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05140" smilref="Title.smil#_05140"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05141" smilref="Title.smil#_05141"> insert L</p><p attribs="{'xml:space': 'preserve'}" id="_05142" smilref="Title.smil#_05142"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05143" smilref="Title.smil#_05143"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05144" smilref="Title.smil#_05144"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05145" smilref="Title.smil#_05145"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05146" smilref="Title.smil#_05146"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05147" smilref="Title.smil#_05147"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05148" smilref="Title.smil#_05148"> insert E</p><p attribs="{'xml:space': 'preserve'}" id="_05149" smilref="Title.smil#_05149"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05150" smilref="Title.smil#_05150"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05151" smilref="Title.smil#_05151"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05152" smilref="Title.smil#_05152"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05153" smilref="Title.smil#_05153"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05154" smilref="Title.smil#_05154"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05155" smilref="Title.smil#_05155"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05156" smilref="Title.smil#_05156"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05157" smilref="Title.smil#_05157"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05158" smilref="Title.smil#_05158"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05159" smilref="Title.smil#_05159"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05160" smilref="Title.smil#_05160"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05161" smilref="Title.smil#_05161"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05162" smilref="Title.smil#_05162"> remove max (P)</p><p attribs="{'xml:space': 'preserve'}" id="_05163" smilref="Title.smil#_05163"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05164" smilref="Title.smil#_05164"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05165" smilref="Title.smil#_05165"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05166" smilref="Title.smil#_05166"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05167" smilref="Title.smil#_05167"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05168" smilref="Title.smil#_05168"> Priority queue operations in a heap</p><p attribs="{'xml:space': 'preserve'}" id="_05169" smilref="Title.smil#_05169" /><pagenum id="p333" page="normal" smilref="Title.smil#p333" /><p attribs="{'xml:space': 'preserve'}" id="_05170" smilref="Title.smil#_05170"> 320</p><p attribs="{'xml:space': 'preserve'}" id="_05171" smilref="Title.smil#_05171"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05172" smilref="Title.smil#_05172"> Array resizing. We can add a no-argument constructor, code for array doubling in insert(), and code for array halving in delMax(), just as we did for stacks in Section 1.3. Thus, clients need not be concerned about arbitrary size restrictions. The logarithmic time bounds implied by PROPOSITION Q are amortized when the size of the priority queue is arbitrary and the arrays are resized (see Exercise 2.4.22). Immutability of keys. The priority queue contains objects that are created by clients but assumes that client code does not change the keys (which might invalidate the heap-order invariant). It is possible to develop mechanisms to enforce this assumption, but programmers typically do not do so because they complicate the code and are likely to degrade performance.</p><p attribs="{'xml:space': 'preserve'}" id="_05173" smilref="Title.smil#_05173"> Index priority queue. In many applications, it makes sense to allow clients to refer to items that are already on the priority queue. One easy way to do so is to associate a unique integer index with each item. Moreover, it is often the case that clients have a universe of items of a known size N and perhaps are using (parallel) arrays to store information about the items, so other unrelated client code might already be using an integer index to refer to items. These considerations lead us to the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_05174" smilref="Title.smil#_05174"> public class IndexMinPQ&lt;Item extends Comparable&lt;Item&gt;&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_05175" smilref="Title.smil#_05175"> IndexMinPQ(int maxN)</p><p attribs="{'xml:space': 'preserve'}" id="_05176" smilref="Title.smil#_05176"> create a priority queue of capacity maxN with possible indices between 0 and maxN-1</p><p attribs="{'xml:space': 'preserve'}" id="_05177" smilref="Title.smil#_05177"> void insert(int k, Item item) insert item ; associate it with k</p><p attribs="{'xml:space': 'preserve'}" id="_05178" smilref="Title.smil#_05178"> boolean contains(int k)</p><p attribs="{'xml:space': 'preserve'}" id="_05179" smilref="Title.smil#_05179"> void delete(int k)</p><p attribs="{'xml:space': 'preserve'}" id="_05180" smilref="Title.smil#_05180"> void change(int k, Item item) change the item associated with k to item is k associated with some item? remove k and its associated item return a minimal item return a minimal item&#8217;s index remove a minimal item and return its index is the priority queue empty? number of items in the priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_05181" smilref="Title.smil#_05181"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_05182" smilref="Title.smil#_05182"> Item min()</p><p attribs="{'xml:space': 'preserve'}" id="_05183" smilref="Title.smil#_05183"> int minIndex()</p><p attribs="{'xml:space': 'preserve'}" id="_05184" smilref="Title.smil#_05184"> int delMin()</p><p attribs="{'xml:space': 'preserve'}" id="_05185" smilref="Title.smil#_05185"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_05186" smilref="Title.smil#_05186"> API for a generic priority queue with associated indices</p><p attribs="{'xml:space': 'preserve'}" id="_05187" smilref="Title.smil#_05187" /><pagenum id="p334" page="normal" smilref="Title.smil#p334" /><p attribs="{'xml:space': 'preserve'}" id="_05188" smilref="Title.smil#_05188"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05189" smilref="Title.smil#_05189"> 321</p><p attribs="{'xml:space': 'preserve'}" id="_05190" smilref="Title.smil#_05190"> A useful way of thinking of this data type is as implementing an array, but with fast access to the smallest entry in the array. Actually it does even better&#8212;it gives fast access to the minimum entry in a specified subset of an array&#8217;s entries (the ones that have been inserted. In other words, you can think of an IndexMinPQ named pq as representing a subset of an array pq[0..N-1] of items. Think of the call pq.insert(k, item) as adding k to the subset and setting pq[k] = item and the call pq.change(k, item) as setting pq[k] = item, both also maintaining data structures needed to support the other operations, most importantly delMin() (remove and return the index of the minimum key) and change() (change the item associated with an index that is already in the data structure&#8212;just as in pq[i] = item). These operations are important in many applications and are enabled by our ability to refer to the key (with the index). Exercise 2.4.33 describes how to extend Algorithm 2.6 to implement index priority queues with remarkable efficiency and with remarkably little code. Intuitively, when an item in the heap changes, we can restore the heap invariant with a sink operation (if the key decreases) and a swim operation (if the key increases). To perform the operations, we use the index to find the item in the heap. The ability to locate an item in the heap also allows us to add the delete() operation to the API.</p><p attribs="{'xml:space': 'preserve'}" id="_05191" smilref="Title.smil#_05191"> contains()</p><p attribs="{'xml:space': 'preserve'}" id="_05192" smilref="Title.smil#_05192"> operation</p><p attribs="{'xml:space': 'preserve'}" id="_05193" smilref="Title.smil#_05193"> insert()</p><p attribs="{'xml:space': 'preserve'}" id="_05194" smilref="Title.smil#_05194"> change()</p><p attribs="{'xml:space': 'preserve'}" id="_05195" smilref="Title.smil#_05195"> delete()</p><p attribs="{'xml:space': 'preserve'}" id="_05196" smilref="Title.smil#_05196"> order of growth of number of compares</p><p attribs="{'xml:space': 'preserve'}" id="_05197" smilref="Title.smil#_05197"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_05198" smilref="Title.smil#_05198"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_05199" smilref="Title.smil#_05199"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05200" smilref="Title.smil#_05200"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_05201" smilref="Title.smil#_05201"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05202" smilref="Title.smil#_05202"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05203" smilref="Title.smil#_05203"> Proposition Q (continued). In an index priority queue of size N, the number of compares required is proportional to at most log N for insert, change priority, delete, and remove the minimum.</p><p attribs="{'xml:space': 'preserve'}" id="_05204" smilref="Title.smil#_05204"> min()</p><p attribs="{'xml:space': 'preserve'}" id="_05205" smilref="Title.smil#_05205"> minIndex()</p><p attribs="{'xml:space': 'preserve'}" id="_05206" smilref="Title.smil#_05206"> Proof : Immediate from inspection of the code and the fact that all paths in a heap are of length at most ~lg N.</p><p attribs="{'xml:space': 'preserve'}" id="_05207" smilref="Title.smil#_05207"> delMin()</p><p attribs="{'xml:space': 'preserve'}" id="_05208" smilref="Title.smil#_05208"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_05209" smilref="Title.smil#_05209"> Worst-case costs for an N-item heap-based indexed priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_05210" smilref="Title.smil#_05210"> This discussion is for a minimum-oriented queue; as usual, we also implement on the booksite a maximum-oriented version IndexMaxPQ. Index priority-queue client. The IndexMinPQ client Multiway on page 322 solves the multiway merge problem: it merges together several sorted input streams into one sorted output stream. This problem arises in many applications: the streams might be the output of scientific instruments (sorted by time), lists of information from the web such as music or movies (sorted by title or artist name), commercial transactions (sorted by account number or time), or whatever. If you have the space, you might just read them all into an array and sort them, but with a priority queue, you can read input streams and put them in sorted order on the output no matter how long they are.</p><p attribs="{'xml:space': 'preserve'}" id="_05211" smilref="Title.smil#_05211" /><pagenum id="p335" page="normal" smilref="Title.smil#p335" /><p attribs="{'xml:space': 'preserve'}" id="_05212" smilref="Title.smil#_05212"> 322</p><p attribs="{'xml:space': 'preserve'}" id="_05213" smilref="Title.smil#_05213"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05214" smilref="Title.smil#_05214"> Multiway merge priority-queue client</p><p attribs="{'xml:space': 'preserve'}" id="_05215" smilref="Title.smil#_05215"> public class Multiway { public static void merge(In[] streams) { int N = streams.length; IndexMinPQ&lt;String&gt; pq = new IndexMinPQ&lt;String&gt;(N);</p><p attribs="{'xml:space': 'preserve'}" id="_05216" smilref="Title.smil#_05216"> for (int i = 0; i &lt; N; i++) if (!streams[i].isEmpty()) pq.insert(i, streams[i].readString());</p><p attribs="{'xml:space': 'preserve'}" id="_05217" smilref="Title.smil#_05217"> while (!pq.isEmpty()) { StdOut.println(pq.min()); int i = pq.delMin(); if (!streams[i].isEmpty()) pq.insert(i, streams[i].readString()); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05218" smilref="Title.smil#_05218"> public static void main(String[] args) { int N = args.length; In[] streams = new In[N]; for (int i = 0; i &lt; N; i++) streams[i] = new In(args[i]); merge(streams); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05219" smilref="Title.smil#_05219"> This IndexMinPQ client merges together the sorted input streams given as command-line arguments into a single sorted output stream on standard output (see text). Each stream index is associated with a key (the next string in the stream). After initialization, it enters a loop that prints the smallest string in the queue and removes the corresponding entry, then adds a new entry for the next string in that stream. For economy, the output is shown on one line below&#8212;the actual output is one string per line.</p><p attribs="{'xml:space': 'preserve'}" id="_05220" smilref="Title.smil#_05220"> % more m1.txt A B C F G I I Z % more m2.txt B D H P Q Q % more m3.txt A B E F J N</p><p attribs="{'xml:space': 'preserve'}" id="_05221" smilref="Title.smil#_05221"> % java Multiway m1.txt m2.txt m3.txt A A B B B C D E F F G H I I J N P Q Q Z</p><p attribs="{'xml:space': 'preserve'}" id="_05222" smilref="Title.smil#_05222" /></level3><level3 id="_00043"><h3 id="ch2-s4-ss15" smilref="Title.smil#ch2-s4-ss15" xml:space="preserve">Heapsort</h3><pagenum id="p336" page="normal" smilref="Title.smil#p336" /><p attribs="{'xml:space': 'preserve'}" id="_05223" smilref="Title.smil#_05223"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05224" smilref="Title.smil#_05224"> 323</p><p attribs="{'xml:space': 'preserve'}" id="_05225" smilref="Title.smil#_05225"> Heapsort We can use any priority queue to develop a sorting method. We insert all the items to be sorted into a minimum-oriented priority queue, then repeatedly use remove the minimum to remove them all in order. Using a priority queue represented as an unordered array in this way corresponds to doing a selection sort; using an ordered array corresponds to doing an insertion sort. What sorting method do we get if we use a heap? An entirely different one! Next, we use the heap to develop a classic elegant sorting algorithm known as heapsort. Heapsort breaks into two phases: heap construction, where we reorganize the original array into a heap, and the sortdown, where we pull the items out of the heap in decreasing order to build the sorted result. For consistency with the code we have studied, we use a maximum-oriented priority queue and repeatedly remove the maximum. Focus- ing on the task of sorting, we abandon the notion of hiding the representation of the priority queue and use swim() and sink() directly. Doing so allows us to sort an array without needing any extra space, by maintaining the heap within the array to be sorted.</p><p attribs="{'xml:space': 'preserve'}" id="_05226" smilref="Title.smil#_05226"> Heap construction. How difficult is the process of building a heap from N given items? Certainly we can accomplish this task in time proportional to N log N, by proceeding from left to right through the array, using swim() to ensure that the items to the left of the scanning pointer make up a heap-ordered complete tree, like successive priority- queue insertions. A clever method that is much more efficient is to proceed from right to left, using sink() to make subheaps as we go. Every position in the array is the root of a small subheap; sink() works for such subheaps, as well. If the two children of a node are heaps, then calling sink() on that node makes the subtree rooted at the parent a heap. This process establishes the heap order inductively. The scan starts halfway back through the array because we can skip the subheaps of size 1. The scan ends at position 1, when we finish building the heap with one call to sink(). As the first phase of a sort, heap construction is a bit counterintuitive, because its goal is to produce a heap-ordered result, which has the largest item first in the array (and other larger items near the beginning), not at the end, where it is destined to fi nish.</p><p attribs="{'xml:space': 'preserve'}" id="_05227" smilref="Title.smil#_05227"> Proposition R. Sink-based heap construction uses fewer than 2N compares and fewer than N exchanges to construct a heap from N items.</p><p attribs="{'xml:space': 'preserve'}" id="_05228" smilref="Title.smil#_05228"> Proof : This fact follows from the observation that most of the heaps processed are small. For example, to build a heap of 127 items, we process 32 heaps of size 3, 16 heaps of size 7, 8 heaps of size 15, 4 heaps of size 31, 2 heaps of size 63, and 1 heap of size 127, so 32&#183;1 + 16&#183;2 + 8&#183;3 + 4&#183;4 + 2&#183;5 + 1&#183;6 = 120 exchanges (twice as many compares) are required (at worst). See Exercise 2.4.20 for a complete proof.</p><p attribs="{'xml:space': 'preserve'}" id="_05229" smilref="Title.smil#_05229" /><pagenum id="p337" page="normal" smilref="Title.smil#p337" /><p attribs="{'xml:space': 'preserve'}" id="_05230" smilref="Title.smil#_05230"> 324</p><p attribs="{'xml:space': 'preserve'}" id="_05231" smilref="Title.smil#_05231"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05232" smilref="Title.smil#_05232"> ALGORITHM 2.7 Heapsort</p><p attribs="{'xml:space': 'preserve'}" id="_05233" smilref="Title.smil#_05233"> public static void sort(Comparable[] a) { int N = a.length; for (int k = N/2; k &gt;= 1; k--) sink(a, k, N); while (N &gt; 1) { exch(a, 1, N--); sink(a, 1, N); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05234" smilref="Title.smil#_05234"> This code sorts a[1] through a[N] using the sink() method (modi&#64257; ed to take a[] and N as argu- ments). The for loop constructs the heap; then the while loop exchanges the largest element a[1] with a[N] and then repairs the heap, continuing until the heap is empty. Decrementing the array indices in the implementations of exch() and less() gives an implementation that sorts a[0] through a[N-1], consistent with our other sorts.</p><p attribs="{'xml:space': 'preserve'}" id="_05235" smilref="Title.smil#_05235"> initial values</p><p attribs="{'xml:space': 'preserve'}" id="_05236" smilref="Title.smil#_05236"> heap-ordered</p><p attribs="{'xml:space': 'preserve'}" id="_05237" smilref="Title.smil#_05237"> a[i] N k 0 1 2 3 4 5 6 7 8 9 10 11 S O R T E X A M P L E 11 5 S O R T L X A M P E E 11 4 S O R T L X A M P E E 11 3 S O X T L R A M P E E 11 2 S T X P L R A M O E E 11 1 X T S P L R A M O E E X T S P L R A M O E E 10 1 T P S O L R A M E E X 9 1 S P R O L E A M E T X 8 1 R P E O L E A M S T X 7 1 P O E M L E A R S T X 6 1 O M E A L E P R S T X 5 1 M L E A E O P R S T X 4 1 L E E A M O P R S T X 3 1 E A E L M O P R S T X 2 1 E A E L M O P R S T X 1 1 A E E L M O P R S T X A E E L M O P R S T X</p><p attribs="{'xml:space': 'preserve'}" id="_05238" smilref="Title.smil#_05238"> sorted result</p><p attribs="{'xml:space': 'preserve'}" id="_05239" smilref="Title.smil#_05239"> Heapsort trace (array contents just after each sink)</p><p attribs="{'xml:space': 'preserve'}" id="_05240" smilref="Title.smil#_05240" /><pagenum id="p338" page="normal" smilref="Title.smil#p338" /><p attribs="{'xml:space': 'preserve'}" id="_05241" smilref="Title.smil#_05241"> sink(5, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_05242" smilref="Title.smil#_05242"> sink(4, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_05243" smilref="Title.smil#_05243"> sink(3, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_05244" smilref="Title.smil#_05244"> sink(2, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_05245" smilref="Title.smil#_05245"> sink(1, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_05246" smilref="Title.smil#_05246"> exch(1, 6) sink(1, 5)</p><p attribs="{'xml:space': 'preserve'}" id="_05247" smilref="Title.smil#_05247"> exch(1, 5) sink(1, 4)</p><p attribs="{'xml:space': 'preserve'}" id="_05248" smilref="Title.smil#_05248"> exch(1, 4) sink(1, 3)</p><p attribs="{'xml:space': 'preserve'}" id="_05249" smilref="Title.smil#_05249"> exch(1, 3) sink(1, 2)</p><p attribs="{'xml:space': 'preserve'}" id="_05250" smilref="Title.smil#_05250"> exch(1, 2) sink(1, 1)</p><p attribs="{'xml:space': 'preserve'}" id="_05251" smilref="Title.smil#_05251"> sortdown</p><p attribs="{'xml:space': 'preserve'}" id="_05252" smilref="Title.smil#_05252"> exch(1, 11) sink(1, 10)</p><p attribs="{'xml:space': 'preserve'}" id="_05253" smilref="Title.smil#_05253"> exch(1, 10) sink(1, 9)</p><p attribs="{'xml:space': 'preserve'}" id="_05254" smilref="Title.smil#_05254"> exch(1, 9) sink(1, 8)</p><p attribs="{'xml:space': 'preserve'}" id="_05255" smilref="Title.smil#_05255"> exch(1, 8) sink(1, 7)</p><p attribs="{'xml:space': 'preserve'}" id="_05256" smilref="Title.smil#_05256"> exch(1, 7) sink(1, 6)</p><p attribs="{'xml:space': 'preserve'}" id="_05257" smilref="Title.smil#_05257"> Heapsort: constructing (left) and sorting down (right) a heap</p><p attribs="{'xml:space': 'preserve'}" id="_05258" smilref="Title.smil#_05258"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05259" smilref="Title.smil#_05259"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05260" smilref="Title.smil#_05260"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05261" smilref="Title.smil#_05261"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05262" smilref="Title.smil#_05262"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05263" smilref="Title.smil#_05263"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05264" smilref="Title.smil#_05264"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05265" smilref="Title.smil#_05265"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05266" smilref="Title.smil#_05266"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05267" smilref="Title.smil#_05267"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05268" smilref="Title.smil#_05268"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05269" smilref="Title.smil#_05269"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05270" smilref="Title.smil#_05270"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05271" smilref="Title.smil#_05271"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05272" smilref="Title.smil#_05272"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05273" smilref="Title.smil#_05273"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05274" smilref="Title.smil#_05274"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05275" smilref="Title.smil#_05275"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05276" smilref="Title.smil#_05276"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05277" smilref="Title.smil#_05277"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05278" smilref="Title.smil#_05278"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05279" smilref="Title.smil#_05279"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05280" smilref="Title.smil#_05280"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05281" smilref="Title.smil#_05281"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05282" smilref="Title.smil#_05282"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05283" smilref="Title.smil#_05283"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05284" smilref="Title.smil#_05284"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05285" smilref="Title.smil#_05285"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05286" smilref="Title.smil#_05286"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05287" smilref="Title.smil#_05287"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05288" smilref="Title.smil#_05288"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05289" smilref="Title.smil#_05289"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05290" smilref="Title.smil#_05290"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05291" smilref="Title.smil#_05291"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05292" smilref="Title.smil#_05292"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05293" smilref="Title.smil#_05293"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05294" smilref="Title.smil#_05294"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05295" smilref="Title.smil#_05295"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05296" smilref="Title.smil#_05296"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05297" smilref="Title.smil#_05297"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05298" smilref="Title.smil#_05298"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05299" smilref="Title.smil#_05299"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05300" smilref="Title.smil#_05300"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05301" smilref="Title.smil#_05301"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05302" smilref="Title.smil#_05302"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05303" smilref="Title.smil#_05303"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05304" smilref="Title.smil#_05304"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05305" smilref="Title.smil#_05305"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05306" smilref="Title.smil#_05306"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05307" smilref="Title.smil#_05307"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05308" smilref="Title.smil#_05308"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05309" smilref="Title.smil#_05309"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05310" smilref="Title.smil#_05310"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05311" smilref="Title.smil#_05311"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05312" smilref="Title.smil#_05312"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05313" smilref="Title.smil#_05313"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05314" smilref="Title.smil#_05314"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05315" smilref="Title.smil#_05315"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05316" smilref="Title.smil#_05316"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05317" smilref="Title.smil#_05317"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05318" smilref="Title.smil#_05318"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05319" smilref="Title.smil#_05319"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05320" smilref="Title.smil#_05320"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05321" smilref="Title.smil#_05321"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05322" smilref="Title.smil#_05322"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05323" smilref="Title.smil#_05323"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05324" smilref="Title.smil#_05324"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05325" smilref="Title.smil#_05325"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05326" smilref="Title.smil#_05326"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05327" smilref="Title.smil#_05327"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05328" smilref="Title.smil#_05328"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05329" smilref="Title.smil#_05329"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05330" smilref="Title.smil#_05330"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05331" smilref="Title.smil#_05331"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05332" smilref="Title.smil#_05332"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05333" smilref="Title.smil#_05333"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05334" smilref="Title.smil#_05334"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05335" smilref="Title.smil#_05335"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05336" smilref="Title.smil#_05336"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05337" smilref="Title.smil#_05337"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05338" smilref="Title.smil#_05338"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05339" smilref="Title.smil#_05339"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05340" smilref="Title.smil#_05340"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05341" smilref="Title.smil#_05341"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05342" smilref="Title.smil#_05342"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05343" smilref="Title.smil#_05343"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05344" smilref="Title.smil#_05344"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05345" smilref="Title.smil#_05345"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05346" smilref="Title.smil#_05346"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05347" smilref="Title.smil#_05347"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05348" smilref="Title.smil#_05348"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05349" smilref="Title.smil#_05349"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05350" smilref="Title.smil#_05350"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05351" smilref="Title.smil#_05351"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05352" smilref="Title.smil#_05352"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05353" smilref="Title.smil#_05353"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05354" smilref="Title.smil#_05354"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05355" smilref="Title.smil#_05355"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05356" smilref="Title.smil#_05356"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05357" smilref="Title.smil#_05357"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05358" smilref="Title.smil#_05358"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05359" smilref="Title.smil#_05359"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05360" smilref="Title.smil#_05360"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05361" smilref="Title.smil#_05361"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05362" smilref="Title.smil#_05362"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05363" smilref="Title.smil#_05363"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05364" smilref="Title.smil#_05364"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05365" smilref="Title.smil#_05365"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05366" smilref="Title.smil#_05366"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05367" smilref="Title.smil#_05367"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05368" smilref="Title.smil#_05368"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05369" smilref="Title.smil#_05369"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05370" smilref="Title.smil#_05370"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05371" smilref="Title.smil#_05371"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05372" smilref="Title.smil#_05372"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05373" smilref="Title.smil#_05373"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05374" smilref="Title.smil#_05374"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05375" smilref="Title.smil#_05375"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05376" smilref="Title.smil#_05376"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05377" smilref="Title.smil#_05377"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05378" smilref="Title.smil#_05378"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05379" smilref="Title.smil#_05379"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05380" smilref="Title.smil#_05380"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05381" smilref="Title.smil#_05381"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05382" smilref="Title.smil#_05382"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05383" smilref="Title.smil#_05383"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05384" smilref="Title.smil#_05384"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05385" smilref="Title.smil#_05385"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05386" smilref="Title.smil#_05386"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05387" smilref="Title.smil#_05387"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05388" smilref="Title.smil#_05388"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05389" smilref="Title.smil#_05389"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05390" smilref="Title.smil#_05390"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05391" smilref="Title.smil#_05391"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05392" smilref="Title.smil#_05392"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05393" smilref="Title.smil#_05393"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05394" smilref="Title.smil#_05394"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05395" smilref="Title.smil#_05395"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05396" smilref="Title.smil#_05396"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05397" smilref="Title.smil#_05397"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05398" smilref="Title.smil#_05398"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05399" smilref="Title.smil#_05399"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05400" smilref="Title.smil#_05400"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05401" smilref="Title.smil#_05401"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05402" smilref="Title.smil#_05402"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05403" smilref="Title.smil#_05403"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05404" smilref="Title.smil#_05404"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05405" smilref="Title.smil#_05405"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05406" smilref="Title.smil#_05406"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05407" smilref="Title.smil#_05407"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05408" smilref="Title.smil#_05408"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05409" smilref="Title.smil#_05409"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05410" smilref="Title.smil#_05410"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05411" smilref="Title.smil#_05411"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05412" smilref="Title.smil#_05412"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05413" smilref="Title.smil#_05413"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05414" smilref="Title.smil#_05414"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05415" smilref="Title.smil#_05415"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05416" smilref="Title.smil#_05416"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05417" smilref="Title.smil#_05417"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05418" smilref="Title.smil#_05418"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05419" smilref="Title.smil#_05419"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05420" smilref="Title.smil#_05420"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05421" smilref="Title.smil#_05421"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05422" smilref="Title.smil#_05422"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05423" smilref="Title.smil#_05423"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05424" smilref="Title.smil#_05424"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05425" smilref="Title.smil#_05425"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05426" smilref="Title.smil#_05426"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05427" smilref="Title.smil#_05427"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05428" smilref="Title.smil#_05428"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05429" smilref="Title.smil#_05429"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05430" smilref="Title.smil#_05430"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05431" smilref="Title.smil#_05431"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05432" smilref="Title.smil#_05432"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05433" smilref="Title.smil#_05433"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05434" smilref="Title.smil#_05434"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05435" smilref="Title.smil#_05435"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05436" smilref="Title.smil#_05436"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05437" smilref="Title.smil#_05437"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05438" smilref="Title.smil#_05438"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05439" smilref="Title.smil#_05439"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05440" smilref="Title.smil#_05440"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05441" smilref="Title.smil#_05441"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05442" smilref="Title.smil#_05442"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05443" smilref="Title.smil#_05443"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05444" smilref="Title.smil#_05444"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05445" smilref="Title.smil#_05445"> R</p><p attribs="{'xml:space': 'preserve'}" id="_05446" smilref="Title.smil#_05446"> A</p><p attribs="{'xml:space': 'preserve'}" id="_05447" smilref="Title.smil#_05447"> S</p><p attribs="{'xml:space': 'preserve'}" id="_05448" smilref="Title.smil#_05448"> M</p><p attribs="{'xml:space': 'preserve'}" id="_05449" smilref="Title.smil#_05449"> T</p><p attribs="{'xml:space': 'preserve'}" id="_05450" smilref="Title.smil#_05450"> L</p><p attribs="{'xml:space': 'preserve'}" id="_05451" smilref="Title.smil#_05451"> X</p><p attribs="{'xml:space': 'preserve'}" id="_05452" smilref="Title.smil#_05452"> O</p><p attribs="{'xml:space': 'preserve'}" id="_05453" smilref="Title.smil#_05453"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05454" smilref="Title.smil#_05454"> E</p><p attribs="{'xml:space': 'preserve'}" id="_05455" smilref="Title.smil#_05455"> P</p><p attribs="{'xml:space': 'preserve'}" id="_05456" smilref="Title.smil#_05456"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05457" smilref="Title.smil#_05457"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_05458" smilref="Title.smil#_05458"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_05459" smilref="Title.smil#_05459"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_05460" smilref="Title.smil#_05460"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_05461" smilref="Title.smil#_05461"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_05462" smilref="Title.smil#_05462"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_05463" smilref="Title.smil#_05463"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_05464" smilref="Title.smil#_05464"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_05465" smilref="Title.smil#_05465"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_05466" smilref="Title.smil#_05466"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_05467" smilref="Title.smil#_05467"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05468" smilref="Title.smil#_05468"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_05469" smilref="Title.smil#_05469"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_05470" smilref="Title.smil#_05470"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_05471" smilref="Title.smil#_05471"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_05472" smilref="Title.smil#_05472"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_05473" smilref="Title.smil#_05473"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_05474" smilref="Title.smil#_05474"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_05475" smilref="Title.smil#_05475"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_05476" smilref="Title.smil#_05476"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_05477" smilref="Title.smil#_05477"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_05478" smilref="Title.smil#_05478"> heap construction</p><p attribs="{'xml:space': 'preserve'}" id="_05479" smilref="Title.smil#_05479"> result (heap-ordered)</p><p attribs="{'xml:space': 'preserve'}" id="_05480" smilref="Title.smil#_05480"> result (sorted)</p><p attribs="{'xml:space': 'preserve'}" id="_05481" smilref="Title.smil#_05481"> starting point (heap-ordered)</p><p attribs="{'xml:space': 'preserve'}" id="_05482" smilref="Title.smil#_05482"> starting point (arbitrary order)</p><p attribs="{'xml:space': 'preserve'}" id="_05483" smilref="Title.smil#_05483"> 325</p><p attribs="{'xml:space': 'preserve'}" id="_05484" smilref="Title.smil#_05484"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05485" smilref="Title.smil#_05485" /><pagenum id="p339" page="normal" smilref="Title.smil#p339" /><p attribs="{'xml:space': 'preserve'}" id="_05486" smilref="Title.smil#_05486"> 326</p><p attribs="{'xml:space': 'preserve'}" id="_05487" smilref="Title.smil#_05487"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05488" smilref="Title.smil#_05488"> input</p><p attribs="{'xml:space': 'preserve'}" id="_05489" smilref="Title.smil#_05489"> heap- ordered</p><p attribs="{'xml:space': 'preserve'}" id="_05490" smilref="Title.smil#_05490"> red entries are items that sank</p><p attribs="{'xml:space': 'preserve'}" id="_05491" smilref="Title.smil#_05491"> gray entries do not move</p><p attribs="{'xml:space': 'preserve'}" id="_05492" smilref="Title.smil#_05492"> black entries are involved in exchanges</p><p attribs="{'xml:space': 'preserve'}" id="_05493" smilref="Title.smil#_05493"> sorted result</p><p attribs="{'xml:space': 'preserve'}" id="_05494" smilref="Title.smil#_05494"> Visual trace of heapsort</p><p attribs="{'xml:space': 'preserve'}" id="_05495" smilref="Title.smil#_05495"> Sortdown. Most of the work during heapsort is done during the second phase, where we remove the largest remaining item from the heap and put it into the array position vacated as the heap shrinks. This process is a bit like selection sort (taking the items in decreasing order instead of in increasing order), but it uses many fewer compares because the heap provides a much more efficient way to find the largest item in the unsorted part of the array.</p><p attribs="{'xml:space': 'preserve'}" id="_05496" smilref="Title.smil#_05496"> Proposition S. Heapsort uses fewer than 2N lg N + 2N compares (and half that many exchanges) to sort N items.</p><p attribs="{'xml:space': 'preserve'}" id="_05497" smilref="Title.smil#_05497"> Proof : The 2 N term covers the cost of heap construction (see Proposition R). The 2 N lg N term follows from bounding the cost of each sink operation during the sort- down by 2lg N (see Proposition PQ).</p><p attribs="{'xml:space': 'preserve'}" id="_05498" smilref="Title.smil#_05498"> Algorithm 2.7 is a full implementation based on these ideas, the classical heapsort algorithm, which was invented by J. W. J. Williams and refined by R. W. Floyd in 1964. Although the loops in this program seem to do different tasks (the first constructs the heap, and the second destroys the heap for the sortdown), they are both built around the sink() method. We provide an implementation outside of our priority-queue API to highlight the simplicity of the sorting algorithm (eight lines of code for sort() and another eight lines of code for sink()) and to make it an in-place sort. As usual, you can gain some insight into the operation of the algorithm by studying a visual trace. At fi rst, the process seems to do anything but sort, because large items are moving to the beginning of the array as the heap is being constructed. But then the method looks more like a mirror image of selection sort (except that it uses far fewer compares). As for all of the other methods that we have studied, various people have investigated ways to improve heap-based priority- queue implementations and heapsort. We now briefly consider one of them.</p><p attribs="{'xml:space': 'preserve'}" id="_05499" smilref="Title.smil#_05499" /><pagenum id="p340" page="normal" smilref="Title.smil#p340" /><p attribs="{'xml:space': 'preserve'}" id="_05500" smilref="Title.smil#_05500"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05501" smilref="Title.smil#_05501"> 327</p><p attribs="{'xml:space': 'preserve'}" id="_05502" smilref="Title.smil#_05502"> Sink to the bottom, then swim. Most items reinserted into the heap during sortdown go all the way to the bottom. Floyd observed in 1964 that we can thus save time by avoiding the check for whether the item has reached its position, simply promoting the larger of the two children until the bottom is reached, then moving back up the heap to the proper position. This idea cuts the number of compares by a factor of 2 as- ymptotically&#8212;close to the number used by mergesort (for a randomly-ordered array). The method requires extra bookkeeping, and it is useful in practice only when the cost of compares is relatively high (for example, when we are sorting items with strings or other types of long keys).</p><p attribs="{'xml:space': 'preserve'}" id="_05503" smilref="Title.smil#_05503"> Heapsort is significant in the study of the complexity of sorting (see page 279) because it is the only method that we have seen that is optimal (within a constant factor) in its use of both time and space&#8212;it is guaranteed to use ~2N lg N compares and constant extra space in the worst case. When space is very tight (for example, in an embedded system or on a low-cost mobile device) it is popular because it can be implemented with just a few dozen lines (even in machine code) while still providing optimal per- formance. However, it is rarely used in typical applications on modern systems because it has poor cache performance: array entries are rarely compared with nearby array entries, so the number of cache misses is far higher than for quicksort, mergesort, and even shellsort, where most compares are with nearby entries. On the other hand, the use of heaps to implement priority queues plays an increasingly important role in modern applications, because it provides an easy way to guarantee logarithmic running time for dynamic situations where large numbers of insert and remove the maximum operations are intermixed. We will encounter several examples later in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_05504" smilref="Title.smil#_05504" /><pagenum id="p341" page="normal" smilref="Title.smil#p341" /><p attribs="{'xml:space': 'preserve'}" id="_05505" smilref="Title.smil#_05505"> 328</p><p attribs="{'xml:space': 'preserve'}" id="_05506" smilref="Title.smil#_05506"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05507" smilref="Title.smil#_05507"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_05508" smilref="Title.smil#_05508"> Q. I&#8217;m still not clear on the purpose of priority queues. Why exactly don&#8217;t we just sort and then consider the items in increasing order in the sorted array? A. In some data-processing examples such as TopM and Multiway, the total amount of data is far too large to consider sorting (or even storing in memory). If you are looking for the top ten entries among a billion items, do you really want to sort a billion-entry array? With a priority queue, you can do it with a ten-entry priority queue. In other ex- amples, all the data does not even exist together at any point in time: we take something from the priority queue, process it, and as a result of processing it perhaps add some more things to the priority queue. Q. Why not use Comparable, as we do for sorts, instead of the generic Item in MaxPQ? A. Doing so would require the client to cast the return value of delMax() to an actual type, such as String. Generally, casts in client code are to be avoided. Q. Why not use a[0] in the heap representation? A. Doing so simplifies the arithmetic a bit. It is not difficult to implement the heap methods based on a 0-based heap where the children of a[0] are a[1] and a[2], the children of a[1] are a[3] and a[4], the children of a[2] are a[5] and a[6], and so forth, but most programmers prefer the simpler arithmetic that we use. Also, using a[0] as a sentinel value (in the parent of a[1]) is useful in some heap applications. Q. Building a heap in heapsort by inserting items one by one seems simpler to me than the tricky bottom-up method described on page 323 in the text. Why bother? A. For a sort implementation, it is 20 percent faster and requires half as much tricky code (no swim() needed). The difficulty of understanding an algorithm has not necessarily much to do with its simplicity, or its ef&#64257; ciency. Q. What happens if I leave off the extends Comparable&lt;Key&gt; phrase in an implementation like MaxPQ ? A. As usual, the easiest way for you to answer a question of this sort for yourself is to simply try it. If you do so for MaxPQ you will get a compile-time error:</p><p attribs="{'xml:space': 'preserve'}" id="_05509" smilref="Title.smil#_05509"> MaxPQ.java:21: cannot find symbol symbol : method compareTo(Item)</p><p attribs="{'xml:space': 'preserve'}" id="_05510" smilref="Title.smil#_05510"> which is Java&#8217;s way of telling you that it does not know about compareTo() in Item because you neglected to declare that Item extends Comparable&lt;Item&gt;.</p><p attribs="{'xml:space': 'preserve'}" id="_05511" smilref="Title.smil#_05511" /><pagenum id="p342" page="normal" smilref="Title.smil#p342" /><p attribs="{'xml:space': 'preserve'}" id="_05512" smilref="Title.smil#_05512"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05513" smilref="Title.smil#_05513"> 329</p><p attribs="{'xml:space': 'preserve'}" id="_05514" smilref="Title.smil#_05514"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_05515" smilref="Title.smil#_05515"> 2.4.1 Suppose that the sequence P R I O * R * * I * T * Y * * * Q U E * * *</p><p attribs="{'xml:space': 'preserve'}" id="_05516" smilref="Title.smil#_05516"> U * E (where a letter means insert and an asterisk means remove the maximum) is applied to an initially empty priority queue. Give the sequence of letters returned by the remove the maximum operations. 2.4.2 Criticize the following idea: To implement find the maximum in constant time, why not use a stack or a queue, but keep track of the maximum value inserted so far, then return that value for find the maximum? 2.4.3 Provide priority-queue implementations that support insert and remove the maximum, one for each of the following underlying data structures: unordered ar- ray, ordered array, unordered linked list, and linked list. Give a table of the worst-case bounds for each operation for each of your four implementations. 2.4.4 Is an array that is sorted in decreasing order a max-oriented heap? 2.4.5 Give the heap that results when the keys E A S Y Q U E S T I O N are inserted in that order into an initially empty max-oriented heap. 2.4.6 Using the conventions of Exercise 2.4.1, give the sequence of heaps produced</p><p attribs="{'xml:space': 'preserve'}" id="_05517" smilref="Title.smil#_05517"> when the operations P R I O * R * * I * T * Y * * * Q U E * * * U * E are</p><p attribs="{'xml:space': 'preserve'}" id="_05518" smilref="Title.smil#_05518"> performed on an initially empty max-oriented heap. 2.4.7 The largest item in a heap must appear in position 1, and the second largest must be in position 2 or position 3. Give the list of positions in a heap of size 31 where the kth largest (i) can appear, and (ii) cannot appear, for k=2, 3, 4 (assuming the values to be distinct). 2.4.8 Answer the previous exercise for the kth smallest item. 2.4.9 Draw all of the different heaps that can be made from the five keys A B C D E, then draw all of the different heaps that can be made from the five keys A A A B B. 2.4.10 Suppose that we wish to avoid wasting one position in a heap-ordered array pq[], putting the largest value in pq[0], its children in pq[1] and pq[2], and so forth, proceeding in level order. Where are the parents and children of pq[k]? 2.4.11 Suppose that your application will have a huge number of insert operations, but only a few remove the maximum operations. Which priority-queue implementation do you think would be most effective: heap, unordered array, or ordered array?</p><p attribs="{'xml:space': 'preserve'}" id="_05519" smilref="Title.smil#_05519" /><pagenum id="p343" page="normal" smilref="Title.smil#p343" /><p attribs="{'xml:space': 'preserve'}" id="_05520" smilref="Title.smil#_05520"> 330</p><p attribs="{'xml:space': 'preserve'}" id="_05521" smilref="Title.smil#_05521"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05522" smilref="Title.smil#_05522"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_05523" smilref="Title.smil#_05523"> 2.4.12 Suppose that your application will have a huge number of find the maximum operations, but a relatively small number of insert and remove the maximum operations. Which priority-queue implementation do you think would be most effective: heap, unordered array, or ordered array? 2.4.13 Describe a way to avoid the j &lt; N test in sink(). 2.4.14 What is the minimum number of items that must be exchanged during a remove the maximum operation in a heap of size N with no duplicate keys? Give a heap of size 15 for which the minimum is achieved. Answer the same questions for two and three successive remove the maximum operations. 2.4.15 Design a linear-time certification algorithm to check whether an array pq[] is a min-oriented heap. 2.4.16 For N=32, give arrays of items that make heapsort use as many and as few compares as possible. 2.4.17 Prove that building a minimum-oriented priority queue of size k then doing N &#11002; k replace the minimum (insert followed by remove the minimum) operations leaves the k largest of the N items in the priority queue. 2.4.18 In MaxPQ, suppose that a client calls insert() with an item that is larger than all items in the queue, and then immediately calls delMax(). Assume that there are no duplicate keys. Is the resulting heap identical to the heap as it was before these op- erations? Answer the same question for two insert() operations (the first with a key larger than all keys in the queue and the second for a key larger than that one) followed by two delMax() operations. 2.4.19 Implement the constructor for MaxPQ that takes an array of items as argument, using the bottom-up heap construction method described on page 323 in the text. 2.4.20 Prove that sink-based heap construction uses fewer than 2N compares and fewer than N exchanges.</p><p attribs="{'xml:space': 'preserve'}" id="_05524" smilref="Title.smil#_05524" /><pagenum id="p344" page="normal" smilref="Title.smil#p344" /><p attribs="{'xml:space': 'preserve'}" id="_05525" smilref="Title.smil#_05525"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05526" smilref="Title.smil#_05526"> 331</p><p attribs="{'xml:space': 'preserve'}" id="_05527" smilref="Title.smil#_05527"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_05528" smilref="Title.smil#_05528"> 2.4.21 Elementary data structures. Explain how to use a priority queue to implement the stack, queue, and randomized queue data types from Chapter 1. 2.4.22 Array resizing. Add array resizing to MaxPQ, and prove bounds like those of Proposition Q for array accesses, in an amortized sense. 2.4.23 Multiway heaps. Considering the cost of compares only, and assuming that it takes t compares to find the largest of t items, find the value of t that minimizes the coefficient of N lg N in the compare count when a t-ary heap is used in heapsort. First, assume a straightforward generalization of sink(); then, assume that Floyd&#8217;s method can save one compare in the inner loop. 2.4.24 Priority queue with explicit links. Implement a priority queue using a heap- ordered binary tree, but use a triply linked structure instead of an array. You will need three links per node: two to traverse down the tree and one to traverse up the tree. Your implementation should guarantee logarithmic running time per operation, even if no maximum priority-queue size is known ahead of time. 2.4.25 Computational number theory. Write a program that prints out all integers of the form a3 + b3 where a and b are integers between 0 and N in sorted order, without using excessive space. That is, instead of computing an array of the N2 sums and sorting them, build a minimum-oriented priority queue, initially containing (03, 0, 0), (13, 1, 0), (23, 2, 0), . . . , (N3, N, 0). Then, while the priority queue is nonempty, remove the smallest item(i3 + j3, i, j), print it, and then, if j &lt; N, insert the item (i3 + (j+1)3, i, j+1). Use this program to find all distinct integers a, b, c, and d between 0 and 106 such that a3 + b3 = c3 + d3. 2.4.26 Heap without exchanges. Because the exch() primitive is used in the sink() and swim() operations, the items are loaded and stored twice as often as necessary. Give more efficient implementations that avoid this inef&#64257; ciency, a la insertion sort (see</p><p attribs="{'xml:space': 'preserve'}" id="_05529" smilref="Title.smil#_05529"> Exercise 2.1.25).</p><p attribs="{'xml:space': 'preserve'}" id="_05530" smilref="Title.smil#_05530"> 2.4.27 Find the minimum. Add a min() method to MaxPQ. Your implementation should use constant time and constant extra space. 2.4.28 Selection fi lter. Write a TopM client that reads points (x, y, z) from standard in- put, takes a value M from the command line, and prints the M points that are closest to the origin in Euclidean distance. Estimate the running time of your client for N = 108</p><p attribs="{'xml:space': 'preserve'}" id="_05531" smilref="Title.smil#_05531" /><pagenum id="p345" page="normal" smilref="Title.smil#p345" /><p attribs="{'xml:space': 'preserve'}" id="_05532" smilref="Title.smil#_05532"> 332</p><p attribs="{'xml:space': 'preserve'}" id="_05533" smilref="Title.smil#_05533"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05534" smilref="Title.smil#_05534"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_05535" smilref="Title.smil#_05535"> and M = 104. 2.4.29 Min/max priority queue. Design a data type that supports the following opera- tions: insert, delete the maximum, and delete the minimum (all in logarithmic time); and find the maximum and find the minimum (both in constant time). Hint: Use two heaps. 2.4.30 Dynamic median-&#64257; nding. Design a data type that supports insert in logarithmic time, find the median in constant time, and delete the median in logarithmic time. Hint: Use a min-heap and a max-heap. 2.4.31 Fast insert. Develop a compare-based implementation of the MinPQ API such that insert uses ~ log log N compares and delete the minimum uses ~2 log N compares. Hint : Use binary search on parent pointers to find the ancestor in swim(). 2.4.32 Lower bound. Prove that it is impossible to develop a compare-based implementation of the MinPQ API such that both insert and delete the minimum guarantee to use ~N log log N compares. 2.4.33 Index priority-queue implementation. Implement the basic operations in the index priority-queue API on page 320 by modifying Algorithm 2.6 as follows: Change pq[] to hold indices, add an array keys[] to hold the key values, and add an array qp[] that is the inverse of pq[] &#8212; qp[i] gives the position of i in pq[] (the index j such that pq[j] is i). Then modify the code in Algorithm 2.6 to maintain these data structures. Use the convention that qp[i] = -1 if i is not on the queue, and include a method contains() that tests this condition. You need to modify the helper methods exch() and less() but not sink() or swim().</p><p attribs="{'xml:space': 'preserve'}" id="_05536" smilref="Title.smil#_05536" /><pagenum id="p346" page="normal" smilref="Title.smil#p346" /><p attribs="{'xml:space': 'preserve'}" id="_05537" smilref="Title.smil#_05537"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05538" smilref="Title.smil#_05538"> 333</p><p attribs="{'xml:space': 'preserve'}" id="_05539" smilref="Title.smil#_05539"> Partial solution :</p><p attribs="{'xml:space': 'preserve'}" id="_05540" smilref="Title.smil#_05540"> public class IndexMinPQ&lt;Key extends Comparable&lt;Key&gt;&gt; { private int N; // number of elements on PQ private int[] pq; // binary heap using 1-based indexing private int[] qp; // inverse: qp[pq[i]] = pq[qp[i]] = i private Key[] keys; // items with priorities public IndexMinPQ(int maxN) { keys = (Key[]) new Comparable[maxN + 1]; pq = new int[maxN + 1]; qp = new int[maxN + 1]; for (int i = 0; i &lt;= maxN; i++) qp[i] = -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_05541" smilref="Title.smil#_05541"> public boolean isEmpty() { return N == 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_05542" smilref="Title.smil#_05542"> public boolean contains(int k) { return qp[k] != -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_05543" smilref="Title.smil#_05543"> public void insert(int k, Key key) { N++; qp[k] = N; pq[N] = k; keys[k] = key; swim(N);</p><p attribs="{'xml:space': 'preserve'}" id="_05544" smilref="Title.smil#_05544"> }</p><p attribs="{'xml:space': 'preserve'}" id="_05545" smilref="Title.smil#_05545"> public Item min() { return keys[pq[1]]; }</p><p attribs="{'xml:space': 'preserve'}" id="_05546" smilref="Title.smil#_05546"> public int delMin() { int indexOfMin = pq[1]; exch(1, N--); sink(1); keys[pq[N+1]] = null; qp[pq[N+1]] = -1; return indexOfMin; }</p><p attribs="{'xml:space': 'preserve'}" id="_05547" smilref="Title.smil#_05547" /><pagenum id="p347" page="normal" smilref="Title.smil#p347" /><p attribs="{'xml:space': 'preserve'}" id="_05548" smilref="Title.smil#_05548"> 334</p><p attribs="{'xml:space': 'preserve'}" id="_05549" smilref="Title.smil#_05549"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05550" smilref="Title.smil#_05550"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_05551" smilref="Title.smil#_05551"> 2.4.34 Index priority-queue implementation (additional operations). Add minIndex(), change(), and delete() to your implementation of Exercise 2.4.33.</p><p attribs="{'xml:space': 'preserve'}" id="_05552" smilref="Title.smil#_05552"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_05553" smilref="Title.smil#_05553"> public int minIndex() { return pq[1]; }</p><p attribs="{'xml:space': 'preserve'}" id="_05554" smilref="Title.smil#_05554"> public void change(int k, Item item) { keys[k] = key; swim(qp[k]); sink(qp[k]); }</p><p attribs="{'xml:space': 'preserve'}" id="_05555" smilref="Title.smil#_05555"> public void delete(int k) { exch(k, N--); swim(qp[k]); sink(qp[k]); keys[pq[N+1]] = null; qp[pq[N+1]] = -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_05556" smilref="Title.smil#_05556"> 2.4.35 Sampling from a discrete probability distribution. Write a class Sample with a constructor that takes an array p[] of double values as argument and supports the following two operations: random()&#8212;return an index i with probability p[i]/T (where T is the sum of the numbers in p[])&#8212;and change(i, v)&#8212;change the value of p[i] to v. Hint: Use a complete binary tree where each node has implied weight p[i]. Store in each node the cumulative weight of all the nodes in its subtree. To generate a random index, pick a random number between 0 and T and use the cumulative weights to determine which branch of the subtree to explore. When updating p[i], change all of the weights of the nodes on the path from the root to i. Avoid explicit pointers, as we do for heaps.</p><p attribs="{'xml:space': 'preserve'}" id="_05557" smilref="Title.smil#_05557" /><pagenum id="p348" page="normal" smilref="Title.smil#p348" /><p attribs="{'xml:space': 'preserve'}" id="_05558" smilref="Title.smil#_05558"> 2 .4 </p><p attribs="{'xml:space': 'preserve'}" id="_05559" smilref="Title.smil#_05559"> 335</p><p attribs="{'xml:space': 'preserve'}" id="_05560" smilref="Title.smil#_05560"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_05561" smilref="Title.smil#_05561"> 2.4.36 Performance driver I. Write a performance driver client program that uses insert to fill a priority queue, then uses remove the maximum to remove half the keys, then uses insert to fill it up again, then uses remove the maximum to remove all the keys, doing so multiple times on random sequences of keys of various lengths ranging from small to large; measures the time taken for each run; and prints out or plots the average running times. 2.4.37 Performance driver II. Write a performance driver client program that uses insert to fill a priority queue, then does as many remove the maximum and insert operations as it can do in 1 second, doing so multiple times on random sequences of keys of various lengths ranging from small to large; and prints out or plots the average number of remove the maximum operations it was able to do. 2.4.38 Exercise driver. Write an exercise driver client program that uses the methods in our priority-queue interface of Algorithm 2.6 on difficult or pathological cases that might turn up in practical applications. Simple examples include keys that are already in order, keys in reverse order, all keys the same, and sequences of keys having only two distinct values. 2.4.39 Cost of construction. Determine empirically the percentage of time heapsort spends in the construction phase for N = 103, 106, and 109. 2.4.40 Floyd&#8217;s method. Implement a version of heapsort based on Floyd&#8217;s sink-to-the- bottom-and-then-swim idea, as described in the text. Count the number of compares used by your program and the number of compares used by the standard implementa- tion, for randomly ordered distinct keys with N = 103, 106, and 109. 2.4.41 Multiway heaps. Implement a version of heapsort based on complete heap- ordered 3-ary and 4-ary trees, as described in the text. Count the number of compares used by each and the number of compares used by the standard implementation, for randomly ordered distinct keys with N = 103, 106, and 109. 2.4.42 Preorder heaps. Implement a version of heapsort based on the idea of representing the heap-ordered tree in preorder rather than in level order. Count the number of compares used by your program and the number of compares used by the standard implementation, for randomly ordered keys with N = 103, 106, and 109.</p><p attribs="{'xml:space': 'preserve'}" id="_05562" smilref="Title.smil#_05562" /><pagenum id="p350" page="normal" smilref="Title.smil#p350" /><p attribs="{'xml:space': 'preserve'}" id="_05563" smilref="Title.smil#_05563"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05564" smilref="Title.smil#_05564"> 337</p><p attribs="{'xml:space': 'preserve'}" id="_05565" smilref="Title.smil#_05565"> Sorting various types of data Our implementations sort arrays of Comparable objects. This Java convention allows us to use Java&#8217;s callback mechanism to sort arrays of objects of any type that implements the Comparable interface. As described in Section 2.1, implementing Comparable amounts to defining a compareTo() method that implements a natural ordering for the type. We can use our code immediately to sort arrays of type String, Integer, Double, and other types such as File and URL, because these data types all implement Comparable. Being able to use the same code for all of those types is convenient, but typical applications involve working with data types that are defined for use within the application. Accordingly it is common to implement a compareTo() method for user-de&#64257; ned data types, so that they implement Comparable, thus enabling client code to sort arrays of that type (and build priority queues of values of that type).</p><p attribs="{'xml:space': 'preserve'}" id="_05566" smilref="Title.smil#_05566"> Transaction example. A prototypical breeding ground for sorting applications is commercial data processing. For example, imagine that a company engaged in internet commerce maintains a record for each transaction involving a customer account that contains all of the pertinent information, such as the customer name, date, amount, and so forth. Nowadays, a successful company needs to be able to handle millions and millions of such transactions. As we saw in Exercise 2.1.21, it is reasonable to decide that a natural ordering of such transactions is that they be ordered by amount, which we can implement by adding an appropriate compareTo() method in the class defi ni- tion. With such a defi nition, we could process an array a[] of Transactions by, for ex- ample, first sorting it with the call Quick.sort(a). Our sorting methods know nothing about our Transaction data type, but Java&#8217;s Comparable interface allows us to define a natural ordering so that we can use any of our methods to sort Transaction objects. Alternatively, we might specify that Transaction objects are to be ordered by date by implementing compareTo() to compare the Date fi elds. Since Date objects are themselves Comparable, we can just invoke the compareTo() method in Date rather than having to implement it from scratch. It is also reasonable to consider ordering this data by it customer fi eld; arranging to allow clients the flexibility to switch among multiple different orders is an interesting challenge that we will soon consider.</p><p attribs="{'xml:space': 'preserve'}" id="_05567" smilref="Title.smil#_05567"> public int compareTo(Transaction that) { return this.when.compareTo(that.when); }</p><p attribs="{'xml:space': 'preserve'}" id="_05568" smilref="Title.smil#_05568"> Alternate compareTo() implementation for sorting transactions by date</p><p attribs="{'xml:space': 'preserve'}" id="_05569" smilref="Title.smil#_05569" /><pagenum id="p351" page="normal" smilref="Title.smil#p351" /><p attribs="{'xml:space': 'preserve'}" id="_05570" smilref="Title.smil#_05570"> 338</p><p attribs="{'xml:space': 'preserve'}" id="_05571" smilref="Title.smil#_05571"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05572" smilref="Title.smil#_05572"> Pointer sorting. The approach we are using is known in the classical literature as pointer sorting, so called because we process references to items and do not move the data itself. In programming languages such as C and C++, programmers explicitly decide whether to manipulate data or pointers to data; in Java, pointer manipulation is implicit. Except for primitive numeric types, we always manipulate references to objects (pointers), not the objects themselves. Pointer sorting adds a level of indirection: the array contains references to the objects to be sorted, not the objects themselves. We briefly consider some associated issues, in the context of sorting. With multiple reference arrays, we can have multiple different sorted representations of different parts of a single body of data (perhaps using multiple keys, as described below). Keys are immutable. It stands to reason that an array might not remain sorted if a client is allowed to change the values of keys after the sort. Similarly, a priority queue can hardly be expected to operate properly if the client can change the values of keys between operations. In Java, it is wise to ensure that key values do not change by using immutable keys. Most of the standard data types that you are likely to use as keys, such as String, Integer, Double, and File, are immutable. Exchanges are inexpensive. Another advantage of using references is that we avoid the cost of moving full items. The cost saving is significant for arrays with large items (and small keys) because the compare needs to access just a small part of the item, and most of the item is not even touched during the sort. The reference approach makes the cost of an exchange roughly equal to the cost of a compare for general situations involving arbitrarily large items (at the cost of the extra space for the references). Indeed, if the keys are long, the exchanges might even wind up being less costly than the compare. One way to study the performance of algorithms that sort arrays of numbers is to simply look at the total number of compares and exchanges they use, implicitly making the assumption that the cost of exchanges is the same as the cost of compares. Conclusions based on this assumption are likely to apply to a broad class of applications in Java, because we are sorting reference objects.</p><p attribs="{'xml:space': 'preserve'}" id="_05573" smilref="Title.smil#_05573"> Alternate orderings. There are many applications where we want to use different orders for the objects that we are sorting, depending on the situation. The Java Comparator interface allows us to build multiple orders within a single class. It has a single public method compare() that compares two objects. If we have a data type that implements this interface, we can pass a Comparator to sort() (which passes it to less()) as in the example on the next page. The Comparator mechanism allows us to sort arrays of any type of object, using any total order that we wish to define for them. Using a Comparator instead of working with Comparable types better separates the definition of the type from the definition of what it means to compare two objects of</p><p attribs="{'xml:space': 'preserve'}" id="_05574" smilref="Title.smil#_05574" /><pagenum id="p352" page="normal" smilref="Title.smil#p352" /><p attribs="{'xml:space': 'preserve'}" id="_05575" smilref="Title.smil#_05575"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05576" smilref="Title.smil#_05576"> 339</p><p attribs="{'xml:space': 'preserve'}" id="_05577" smilref="Title.smil#_05577"> that type. Indeed, there are typically many possible ways to compare objects, and the Comparator mechanism allows us to choose among them. For instance, to sort an array a[] of strings without regard to whether characters are uppercase or lowercase you</p><p attribs="{'xml:space': 'preserve'}" id="_05578" smilref="Title.smil#_05578"> can just call Insertion.sort(a, String.CASE_INSENSITIVE_ORDER) which makes</p><p attribs="{'xml:space': 'preserve'}" id="_05579" smilref="Title.smil#_05579"> use of the CASE_INSENSITIVE_ORDER comparator defined in Java&#8217;s String class. As you can imagine, the precise rules for ordering strings are complicated and quite different for various natural languages, so Java has many String comparators.</p><p attribs="{'xml:space': 'preserve'}" id="_05580" smilref="Title.smil#_05580"> Items with multiple keys. In typical applications, items have multiple instance variables that might need to serve as sort keys. In our transaction example, one client may need to sort the transaction list by customer (for example, to bring together all transactions involving each customer); another client might need to sort the list by amount (for example, to identify high-value transactions); and other clients might need to use other fields as sort keys. The Comparator mechanism is precisely what we need to allow this fl exibility. We can define multiple comparators, as in the alternate implementation of Transaction shown on the bottom of the next page. With this defi nition, a client can sort an array of Transaction objects by time with the call</p><p attribs="{'xml:space': 'preserve'}" id="_05581" smilref="Title.smil#_05581"> Insertion.sort(a, new Transaction.WhenOrder())</p><p attribs="{'xml:space': 'preserve'}" id="_05582" smilref="Title.smil#_05582"> or by amount with the call</p><p attribs="{'xml:space': 'preserve'}" id="_05583" smilref="Title.smil#_05583"> Insertion.sort(a, new Transaction.HowMuchOrder()).</p><p attribs="{'xml:space': 'preserve'}" id="_05584" smilref="Title.smil#_05584"> The sort does each compare through a callback to the compare() method in Transaction that is specified by the client code. To avoid the cost of making a new Comparator object for each sort, we could use public final instance variables to define the comparators (as Java does for CASE_INSENSITIVE_ORDER).</p><p attribs="{'xml:space': 'preserve'}" id="_05585" smilref="Title.smil#_05585"> public static void sort(Object[] a, Comparator c) { int N = a.length; for (int i = 1; i &lt; N; i++) for (int j = i; j &gt; 0 &amp;&amp; less(c, a[j], a[j-1]); j--) exch(a, j, j-1); }</p><p attribs="{'xml:space': 'preserve'}" id="_05586" smilref="Title.smil#_05586"> private static boolean less(Comparator c, Object v, Object w) { return c.compare (v, w) &lt; 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_05587" smilref="Title.smil#_05587"> private static void exch(Object[] a, int i, int j) { Object t = a[i]; a[i] = a[j]; a[j] = t; }</p><p attribs="{'xml:space': 'preserve'}" id="_05588" smilref="Title.smil#_05588"> Insertion sorting with a Comparator</p><p attribs="{'xml:space': 'preserve'}" id="_05589" smilref="Title.smil#_05589" /></level3><level3 id="_00044"><h3 id="ch2-s5-ss16" smilref="Title.smil#ch2-s5-ss16" xml:space="preserve">Comparators</h3><pagenum id="p353" page="normal" smilref="Title.smil#p353" /><p attribs="{'xml:space': 'preserve'}" id="_05590" smilref="Title.smil#_05590"> 340</p><p attribs="{'xml:space': 'preserve'}" id="_05591" smilref="Title.smil#_05591"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05592" smilref="Title.smil#_05592"> Priority queues with comparators. The same flexibility to use comparators is also useful for priority queues. Extending our standard implementation in Algorithm 2.6 to support comparators involves the following steps:</p><p attribs="{'xml:space': 'preserve'}" id="_05593" smilref="Title.smil#_05593"> </p><p attribs="{'xml:space': 'preserve'}" id="_05594" smilref="Title.smil#_05594"> </p><p attribs="{'xml:space': 'preserve'}" id="_05595" smilref="Title.smil#_05595"> import java.util.Comparator;</p><p attribs="{'xml:space': 'preserve'}" id="_05596" smilref="Title.smil#_05596"> public class Transaction { ... private final String who; private final Date when; private final double amount; ... public static class WhoOrder implements Comparator&lt;Transaction&gt; { public int compare(Transaction v, Transaction w) { return v.who.compareTo(w.who); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05597" smilref="Title.smil#_05597"> public static class WhenOrder implements Comparator&lt;Transaction&gt; { public int compare(Transaction v, Transaction w) { return v.when.compareTo(w.when); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05598" smilref="Title.smil#_05598"> public static class HowMuchOrder implements Comparator&lt;Transaction&gt; { public int compare(Transaction v, Transaction w) { if (v.amount &lt; w.amount) return -1; if (v.amount &gt; w.amount) return +1; return 0; } } }</p><p attribs="{'xml:space': 'preserve'}" id="_05599" smilref="Title.smil#_05599"> Comparator implementation for Transaction data type</p><p attribs="{'xml:space': 'preserve'}" id="_05600" smilref="Title.smil#_05600" /></level3><level3 id="_00045"><h3 id="ch2-s5-ss17" smilref="Title.smil#ch2-s5-ss17" xml:space="preserve">Stability</h3><pagenum id="p354" page="normal" smilref="Title.smil#p354" /><p attribs="{'xml:space': 'preserve'}" id="_05601" smilref="Title.smil#_05601"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05602" smilref="Title.smil#_05602"> 341</p><p attribs="{'xml:space': 'preserve'}" id="_05603" smilref="Title.smil#_05603"> Stability. A sorting method is stable if it preserves the relative order of equal keys in the array. This property is frequently important. For example, consider an internet commerce application where we have to process a large number of events that have locations and timestamps. To begin, suppose that we store events in an array as they arrive, so they are in order of the timestamp in the array. Now suppose that the application requires that the transactions be separated out by location for further processing. One easy way to do so is to sort the array by location. If the sort is unstable, the transactions for each city may not necessarily be in order by timestamp after the sort. Often, programmers who are unfamiliar with stability are surprised, when they first encounter the situation, by the way an unstable algorithm seems to scramble the data. Some of the sorting methods that we have considered in this chapter are stable ( insertion sort and mergesort); many are not (selection sort, shellsort, quicksort, and heapsort). There are ways to trick any sort into stable behavior (see Exercise 2.5.18), but using a stable algorithm is generally preferable when stability is an essential requirement. It is easy to take stability for granted; actually, no practical method in common use achieves stability without using significant extra time or space (researchers have developed algorithms that do so, but applications programmers have judged them too complicated to be useful).</p><p attribs="{'xml:space': 'preserve'}" id="_05604" smilref="Title.smil#_05604"> sorted by time</p><p attribs="{'xml:space': 'preserve'}" id="_05605" smilref="Title.smil#_05605"> sorted by location (not stable)</p><p attribs="{'xml:space': 'preserve'}" id="_05606" smilref="Title.smil#_05606"> sorted by location (stable)</p><p attribs="{'xml:space': 'preserve'}" id="_05607" smilref="Title.smil#_05607"> Chicago 09:00:00 Phoenix 09:00:03 Houston 09:00:13 Chicago 09:00:59 Houston 09:01:10 Chicago 09:03:13 Seattle 09:10:11 Seattle 09:10:25 Phoenix 09:14:25 Chicago 09:19:32 Chicago 09:19:46 Chicago 09:21:05 Seattle 09:22:43 Seattle 09:22:54 Chicago 09:25:52 Chicago 09:35:21 Seattle 09:36:14 Phoenix 09:37:44</p><p attribs="{'xml:space': 'preserve'}" id="_05608" smilref="Title.smil#_05608"> Chicago 09:25:52 Chicago 09:03:13 Chicago 09:21:05 Chicago 09:19:46 Chicago 09:19:32 Chicago 09:00:00 Chicago 09:35:21 Chicago 09:00:59 Houston 09:01:10 Houston 09:00:13 Phoenix 09:37:44 Phoenix 09:00:03 Phoenix 09:14:25 Seattle 09:10:25 Seattle 09:36:14 Seattle 09:22:43 Seattle 09:10:11 Seattle 09:22:54</p><p attribs="{'xml:space': 'preserve'}" id="_05609" smilref="Title.smil#_05609"> Chicago 09:00:00 Chicago 09:00:59 Chicago 09:03:13 Chicago 09:19:32 Chicago 09:19:46 Chicago 09:21:05 Chicago 09:25:52 Chicago 09:35:21 Houston 09:00:13 Houston 09:01:10 Phoenix 09:00:03 Phoenix 09:14:25 Phoenix 09:37:44 Seattle 09:10:11 Seattle 09:10:25 Seattle 09:22:43 Seattle 09:22:54 Seattle 09:36:14</p><p attribs="{'xml:space': 'preserve'}" id="_05610" smilref="Title.smil#_05610"> no longer sorted by time</p><p attribs="{'xml:space': 'preserve'}" id="_05611" smilref="Title.smil#_05611"> Stability when sorting on a second key</p><p attribs="{'xml:space': 'preserve'}" id="_05612" smilref="Title.smil#_05612"> still sorted by time</p><p attribs="{'xml:space': 'preserve'}" id="_05613" smilref="Title.smil#_05613" /><pagenum id="p355" page="normal" smilref="Title.smil#p355" /><p attribs="{'xml:space': 'preserve'}" id="_05614" smilref="Title.smil#_05614"> 342</p><p attribs="{'xml:space': 'preserve'}" id="_05615" smilref="Title.smil#_05615"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05616" smilref="Title.smil#_05616"> Which sorting algorithm should I use? We have considered numerous sorting</p><p attribs="{'xml:space': 'preserve'}" id="_05617" smilref="Title.smil#_05617"> algorithms in this chapter, so this question is natural. Knowing which algorithm is best possible depends heavily on details of the application and implementation, but we have studied some general-purpose methods that can be nearly as effective as the best possible for a wide variety of applications. The table at the bottom of this page is a general guide that summarizes the important characteristics of the sort algorithms that we have studied in this chapter. In all cases but shellsort (where the growth rate is only an estimate), insertion sort (where the growth rate depends on the order of the input keys), and both versions of quicksort (where the growth rate is probabilitic and may depend on the distribution of input key values), multiplying these growth rates by appropriate constants gives an effective way to predict running time. The constants involved are partly algorithm-dependent (for example, heapsort uses twice the number of compares as mergesort and both do many more array accesses than quicksort) but are primarily dependent on the implementa- tion, the Java compiler, and your computer, which determine the number of machine instructions that are executed and the time that each requires. Most important, since they are constants, you can generally predict the running time for large N by running experiments for smaller N and extrapolating, using our standard doubling protocol.</p><p attribs="{'xml:space': 'preserve'}" id="_05618" smilref="Title.smil#_05618"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_05619" smilref="Title.smil#_05619"> stable?</p><p attribs="{'xml:space': 'preserve'}" id="_05620" smilref="Title.smil#_05620"> in place?</p><p attribs="{'xml:space': 'preserve'}" id="_05621" smilref="Title.smil#_05621"> order of growth to sort N items running time extra space</p><p attribs="{'xml:space': 'preserve'}" id="_05622" smilref="Title.smil#_05622"> notes</p><p attribs="{'xml:space': 'preserve'}" id="_05623" smilref="Title.smil#_05623"> selection sort</p><p attribs="{'xml:space': 'preserve'}" id="_05624" smilref="Title.smil#_05624"> insertion sort</p><p attribs="{'xml:space': 'preserve'}" id="_05625" smilref="Title.smil#_05625"> shellsort</p><p attribs="{'xml:space': 'preserve'}" id="_05626" smilref="Title.smil#_05626"> quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_05627" smilref="Title.smil#_05627"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05628" smilref="Title.smil#_05628"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05629" smilref="Title.smil#_05629"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05630" smilref="Title.smil#_05630"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05631" smilref="Title.smil#_05631"> 3-way quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_05632" smilref="Title.smil#_05632"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05633" smilref="Title.smil#_05633"> mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_05634" smilref="Title.smil#_05634"> heapsort</p><p attribs="{'xml:space': 'preserve'}" id="_05635" smilref="Title.smil#_05635"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05636" smilref="Title.smil#_05636"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05637" smilref="Title.smil#_05637"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05638" smilref="Title.smil#_05638"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05639" smilref="Title.smil#_05639"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05640" smilref="Title.smil#_05640"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05641" smilref="Title.smil#_05641"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05642" smilref="Title.smil#_05642"> no</p><p attribs="{'xml:space': 'preserve'}" id="_05643" smilref="Title.smil#_05643"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_05644" smilref="Title.smil#_05644"> N 2</p><p attribs="{'xml:space': 'preserve'}" id="_05645" smilref="Title.smil#_05645"> between N and N 2 N log N ?</p><p attribs="{'xml:space': 'preserve'}" id="_05646" smilref="Title.smil#_05646"> N 6/5 ?</p><p attribs="{'xml:space': 'preserve'}" id="_05647" smilref="Title.smil#_05647"> N log N</p><p attribs="{'xml:space': 'preserve'}" id="_05648" smilref="Title.smil#_05648"> between N and N log N</p><p attribs="{'xml:space': 'preserve'}" id="_05649" smilref="Title.smil#_05649"> N log N</p><p attribs="{'xml:space': 'preserve'}" id="_05650" smilref="Title.smil#_05650"> N log N</p><p attribs="{'xml:space': 'preserve'}" id="_05651" smilref="Title.smil#_05651"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05652" smilref="Title.smil#_05652"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05653" smilref="Title.smil#_05653"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05654" smilref="Title.smil#_05654"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_05655" smilref="Title.smil#_05655"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_05656" smilref="Title.smil#_05656"> N</p><p attribs="{'xml:space': 'preserve'}" id="_05657" smilref="Title.smil#_05657"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_05658" smilref="Title.smil#_05658"> Performance characteristics of sorting algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_05659" smilref="Title.smil#_05659"> depends on order of items</p><p attribs="{'xml:space': 'preserve'}" id="_05660" smilref="Title.smil#_05660"> probabilistic guarantee probabilistic, also depends on distribution of input keys</p><p attribs="{'xml:space': 'preserve'}" id="_05661" smilref="Title.smil#_05661" /><pagenum id="p356" page="normal" smilref="Title.smil#p356" /><p attribs="{'xml:space': 'preserve'}" id="_05662" smilref="Title.smil#_05662"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05663" smilref="Title.smil#_05663"> 343</p><p attribs="{'xml:space': 'preserve'}" id="_05664" smilref="Title.smil#_05664"> Property T. Quicksort is the fastest general-purpose sort.</p><p attribs="{'xml:space': 'preserve'}" id="_05665" smilref="Title.smil#_05665"> Evidence: This hypothesis is supported by countless implementations of quick- sort on countless computer systems since its invention decades ago. Generally, the reason that quicksort is fastest is that it has only a few instructions in its inner loop (and it does well with cache memories because it most often references data sequentially) so that its running time is ~c N lg N with the value of c smaller than the corresponding constants for other linearithmic sorts. With 3-way partitioning, quicksort becomes linear for certain key distributions likely to arise in practice, where other sorts are linearithmic.</p><p attribs="{'xml:space': 'preserve'}" id="_05666" smilref="Title.smil#_05666"> Thus, in most practical situations, quicksort is the method of choice. Still, given the broad reach of sorting and the broad variety of computers and systems, aflat statement like this is difficult to justify. For example, we have already seen one notable exception: if stability is important and space is available, mergesort might be best. We will see other exceptions in Chapter 5. With tools like SortCompare and a considerable amount of time and effort, you can do a more detailed study of comparative performance of these algorithms and the refinements that we have discussed for your computer, as discussed in several exercises at the end of this section. Perhaps the best way to interpret Prop- erty T is as saying that you certainly should seriously consider using quicksort in any sort application where running time is important.</p><p attribs="{'xml:space': 'preserve'}" id="_05667" smilref="Title.smil#_05667"> Sorting primitive types. In some performance-critical applications, the focus may be on sorting numbers, so it is reasonable to avoid the costs of using references and sort primitive types instead. For example, consider the difference between sorting an array of double values and sorting an array of Double values. In the former case, we exchange the numbers themselves and put them in order in the array ; in the latter, we exchange references to Double objects, which contain the numbers. If we are doing nothing more than sorting a huge array of numbers, we avoid paying the cost of storing an equal number of references plus the extra cost of accessing the numbers through the refer- ences, not to mention the cost of invoking compareTo() and less() methods. We can develop efficient versions of our sort codes for such purposes by replacing Comparable with the primitive type name, and redefining less() or just replacing calls to less() with code like a[i] &lt; a[j] (see Exercise 2.1.26). Java system sort. As an example of applying the information given in the table on page 342, consider Java&#8217;s primary system sort method, java.util.Arrays.sort(). With overloading of argument types, this name actually represents a collection of methods:</p><p attribs="{'xml:space': 'preserve'}" id="_05668" smilref="Title.smil#_05668" /><pagenum id="p357" page="normal" smilref="Title.smil#p357" /><p attribs="{'xml:space': 'preserve'}" id="_05669" smilref="Title.smil#_05669"> 344</p><p attribs="{'xml:space': 'preserve'}" id="_05670" smilref="Title.smil#_05670"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05671" smilref="Title.smil#_05671"> </p><p attribs="{'xml:space': 'preserve'}" id="_05672" smilref="Title.smil#_05672"> The algorithms and ideas that we have been considering are an essential part of many modern systems, including Java. When developing Java programs to address an application, you are likely to find that Java&#8217;s Arrays.sort() implementations (perhaps supplemented by your own implementation(s) of compareTo() and/or compare()) will meet your needs, because you will be using 3-way quicksort or mergesort, both proven classic algorithms. In this book, we generally will use our own Quick.sort() (usually) or Merge.sort() (when stability is important and space is not) in sort clients. You may feel free to use Arrays.sort() unless you have a good reason to use another specific method.</p><p attribs="{'xml:space': 'preserve'}" id="_05673" smilref="Title.smil#_05673"> Reductions The idea that we can use sorting algorithms to solve other problems is an example of a basic technique in algorithm design known as reduction. We consider reduction in detail in Chapter 6 because of its importance in the theory of al- gorithms&#8212;in the meantime, we will consider several practical examples. A reduction is a situation where an algorithm developed for one problem is used to solve another. Applications programmers are quite used to the concept of reduction (whether or not it is explicitly articulated)&#8212;every time you make use of a method that solves problem B in order to solve problem A, you are doing a reduction from A to B. Indeed, one goal in implementing algorithms is to facilitate reductions by making the algorithms useful for as wide a variety as possible of applications. We begin with a few elementary examples for sorting. Many of these take the form of algorithmic puzzles where a quadratic brute-force algorithm is immediate. It is often the case that sorting the data first makes it easy to finish solving the problem in linear additional time, thus reducing the total cost from quadratic to linearithmic.</p><p attribs="{'xml:space': 'preserve'}" id="_05674" smilref="Title.smil#_05674"> Duplicates. Are there any duplicate keys in an array of Comparable objects? How many distinct keys are there? Which value appears most frequently? For small arrays, these kinds of questions are easy to answer with a quadratic algorithm that compares each array entry with each other array entry. For large arrays, using a quadratic algorithm is not feasible. With sorting, you can answer these questions in linearithmic time:</p><p attribs="{'xml:space': 'preserve'}" id="_05675" smilref="Title.smil#_05675" /></level3><level3 id="_00046"><h3 id="ch2-s5-ss18" smilref="Title.smil#ch2-s5-ss18" xml:space="preserve">Median and order statistics</h3><pagenum id="p358" page="normal" smilref="Title.smil#p358" /><p attribs="{'xml:space': 'preserve'}" id="_05676" smilref="Title.smil#_05676"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05677" smilref="Title.smil#_05677"> 345</p><p attribs="{'xml:space': 'preserve'}" id="_05678" smilref="Title.smil#_05678"> first sort the array, then make a pass through the sorted array, taking note of duplicate keys that appear consecutively in the ordered array. For example, the code fragment at right counts the distinct keys in an array. With simple modifications to this code, you can answer the questions above and perform tasks such as printing all the distinct val- ues, all the values that are duplicated, and so forth, even for huge arrays.</p><p attribs="{'xml:space': 'preserve'}" id="_05679" smilref="Title.smil#_05679"> Quick.sort(a); int count = 1; // Assume a.length &gt; 0. for (int i = 1; i &lt; a.length; i++) if (a[i].compareTo(a[i-1]) != 0) count++;</p><p attribs="{'xml:space': 'preserve'}" id="_05680" smilref="Title.smil#_05680"> Rankings. A permutation (or ranking) is an array of N integers where each of the integers between 0 and N-1 appears exactly once. The Kendall tau distance between two rankings is the number of pairs that are in different order in the two rankings. For example, the Kendall tau distance between 0 3 1 6 2 5 4 and 1 0 3 6 4 2 5 is four because the pairs 0-1, 3-1, 2-4, 5-4 are in different relative order in the two rankings, but all other pairs are in the same relative order. This statistic is widely used: in sociology to study social choice and voting theory, in molecular biology to compare genes using expression pro&#64257; les, and in ranking search engine results on the web, among many other applications. The Kendall tau distance between a permutation and the identity permutation (where each entry is equal to its index) is the number of inversions in the permutation, and a quadratic algorithm based on insertion sort is not difficult to devise (recall Proposition C in Section 2.1). Ef&#64257; ciently computing the Kendall tau distance is an interesting exercise for a programmer (or a student!) who is familiar with the classical sorting algorithms that we have studied (see Exercise</p><p attribs="{'xml:space': 'preserve'}" id="_05681" smilref="Title.smil#_05681"> Counting the distinct keys in a[]</p><p attribs="{'xml:space': 'preserve'}" id="_05682" smilref="Title.smil#_05682"> 2.5.19).</p><p attribs="{'xml:space': 'preserve'}" id="_05683" smilref="Title.smil#_05683"> Priority-queue reductions. In Section 2.4, we considered two examples of problems that reduce to a sequence of operations on priority queues. TopM, on page 311, finds the M items in an input stream with the highest keys. Multiway, on page 322, merges M sorted input streams together to make a sorted output stream. Both of these problems are easily addressed with a priority queue of size M.</p><p attribs="{'xml:space': 'preserve'}" id="_05684" smilref="Title.smil#_05684"> Median and order statistics. An important application related to sorting but for which a full sort is not required is the operation of finding the median of a collection of keys (the value with the property that half the keys are no larger and half the keys are no smaller). This operation is a common computation in statistics and in various other data-processing applications. Finding the median is a special case of selection: finding the k th smallest of a collection of numbers. Selection has many applications in the processing of experimental and other data. The use of the median and other order</p><p attribs="{'xml:space': 'preserve'}" id="_05685" smilref="Title.smil#_05685" /><pagenum id="p359" page="normal" smilref="Title.smil#p359" /><p attribs="{'xml:space': 'preserve'}" id="_05686" smilref="Title.smil#_05686"> 346</p><p attribs="{'xml:space': 'preserve'}" id="_05687" smilref="Title.smil#_05687"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05688" smilref="Title.smil#_05688"> Selecting the k smallest elements in a[]</p><p attribs="{'xml:space': 'preserve'}" id="_05689" smilref="Title.smil#_05689"> public static Comparable select(Comparable[] a, int k) { StdRandom.shuffle(a); int lo = 0, hi = a.length - 1; while (hi &gt; lo) { int j = partition(a, lo, hi); if (j == k) return a[k]; else if (j &gt; k) hi = j - 1; else if (j &lt; k) lo = j + 1; } return a[k]; }</p><p attribs="{'xml:space': 'preserve'}" id="_05690" smilref="Title.smil#_05690"> statistics to divide an array into smaller groups is common. Often, only a small part of a large array is to be saved for further processing; in such cases, a program that can select, say, the top 10 percent of the items of the array might be more appropriate than a full sort. Our TopM application of Section 2.4 solves this problem for an unbounded input stream, using a priority queue. An effective alternative to TopM when you have the items in an array is to just sort it: after the call Quick.sort(a) the k smallest values in the array are in the first k array positions for all k less than the array length. But this approach involves a sort, so the running time is linearithmic. Can we do better? Finding the k smallest values in an array is easy when k is very small or very large, but more c h a l l e n g i n g when k is a constant fraction of the array size, such as finding the median (k = N/2). You might be surprised to learn that it is possible to solve this problem in linear time, as in the select() method above (this implementation requires a client cast; for the more pedantic code needed to avoid this requirement, see the booksite). To do the job, select() maintains the variables lo and hi to delimit the subarray that contains the index k of the item to be selected and uses quicksort partitioning to shrink the size of the subarray. Recall that partition() rearranges an array a[lo] through a[hi] and returns an integer j such that a[lo] through a[j-1] are less than or equal to a[j], and a[j+1] through a[hi] are greater than or equal to a[j]. Now, if k is equal to j, then we are done. Otherwise, if k &lt; j, then we need to continue working in the left subarray (by changing the value of hi to j-1); if k &gt; j, then we need to continue working in the right subarray (by changing lo to j+1). The loop maintains the invariant that no entry to the left of lo is larger and no entry to the right of hi is smaller than any element within a[lo..hi]. After partitioning, we preserve this invariant and shrink the interval until it consists just of</p><p attribs="{'xml:space': 'preserve'}" id="_05691" smilref="Title.smil#_05691"> median</p><p attribs="{'xml:space': 'preserve'}" id="_05692" smilref="Title.smil#_05692"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_05693" smilref="Title.smil#_05693"> i</p><p attribs="{'xml:space': 'preserve'}" id="_05694" smilref="Title.smil#_05694"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_05695" smilref="Title.smil#_05695"> Partitioning to find the median</p><p attribs="{'xml:space': 'preserve'}" id="_05696" smilref="Title.smil#_05696" /><pagenum id="p360" page="normal" smilref="Title.smil#p360" /><p attribs="{'xml:space': 'preserve'}" id="_05697" smilref="Title.smil#_05697"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05698" smilref="Title.smil#_05698"> 347</p><p attribs="{'xml:space': 'preserve'}" id="_05699" smilref="Title.smil#_05699"> k. Upon termination, a[k] contains the (k +1)st smallest entry, a[0] through a[k-1] are all smaller than (or equal to) a[k], and a[k+1] through the end of the array are all greater than (or equal to) a[k]. To gain some insight into why this is a linear-time al- gorithm, suppose that partitioning divides the array exactly in half each time. Then the number of compares is N &#11001; N/2 &#11001; N/4 &#11001; N/8 &#11001; . . . , terminating when the k th smallest item is found. This sum is less than 2 N. As with quicksort, it takes a bit of math to find the true bound, which is a bit higher . Also as with quicksort, the analysis depends on partitioning on a random item, so that the guarantee is probabilistic.</p><p attribs="{'xml:space': 'preserve'}" id="_05700" smilref="Title.smil#_05700"> Proposition U. Partitioning-based selection is a linear-time algorithm, on average.</p><p attribs="{'xml:space': 'preserve'}" id="_05701" smilref="Title.smil#_05701"> Proof : An analysis similar to, but significantly more complex than, the proof of Proposition K for quicksort leads to the result that the average number of compares is ~ 2N &#11001; 2k ln(N/k) &#11001; 2(N &#11002; k) ln(N/(N &#11002; k)), which is linear for any allowed value of k. For example, this formula says that finding the median (k = N/2) requires ~ (2 &#11001; 2 ln 2)N compares, on the average. Note that the worst case is quadratic but randomization protects against that possibility, as with quicksort.</p><p attribs="{'xml:space': 'preserve'}" id="_05702" smilref="Title.smil#_05702"> Designing a selection algorithm that is guaranteed to use a linear number of compares in the worst case is a classic result in computational complexity, but it has not yet led to a useful practical algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_05703" smilref="Title.smil#_05703" /><pagenum id="p361" page="normal" smilref="Title.smil#p361" /><p attribs="{'xml:space': 'preserve'}" id="_05704" smilref="Title.smil#_05704"> 348</p><p attribs="{'xml:space': 'preserve'}" id="_05705" smilref="Title.smil#_05705"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05706" smilref="Title.smil#_05706"> A brief survey of sorting applications Direct applications of sorting are fa-</p><p attribs="{'xml:space': 'preserve'}" id="_05707" smilref="Title.smil#_05707"> miliar, ubiquitous, and far too numerous for us to list them all. You sort your music by song title or by artist name, your email or phone calls by time or origin, and your photos by date. Universities sort student accounts by name or ID. Credit card companies sort millions or even billions of transactions by date or amount. Scientists sort not only experimental data by time or other identifier but also to enable detailed simulations of the natural world, from the motion of particles or heavenly bodies to the structure of materials to social interations and relationships. Indeed, it is difficult to identify a computational application that does not involve sorting! To elaborate upon this point, we describe in this section examples of applications that are more complicated than the reductions just considered, including several that we will examine in detail later in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_05708" smilref="Title.smil#_05708"> Commercial computing. The world is awash in information. Government organiza- tions, financial institutions, and commercial enterprises organize much of this information by sorting it. Whether the information is accounts to be sorted by name or number, transactions to be sorted by date or amount, mail to be sorted by postal code or address, files to be sorted by name or date, or whatever, processing such data is sure to involve a sorting algorithm somewhere along the way. Typically, such information is organized in huge databases, sorted by multiple keys for efficient search. An effective strategy that is widely used is to collect new information, add it to the database, sort it on the keys of interest, and merge the sorted result for each key into the existing data- base. The methods that we have discussed have been used effectively since the early days of computing to build a huge infrastructure of sorted data and methods for processing it that serve as the basis for all of this commercial activity. Arrays having millions or even billions of entries are routinely processed today&#8212;without linearithmic sorting algorithms, such arrays could not be sorted, making such processing extremely difficult or impossible.</p><p attribs="{'xml:space': 'preserve'}" id="_05709" smilref="Title.smil#_05709"> Search for information. Keeping data in sorted order makes it possible to efficiently search through it using the classic binary search algorithm (see Chapter 1). You will also see that the same scheme makes it easy to quickly handle many other kinds of queries. How many items are smaller than a given item? Which items fall within a given range? In Chapter 3, we consider such questions. We also consider in detail various extensions to sorting and binary search that allow us to intermix such queries with operations that insert and remove objects from the set, still guaranteeing logarithmic performance for all operations.</p><p attribs="{'xml:space': 'preserve'}" id="_05710" smilref="Title.smil#_05710" /><pagenum id="p362" page="normal" smilref="Title.smil#p362" /><p attribs="{'xml:space': 'preserve'}" id="_05711" smilref="Title.smil#_05711"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05712" smilref="Title.smil#_05712"> 349</p><p attribs="{'xml:space': 'preserve'}" id="_05713" smilref="Title.smil#_05713"> Operations research. The field of operations research (OR) develops and applies mathematical models for problem-solving and decision-making. We will see several examples in this book of relationships between OR and the study of algorithms, beginning here with the use of sorting in a classic OR problem known as scheduling. Suppose that we have N jobs to complete, where job j requires tj seconds of processing time. We need to complete all of the jobs but want to maximize customer satisfaction by minimizing the average completion time of the jobs. The shortest processing time first rule, where we schedule the jobs in increasing order of processing time, is known to accomplish this goal. Therefore we can sort the jobs by processing time or put them on a minimum- oriented priority queue. With various other constraints and restrictions, we get various other scheduling problems, which frequently arise in industrial applications and are well-studied. As another example, consider the load-balancing problem, where we have M identical processors and N jobs to complete, and our goal is to schedule all of the jobs on the processors so that the time at which the last job completes is as early as pos- sible. This specific problem is NP-hard (see Chapter 6) so we do not expect to find a practical way to compute an optimal schedule. One method that is known to produce a good schedule is the longest processing time first rule, where we consider the jobs in descending order of processing time, assigning each job to the processor that becomes available fi rst. To implement this algorithm, we first sort the jobs in reverse order. Then we maintain a priority queue of M processors, where the priority is the sum of the processing times of its jobs. At each step, we delete the processor with the minimum prior- ity, add the next job to the processor, and reinsert that processor into the priority queue.</p><p attribs="{'xml:space': 'preserve'}" id="_05714" smilref="Title.smil#_05714"> Event-driven simulation. Many scientific applications involve simulation, where the point of the computation is to model some aspect of the real world in order to be able to better understand it. Before the advent of computing, scientists had little choice but to build mathematical models for this purpose; such models are now well-complemented by computational models. Doing such simulations efficiently can be challenging, and use of appropriate algorithms certainly can make the difference between being able to complete the simulation in a reasonable amount of time and being stuck with the choice of accepting inaccurate results or waiting for the simulation to do the computation necessary to get accurate results. We will consider in Chapter 6 a detailed example that illustrates this point.</p><p attribs="{'xml:space': 'preserve'}" id="_05715" smilref="Title.smil#_05715"> Numerical computations. Scienti&#64257; c computing is often concerned with accuracy (how close are we to the true answer?). Accuracy is extremely important when we are performing millions of computations with estimated values such as the fl oating-point representation of real numbers that we commonly use on computers. Some numerical algorithms use priority queues and sorting to control accuracy in calculations. For</p><p attribs="{'xml:space': 'preserve'}" id="_05716" smilref="Title.smil#_05716" /><pagenum id="p363" page="normal" smilref="Title.smil#p363" /><p attribs="{'xml:space': 'preserve'}" id="_05717" smilref="Title.smil#_05717"> 350</p><p attribs="{'xml:space': 'preserve'}" id="_05718" smilref="Title.smil#_05718"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05719" smilref="Title.smil#_05719"> example, one way to do numerical integration (quadrature), where the goal is to estimate the area under a curve, is to maintain a priority queue with accuracy estimates for a set of subintervals that comprise the whole interval. The process is to remove the least accurate subinterval, split it in half (thus achieving better accuracy for the two halves), and put the two halves back onto the priority queue, continuing until a desired tolerance is reached.</p><p attribs="{'xml:space': 'preserve'}" id="_05720" smilref="Title.smil#_05720"> Combinatorial search. A classic paradigm inartificial intelligence and in coping with intractable problems is to define a set of configurations with well-de&#64257; ned moves from one configuration to the next and a priority associated with each move. Also defined is a start configuration and a goal configuration (which corresponds to having solved the problem). The well-known A* algorithm is a problem-solving process where we put the start configuration on the priority queue, then do the following until reaching the goal: remove the highest-priority configuration and add to the queue all configurations that can be reached from that with one move (excluding the one just removed). As with event-driven simulation, this process is tailor-made for priority queues. It reduces solving the problem to defining an effective priority function. See Exercise 2.5.32 for an example.</p><p attribs="{'xml:space': 'preserve'}" id="_05721" smilref="Title.smil#_05721"> Beyond such direct applications (and we have only indicated a small fraction of those), sorting and priority queues are an essential abstraction in algorithm design, so they will surface frequently throughout this book. We next list some examples of applications from later in the book. All of these applications depend upon the efficient implementations of sorting algorithms and the priority-queue data type that we have considered in this chapter.</p><p attribs="{'xml:space': 'preserve'}" id="_05722" smilref="Title.smil#_05722"> Prim&#8217;s algorithm and Dijkstra&#8217;s algorithm are classical algorithms from Chapter 4.</p><p attribs="{'xml:space': 'preserve'}" id="_05723" smilref="Title.smil#_05723"> That chapter is about algorithms that process graphs, a fundamental model for items and edges that connect pairs of items. The basis for these and several other algorithms is graph search, where we proceed from item to item along edges. Priority queues play a fundamental role in organizing graph searches, enabling efficient algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_05724" smilref="Title.smil#_05724"> Kruskal&#8217;s algorithm is another classic algorithm for graphs whose edges have weights that depends upon processing the edges in order of their weight. Its running time is dominated by the cost of the sort.</p><p attribs="{'xml:space': 'preserve'}" id="_05725" smilref="Title.smil#_05725"> Huffman compression is a classic data compression algorithm that depends upon processing a set of items with integer weights by combining the two smallest to produce a new one whose weight is the sum of its two constituents. Implementing this opera-</p><p attribs="{'xml:space': 'preserve'}" id="_05726" smilref="Title.smil#_05726" /><pagenum id="p364" page="normal" smilref="Title.smil#p364" /><p attribs="{'xml:space': 'preserve'}" id="_05727" smilref="Title.smil#_05727"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05728" smilref="Title.smil#_05728"> 351</p><p attribs="{'xml:space': 'preserve'}" id="_05729" smilref="Title.smil#_05729"> tion is immediate, using a priority queue. Several other data-compression schemes are based upon sorting.</p><p attribs="{'xml:space': 'preserve'}" id="_05730" smilref="Title.smil#_05730"> String-processing algorithms, which are of critical importance in modern applications in cryptology and in genomics, are often based on sorting (generally using one of the specialized string sorts discussed in Chapter 5). For example, we will discuss in Chapter 6 algorithms for finding the longest repeated substring in a given string that is based on first sorting suffixes of the strings.</p><p attribs="{'xml:space': 'preserve'}" id="_05731" smilref="Title.smil#_05731" /><pagenum id="p365" page="normal" smilref="Title.smil#p365" /><p attribs="{'xml:space': 'preserve'}" id="_05732" smilref="Title.smil#_05732"> 352</p><p attribs="{'xml:space': 'preserve'}" id="_05733" smilref="Title.smil#_05733"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05734" smilref="Title.smil#_05734"> Q &amp; A</p><p attribs="{'xml:space': 'preserve'}" id="_05735" smilref="Title.smil#_05735"> Q. Is there a priority-queue data type in the Java library?</p><p attribs="{'xml:space': 'preserve'}" id="_05736" smilref="Title.smil#_05736"> A. Yes, see java.util.PriorityQueue.</p><p attribs="{'xml:space': 'preserve'}" id="_05737" smilref="Title.smil#_05737" /><pagenum id="p366" page="normal" smilref="Title.smil#p366" /><p attribs="{'xml:space': 'preserve'}" id="_05738" smilref="Title.smil#_05738"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05739" smilref="Title.smil#_05739"> 353</p><p attribs="{'xml:space': 'preserve'}" id="_05740" smilref="Title.smil#_05740"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_05741" smilref="Title.smil#_05741"> 2.5.1 Consider the following implementation of the compareTo() method for String. How does the third line help with ef&#64257; ciency?</p><p attribs="{'xml:space': 'preserve'}" id="_05742" smilref="Title.smil#_05742"> public int compareTo(String that) { if (this == that) return 0; // this line int n = Math.min(this.length(), that.length()); for (int i = 0; i &lt; n; i++) { if (this.charAt(i) &lt; that.charAt(i)) return -1; else if (this.charAt(i) &gt; that.charAt(i)) return +1; } return this.length() - that.length(); }</p><p attribs="{'xml:space': 'preserve'}" id="_05743" smilref="Title.smil#_05743"> 2.5.2 Write a program that reads a list of words from standard input and prints all two- word compound words in the list. For example, if after, thought, and afterthought are in the list, then afterthought is a compound word. 2.5.3 Criticize the following implementation of a class intended to represent account balances. Why is compareTo() a flawed implementation of the Comparable interface?</p><p attribs="{'xml:space': 'preserve'}" id="_05744" smilref="Title.smil#_05744"> public class Balance implements Comparable&lt;Balance&gt; { ... private double amount; public int compareTo(Balance that) { if (this.amount &lt; that.amount - 0.005) return -1; if (this.amount &gt; that.amount + 0.005) return +1; return 0; } ... }</p><p attribs="{'xml:space': 'preserve'}" id="_05745" smilref="Title.smil#_05745"> Describe a way to fix this problem. 2.5.4 Implement a method String[] dedup(String[] a) that returns the objects in a[] in sorted order, with duplicates removed. 2.5.5 Explain why selection sort is not stable.</p><p attribs="{'xml:space': 'preserve'}" id="_05746" smilref="Title.smil#_05746" /><pagenum id="p367" page="normal" smilref="Title.smil#p367" /><p attribs="{'xml:space': 'preserve'}" id="_05747" smilref="Title.smil#_05747"> 354</p><p attribs="{'xml:space': 'preserve'}" id="_05748" smilref="Title.smil#_05748"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05749" smilref="Title.smil#_05749"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_05750" smilref="Title.smil#_05750"> 2.5.6 Implement a recursive version of select(). 2.5.7 About how many compares are required, on the average, to find the smallest of N items using select()? 2.5.8 Write a program Frequency that reads strings from standard input and prints the number of times each string occurs, in descending order of frequency. 2.5.9 Develop a data type that allows you to write a client that can sort a file such as the one shown at right. 2.5.10 Create a data type Version that represents a software version number, such as 115.1.1, 115.10.1, 115.10.2. Implement the Comparable interface so that 115.1.1 is less than 115.10.1, and so forth. 2.5.11 One way to describe the result of a sorting algorithm is to specify a permutation p[] of the numbers 0 to a.length-1, such that p[i] specifies where the key originally in a[i] ends up. Give the permutations that describe the results of insertion sort, selection sort, shellsort, mergesort, quicksort, and heapsort for an array of seven equal keys.</p><p attribs="{'xml:space': 'preserve'}" id="_05751" smilref="Title.smil#_05751"> 1-Oct-28 3500000 2-Oct-28 3850000 3-Oct-28 4060000 4-Oct-28 4330000 5-Oct-28 4360000 ... 30-Dec-99 554680000 31-Dec-99 374049984 3-Jan-00 931800000 4-Jan-00 1009000000 5-Jan-00 1085500032 ...</p><p attribs="{'xml:space': 'preserve'}" id="_05752" smilref="Title.smil#_05752"> input (DJI volumes for each day)</p><p attribs="{'xml:space': 'preserve'}" id="_05753" smilref="Title.smil#_05753"> output</p><p attribs="{'xml:space': 'preserve'}" id="_05754" smilref="Title.smil#_05754"> 19-Aug-40 130000 26-Aug-40 160000 24-Jul-40 200000 10-Aug-42 210000 23-Jun-42 210000 ... 23-Jul-02 2441019904 17-Jul-02 2566500096 15-Jul-02 2574799872 19-Jul-02 2654099968 24-Jul-02 2775559936</p><p attribs="{'xml:space': 'preserve'}" id="_05755" smilref="Title.smil#_05755" /><pagenum id="p368" page="normal" smilref="Title.smil#p368" /><p attribs="{'xml:space': 'preserve'}" id="_05756" smilref="Title.smil#_05756"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05757" smilref="Title.smil#_05757"> 355</p><p attribs="{'xml:space': 'preserve'}" id="_05758" smilref="Title.smil#_05758"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_05759" smilref="Title.smil#_05759"> 2.5.12 Scheduling. Write a program SPT.java that reads job names and processing times from standard input and prints a schedule that minimizes average completion time using the shortest processing time first rule, as described on page 349. 2.5.13 Load balancing. Write a program LPT.java that takes an integer M as a com- mand-line argument, reads job names and processing times from standard input and prints a schedule assigning the jobs to M processors that approximately minimizes the time when the last job completes using the longest processing time first rule, as described on page 349. 2.5.14 Sort by reverse domain. Write a data type Domain that represents domain names, including an appropriate compareTo() method where the natural order is in order of the reverse domain name. For example, the reverse domain of cs.princeton.edu is edu.princeton.cs. This is useful for web log analysis. Hint: Use s.split("\\.") to split the string s into tokens, delimited by dots. Write a client that reads domain names from standard input and prints the reverse domains in sorted order. 2.5.15 Spam campaign. To initiate an illegal spam campaign, you have a list of email addresses from various domains (the part of the email address that follows the @ symbol). To better forge the return addresses, you want to send the email from another user at the same domain. For example, you might want to forge an email from wayne@princeton.edu to rs@princeton.edu. How would you process the email list to make this an efficient task? 2.5.16 Unbiased election. In order to thwart bias against candidates whose names appear toward the end of the alphabet, California sorted the candidates appearing on its 2003 gubernatorial ballot by using the following order of characters:</p><p attribs="{'xml:space': 'preserve'}" id="_05760" smilref="Title.smil#_05760"> R W Q O J M V A H B S G Z X N T C I E K U P D Y F L</p><p attribs="{'xml:space': 'preserve'}" id="_05761" smilref="Title.smil#_05761"> Create a data type where this is the natural order and write a client California with a single static method main() that sorts strings according to this ordering. Assume that each string is composed solely of uppercase letters.</p><p attribs="{'xml:space': 'preserve'}" id="_05762" smilref="Title.smil#_05762"> 2.5.17 Check stability. Extend your check() method from Exercise 2.1.16 to call sort() for a given array and return true if sort() sorts the array in order in a stable manner, false otherwise. Do not assume that sort() is restricted to move data only with exch().</p><p attribs="{'xml:space': 'preserve'}" id="_05763" smilref="Title.smil#_05763" /><pagenum id="p369" page="normal" smilref="Title.smil#p369" /><p attribs="{'xml:space': 'preserve'}" id="_05764" smilref="Title.smil#_05764"> 356</p><p attribs="{'xml:space': 'preserve'}" id="_05765" smilref="Title.smil#_05765"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05766" smilref="Title.smil#_05766"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_05767" smilref="Title.smil#_05767"> 2.5.18 Force stability. Write a wrapper method that makes any sort stable by creating a new key type that allows you to append each key&#8217;s index to the key, call sort(), then restore the original key after the sort. 2.5.19 Kendall tau distance. Write a program KendallTau.java that computes the Kendall tau distance between two permutations in linearithmic time. 2.5.20 Idle time. Suppose that a parallel machine processes N jobs. Write a program that, given the list of job start and finish times, finds the largest interval where the machine is idle and the largest interval where the machine is not idle. 2.5.21 Multidimensional sort. Write a Vector data type for use in having the sorting methods sort multidimensional vectors of d integers, putting the vectors in order by first component, those with equal first component in order by second component, those with equal first and second components in order by third component, and so forth. 2.5.22 Stock market trading. Investors place buy and sell orders for a particular stock on an electronic exchange, specifying a maximum buy or minimum sell price that they are willing to pay, and how many shares they wish to trade at that price. Develop a program that uses priority queues to match up buyers and sellers and test it through simulation. Maintain two priority queues, one for buyers and one for sellers, executing trades whenever a new order can be matched with an existing order or orders. 2.5.23 Sampling for selection. Investigate the idea of using sampling to improve selec- tion. Hint: Using the median may not always be helpful. 2.5.24 Stable priority queue. Develop a stable priority-queue implementation (which returns duplicate keys in the same order in which they were inserted). 2.5.25 Points in the plane. Write three static comparators for the Point2D data type of page 77, one that compares points by their x coordinate, one that compares them by their y coordinate, and one that compares them by their distance from the origin. Write two non-static comparators for the Point2D data type, one that compares them by their distance to a specified point and one that compares them by their polar angle with respect to a specified point. 2.5.26 Simple polygon. Given N points in the plane, draw a simple polygon with N</p><p attribs="{'xml:space': 'preserve'}" id="_05768" smilref="Title.smil#_05768" /><pagenum id="p370" page="normal" smilref="Title.smil#p370" /><p attribs="{'xml:space': 'preserve'}" id="_05769" smilref="Title.smil#_05769"> 2 .5 </p><p attribs="{'xml:space': 'preserve'}" id="_05770" smilref="Title.smil#_05770"> 357</p><p attribs="{'xml:space': 'preserve'}" id="_05771" smilref="Title.smil#_05771"> points as vertices. Hint : Find the point p with the smallest y coordinate, breaking ties with the smallest x coordinate. Connect the points in increasing order of the polar angle they make with p. 2.5.27 One-dimensional intervals. Write three comparators for the Interval1D data type of page 77, one that compares intervals by their left endpoint, one that compares intervals by their right endpoint, and one that compares intervals by their length. 2.5.28 Sort files by name. Write a program FileSorter that takes the name of a directory as a command-line argument and prints out all of the files in the current directory, sorted by file name. Hint : Use the File data type. 2.5.29 Sort files by size and date of last modi&#64257; cation. Write comparators for the type File to order by increasing/decreasing order of file size, ascending/descending order of file name, and ascending/descending order of last modification date. Use these comparators in a program LS that takes a command-line argument and lists the files in the current directory according to a specified order, e.g., "-t" to sort by timestamp. Support multiple flags to break ties. Be sure to use a stable sort. 2.5.30 Boerner&#8217;s theorem. True or false: If you sort each column of a matrix, then sort each row, the columns are still sorted. Justify your answer.</p><p attribs="{'xml:space': 'preserve'}" id="_05772" smilref="Title.smil#_05772" /><pagenum id="p371" page="normal" smilref="Title.smil#p371" /><p attribs="{'xml:space': 'preserve'}" id="_05773" smilref="Title.smil#_05773"> 358</p><p attribs="{'xml:space': 'preserve'}" id="_05774" smilref="Title.smil#_05774"> CHAPTER 2 </p><p attribs="{'xml:space': 'preserve'}" id="_05775" smilref="Title.smil#_05775"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_05776" smilref="Title.smil#_05776"> 2.5.31 Duplicates. Write a client that takes integers M, N, and T as command-line argu- ments, then uses the code given in the text to perform T trials of the following experi- ment: Generate N random int values between 0 and M &#8211; 1 and count the number of duplicates. Run your program for T = 10 and N = 10 3, 10 4, 10 5, and 10 6, with M = N &#11408; 2, and N, and 2N. Probability theory says that the number of duplicates should be about (1 &#8211; e &#8211;&#9251;) where &#9251; &#11005; N &#11408; M&#8212;print a table to help you confirm that your experiments validate that formula. 2.5.32 8 puzzle. The 8 puzzle is a game popularized by S. Loyd in the 1870s. It is played on a 3-by-3 grid with 8 tiles labeled 1 through 8 and a blank square. Your goal is to rearrange the tiles so that they are in order. You are permitted to slide one of the available tiles horizontally or vertically (but not diagonally) into the blank square. Write a program that solves the puzzle using the A* algorithm. Start by using as priority the sum of the number of moves made to get to this board position plus the number of tiles in the wrong position. (Note that the number of moves you must make from a given board position is at least as big as the number of tiles in the wrong place.) Investigate substituting other functions for the number of tiles in the wrong position, such as the sum of the Manhattan distance from each tile to its correct position, or the sums of the squares of these distances.</p><p attribs="{'xml:space': 'preserve'}" id="_05777" smilref="Title.smil#_05777"> 2.5.33 Random transactions. Develop a generator that takes an argument N, generates N random Transaction objects (see Exercises 2.1.21 and 2.1.22), using assumptions about the transactions that you can defend. Then compare the performance of shellsort, mergesort, quicksort, and heapsort for sorting N transactions, for N=103, 104, 105, and 106.</p><p attribs="{'xml:space': 'preserve'}" id="_05778" smilref="Title.smil#_05778" /><pagenum id="p372" page="normal" smilref="Title.smil#p372" /><p attribs="{'xml:space': 'preserve'}" id="_05779" smilref="Title.smil#_05779"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_05780" smilref="Title.smil#_05780" /></level3></level1><level1 id="ch3"><section epub:type="chapter" id="section_00002"><header id="header_00002"><pagenum epub:type="pagebreak" id="p373" page="normal" smilref="Title.smil#p373" /><h1 id="ch3-start" smilref="Title.smil#ch3-start" xml:space="preserve">3 Searching</h1></header></section><pagenum id="p373" page="normal" smilref="Title.smil#p373" /><p attribs="{'xml:space': 'preserve'}" id="_05781" smilref="Title.smil#_05781"> T H R E E</p><p attribs="{'xml:space': 'preserve'}" id="_05782" smilref="Title.smil#_05782"> Searching</p><p attribs="{'xml:space': 'preserve'}" id="_05783" smilref="Title.smil#_05783"> Symbol Tables . . . . . . . . . . . . . . 362</p><p attribs="{'xml:space': 'preserve'}" id="_05784" smilref="Title.smil#_05784"> Binary Search Trees . . . . . . . . . . . 396</p><p attribs="{'xml:space': 'preserve'}" id="_05785" smilref="Title.smil#_05785"> 3.1 3.2 3.3 Balanced Search Trees . . . . . . . . . 424 3.4 Hash Tables . . . . . . . . . . . . . . . . 458 3.5 Applications . . . . . . . . . . . . . . . . 486</p><p attribs="{'xml:space': 'preserve'}" id="_05786" smilref="Title.smil#_05786" /><pagenum id="p374" page="normal" smilref="Title.smil#p374" /><p attribs="{'xml:space': 'preserve'}" id="_05787" smilref="Title.smil#_05787"> Modern computing and the internet have made accessible a vast amount of information. The ability to efficiently search through this information is fundamental to processing it. This chapter describes classical searching algorithms that have proven to be effective in numerous diverse applications for decades. Without algorithms like these, the development of the computational infrastructure that we enjoy in the modern world would not have been possible. We use the term symbol table to describe an abstract mechanism where we save information (a value) that we can later search for and retrieve by specifying a key. The nature of the keys and the values depends upon the application. There can be a huge number of keys and a huge amount of information, so implementing an efficient symbol table is a significant computational challenge. Symbol tables are sometimes called dictionaries, by analogy with the time-honored system of providing definitions for words by listing them alphabetically in a reference book. In an English-language dictionary, a key is a word and its values is the entry associated with the word that contains the defi nition, pronunciation, and etymology. Symbol tables are also sometimes called indices, by analogy with another time-honored system of providing access to terms by listing them alphabetically at the end of a book such as a textbook. In a book index, a key is a term of interest and its value is the list of page numbers that tell readers where to find that term in the book. After describing the basic APIs and two fundamental implementations, we consider three classic data structures that can support efficient symbol-table implementations: binary search trees, red-black trees, and hash tables. We conclude with several extensions and applications, many of which would not be feasible without the efficient algorithms that you will learn about in this chapter.</p><p attribs="{'xml:space': 'preserve'}" id="_05788" smilref="Title.smil#_05788"> 361</p><p attribs="{'xml:space': 'preserve'}" id="_05789" smilref="Title.smil#_05789" /><level3 id="_00047"><h3 id="ch3-s1-ss1" smilref="Title.smil#ch3-s1-ss1" xml:space="preserve">Symbol table API</h3><pagenum id="p376" page="normal" smilref="Title.smil#p376" /><p attribs="{'xml:space': 'preserve'}" id="_05790" smilref="Title.smil#_05790"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05791" smilref="Title.smil#_05791"> 363</p><p attribs="{'xml:space': 'preserve'}" id="_05792" smilref="Title.smil#_05792"> API The symbol table is a prototypical abstract data type (see Chapter 1): it represents a well-de&#64257; ned set of values and operations on those values, enabling us to develop clients and implementations separately. As usual, we precisely define the operations by specifying an applications programming interface (API) that provides the contract between client and implementation:</p><p attribs="{'xml:space': 'preserve'}" id="_05793" smilref="Title.smil#_05793"> public class ST&lt;Key, Value&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_05794" smilref="Title.smil#_05794"> ST()</p><p attribs="{'xml:space': 'preserve'}" id="_05795" smilref="Title.smil#_05795"> Value get(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_05796" smilref="Title.smil#_05796"> create a symbol table void put(Key key, Value val) put key-value pair into the table (remove key from table if value is null) value paired with key (null if key is absent) remove key (and its value) from table is there a value paired with key? is the table empty? number of key-value pairs in the table all the keys in the table</p><p attribs="{'xml:space': 'preserve'}" id="_05797" smilref="Title.smil#_05797"> void delete(Key key) boolean contains(Key key) boolean isEmpty() int size()</p><p attribs="{'xml:space': 'preserve'}" id="_05798" smilref="Title.smil#_05798"> Iterable&lt;Key&gt; keys()</p><p attribs="{'xml:space': 'preserve'}" id="_05799" smilref="Title.smil#_05799"> API for a generic basic symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_05800" smilref="Title.smil#_05800"> Before examining client code, we consider several design choices for our implementations to make our code consistent, compact, and useful.</p><p attribs="{'xml:space': 'preserve'}" id="_05801" smilref="Title.smil#_05801"> Generics. As we did with sorting, we will consider the methods without specifying the types of the items being processed, using generics. For symbol tables, we emphasize the separate roles played by keys and values in search by specifying the key and value types explicitly instead of viewing keys as implicit in items as we did for priority queues in Section 2.4. After we have considered some of the characteristics of this basic API (for example, note that there is no mention of order among the keys), we will consider an extension for the typical case when keys are Comparable, which enables numerous additional methods.</p><p attribs="{'xml:space': 'preserve'}" id="_05802" smilref="Title.smil#_05802"> Duplicate keys. We adopt the following conventions in all of our implementations: </p><p attribs="{'xml:space': 'preserve'}" id="_05803" smilref="Title.smil#_05803" /><pagenum id="p377" page="normal" smilref="Title.smil#p377" /><p attribs="{'xml:space': 'preserve'}" id="_05804" smilref="Title.smil#_05804"> 364</p><p attribs="{'xml:space': 'preserve'}" id="_05805" smilref="Title.smil#_05805"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_05806" smilref="Title.smil#_05806"> entries. In a conventional array, keys are integer indices that we use to quickly access array values; in an associative array (symbol table), keys are of arbitrary type, but we can still use them to quickly access values. Some programming languages (not Java) provide special support that allows programmers to use code such as st[key] for st.get(key) and st[key] = val for st.put(key, val) where key and val are objects of arbitrary type.</p><p attribs="{'xml:space': 'preserve'}" id="_05807" smilref="Title.smil#_05807"> Null keys. Keys must not be null. As with many mechanisms in Java, use of a null key results in an exception at runtime (see the third Q&amp;A on page 387).</p><p attribs="{'xml:space': 'preserve'}" id="_05808" smilref="Title.smil#_05808"> Null values. We also adopt the convention that no key can be associated with the value null. This convention is directly tied to our specification in the API that get() should return null for keys not in the table, effectively associating the value null with every key not in the table. This convention has two (intended) consequences: First, we can test whether or not the symbol table defines a value associated with a given key by testing whether get() returns null. Second, we can use the operation of calling put() with null as its second (value) argument to implement deletion, as described in the next paragraph.</p><p attribs="{'xml:space': 'preserve'}" id="_05809" smilref="Title.smil#_05809"> Deletion. Deletion in symbol tables generally involves one of two strategies: lazy dele- tion, where we associate keys in the table with null, then perhaps remove all such keys at some later time; and eager deletion, where we remove the key from the table imme- diately. As just discussed, the code put(key, null) is an easy (lazy) implementation of delete(key). When we give an (eager) implementation of delete(), it is intended to replace this default. In our symbol-table implementations that do not use the default delete(), the put() implementations on the booksite begin with the defensive code</p><p attribs="{'xml:space': 'preserve'}" id="_05810" smilref="Title.smil#_05810"> if (val == null) { delete(key); return; }</p><p attribs="{'xml:space': 'preserve'}" id="_05811" smilref="Title.smil#_05811"> to ensure that no key in the table is associated with null. For economy, we do not include this code in the book (and we do not call put() with a null value in client code).</p><p attribs="{'xml:space': 'preserve'}" id="_05812" smilref="Title.smil#_05812"> Shorthand methods. For clarity in client code, we include the methods contains() and isEmpty() in the API, with the default one-line implementations shown here. For economy, we do not repeat this code, but we assume it to be present in all implementations of the symbol-table API and use these methods freely in client code.</p><p attribs="{'xml:space': 'preserve'}" id="_05813" smilref="Title.smil#_05813"> void delete(Key key) put(key, null);</p><p attribs="{'xml:space': 'preserve'}" id="_05814" smilref="Title.smil#_05814"> default implementation</p><p attribs="{'xml:space': 'preserve'}" id="_05815" smilref="Title.smil#_05815"> boolean contains(key)</p><p attribs="{'xml:space': 'preserve'}" id="_05816" smilref="Title.smil#_05816"> return get(key) != null;</p><p attribs="{'xml:space': 'preserve'}" id="_05817" smilref="Title.smil#_05817"> method</p><p attribs="{'xml:space': 'preserve'}" id="_05818" smilref="Title.smil#_05818"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_05819" smilref="Title.smil#_05819"> return size() == 0;</p><p attribs="{'xml:space': 'preserve'}" id="_05820" smilref="Title.smil#_05820"> Default implementations</p><p attribs="{'xml:space': 'preserve'}" id="_05821" smilref="Title.smil#_05821" /><pagenum id="p378" page="normal" smilref="Title.smil#p378" /><p attribs="{'xml:space': 'preserve'}" id="_05822" smilref="Title.smil#_05822"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05823" smilref="Title.smil#_05823"> 365</p><p attribs="{'xml:space': 'preserve'}" id="_05824" smilref="Title.smil#_05824"> Iteration. To enable clients to process all the keys and values in the table, we might add the phrase implements Iterable&lt;Key&gt; to the first line of the API to specify that every implementation must implement an iterator() method that returns an iterator having appropriate implementations of hasNext() and next(), as described for stacks and queues in Section 1.3. For symbol tables, we adopt a simpler alternative approach, where we specify a keys() method that returns an Iterable&lt;Key&gt; object for clients to use to iterate through the keys. Our reason for doing so is to maintain consistency with methods that we will define for ordered symbol tables that allow clients to iterate through a specified subset of keys in the table.</p><p attribs="{'xml:space': 'preserve'}" id="_05825" smilref="Title.smil#_05825"> Key equality. Determining whether or not a given key is in a symbol table is based on the concept of object equality, which we discussed at length in Section 1.2 (see page 102). Java&#8217;s convention that all objects inherit an equals() method and its implementation of equals() both for standard types such as Integer, Double, and String and for more complicated types such as File and URL is a head start&#8212;when using these types of data, you can just use the built-in implementation. For example, if x and y are String values, then x.equals(y) is true if and only if x and y have the same length and are identical in each character position. For such client-de&#64257; ned keys, you need to override equals(), as discussed in Section 1.2. You can use our implementation of equals() for Date (page 103) as a template to develop equals() for a type of your own. As discussed for priority queues on page 320, a best practice is to make Key types immu- table, because consistency cannot otherwise be guaranteed.</p><p attribs="{'xml:space': 'preserve'}" id="_05826" smilref="Title.smil#_05826" /></level3><level3 id="_00048"><h3 id="ch3-s1-ss2" smilref="Title.smil#ch3-s1-ss2" xml:space="preserve">Ordered symbol table API</h3><pagenum id="p379" page="normal" smilref="Title.smil#p379" /><p attribs="{'xml:space': 'preserve'}" id="_05827" smilref="Title.smil#_05827"> 366</p><p attribs="{'xml:space': 'preserve'}" id="_05828" smilref="Title.smil#_05828"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_05829" smilref="Title.smil#_05829"> Ordered symbol tables</p><p attribs="{'xml:space': 'preserve'}" id="_05830" smilref="Title.smil#_05830"> In typical applications, keys are Comparable objects, so the option exists of using the code a.compareTo(b) to compare two keys a and b. Several symbol-table implementations take advantage of order among the keys that is implied by Comparable to provide efficient implementations of the put() and get() operations. More important, in such implementations, we can think of the symbol table as keeping the keys in order and consider a significantly expanded API that defines numerous natural and useful operations involving relative key order. For example, suppose that your keys are times of the day. You might be interested in knowing the earliest or the latest time, the set of keys that fall between two given times, and so forth. In most cases, such operations are not difficult to implement with the same data structures and methods underlying the put() and get() implementations. Speci&#64257; cally, for applications where keys are Comparable, we implement in this chapter the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_05831" smilref="Title.smil#_05831"> public class ST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; ST()</p><p attribs="{'xml:space': 'preserve'}" id="_05832" smilref="Title.smil#_05832"> void put(Key key, Value val)</p><p attribs="{'xml:space': 'preserve'}" id="_05833" smilref="Title.smil#_05833"> Value get(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_05834" smilref="Title.smil#_05834"> void delete(Key key) boolean contains(Key key) boolean isEmpty() int size() Key min() Key max() Key floor(Key key) Key ceiling(Key key) int rank(Key key) Key select(int k) void deleteMin() void deleteMax() int size(Key lo, Key hi) Iterable&lt;Key&gt; keys(Key lo, Key hi) Iterable&lt;Key&gt; keys()</p><p attribs="{'xml:space': 'preserve'}" id="_05835" smilref="Title.smil#_05835"> create an ordered symbol table put key-value pair into the table (remove key from table if value is null) value paired with key (null if key is absent) remove key (and its value) from table is there a value paired with key? is the table empty? number of key-value pairs smallest key largest key largest key less than or equal to key smallest key greater than or equal to key number of keys less than key key of rank k delete smallest key delete largest key number of keys in [lo..hi] keys in [lo..hi], in sorted order all keys in the table, in sorted order</p><p attribs="{'xml:space': 'preserve'}" id="_05836" smilref="Title.smil#_05836"> API for a generic ordered symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_05837" smilref="Title.smil#_05837" /><pagenum id="p380" page="normal" smilref="Title.smil#p380" /><p attribs="{'xml:space': 'preserve'}" id="_05838" smilref="Title.smil#_05838"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05839" smilref="Title.smil#_05839"> 367</p><p attribs="{'xml:space': 'preserve'}" id="_05840" smilref="Title.smil#_05840"> Your signal that one of our programs is implementing this API is the presence of the Key extends Comparable&lt;Key&gt; generic type variable in the class declaration, which specifies that the code depends upon the keys being Comparable and implements the richer set of operations. Together, these operations define for client programs an ordered symbol table.</p><p attribs="{'xml:space': 'preserve'}" id="_05841" smilref="Title.smil#_05841"> Minimum and maximum. Perhaps the most natural queries for a set of ordered keys are to ask for the smallest and largest keys. We have already encountered these opera- tions, in our discussion of priority queues in Section 2.4. In ordered symbol tables, we also have methods to delete the maximum and minimum keys (and their associated val- ues). With this capability, the symbol table can operate like the IndexMinPQ() class that we discussed in Section 2.4. The primary differences are that equal keys are allowed in priority queues but not in symbol tables and that ordered symbol tables support a much larger set of operations.</p><p attribs="{'xml:space': 'preserve'}" id="_05842" smilref="Title.smil#_05842"> floor(09:05:00)</p><p attribs="{'xml:space': 'preserve'}" id="_05843" smilref="Title.smil#_05843"> get(09:00:13)</p><p attribs="{'xml:space': 'preserve'}" id="_05844" smilref="Title.smil#_05844"> select(7)</p><p attribs="{'xml:space': 'preserve'}" id="_05845" smilref="Title.smil#_05845"> min()</p><p attribs="{'xml:space': 'preserve'}" id="_05846" smilref="Title.smil#_05846"> keys</p><p attribs="{'xml:space': 'preserve'}" id="_05847" smilref="Title.smil#_05847"> values</p><p attribs="{'xml:space': 'preserve'}" id="_05848" smilref="Title.smil#_05848"> 09:00:00 Chicago 09:00:03 Phoenix 09:00:13 Houston 09:00:59 Chicago 09:01:10 Houston 09:03:13 Chicago 09:10:11 Seattle 09:10:25 Seattle 09:14:25 Phoenix 09:19:32 Chicago 09:19:46 Chicago 09:21:05 Chicago 09:22:43 Seattle 09:22:54 Seattle 09:25:52 Chicago 09:35:21 Chicago 09:36:14 Seattle 09:37:44 Phoenix</p><p attribs="{'xml:space': 'preserve'}" id="_05849" smilref="Title.smil#_05849"> Floor and ceiling. Given a key, it is often useful to be able to perform the floor operation (&#64257; nd the largest key that is less than or equal to the given key) and the ceiling operation (&#64257; nd the smallest key that is greater than or equal to the given key). The nomenclature comes from functions defined on real numbers (the floor of a real number x is the largest integer that is smaller than or equal to x and the ceiling of a real number x is the smallest integer that is greater than or equal to x).</p><p attribs="{'xml:space': 'preserve'}" id="_05850" smilref="Title.smil#_05850"> keys(09:15:00, 09:25:00)</p><p attribs="{'xml:space': 'preserve'}" id="_05851" smilref="Title.smil#_05851"> ceiling(09:30:00)</p><p attribs="{'xml:space': 'preserve'}" id="_05852" smilref="Title.smil#_05852"> max()</p><p attribs="{'xml:space': 'preserve'}" id="_05853" smilref="Title.smil#_05853"> size(09:15:00, 09:25:00) is 5 rank(09:10:25) is 7</p><p attribs="{'xml:space': 'preserve'}" id="_05854" smilref="Title.smil#_05854"> Examples of ordered symbol-table operations</p><p attribs="{'xml:space': 'preserve'}" id="_05855" smilref="Title.smil#_05855"> Rank and selection. The basic operations for determining where a new key fits in the order are the rank operation (&#64257; nd the number of keys less than a given key) and the select operation (&#64257; nd the key with a given rank). To test your understanding of their meaning, confirm for yourself that both i == rank(select(i)) for all i between 0 and size()-1 and all keys in the table satisfy key == select(rank(key)). We have already encountered the need for these operations, in our discussion of sort applications in Section 2.5. For symbol tables, our challenge is to perform these operations quickly, intermixed with insertions, deletions, and searches.</p><p attribs="{'xml:space': 'preserve'}" id="_05856" smilref="Title.smil#_05856" /><pagenum id="p381" page="normal" smilref="Title.smil#p381" /><p attribs="{'xml:space': 'preserve'}" id="_05857" smilref="Title.smil#_05857"> 368</p><p attribs="{'xml:space': 'preserve'}" id="_05858" smilref="Title.smil#_05858"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_05859" smilref="Title.smil#_05859"> Range queries. How many keys fall within a given range (between two given keys)? Which keys fall in a given range? The two-argument size() and keys() methods that answer these questions are useful in many applications, particularly in large databases. The capability to handle such queries is one prime reason that ordered symbol tables are so widely used in practice.</p><p attribs="{'xml:space': 'preserve'}" id="_05860" smilref="Title.smil#_05860"> Exceptional cases. When a method is to return a key and there is no key fitting the description in the table, our convention is to throw an exception (an alternate approach, which is also reasonable, would be to return null in such cases). For example, min(),</p><p attribs="{'xml:space': 'preserve'}" id="_05861" smilref="Title.smil#_05861"> max(), deleteMin(), deleteMax(), floor(), and ceiling() all throw exceptions if</p><p attribs="{'xml:space': 'preserve'}" id="_05862" smilref="Title.smil#_05862"> the table is empty, as does select(k) if k is less than 0 or not less than size().</p><p attribs="{'xml:space': 'preserve'}" id="_05863" smilref="Title.smil#_05863"> Shorthand methods. As we have already seen with isEmpty() and contains() in our basic API, we keep some redundant methods in the API for clarity in client code. For economy in the text, we assume that the following default implementations are included in any implementation of the ordered symbol-table API unless otherwise speci&#64257; ed:</p><p attribs="{'xml:space': 'preserve'}" id="_05864" smilref="Title.smil#_05864"> method</p><p attribs="{'xml:space': 'preserve'}" id="_05865" smilref="Title.smil#_05865"> default implementation</p><p attribs="{'xml:space': 'preserve'}" id="_05866" smilref="Title.smil#_05866"> void deleteMin()</p><p attribs="{'xml:space': 'preserve'}" id="_05867" smilref="Title.smil#_05867"> delete(min());</p><p attribs="{'xml:space': 'preserve'}" id="_05868" smilref="Title.smil#_05868"> void deleteMax()</p><p attribs="{'xml:space': 'preserve'}" id="_05869" smilref="Title.smil#_05869"> delete(max());</p><p attribs="{'xml:space': 'preserve'}" id="_05870" smilref="Title.smil#_05870"> int size(Key lo, Key hi) if (hi.compareTo(lo) &lt; 0) return 0; else if (contains(hi)) return rank(hi) - rank(lo) + 1; else return rank(hi) - rank(lo);</p><p attribs="{'xml:space': 'preserve'}" id="_05871" smilref="Title.smil#_05871"> Iterable&lt;Key&gt; keys()</p><p attribs="{'xml:space': 'preserve'}" id="_05872" smilref="Title.smil#_05872"> return keys(min(), max());</p><p attribs="{'xml:space': 'preserve'}" id="_05873" smilref="Title.smil#_05873"> Default implementations of redundant order-based symbol-table methods</p><p attribs="{'xml:space': 'preserve'}" id="_05874" smilref="Title.smil#_05874"> Key equality (revisited). The best practice in Java is to make compareTo() consistent with equals() in all Comparable types. That is, for every pair of values a and b in any given Comparable type, it should be the case that (a.compareTo(b) == 0) and a.equals(b) have the same value. To avoid any potential ambiguities, we avoid the use of equals() in ordered symbol-table implementations. Instead, we use compareTo() exclusively to compare keys: we take the boolean expression a.compareTo(b) == 0 to</p><p attribs="{'xml:space': 'preserve'}" id="_05875" smilref="Title.smil#_05875" /><pagenum id="p382" page="normal" smilref="Title.smil#p382" /><p attribs="{'xml:space': 'preserve'}" id="_05876" smilref="Title.smil#_05876"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05877" smilref="Title.smil#_05877"> 369</p><p attribs="{'xml:space': 'preserve'}" id="_05878" smilref="Title.smil#_05878"> mean &#8220;Are a and b equal ?&#8221; Typically, such a test marks the successful end of a search for a in the symbol table (by finding b). As you saw with sorting algorithms, Java provides standard implementations of compareTo() for many commonly used types of keys, and it is not difficult to develop a compareTo() implementation for your own data types (see Section 2.5). Cost model. Whether we use equals() (for symbol tables where keys are not Comparable) or compareTo() (for ordered symbol tables with Comparable keys), we use the term compare to refer to the operation of comparing a symbol- table entry against a search key. In most symbol-table imple- mentations, this operation is in the inner loop. In the few cases where that is not the case, we also count array accesses.</p><p attribs="{'xml:space': 'preserve'}" id="_05879" smilref="Title.smil#_05879"> Searching cost model.</p><p attribs="{'xml:space': 'preserve'}" id="_05880" smilref="Title.smil#_05880"> When studying symbol-table implementations, we count compares (equality tests or key comparisons). In (rare) cases where compares are not in the inner loop, we count array accesses.</p><p attribs="{'xml:space': 'preserve'}" id="_05881" smilref="Title.smil#_05881"> Symbol-table implementations are generally character-</p><p attribs="{'xml:space': 'preserve'}" id="_05882" smilref="Title.smil#_05882"> ized by their underlying data structures and their implementations of get() and put(). We do not always provide implementations of all of the other methods in the text because many of them make good exercises to test your understanding of the underlying data structures. To distinguish implementations, we add a descriptive prefix to ST that refers to the implementation in the class name of symbol-table implementations. In clients, we use ST to call on a reference implementation unless we wish to refer to a specific implementation. You will gradually develop a better feeling for the rationale behind the methods in the APIs in the context of the numerous clients and symbol-table implementations that we present and discuss throughout this chapter and throughout the rest of this book. We also discuss alternatives to the various design choices that we have described here in the Q&amp;A and exercises.</p><p attribs="{'xml:space': 'preserve'}" id="_05883" smilref="Title.smil#_05883" /><pagenum id="p383" page="normal" smilref="Title.smil#p383" /><p attribs="{'xml:space': 'preserve'}" id="_05884" smilref="Title.smil#_05884"> 370</p><p attribs="{'xml:space': 'preserve'}" id="_05885" smilref="Title.smil#_05885"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_05886" smilref="Title.smil#_05886"> Sample clients While we defer detailed consideration of applications to Section 3.5, it is worthwhile to consider some client code before considering implementations. Accordingly, we now consider two clients: a test client that we use to trace algorithm behavior on small inputs and a performance client that we use to motivate the development of efficient implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_05887" smilref="Title.smil#_05887"> Test client. For tracing our algorithms on small inputs we assume that all of our implementations use the test client below, which takes a sequence of strings from standard input, builds a symbol table that associates the value i with the ith string in the input, and then prints the table. In the traces in the text, we assume that the input is a sequence of single-character strings. Most often, we</p><p attribs="{'xml:space': 'preserve'}" id="_05888" smilref="Title.smil#_05888"> use the string "S E A R C H E X A M P L E".</p><p attribs="{'xml:space': 'preserve'}" id="_05889" smilref="Title.smil#_05889"> By our conventions, this client associates the key S with the value 0, the key R with the value 3, and so forth. But E is associated with the value 12 (not 1 or 6) and A with the value 8 (not 2) because our associative- array convention implies that each key is associated with the value used in the most recent call to put(). For basic (unordered) implementations, the order of the keys in the output of this test client is not specified (it depends on characteristics of the imple- mentation); for an ordered symbol table the test client prints the keys in sorted order. This client is an example of an indexing cli- ent, a special case of a fundamental symbol- table application that we discuss in Section</p><p attribs="{'xml:space': 'preserve'}" id="_05890" smilref="Title.smil#_05890"> 3.5.</p><p attribs="{'xml:space': 'preserve'}" id="_05891" smilref="Title.smil#_05891"> public static void main(String[] args) { ST&lt;String, Integer&gt; st; st = new ST&lt;String, Integer&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_05892" smilref="Title.smil#_05892"> for (int i = 0; !StdIn.isEmpty(); i++) { String key = StdIn.readString(); st.put(key, i); }</p><p attribs="{'xml:space': 'preserve'}" id="_05893" smilref="Title.smil#_05893"> for (String s : st.keys()) StdOut.println(s + " " + st.get(s)); }</p><p attribs="{'xml:space': 'preserve'}" id="_05894" smilref="Title.smil#_05894"> Basic symbol-table test client</p><p attribs="{'xml:space': 'preserve'}" id="_05895" smilref="Title.smil#_05895"> keys values</p><p attribs="{'xml:space': 'preserve'}" id="_05896" smilref="Title.smil#_05896"> S E A R C H E X A M P L E 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_05897" smilref="Title.smil#_05897"> output for basic symbol table (one possibility)</p><p attribs="{'xml:space': 'preserve'}" id="_05898" smilref="Title.smil#_05898"> output for ordered symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_05899" smilref="Title.smil#_05899"> L 11 P 10 M 9 X 7 H 5 C 4 R 3 A 8 E 12 S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05900" smilref="Title.smil#_05900"> A 8 C 4 E 12 H 5 L 11 M 9 P 10 R 3 S 0 X 7</p><p attribs="{'xml:space': 'preserve'}" id="_05901" smilref="Title.smil#_05901"> Keys, values, and output for test client</p><p attribs="{'xml:space': 'preserve'}" id="_05902" smilref="Title.smil#_05902" /><pagenum id="p384" page="normal" smilref="Title.smil#p384" /><p attribs="{'xml:space': 'preserve'}" id="_05903" smilref="Title.smil#_05903"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05904" smilref="Title.smil#_05904"> 371</p><p attribs="{'xml:space': 'preserve'}" id="_05905" smilref="Title.smil#_05905"> Performance client. FrequencyCounter (on the next page) is a symbol-table client that finds the number of occurrences of each string (having at least as many characters as a given threshold length) in a sequence of strings from standard input, then iterates through the keys to find the one that occurs the most frequently. This client is an example of a dictionary client, an application that we discuss in more detail in Section 3.5. This client answers a simple question: Which word (no shorter than a given length) occurs most frequently in a given text? Throughout this chapter, we measure performance of this client with three reference inputs: the first five lines of C. Dickens&#8217;s Tale of Two Cities (tinyTale.txt), the full text of the book (tale.txt), and a popular database of 1 million sentences taken at random from the web that is known as the Leipzig Corpora Collection (leipzig1M.txt). For example, here is the content of tinyTale.txt:</p><p attribs="{'xml:space': 'preserve'}" id="_05906" smilref="Title.smil#_05906"> % more tinyTale.txt it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief it was the epoch of incredulity it was the season of light it was the season of darkness it was the spring of hope it was the winter of despair</p><p attribs="{'xml:space': 'preserve'}" id="_05907" smilref="Title.smil#_05907"> Small test input</p><p attribs="{'xml:space': 'preserve'}" id="_05908" smilref="Title.smil#_05908"> This text has 60 words taken from 20 distinct words, four of which occur ten times (the highest frequency). Given this input, FrequencyCounter will print out any of it, was, the, or of (the one chosen may vary, depending upon characteristics of the symbol- table implementation), followed by the frequency, 10. To study performance for the larger inputs, it is clear that two measures are of inter- est: Each word in the input is used as a search key once, so the total number of words in the text is certainly relevant. Second, each distinct word in the input is put into the</p><p attribs="{'xml:space': 'preserve'}" id="_05909" smilref="Title.smil#_05909"> tinyTale.txt</p><p attribs="{'xml:space': 'preserve'}" id="_05910" smilref="Title.smil#_05910"> tale.txt</p><p attribs="{'xml:space': 'preserve'}" id="_05911" smilref="Title.smil#_05911"> leipzig1M.txt</p><p attribs="{'xml:space': 'preserve'}" id="_05912" smilref="Title.smil#_05912"> words</p><p attribs="{'xml:space': 'preserve'}" id="_05913" smilref="Title.smil#_05913"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_05914" smilref="Title.smil#_05914"> words</p><p attribs="{'xml:space': 'preserve'}" id="_05915" smilref="Title.smil#_05915"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_05916" smilref="Title.smil#_05916"> words</p><p attribs="{'xml:space': 'preserve'}" id="_05917" smilref="Title.smil#_05917"> all words at least 8 letters at least 10 letters</p><p attribs="{'xml:space': 'preserve'}" id="_05918" smilref="Title.smil#_05918"> 60 3 2</p><p attribs="{'xml:space': 'preserve'}" id="_05919" smilref="Title.smil#_05919"> 20 3 2</p><p attribs="{'xml:space': 'preserve'}" id="_05920" smilref="Title.smil#_05920"> 135,635 14,350 4,582</p><p attribs="{'xml:space': 'preserve'}" id="_05921" smilref="Title.smil#_05921"> 10,679 5,737 2,260</p><p attribs="{'xml:space': 'preserve'}" id="_05922" smilref="Title.smil#_05922"> 21,191,455 4,239,597 1,610,829</p><p attribs="{'xml:space': 'preserve'}" id="_05923" smilref="Title.smil#_05923"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_05924" smilref="Title.smil#_05924"> 534,580 299,593 165,555</p><p attribs="{'xml:space': 'preserve'}" id="_05925" smilref="Title.smil#_05925"> Characteristics of larger test input streams</p><p attribs="{'xml:space': 'preserve'}" id="_05926" smilref="Title.smil#_05926" /><pagenum id="p385" page="normal" smilref="Title.smil#p385" /><p attribs="{'xml:space': 'preserve'}" id="_05927" smilref="Title.smil#_05927"> 372</p><p attribs="{'xml:space': 'preserve'}" id="_05928" smilref="Title.smil#_05928"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_05929" smilref="Title.smil#_05929"> A symbol-table client</p><p attribs="{'xml:space': 'preserve'}" id="_05930" smilref="Title.smil#_05930"> public class FrequencyCounter { public static void main(String[] args) { int minlen = Integer.parseInt(args[0]); // key-length cutoff ST&lt;String, Integer&gt; st = new ST&lt;String, Integer&gt;(); while (!StdIn.isEmpty()) { // Build symbol table and count frequencies. String word = StdIn.readString(); if (word.length() &lt; minlen) continue; // Ignore short keys. if (!st.contains(word)) st.put(word, 1); else st.put(word, st.get(word) + 1); } // Find a key with the highest frequency count. String max = ""; st.put(max, 0); for (String word : st.keys()) if (st.get(word) &gt; st.get(max)) max = word; StdOut.println(max + " " + st.get(max)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_05931" smilref="Title.smil#_05931"> This ST client counts the frequency of occurrence of the strings in standard input, then prints out one that occurs with highest frequency. The command-line argument specifies a lower bound on the length of keys considered.</p><p attribs="{'xml:space': 'preserve'}" id="_05932" smilref="Title.smil#_05932"> % java FrequencyCounter 1 &lt; tinyTale.txt it 10</p><p attribs="{'xml:space': 'preserve'}" id="_05933" smilref="Title.smil#_05933"> % java FrequencyCounter 8 &lt; tale.txt business 122</p><p attribs="{'xml:space': 'preserve'}" id="_05934" smilref="Title.smil#_05934"> % java FrequencyCounter 10 &lt; leipzig1M.txt government 24763</p><p attribs="{'xml:space': 'preserve'}" id="_05935" smilref="Title.smil#_05935" /><pagenum id="p386" page="normal" smilref="Title.smil#p386" /><p attribs="{'xml:space': 'preserve'}" id="_05936" smilref="Title.smil#_05936"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_05937" smilref="Title.smil#_05937"> 373</p><p attribs="{'xml:space': 'preserve'}" id="_05938" smilref="Title.smil#_05938"> symbol table (and the total number of distinct words in the input gives the size of the table after all keys have been inserted), so the total number of distinct words in the input stream is certainly relevant. We need to know both of these quantities in order to estimate the running time of FrequencyCounter (for a start, see Exercise 3.1.6). We defer details until we consider some algorithms, but you should have in mind a general idea of the needs of typical applications like this one. For example, running FrequencyCounter on leipzig1M.txt for words of length 8 or more involves millions of searches in a table with hundreds of thousands of keys and values. A server on the web might need to handle billions of transactions on tables with millions of keys and values.</p><p attribs="{'xml:space': 'preserve'}" id="_05939" smilref="Title.smil#_05939"> The basic question that this client and these examples raise is the following: Can we develop a symbol-table implementation that can handle a huge number of get() operations on a large table, which itself was built with a large number of intermixed get() and put() operations? If you are only doing a few searches, any implementation will do, but you cannot make use of a client like FrequencyCounter for large problems without a good symbol-table implementation. FrequencyCounter is surrogate for a very common situation. Speci&#64257; cally, it has the following characteristics, which are shared by many other symbol-table clients: </p><p attribs="{'xml:space': 'preserve'}" id="_05940" smilref="Title.smil#_05940" /><pagenum id="p387" page="normal" smilref="Title.smil#p387" /><p attribs="{'xml:space': 'preserve'}" id="_05941" smilref="Title.smil#_05941"> Sequential search in an unordered linked list One straightforward option</p><p attribs="{'xml:space': 'preserve'}" id="_05942" smilref="Title.smil#_05942"> for the underlying data structure for a symbol table is a linked list of nodes that contain keys and values, as in the code on the facing page. To implement get(), we scan through the list, using equals() to compare the search key with the key in each node in the list. If we find the match, we return the associated value; if not, we return null. To implement put(), we also scan through the list, using equals() to compare the client key with the key in each node in the list. If we find the match, we update the value associated with that key to be the value given in the second argument; if not, we create a new node with the given key and value and insert it at the beginning of the list. This method is known as sequential search: we search by considering the keys in the table one after another, using equals() to test for a match with our search key. Algorithm 3.1 (SequentialSearchST) is an implementation of our basic symbol- table API that uses standard list-processing mechanisms, which we have used for elementary data structures in Chapter 1. We have left the implementations of size(), keys(), and eager delete() for exercises. You are encouraged to work these exercises to cement your understanding of the linked-list data structure and the basic symbol- table API. Can this linked-list-based implementation handle applications that need large ta- bles, such as our sample clients? As we have noted, analyzing symbol-table algorithms is more complicated than analyzing sorting algorithms because of the difficulty of</p><p attribs="{'xml:space': 'preserve'}" id="_05943" smilref="Title.smil#_05943"> Trace of linked-list ST implementation for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_05944" smilref="Title.smil#_05944"> red nodes are new</p><p attribs="{'xml:space': 'preserve'}" id="_05945" smilref="Title.smil#_05945"> black nodes are accessed in search</p><p attribs="{'xml:space': 'preserve'}" id="_05946" smilref="Title.smil#_05946"> first</p><p attribs="{'xml:space': 'preserve'}" id="_05947" smilref="Title.smil#_05947"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05948" smilref="Title.smil#_05948"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05949" smilref="Title.smil#_05949"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_05950" smilref="Title.smil#_05950"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05951" smilref="Title.smil#_05951"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_05952" smilref="Title.smil#_05952"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05953" smilref="Title.smil#_05953"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05954" smilref="Title.smil#_05954"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_05955" smilref="Title.smil#_05955"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05956" smilref="Title.smil#_05956"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05957" smilref="Title.smil#_05957"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05958" smilref="Title.smil#_05958"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_05959" smilref="Title.smil#_05959"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05960" smilref="Title.smil#_05960"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05961" smilref="Title.smil#_05961"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05962" smilref="Title.smil#_05962"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05963" smilref="Title.smil#_05963"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_05964" smilref="Title.smil#_05964"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05965" smilref="Title.smil#_05965"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05966" smilref="Title.smil#_05966"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05967" smilref="Title.smil#_05967"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_05968" smilref="Title.smil#_05968"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05969" smilref="Title.smil#_05969"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_05970" smilref="Title.smil#_05970"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05971" smilref="Title.smil#_05971"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05972" smilref="Title.smil#_05972"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05973" smilref="Title.smil#_05973"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_05974" smilref="Title.smil#_05974"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05975" smilref="Title.smil#_05975"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_05976" smilref="Title.smil#_05976"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_05977" smilref="Title.smil#_05977"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05978" smilref="Title.smil#_05978"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05979" smilref="Title.smil#_05979"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_05980" smilref="Title.smil#_05980"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05981" smilref="Title.smil#_05981"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_05982" smilref="Title.smil#_05982"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_05983" smilref="Title.smil#_05983"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05984" smilref="Title.smil#_05984"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05985" smilref="Title.smil#_05985"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_05986" smilref="Title.smil#_05986"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_05987" smilref="Title.smil#_05987"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_05988" smilref="Title.smil#_05988"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_05989" smilref="Title.smil#_05989"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_05990" smilref="Title.smil#_05990"> L 11</p><p attribs="{'xml:space': 'preserve'}" id="_05991" smilref="Title.smil#_05991"> L 11</p><p attribs="{'xml:space': 'preserve'}" id="_05992" smilref="Title.smil#_05992"> circled entries are changed values</p><p attribs="{'xml:space': 'preserve'}" id="_05993" smilref="Title.smil#_05993"> gray nodes are untouched</p><p attribs="{'xml:space': 'preserve'}" id="_05994" smilref="Title.smil#_05994"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_05995" smilref="Title.smil#_05995"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_05996" smilref="Title.smil#_05996"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_05997" smilref="Title.smil#_05997"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_05998" smilref="Title.smil#_05998"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_05999" smilref="Title.smil#_05999"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06000" smilref="Title.smil#_06000"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06001" smilref="Title.smil#_06001"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_06002" smilref="Title.smil#_06002"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_06003" smilref="Title.smil#_06003"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_06004" smilref="Title.smil#_06004"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_06005" smilref="Title.smil#_06005"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_06006" smilref="Title.smil#_06006"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_06007" smilref="Title.smil#_06007"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06008" smilref="Title.smil#_06008"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06009" smilref="Title.smil#_06009"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_06010" smilref="Title.smil#_06010"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_06011" smilref="Title.smil#_06011"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_06012" smilref="Title.smil#_06012"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_06013" smilref="Title.smil#_06013"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_06014" smilref="Title.smil#_06014"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_06015" smilref="Title.smil#_06015"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_06016" smilref="Title.smil#_06016"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06017" smilref="Title.smil#_06017"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06018" smilref="Title.smil#_06018"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_06019" smilref="Title.smil#_06019"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_06020" smilref="Title.smil#_06020"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_06021" smilref="Title.smil#_06021"> E 12</p><p attribs="{'xml:space': 'preserve'}" id="_06022" smilref="Title.smil#_06022"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_06023" smilref="Title.smil#_06023"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_06024" smilref="Title.smil#_06024"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_06025" smilref="Title.smil#_06025"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06026" smilref="Title.smil#_06026"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06027" smilref="Title.smil#_06027"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_06028" smilref="Title.smil#_06028"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_06029" smilref="Title.smil#_06029"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_06030" smilref="Title.smil#_06030"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_06031" smilref="Title.smil#_06031"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_06032" smilref="Title.smil#_06032"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_06033" smilref="Title.smil#_06033"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06034" smilref="Title.smil#_06034"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_06035" smilref="Title.smil#_06035"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06036" smilref="Title.smil#_06036"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_06037" smilref="Title.smil#_06037"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_06038" smilref="Title.smil#_06038"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_06039" smilref="Title.smil#_06039"> L 11</p><p attribs="{'xml:space': 'preserve'}" id="_06040" smilref="Title.smil#_06040"> E 12</p><p attribs="{'xml:space': 'preserve'}" id="_06041" smilref="Title.smil#_06041"> 374</p><p attribs="{'xml:space': 'preserve'}" id="_06042" smilref="Title.smil#_06042"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06043" smilref="Title.smil#_06043" /><pagenum id="p388" page="normal" smilref="Title.smil#p388" /><p attribs="{'xml:space': 'preserve'}" id="_06044" smilref="Title.smil#_06044"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06045" smilref="Title.smil#_06045"> 375</p><p attribs="{'xml:space': 'preserve'}" id="_06046" smilref="Title.smil#_06046"> ALGORITHM 3.1 Sequential search (in an unordered linked list)</p><p attribs="{'xml:space': 'preserve'}" id="_06047" smilref="Title.smil#_06047"> public class SequentialSearchST&lt;Key, Value&gt; { private Node first; // first node in the linked list</p><p attribs="{'xml:space': 'preserve'}" id="_06048" smilref="Title.smil#_06048"> private class Node { // linked-list node Key key; Value val; Node next; public Node(Key key, Value val, Node next) { this.key = key; this.val = val; this.next = next; } }</p><p attribs="{'xml:space': 'preserve'}" id="_06049" smilref="Title.smil#_06049"> public Value get(Key key) { // Search for key, return associated value. for (Node x = first; x != null; x = x.next) if (key.equals(x.key)) return x.val; // search hit return null; // search miss }</p><p attribs="{'xml:space': 'preserve'}" id="_06050" smilref="Title.smil#_06050"> public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. for (Node x = first; x != null; x = x.next) if (key.equals(x.key)) { x.val = val; return; } // Search hit: update val. first = new Node(key, val, first); // Search miss: add new node. } }</p><p attribs="{'xml:space': 'preserve'}" id="_06051" smilref="Title.smil#_06051"> This ST implementation uses a private Node inner class to keep the keys and values in an unordered linked list. The get() implementation searches the list sequentially to find whether the key is in the table (and returns the associated value if so). The put() implementation also searches the list sequentially to check whether the key is in the table. If so, it updates the associated value; if not, it creates a new node with the given key and value and inserts it at the beginning of the list. Implementations of size(), keys(), and eager delete() are left for exercises.</p><p attribs="{'xml:space': 'preserve'}" id="_06052" smilref="Title.smil#_06052" /><pagenum id="p389" page="normal" smilref="Title.smil#p389" /><p attribs="{'xml:space': 'preserve'}" id="_06053" smilref="Title.smil#_06053"> 376</p><p attribs="{'xml:space': 'preserve'}" id="_06054" smilref="Title.smil#_06054"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06055" smilref="Title.smil#_06055"> characterizing the sequence of operations that might be invoked by a given client. As noted for FrequencyCounter, the most common situation is that, while search and insert patterns are unpredictable, they certainly are not random. For this reason, we pay careful attention to worst-case performance. For economy, we use the term search hit to refer to a successful search and search miss to refer to an unsuccessful search.</p><p attribs="{'xml:space': 'preserve'}" id="_06056" smilref="Title.smil#_06056"> Proposition A. Search misses and insertions in an (unordered) linked-list symbol table having N key-value pairs both require N compares, and search hits N compares in the worst case. In particular, inserting N distinct keys into an initially empty linked-list symbol table uses ~N 2/2 compares.</p><p attribs="{'xml:space': 'preserve'}" id="_06057" smilref="Title.smil#_06057"> Proof : When searching for a key that is not in the list, we test every key in the table against the search key. Because of our policy of disallowing duplicate keys, we need to do such a search before each insertion.</p><p attribs="{'xml:space': 'preserve'}" id="_06058" smilref="Title.smil#_06058"> Corollary. Inserting N distinct keys into an initially empty linked-list symbol table uses ~N 2/2 compares.</p><p attribs="{'xml:space': 'preserve'}" id="_06059" smilref="Title.smil#_06059"> It is true that searches for keys that are in the table need not take linear time. One useful measure is to compute the total cost of searching for all of the keys in the table, divided by N. This quantity is precisely the expected number of compares required for a search under the condition that searches for each key in the table are equally likely. We refer to such a search as a random search hit. Though client search patterns are not likely to be random, they often are well-described by this model. It is easy to show that the average number of compares for a random search hit is ~ N/2: the get() method in Algo- rithm 3.1 uses 1 compare to find the first key, 2 compares to find the second key, and so forth, for an average cost of (1 + 2 + ... + N )/ N = (N &#11001; 1)/2 ~ N/2. This analysis strongly indicates that a linked-list implementation with sequential search is too slow for it to be used to solve huge problems such as our reference inputs with clients like FrequencyCounter. The total number of compares is proportional to the product of the number of searches and the number of inserts, which is more than 10 9 for Tale of Two Cities and more than 1014 for the Leipzig Corpora. As usual, to validate analytic results, we need to run experiments. As an example, we study the operation of FrequencyCounter with command-line argument 8 for tale.txt, which involves 14,350 put() operations (recall that every word in the input leads to a put(), to update its frequency, and we ignore the cost of easily avoided calls</p><p attribs="{'xml:space': 'preserve'}" id="_06060" smilref="Title.smil#_06060" /><pagenum id="p390" page="normal" smilref="Title.smil#p390" /><p attribs="{'xml:space': 'preserve'}" id="_06061" smilref="Title.smil#_06061"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06062" smilref="Title.smil#_06062"> 377</p><p attribs="{'xml:space': 'preserve'}" id="_06063" smilref="Title.smil#_06063"> to contains()). The symbol table grows to 5,737 keys, so about one-third of the operations increase the size of the table; the rest are searches. To visualize the performance, we use VisualAccumulator (see page 95) to plot two points corresponding to each put() operation as follows: for the i th put() operation we plot a gray point with x coordinate i and y coordinate the number of key compares it uses and a red point with x coordinate i and y coordinate the cumulative average number of key compares used for the first i put() operations. As with any scientific data, there is a great deal of information in this data for us to investigate (this plot has 14,350 gray points and 14,350 red points). In this context, our primary interest is that the plot validates our hypothesis that about half the list is accessed for the average put() operation. The actual total is slightly lower than half, but this fact (and the precise shape of the curves) is perhaps best explained by characteristics of the application, not our algorithms (see Exercise 3.1.36). While detailed characterization of performance for particular clients can be com- plicated, specific hypotheses are easy to formulate and to test for FrequencyCount with our reference inputs or with randomly ordered inputs, using a client like the DoublingTest client that we introduced in Chapter 1. We will reserve such testing for exercises and for the more sophisticated implementations that follow . If you are not already convinced that we need faster implementations, be sure to work these exercises</p><p attribs="{'xml:space': 'preserve'}" id="_06064" smilref="Title.smil#_06064"> (or just run FrequencyCounter with SequentialSearchST on leipzig1M.txt!).</p><p attribs="{'xml:space': 'preserve'}" id="_06065" smilref="Title.smil#_06065"> 5737</p><p attribs="{'xml:space': 'preserve'}" id="_06066" smilref="Title.smil#_06066"> s</p><p attribs="{'xml:space': 'preserve'}" id="_06067" smilref="Title.smil#_06067"> e</p><p attribs="{'xml:space': 'preserve'}" id="_06068" smilref="Title.smil#_06068"> r</p><p attribs="{'xml:space': 'preserve'}" id="_06069" smilref="Title.smil#_06069"> a</p><p attribs="{'xml:space': 'preserve'}" id="_06070" smilref="Title.smil#_06070"> p</p><p attribs="{'xml:space': 'preserve'}" id="_06071" smilref="Title.smil#_06071"> m</p><p attribs="{'xml:space': 'preserve'}" id="_06072" smilref="Title.smil#_06072"> o</p><p attribs="{'xml:space': 'preserve'}" id="_06073" smilref="Title.smil#_06073"> c</p><p attribs="{'xml:space': 'preserve'}" id="_06074" smilref="Title.smil#_06074"> 2246</p><p attribs="{'xml:space': 'preserve'}" id="_06075" smilref="Title.smil#_06075"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06076" smilref="Title.smil#_06076"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06077" smilref="Title.smil#_06077"> Costs for java FrequencyCounter 8 &lt; tale.txt using SequentialSearchST</p><p attribs="{'xml:space': 'preserve'}" id="_06078" smilref="Title.smil#_06078"> operations</p><p attribs="{'xml:space': 'preserve'}" id="_06079" smilref="Title.smil#_06079"> 14350</p><p attribs="{'xml:space': 'preserve'}" id="_06080" smilref="Title.smil#_06080" /></level3><level3 id="_00049"><h3 id="ch3-s1-ss3" smilref="Title.smil#ch3-s1-ss3" xml:space="preserve">Sequential search</h3><pagenum id="p391" page="normal" smilref="Title.smil#p391" /><p attribs="{'xml:space': 'preserve'}" id="_06081" smilref="Title.smil#_06081"> 378</p><p attribs="{'xml:space': 'preserve'}" id="_06082" smilref="Title.smil#_06082"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06083" smilref="Title.smil#_06083"> Binary search in an ordered array Next, we consider a full implementation of our ordered symbol-table API. The underlying data structure is a pair of parallel arrays, one for the keys and one for the values. Algorithm 3.2 (BinarySearchST) on the facing page keeps Comparable keys in order in the array, then uses array indexing to enable fast implementation of get() and other operations. The heart of the implementation is the rank() method, which returns the number of keys smaller than a given key. For get(), the rank tells us precisely where the key is to be found if it is in the table (and, if it is not there, that it is not in the table). For put(), the rank tells us precisely where to update the value when the key is in the table, and precisely where to put the key when the key is not in the table. We move all larger keys over one position to make room (working from back to front) and insert the given key and value into the proper positions in their respective arrays. Again, studying BinarySearchST in conjunction with a trace of our test client is an instructive introduction to this data structure. This code maintains parallel arrays of keys and values (see Exercise 3.1.12 for an alternative). As with our implementations of generic stacks and queues in Chapter 1, this code carries the inconvenience of having to create a Key array of type Comparable and a Value array of type Object, and to cast them back to Key[] and Value[] in the constructor. As usual, we can use array resizing so that clients do not have to be concerned with the size of the array (noting, as you shall see, that this method is too slow to use with large arrays).</p><p attribs="{'xml:space': 'preserve'}" id="_06084" smilref="Title.smil#_06084"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_06085" smilref="Title.smil#_06085"> entries in red were inserted</p><p attribs="{'xml:space': 'preserve'}" id="_06086" smilref="Title.smil#_06086"> entries in gray did not move</p><p attribs="{'xml:space': 'preserve'}" id="_06087" smilref="Title.smil#_06087"> entries in black moved to the right</p><p attribs="{'xml:space': 'preserve'}" id="_06088" smilref="Title.smil#_06088"> keys[] vals[] 0 1 2 3 4 5 6 7 8 9 N 0 1 2 3 4 5 6 7 8 9 S 0 S 1 0 E 1 E S 2 1 0 A 2 A E S 3 2 1 0 R 3 A E R S 4 2 1 3 0 C 4 A C E R S 5 2 4 1 3 0 H 5 A C E H R S 6 2 4 1 5 3 0 E 6 A C E H R S 6 2 4 6 5 3 0 X 7 A C E H R S X 7 2 4 6 5 3 0 7 A 8 A C E H R S X 7 8 4 6 5 3 0 7 M 9 A C E H M R S X 8 8 4 6 5 9 3 0 7 P 10 A C E H M P R S X 9 8 4 6 5 9 10 3 0 7 L 11 A C E H L M P R S X 10 8 4 6 5 11 9 10 3 0 7 E 12 A C E H L M P R S X 10 8 4 12 5 11 9 10 3 0 7 A C E H L M P R S X 8 4 12 5 11 9 10 3 0 7</p><p attribs="{'xml:space': 'preserve'}" id="_06089" smilref="Title.smil#_06089"> circled entries are changed values</p><p attribs="{'xml:space': 'preserve'}" id="_06090" smilref="Title.smil#_06090"> Trace of ordered-array ST implementation for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_06091" smilref="Title.smil#_06091" /><pagenum id="p392" page="normal" smilref="Title.smil#p392" /><p attribs="{'xml:space': 'preserve'}" id="_06092" smilref="Title.smil#_06092"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06093" smilref="Title.smil#_06093"> 379</p><p attribs="{'xml:space': 'preserve'}" id="_06094" smilref="Title.smil#_06094"> ALGORITHM 3.2 Binary search (in an ordered array)</p><p attribs="{'xml:space': 'preserve'}" id="_06095" smilref="Title.smil#_06095"> public class BinarySearchST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; { private Key[] keys; private Value[] vals; private int N;</p><p attribs="{'xml:space': 'preserve'}" id="_06096" smilref="Title.smil#_06096"> public BinarySearchST(int capacity) { // See Algorithm 1.1 for standard array-resizing code. keys = (Key[]) new Comparable[capacity]; vals = (Value[]) new Object[capacity]; }</p><p attribs="{'xml:space': 'preserve'}" id="_06097" smilref="Title.smil#_06097"> public int size() { return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_06098" smilref="Title.smil#_06098"> public Value get(Key key) { if (isEmpty()) return null; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) return vals[i]; else return null; }</p><p attribs="{'xml:space': 'preserve'}" id="_06099" smilref="Title.smil#_06099"> public int rank(Key key) // See page 381.</p><p attribs="{'xml:space': 'preserve'}" id="_06100" smilref="Title.smil#_06100"> public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) { vals[i] = val; return; } for (int j = N; j &gt; i; j--) { keys[j] = keys[j-1]; vals[j] = vals[j-1]; } keys[i] = key; vals[i] = val; N++; }</p><p attribs="{'xml:space': 'preserve'}" id="_06101" smilref="Title.smil#_06101"> public void delete(Key key) // See Exercise 3.1.16 for this method.</p><p attribs="{'xml:space': 'preserve'}" id="_06102" smilref="Title.smil#_06102"> }</p><p attribs="{'xml:space': 'preserve'}" id="_06103" smilref="Title.smil#_06103"> This ST implementation keeps the keys and values in parallel arrays. The put() implementation moves larger keys one position to the right before growing the table as in the array-based stack implementation in Section 1.3. Array-resizing code is omitted here.</p><p attribs="{'xml:space': 'preserve'}" id="_06104" smilref="Title.smil#_06104" /></level3><level3 id="_00050"><h3 id="ch3-s1-ss4" smilref="Title.smil#ch3-s1-ss4" xml:space="preserve">Binary search</h3><pagenum id="p393" page="normal" smilref="Title.smil#p393" /><p attribs="{'xml:space': 'preserve'}" id="_06105" smilref="Title.smil#_06105"> 380</p><p attribs="{'xml:space': 'preserve'}" id="_06106" smilref="Title.smil#_06106"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06107" smilref="Title.smil#_06107"> Recursive binary search</p><p attribs="{'xml:space': 'preserve'}" id="_06108" smilref="Title.smil#_06108"> public int rank(Key key, int lo, int hi) { if (hi &lt; lo) return lo; int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) return rank(key, lo, mid-1); else if (cmp &gt; 0) return rank(key, mid+1, hi); else return mid; }</p><p attribs="{'xml:space': 'preserve'}" id="_06109" smilref="Title.smil#_06109"> Binary search. The reason that we keep keys in an ordered array is so that we can use array indexing to dramatically reduce the number of compares required for each search, using the classic and venerable binary search algorithm that we used as an example in Chapter 1. We maintain indices into the sorted key array that delimit the subar- ray that might contain the search key. To search, we compare the search key against the key in the middle of the subarray. If the search key is less than the key in the middle, we search in the left half of the subarray ; if the search key is greater than the key in the middle, we search in the right half of the subarray ; otherwise the key in the middle is equal to the search key. The rank() code on the facing page uses binary search to complete the symbol-table implementation just discussed. This implementation is worthy of careful study. To study it, we start with the equivalent recursive code at left. A call to rank(key, 0, N-1) does the same sequence of compares as a call to the nonrecursive implementation in Algorithm 3.2, but this alternate version better exposes the structure of the algorithm, as discussed in Section 1.1. This recursive rank() preserves the following properties: </p><p attribs="{'xml:space': 'preserve'}" id="_06110" smilref="Title.smil#_06110"> Other operations. Since the keys are kept in an ordered array, most of the order-based operations are compact and straightforward, as you can see from the code on page 382. For example, a call to select(k) just returns keys[k].We have left delete() and floor() as exercises. You are encouraged to study the implementation of ceiling() and the two-argument keys() and to work these exercises to cement your understanding of the ordered symbol-table API and this implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_06111" smilref="Title.smil#_06111" /><pagenum id="p394" page="normal" smilref="Title.smil#p394" /><p attribs="{'xml:space': 'preserve'}" id="_06112" smilref="Title.smil#_06112"> ALGORITHM 3.2 (continued) Binary search in an ordered array (iterative)</p><p attribs="{'xml:space': 'preserve'}" id="_06113" smilref="Title.smil#_06113"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06114" smilref="Title.smil#_06114"> 381</p><p attribs="{'xml:space': 'preserve'}" id="_06115" smilref="Title.smil#_06115"> public int rank(Key key) { int lo = 0, hi = N-1; while (lo &lt;= hi) { int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) hi = mid - 1; else if (cmp &gt; 0) lo = mid + 1; else return mid;</p><p attribs="{'xml:space': 'preserve'}" id="_06116" smilref="Title.smil#_06116"> } return lo; }</p><p attribs="{'xml:space': 'preserve'}" id="_06117" smilref="Title.smil#_06117"> This method uses the classic method described in the text to compute the number of keys in the table that are smaller than key. Compare key with the key in the middle: if it is equal, return its index; if it is less, look in the left half; if it is greater, look in the right half.</p><p attribs="{'xml:space': 'preserve'}" id="_06118" smilref="Title.smil#_06118"> successful search for P</p><p attribs="{'xml:space': 'preserve'}" id="_06119" smilref="Title.smil#_06119"> keys[] 0 1 2 3 4 5 6 7 8 9 lo hi mid 0 9 4 A C E H L M P R S X 5 9 7 A C E H L M P R S X 5 6 5 A C E H L M P R S X 6 6 6 A C E H L M P R S X</p><p attribs="{'xml:space': 'preserve'}" id="_06120" smilref="Title.smil#_06120"> entries in black are a[lo..hi]</p><p attribs="{'xml:space': 'preserve'}" id="_06121" smilref="Title.smil#_06121"> entry in red is a[mid]</p><p attribs="{'xml:space': 'preserve'}" id="_06122" smilref="Title.smil#_06122"> unsuccessful search for Q</p><p attribs="{'xml:space': 'preserve'}" id="_06123" smilref="Title.smil#_06123"> loop exits with keys[mid] = P: return</p><p attribs="{'xml:space': 'preserve'}" id="_06124" smilref="Title.smil#_06124"> lo hi mid 0 9 4 A C E H L M P R S X 5 9 7 A C E H L M P R S X 5 6 5 A C E H L M P R S X 7 6 6 A C E H L M P R S X</p><p attribs="{'xml:space': 'preserve'}" id="_06125" smilref="Title.smil#_06125"> loop exits with lo &gt; hi: return 7</p><p attribs="{'xml:space': 'preserve'}" id="_06126" smilref="Title.smil#_06126"> Trace of binary search for rank in an ordered array</p><p attribs="{'xml:space': 'preserve'}" id="_06127" smilref="Title.smil#_06127" /><pagenum id="p395" page="normal" smilref="Title.smil#p395" /><p attribs="{'xml:space': 'preserve'}" id="_06128" smilref="Title.smil#_06128"> 382</p><p attribs="{'xml:space': 'preserve'}" id="_06129" smilref="Title.smil#_06129"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06130" smilref="Title.smil#_06130"> ALGORITHM 3.2 (continued) Ordered symbol-table operations for binary search</p><p attribs="{'xml:space': 'preserve'}" id="_06131" smilref="Title.smil#_06131"> public Key min() { return keys[0]; }</p><p attribs="{'xml:space': 'preserve'}" id="_06132" smilref="Title.smil#_06132"> public Key max() { return keys[N-1]; }</p><p attribs="{'xml:space': 'preserve'}" id="_06133" smilref="Title.smil#_06133"> public Key select(int k) { return keys[k]; }</p><p attribs="{'xml:space': 'preserve'}" id="_06134" smilref="Title.smil#_06134"> public Key ceiling(Key key) { int i = rank(key); return keys[i]; }</p><p attribs="{'xml:space': 'preserve'}" id="_06135" smilref="Title.smil#_06135"> public Key floor(Key key) // See Exercise 3.1.17.</p><p attribs="{'xml:space': 'preserve'}" id="_06136" smilref="Title.smil#_06136"> public Key delete(Key key) // See Exercise 3.1.16.</p><p attribs="{'xml:space': 'preserve'}" id="_06137" smilref="Title.smil#_06137"> public Iterable&lt;Key&gt; keys(Key lo, Key hi) { Queue&lt;Key&gt; q = new Queue&lt;Key&gt;(); for (int i = rank(lo); i &lt; rank(hi); i++) q.enqueue(keys[i]); if (contains(hi)) q.enqueue(keys[rank(hi)]); return q; }</p><p attribs="{'xml:space': 'preserve'}" id="_06138" smilref="Title.smil#_06138"> These methods, along with the methods of Exercise 3.1.16 and Exercise 3.1.17, complete the implementation of our (ordered) symbol-table API using binary search in an ordered array. The min(), max(), and select() methods are trivial, just amounting to returning the appropriate key from its known position in the array. The rank() method, which is the basis of binary search, plays a central role in the others. The floor() and delete() implementations, left for exercises, are more compli- cated, but still straightforward.</p><p attribs="{'xml:space': 'preserve'}" id="_06139" smilref="Title.smil#_06139" /><pagenum id="p396" page="normal" smilref="Title.smil#p396" /><p attribs="{'xml:space': 'preserve'}" id="_06140" smilref="Title.smil#_06140"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06141" smilref="Title.smil#_06141"> 383</p><p attribs="{'xml:space': 'preserve'}" id="_06142" smilref="Title.smil#_06142"> Analysis of binary search The recursive implementation of rank() also leads to an immediate argument that binary search guarantees fast search, because it corresponds to a recurrence relation that describes an upper bound on the number of compares.</p><p attribs="{'xml:space': 'preserve'}" id="_06143" smilref="Title.smil#_06143"> Proposition B. Binary search in an ordered array with N keys uses no more than lg N &#11001; 1 compares for a search (successful or unsuccessful).</p><p attribs="{'xml:space': 'preserve'}" id="_06144" smilref="Title.smil#_06144"> Proof : This analysis is similar to (but simpler than) the analysis of mergesort (Proposition F in Chapter 2). Let C(N) be the number of compares needed to search for a key in a symbol table of size N. We have C(0) = 0, C(1) = 1, and for N &gt; 0 we can write a recurrence relationship that directly mirrors the recursive method: C(N ) &#11349; C(&#9123;N/2&#9126;) Whether the search goes to the left or to the right, the size of the subarray is no more than &#9123;N/2&#9126;, and we use one compare to check for equality and to choose whether to go left or right. When N is one less than a power of 2 (say N = 2n&#11002;1), this recurrence is not difficult to solve. First, since &#9123;N/2&#9126; = 2n&#11002;1&#11002;1, we have C(2n &#11002;1) &#11349; C(2n&#11002;1&#11002;1) &#11001; 1</p><p attribs="{'xml:space': 'preserve'}" id="_06145" smilref="Title.smil#_06145"> &#11001; 1</p><p attribs="{'xml:space': 'preserve'}" id="_06146" smilref="Title.smil#_06146"> Applying the same equation to the first term on the right, we have C(2n &#11002;1) &#11349; C(2n&#11002;2&#11002;1) &#11001; 1 &#11001; 1 Repeating the previous step n &#11002; 2 additional times gives C(2n &#11002;1) &#11349; C(20) &#11001; n</p><p attribs="{'xml:space': 'preserve'}" id="_06147" smilref="Title.smil#_06147"> which leaves us with the solution C(N ) = C(2n ) &#11349; n &#11001; 1 &lt; lg N &#11001; 1 Exact solutions for general N are more complicated, but it is not difficult to extend this argument to establish the stated property for all values of N (see Exercise 3.1.20). With binary search, we achieve a logarithmic-time search guarantee.</p><p attribs="{'xml:space': 'preserve'}" id="_06148" smilref="Title.smil#_06148"> The implementation just given for ceiling() is based on a single call to rank(), and the default two-argument size() implementation calls rank() twice, so this proof also establishes that these operations (and floor()) are supported in guaranteed logarithmic time (min(), max(), and select() are constant-time operations).</p><p attribs="{'xml:space': 'preserve'}" id="_06149" smilref="Title.smil#_06149" /><pagenum id="p397" page="normal" smilref="Title.smil#p397" /><p attribs="{'xml:space': 'preserve'}" id="_06150" smilref="Title.smil#_06150"> 384</p><p attribs="{'xml:space': 'preserve'}" id="_06151" smilref="Title.smil#_06151"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06152" smilref="Title.smil#_06152"> method</p><p attribs="{'xml:space': 'preserve'}" id="_06153" smilref="Title.smil#_06153"> put()</p><p attribs="{'xml:space': 'preserve'}" id="_06154" smilref="Title.smil#_06154"> get()</p><p attribs="{'xml:space': 'preserve'}" id="_06155" smilref="Title.smil#_06155"> delete()</p><p attribs="{'xml:space': 'preserve'}" id="_06156" smilref="Title.smil#_06156"> contains()</p><p attribs="{'xml:space': 'preserve'}" id="_06157" smilref="Title.smil#_06157"> size()</p><p attribs="{'xml:space': 'preserve'}" id="_06158" smilref="Title.smil#_06158"> min()</p><p attribs="{'xml:space': 'preserve'}" id="_06159" smilref="Title.smil#_06159"> max()</p><p attribs="{'xml:space': 'preserve'}" id="_06160" smilref="Title.smil#_06160"> floor()</p><p attribs="{'xml:space': 'preserve'}" id="_06161" smilref="Title.smil#_06161"> ceiling()</p><p attribs="{'xml:space': 'preserve'}" id="_06162" smilref="Title.smil#_06162"> rank()</p><p attribs="{'xml:space': 'preserve'}" id="_06163" smilref="Title.smil#_06163"> select()</p><p attribs="{'xml:space': 'preserve'}" id="_06164" smilref="Title.smil#_06164"> deleteMin()</p><p attribs="{'xml:space': 'preserve'}" id="_06165" smilref="Title.smil#_06165"> order of growth of running time</p><p attribs="{'xml:space': 'preserve'}" id="_06166" smilref="Title.smil#_06166"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06167" smilref="Title.smil#_06167"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_06168" smilref="Title.smil#_06168"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06169" smilref="Title.smil#_06169"> log N 1</p><p attribs="{'xml:space': 'preserve'}" id="_06170" smilref="Title.smil#_06170"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06171" smilref="Title.smil#_06171"> 1 log N log N log N 1</p><p attribs="{'xml:space': 'preserve'}" id="_06172" smilref="Title.smil#_06172"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06173" smilref="Title.smil#_06173"> Despite its guaranteed logarithmic search, BinarySearchST still does not enable us to use clients like FrequencyCounter to solve huge problems, because the put() method is too slow. Bi- nary search reduces the number of compares, but not the running time, because its use does not change the fact that the number of array accesses required to build a symbol table in an ordered array is quadratic in the size of the array when keys are randomly ordered (and in typical practical situations where the keys, while not random, are well-described by this model).</p><p attribs="{'xml:space': 'preserve'}" id="_06174" smilref="Title.smil#_06174"> Proposition B (continued). Inserting a new key into an ordered array of size N uses ~ 2N array accesses in the worst case, so inserting N keys into an initially empty table uses ~ N 2 array accesses in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_06175" smilref="Title.smil#_06175"> Proof : Same as for Proposition A.</p><p attribs="{'xml:space': 'preserve'}" id="_06176" smilref="Title.smil#_06176"> deleteMax()</p><p attribs="{'xml:space': 'preserve'}" id="_06177" smilref="Title.smil#_06177"> BinarySearchST costs</p><p attribs="{'xml:space': 'preserve'}" id="_06178" smilref="Title.smil#_06178"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06179" smilref="Title.smil#_06179"> For Tale of Two Cities, with over 10 4 distinct keys, the cost to build the table is nearly 10 8 array accesses, and for the Leipzig project, with over 106 distinct keys, the cost to build the table is over 10 11 array accesses. While not quite prohibitive on modern computers, these costs are extremely (and unnecessarily) high. Returning to the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a reduction in the average cost from 2,246 compares (plus array accesses) per operation for SequentialSearchST to 484 for BinarySearchST. As before, this cost is even better than would be predicted by analysis, and the extra improvement is likely again explained by properties of the application (see Exercise 3.1.36). This improvement is impressive, but we can do much better, as you shall see.</p><p attribs="{'xml:space': 'preserve'}" id="_06180" smilref="Title.smil#_06180"> 5737</p><p attribs="{'xml:space': 'preserve'}" id="_06181" smilref="Title.smil#_06181"> t s</p><p attribs="{'xml:space': 'preserve'}" id="_06182" smilref="Title.smil#_06182"> o</p><p attribs="{'xml:space': 'preserve'}" id="_06183" smilref="Title.smil#_06183"> c</p><p attribs="{'xml:space': 'preserve'}" id="_06184" smilref="Title.smil#_06184"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06185" smilref="Title.smil#_06185"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06186" smilref="Title.smil#_06186"> operations Costs for java FrequencyCounter 8 &lt; tale.txt using BinarySearchST</p><p attribs="{'xml:space': 'preserve'}" id="_06187" smilref="Title.smil#_06187"> 14350</p><p attribs="{'xml:space': 'preserve'}" id="_06188" smilref="Title.smil#_06188"> 484</p><p attribs="{'xml:space': 'preserve'}" id="_06189" smilref="Title.smil#_06189" /><pagenum id="p398" page="normal" smilref="Title.smil#p398" /><p attribs="{'xml:space': 'preserve'}" id="_06190" smilref="Title.smil#_06190"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06191" smilref="Title.smil#_06191"> 385</p><p attribs="{'xml:space': 'preserve'}" id="_06192" smilref="Title.smil#_06192"> Preview Binary search is typically far better than sequential search and is the method of choice in numerous practical applications. For a static table (with no insert operations allowed), it is worthwhile to initialize and sort the table, as in the version of binary search that we considered in Chapter 1 (see page 99). Even when the bulk of the key-value pairs is known before the bulk of the searches (a common situation in applications), it is worthwhile to add to BinarySearchST a constructor that initializes and sorts the table (see Exercise 3.1.12). Still, binary search is infeasible for use in many other applications. For example, it fails for our Leipzig Corpora application because searches and inserts are intermixed and the table size is too large. As we have emphasized, typical modern search clients require symbol tables that can support fast implementations of both search and insert. That is, we need to be able to build huge tables where we can insert (and perhaps remove) key-value pairs in unpredictable pat- terns, intermixed with searches. The table below summarizes performance characteristics for the elementary sym- bol-table implementations considered in this section. The table entries give the leading term of the cost (number of array accesses for binary search, number of compares for the others), which implies the order of growth of the running time.</p><p attribs="{'xml:space': 'preserve'}" id="_06193" smilref="Title.smil#_06193"> algorithm (data structure)</p><p attribs="{'xml:space': 'preserve'}" id="_06194" smilref="Title.smil#_06194"> sequential search (unordered linked list) binary search (ordered array)</p><p attribs="{'xml:space': 'preserve'}" id="_06195" smilref="Title.smil#_06195"> worst-case cost (after N inserts) search insert</p><p attribs="{'xml:space': 'preserve'}" id="_06196" smilref="Title.smil#_06196"> average-case cost (after N random inserts) search hit insert</p><p attribs="{'xml:space': 'preserve'}" id="_06197" smilref="Title.smil#_06197"> efficiently support ordered operations?</p><p attribs="{'xml:space': 'preserve'}" id="_06198" smilref="Title.smil#_06198"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06199" smilref="Title.smil#_06199"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_06200" smilref="Title.smil#_06200"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06201" smilref="Title.smil#_06201"> 2N</p><p attribs="{'xml:space': 'preserve'}" id="_06202" smilref="Title.smil#_06202"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_06203" smilref="Title.smil#_06203"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_06204" smilref="Title.smil#_06204"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06205" smilref="Title.smil#_06205"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06206" smilref="Title.smil#_06206"> no</p><p attribs="{'xml:space': 'preserve'}" id="_06207" smilref="Title.smil#_06207"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_06208" smilref="Title.smil#_06208"> Cost summary for basic symbol-table implementations</p><p attribs="{'xml:space': 'preserve'}" id="_06209" smilref="Title.smil#_06209"> The central question is whether we can devise algorithms and data structures that achieve logarithmic performance for both search and insert. The answer is a resounding yes! Providing that answer is the main thrust of this chapter. Along with the fast sort capability discussed in Chapter 2, fast symbol-table search/insert is one of the most important contributions of algorithmics and one of the most important steps toward the development of the rich computational infrastructure that we now enjoy. How can we achieve this goal? To support efficient insertion, it seems that we need a linked structure. But a singly linked list forecloses the use of binary search, because the efficiency of binary search depends on our ability to get to the middle of any subarray</p><p attribs="{'xml:space': 'preserve'}" id="_06210" smilref="Title.smil#_06210" /><pagenum id="p399" page="normal" smilref="Title.smil#p399" /><p attribs="{'xml:space': 'preserve'}" id="_06211" smilref="Title.smil#_06211"> 386</p><p attribs="{'xml:space': 'preserve'}" id="_06212" smilref="Title.smil#_06212"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06213" smilref="Title.smil#_06213"> quickly via indexing (and the only way to get to the middle of a singly linked list is to follow links). To combine the efficiency of binary search with the flexibility of linked structures, we need more complicated data structures. That combination is provided both by binary search trees, the subject of the next two sections, and by hash tables, the subject of Section 3.4. We consider six symbol-table implementations in this chapter, so a brief preview is in order. The table below is a list of the data structures, along with the primary reasons in favor of and against using each for an application. They appear in the order in which we consider them. We will get into more detail on properties of the algorithms and implementations as we discuss them, but the brief characterizations in this table will help you keep them in a broader context as you learn them. The bottom line is that we have several fast symbol-table implementations that can be and are used to great effect in countless applications.</p><p attribs="{'xml:space': 'preserve'}" id="_06214" smilref="Title.smil#_06214"> underlying data structure</p><p attribs="{'xml:space': 'preserve'}" id="_06215" smilref="Title.smil#_06215"> linked list (sequential search)</p><p attribs="{'xml:space': 'preserve'}" id="_06216" smilref="Title.smil#_06216"> ordered array (binary search)</p><p attribs="{'xml:space': 'preserve'}" id="_06217" smilref="Title.smil#_06217"> binary search tree</p><p attribs="{'xml:space': 'preserve'}" id="_06218" smilref="Title.smil#_06218"> balanced BST</p><p attribs="{'xml:space': 'preserve'}" id="_06219" smilref="Title.smil#_06219"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_06220" smilref="Title.smil#_06220"> pros</p><p attribs="{'xml:space': 'preserve'}" id="_06221" smilref="Title.smil#_06221"> cons</p><p attribs="{'xml:space': 'preserve'}" id="_06222" smilref="Title.smil#_06222"> SequentialSearchST</p><p attribs="{'xml:space': 'preserve'}" id="_06223" smilref="Title.smil#_06223"> best for tiny STs</p><p attribs="{'xml:space': 'preserve'}" id="_06224" smilref="Title.smil#_06224"> slow for large STs</p><p attribs="{'xml:space': 'preserve'}" id="_06225" smilref="Title.smil#_06225"> BinarySearchST</p><p attribs="{'xml:space': 'preserve'}" id="_06226" smilref="Title.smil#_06226"> BST</p><p attribs="{'xml:space': 'preserve'}" id="_06227" smilref="Title.smil#_06227"> RedBlackBST</p><p attribs="{'xml:space': 'preserve'}" id="_06228" smilref="Title.smil#_06228"> optimal search and space, order-based ops</p><p attribs="{'xml:space': 'preserve'}" id="_06229" smilref="Title.smil#_06229"> easy to implement, order-based ops</p><p attribs="{'xml:space': 'preserve'}" id="_06230" smilref="Title.smil#_06230"> optimal search and insert, order-based ops</p><p attribs="{'xml:space': 'preserve'}" id="_06231" smilref="Title.smil#_06231"> slow insert</p><p attribs="{'xml:space': 'preserve'}" id="_06232" smilref="Title.smil#_06232"> no guarantees space for links</p><p attribs="{'xml:space': 'preserve'}" id="_06233" smilref="Title.smil#_06233"> space for links</p><p attribs="{'xml:space': 'preserve'}" id="_06234" smilref="Title.smil#_06234"> hash table</p><p attribs="{'xml:space': 'preserve'}" id="_06235" smilref="Title.smil#_06235"> SeparateChainingHashST LinearProbingHashST</p><p attribs="{'xml:space': 'preserve'}" id="_06236" smilref="Title.smil#_06236"> fast search/insert for common types of data</p><p attribs="{'xml:space': 'preserve'}" id="_06237" smilref="Title.smil#_06237"> need hash for each type no order-based ops space for links/empty</p><p attribs="{'xml:space': 'preserve'}" id="_06238" smilref="Title.smil#_06238"> Pros and cons of symbol-table implementations</p><p attribs="{'xml:space': 'preserve'}" id="_06239" smilref="Title.smil#_06239" /><pagenum id="p400" page="normal" smilref="Title.smil#p400" /><p attribs="{'xml:space': 'preserve'}" id="_06240" smilref="Title.smil#_06240"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06241" smilref="Title.smil#_06241"> 387</p><p attribs="{'xml:space': 'preserve'}" id="_06242" smilref="Title.smil#_06242"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_06243" smilref="Title.smil#_06243"> Q. Why not use an Item type that implements Comparable for symbol tables, in the same way as we did for priority queues in Section 2.4, instead of having separate keys and values ? A. That is also a reasonable option. These two approaches illustrate two different ways to associate information with keys&#8212;we can do so implicitly by building a data type that includes the key or explicitly by separating keys from values. For symbol tables, we have chosen to highlight the associative array abstraction. Note also that a client specifies just a key in search, not a key-value aggregation. Q. Why bother with equals() ? Why not just use compareTo() throughout? A. Not all data types lead to key values that are easy to compare, even though having a symbol table still might make sense. To take an extreme example, you may wish to use pictures or songs as keys. There is no natural way to compare them, but we can certainly test equality (with some work). Q. Why not allow keys to take the value null? A. We assume that Key is an Object because we use it to invoke compareTo() or equals(). But a call like a.compareTo(b) would cause a null pointer exception if a is null. By ruling out this possibility, we allow for simpler client code. Q. Why not use a method like the less() method that we used for sorting? A. Equality plays a special role in symbol tables, so we also would need a method for testing equality. To avoid proliferation of methods that have essentially the same func- tion, we adopt the built-in Java methods equals() and compareTo(). Q. Why not declare key[] as Object[] (instead of Comparable[]) in BinarySearchST before casting, in the same way that val[] is declared as Object? A. Good question. If you do so, you will get a ClassCastException because keys need to be Comparable (to ensure that entries in key[] have a compareTo() method). Thus, declaring key[] as Comparable[] is required. Delving into the details of program- ming-language design to explain the reasons would take us somewhat off topic. We use precisely this idiom (and nothing more complicated) in any code that uses Comparable generics and arrays throughout this book.</p><p attribs="{'xml:space': 'preserve'}" id="_06244" smilref="Title.smil#_06244" /><pagenum id="p401" page="normal" smilref="Title.smil#p401" /><p attribs="{'xml:space': 'preserve'}" id="_06245" smilref="Title.smil#_06245"> 388</p><p attribs="{'xml:space': 'preserve'}" id="_06246" smilref="Title.smil#_06246"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06247" smilref="Title.smil#_06247"> Q&amp;A (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06248" smilref="Title.smil#_06248"> Q. What if we need to associate multiple values with the same key? For example, if we use Date as a key in an application, wouldn&#8217;t we have to process equal keys? A. Maybe, maybe not. For example, you can&#8217;t have two trains arrive at the station on the same track at the same time (but they could arrive on different tracks at the same time). There are two ways to handle the situation: use some other information to disambiguate or make the value a Queue of values having the same key. We consider applications in detail in Section 3.5. Q. Presorting the table as discussed on page 385 seems like a good idea. Why relegate that to an exercise (see Exercise 3.1.12)? A. Indeed, this may be the method of choice in some applications. But adding a slow insert method to a data structure designed for fast search &#8220;for convenience&#8221; is a performance trap, because an unsuspecting client might intermix searches and inserts in a huge table and experience quadratic performance. Such traps are all too common, so that &#8220;buyer beware&#8221; is certainly appropriate when using software developed by oth- ers, particularly when interfaces are too wide. This problem becomes acute when a large number of methods are included &#8220;for convenience&#8221; leaving performance traps throughout, while a client might expect efficient implementations of all methods. Java&#8217;s ArrayList class is an example (see Exercise 3.5.27).</p><p attribs="{'xml:space': 'preserve'}" id="_06249" smilref="Title.smil#_06249" /><pagenum id="p402" page="normal" smilref="Title.smil#p402" /><p attribs="{'xml:space': 'preserve'}" id="_06250" smilref="Title.smil#_06250"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06251" smilref="Title.smil#_06251"> 389</p><p attribs="{'xml:space': 'preserve'}" id="_06252" smilref="Title.smil#_06252"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_06253" smilref="Title.smil#_06253"> 3.1.1 Write a client that creates a symbol table mapping letter grades to numerical scores, as in the table below, then reads from standard input a list of letter grades and computes and prints the GPA (the average of the numbers corresponding to the grades).</p><p attribs="{'xml:space': 'preserve'}" id="_06254" smilref="Title.smil#_06254"> A+</p><p attribs="{'xml:space': 'preserve'}" id="_06255" smilref="Title.smil#_06255"> 4.33</p><p attribs="{'xml:space': 'preserve'}" id="_06256" smilref="Title.smil#_06256"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06257" smilref="Title.smil#_06257"> 4.00</p><p attribs="{'xml:space': 'preserve'}" id="_06258" smilref="Title.smil#_06258"> A-</p><p attribs="{'xml:space': 'preserve'}" id="_06259" smilref="Title.smil#_06259"> 3.67</p><p attribs="{'xml:space': 'preserve'}" id="_06260" smilref="Title.smil#_06260"> B+</p><p attribs="{'xml:space': 'preserve'}" id="_06261" smilref="Title.smil#_06261"> 3.33</p><p attribs="{'xml:space': 'preserve'}" id="_06262" smilref="Title.smil#_06262"> B</p><p attribs="{'xml:space': 'preserve'}" id="_06263" smilref="Title.smil#_06263"> 3.00</p><p attribs="{'xml:space': 'preserve'}" id="_06264" smilref="Title.smil#_06264"> B-</p><p attribs="{'xml:space': 'preserve'}" id="_06265" smilref="Title.smil#_06265"> 2.67</p><p attribs="{'xml:space': 'preserve'}" id="_06266" smilref="Title.smil#_06266"> C+</p><p attribs="{'xml:space': 'preserve'}" id="_06267" smilref="Title.smil#_06267"> 2.33</p><p attribs="{'xml:space': 'preserve'}" id="_06268" smilref="Title.smil#_06268"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06269" smilref="Title.smil#_06269"> 2.00</p><p attribs="{'xml:space': 'preserve'}" id="_06270" smilref="Title.smil#_06270"> C-</p><p attribs="{'xml:space': 'preserve'}" id="_06271" smilref="Title.smil#_06271"> 1.67</p><p attribs="{'xml:space': 'preserve'}" id="_06272" smilref="Title.smil#_06272"> D</p><p attribs="{'xml:space': 'preserve'}" id="_06273" smilref="Title.smil#_06273"> 1.00</p><p attribs="{'xml:space': 'preserve'}" id="_06274" smilref="Title.smil#_06274"> F</p><p attribs="{'xml:space': 'preserve'}" id="_06275" smilref="Title.smil#_06275"> 0.00</p><p attribs="{'xml:space': 'preserve'}" id="_06276" smilref="Title.smil#_06276"> 3.1.2 Develop a symbol-table implementation ArrayST that uses an (unordered) array as the underlying data structure to implement our basic symbol-table API. 3.1.3 Develop a symbol-table implementation OrderedSequentialSearchST that uses an ordered linked list as the underlying data structure to implement our ordered symbol-table API. 3.1.4 Develop Time and Event ADTs that allow processing of data as in the example illustrated on page 367.</p><p attribs="{'xml:space': 'preserve'}" id="_06277" smilref="Title.smil#_06277"> 3.1.5 Implement size(), delete(), and keys() for SequentialSearchST.</p><p attribs="{'xml:space': 'preserve'}" id="_06278" smilref="Title.smil#_06278"> 3.1.6 Give the number of calls to put() and get() issued by FrequencyCounter, as a function of the number W of words and the number D of distinct words in the input. 3.1.7 What is the average number of distinct keys that FrequencyCounter will find among N random nonnegative integers less than 1,000, for N=10, 102, 103, 104, 105, and 106? 3.1.8 What is the most frequently used word of ten letters or more in Tale of Two Cities? 3.1.9 Add code to FrequencyCounter to keep track of the last call to put(). Print the last word inserted and the number of words that were processed in the input stream prior to this insertion. Run your program for tale.txt with length cutoffs 1, 8, and 10. 3.1.10 Give a trace of the process of inserting the keys E A S Y Q U E S T I O N into an initially empty table using SequentialSearchST. How many compares are involved? 3.1.11 Give a trace of the process of inserting the keys E A S Y Q U E S T I O N into an initially empty table using BinarySearchST. How many compares are involved? 3.1.12 Modify BinarySearchST to maintain one array of Item objects that contain keys and values, rather than two parallel arrays. Add a constructor that takes an array of</p><p attribs="{'xml:space': 'preserve'}" id="_06279" smilref="Title.smil#_06279" /><pagenum id="p403" page="normal" smilref="Title.smil#p403" /><p attribs="{'xml:space': 'preserve'}" id="_06280" smilref="Title.smil#_06280"> 390</p><p attribs="{'xml:space': 'preserve'}" id="_06281" smilref="Title.smil#_06281"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06282" smilref="Title.smil#_06282"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06283" smilref="Title.smil#_06283"> Item values as argument and uses mergesort to sort the array. 3.1.13 Which of the symbol-table implementations in this section would you use for an application that does 10 3 put() operations and 10 6 get() operations, randomly intermixed? Justify your answer. 3.1.14 Which of the symbol-table implementations in this section would you use for an application that does 10 6 put() operations and 10 3 get() operations, randomly intermixed? Justify your answer. 3.1.15 Assume that searches are 1,000 times more frequent than insertions for a BinarySearchST client. Estimate the percentage of the total time that is devoted to insertions, when the number of searches is 103, 10 6, and 10 9. 3.1.16 Implement the delete() method for BinarySearchST. 3.1.17 Implement the floor() method for BinarySearchST. 3.1.18 Prove that the rank() method in BinarySearchST is correct. 3.1.19 Modify FrequencyCounter to print all of the values having the highest frequency of occurrence, not just one of them. Hint : Use a Queue. 3.1.20 Complete the proof of Proposition B (show that it holds for all values of N). Hint : Start by showing that C(N) is monotonic: C(N) &#11349; C(N+1) for all N &gt; 0.</p><p attribs="{'xml:space': 'preserve'}" id="_06284" smilref="Title.smil#_06284" /><pagenum id="p404" page="normal" smilref="Title.smil#p404" /><p attribs="{'xml:space': 'preserve'}" id="_06285" smilref="Title.smil#_06285"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06286" smilref="Title.smil#_06286"> 391</p><p attribs="{'xml:space': 'preserve'}" id="_06287" smilref="Title.smil#_06287"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_06288" smilref="Title.smil#_06288"> 3.1.21 Memory usage. Compare the memory usage of BinarySearchST with that of SequentialSearchST for N key-value pairs, under the assumptions described in Sec- tion 1.4. Do not count the memory for the keys and values themselves, but do count references to them. For BinarySearchST, assume that array resizing is used, so that the array is between 25 percent and 100 percent full. 3.1.22 Self-organizing search. A self-organizing search algorithm is one that rearranges items to make those that are accessed frequently likely to be found early in the search. Modify your search implementation for Exercise 3.1.2 to perform the following action on every search hit: move the key-value pair found to the beginning of the list, moving all pairs between the beginning of the list and the vacated position to the right one posi- tion. This procedure is called the move-to-front heuristic. 3.1.23 Analysis of binary search. Prove that the maximum number of compares used for a binary search in a table of size N is precisely the number of bits in the binary representation of N, because the operation of shifting 1 bit to the right converts the binary representation of N into the binary representation of &#9123;N/2&#9126;. 3.1.24 Interpolation search. Suppose that arithmetic operations are allowed on keys (for example, they may be Double or Integer values). Write a version of binary search that mimics the process of looking near the beginning of a dictionary when the word begins with a letter near the beginning of the alphabet. Speci&#64257; cally, if kx is the key value sought, klo is the key value of the first key in the table, and khi is the key value of the last key in the table, look first &#9123;(kx &#11002; klo)/(khi &#11002; klo)&#9126;-way through the table, not half- way. Test your implementation against BinarySearchST for FrequencyCounter using</p><p attribs="{'xml:space': 'preserve'}" id="_06289" smilref="Title.smil#_06289"> SearchCompare.</p><p attribs="{'xml:space': 'preserve'}" id="_06290" smilref="Title.smil#_06290"> 3.1.25 Software caching. Since the default implementation of contains() calls get(), the inner loop of FrequencyCounter</p><p attribs="{'xml:space': 'preserve'}" id="_06291" smilref="Title.smil#_06291"> if (!st.contains(word)) st.put(word, 1); else st.put(word, st.get(word) + 1);</p><p attribs="{'xml:space': 'preserve'}" id="_06292" smilref="Title.smil#_06292"> leads to two or three searches for the same key. To enable clear client code like this without sacrificing ef&#64257; ciency, we can use a technique known as software caching, where we save the location of the most recently accessed key in an instance variable. Modify SequentialSearchST and BinarySearchST to take advantage of this idea.</p><p attribs="{'xml:space': 'preserve'}" id="_06293" smilref="Title.smil#_06293" /><pagenum id="p405" page="normal" smilref="Title.smil#p405" /><p attribs="{'xml:space': 'preserve'}" id="_06294" smilref="Title.smil#_06294"> 392</p><p attribs="{'xml:space': 'preserve'}" id="_06295" smilref="Title.smil#_06295"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06296" smilref="Title.smil#_06296"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06297" smilref="Title.smil#_06297"> 3.1.26 Frequency count from a dictionary. Modify FrequencyCounter to take the name of a dictionary file as its argument, count frequencies of the words from standard input that are also in that fi le, and print two tables of the words with their frequencies, one sorted by frequency, the other sorted in the order found in the dictionary fi le. 3.1.27 Small tables. Suppose that a BinarySearchST client has S search operations and N distinct keys. Give the order of growth of S such that the cost of building the table is the same as the cost of all the searches. 3.1.28 Ordered insertions. Modify BinarySearchST so that inserting a key that is larger than all keys in the table takes constant time (so that building a table by calling put() for keys that are in order takes linear time). 3.1.29 Test client. Write a test client for BinarySearchST that tests the implemen-</p><p attribs="{'xml:space': 'preserve'}" id="_06298" smilref="Title.smil#_06298"> tations of min(), max(), floor(), ceiling(), select(), rank(), deleteMin(),</p><p attribs="{'xml:space': 'preserve'}" id="_06299" smilref="Title.smil#_06299"> deleteMax(), and keys() that are given in the text. Start with the standard indexing client given on page 370. Add code to take additional command-line arguments, as appropriate. 3.1.30 Certi&#64257; cation. Add assert statements to BinarySearchST to check algorithm invariants and data structure integrity after every insertion and deletion. For example, every index i should always be equal to rank(select(i)) and the array should always be in order.</p><p attribs="{'xml:space': 'preserve'}" id="_06300" smilref="Title.smil#_06300" /><pagenum id="p406" page="normal" smilref="Title.smil#p406" /><p attribs="{'xml:space': 'preserve'}" id="_06301" smilref="Title.smil#_06301"> 3.1 </p><p attribs="{'xml:space': 'preserve'}" id="_06302" smilref="Title.smil#_06302"> 393</p><p attribs="{'xml:space': 'preserve'}" id="_06303" smilref="Title.smil#_06303"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_06304" smilref="Title.smil#_06304"> 3.1.31 Performance driver. Write a performance driver program that uses put() to fill a symbol table, then uses get() such that each key in the table is hit an average of ten times and there is about the same number of misses, doing so multiple times on random sequences of string keys of various lengths ranging from 2 to 50 characters; measures the time taken for each run; and prints out or plots the average running times. 3.1.32 Exercise driver. Write an exercise driver program that uses the methods in our ordered symbol-table API on difficult or pathological cases that might turn up in practical applications. Simple examples include key sequences that are already in order, key sequences in reverse order, key sequences where all keys are the same, and keys consisting of only two distinct values. 3.1.33 Driver for self-organizing search. Write a driver program for self-organizing search implementations (see Exercise 3.1.22) that uses get() to fill a symbol table with N keys, then does 10 N successful searches according to a predefined probability distribution. Use this driver to compare the running time of your implementation from Exercise 3.1.22 with BinarySearchST for N = 103, 104, 105, and 106 using the probability distribution where search hits the i th smallest key with probability 1/2 i . 3.1.34 Zipf &#8217;s law. Do the previous exercise for the probability distribution where search hits the i th smallest key with probability 1/(i HN) where HN is a Harmonic number (see page 185). This distribution is called Zipf &#8217;s law. Compare the move-to-front heuristic with the optimal arrangement for the distributions in the previous exercise, which is to keep the keys in increasing order (decreasing order of their expected frequency). 3.1.35 Performance validation I. Run doubling tests that use the first N words of Tale of Two Cities for various values of N to test the hypothesis that the running time of FrequencyCounter is quadratic when it uses SequentialSearchST for its symbol table. 3.1.36 Performance validation II. Explain why the performance of BinarySearchST and SequentialSearchST for FrequencyCounter is even better than predicted by analysis. 3.1.37 Put/get ratio. Determine empirically the ratio of the amount of time that BinarySearchST spends on put() operations to the time that it spends on get() operations when FrequencyCounter is used to find the frequency of occurrence of values</p><p attribs="{'xml:space': 'preserve'}" id="_06305" smilref="Title.smil#_06305" /><pagenum id="p407" page="normal" smilref="Title.smil#p407" /><p attribs="{'xml:space': 'preserve'}" id="_06306" smilref="Title.smil#_06306"> 394</p><p attribs="{'xml:space': 'preserve'}" id="_06307" smilref="Title.smil#_06307"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06308" smilref="Title.smil#_06308"> EXPERIMENTS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06309" smilref="Title.smil#_06309"> in 1 million random M-bit int values, for M = 10, 20, and 30. Answer the same question for tale.txt and compare the results. 3.1.38 Amortized cost plots. Develop instrumentation for FrequencyCounter, SequentialSearchST, and BinarySearchST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation. 3.1.39 Actual timings. Instrument FrequencyCounter to use Stopwatch and StdDraw to make a plot where the x-axis is the number of calls on get() or put() and the y-axis is the total running time, with a point plotted of the cumulative time after each call. Run your program for Tale of Two Cities using SequentialSearchST and again using BinarySearchST and discuss the results. Note : Sharp jumps in the curve may be explained by caching, which is beyond the scope of this question. 3.1.40 Crossover to binary search. Find the values of N for which binary search in a symbol table of size N becomes 10, 100, and 1,000 times faster than sequential search. Predict the values with analysis and verify them experimentally. 3.1.41 Crossover to interpolation search. Find the values of N for which interpolation search in a symbol table of size N becomes 1, 2, and 10 times faster than binary search, assuming the keys to be random 32-bit integers (see Exercise 3.1.24). Predict the values with analysis, and verify them experimentally.</p><p attribs="{'xml:space': 'preserve'}" id="_06310" smilref="Title.smil#_06310" /><pagenum id="p408" page="normal" smilref="Title.smil#p408" /><p attribs="{'xml:space': 'preserve'}" id="_06311" smilref="Title.smil#_06311"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_06312" smilref="Title.smil#_06312" /></level3><level3 id="_00051"><h3 id="ch3-s2-ss5" smilref="Title.smil#ch3-s2-ss5" xml:space="preserve">Basic implementation</h3><pagenum id="p410" page="normal" smilref="Title.smil#p410" /><p attribs="{'xml:space': 'preserve'}" id="_06313" smilref="Title.smil#_06313"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06314" smilref="Title.smil#_06314"> 397</p><p attribs="{'xml:space': 'preserve'}" id="_06315" smilref="Title.smil#_06315"> Basic implementation Algorithm 3.3 defines the BST data structure that we use throughout this section to implement the ordered symbol-table API. We begin by considering this classic data structure definition and the characteristic associated implementations of the get() (search) and put() (insert) methods.</p><p attribs="{'xml:space': 'preserve'}" id="_06316" smilref="Title.smil#_06316"> Representation. We define a private nested class to define nodes in BSTs, just as we did for linked lists. Each node contains a key, a value, a left link, a right link, and a node count (when relevant, we include node counts in red above the node in our drawings). The left link points to a BST for items with smaller keys, and the right link points to a BST for items with larger keys. The instance variable N gives the node count in the subtree rooted at the node. This field facilitates the implementation of various ordered symbol-table operations, as you will see. The private size() method in Algorithm 3.3 is implemented to assign the value 0 to null links, so that we can maintain this field by making sure that the invariant</p><p attribs="{'xml:space': 'preserve'}" id="_06317" smilref="Title.smil#_06317"> node count N</p><p attribs="{'xml:space': 'preserve'}" id="_06318" smilref="Title.smil#_06318"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06319" smilref="Title.smil#_06319"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06320" smilref="Title.smil#_06320"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06321" smilref="Title.smil#_06321"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_06322" smilref="Title.smil#_06322"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06323" smilref="Title.smil#_06323"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06324" smilref="Title.smil#_06324"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06325" smilref="Title.smil#_06325"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_06326" smilref="Title.smil#_06326"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06327" smilref="Title.smil#_06327"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06328" smilref="Title.smil#_06328"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06329" smilref="Title.smil#_06329"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_06330" smilref="Title.smil#_06330"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06331" smilref="Title.smil#_06331"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06332" smilref="Title.smil#_06332"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06333" smilref="Title.smil#_06333"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06334" smilref="Title.smil#_06334"> A C E H M R S X</p><p attribs="{'xml:space': 'preserve'}" id="_06335" smilref="Title.smil#_06335"> size(x) = size(x.left) + size(x.right) + 1</p><p attribs="{'xml:space': 'preserve'}" id="_06336" smilref="Title.smil#_06336"> holds for every node x in the tree. A BST represents a set of keys (and associated values), and there are many different BSTs that represent the same set. If we project the keys in a BST such that all keys in each node&#8217;s left subtree appear to the left of the key in the node and all keys in each node&#8217;s right subtree appear to the right of the key in the node, then we always get the keys in sorted order. We take advantage of the flexibility inherent in having many BSTs represent this sorted order to develop efficient algorithms for building and using BSTs.</p><p attribs="{'xml:space': 'preserve'}" id="_06337" smilref="Title.smil#_06337"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_06338" smilref="Title.smil#_06338"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06339" smilref="Title.smil#_06339"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06340" smilref="Title.smil#_06340"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06341" smilref="Title.smil#_06341"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06342" smilref="Title.smil#_06342"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06343" smilref="Title.smil#_06343"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_06344" smilref="Title.smil#_06344"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06345" smilref="Title.smil#_06345"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06346" smilref="Title.smil#_06346"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06347" smilref="Title.smil#_06347"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06348" smilref="Title.smil#_06348"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06349" smilref="Title.smil#_06349"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06350" smilref="Title.smil#_06350"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06351" smilref="Title.smil#_06351"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06352" smilref="Title.smil#_06352"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06353" smilref="Title.smil#_06353"> A C E H M R S X</p><p attribs="{'xml:space': 'preserve'}" id="_06354" smilref="Title.smil#_06354"> Two BSTs that represent the same set of keys</p><p attribs="{'xml:space': 'preserve'}" id="_06355" smilref="Title.smil#_06355"> Search. As usual, when we search for a key in a symbol table, we have one of two possible outcomes. If a node containing the key is in the table, we have a search hit, so we return the associated value. Otherwise, we have a search miss (and return null). A recursive algorithm to search for a key in a BST follows immediately from the recursive structure: if the tree is empty, we have a search miss; if the search key is equal to the key at the root, we have a search hit. Otherwise, we search (recursively) in the appropriate subtree, moving left if the search key is smaller, right if it is larger. The recursive get() method on page 399 implements this algorithm directly. It takes a node (root of a subtree) as first argument and a key as second argument, starting with the root of the tree and the search key. The code maintains the invariant that no parts of the tree other than the subtree rooted at the current node can have a node whose key is equal to the search key. Just as the size of the interval in binary search shrinks by about half on each iteration,</p><p attribs="{'xml:space': 'preserve'}" id="_06356" smilref="Title.smil#_06356" /><pagenum id="p411" page="normal" smilref="Title.smil#p411" /><p attribs="{'xml:space': 'preserve'}" id="_06357" smilref="Title.smil#_06357"> 398</p><p attribs="{'xml:space': 'preserve'}" id="_06358" smilref="Title.smil#_06358"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06359" smilref="Title.smil#_06359"> ALGORITHM 3.3 Binary search tree symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_06360" smilref="Title.smil#_06360"> public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; { private Node root; // root of BST</p><p attribs="{'xml:space': 'preserve'}" id="_06361" smilref="Title.smil#_06361"> private class Node { private Key key; // key private Value val; // associated value private Node left, right; // links to subtrees private int N; // # nodes in subtree rooted here</p><p attribs="{'xml:space': 'preserve'}" id="_06362" smilref="Title.smil#_06362"> public Node(Key key, Value val, int N) { this.key = key; this.val = val; this.N = N; } }</p><p attribs="{'xml:space': 'preserve'}" id="_06363" smilref="Title.smil#_06363"> public int size() { return size(root); }</p><p attribs="{'xml:space': 'preserve'}" id="_06364" smilref="Title.smil#_06364"> private int size(Node x) { if (x == null) return 0; else return x.N; }</p><p attribs="{'xml:space': 'preserve'}" id="_06365" smilref="Title.smil#_06365"> public Value get(Key key) // See page 399.</p><p attribs="{'xml:space': 'preserve'}" id="_06366" smilref="Title.smil#_06366"> public void put(Key key, Value val) // See page 399.</p><p attribs="{'xml:space': 'preserve'}" id="_06367" smilref="Title.smil#_06367"> // See page 407 for min(), max(), floor(), and ceiling(). // See page 409 for select() and rank(). // See page 411 for delete(), deleteMin(), and deleteMax(). // See page 413 for keys().</p><p attribs="{'xml:space': 'preserve'}" id="_06368" smilref="Title.smil#_06368"> }</p><p attribs="{'xml:space': 'preserve'}" id="_06369" smilref="Title.smil#_06369"> This implementation of the ordered symbol-table API uses a binary search tree built from Node objects that each contain a key, associated value, two links, and a node count N. Each Node is the root of a subtree containing N nodes, with its left link pointing to a Node that is the root of a subtree with smaller keys and its right link pointing to a Node that is the root of a subtree with larger keys. The instance variable root points to the Node at the root of the BST (which has all the keys and associated values in the symbol table). Implementations of other methods appear throughout this section.</p><p attribs="{'xml:space': 'preserve'}" id="_06370" smilref="Title.smil#_06370" /><pagenum id="p412" page="normal" smilref="Title.smil#p412" /><p attribs="{'xml:space': 'preserve'}" id="_06371" smilref="Title.smil#_06371"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06372" smilref="Title.smil#_06372"> 399</p><p attribs="{'xml:space': 'preserve'}" id="_06373" smilref="Title.smil#_06373"> ALGORITHM 3.3 (continued) Search and insert for BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_06374" smilref="Title.smil#_06374"> public Value get(Key key) { return get(root, key); }</p><p attribs="{'xml:space': 'preserve'}" id="_06375" smilref="Title.smil#_06375"> private Value get(Node x, Key key) { // Return value associated with key in the subtree rooted at x; // return null if key not present in subtree rooted at x. if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return get(x.left, key); else if (cmp &gt; 0) return get(x.right, key); else return x.val; }</p><p attribs="{'xml:space': 'preserve'}" id="_06376" smilref="Title.smil#_06376"> public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. root = put(root, key, val); }</p><p attribs="{'xml:space': 'preserve'}" id="_06377" smilref="Title.smil#_06377"> private Node put(Node x, Key key, Value val) { // Change key&#8217;s value to val if key in subtree rooted at x. // Otherwise, add new node to subtree associating key with val. if (x == null) return new Node(key, val, 1); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else x.val = val; x.N = size(x.left) + size(x.right) + 1; return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_06378" smilref="Title.smil#_06378"> These implementations of get() and put() for the symbol-table API are characteristic recursive BST methods that also serve as models for several other implementations that we consider later in the chapter. Each method can be understood as both working code and a proof by induction of the inductive hypothesis in the opening comment.</p><p attribs="{'xml:space': 'preserve'}" id="_06379" smilref="Title.smil#_06379" /><pagenum id="p413" page="normal" smilref="Title.smil#p413" /><p attribs="{'xml:space': 'preserve'}" id="_06380" smilref="Title.smil#_06380"> 400</p><p attribs="{'xml:space': 'preserve'}" id="_06381" smilref="Title.smil#_06381"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06382" smilref="Title.smil#_06382"> successful search for R</p><p attribs="{'xml:space': 'preserve'}" id="_06383" smilref="Title.smil#_06383"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06384" smilref="Title.smil#_06384"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06385" smilref="Title.smil#_06385"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06386" smilref="Title.smil#_06386"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06387" smilref="Title.smil#_06387"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06388" smilref="Title.smil#_06388"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06389" smilref="Title.smil#_06389"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06390" smilref="Title.smil#_06390"> R is less than S so look to the left</p><p attribs="{'xml:space': 'preserve'}" id="_06391" smilref="Title.smil#_06391"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06392" smilref="Title.smil#_06392"> black nodes could match the search key</p><p attribs="{'xml:space': 'preserve'}" id="_06393" smilref="Title.smil#_06393"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06394" smilref="Title.smil#_06394"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06395" smilref="Title.smil#_06395"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06396" smilref="Title.smil#_06396"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06397" smilref="Title.smil#_06397"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06398" smilref="Title.smil#_06398"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06399" smilref="Title.smil#_06399"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06400" smilref="Title.smil#_06400"> R is greater than E so look to the right</p><p attribs="{'xml:space': 'preserve'}" id="_06401" smilref="Title.smil#_06401"> gray nodes cannot match the search key</p><p attribs="{'xml:space': 'preserve'}" id="_06402" smilref="Title.smil#_06402"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06403" smilref="Title.smil#_06403"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06404" smilref="Title.smil#_06404"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06405" smilref="Title.smil#_06405"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06406" smilref="Title.smil#_06406"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06407" smilref="Title.smil#_06407"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06408" smilref="Title.smil#_06408"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06409" smilref="Title.smil#_06409"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06410" smilref="Title.smil#_06410"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06411" smilref="Title.smil#_06411"> found R (search hit) so return value</p><p attribs="{'xml:space': 'preserve'}" id="_06412" smilref="Title.smil#_06412"> unsuccessful search for T</p><p attribs="{'xml:space': 'preserve'}" id="_06413" smilref="Title.smil#_06413"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06414" smilref="Title.smil#_06414"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06415" smilref="Title.smil#_06415"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06416" smilref="Title.smil#_06416"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06417" smilref="Title.smil#_06417"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06418" smilref="Title.smil#_06418"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06419" smilref="Title.smil#_06419"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06420" smilref="Title.smil#_06420"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06421" smilref="Title.smil#_06421"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06422" smilref="Title.smil#_06422"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06423" smilref="Title.smil#_06423"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06424" smilref="Title.smil#_06424"> T is greater than S so look to the right</p><p attribs="{'xml:space': 'preserve'}" id="_06425" smilref="Title.smil#_06425"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06426" smilref="Title.smil#_06426"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06427" smilref="Title.smil#_06427"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06428" smilref="Title.smil#_06428"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06429" smilref="Title.smil#_06429"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06430" smilref="Title.smil#_06430"> T is less than X so look to the left</p><p attribs="{'xml:space': 'preserve'}" id="_06431" smilref="Title.smil#_06431"> link is null so T is not in tree (search miss)</p><p attribs="{'xml:space': 'preserve'}" id="_06432" smilref="Title.smil#_06432"> Search hit (left) and search miss (right) in a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06433" smilref="Title.smil#_06433"> the size of the subtree rooted at the current node when searching in a BST shrinks when we go down the tree (by about half, ideally, but at least by one). The procedure stops either when a node containing the search key is found (search hit) or when the current subtree becomes empty (search miss). Starting at the top, the search procedure at each node involves a recursive invocation for one of that node&#8217;s children, so the search defines a path through the tree. For a search hit, the path terminates at the node containing the key. For a search miss, the path terminates at a null link. Insert. The search code in Algorithm 3.3 is almost as simple as binary search; that simplicity is an essential feature of BSTs. A more important essential feature of BSTs is that insert is not much more difficult to implement than search. Indeed, a search for a key not in the tree ends at a null link, and all that we need to do is replace that link with a new node containing the key (see the diagram on the next page). The recursive put() method in Algorithm 3.3 accomplishes this task using logic similar to that we used for the recursive search: if the tree is empty, we return a new node containing the key and value; if the search key is less than the key at the root, we set the left link to the result of inserting the key into the left subtree; otherwise, we set the right link to the result of inserting the key into the right subtree.</p><p attribs="{'xml:space': 'preserve'}" id="_06434" smilref="Title.smil#_06434" /><pagenum id="p414" page="normal" smilref="Title.smil#p414" /><p attribs="{'xml:space': 'preserve'}" id="_06435" smilref="Title.smil#_06435"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06436" smilref="Title.smil#_06436"> 401</p><p attribs="{'xml:space': 'preserve'}" id="_06437" smilref="Title.smil#_06437"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06438" smilref="Title.smil#_06438"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06439" smilref="Title.smil#_06439"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_06440" smilref="Title.smil#_06440"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06441" smilref="Title.smil#_06441"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06442" smilref="Title.smil#_06442"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06443" smilref="Title.smil#_06443"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06444" smilref="Title.smil#_06444"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06445" smilref="Title.smil#_06445"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06446" smilref="Title.smil#_06446"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_06447" smilref="Title.smil#_06447"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06448" smilref="Title.smil#_06448"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06449" smilref="Title.smil#_06449"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06450" smilref="Title.smil#_06450"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_06451" smilref="Title.smil#_06451"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06452" smilref="Title.smil#_06452"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_06453" smilref="Title.smil#_06453"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06454" smilref="Title.smil#_06454"> inserting L</p><p attribs="{'xml:space': 'preserve'}" id="_06455" smilref="Title.smil#_06455"> search for L ends at this null link</p><p attribs="{'xml:space': 'preserve'}" id="_06456" smilref="Title.smil#_06456"> Recursion. It is worthwhile to take the time to understand the dynamics of these recursive im- plementations. You can think of the code before the recursive calls as happening on the way down the tree: it compares the given key against the key at each node and moves right or left accord- ingly. Then, think of the code after the recursive calls as happening on the way up the tree. For get() this amounts to a series of return state- ments, but for put(), it corresponds to resetting the link of each parent to its child on the search path and to incrementing the counts on the way up the path. In simple BSTs, the only new link is the one at the bottom, but resetting the links higher up on the path is as easy as the test to avoid setting them. Also, we just need to increment the node count on each node on the path, but we use more general code that sets each to one plus the sum of the counts in its subtrees. Later in this section and in the next section, we shall study more advanced algorithms that are naturally expressed with this same recursive scheme but that can change more links on the search paths and need the more general node-count-update code. Elementary BSTs are often implemented with nonrecursive code (see Exercise 3.2.12)&#8212;we use recursion in our implementations both to make it easy for you to convince yourself that the code is operating as described and to prepare the groundwork for more sophisticated algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_06457" smilref="Title.smil#_06457"> reset links and increment counts on the way up</p><p attribs="{'xml:space': 'preserve'}" id="_06458" smilref="Title.smil#_06458"> Insertion into a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06459" smilref="Title.smil#_06459"> create new node</p><p attribs="{'xml:space': 'preserve'}" id="_06460" smilref="Title.smil#_06460"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_06461" smilref="Title.smil#_06461"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06462" smilref="Title.smil#_06462"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_06463" smilref="Title.smil#_06463"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06464" smilref="Title.smil#_06464"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_06465" smilref="Title.smil#_06465"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06466" smilref="Title.smil#_06466"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_06467" smilref="Title.smil#_06467"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06468" smilref="Title.smil#_06468"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_06469" smilref="Title.smil#_06469"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06470" smilref="Title.smil#_06470"> L</p><p attribs="{'xml:space': 'preserve'}" id="_06471" smilref="Title.smil#_06471"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06472" smilref="Title.smil#_06472"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06473" smilref="Title.smil#_06473"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06474" smilref="Title.smil#_06474"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06475" smilref="Title.smil#_06475"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06476" smilref="Title.smil#_06476"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06477" smilref="Title.smil#_06477"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_06478" smilref="Title.smil#_06478"> L</p><p attribs="{'xml:space': 'preserve'}" id="_06479" smilref="Title.smil#_06479"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06480" smilref="Title.smil#_06480"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06481" smilref="Title.smil#_06481"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06482" smilref="Title.smil#_06482"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06483" smilref="Title.smil#_06483"> A careful study of the trace for our standard indexing client that is shown on the next page will give you a feeling for the way in which binary search trees grow. New nodes are attached to null links at the bottom of the tree; the tree structure is not otherwise changed. For example, the root has the first key inserted, one of the children of the root has the second key inserted, and so forth. Because each node has two links, the tree tends to grow out, rather than just down. Moreover, only the keys on the path from the root to the sought or inserted key are examined, so the number of keys examined becomes a smaller and smaller fraction of the number of keys in the tree as the tree size increases.</p><p attribs="{'xml:space': 'preserve'}" id="_06484" smilref="Title.smil#_06484" /><pagenum id="p415" page="normal" smilref="Title.smil#p415" /><p attribs="{'xml:space': 'preserve'}" id="_06485" smilref="Title.smil#_06485"> S S</p><p attribs="{'xml:space': 'preserve'}" id="_06486" smilref="Title.smil#_06486"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06487" smilref="Title.smil#_06487"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06488" smilref="Title.smil#_06488"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06489" smilref="Title.smil#_06489"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06490" smilref="Title.smil#_06490"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06491" smilref="Title.smil#_06491"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06492" smilref="Title.smil#_06492"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06493" smilref="Title.smil#_06493"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06494" smilref="Title.smil#_06494"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06495" smilref="Title.smil#_06495"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06496" smilref="Title.smil#_06496"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06497" smilref="Title.smil#_06497"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06498" smilref="Title.smil#_06498"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06499" smilref="Title.smil#_06499"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06500" smilref="Title.smil#_06500"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06501" smilref="Title.smil#_06501"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06502" smilref="Title.smil#_06502"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06503" smilref="Title.smil#_06503"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06504" smilref="Title.smil#_06504"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06505" smilref="Title.smil#_06505"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06506" smilref="Title.smil#_06506"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06507" smilref="Title.smil#_06507"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06508" smilref="Title.smil#_06508"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06509" smilref="Title.smil#_06509"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06510" smilref="Title.smil#_06510"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06511" smilref="Title.smil#_06511"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06512" smilref="Title.smil#_06512"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06513" smilref="Title.smil#_06513"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06514" smilref="Title.smil#_06514"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06515" smilref="Title.smil#_06515"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06516" smilref="Title.smil#_06516"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06517" smilref="Title.smil#_06517"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06518" smilref="Title.smil#_06518"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06519" smilref="Title.smil#_06519"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_06520" smilref="Title.smil#_06520"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_06521" smilref="Title.smil#_06521"> E 1</p><p attribs="{'xml:space': 'preserve'}" id="_06522" smilref="Title.smil#_06522"> A 2</p><p attribs="{'xml:space': 'preserve'}" id="_06523" smilref="Title.smil#_06523"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_06524" smilref="Title.smil#_06524"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_06525" smilref="Title.smil#_06525"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_06526" smilref="Title.smil#_06526"> E 6</p><p attribs="{'xml:space': 'preserve'}" id="_06527" smilref="Title.smil#_06527"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_06528" smilref="Title.smil#_06528"> red nodes are new</p><p attribs="{'xml:space': 'preserve'}" id="_06529" smilref="Title.smil#_06529"> black nodes are accessed in search</p><p attribs="{'xml:space': 'preserve'}" id="_06530" smilref="Title.smil#_06530"> changed value</p><p attribs="{'xml:space': 'preserve'}" id="_06531" smilref="Title.smil#_06531"> changed value</p><p attribs="{'xml:space': 'preserve'}" id="_06532" smilref="Title.smil#_06532"> changed value</p><p attribs="{'xml:space': 'preserve'}" id="_06533" smilref="Title.smil#_06533"> gray nodes are untouched</p><p attribs="{'xml:space': 'preserve'}" id="_06534" smilref="Title.smil#_06534"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06535" smilref="Title.smil#_06535"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06536" smilref="Title.smil#_06536"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06537" smilref="Title.smil#_06537"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06538" smilref="Title.smil#_06538"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06539" smilref="Title.smil#_06539"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06540" smilref="Title.smil#_06540"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06541" smilref="Title.smil#_06541"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06542" smilref="Title.smil#_06542"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06543" smilref="Title.smil#_06543"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06544" smilref="Title.smil#_06544"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06545" smilref="Title.smil#_06545"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06546" smilref="Title.smil#_06546"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06547" smilref="Title.smil#_06547"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06548" smilref="Title.smil#_06548"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06549" smilref="Title.smil#_06549"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06550" smilref="Title.smil#_06550"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06551" smilref="Title.smil#_06551"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06552" smilref="Title.smil#_06552"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06553" smilref="Title.smil#_06553"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06554" smilref="Title.smil#_06554"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06555" smilref="Title.smil#_06555"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06556" smilref="Title.smil#_06556"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06557" smilref="Title.smil#_06557"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06558" smilref="Title.smil#_06558"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06559" smilref="Title.smil#_06559"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06560" smilref="Title.smil#_06560"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06561" smilref="Title.smil#_06561"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06562" smilref="Title.smil#_06562"> L</p><p attribs="{'xml:space': 'preserve'}" id="_06563" smilref="Title.smil#_06563"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06564" smilref="Title.smil#_06564"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06565" smilref="Title.smil#_06565"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06566" smilref="Title.smil#_06566"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06567" smilref="Title.smil#_06567"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06568" smilref="Title.smil#_06568"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06569" smilref="Title.smil#_06569"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06570" smilref="Title.smil#_06570"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06571" smilref="Title.smil#_06571"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06572" smilref="Title.smil#_06572"> L</p><p attribs="{'xml:space': 'preserve'}" id="_06573" smilref="Title.smil#_06573"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06574" smilref="Title.smil#_06574"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06575" smilref="Title.smil#_06575"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06576" smilref="Title.smil#_06576"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06577" smilref="Title.smil#_06577"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06578" smilref="Title.smil#_06578"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_06579" smilref="Title.smil#_06579"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_06580" smilref="Title.smil#_06580"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_06581" smilref="Title.smil#_06581"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_06582" smilref="Title.smil#_06582"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_06583" smilref="Title.smil#_06583"> L 11</p><p attribs="{'xml:space': 'preserve'}" id="_06584" smilref="Title.smil#_06584"> E 12</p><p attribs="{'xml:space': 'preserve'}" id="_06585" smilref="Title.smil#_06585"> BST trace for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_06586" smilref="Title.smil#_06586"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_06587" smilref="Title.smil#_06587"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_06588" smilref="Title.smil#_06588"> 402</p><p attribs="{'xml:space': 'preserve'}" id="_06589" smilref="Title.smil#_06589"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06590" smilref="Title.smil#_06590" /><pagenum id="p416" page="normal" smilref="Title.smil#p416" /><p attribs="{'xml:space': 'preserve'}" id="_06591" smilref="Title.smil#_06591"> Analysis The running times of algorithms on binary search trees depend on the shapes of the trees, which, in turn, depend on the order in which keys are inserted. In the best case, a tree with N nodes could be perfectly balanced, with ~ lg N nodes between the root and each null link. In the worst case there could be N nodes on the search path. The balance in typical trees turns out to be much closer to the best case than the worst case. For many applications, the following simple model is rea- sonable: We assume that the keys are (uniformly) random, or, equivalently, that they are inserted in random order. Analysis of this model stems from the observation that BSTs are dual to quicksort. The node at the root of the tree corresponds to the first partitioning item in quicksort (no keys to the left are larger, and no keys to the right are smaller) and the subtrees are built recursively, corresponding to quicksort&#8217;s recursive subar- ray sorts. This observation leads us to the analysis of properties of the trees.</p><p attribs="{'xml:space': 'preserve'}" id="_06592" smilref="Title.smil#_06592"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06593" smilref="Title.smil#_06593"> 403</p><p attribs="{'xml:space': 'preserve'}" id="_06594" smilref="Title.smil#_06594"> best case</p><p attribs="{'xml:space': 'preserve'}" id="_06595" smilref="Title.smil#_06595"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06596" smilref="Title.smil#_06596"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06597" smilref="Title.smil#_06597"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06598" smilref="Title.smil#_06598"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06599" smilref="Title.smil#_06599"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06600" smilref="Title.smil#_06600"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06601" smilref="Title.smil#_06601"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06602" smilref="Title.smil#_06602"> typical case</p><p attribs="{'xml:space': 'preserve'}" id="_06603" smilref="Title.smil#_06603"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06604" smilref="Title.smil#_06604"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06605" smilref="Title.smil#_06605"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06606" smilref="Title.smil#_06606"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06607" smilref="Title.smil#_06607"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06608" smilref="Title.smil#_06608"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06609" smilref="Title.smil#_06609"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06610" smilref="Title.smil#_06610"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06611" smilref="Title.smil#_06611"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06612" smilref="Title.smil#_06612"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06613" smilref="Title.smil#_06613"> worst case</p><p attribs="{'xml:space': 'preserve'}" id="_06614" smilref="Title.smil#_06614"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06615" smilref="Title.smil#_06615"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06616" smilref="Title.smil#_06616"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06617" smilref="Title.smil#_06617"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06618" smilref="Title.smil#_06618"> BST possibilities</p><p attribs="{'xml:space': 'preserve'}" id="_06619" smilref="Title.smil#_06619"> Proposition C. Search hits in a BST built from N random keys require ~ 2 ln N (about 1.39 lg N) compares, on the average.</p><p attribs="{'xml:space': 'preserve'}" id="_06620" smilref="Title.smil#_06620"> Proof : The number of compares used for a search hit ending at a given node is 1 plus the depth. Adding the depths of all nodes, we get a quantity known as the internal path length of the tree. Thus, the desired quantity is 1 plus the average internal path length of the BST, which we can analyze with the same argument that we used for Proposition K in Section 2.3: Let CN be the total internal path length of a BST built from inserting N randomly ordered distinct keys, so that the average cost of a search hit is 1 &#11001;CN / N. We have C0 = C1 = 0 and for N &gt; 1 we can write a recurrence relationship that directly mirrors the recursive BST structure: CN = N &#11002; 1 &#11001; (C0 &#11001; CN&#11002;1) / N + (C1 &#11001; CN&#11002;2)/N &#11001; . . . (CN&#11002;1 The N &#11002; 1 term takes into account that the root contributes 1 to the path length of each of the other N &#11002; 1 nodes in the tree; the rest of the expression accounts for the subtrees, which are equally likely to be any of the N sizes. After rearranging terms, this recurrence is nearly identical to the one that we solved in Section 2.3 for quicksort, and we can derive the approximation CN ~ 2N ln N.</p><p attribs="{'xml:space': 'preserve'}" id="_06621" smilref="Title.smil#_06621"> &#11001; C0 )/N</p><p attribs="{'xml:space': 'preserve'}" id="_06622" smilref="Title.smil#_06622" /><pagenum id="p417" page="normal" smilref="Title.smil#p417" /><p attribs="{'xml:space': 'preserve'}" id="_06623" smilref="Title.smil#_06623"> 404</p><p attribs="{'xml:space': 'preserve'}" id="_06624" smilref="Title.smil#_06624"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06625" smilref="Title.smil#_06625"> Proposition D. Insertions and search misses in a BST built from N random keys require ~ 2 ln N (about 1.39 lg N) compares, on the average.</p><p attribs="{'xml:space': 'preserve'}" id="_06626" smilref="Title.smil#_06626"> Proof : Insertions and search misses take one more compare, on the average, than search hits. This fact is not difficult to establish by induction (see Exercise 3.2.16).</p><p attribs="{'xml:space': 'preserve'}" id="_06627" smilref="Title.smil#_06627"> Proposition C says that we should expect the BST search cost for random keys to be about 39 percent higher than that for binary search. Proposition D says that the extra cost is well worthwhile, because the cost of inserting a new key is also expected to be logarithmic&#8212;&#64258; exibility not available with binary search in an ordered array, where the number of array accesses required for an insertion is typically linear. As with quicksort, the standard deviation of the number of compares is known to be low, so that these formulas become increasingly accurate as N increases.</p><p attribs="{'xml:space': 'preserve'}" id="_06628" smilref="Title.smil#_06628"> Experiments. How well does our random-key model match what is found in typical symbol-table clients? As usual, this question has to be studied carefully for particular practical applications, because of the large potential variation in performance. Fortu- nately, for many clients, the model is quite good for BSTs. For our example study of the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a reduction in the average cost from 484 array accesses or compares per operation for BinarySearchST to 13 for BST, again providing a quick validation of the logarithmic performance predicted by the theoretical model. More extensive experiments for larger inputs are illustrated in the table on the next page. On the basis of Propositions C and D, it is reasonable to predict that this number should be about twice the natural logarithm of the table size, because the preponderance of operations are searches in a nearly full table. This prediction has at least the following inherent inaccuracies: </p><p attribs="{'xml:space': 'preserve'}" id="_06629" smilref="Title.smil#_06629"> 3.2.35).</p><p attribs="{'xml:space': 'preserve'}" id="_06630" smilref="Title.smil#_06630" /><pagenum id="p418" page="normal" smilref="Title.smil#p418" /><p attribs="{'xml:space': 'preserve'}" id="_06631" smilref="Title.smil#_06631"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06632" smilref="Title.smil#_06632"> 405</p><p attribs="{'xml:space': 'preserve'}" id="_06633" smilref="Title.smil#_06633"> Typical BST, built from 256 random keys</p><p attribs="{'xml:space': 'preserve'}" id="_06634" smilref="Title.smil#_06634"> scale magnified by a factor of 250 compared to previous figures</p><p attribs="{'xml:space': 'preserve'}" id="_06635" smilref="Title.smil#_06635"> 13.9</p><p attribs="{'xml:space': 'preserve'}" id="_06636" smilref="Title.smil#_06636"> operations Costs for java FrequencyCounter 8 &lt; tale.txt using BST</p><p attribs="{'xml:space': 'preserve'}" id="_06637" smilref="Title.smil#_06637"> 14350</p><p attribs="{'xml:space': 'preserve'}" id="_06638" smilref="Title.smil#_06638"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_06639" smilref="Title.smil#_06639"> t s</p><p attribs="{'xml:space': 'preserve'}" id="_06640" smilref="Title.smil#_06640"> o</p><p attribs="{'xml:space': 'preserve'}" id="_06641" smilref="Title.smil#_06641"> c</p><p attribs="{'xml:space': 'preserve'}" id="_06642" smilref="Title.smil#_06642"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06643" smilref="Title.smil#_06643"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_06644" smilref="Title.smil#_06644"> tale.txt</p><p attribs="{'xml:space': 'preserve'}" id="_06645" smilref="Title.smil#_06645"> leipzig1M.txt</p><p attribs="{'xml:space': 'preserve'}" id="_06646" smilref="Title.smil#_06646"> words</p><p attribs="{'xml:space': 'preserve'}" id="_06647" smilref="Title.smil#_06647"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_06648" smilref="Title.smil#_06648"> compares model actual</p><p attribs="{'xml:space': 'preserve'}" id="_06649" smilref="Title.smil#_06649"> words</p><p attribs="{'xml:space': 'preserve'}" id="_06650" smilref="Title.smil#_06650"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_06651" smilref="Title.smil#_06651"> all words 8+ letters 10+ letters</p><p attribs="{'xml:space': 'preserve'}" id="_06652" smilref="Title.smil#_06652"> 135,635 14,350 4,582</p><p attribs="{'xml:space': 'preserve'}" id="_06653" smilref="Title.smil#_06653"> 10,679 5,737 2,260</p><p attribs="{'xml:space': 'preserve'}" id="_06654" smilref="Title.smil#_06654"> 18.6 17.6 15.4</p><p attribs="{'xml:space': 'preserve'}" id="_06655" smilref="Title.smil#_06655"> 17.5 13.9 13.1</p><p attribs="{'xml:space': 'preserve'}" id="_06656" smilref="Title.smil#_06656"> 21,191,455 4,239,597 1,610,829</p><p attribs="{'xml:space': 'preserve'}" id="_06657" smilref="Title.smil#_06657"> 534,580 299,593 165,555</p><p attribs="{'xml:space': 'preserve'}" id="_06658" smilref="Title.smil#_06658"> compares model actual</p><p attribs="{'xml:space': 'preserve'}" id="_06659" smilref="Title.smil#_06659"> 23.4 22.7 20.5</p><p attribs="{'xml:space': 'preserve'}" id="_06660" smilref="Title.smil#_06660"> 22.1 21.4 19.3</p><p attribs="{'xml:space': 'preserve'}" id="_06661" smilref="Title.smil#_06661"> Average number of compares per put() for FrequencyCounter using BST</p><p attribs="{'xml:space': 'preserve'}" id="_06662" smilref="Title.smil#_06662" /></level3><level3 id="_00052"><h3 id="ch3-s2-ss6" smilref="Title.smil#ch3-s2-ss6" xml:space="preserve">Order-based methods</h3><pagenum id="p419" page="normal" smilref="Title.smil#p419" /><p attribs="{'xml:space': 'preserve'}" id="_06663" smilref="Title.smil#_06663"> 406</p><p attribs="{'xml:space': 'preserve'}" id="_06664" smilref="Title.smil#_06664"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06665" smilref="Title.smil#_06665"> Order-based methods and deletion An important reason that BSTs are widely used is that they allow us to keep the keys in order. As such, they can serve as the basis for implementing the numerous methods in our ordered symbol-table API (see page 366) that allow clients to access key-value pairs not just by providing the key, but also by relative key order. Next, we consider implementations of the various methods in our ordered symbol-table API.</p><p attribs="{'xml:space': 'preserve'}" id="_06666" smilref="Title.smil#_06666"> Minimum and maximum. If the left link of the root is null, the smallest key in a BST is the key at the root; if the left link is not null, the smallest key in the BST is the smallest key in the subtree rooted at the node referenced by the left link. This statement is both a description of the recursive min() method on page 407 and an inductive proof that it finds the smallest key in the BST. The computation is equivalent to a simple iteration (move left until finding a null link), but we use recursion for consistency. We might have the recursive method return a Key instead of a Node, but we will later have a need to use this method to access the Node containing the minimum key. Finding the maximum key is similar, moving to the right instead of to the left.</p><p attribs="{'xml:space': 'preserve'}" id="_06667" smilref="Title.smil#_06667"> finding floor(G)</p><p attribs="{'xml:space': 'preserve'}" id="_06668" smilref="Title.smil#_06668"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06669" smilref="Title.smil#_06669"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06670" smilref="Title.smil#_06670"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06671" smilref="Title.smil#_06671"> Floor and ceiling. If a given key key is less than the key at the root of a BST, then the floor of key (the largest key in the BST less than or equal to key) must be in the left subtree. If key is greater than the key at the root, then the floor of key could be in the right subtree, but only if there is a key smaller than or equal to key in the right subtree; if not (or if key is equal to the key at the root), then the key at the root is the floor of key. Again, this description serves both as the basis for the recursive floor() method and for an inductive proof that it computes the desired result. Interchanging right and left (and less and greater)</p><p attribs="{'xml:space': 'preserve'}" id="_06672" smilref="Title.smil#_06672"> gives ceiling().</p><p attribs="{'xml:space': 'preserve'}" id="_06673" smilref="Title.smil#_06673"> Selection. Selection in a BST works in a manner analogous to the partition-based method of selection in an array that we studied in Section 2.5. We maintain in BST nodes the variable N that counts the number of keys in the subtree rooted at that node precisely to support this operation.</p><p attribs="{'xml:space': 'preserve'}" id="_06674" smilref="Title.smil#_06674"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06675" smilref="Title.smil#_06675"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06676" smilref="Title.smil#_06676"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06677" smilref="Title.smil#_06677"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06678" smilref="Title.smil#_06678"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06679" smilref="Title.smil#_06679"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06680" smilref="Title.smil#_06680"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06681" smilref="Title.smil#_06681"> G is greater than E so floor(G) could be on the right</p><p attribs="{'xml:space': 'preserve'}" id="_06682" smilref="Title.smil#_06682"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06683" smilref="Title.smil#_06683"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06684" smilref="Title.smil#_06684"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06685" smilref="Title.smil#_06685"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06686" smilref="Title.smil#_06686"> floor(G)in left subtree is null</p><p attribs="{'xml:space': 'preserve'}" id="_06687" smilref="Title.smil#_06687"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06688" smilref="Title.smil#_06688"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06689" smilref="Title.smil#_06689"> result</p><p attribs="{'xml:space': 'preserve'}" id="_06690" smilref="Title.smil#_06690"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06691" smilref="Title.smil#_06691"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06692" smilref="Title.smil#_06692"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06693" smilref="Title.smil#_06693"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06694" smilref="Title.smil#_06694"> G is less than S so floor(G) must be on the left</p><p attribs="{'xml:space': 'preserve'}" id="_06695" smilref="Title.smil#_06695"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06696" smilref="Title.smil#_06696"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06697" smilref="Title.smil#_06697"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06698" smilref="Title.smil#_06698"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06699" smilref="Title.smil#_06699"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06700" smilref="Title.smil#_06700"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06701" smilref="Title.smil#_06701"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06702" smilref="Title.smil#_06702"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06703" smilref="Title.smil#_06703"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06704" smilref="Title.smil#_06704"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06705" smilref="Title.smil#_06705"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06706" smilref="Title.smil#_06706"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06707" smilref="Title.smil#_06707"> Computing the floor function</p><p attribs="{'xml:space': 'preserve'}" id="_06708" smilref="Title.smil#_06708" /><pagenum id="p420" page="normal" smilref="Title.smil#p420" /><p attribs="{'xml:space': 'preserve'}" id="_06709" smilref="Title.smil#_06709"> ALGORITHM 3.3 (continued) Min, max, floor, and ceiling in BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_06710" smilref="Title.smil#_06710"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06711" smilref="Title.smil#_06711"> 407</p><p attribs="{'xml:space': 'preserve'}" id="_06712" smilref="Title.smil#_06712"> public Key min() { return min(root).key; }</p><p attribs="{'xml:space': 'preserve'}" id="_06713" smilref="Title.smil#_06713"> private Node min(Node x) { if (x.left == null) return x; return min(x.left); }</p><p attribs="{'xml:space': 'preserve'}" id="_06714" smilref="Title.smil#_06714"> public Key floor(Key key) { Node x = floor(root, key); if (x == null) return null; return x.key; }</p><p attribs="{'xml:space': 'preserve'}" id="_06715" smilref="Title.smil#_06715"> private Node floor(Node x, Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp == 0) return x; if (cmp &lt; 0) return floor(x.left, key); Node t = floor(x.right, key); if (t != null) return t; else return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_06716" smilref="Title.smil#_06716"> Each client method calls a corresponding private method that takes an additional link (to a Node) as argument and returns null or a Node containing the desired Key via the recursive procedure described in the text. The max() and ceiling() methods are the same as min() and floor() (respec- tively) with right and left (and &lt; and &gt;) interchanged.</p><p attribs="{'xml:space': 'preserve'}" id="_06717" smilref="Title.smil#_06717" /><pagenum id="p421" page="normal" smilref="Title.smil#p421" /><p attribs="{'xml:space': 'preserve'}" id="_06718" smilref="Title.smil#_06718"> 408</p><p attribs="{'xml:space': 'preserve'}" id="_06719" smilref="Title.smil#_06719"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06720" smilref="Title.smil#_06720"> Suppose that we seek the key of rank k (the key such that precisely k other keys in the BST are smaller). If the number of keys t in the left subtree is larger than k, we look (recursively) for the key of rank k in the left subtree; if t is equal to k, we return the key at the root; and if t is smaller than k, we look (recursively) for the key of rank k &#11002; t &#11002; 1 in the right subtree. As usual, this description serves both as the basis for the recursive select() method on the facing page and for a proof by induction that it works as expected.</p><p attribs="{'xml:space': 'preserve'}" id="_06721" smilref="Title.smil#_06721"> Rank. The inverse method rank() that returns the rank of a given key is similar: if the given key is equal to the key at the root, we return the number of keys t in the left subtree; if the given key is less than the key at the root, we return the rank of the key in the left subtree (recursively computed); and if the given key is larger than the key at the root, we return t plus one (to count the key at the root) plus the rank of the key in the right subtree (recursively computed).</p><p attribs="{'xml:space': 'preserve'}" id="_06722" smilref="Title.smil#_06722"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06723" smilref="Title.smil#_06723"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06724" smilref="Title.smil#_06724"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06725" smilref="Title.smil#_06725"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06726" smilref="Title.smil#_06726"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06727" smilref="Title.smil#_06727"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06728" smilref="Title.smil#_06728"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06729" smilref="Title.smil#_06729"> go left until reaching null left link</p><p attribs="{'xml:space': 'preserve'}" id="_06730" smilref="Title.smil#_06730"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06731" smilref="Title.smil#_06731"> return that node&#8217;s right link</p><p attribs="{'xml:space': 'preserve'}" id="_06732" smilref="Title.smil#_06732"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06733" smilref="Title.smil#_06733"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06734" smilref="Title.smil#_06734"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06735" smilref="Title.smil#_06735"> finding select(3) the key of rank 3</p><p attribs="{'xml:space': 'preserve'}" id="_06736" smilref="Title.smil#_06736"> count N</p><p attribs="{'xml:space': 'preserve'}" id="_06737" smilref="Title.smil#_06737"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06738" smilref="Title.smil#_06738"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06739" smilref="Title.smil#_06739"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06740" smilref="Title.smil#_06740"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_06741" smilref="Title.smil#_06741"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06742" smilref="Title.smil#_06742"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06743" smilref="Title.smil#_06743"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06744" smilref="Title.smil#_06744"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06745" smilref="Title.smil#_06745"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06746" smilref="Title.smil#_06746"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06747" smilref="Title.smil#_06747"> 2 keys in left subtree so search for key of rank 3-2-1 = 0 on the right</p><p attribs="{'xml:space': 'preserve'}" id="_06748" smilref="Title.smil#_06748"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06749" smilref="Title.smil#_06749"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06750" smilref="Title.smil#_06750"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_06751" smilref="Title.smil#_06751"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06752" smilref="Title.smil#_06752"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06753" smilref="Title.smil#_06753"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06754" smilref="Title.smil#_06754"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06755" smilref="Title.smil#_06755"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06756" smilref="Title.smil#_06756"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06757" smilref="Title.smil#_06757"> 0 keys in left subtree and searching for key of rank 0 so return H</p><p attribs="{'xml:space': 'preserve'}" id="_06758" smilref="Title.smil#_06758"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06759" smilref="Title.smil#_06759"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06760" smilref="Title.smil#_06760"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06761" smilref="Title.smil#_06761"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06762" smilref="Title.smil#_06762"> 8 keys in left subtree so search for key of rank 3 on the left</p><p attribs="{'xml:space': 'preserve'}" id="_06763" smilref="Title.smil#_06763"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06764" smilref="Title.smil#_06764"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06765" smilref="Title.smil#_06765"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06766" smilref="Title.smil#_06766"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06767" smilref="Title.smil#_06767"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06768" smilref="Title.smil#_06768"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06769" smilref="Title.smil#_06769"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06770" smilref="Title.smil#_06770"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06771" smilref="Title.smil#_06771"> 2 keys in left subtree so search for key of rank 0 on the left</p><p attribs="{'xml:space': 'preserve'}" id="_06772" smilref="Title.smil#_06772"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06773" smilref="Title.smil#_06773"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06774" smilref="Title.smil#_06774"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06775" smilref="Title.smil#_06775"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06776" smilref="Title.smil#_06776"> Selection in a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06777" smilref="Title.smil#_06777"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06778" smilref="Title.smil#_06778"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06779" smilref="Title.smil#_06779"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06780" smilref="Title.smil#_06780"> available for garbage collection</p><p attribs="{'xml:space': 'preserve'}" id="_06781" smilref="Title.smil#_06781"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06782" smilref="Title.smil#_06782"> update links and node counts after recursive calls</p><p attribs="{'xml:space': 'preserve'}" id="_06783" smilref="Title.smil#_06783"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_06784" smilref="Title.smil#_06784"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06785" smilref="Title.smil#_06785"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06786" smilref="Title.smil#_06786"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06787" smilref="Title.smil#_06787"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06788" smilref="Title.smil#_06788"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06789" smilref="Title.smil#_06789"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06790" smilref="Title.smil#_06790"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_06791" smilref="Title.smil#_06791"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06792" smilref="Title.smil#_06792"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06793" smilref="Title.smil#_06793"> Deleting the minimum in a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06794" smilref="Title.smil#_06794"> Delete the minimum/maximum. The most difficult BST op-</p><p attribs="{'xml:space': 'preserve'}" id="_06795" smilref="Title.smil#_06795"> eration to implement is the delete() method that removes a key-value pair from the symbol table. As a warmup, consider deleteMin() (remove the key-value pair with the smallest key). As with put() we write a recursive method that takes a link to a Node as argument and returns a link to a Node, so that we can reflect changes to the tree by assigning the result to the link used as argument. For deleteMin() we go left until finding a Node that has a null left link and then replace the link to that node by its right link (simply by returning the right link in the recursive method). The deleted node, with no link now pointing to it, is</p><p attribs="{'xml:space': 'preserve'}" id="_06796" smilref="Title.smil#_06796" /><pagenum id="p422" page="normal" smilref="Title.smil#p422" /><p attribs="{'xml:space': 'preserve'}" id="_06797" smilref="Title.smil#_06797"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06798" smilref="Title.smil#_06798"> 409</p><p attribs="{'xml:space': 'preserve'}" id="_06799" smilref="Title.smil#_06799"> ALGORITHM 3.3 (continued) Selection and rank in BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_06800" smilref="Title.smil#_06800"> public Key select(int k) { return select(root, k).key; }</p><p attribs="{'xml:space': 'preserve'}" id="_06801" smilref="Title.smil#_06801"> private Node select(Node x, int k) { // Return Node containing key of rank k. if (x == null) return null; int t = size(x.left); if (t &gt; k) return select(x.left, k); else if (t &lt; k) return select(x.right, k-t-1); else return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_06802" smilref="Title.smil#_06802"> public int rank(Key key) { return rank(key, root); }</p><p attribs="{'xml:space': 'preserve'}" id="_06803" smilref="Title.smil#_06803"> private int rank(Key key, Node x) { // Return number of keys less than x.key in the subtree rooted at x. if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key, x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key, x.right); else return size(x.left); }</p><p attribs="{'xml:space': 'preserve'}" id="_06804" smilref="Title.smil#_06804"> This code uses the same recursive scheme that we have been using throughout this chapter to implement the select() and rank() methods. It depends on using the private size() method given at the beginning of this section that gives the number of subtrees rooted at each node.</p><p attribs="{'xml:space': 'preserve'}" id="_06805" smilref="Title.smil#_06805" /><pagenum id="p423" page="normal" smilref="Title.smil#p423" /><p attribs="{'xml:space': 'preserve'}" id="_06806" smilref="Title.smil#_06806"> 410</p><p attribs="{'xml:space': 'preserve'}" id="_06807" smilref="Title.smil#_06807"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06808" smilref="Title.smil#_06808"> available for garbage collection. Our standard recursive setup accomplishes, after the deletion, the task of setting the appropriate link in the parent and updating the counts in all nodes in the path to the root. The symmetric method works for deleteMax().</p><p attribs="{'xml:space': 'preserve'}" id="_06809" smilref="Title.smil#_06809"> Delete. We can proceed in a similar manner to delete any node that has one child (or no children), but what can we do to delete a node that has two chil- dren? We are left with two links, but have a place in the parent node for only one of them. An answer to this dilemma, first proposed by T. Hibbard in 1962, is to delete a node x by replacing it with its successor. Because x has a right child, its successor is the node with the smallest key in its right subtree. The replacement preserves order in the tree because there are no keys between x.key and the successor&#8217;s key. We can accomplish the task of replacing x by its successor in four (!) easy steps: </p><p attribs="{'xml:space': 'preserve'}" id="_06810" smilref="Title.smil#_06810"> than x.key) to deleteMin(t.right), the link</p><p attribs="{'xml:space': 'preserve'}" id="_06811" smilref="Title.smil#_06811"> deleting E</p><p attribs="{'xml:space': 'preserve'}" id="_06812" smilref="Title.smil#_06812"> node to delete</p><p attribs="{'xml:space': 'preserve'}" id="_06813" smilref="Title.smil#_06813"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06814" smilref="Title.smil#_06814"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06815" smilref="Title.smil#_06815"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06816" smilref="Title.smil#_06816"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06817" smilref="Title.smil#_06817"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06818" smilref="Title.smil#_06818"> t</p><p attribs="{'xml:space': 'preserve'}" id="_06819" smilref="Title.smil#_06819"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06820" smilref="Title.smil#_06820"> x</p><p attribs="{'xml:space': 'preserve'}" id="_06821" smilref="Title.smil#_06821"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06822" smilref="Title.smil#_06822"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06823" smilref="Title.smil#_06823"> go right, then go left until reaching null left link</p><p attribs="{'xml:space': 'preserve'}" id="_06824" smilref="Title.smil#_06824"> x</p><p attribs="{'xml:space': 'preserve'}" id="_06825" smilref="Title.smil#_06825"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06826" smilref="Title.smil#_06826"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06827" smilref="Title.smil#_06827"> t.left</p><p attribs="{'xml:space': 'preserve'}" id="_06828" smilref="Title.smil#_06828"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06829" smilref="Title.smil#_06829"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06830" smilref="Title.smil#_06830"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06831" smilref="Title.smil#_06831"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06832" smilref="Title.smil#_06832"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06833" smilref="Title.smil#_06833"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06834" smilref="Title.smil#_06834"> search for key E</p><p attribs="{'xml:space': 'preserve'}" id="_06835" smilref="Title.smil#_06835"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06836" smilref="Title.smil#_06836"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06837" smilref="Title.smil#_06837"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06838" smilref="Title.smil#_06838"> successor</p><p attribs="{'xml:space': 'preserve'}" id="_06839" smilref="Title.smil#_06839"> min(t.right)</p><p attribs="{'xml:space': 'preserve'}" id="_06840" smilref="Title.smil#_06840"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06841" smilref="Title.smil#_06841"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06842" smilref="Title.smil#_06842"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06843" smilref="Title.smil#_06843"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06844" smilref="Title.smil#_06844"> deleteMin(t.right)</p><p attribs="{'xml:space': 'preserve'}" id="_06845" smilref="Title.smil#_06845"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06846" smilref="Title.smil#_06846"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06847" smilref="Title.smil#_06847"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06848" smilref="Title.smil#_06848"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06849" smilref="Title.smil#_06849"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_06850" smilref="Title.smil#_06850"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06851" smilref="Title.smil#_06851"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_06852" smilref="Title.smil#_06852"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06853" smilref="Title.smil#_06853"> to the BST containing all the keys that are larger than x.key after the deletion. </p><p attribs="{'xml:space': 'preserve'}" id="_06854" smilref="Title.smil#_06854"> update links and node counts after recursive calls</p><p attribs="{'xml:space': 'preserve'}" id="_06855" smilref="Title.smil#_06855"> Deletion in a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06856" smilref="Title.smil#_06856"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06857" smilref="Title.smil#_06857"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06858" smilref="Title.smil#_06858" /></level3><level3 id="_00053"><h3 id="ch3-s2-ss7" smilref="Title.smil#ch3-s2-ss7" xml:space="preserve">Deletion</h3><pagenum id="p424" page="normal" smilref="Title.smil#p424" /><p attribs="{'xml:space': 'preserve'}" id="_06859" smilref="Title.smil#_06859"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06860" smilref="Title.smil#_06860"> 411</p><p attribs="{'xml:space': 'preserve'}" id="_06861" smilref="Title.smil#_06861"> ALGORITHM 3.3 (continued) Deletion in BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_06862" smilref="Title.smil#_06862"> public void deleteMin() { root = deleteMin(root); }</p><p attribs="{'xml:space': 'preserve'}" id="_06863" smilref="Title.smil#_06863"> private Node deleteMin(Node x) { if (x.left == null) return x.right; x.left = deleteMin(x.left); x.N = size(x.left) + size(x.right) + 1; return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_06864" smilref="Title.smil#_06864"> public void delete(Key key) { root = delete(root, key); }</p><p attribs="{'xml:space': 'preserve'}" id="_06865" smilref="Title.smil#_06865"> private Node delete(Node x, Key key) { if (x == null) return null; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = delete(x.left, key); else if (cmp &gt; 0) x.right = delete(x.right, key); else { if (x.right == null) return x.left; if (x.left == null) return x.right; Node t = x; x = min(t.right); // See page 407. x.right = deleteMin(t.right); x.left = t.left; } x.N = size(x.left) + size(x.right) + 1; return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_06866" smilref="Title.smil#_06866"> These methods implement eager Hibbard deletion in BSTs, as described in the text on the facing page. The delete() code is compact, but tricky. Perhaps the best way to understand it is to read the description at left, try to write the code yourself on the basis of the description, then compare your code with this code. This method is typically effective, but performance in large-scale applications can become a bit problematic (see Exercise 3.2.42). The deleteMax() method is the same as deleteMin() with right and left interchanged.</p><p attribs="{'xml:space': 'preserve'}" id="_06867" smilref="Title.smil#_06867" /><pagenum id="p425" page="normal" smilref="Title.smil#p425" /><p attribs="{'xml:space': 'preserve'}" id="_06868" smilref="Title.smil#_06868"> 412</p><p attribs="{'xml:space': 'preserve'}" id="_06869" smilref="Title.smil#_06869"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06870" smilref="Title.smil#_06870"> private void print(Node x) { if (x == null) return; print(x.left); StdOut.println(x.key); print(x.right); }</p><p attribs="{'xml:space': 'preserve'}" id="_06871" smilref="Title.smil#_06871"> Range queries. To implement the keys() method that returns the keys in a given range, we begin with a basic recursive BST traversal method, known as inorder traversal. To illustrate the method, we consider the task of printing all the keys in a BST in order. To do so, print all the keys in the left subtree (which are less than the key at the root by definition of BSTs), then print the key at the root, then print all the keys in the right subtree (which are greater than the key at the root by definition of BSTs), as in the code at left. As usual, the description serves as an argument by induction that this code prints the keys in order. To implement the two-argument keys() method that returns to a client all the keys in a specified range, we modify this code to add each key that is in the range to a Queue, and to skip the recursive calls for subtrees that cannot contain keys in the range. As with BinarySearchST, the fact that we gather the keys in a Queue is hidden from the client. The intention is that clients should process all the keys in the range of interest using Java&#8217;s foreach construct rather than needing to know what data structure we use to implement Iterable&lt;Key&gt;.</p><p attribs="{'xml:space': 'preserve'}" id="_06872" smilref="Title.smil#_06872"> Printing the keys in a BST in order</p><p attribs="{'xml:space': 'preserve'}" id="_06873" smilref="Title.smil#_06873"> Analysis. How efficient are the order-based operations in BSTs? To study this question, we consider the tree height (the maximum depth of any node in the tree). Given a tree, its height determines the worst-case cost of all BST operations (except for range search which incurs additional cost proportional to the number of keys returned).</p><p attribs="{'xml:space': 'preserve'}" id="_06874" smilref="Title.smil#_06874"> Proposition E. In a BST, all operations take time proportional to the height of the tree, in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_06875" smilref="Title.smil#_06875"> Proof : All of these methods go down one or two paths in the tree. The length of any path is no more than the height, by defi nition.</p><p attribs="{'xml:space': 'preserve'}" id="_06876" smilref="Title.smil#_06876"> We expect the tree height (the worst-case cost) to be higher than the average internal path length that we defined on page 403 (which averages in the short paths as well), but how much higher? This question may seem to you to be similar to the questions answered by Proposition C and Proposition D, but it is far more difficult to answer, certainly beyond the scope of this book. The average height of a BST built from random keys was shown to be logarithmic by J. Robson in 1979, and L. Devroye later showed that the value approaches 2.99 lg N for large N. Thus, if the insertions in our application are well-described by the random-key model, we are well on the way toward our goal of developing a symbol-table implementation that supports all of these operations</p><p attribs="{'xml:space': 'preserve'}" id="_06877" smilref="Title.smil#_06877" /><pagenum id="p426" page="normal" smilref="Title.smil#p426" /><p attribs="{'xml:space': 'preserve'}" id="_06878" smilref="Title.smil#_06878"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06879" smilref="Title.smil#_06879"> 413</p><p attribs="{'xml:space': 'preserve'}" id="_06880" smilref="Title.smil#_06880"> ALGORITHM 3.3 (continued) Range searching in BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_06881" smilref="Title.smil#_06881"> public Iterable&lt;Key&gt; keys() { return keys(min(), max()); }</p><p attribs="{'xml:space': 'preserve'}" id="_06882" smilref="Title.smil#_06882"> public Iterable&lt;Key&gt; keys(Key lo, Key hi) { Queue&lt;Key&gt; queue = new Queue&lt;Key&gt;(); keys(root, queue, lo, hi); return queue; }</p><p attribs="{'xml:space': 'preserve'}" id="_06883" smilref="Title.smil#_06883"> private void keys(Node x, Queue&lt;Key&gt; queue, Key lo, Key hi) { if (x == null) return; int cmplo = lo.compareTo(x.key); int cmphi = hi.compareTo(x.key); if (cmplo &lt; 0) keys(x.left, queue, lo, hi); if (cmplo &lt;= 0 &amp;&amp; cmphi &gt;= 0) queue.enqueue(x.key); if (cmphi &gt; 0) keys(x.right, queue, lo, hi); }</p><p attribs="{'xml:space': 'preserve'}" id="_06884" smilref="Title.smil#_06884"> To enqueue all the keys from the tree rooted at a given node that fall in a given range onto a queue, we (recursively) enqueue all the keys from the left subtree (if any of them could fall in the range), then enqueue the node at the root (if it falls in the range), then (recursively) enqueue all the keys from the right subtree (if any of them could fall in the range).</p><p attribs="{'xml:space': 'preserve'}" id="_06885" smilref="Title.smil#_06885"> searching in the range [F..T]</p><p attribs="{'xml:space': 'preserve'}" id="_06886" smilref="Title.smil#_06886"> red keys are used in compares but are not in the range</p><p attribs="{'xml:space': 'preserve'}" id="_06887" smilref="Title.smil#_06887"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06888" smilref="Title.smil#_06888"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06889" smilref="Title.smil#_06889"> C</p><p attribs="{'xml:space': 'preserve'}" id="_06890" smilref="Title.smil#_06890"> H</p><p attribs="{'xml:space': 'preserve'}" id="_06891" smilref="Title.smil#_06891"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06892" smilref="Title.smil#_06892"> X</p><p attribs="{'xml:space': 'preserve'}" id="_06893" smilref="Title.smil#_06893"> R</p><p attribs="{'xml:space': 'preserve'}" id="_06894" smilref="Title.smil#_06894"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06895" smilref="Title.smil#_06895"> L</p><p attribs="{'xml:space': 'preserve'}" id="_06896" smilref="Title.smil#_06896"> P</p><p attribs="{'xml:space': 'preserve'}" id="_06897" smilref="Title.smil#_06897"> black keys are in the range</p><p attribs="{'xml:space': 'preserve'}" id="_06898" smilref="Title.smil#_06898"> Range search in a BST</p><p attribs="{'xml:space': 'preserve'}" id="_06899" smilref="Title.smil#_06899" /><pagenum id="p427" page="normal" smilref="Title.smil#p427" /><p attribs="{'xml:space': 'preserve'}" id="_06900" smilref="Title.smil#_06900"> 414</p><p attribs="{'xml:space': 'preserve'}" id="_06901" smilref="Title.smil#_06901"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06902" smilref="Title.smil#_06902"> in logarithmic time. We can expect that no path in a tree built from random keys is longer than 3 lg N, but what can we expect if the keys are not random? In the next sec- tion, you will see why this question is moot in practice because of balanced BSTs, which guarantee that the BST height will be logarithmic regardless of the order in which keys are inserted.</p><p attribs="{'xml:space': 'preserve'}" id="_06903" smilref="Title.smil#_06903"> In summary, BSTs are not difficult to implement and can provide fast search and insert for practical applications of all kinds if the key insertions are well-approximated by the random-key model. For our examples (and for many practical applications) BSTs make the difference between being able to accomplish the task at hand and not being able to do so. Moreover, many programmers choose BSTs for symbol-table implementations because they also support fast rank, select, delete, and range query operations. Still, as we have emphasized, the bad worst-case performance of BSTs may not be tolerable in some situations. Good performance of the basic BST implementation is dependent on the keys being sufficiently similar to random keys that the tree is not likely to contain many long paths. With quicksort, we were able to randomize; with a symbol-table API, we do not have that freedom, because the client controls the mix of operations. Indeed, the worst-case behavior is not unlikely in practice&#8212;it arises when a client inserts keys in order or in reverse order, a sequence of operations that some client certainly might attempt in the absence of any explicit warnings to avoid doing so. This possibility is a primary reason to seek better algorithms and data structures, which we consider next.</p><p attribs="{'xml:space': 'preserve'}" id="_06904" smilref="Title.smil#_06904"> algorithm (data structure)</p><p attribs="{'xml:space': 'preserve'}" id="_06905" smilref="Title.smil#_06905"> sequential search (unordered linked list) binary search (ordered array) binary tree search (BST)</p><p attribs="{'xml:space': 'preserve'}" id="_06906" smilref="Title.smil#_06906"> worst-case cost (after N inserts)</p><p attribs="{'xml:space': 'preserve'}" id="_06907" smilref="Title.smil#_06907"> average-case cost (after N random inserts)</p><p attribs="{'xml:space': 'preserve'}" id="_06908" smilref="Title.smil#_06908"> search</p><p attribs="{'xml:space': 'preserve'}" id="_06909" smilref="Title.smil#_06909"> insert</p><p attribs="{'xml:space': 'preserve'}" id="_06910" smilref="Title.smil#_06910"> search hit</p><p attribs="{'xml:space': 'preserve'}" id="_06911" smilref="Title.smil#_06911"> insert</p><p attribs="{'xml:space': 'preserve'}" id="_06912" smilref="Title.smil#_06912"> efficiently support ordered operations?</p><p attribs="{'xml:space': 'preserve'}" id="_06913" smilref="Title.smil#_06913"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06914" smilref="Title.smil#_06914"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_06915" smilref="Title.smil#_06915"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06916" smilref="Title.smil#_06916"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06917" smilref="Title.smil#_06917"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06918" smilref="Title.smil#_06918"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06919" smilref="Title.smil#_06919"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_06920" smilref="Title.smil#_06920"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_06921" smilref="Title.smil#_06921"> N</p><p attribs="{'xml:space': 'preserve'}" id="_06922" smilref="Title.smil#_06922"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_06923" smilref="Title.smil#_06923"> 1.39 lg N 1.39 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_06924" smilref="Title.smil#_06924"> no</p><p attribs="{'xml:space': 'preserve'}" id="_06925" smilref="Title.smil#_06925"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_06926" smilref="Title.smil#_06926"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_06927" smilref="Title.smil#_06927"> Cost summary for basic symbol-table implementations (updated)</p><p attribs="{'xml:space': 'preserve'}" id="_06928" smilref="Title.smil#_06928" /><pagenum id="p428" page="normal" smilref="Title.smil#p428" /><p attribs="{'xml:space': 'preserve'}" id="_06929" smilref="Title.smil#_06929"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06930" smilref="Title.smil#_06930"> 415</p><p attribs="{'xml:space': 'preserve'}" id="_06931" smilref="Title.smil#_06931"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_06932" smilref="Title.smil#_06932"> Q. I&#8217;ve seen BSTs before, but not using recursion. What are the tradeoffs? A. Generally, recursive implementations are a bit easier to verify for correctness; non- recursive implementations are a bit more ef&#64257; cient. See Exercise 3.2.13 for an implementation of get(), the one case where you might notice the improved ef&#64257; ciency. If trees are unbalanced, the depth of the function-call stack could be a problem in a recursive implementation. Our primary reason for using recursion is to ease the transition to the balanced BST implementations of the next section, which definitely are easier to implement and debug with recursion. Q. Maintaining the node count field in Node seems to require a lot of code. Is it really necessary? Why not maintain a single instance variable containing the number of nodes in the tree to implement the size() client method? A. The rank() and select() methods need to have the size of the subtree rooted at each node. If you are not using these ordered operations, you can streamline the code by eliminating this field (see Exercise 3.2.12). Keeping the node count correct for all nodes is admittedly error-prone, but also a good check for debugging. You might also use a recursive method to implement size() for clients, but that would take linear time to count all the nodes and is a dangerous choice because you might experience poor performance in a client program, not realizing that such a simple operation is so expensive.</p><p attribs="{'xml:space': 'preserve'}" id="_06933" smilref="Title.smil#_06933" /><pagenum id="p429" page="normal" smilref="Title.smil#p429" /><p attribs="{'xml:space': 'preserve'}" id="_06934" smilref="Title.smil#_06934"> 416</p><p attribs="{'xml:space': 'preserve'}" id="_06935" smilref="Title.smil#_06935"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06936" smilref="Title.smil#_06936"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_06937" smilref="Title.smil#_06937"> 3.2.1 Draw the BST that results when you insert the keys E A S Y Q U E S T I O N, in that order (associating the value i with the ith key, as per the convention in the text) into an initially empty tree. How many compares are needed to build the tree? 3.2.2 Inserting the keys in the order A X C S E R H into an initially empty BST gives a worst-case tree where every node has one null link, except one at the bottom, which has two null links. Give five other orderings of these keys that produce worst-case trees. 3.2.3 Give five orderings of the keys A X C S E R H that, when inserted into an initially empty BST, produce the best-case tree. 3.2.4 Suppose that a certain BST has keys that are integers between 1 and 10, and we search for 5. Which sequence below cannot be the sequence of keys examined?</p><p attribs="{'xml:space': 'preserve'}" id="_06938" smilref="Title.smil#_06938"> a. 10, 9, 8, 7, 6, 5 b. 4, 10, 8, 7, 53 c. 1, 10, 2, 9, 3, 8, 4, 7, 6, 5 d. 2, 7, 3, 8, 4, 5 e. 1, 2, 10, 4, 8, 5</p><p attribs="{'xml:space': 'preserve'}" id="_06939" smilref="Title.smil#_06939"> 3.2.5 Suppose that we have an estimate ahead of time of how often search keys are to be accessed in a BST, and the freedom to insert them in any order that we desire. Should the keys be inserted into the tree in increasing order, decreasing order of likely frequency of access, or some other order? Explain your answer. 3.2.6 Add to BST a method height() that computes the height of the tree. Develop two implementations: a recursive method (which takes linear time and space proportional to the height), and a method like size() that adds afield to each node in the tree (and takes linear space and constant time per query). 3.2.7 Add to BST a recursive method avgCompares() that computes the average number of compares required by a random search hit in a given BST (the internal path length of the tree divided by its size, plus one). Develop two implementations: a recursive method (which takes linear time and space proportional to the height), and a method like size() that adds afield to each node in the tree (and takes linear space and constant time per query). 3.2.8 Write a static method optCompares() that takes an integer argument N and computes the number of compares required by a random search hit in an optimal (perfectly</p><p attribs="{'xml:space': 'preserve'}" id="_06940" smilref="Title.smil#_06940" /><pagenum id="p430" page="normal" smilref="Title.smil#p430" /><p attribs="{'xml:space': 'preserve'}" id="_06941" smilref="Title.smil#_06941"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06942" smilref="Title.smil#_06942"> 417</p><p attribs="{'xml:space': 'preserve'}" id="_06943" smilref="Title.smil#_06943"> balanced) BST, where all the null links are on the same level if the number of links is a power of 2 or on one of two levels otherwise. 3.2.9 Draw all the different BST shapes that can result when N keys are inserted into an initially empty tree, for N = 2, 3, 4, 5, and 6. 3.2.10 Write a test client for BST that tests the implementations of min(), max(),</p><p attribs="{'xml:space': 'preserve'}" id="_06944" smilref="Title.smil#_06944"> floor(), ceiling(), select(), rank(), delete(), deleteMin(), deleteMax(), and</p><p attribs="{'xml:space': 'preserve'}" id="_06945" smilref="Title.smil#_06945"> keys() that are given in the text. Start with the standard indexing client given on page 370. Add code to take additional command-line arguments, as appropriate. 3.2.11 How many binary tree shapes of N nodes are there with height N? How many different ways are there to insert N distinct keys into an initially empty BST that result in a tree of height N? (See Exercise 3.2.2.) 3.2.12 Develop a BST implementation that omits rank() and select() and does not use a count field in Node. 3.2.13 Give nonrecursive implementations of get() and put() for BST. Partial solution : Here is an implementation of get():</p><p attribs="{'xml:space': 'preserve'}" id="_06946" smilref="Title.smil#_06946"> public Value get(Key key) { Node x = root; while (x != null) { int cmp = key.compareTo(x.key); if (cmp == 0) return x.val; else if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; } return null; }</p><p attribs="{'xml:space': 'preserve'}" id="_06947" smilref="Title.smil#_06947"> The implementation of put() is more complicated because of the need to save a pointer to the parent node to link in the new node at the bottom. Also, you need a separate pass to check whether the key is already in the table because of the need to update the counts. Since there are many more searches than inserts in performance-critical imple- mentations, using this code for get() is justi&#64257; ed; the corresponding change for put() might not be noticed.</p><p attribs="{'xml:space': 'preserve'}" id="_06948" smilref="Title.smil#_06948" /><pagenum id="p431" page="normal" smilref="Title.smil#p431" /><p attribs="{'xml:space': 'preserve'}" id="_06949" smilref="Title.smil#_06949"> 418</p><p attribs="{'xml:space': 'preserve'}" id="_06950" smilref="Title.smil#_06950"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06951" smilref="Title.smil#_06951"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06952" smilref="Title.smil#_06952"> 3.2.14 Give nonrecursive implementations of min(), max(), floor(), ceiling(),</p><p attribs="{'xml:space': 'preserve'}" id="_06953" smilref="Title.smil#_06953"> rank(), and select().</p><p attribs="{'xml:space': 'preserve'}" id="_06954" smilref="Title.smil#_06954"> 3.2.15 Give the sequences of nodes examined when the methods in BST are used to compute each of the following quantities for the tree drawn at right.</p><p attribs="{'xml:space': 'preserve'}" id="_06955" smilref="Title.smil#_06955"> a. floor("Q") b. select(5) c. ceiling("Q") d. rank("J") e. size("D", "T") f. keys("D", "T")</p><p attribs="{'xml:space': 'preserve'}" id="_06956" smilref="Title.smil#_06956"> E</p><p attribs="{'xml:space': 'preserve'}" id="_06957" smilref="Title.smil#_06957"> D</p><p attribs="{'xml:space': 'preserve'}" id="_06958" smilref="Title.smil#_06958"> Q</p><p attribs="{'xml:space': 'preserve'}" id="_06959" smilref="Title.smil#_06959"> A</p><p attribs="{'xml:space': 'preserve'}" id="_06960" smilref="Title.smil#_06960"> J</p><p attribs="{'xml:space': 'preserve'}" id="_06961" smilref="Title.smil#_06961"> T</p><p attribs="{'xml:space': 'preserve'}" id="_06962" smilref="Title.smil#_06962"> M</p><p attribs="{'xml:space': 'preserve'}" id="_06963" smilref="Title.smil#_06963"> S</p><p attribs="{'xml:space': 'preserve'}" id="_06964" smilref="Title.smil#_06964"> 3.2.16 De&#64257; ne the external path length of a tree to be the sum of the number of nodes on the paths from the root to all null links. Prove that the difference between the external and internal path lengths in any binary tree with N nodes is 2N (see Proposition C). 3.2.17 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, in the order they were inserted. 3.2.18 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, in alphabetical order. 3.2.19 Draw the sequence of BSTs that results when you delete the keys from the tree of Exercise 3.2.1, one by one, by successively deleting the key at the root. 3.2.20 Prove that the running time of the two-argument keys() in a BST with N nodes is at most proportional to the tree height plus the number of keys in the range. 3.2.21 Add a BST method randomKey() that returns a random key from the symbol table in time proportional to the tree height, in the worst case. 3.2.22 Prove that if a node in a BST has two children, its successor has no left child and its predecessor has no right child. 3.2.23 Is delete() commutative? (Does deleting x, then y give the same result as deleting y, then x?) 3.2.24 Prove that no compare-based algorithm can build a BST using fewer than lg(N !) ~ N lg N compares.</p><p attribs="{'xml:space': 'preserve'}" id="_06965" smilref="Title.smil#_06965" /><pagenum id="p432" page="normal" smilref="Title.smil#p432" /><p attribs="{'xml:space': 'preserve'}" id="_06966" smilref="Title.smil#_06966"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06967" smilref="Title.smil#_06967"> 419</p><p attribs="{'xml:space': 'preserve'}" id="_06968" smilref="Title.smil#_06968"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_06969" smilref="Title.smil#_06969"> 3.2.25 Perfect balance. Write a program that inserts a set of keys into an initially empty BST such that the tree produced is equivalent to binary search, in the sense that the sequence of compares done in the search for any key in the BST is the same as the sequence of compares used by binary search for the same set of keys. 3.2.26 Exact probabilities. Find the probability that each of the trees in Exercise 3.2.9 is the result of inserting N random distinct elements into an initially empty tree. 3.2.27 Memory usage. Compare the memory usage of BST with the memory usage of BinarySearchST and SequentialSearchST for N key-value pairs, under the assumptions described in Section 1.4 (see Exercise 3.1.21). Do not count the memory for the keys and values themselves, but do count references to them. Then draw a diagram that depicts the precise memory usage of a BST with String keys and Integer values (such as the ones built by FrequencyCounter), and then estimate the memory usage (in bytes) for the BST built when FrequencyCounter uses BST for Tale of Two Cities. 3.2.28 Sofware caching. Modify BST to keep the most recently accessed Node in an instance variable so that it can be accessed in constant time if the next put() or get() uses the same key (see Exercise 3.1.25). 3.2.29 Tree traversal with constant extra memory. Design an algorithm that performs an inorder tree traversal of a BST using only a constant amount of extra memory. Hint : On the way down the tree, make the child point to the parent and reverse it on the way back up the tree. 3.2.30 BST reconstruction. Given the preorder (or postorder) traversal of a BST (not including null nodes), design an algorithm to reconstruct the BST.</p><p attribs="{'xml:space': 'preserve'}" id="_06970" smilref="Title.smil#_06970" /><pagenum id="p433" page="normal" smilref="Title.smil#p433" /><p attribs="{'xml:space': 'preserve'}" id="_06971" smilref="Title.smil#_06971"> 420</p><p attribs="{'xml:space': 'preserve'}" id="_06972" smilref="Title.smil#_06972"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06973" smilref="Title.smil#_06973"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_06974" smilref="Title.smil#_06974"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_06975" smilref="Title.smil#_06975"> private boolean isBST() { if (!isBinaryTree(root)) return false; if (!isOrdered(root, min(), max())) return false; if (!hasNoDuplicates(root)) return false; return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_06976" smilref="Title.smil#_06976"> 3.2.33 Select/rank check. Write a method that checks, for all i from 0 to size()-1, whether i is equal to rank(select(i)) and, for all keys in the BST, whether key is</p><p attribs="{'xml:space': 'preserve'}" id="_06977" smilref="Title.smil#_06977"> equal to select(rank(key)).</p><p attribs="{'xml:space': 'preserve'}" id="_06978" smilref="Title.smil#_06978"> 3.2.34 Threading. Your goal is to support an extended API ThreadedST that supports the following additional operations in constant time:</p><p attribs="{'xml:space': 'preserve'}" id="_06979" smilref="Title.smil#_06979"> Key next(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_06980" smilref="Title.smil#_06980"> Key prev(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_06981" smilref="Title.smil#_06981"> key that follows key (null if key is the maximum) key that precedes key (null if key is the minimum)</p><p attribs="{'xml:space': 'preserve'}" id="_06982" smilref="Title.smil#_06982"> To do so, add fields pred and succ to Node that contain links to the predecessor and successor nodes, and modify put(), deleteMin(), deleteMax(), and delete() to maintain these fi elds. 3.2.35 Re&#64257; ned analysis. Re&#64257; ne the mathematical model to better explain the experimental results in the table given in the text. Speci&#64257; cally, show that the average number of compares for a successful search in a tree built from random keys approaches the limit 2 ln N &#11001; 2&#9253; &#8211; 3 &#11015; 1.39 lg N &#8211; 1.85 as N increases, where &#9253; &#11005; .57721... is Euler&#8217;s constant. Hint : Referring to the quicksort analysis in Section 2.3, use the fact that the integral of 1/x approaches ln N &#11001; &#9253;. 3.2.36 Iterator. Is it possible to write a nonrecursive version of keys() that uses space proportional to the tree height (independent of the number of keys in the range)? 3.2.37 Level-order traversal. Write a method printLevel() that takes a Node as argument and prints the keys in the subtree rooted at that node in level order (in order of their distance from the root, with nodes on each level in order from left to right). Hint : Use a Queue.</p><p attribs="{'xml:space': 'preserve'}" id="_06983" smilref="Title.smil#_06983" /><pagenum id="p434" page="normal" smilref="Title.smil#p434" /><p attribs="{'xml:space': 'preserve'}" id="_06984" smilref="Title.smil#_06984"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06985" smilref="Title.smil#_06985"> 421</p><p attribs="{'xml:space': 'preserve'}" id="_06986" smilref="Title.smil#_06986"> 3.2.38 Tree drawing. Add a method draw() to BST that draws BST figures in the style of the text. Hint : Use instance variables to hold node coordinates, and use a recursive method to set the values of these variables.</p><p attribs="{'xml:space': 'preserve'}" id="_06987" smilref="Title.smil#_06987" /><pagenum id="p435" page="normal" smilref="Title.smil#p435" /><p attribs="{'xml:space': 'preserve'}" id="_06988" smilref="Title.smil#_06988"> 422</p><p attribs="{'xml:space': 'preserve'}" id="_06989" smilref="Title.smil#_06989"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_06990" smilref="Title.smil#_06990"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_06991" smilref="Title.smil#_06991"> 3.2.39 Average case. Run empirical studies to estimate the average and standard deviation of the number of compares used for search hits and for search misses in a BST built by running 100 trials of the experiment of inserting N random keys into an initially empty tree, for N = 10 4, 10 5, and 10 6. Compare your results against the formula for the average given in Exercise 3.2.35. 3.2.40 Height. Run empirical studies to estimate average BST height by running 100 trials of the experiment of inserting N random keys into an initially empty tree, for N = 104, 105, and 10 6. Compare your results against the 2.99 lg N estimate that is described in the text. 3.2.41 Array representation. Develop a BST implementation that represents the BST with three arrays (preallocated to the maximum size given in the constructor): one with the keys, one with array indices corresponding to left links, and one with array indices corresponding to right links. Compare the performance of your program with that of the standard implementation. 3.2.42 Hibbard deletion degradation. Write a program that takes an integer N from the command line, builds a random BST of size N, then enters into a loop where it deletes a random key (using the code delete(select(StdRandom.uniform(N)))) and then inserts a random key, iterating the loop N 2 times. After the loop, measure and print the average length of a path in the tree (the internal path length divided by N, plus 1). Run your program for N = 102, 103, and 10 4 to test the somewhat counterintuitive hypothesis that this process increases the average path length of the tree to be proportional to the square root of N. Run the same experiments for a delete() implementation that makes a random choice whether to use the predecessor or the successor node. 3.2.43 Put/get ratio. Determine empirically the ratio of the amount of time that BST spends on put() operations to the time that it spends on get() operations when FrequencyCounter is used to find the frequency of occurrence of values in 1 million randomly-generated integers. 3.2.44 Cost plots. Instrument BST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation (see Exer-</p><p attribs="{'xml:space': 'preserve'}" id="_06992" smilref="Title.smil#_06992"> cise 3.1.38).</p><p attribs="{'xml:space': 'preserve'}" id="_06993" smilref="Title.smil#_06993"> 3.2.45 Actual timings. Instrument FrequencyCounter to use Stopwatch and StdDraw to make a plot where the x axis is the number of calls on get() or put() and the y axis</p><p attribs="{'xml:space': 'preserve'}" id="_06994" smilref="Title.smil#_06994" /><pagenum id="p436" page="normal" smilref="Title.smil#p436" /><p attribs="{'xml:space': 'preserve'}" id="_06995" smilref="Title.smil#_06995"> 3.2 </p><p attribs="{'xml:space': 'preserve'}" id="_06996" smilref="Title.smil#_06996"> 423</p><p attribs="{'xml:space': 'preserve'}" id="_06997" smilref="Title.smil#_06997"> is the total running time, with a point plotted of the cumulative time after each call. Run your program for Tale of Two Cities using SequentialSearchST and again using BinarySearchST and again using BST and discuss the results. Note : Sharp jumps in the curve may be explained by caching, which is beyond the scope of this question (see</p><p attribs="{'xml:space': 'preserve'}" id="_06998" smilref="Title.smil#_06998"> Exercise 3.1.39).</p><p attribs="{'xml:space': 'preserve'}" id="_06999" smilref="Title.smil#_06999"> 3.2.46 Crossover to binary search trees. Find the values of N for which using a binary search tree to build a symbol table of N random double keys becomes 10, 100, and 1,000 times faster than binary search. Predict the values with analysis and verify them experimentally. 3.2.47 Average search time. Run empirical studies to compute the average and standard deviation of the average length of a path to a random node (internal path length divided by tree size, plus 1) in a BST built by insertion of N random keys into an initially empty tree, for N from 100 to 10,000. Do 1,000 trials for each tree size. Plot the results in a Tufte plot, like the one at the bottom of this page, fit with a curve plotting the function</p><p attribs="{'xml:space': 'preserve'}" id="_07000" smilref="Title.smil#_07000"> 1.39 lg N &#8211; 1.85 (see Exercise 3.2.35 and Exercise 3.2.39).</p><p attribs="{'xml:space': 'preserve'}" id="_07001" smilref="Title.smil#_07001"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_07002" smilref="Title.smil#_07002"> s</p><p attribs="{'xml:space': 'preserve'}" id="_07003" smilref="Title.smil#_07003"> e</p><p attribs="{'xml:space': 'preserve'}" id="_07004" smilref="Title.smil#_07004"> r</p><p attribs="{'xml:space': 'preserve'}" id="_07005" smilref="Title.smil#_07005"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07006" smilref="Title.smil#_07006"> p</p><p attribs="{'xml:space': 'preserve'}" id="_07007" smilref="Title.smil#_07007"> m</p><p attribs="{'xml:space': 'preserve'}" id="_07008" smilref="Title.smil#_07008"> o</p><p attribs="{'xml:space': 'preserve'}" id="_07009" smilref="Title.smil#_07009"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07010" smilref="Title.smil#_07010"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_07011" smilref="Title.smil#_07011"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_07012" smilref="Title.smil#_07012"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_07013" smilref="Title.smil#_07013"> 1.39 lg N &#8722; 1.85</p><p attribs="{'xml:space': 'preserve'}" id="_07014" smilref="Title.smil#_07014"> operations</p><p attribs="{'xml:space': 'preserve'}" id="_07015" smilref="Title.smil#_07015"> 10000</p><p attribs="{'xml:space': 'preserve'}" id="_07016" smilref="Title.smil#_07016"> Average path length to a random node in a BST built from random keys</p><p attribs="{'xml:space': 'preserve'}" id="_07017" smilref="Title.smil#_07017" /></level3><level3 id="_00054"><h3 id="ch3-s3-ss8" smilref="Title.smil#ch3-s3-ss8" xml:space="preserve">2-3 search trees</h3><p attribs="{'xml:space': 'preserve'}" id="_07018" smilref="Title.smil#_07018"> 3.3</p><p attribs="{'xml:space': 'preserve'}" id="_07019" smilref="Title.smil#_07019"> BALANCED SEARCH TREES</p><p attribs="{'xml:space': 'preserve'}" id="_07020" smilref="Title.smil#_07020"> The algorithms in the previous section work well for a wide variety of applications, but they have poor worst-case performance. We introduce in this section a type of binary search tree where costs are guaranteed to be logarithmic, no matter what sequence of keys is used to construct them. Ideally, we would like to keep our binary search trees perfectly balanced. In an N-node tree, we would like the height to be ~lg N so that we can guarantee that all searches can be completed in ~lg N compares, just as for binary search (see Proposition B). Unfortunately, maintaining perfect balance for dynamic insertions is too expensive. In this section, we consider a data structure that slightly relaxes the perfect balance requirement to provide guaranteed logarithmic performance not just for the insert and search operations in our symbol-table API but also for all of the ordered operations (except range search).</p><p attribs="{'xml:space': 'preserve'}" id="_07021" smilref="Title.smil#_07021"> 2-3 search trees The primary step to get the flexibility that we need to guarantee balance in search trees is to allow the nodes in our trees to hold more than one key. Spe- ci&#64257; cally, referring to the nodes in a standard BST as 2-nodes (they hold two links and one key), we now also allow 3-nodes, which hold three links and two keys. Both 2-nodes and 3-nodes have one link for each of the intervals subtended by its keys.</p><p attribs="{'xml:space': 'preserve'}" id="_07022" smilref="Title.smil#_07022"> 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07023" smilref="Title.smil#_07023"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07024" smilref="Title.smil#_07024"> 2-node</p><p attribs="{'xml:space': 'preserve'}" id="_07025" smilref="Title.smil#_07025"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07026" smilref="Title.smil#_07026"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07027" smilref="Title.smil#_07027"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07028" smilref="Title.smil#_07028"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07029" smilref="Title.smil#_07029"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07030" smilref="Title.smil#_07030"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07031" smilref="Title.smil#_07031"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07032" smilref="Title.smil#_07032"> null link</p><p attribs="{'xml:space': 'preserve'}" id="_07033" smilref="Title.smil#_07033"> Anatomy of a 2-3 search tree</p><p attribs="{'xml:space': 'preserve'}" id="_07034" smilref="Title.smil#_07034"> Definition. A 2-3 search tree is a tree that is either empty or </p><p attribs="{'xml:space': 'preserve'}" id="_07035" smilref="Title.smil#_07035"> A perfectly balanced 2-3 search tree is one whose null links are all the same distance from the root. To be concise, we use the term 2-3 tree to refer to a perfectly balanced 2-3 search tree (the term denotes a more general structure in other contexts). Later, we shall see efficient ways to define and implement the basic operations on 2-nodes, 3-nodes, and 2-3 trees; for now, let us assume that we can manipulate them conveniently and see how we can use them as search trees.</p><p attribs="{'xml:space': 'preserve'}" id="_07036" smilref="Title.smil#_07036"> 424</p><p attribs="{'xml:space': 'preserve'}" id="_07037" smilref="Title.smil#_07037" /><p attribs="{'xml:space': 'preserve'}" id="_07038" smilref="Title.smil#_07038"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07039" smilref="Title.smil#_07039"> 425</p><p attribs="{'xml:space': 'preserve'}" id="_07040" smilref="Title.smil#_07040"> successful search for H</p><p attribs="{'xml:space': 'preserve'}" id="_07041" smilref="Title.smil#_07041"> unsuccessful search for B</p><p attribs="{'xml:space': 'preserve'}" id="_07042" smilref="Title.smil#_07042"> H is less than M so look to the left</p><p attribs="{'xml:space': 'preserve'}" id="_07043" smilref="Title.smil#_07043"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07044" smilref="Title.smil#_07044"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07045" smilref="Title.smil#_07045"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07046" smilref="Title.smil#_07046"> B is less than M so look to the left</p><p attribs="{'xml:space': 'preserve'}" id="_07047" smilref="Title.smil#_07047"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07048" smilref="Title.smil#_07048"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07049" smilref="Title.smil#_07049"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07050" smilref="Title.smil#_07050"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07051" smilref="Title.smil#_07051"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07052" smilref="Title.smil#_07052"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07053" smilref="Title.smil#_07053"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07054" smilref="Title.smil#_07054"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07055" smilref="Title.smil#_07055"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07056" smilref="Title.smil#_07056"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07057" smilref="Title.smil#_07057"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07058" smilref="Title.smil#_07058"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07059" smilref="Title.smil#_07059"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07060" smilref="Title.smil#_07060"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07061" smilref="Title.smil#_07061"> H is between E and J so look in the middle</p><p attribs="{'xml:space': 'preserve'}" id="_07062" smilref="Title.smil#_07062"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07063" smilref="Title.smil#_07063"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07064" smilref="Title.smil#_07064"> B is less than E so look to the left</p><p attribs="{'xml:space': 'preserve'}" id="_07065" smilref="Title.smil#_07065"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07066" smilref="Title.smil#_07066"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07067" smilref="Title.smil#_07067"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07068" smilref="Title.smil#_07068"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07069" smilref="Title.smil#_07069"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07070" smilref="Title.smil#_07070"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07071" smilref="Title.smil#_07071"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07072" smilref="Title.smil#_07072"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07073" smilref="Title.smil#_07073"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07074" smilref="Title.smil#_07074"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07075" smilref="Title.smil#_07075"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07076" smilref="Title.smil#_07076"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07077" smilref="Title.smil#_07077"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07078" smilref="Title.smil#_07078"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07079" smilref="Title.smil#_07079"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07080" smilref="Title.smil#_07080"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07081" smilref="Title.smil#_07081"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07082" smilref="Title.smil#_07082"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07083" smilref="Title.smil#_07083"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07084" smilref="Title.smil#_07084"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07085" smilref="Title.smil#_07085"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07086" smilref="Title.smil#_07086"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07087" smilref="Title.smil#_07087"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07088" smilref="Title.smil#_07088"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07089" smilref="Title.smil#_07089"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07090" smilref="Title.smil#_07090"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07091" smilref="Title.smil#_07091"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07092" smilref="Title.smil#_07092"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07093" smilref="Title.smil#_07093"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07094" smilref="Title.smil#_07094"> found H so return value (search hit)</p><p attribs="{'xml:space': 'preserve'}" id="_07095" smilref="Title.smil#_07095"> B is between A and C so look in the middle link is null so B is not in the tree (search miss)</p><p attribs="{'xml:space': 'preserve'}" id="_07096" smilref="Title.smil#_07096"> Search hit (left) and search miss (right) in a 2-3 tree</p><p attribs="{'xml:space': 'preserve'}" id="_07097" smilref="Title.smil#_07097"> Search. The search algorithm for keys in a 2-3 tree directly generalizes the search algorithm for BSTs. To determine whether a key is in the tree, we compare it against the keys at the root. If it is equal to any of them, we have a search hit; otherwise, we follow the link from the root to the subtree corresponding to the interval of key values that could contain the search key. If that link is null, we have a search miss; otherwise we recursively search in that subtree.</p><p attribs="{'xml:space': 'preserve'}" id="_07098" smilref="Title.smil#_07098"> inserting K</p><p attribs="{'xml:space': 'preserve'}" id="_07099" smilref="Title.smil#_07099"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07100" smilref="Title.smil#_07100"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07101" smilref="Title.smil#_07101"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07102" smilref="Title.smil#_07102"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07103" smilref="Title.smil#_07103"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07104" smilref="Title.smil#_07104"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07105" smilref="Title.smil#_07105"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07106" smilref="Title.smil#_07106"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07107" smilref="Title.smil#_07107"> search for K ends here</p><p attribs="{'xml:space': 'preserve'}" id="_07108" smilref="Title.smil#_07108"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07109" smilref="Title.smil#_07109"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07110" smilref="Title.smil#_07110"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07111" smilref="Title.smil#_07111"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07112" smilref="Title.smil#_07112"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07113" smilref="Title.smil#_07113"> K L</p><p attribs="{'xml:space': 'preserve'}" id="_07114" smilref="Title.smil#_07114"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07115" smilref="Title.smil#_07115"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07116" smilref="Title.smil#_07116"> replace 2-node with new 3-node containing K</p><p attribs="{'xml:space': 'preserve'}" id="_07117" smilref="Title.smil#_07117"> Insert into a 2-node</p><p attribs="{'xml:space': 'preserve'}" id="_07118" smilref="Title.smil#_07118"> Insert into a 2-node. To insert a new node in a 2-3 tree, we might do an unsuccessful search and then hook on the node at the bottom, as we did with BSTs, but the new tree would not remain perfectly balanced. The primary reason that 2-3 trees are useful is that we can do insertions and still maintain perfect balance. It is easy to accomplish this task if the node at which the search terminates is a 2-node: we just replace the node with a 3-node containing its key and the new key to be inserted. If the node where the search terminates is a 3-node, we have more work to do.</p><p attribs="{'xml:space': 'preserve'}" id="_07119" smilref="Title.smil#_07119" /><p attribs="{'xml:space': 'preserve'}" id="_07120" smilref="Title.smil#_07120"> 426</p><p attribs="{'xml:space': 'preserve'}" id="_07121" smilref="Title.smil#_07121"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07122" smilref="Title.smil#_07122"> Insert into a tree consisting of a single 3-node. As a first warmup before considering</p><p attribs="{'xml:space': 'preserve'}" id="_07123" smilref="Title.smil#_07123"> the general case, suppose that we want to insert into a tiny 2-3 tree consisting of just a single 3-node. Such a tree has two keys, but no room for a new key in its one node. To be able to perform the insertion, we temporarily put the new key into a 4-node, a natural extension of our node type that has three keys and four links. Creating the 4-node is convenient because it is easy to convert it into a 2-3 tree made up of three 2-nodes, one with the middle key (at the root), one with the smallest of the three keys (pointed to by the left link of the root), and one with the largest of the three keys (pointed to by the right link of the root). Such a tree is a 3-node BST and also a perfectly balanced 2-3 search tree, with all the null links at the same distance from the root. Before the insertion, the height of the tree is 0; after the insertion, the height of the tree is 1. This case is simple, but it is worth considering because it illustrates height growth in 2-3 trees.</p><p attribs="{'xml:space': 'preserve'}" id="_07124" smilref="Title.smil#_07124"> Insert into a single 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07125" smilref="Title.smil#_07125"> split 4-node into this 2-3 tree</p><p attribs="{'xml:space': 'preserve'}" id="_07126" smilref="Title.smil#_07126"> make a 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07127" smilref="Title.smil#_07127"> no room for S</p><p attribs="{'xml:space': 'preserve'}" id="_07128" smilref="Title.smil#_07128"> A E S</p><p attribs="{'xml:space': 'preserve'}" id="_07129" smilref="Title.smil#_07129"> inserting S</p><p attribs="{'xml:space': 'preserve'}" id="_07130" smilref="Title.smil#_07130"> A E</p><p attribs="{'xml:space': 'preserve'}" id="_07131" smilref="Title.smil#_07131"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07132" smilref="Title.smil#_07132"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07133" smilref="Title.smil#_07133"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07134" smilref="Title.smil#_07134"> Insert into a 3-node whose parent is a 2-node. As a second warmup, suppose that the</p><p attribs="{'xml:space': 'preserve'}" id="_07135" smilref="Title.smil#_07135"> inserting Z</p><p attribs="{'xml:space': 'preserve'}" id="_07136" smilref="Title.smil#_07136"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07137" smilref="Title.smil#_07137"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07138" smilref="Title.smil#_07138"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07139" smilref="Title.smil#_07139"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07140" smilref="Title.smil#_07140"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07141" smilref="Title.smil#_07141"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07142" smilref="Title.smil#_07142"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07143" smilref="Title.smil#_07143"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07144" smilref="Title.smil#_07144"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07145" smilref="Title.smil#_07145"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07146" smilref="Title.smil#_07146"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07147" smilref="Title.smil#_07147"> search for Z ends at this 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07148" smilref="Title.smil#_07148"> search ends at a 3-node at the bottom whose parent is a 2-node. In this case, we can still make room for the new key while maintaining perfect balance in the tree, by making a temporary 4-node as just described, then splitting the 4-node as just described, but then, instead of creating a new node to hold the middle key, moving the middle key to the node&#8217;s parent. You can think of the transformation as replacing the link to the old 3-node in the parent by the middle key with links on either side to the new 2-nodes. By our assumption, there is room for doing so in the parent: the parent was a 2-node (with one key and two links) and becomes a 3-node (with two keys and three links). Also, this transformation does not affect the defining properties of (perfectly balanced) 2-3 trees. The tree remains ordered because the middle key is moved to the parent, and it remains perfectly balanced: if all null links are the same distance from the root before the insertion, they are all the same distance from the root after the insertion. Be certain that you understand this trans- formation&#8212;it is the crux of 2-3 tree dynamics.</p><p attribs="{'xml:space': 'preserve'}" id="_07149" smilref="Title.smil#_07149"> replace 2-node with new 3-node containing middle key</p><p attribs="{'xml:space': 'preserve'}" id="_07150" smilref="Title.smil#_07150"> replace 3-node with temporary 4-node containing Z</p><p attribs="{'xml:space': 'preserve'}" id="_07151" smilref="Title.smil#_07151"> split 4-node into two 2-nodes pass middle key to parent</p><p attribs="{'xml:space': 'preserve'}" id="_07152" smilref="Title.smil#_07152"> S X Z</p><p attribs="{'xml:space': 'preserve'}" id="_07153" smilref="Title.smil#_07153"> R X</p><p attribs="{'xml:space': 'preserve'}" id="_07154" smilref="Title.smil#_07154"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07155" smilref="Title.smil#_07155"> Z</p><p attribs="{'xml:space': 'preserve'}" id="_07156" smilref="Title.smil#_07156"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07157" smilref="Title.smil#_07157"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07158" smilref="Title.smil#_07158"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07159" smilref="Title.smil#_07159"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07160" smilref="Title.smil#_07160"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07161" smilref="Title.smil#_07161"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07162" smilref="Title.smil#_07162"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07163" smilref="Title.smil#_07163"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07164" smilref="Title.smil#_07164"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07165" smilref="Title.smil#_07165"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07166" smilref="Title.smil#_07166"> Insert into a 3-node whose parent is a 2-node</p><p attribs="{'xml:space': 'preserve'}" id="_07167" smilref="Title.smil#_07167" /><p attribs="{'xml:space': 'preserve'}" id="_07168" smilref="Title.smil#_07168"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07169" smilref="Title.smil#_07169"> 427</p><p attribs="{'xml:space': 'preserve'}" id="_07170" smilref="Title.smil#_07170"> Insert into a 3-node whose parent is a 3-node. Now</p><p attribs="{'xml:space': 'preserve'}" id="_07171" smilref="Title.smil#_07171"> inserting D</p><p attribs="{'xml:space': 'preserve'}" id="_07172" smilref="Title.smil#_07172"> suppose that the search ends at a node whose parent is a 3-node. Again, we make a temporary 4-node as just described, then split it and insert its middle key into the parent. The parent was a 3-node, so we replace it with a temporary new 4-node containing the middle key from the 4-node split. Then, we perform precisely the same transformation on that node. That is, we split the new 4-node and insert its middle key into its par- ent. Extending to the general case is clear: we continue up the tree, splitting 4-nodes and inserting their middle keys in their parents until reaching a 2-node, which we replace with a 3-node that does not need to be further split, or until reaching a 3-node at the root.</p><p attribs="{'xml:space': 'preserve'}" id="_07173" smilref="Title.smil#_07173"> search for D ends at this 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07174" smilref="Title.smil#_07174"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07175" smilref="Title.smil#_07175"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07176" smilref="Title.smil#_07176"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07177" smilref="Title.smil#_07177"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07178" smilref="Title.smil#_07178"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07179" smilref="Title.smil#_07179"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07180" smilref="Title.smil#_07180"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07181" smilref="Title.smil#_07181"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07182" smilref="Title.smil#_07182"> add new key D to 3-node to make temporary 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07183" smilref="Title.smil#_07183"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07184" smilref="Title.smil#_07184"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07185" smilref="Title.smil#_07185"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07186" smilref="Title.smil#_07186"> A C D</p><p attribs="{'xml:space': 'preserve'}" id="_07187" smilref="Title.smil#_07187"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07188" smilref="Title.smil#_07188"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07189" smilref="Title.smil#_07189"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07190" smilref="Title.smil#_07190"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07191" smilref="Title.smil#_07191"> add middle key C to 3-node to make temporary 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07192" smilref="Title.smil#_07192"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07193" smilref="Title.smil#_07193"> C E J</p><p attribs="{'xml:space': 'preserve'}" id="_07194" smilref="Title.smil#_07194"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07195" smilref="Title.smil#_07195"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07196" smilref="Title.smil#_07196"> D</p><p attribs="{'xml:space': 'preserve'}" id="_07197" smilref="Title.smil#_07197"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07198" smilref="Title.smil#_07198"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07199" smilref="Title.smil#_07199"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07200" smilref="Title.smil#_07200"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07201" smilref="Title.smil#_07201"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07202" smilref="Title.smil#_07202"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07203" smilref="Title.smil#_07203"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07204" smilref="Title.smil#_07204"> inserting D</p><p attribs="{'xml:space': 'preserve'}" id="_07205" smilref="Title.smil#_07205"> search for D ends at this 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07206" smilref="Title.smil#_07206"> split 4-node into two 2-nodes pass middle key to parent</p><p attribs="{'xml:space': 'preserve'}" id="_07207" smilref="Title.smil#_07207"> add middle key E to 2-node to make new 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07208" smilref="Title.smil#_07208"> Splitting the root. If we have 3-nodes along the whole path from the insertion point to the root, we end up with a temporary 4-node at the root. In this case we can proceed in precisely the same way as for insertion into a tree consisting of a single 3-node. We split the temporary 4-node into three 2-nodes, increasing the height of the tree by 1. Note that this last transformation preserves perfect balance because it is performed at the root.</p><p attribs="{'xml:space': 'preserve'}" id="_07209" smilref="Title.smil#_07209"> split 4-node into two 2-nodes pass middle key to parent</p><p attribs="{'xml:space': 'preserve'}" id="_07210" smilref="Title.smil#_07210"> add middle key C to 3-node to make temporary 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07211" smilref="Title.smil#_07211"> add new key D to 3-node to make temporary 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07212" smilref="Title.smil#_07212"> A C D</p><p attribs="{'xml:space': 'preserve'}" id="_07213" smilref="Title.smil#_07213"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07214" smilref="Title.smil#_07214"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07215" smilref="Title.smil#_07215"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07216" smilref="Title.smil#_07216"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07217" smilref="Title.smil#_07217"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07218" smilref="Title.smil#_07218"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07219" smilref="Title.smil#_07219"> D</p><p attribs="{'xml:space': 'preserve'}" id="_07220" smilref="Title.smil#_07220"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07221" smilref="Title.smil#_07221"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07222" smilref="Title.smil#_07222"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07223" smilref="Title.smil#_07223"> E M</p><p attribs="{'xml:space': 'preserve'}" id="_07224" smilref="Title.smil#_07224"> J</p><p attribs="{'xml:space': 'preserve'}" id="_07225" smilref="Title.smil#_07225"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07226" smilref="Title.smil#_07226"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07227" smilref="Title.smil#_07227"> C E J</p><p attribs="{'xml:space': 'preserve'}" id="_07228" smilref="Title.smil#_07228"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07229" smilref="Title.smil#_07229"> D</p><p attribs="{'xml:space': 'preserve'}" id="_07230" smilref="Title.smil#_07230"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07231" smilref="Title.smil#_07231"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07232" smilref="Title.smil#_07232"> split 4-node into two 2-nodes pass middle key to parent</p><p attribs="{'xml:space': 'preserve'}" id="_07233" smilref="Title.smil#_07233"> split 4-node into three 2-nodes increasing tree height by 1</p><p attribs="{'xml:space': 'preserve'}" id="_07234" smilref="Title.smil#_07234"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07235" smilref="Title.smil#_07235"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07236" smilref="Title.smil#_07236"> J</p><p attribs="{'xml:space': 'preserve'}" id="_07237" smilref="Title.smil#_07237"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07238" smilref="Title.smil#_07238"> D</p><p attribs="{'xml:space': 'preserve'}" id="_07239" smilref="Title.smil#_07239"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07240" smilref="Title.smil#_07240"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07241" smilref="Title.smil#_07241"> Splitting the root</p><p attribs="{'xml:space': 'preserve'}" id="_07242" smilref="Title.smil#_07242"> Local transformations. Splitting a temporary 4-node in a 2-3 tree involves one of six transformations, summarized at the bottom of the next page. The 4-node may be the root; it may be the left child or the right child of a 2-node; or it may be the left child, middle child, or right child of a 3-node. The basis of the 2-3 tree insertion algorithm is that all of these transformations are purely lo- cal: no part of the tree needs to be examined or modified other than the specified nodes and links. The number of</p><p attribs="{'xml:space': 'preserve'}" id="_07243" smilref="Title.smil#_07243"> Insert into a 3-node whose parent is a 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07244" smilref="Title.smil#_07244" /><p attribs="{'xml:space': 'preserve'}" id="_07245" smilref="Title.smil#_07245"> 428</p><p attribs="{'xml:space': 'preserve'}" id="_07246" smilref="Title.smil#_07246"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07247" smilref="Title.smil#_07247"> links changed for each transformation is bounded by a small constant. In particular, the transformations are effective when we find the specified patterns anywhere in the tree, not just at the bottom. Each of the transformations passes up one of the keys from a 4-node to that node&#8217;s parent in the tree and then restructures links ac- cordingly, without touching any other part of the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_07248" smilref="Title.smil#_07248"> Global properties. Moreover,</p><p attribs="{'xml:space': 'preserve'}" id="_07249" smilref="Title.smil#_07249"> a e</p><p attribs="{'xml:space': 'preserve'}" id="_07250" smilref="Title.smil#_07250"> b c d</p><p attribs="{'xml:space': 'preserve'}" id="_07251" smilref="Title.smil#_07251"> less than a</p><p attribs="{'xml:space': 'preserve'}" id="_07252" smilref="Title.smil#_07252"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07253" smilref="Title.smil#_07253"> between a and b</p><p attribs="{'xml:space': 'preserve'}" id="_07254" smilref="Title.smil#_07254"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07255" smilref="Title.smil#_07255"> between b and c</p><p attribs="{'xml:space': 'preserve'}" id="_07256" smilref="Title.smil#_07256"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07257" smilref="Title.smil#_07257"> between c and d</p><p attribs="{'xml:space': 'preserve'}" id="_07258" smilref="Title.smil#_07258"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07259" smilref="Title.smil#_07259"> between d and e</p><p attribs="{'xml:space': 'preserve'}" id="_07260" smilref="Title.smil#_07260"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07261" smilref="Title.smil#_07261"> greater than e</p><p attribs="{'xml:space': 'preserve'}" id="_07262" smilref="Title.smil#_07262"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07263" smilref="Title.smil#_07263"> a c e</p><p attribs="{'xml:space': 'preserve'}" id="_07264" smilref="Title.smil#_07264"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07265" smilref="Title.smil#_07265"> d</p><p attribs="{'xml:space': 'preserve'}" id="_07266" smilref="Title.smil#_07266"> less than a</p><p attribs="{'xml:space': 'preserve'}" id="_07267" smilref="Title.smil#_07267"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07268" smilref="Title.smil#_07268"> between a and b</p><p attribs="{'xml:space': 'preserve'}" id="_07269" smilref="Title.smil#_07269"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07270" smilref="Title.smil#_07270"> between b and c</p><p attribs="{'xml:space': 'preserve'}" id="_07271" smilref="Title.smil#_07271"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07272" smilref="Title.smil#_07272"> between c and d</p><p attribs="{'xml:space': 'preserve'}" id="_07273" smilref="Title.smil#_07273"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07274" smilref="Title.smil#_07274"> between d and e</p><p attribs="{'xml:space': 'preserve'}" id="_07275" smilref="Title.smil#_07275"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07276" smilref="Title.smil#_07276"> greater than e</p><p attribs="{'xml:space': 'preserve'}" id="_07277" smilref="Title.smil#_07277"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07278" smilref="Title.smil#_07278"> Splitting a 4-node is a local transformation that preserves order and perfect balance</p><p attribs="{'xml:space': 'preserve'}" id="_07279" smilref="Title.smil#_07279"> these local transformations preserve the global properties that the tree is ordered and perfectly balanced: the number of links on the path from the root to any null link is the same. For reference, a complete diagram illustrating this point for the case that the 4-node is the middle child of a 3-node is shown above. If the length of every path from a root to a null link is h before the transformation, then it is h after the transformation. Each transformation preserves this property, even while splitting the 4-node into two 2-nodes and while changing the parent from a 2-node to a 3-node or from a 3-node into a temporary 4-node. When the root splits into three 2-nodes, the length of every path from the root to a null link increases by 1. If you are not fully convinced, work Exercise 3.3.7, which asks you to</p><p attribs="{'xml:space': 'preserve'}" id="_07280" smilref="Title.smil#_07280"> root</p><p attribs="{'xml:space': 'preserve'}" id="_07281" smilref="Title.smil#_07281"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07282" smilref="Title.smil#_07282"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07283" smilref="Title.smil#_07283"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07284" smilref="Title.smil#_07284"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07285" smilref="Title.smil#_07285"> parent is a 2-node</p><p attribs="{'xml:space': 'preserve'}" id="_07286" smilref="Title.smil#_07286"> left</p><p attribs="{'xml:space': 'preserve'}" id="_07287" smilref="Title.smil#_07287"> d</p><p attribs="{'xml:space': 'preserve'}" id="_07288" smilref="Title.smil#_07288"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07289" smilref="Title.smil#_07289"> right</p><p attribs="{'xml:space': 'preserve'}" id="_07290" smilref="Title.smil#_07290"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07291" smilref="Title.smil#_07291"> b c d</p><p attribs="{'xml:space': 'preserve'}" id="_07292" smilref="Title.smil#_07292"> b d</p><p attribs="{'xml:space': 'preserve'}" id="_07293" smilref="Title.smil#_07293"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07294" smilref="Title.smil#_07294"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07295" smilref="Title.smil#_07295"> a c</p><p attribs="{'xml:space': 'preserve'}" id="_07296" smilref="Title.smil#_07296"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07297" smilref="Title.smil#_07297"> d</p><p attribs="{'xml:space': 'preserve'}" id="_07298" smilref="Title.smil#_07298"> parent is a 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07299" smilref="Title.smil#_07299"> left</p><p attribs="{'xml:space': 'preserve'}" id="_07300" smilref="Title.smil#_07300"> d e</p><p attribs="{'xml:space': 'preserve'}" id="_07301" smilref="Title.smil#_07301"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07302" smilref="Title.smil#_07302"> middle</p><p attribs="{'xml:space': 'preserve'}" id="_07303" smilref="Title.smil#_07303"> a e</p><p attribs="{'xml:space': 'preserve'}" id="_07304" smilref="Title.smil#_07304"> b c d</p><p attribs="{'xml:space': 'preserve'}" id="_07305" smilref="Title.smil#_07305"> right</p><p attribs="{'xml:space': 'preserve'}" id="_07306" smilref="Title.smil#_07306"> a b</p><p attribs="{'xml:space': 'preserve'}" id="_07307" smilref="Title.smil#_07307"> c d e</p><p attribs="{'xml:space': 'preserve'}" id="_07308" smilref="Title.smil#_07308"> Splitting a temporary 4-node in a 2-3 tree (summary)</p><p attribs="{'xml:space': 'preserve'}" id="_07309" smilref="Title.smil#_07309"> b d e</p><p attribs="{'xml:space': 'preserve'}" id="_07310" smilref="Title.smil#_07310"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07311" smilref="Title.smil#_07311"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07312" smilref="Title.smil#_07312"> a c e</p><p attribs="{'xml:space': 'preserve'}" id="_07313" smilref="Title.smil#_07313"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07314" smilref="Title.smil#_07314"> d</p><p attribs="{'xml:space': 'preserve'}" id="_07315" smilref="Title.smil#_07315"> a b d</p><p attribs="{'xml:space': 'preserve'}" id="_07316" smilref="Title.smil#_07316"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07317" smilref="Title.smil#_07317"> e</p><p attribs="{'xml:space': 'preserve'}" id="_07318" smilref="Title.smil#_07318" /><p attribs="{'xml:space': 'preserve'}" id="_07319" smilref="Title.smil#_07319"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07320" smilref="Title.smil#_07320"> 429</p><p attribs="{'xml:space': 'preserve'}" id="_07321" smilref="Title.smil#_07321"> extend the diagrams at the top of the previous page for the other five cases to illustrate the same point. Understanding that every local transformation preserves order and perfect balance in the whole tree is the key to understanding the algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_07322" smilref="Title.smil#_07322"> Unlike standard BSTs, which grow down from the top, 2-3 trees grow up from the bottom. If you take the time to carefully study the figure on the next page, which gives the sequence of 2-3 trees that is produced by our standard indexing test client and the sequence of 2-3 trees that is produced when the same keys are inserted in increasing or- der, you will have a good understanding of the way that 2-3 trees are built. Recall that in a BST, the increasing-order sequence for 10 keys results in a worst-case tree of height 9. In the 2-3 trees, the height is 2. The preceding description is sufficient to define a symbol-table implementation with 2-3 trees as the underlying data structure. Analyzing 2-3 trees is different from analyzing BSTs because our primary interest is in worst-case performance, as opposed to average-case performance (where we analyze expected performance under the ran- dom-key model). In symbol-table implementations, we normally have no control over the order in which clients insert keys into the table and worst-case analysis is one way to provide performance guarantees.</p><p attribs="{'xml:space': 'preserve'}" id="_07323" smilref="Title.smil#_07323"> Proposition F. Search and insert operations in a 2-3 tree with N keys are guaranteed to visit at most lg N nodes. Proof : The height of an N-node 2-3 tree is between &#9123;log3 N&#9126; = &#9123;(lg N)/(lg 3)&#9126; (if the tree is all 3-nodes) and &#9123;lg N&#9126; (if the tree is all 2-nodes) (see Exercise 3.3.4).</p><p attribs="{'xml:space': 'preserve'}" id="_07324" smilref="Title.smil#_07324"> Thus, we can guarantee good worst-case performance with 2-3 trees. The amount of time required at each node by each of the operations is bounded by a constant, and both operations examine nodes on just one path, so the total cost of any search or insert is guaranteed to be logarithmic. As you can see from comparing the 2-3 tree depicted at the bottom of page 431 with the BST formed from the same keys on page 405, a perfectly balanced 2-3 tree strikes a remarkably flat posture. For example, the height of a 2-3 tree that contains 1 billion keys is between 19 and 30. It is quite remarkable that we can guarantee to perform arbitrary search and insertion operations among 1 billion keys by examining at most 30 nodes. However, we are only part of the way to an implementation. Although it is possible to write code that performs transformations on distinct data types representing 2- and 3-nodes, most of the tasks that we have described are inconvenient to implement in</p><p attribs="{'xml:space': 'preserve'}" id="_07325" smilref="Title.smil#_07325" /><p attribs="{'xml:space': 'preserve'}" id="_07326" smilref="Title.smil#_07326"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07327" smilref="Title.smil#_07327"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07328" smilref="Title.smil#_07328"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07329" smilref="Title.smil#_07329"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07330" smilref="Title.smil#_07330"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07331" smilref="Title.smil#_07331"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07332" smilref="Title.smil#_07332"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07333" smilref="Title.smil#_07333"> E S</p><p attribs="{'xml:space': 'preserve'}" id="_07334" smilref="Title.smil#_07334"> R S</p><p attribs="{'xml:space': 'preserve'}" id="_07335" smilref="Title.smil#_07335"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07336" smilref="Title.smil#_07336"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07337" smilref="Title.smil#_07337"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07338" smilref="Title.smil#_07338"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07339" smilref="Title.smil#_07339"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07340" smilref="Title.smil#_07340"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07341" smilref="Title.smil#_07341"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07342" smilref="Title.smil#_07342"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07343" smilref="Title.smil#_07343"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07344" smilref="Title.smil#_07344"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07345" smilref="Title.smil#_07345"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07346" smilref="Title.smil#_07346"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07347" smilref="Title.smil#_07347"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07348" smilref="Title.smil#_07348"> R S</p><p attribs="{'xml:space': 'preserve'}" id="_07349" smilref="Title.smil#_07349"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07350" smilref="Title.smil#_07350"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07351" smilref="Title.smil#_07351"> E R</p><p attribs="{'xml:space': 'preserve'}" id="_07352" smilref="Title.smil#_07352"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07353" smilref="Title.smil#_07353"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07354" smilref="Title.smil#_07354"> E R</p><p attribs="{'xml:space': 'preserve'}" id="_07355" smilref="Title.smil#_07355"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07356" smilref="Title.smil#_07356"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07357" smilref="Title.smil#_07357"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07358" smilref="Title.smil#_07358"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07359" smilref="Title.smil#_07359"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07360" smilref="Title.smil#_07360"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07361" smilref="Title.smil#_07361"> E H</p><p attribs="{'xml:space': 'preserve'}" id="_07362" smilref="Title.smil#_07362"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07363" smilref="Title.smil#_07363"> E R</p><p attribs="{'xml:space': 'preserve'}" id="_07364" smilref="Title.smil#_07364"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07365" smilref="Title.smil#_07365"> H M</p><p attribs="{'xml:space': 'preserve'}" id="_07366" smilref="Title.smil#_07366"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07367" smilref="Title.smil#_07367"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07368" smilref="Title.smil#_07368"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07369" smilref="Title.smil#_07369"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07370" smilref="Title.smil#_07370"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07371" smilref="Title.smil#_07371"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07372" smilref="Title.smil#_07372"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07373" smilref="Title.smil#_07373"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07374" smilref="Title.smil#_07374"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07375" smilref="Title.smil#_07375"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07376" smilref="Title.smil#_07376"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07377" smilref="Title.smil#_07377"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07378" smilref="Title.smil#_07378"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07379" smilref="Title.smil#_07379"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07380" smilref="Title.smil#_07380"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07381" smilref="Title.smil#_07381"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07382" smilref="Title.smil#_07382"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07383" smilref="Title.smil#_07383"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07384" smilref="Title.smil#_07384"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07385" smilref="Title.smil#_07385"> H L</p><p attribs="{'xml:space': 'preserve'}" id="_07386" smilref="Title.smil#_07386"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07387" smilref="Title.smil#_07387"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07388" smilref="Title.smil#_07388"> L M</p><p attribs="{'xml:space': 'preserve'}" id="_07389" smilref="Title.smil#_07389"> P R</p><p attribs="{'xml:space': 'preserve'}" id="_07390" smilref="Title.smil#_07390"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07391" smilref="Title.smil#_07391"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07392" smilref="Title.smil#_07392"> C H</p><p attribs="{'xml:space': 'preserve'}" id="_07393" smilref="Title.smil#_07393"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07394" smilref="Title.smil#_07394"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07395" smilref="Title.smil#_07395"> C H</p><p attribs="{'xml:space': 'preserve'}" id="_07396" smilref="Title.smil#_07396"> M R</p><p attribs="{'xml:space': 'preserve'}" id="_07397" smilref="Title.smil#_07397"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07398" smilref="Title.smil#_07398"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07399" smilref="Title.smil#_07399"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07400" smilref="Title.smil#_07400"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07401" smilref="Title.smil#_07401"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07402" smilref="Title.smil#_07402"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07403" smilref="Title.smil#_07403"> M R</p><p attribs="{'xml:space': 'preserve'}" id="_07404" smilref="Title.smil#_07404"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07405" smilref="Title.smil#_07405"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07406" smilref="Title.smil#_07406"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07407" smilref="Title.smil#_07407"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07408" smilref="Title.smil#_07408"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07409" smilref="Title.smil#_07409"> standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_07410" smilref="Title.smil#_07410"> same keys in increasing order</p><p attribs="{'xml:space': 'preserve'}" id="_07411" smilref="Title.smil#_07411"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07412" smilref="Title.smil#_07412"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07413" smilref="Title.smil#_07413"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07414" smilref="Title.smil#_07414"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07415" smilref="Title.smil#_07415"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07416" smilref="Title.smil#_07416"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07417" smilref="Title.smil#_07417"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07418" smilref="Title.smil#_07418"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07419" smilref="Title.smil#_07419"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07420" smilref="Title.smil#_07420"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07421" smilref="Title.smil#_07421"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07422" smilref="Title.smil#_07422"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07423" smilref="Title.smil#_07423"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07424" smilref="Title.smil#_07424"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07425" smilref="Title.smil#_07425"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07426" smilref="Title.smil#_07426"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07427" smilref="Title.smil#_07427"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07428" smilref="Title.smil#_07428"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07429" smilref="Title.smil#_07429"> insert S</p><p attribs="{'xml:space': 'preserve'}" id="_07430" smilref="Title.smil#_07430"> insert A</p><p attribs="{'xml:space': 'preserve'}" id="_07431" smilref="Title.smil#_07431"> 2-3 construction traces</p><p attribs="{'xml:space': 'preserve'}" id="_07432" smilref="Title.smil#_07432"> 430</p><p attribs="{'xml:space': 'preserve'}" id="_07433" smilref="Title.smil#_07433"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07434" smilref="Title.smil#_07434" /><p attribs="{'xml:space': 'preserve'}" id="_07435" smilref="Title.smil#_07435"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07436" smilref="Title.smil#_07436"> 431</p><p attribs="{'xml:space': 'preserve'}" id="_07437" smilref="Title.smil#_07437"> this direct representation because there are numerous different cases to be handled. We would need to maintain two different types of nodes, compare search keys against each of the keys in the nodes, copy links and other information from one type of node to another, convert nodes from one type to another, and so forth. Not only is there a substantial amount of code involved, but the overhead incurred could make the algorithms slower than standard BST search and insert. The primary purpose of balancing is to provide insurance against a bad worst case, but we would prefer the overhead cost for that insurance to be low. Fortunately, as you will see, we can do the transformations in a uniform way using little overhead.</p><p attribs="{'xml:space': 'preserve'}" id="_07438" smilref="Title.smil#_07438"> Typical 2-3 tree built from random keys</p><p attribs="{'xml:space': 'preserve'}" id="_07439" smilref="Title.smil#_07439" /></level3><level3 id="_00055"><h3 id="ch3-s3-ss9" smilref="Title.smil#ch3-s3-ss9" xml:space="preserve">Red-black BSTs</h3><pagenum id="p445" page="normal" smilref="Title.smil#p445" /><p attribs="{'xml:space': 'preserve'}" id="_07440" smilref="Title.smil#_07440"> 432</p><p attribs="{'xml:space': 'preserve'}" id="_07441" smilref="Title.smil#_07441"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07442" smilref="Title.smil#_07442"> Red-black BSTs The insertion algorithm for 2-3 trees just described is not difficult to understand; now, we will see that it is also not difficult to implement. We will consider a simple representation known as a red-black BST that leads to a natural imple- mentation. In the end, not much code is required, but understanding how and why the code gets the job done requires a careful look.</p><p attribs="{'xml:space': 'preserve'}" id="_07443" smilref="Title.smil#_07443"> 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07444" smilref="Title.smil#_07444"> a b</p><p attribs="{'xml:space': 'preserve'}" id="_07445" smilref="Title.smil#_07445"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07446" smilref="Title.smil#_07446"> greater than b</p><p attribs="{'xml:space': 'preserve'}" id="_07447" smilref="Title.smil#_07447"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07448" smilref="Title.smil#_07448"> less than a</p><p attribs="{'xml:space': 'preserve'}" id="_07449" smilref="Title.smil#_07449"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07450" smilref="Title.smil#_07450"> between a and b</p><p attribs="{'xml:space': 'preserve'}" id="_07451" smilref="Title.smil#_07451"> Encoding 3-nodes. The basic idea behind red-black BSTs is to encode 2-3 trees by starting with standard BSTs (which are made up of 2-nodes) and adding extra information to encode 3-nodes. We think of the links as being of two different types: red links, which bind together two 2-nodes to represent 3-nodes, and black links, which bind together the 2-3 tree. Speci&#64257; cally, we represent 3-nodes as two 2-nodes connected by a single red link that leans left (one of the 2-nodes is the left child of the other). One advantage of using such a representation is that it allows us to use our get() code for standard BST search without modi&#64257; cation. Given any 2-3 tree, we can immediately derive a corresponding BST, just by converting each node as speci&#64257; ed. We refer to BSTs that represent 2-3 trees in this way as red-black BSTs.</p><p attribs="{'xml:space': 'preserve'}" id="_07452" smilref="Title.smil#_07452"> ... ... Encoding a 3-node with two 2-nodes connected by a left-leaning red link</p><p attribs="{'xml:space': 'preserve'}" id="_07453" smilref="Title.smil#_07453"> greater than b</p><p attribs="{'xml:space': 'preserve'}" id="_07454" smilref="Title.smil#_07454"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07455" smilref="Title.smil#_07455"> less than a</p><p attribs="{'xml:space': 'preserve'}" id="_07456" smilref="Title.smil#_07456"> between a and b</p><p attribs="{'xml:space': 'preserve'}" id="_07457" smilref="Title.smil#_07457"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_07458" smilref="Title.smil#_07458"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07459" smilref="Title.smil#_07459"> An equivalent defi nition. Another way to proceed is to define red-black BSTs as BSTs having red and black links and satisfying the following three restrictions: </p><p attribs="{'xml:space': 'preserve'}" id="_07460" smilref="Title.smil#_07460"> A 1-1 correspondence. If we draw the red links horizontally in a red-black BST, all of the null links are the same distance from the root, and if we then collapse together the nodes connected by red links, the result is a 2-3 tree. Conversely, if we draw 3-nodes in</p><p attribs="{'xml:space': 'preserve'}" id="_07461" smilref="Title.smil#_07461"> A red-black tree with horizontal red links is a 2-3 tree</p><p attribs="{'xml:space': 'preserve'}" id="_07462" smilref="Title.smil#_07462" /><pagenum id="p446" page="normal" smilref="Title.smil#p446" /><p attribs="{'xml:space': 'preserve'}" id="_07463" smilref="Title.smil#_07463"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07464" smilref="Title.smil#_07464"> 433</p><p attribs="{'xml:space': 'preserve'}" id="_07465" smilref="Title.smil#_07465"> red-black BST</p><p attribs="{'xml:space': 'preserve'}" id="_07466" smilref="Title.smil#_07466"> J</p><p attribs="{'xml:space': 'preserve'}" id="_07467" smilref="Title.smil#_07467"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07468" smilref="Title.smil#_07468"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07469" smilref="Title.smil#_07469"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07470" smilref="Title.smil#_07470"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07471" smilref="Title.smil#_07471"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07472" smilref="Title.smil#_07472"> horizontal red links</p><p attribs="{'xml:space': 'preserve'}" id="_07473" smilref="Title.smil#_07473"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07474" smilref="Title.smil#_07474"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07475" smilref="Title.smil#_07475"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07476" smilref="Title.smil#_07476"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07477" smilref="Title.smil#_07477"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07478" smilref="Title.smil#_07478"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07479" smilref="Title.smil#_07479"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07480" smilref="Title.smil#_07480"> J</p><p attribs="{'xml:space': 'preserve'}" id="_07481" smilref="Title.smil#_07481"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07482" smilref="Title.smil#_07482"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07483" smilref="Title.smil#_07483"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07484" smilref="Title.smil#_07484"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07485" smilref="Title.smil#_07485"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07486" smilref="Title.smil#_07486"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07487" smilref="Title.smil#_07487"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07488" smilref="Title.smil#_07488"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07489" smilref="Title.smil#_07489"> 2-3 tree</p><p attribs="{'xml:space': 'preserve'}" id="_07490" smilref="Title.smil#_07490"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07491" smilref="Title.smil#_07491"> E J</p><p attribs="{'xml:space': 'preserve'}" id="_07492" smilref="Title.smil#_07492"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07493" smilref="Title.smil#_07493"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07494" smilref="Title.smil#_07494"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07495" smilref="Title.smil#_07495"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07496" smilref="Title.smil#_07496"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07497" smilref="Title.smil#_07497"> S X</p><p attribs="{'xml:space': 'preserve'}" id="_07498" smilref="Title.smil#_07498"> a 2-3 tree as two 2-nodes connected by a red link that leans left, then no node has two red links connected to it, and the tree has perfect black balance, since the black links correspond to the 2-3 tree links, which are perfectly balanced by defi nition. Whichever way we choose to define them, red-black BSTs are both BSTs and 2-3 trees. Thus, if we can implement the 2-3 tree insertion algorithm by maintaining the 1-1 correspondence, then we get the best of both worlds: the simple and efficient search method from standard BSTs and the efficient inser- tion-balancing method from 2-3 trees.</p><p attribs="{'xml:space': 'preserve'}" id="_07499" smilref="Title.smil#_07499"> 1-1 correspondence between red-black BSTs and 2-3 trees</p><p attribs="{'xml:space': 'preserve'}" id="_07500" smilref="Title.smil#_07500"> Color representation. For convenience, since</p><p attribs="{'xml:space': 'preserve'}" id="_07501" smilref="Title.smil#_07501"> each node is pointed to by precisely one link (from its parent), we encode the color of links in nodes, by adding a boolean instance variable color to our Node data type, which is true if the link from the parent is red and false if it is black. By convention, null links are black. For clarity in our code, we define constants RED and BLACK for use in setting and testing this variable. We use a private method isRed() to test the color of a node&#8217;s link to its parent. When we refer to the color of a node, we are referring to the color of the link pointing to it, and vice versa.</p><p attribs="{'xml:space': 'preserve'}" id="_07502" smilref="Title.smil#_07502"> Rotations. The implementation that we will consider might allow right-leaning red links or two red links in a row during an operation, but it always corrects these conditions before com- pletion, through judicious use of an operation called rotation that switches the orientation of</p><p attribs="{'xml:space': 'preserve'}" id="_07503" smilref="Title.smil#_07503"> h.left.color is RED</p><p attribs="{'xml:space': 'preserve'}" id="_07504" smilref="Title.smil#_07504"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07505" smilref="Title.smil#_07505"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07506" smilref="Title.smil#_07506"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07507" smilref="Title.smil#_07507"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07508" smilref="Title.smil#_07508"> D</p><p attribs="{'xml:space': 'preserve'}" id="_07509" smilref="Title.smil#_07509"> J</p><p attribs="{'xml:space': 'preserve'}" id="_07510" smilref="Title.smil#_07510"> G</p><p attribs="{'xml:space': 'preserve'}" id="_07511" smilref="Title.smil#_07511"> h.right.color is BLACK</p><p attribs="{'xml:space': 'preserve'}" id="_07512" smilref="Title.smil#_07512"> private static final boolean RED = true; private static final boolean BLACK = false;</p><p attribs="{'xml:space': 'preserve'}" id="_07513" smilref="Title.smil#_07513"> private class Node {</p><p attribs="{'xml:space': 'preserve'}" id="_07514" smilref="Title.smil#_07514"> Key key; // key Value val; // associated data Node left, right; // subtrees int N; // # nodes in this subtree boolean color; // color of link from // parent to this node</p><p attribs="{'xml:space': 'preserve'}" id="_07515" smilref="Title.smil#_07515"> Node(Key key, Value val, int N, boolean color) { this.key = key; this.val = val; this.N = N; this.color = color; }</p><p attribs="{'xml:space': 'preserve'}" id="_07516" smilref="Title.smil#_07516"> }</p><p attribs="{'xml:space': 'preserve'}" id="_07517" smilref="Title.smil#_07517"> private boolean isRed(Node x) {</p><p attribs="{'xml:space': 'preserve'}" id="_07518" smilref="Title.smil#_07518"> if (x == null) return false; return x.color == RED;</p><p attribs="{'xml:space': 'preserve'}" id="_07519" smilref="Title.smil#_07519"> }</p><p attribs="{'xml:space': 'preserve'}" id="_07520" smilref="Title.smil#_07520"> Node representation for red-black BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_07521" smilref="Title.smil#_07521" /><pagenum id="p447" page="normal" smilref="Title.smil#p447" /><p attribs="{'xml:space': 'preserve'}" id="_07522" smilref="Title.smil#_07522"> 434</p><p attribs="{'xml:space': 'preserve'}" id="_07523" smilref="Title.smil#_07523"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07524" smilref="Title.smil#_07524"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07525" smilref="Title.smil#_07525"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07526" smilref="Title.smil#_07526"> less than E</p><p attribs="{'xml:space': 'preserve'}" id="_07527" smilref="Title.smil#_07527"> could be right or left, red or black</p><p attribs="{'xml:space': 'preserve'}" id="_07528" smilref="Title.smil#_07528"> x</p><p attribs="{'xml:space': 'preserve'}" id="_07529" smilref="Title.smil#_07529"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07530" smilref="Title.smil#_07530"> between E and S</p><p attribs="{'xml:space': 'preserve'}" id="_07531" smilref="Title.smil#_07531"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07532" smilref="Title.smil#_07532"> Node rotateLeft(Node h) { Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_07533" smilref="Title.smil#_07533"> x</p><p attribs="{'xml:space': 'preserve'}" id="_07534" smilref="Title.smil#_07534"> red links. First, suppose that we have a right-leaning red link that needs to be rotated to lean to the left (see the diagram at left). This operation is called a left rotation. We organize the computation as a method that takes a link to a red-black BST as argument and, assuming that link to be to a Node h whose right link is red, makes the necessary adjustments and returns a link to a node that is the root of a red-black BST for the same set of keys whose left link is red. If you check each of the lines of code against the before/after drawings in the diagram, you will find this operation is easy to understand: we are switching from having the smaller of the two keys at the root to having the larger of the two keys at the root. Implementing a right rotation that converts a left-leaning red link to a right-leaning one amounts to the same code, with left and right interchanged (see the diagram at right below).</p><p attribs="{'xml:space': 'preserve'}" id="_07535" smilref="Title.smil#_07535"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07536" smilref="Title.smil#_07536"> Resetting the link in the parent after a rotation. Whether left or</p><p attribs="{'xml:space': 'preserve'}" id="_07537" smilref="Title.smil#_07537"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07538" smilref="Title.smil#_07538"> between E and S</p><p attribs="{'xml:space': 'preserve'}" id="_07539" smilref="Title.smil#_07539"> right, every rotation leaves us with a link. We always use the link returned by rotateRight() or rotateLeft() to reset the appropriate link in the parent (or the root of the tree). That may be a right or a left link, but we can always use it to reset the link in the parent. This link may be red or black&#8212;both rotateLeft() and rotateRight() preserve its color by setting x.color to h.color. This might allow two red links in a row to occur within the tree, but our algorithms will also use rotations to correct this condition when it arises. For example, the code</p><p attribs="{'xml:space': 'preserve'}" id="_07540" smilref="Title.smil#_07540"> less than E</p><p attribs="{'xml:space': 'preserve'}" id="_07541" smilref="Title.smil#_07541"> between S and E</p><p attribs="{'xml:space': 'preserve'}" id="_07542" smilref="Title.smil#_07542"> x</p><p attribs="{'xml:space': 'preserve'}" id="_07543" smilref="Title.smil#_07543"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07544" smilref="Title.smil#_07544"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07545" smilref="Title.smil#_07545"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07546" smilref="Title.smil#_07546"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07547" smilref="Title.smil#_07547"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07548" smilref="Title.smil#_07548"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07549" smilref="Title.smil#_07549"> less than E</p><p attribs="{'xml:space': 'preserve'}" id="_07550" smilref="Title.smil#_07550"> Left rotate (right link of h)</p><p attribs="{'xml:space': 'preserve'}" id="_07551" smilref="Title.smil#_07551"> h = rotateLeft(h);</p><p attribs="{'xml:space': 'preserve'}" id="_07552" smilref="Title.smil#_07552"> rotates left a right-leaning red link that is to the right of node h, setting h to point to the root of the resulting subtree (which contains all the same nodes as the subtree pointed to by h before the rotation, but a different root). The ease of writing this type of code is the primary reason we use recursive implementations of BST methods, as it makes doing rotations an easy supplement to normal in- sertion, as you will see.</p><p attribs="{'xml:space': 'preserve'}" id="_07553" smilref="Title.smil#_07553"> Node rotateRight(Node h) { Node x = h.left; h.left = x.right; x.right = h; x.color = h.color; h.color = RED; x.N = h.N; h.N = 1 + size(h.left) + size(h.right); return x; } x</p><p attribs="{'xml:space': 'preserve'}" id="_07554" smilref="Title.smil#_07554"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07555" smilref="Title.smil#_07555"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07556" smilref="Title.smil#_07556"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07557" smilref="Title.smil#_07557"> less than E</p><p attribs="{'xml:space': 'preserve'}" id="_07558" smilref="Title.smil#_07558"> between S and E</p><p attribs="{'xml:space': 'preserve'}" id="_07559" smilref="Title.smil#_07559"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07560" smilref="Title.smil#_07560"> Right rotate (left link of h)</p><p attribs="{'xml:space': 'preserve'}" id="_07561" smilref="Title.smil#_07561" /><pagenum id="p448" page="normal" smilref="Title.smil#p448" /><p attribs="{'xml:space': 'preserve'}" id="_07562" smilref="Title.smil#_07562"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07563" smilref="Title.smil#_07563"> 435</p><p attribs="{'xml:space': 'preserve'}" id="_07564" smilref="Title.smil#_07564"> We can use rotations to help maintain the 1-1 correspondence between 2-3 trees and red-black BSTs as new keys are inserted because they preserve the two defining properties of red-black BSTs: order and perfect black balance. That is, we can use rotations on a red-black BST without having to worry about losing its order or its perfect black balance. Next, we see how to use rotations to preserve the other two defining properties of red- black BSTs (no consecutive red links on any path and no right-leaning red links). We warm up with some easy cases. Insert into a single 2-node. A red-black BST with 1 key is just a single 2-node. Inserting the second key immediately shows the need for having a rotation operation. If the new key is smaller than the key in the tree, we just make a new (red) node with the new key and we are done: we have a red-black BST that is equivalent to a single 3-node. But if the new key is larger than the key in the tree, then attaching a new (red) node gives a right-leaning red link, and the code root = rotateLeft(root); completes the insertion by rotating the red link to the left and updating the tree root link. The result in both cases is the red-black representation of a single 3-node, with two keys, one left-leaning red link, and black height 1.</p><p attribs="{'xml:space': 'preserve'}" id="_07565" smilref="Title.smil#_07565"> Insert into a 2-node at the bottom. We insert keys into a red-black BST</p><p attribs="{'xml:space': 'preserve'}" id="_07566" smilref="Title.smil#_07566"> as usual into a BST, adding a new node at the bottom (respecting the or- der), but always connected to its parent with a red link. If the parent is a 2-node, then the same two cases just discussed are effective. If the new node is attached to the left link, the parent simply becomes a 3-node; if it is attached to a right link, we have a 3-node leaning the wrong way, but a left rotation finishes the job.</p><p attribs="{'xml:space': 'preserve'}" id="_07567" smilref="Title.smil#_07567"> Insert into a tree with two keys (in a 3-node). This case reduces to three</p><p attribs="{'xml:space': 'preserve'}" id="_07568" smilref="Title.smil#_07568"> subcases: the new key is either less than both keys in the tree, between them, or greater than both of them. Each of the cases introduces a node with two red links connected to it; our goal is to correct this condition. </p><p attribs="{'xml:space': 'preserve'}" id="_07569" smilref="Title.smil#_07569"> left</p><p attribs="{'xml:space': 'preserve'}" id="_07570" smilref="Title.smil#_07570"> root</p><p attribs="{'xml:space': 'preserve'}" id="_07571" smilref="Title.smil#_07571"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07572" smilref="Title.smil#_07572"> search ends at this null link root</p><p attribs="{'xml:space': 'preserve'}" id="_07573" smilref="Title.smil#_07573"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07574" smilref="Title.smil#_07574"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07575" smilref="Title.smil#_07575"> red link to new node containing a converts 2-node to 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07576" smilref="Title.smil#_07576"> right</p><p attribs="{'xml:space': 'preserve'}" id="_07577" smilref="Title.smil#_07577"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07578" smilref="Title.smil#_07578"> root search ends at this null link</p><p attribs="{'xml:space': 'preserve'}" id="_07579" smilref="Title.smil#_07579"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07580" smilref="Title.smil#_07580"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07581" smilref="Title.smil#_07581"> attached new node with red link</p><p attribs="{'xml:space': 'preserve'}" id="_07582" smilref="Title.smil#_07582"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07583" smilref="Title.smil#_07583"> root</p><p attribs="{'xml:space': 'preserve'}" id="_07584" smilref="Title.smil#_07584"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07585" smilref="Title.smil#_07585"> rotated left to make a legal 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_07586" smilref="Title.smil#_07586"> Insert into a single 2-node (two cases)</p><p attribs="{'xml:space': 'preserve'}" id="_07587" smilref="Title.smil#_07587"> insert C</p><p attribs="{'xml:space': 'preserve'}" id="_07588" smilref="Title.smil#_07588"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07589" smilref="Title.smil#_07589"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07590" smilref="Title.smil#_07590"> add new node here</p><p attribs="{'xml:space': 'preserve'}" id="_07591" smilref="Title.smil#_07591"> right link red so rotate left</p><p attribs="{'xml:space': 'preserve'}" id="_07592" smilref="Title.smil#_07592"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07593" smilref="Title.smil#_07593"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07594" smilref="Title.smil#_07594"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07595" smilref="Title.smil#_07595"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07596" smilref="Title.smil#_07596"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07597" smilref="Title.smil#_07597"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07598" smilref="Title.smil#_07598"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07599" smilref="Title.smil#_07599"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07600" smilref="Title.smil#_07600"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07601" smilref="Title.smil#_07601"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07602" smilref="Title.smil#_07602"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07603" smilref="Title.smil#_07603"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07604" smilref="Title.smil#_07604"> Insert into a 2-node at the bottom</p><p attribs="{'xml:space': 'preserve'}" id="_07605" smilref="Title.smil#_07605" /><pagenum id="p449" page="normal" smilref="Title.smil#p449" /><p attribs="{'xml:space': 'preserve'}" id="_07606" smilref="Title.smil#_07606"> 436</p><p attribs="{'xml:space': 'preserve'}" id="_07607" smilref="Title.smil#_07607"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07608" smilref="Title.smil#_07608"> </p><p attribs="{'xml:space': 'preserve'}" id="_07609" smilref="Title.smil#_07609"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07610" smilref="Title.smil#_07610"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07611" smilref="Title.smil#_07611"> could be left or right link</p><p attribs="{'xml:space': 'preserve'}" id="_07612" smilref="Title.smil#_07612"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07613" smilref="Title.smil#_07613"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07614" smilref="Title.smil#_07614"> less than A</p><p attribs="{'xml:space': 'preserve'}" id="_07615" smilref="Title.smil#_07615"> between A and E</p><p attribs="{'xml:space': 'preserve'}" id="_07616" smilref="Title.smil#_07616"> between E and S</p><p attribs="{'xml:space': 'preserve'}" id="_07617" smilref="Title.smil#_07617"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07618" smilref="Title.smil#_07618"> void flipColors(Node h) { h.color = RED; h.left.color = BLACK; h.right.color = BLACK; }</p><p attribs="{'xml:space': 'preserve'}" id="_07619" smilref="Title.smil#_07619"> red link attaches middle node to parent</p><p attribs="{'xml:space': 'preserve'}" id="_07620" smilref="Title.smil#_07620"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07621" smilref="Title.smil#_07621"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07622" smilref="Title.smil#_07622"> black links split to 2-nodes</p><p attribs="{'xml:space': 'preserve'}" id="_07623" smilref="Title.smil#_07623"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07624" smilref="Title.smil#_07624"> less than A</p><p attribs="{'xml:space': 'preserve'}" id="_07625" smilref="Title.smil#_07625"> between A and E</p><p attribs="{'xml:space': 'preserve'}" id="_07626" smilref="Title.smil#_07626"> between E and S</p><p attribs="{'xml:space': 'preserve'}" id="_07627" smilref="Title.smil#_07627"> greater than S</p><p attribs="{'xml:space': 'preserve'}" id="_07628" smilref="Title.smil#_07628"> Flipping colors to split a 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_07629" smilref="Title.smil#_07629"> larger</p><p attribs="{'xml:space': 'preserve'}" id="_07630" smilref="Title.smil#_07630"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07631" smilref="Title.smil#_07631"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07632" smilref="Title.smil#_07632"> search ends at this null link</p><p attribs="{'xml:space': 'preserve'}" id="_07633" smilref="Title.smil#_07633"> smaller</p><p attribs="{'xml:space': 'preserve'}" id="_07634" smilref="Title.smil#_07634"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07635" smilref="Title.smil#_07635"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07636" smilref="Title.smil#_07636"> between</p><p attribs="{'xml:space': 'preserve'}" id="_07637" smilref="Title.smil#_07637"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07638" smilref="Title.smil#_07638"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07639" smilref="Title.smil#_07639"> search ends at this null link</p><p attribs="{'xml:space': 'preserve'}" id="_07640" smilref="Title.smil#_07640"> search ends at this null link</p><p attribs="{'xml:space': 'preserve'}" id="_07641" smilref="Title.smil#_07641"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07642" smilref="Title.smil#_07642"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07643" smilref="Title.smil#_07643"> attached new node with red link</p><p attribs="{'xml:space': 'preserve'}" id="_07644" smilref="Title.smil#_07644"> rotated right</p><p attribs="{'xml:space': 'preserve'}" id="_07645" smilref="Title.smil#_07645"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07646" smilref="Title.smil#_07646"> colors flipped to black</p><p attribs="{'xml:space': 'preserve'}" id="_07647" smilref="Title.smil#_07647"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07648" smilref="Title.smil#_07648"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07649" smilref="Title.smil#_07649"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07650" smilref="Title.smil#_07650"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07651" smilref="Title.smil#_07651"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07652" smilref="Title.smil#_07652"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07653" smilref="Title.smil#_07653"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07654" smilref="Title.smil#_07654"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07655" smilref="Title.smil#_07655"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07656" smilref="Title.smil#_07656"> attached new node with red link</p><p attribs="{'xml:space': 'preserve'}" id="_07657" smilref="Title.smil#_07657"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07658" smilref="Title.smil#_07658"> rotated left</p><p attribs="{'xml:space': 'preserve'}" id="_07659" smilref="Title.smil#_07659"> rotated right</p><p attribs="{'xml:space': 'preserve'}" id="_07660" smilref="Title.smil#_07660"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07661" smilref="Title.smil#_07661"> colors flipped to black</p><p attribs="{'xml:space': 'preserve'}" id="_07662" smilref="Title.smil#_07662"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07663" smilref="Title.smil#_07663"> attached new node with red link</p><p attribs="{'xml:space': 'preserve'}" id="_07664" smilref="Title.smil#_07664"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07665" smilref="Title.smil#_07665"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07666" smilref="Title.smil#_07666"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07667" smilref="Title.smil#_07667"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07668" smilref="Title.smil#_07668"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07669" smilref="Title.smil#_07669"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07670" smilref="Title.smil#_07670"> colors flipped to black</p><p attribs="{'xml:space': 'preserve'}" id="_07671" smilref="Title.smil#_07671"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07672" smilref="Title.smil#_07672"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07673" smilref="Title.smil#_07673"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07674" smilref="Title.smil#_07674"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07675" smilref="Title.smil#_07675"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07676" smilref="Title.smil#_07676"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07677" smilref="Title.smil#_07677"> Insert into a single 3-node (three cases)</p><p attribs="{'xml:space': 'preserve'}" id="_07678" smilref="Title.smil#_07678"> again have two red links in a row, a right-leaning one below a left-leaning one, which we can reduce to the previous case (two red links in a row, to the left) by rotating left the bottom link. In summary, we achieve the desired result by doing zero, one, or two rotations followed by flipping the colors of the two children of the root. As with 2-3 trees, be certain that you understand these transformations, as they are the key to red-black tree dynamics.</p><p attribs="{'xml:space': 'preserve'}" id="_07679" smilref="Title.smil#_07679"> Flipping colors. To flip the colors of the two red children of a node, we use a method flipColors(), shown at left. In addition to flipping the colors of the children from red to black, we also flip the color of the parent from black to red. A critically important characteristic of this operation is that, like rotations, it is a local transformation that preserves perfect black balance in the tree. Moreover, this convention immediately leads us to a full implementation, as we describe next.</p><p attribs="{'xml:space': 'preserve'}" id="_07680" smilref="Title.smil#_07680" /><pagenum id="p450" page="normal" smilref="Title.smil#p450" /><p attribs="{'xml:space': 'preserve'}" id="_07681" smilref="Title.smil#_07681"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07682" smilref="Title.smil#_07682"> 437</p><p attribs="{'xml:space': 'preserve'}" id="_07683" smilref="Title.smil#_07683"> Keeping the root black. In the case just considered (insert into a single 3-node), the color flip will color the root red. This can also happen in larger trees. Strictly speaking, a red root implies that the root is part of a 3-node, but that is not the case, so we color the root black after each insertion. Note that the black height of the tree increases by 1 whenever the color of the color of the root is flipped from black to red.</p><p attribs="{'xml:space': 'preserve'}" id="_07684" smilref="Title.smil#_07684"> inserting H</p><p attribs="{'xml:space': 'preserve'}" id="_07685" smilref="Title.smil#_07685"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07686" smilref="Title.smil#_07686"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07687" smilref="Title.smil#_07687"> Insert into a 3-node at the bottom. Now suppose that</p><p attribs="{'xml:space': 'preserve'}" id="_07688" smilref="Title.smil#_07688"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07689" smilref="Title.smil#_07689"> R S</p><p attribs="{'xml:space': 'preserve'}" id="_07690" smilref="Title.smil#_07690"> we add a new node at the bottom that is connected to a 3-node. The same three cases just discussed arise. Either the new link is connected to the right link of the 3-node (in which case we just flip colors) or to the left link of the 3-node (in which case we need to rotate the top link right and flip colors) or to the middle link of the 3-node (in which case we rotate left the bottom link, then rotate right the top link, then flip colors). Flipping the colors makes the link to the middle node red, which amounts to passing it up to its parent, putting us back in the same situation with respect to the parent, which we can fix by moving up the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_07691" smilref="Title.smil#_07691"> Passing a red link up the tree. The 2-3 tree insertion</p><p attribs="{'xml:space': 'preserve'}" id="_07692" smilref="Title.smil#_07692"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07693" smilref="Title.smil#_07693"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07694" smilref="Title.smil#_07694"> H R S</p><p attribs="{'xml:space': 'preserve'}" id="_07695" smilref="Title.smil#_07695"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07696" smilref="Title.smil#_07696"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07697" smilref="Title.smil#_07697"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07698" smilref="Title.smil#_07698"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07699" smilref="Title.smil#_07699"> add new node here</p><p attribs="{'xml:space': 'preserve'}" id="_07700" smilref="Title.smil#_07700"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07701" smilref="Title.smil#_07701"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07702" smilref="Title.smil#_07702"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07703" smilref="Title.smil#_07703"> two lefts in a row so rotate right</p><p attribs="{'xml:space': 'preserve'}" id="_07704" smilref="Title.smil#_07704"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07705" smilref="Title.smil#_07705"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07706" smilref="Title.smil#_07706"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07707" smilref="Title.smil#_07707"> both children red so flip colors</p><p attribs="{'xml:space': 'preserve'}" id="_07708" smilref="Title.smil#_07708"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07709" smilref="Title.smil#_07709"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07710" smilref="Title.smil#_07710"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07711" smilref="Title.smil#_07711"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07712" smilref="Title.smil#_07712"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07713" smilref="Title.smil#_07713"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07714" smilref="Title.smil#_07714"> right link red so rotate left</p><p attribs="{'xml:space': 'preserve'}" id="_07715" smilref="Title.smil#_07715"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07716" smilref="Title.smil#_07716"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07717" smilref="Title.smil#_07717"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07718" smilref="Title.smil#_07718"> algorithm calls for us to split the 3-node, passing the middle key up to be inserted into its parent, continuing until encountering a 2-node or the root. In every case we have considered, we precisely accomplish this objec- tive: after doing any necessary rotations, we flip colors, which turns the middle node to red. From the point of view of the parent of that node, that link becoming red can be handled in precisely the same manner as if the red link came from attaching a new node: we pass up a red link to the middle node. The three cases summarized in the diagram on the next page precisely capture the operations necessary in a red-black tree to implement the key operation in 2-3 tree insertion: to insert into a 3-node, create a temporary 4-node, split it, and pass a red link to the middle key up to its parent. Continuing the same process, we pass a red link up the tree until reaching a 2-node or the root.</p><p attribs="{'xml:space': 'preserve'}" id="_07719" smilref="Title.smil#_07719"> E R</p><p attribs="{'xml:space': 'preserve'}" id="_07720" smilref="Title.smil#_07720"> A C</p><p attribs="{'xml:space': 'preserve'}" id="_07721" smilref="Title.smil#_07721"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07722" smilref="Title.smil#_07722"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07723" smilref="Title.smil#_07723"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07724" smilref="Title.smil#_07724"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07725" smilref="Title.smil#_07725"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07726" smilref="Title.smil#_07726"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07727" smilref="Title.smil#_07727"> Insert into a 3-node at the bottom</p><p attribs="{'xml:space': 'preserve'}" id="_07728" smilref="Title.smil#_07728"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07729" smilref="Title.smil#_07729"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07730" smilref="Title.smil#_07730"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07731" smilref="Title.smil#_07731"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07732" smilref="Title.smil#_07732"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07733" smilref="Title.smil#_07733" /><pagenum id="p451" page="normal" smilref="Title.smil#p451" /><p attribs="{'xml:space': 'preserve'}" id="_07734" smilref="Title.smil#_07734"> 438</p><p attribs="{'xml:space': 'preserve'}" id="_07735" smilref="Title.smil#_07735"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07736" smilref="Title.smil#_07736"> In summary, we can maintain our 1-1</p><p attribs="{'xml:space': 'preserve'}" id="_07737" smilref="Title.smil#_07737"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07738" smilref="Title.smil#_07738"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07739" smilref="Title.smil#_07739"> left rotate</p><p attribs="{'xml:space': 'preserve'}" id="_07740" smilref="Title.smil#_07740"> h</p><p attribs="{'xml:space': 'preserve'}" id="_07741" smilref="Title.smil#_07741"> correspondence between 2-3 trees and red-black BSTs during insertion by judicious use of three simple operations: left rotate, right rotate, and color fl ip. We can accomplish the insertion by performing the following operations, one after the other, on each node as we pass up the tree from the point of insertion: </p><p attribs="{'xml:space': 'preserve'}" id="_07742" smilref="Title.smil#_07742"> Passing a red link up a red-black BST</p><p attribs="{'xml:space': 'preserve'}" id="_07743" smilref="Title.smil#_07743"> right rotate</p><p attribs="{'xml:space': 'preserve'}" id="_07744" smilref="Title.smil#_07744"> flip colors</p><p attribs="{'xml:space': 'preserve'}" id="_07745" smilref="Title.smil#_07745"> Implementation Since the balancing operations are to be performed on the way up the tree from the point of insertion, implementing them is easy in our standard recursive implementation: we just do them after the recursive calls, as shown in Algo- rithm 3.4. The three operations listed in the previous paragraph each can be accomplished with a single if statement that tests the colors of two nodes in the tree. Even though it involves a small amount of code, this implementation would be quite difficult to understand without the two layers of abstraction that we have developed (2-3 trees and red-black BSTs) to implement it. At a cost of testing three to five node colors (and perhaps doing a rotation or two or flipping colors when a test succeeds), we get BSTs that have nearly perfect balance. The traces for our standard indexing client and for the same keys inserted in increasing order are given on page 440. Considering these examples simply in terms of our three operations on red-black trees, as we have been doing, is an instructive exercise. Another instructive exercise is to check the correspondence with 2-3 trees that the algorithm maintains (using the figure for the same keys given on page 430). In both cases, you can test your understanding of the algorithm by considering the transformations (two color flips and two rotations) that are needed when P is inserted into the red-black</p><p attribs="{'xml:space': 'preserve'}" id="_07746" smilref="Title.smil#_07746"> BST (see Exercise 3.3.12).</p><p attribs="{'xml:space': 'preserve'}" id="_07747" smilref="Title.smil#_07747" /><pagenum id="p452" page="normal" smilref="Title.smil#p452" /><p attribs="{'xml:space': 'preserve'}" id="_07748" smilref="Title.smil#_07748"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07749" smilref="Title.smil#_07749"> 439</p><p attribs="{'xml:space': 'preserve'}" id="_07750" smilref="Title.smil#_07750"> ALGORITHM 3.4</p><p attribs="{'xml:space': 'preserve'}" id="_07751" smilref="Title.smil#_07751"> Insert for red-black BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_07752" smilref="Title.smil#_07752"> public class RedBlackBST&lt;Key extends Comparable&lt;Key&gt;, Value&gt; {</p><p attribs="{'xml:space': 'preserve'}" id="_07753" smilref="Title.smil#_07753"> private Node root;</p><p attribs="{'xml:space': 'preserve'}" id="_07754" smilref="Title.smil#_07754"> private class Node // BST node with color bit (see page 433)</p><p attribs="{'xml:space': 'preserve'}" id="_07755" smilref="Title.smil#_07755"> private boolean isRed(Node h) // See page 433. private Node rotateLeft(Node h) // See page 434. private Node rotateRight(Node h) // See page 434. private void flipColors(Node h) // See page 436.</p><p attribs="{'xml:space': 'preserve'}" id="_07756" smilref="Title.smil#_07756"> private int size() // See page 398.</p><p attribs="{'xml:space': 'preserve'}" id="_07757" smilref="Title.smil#_07757"> public void put(Key key, Value val) { // Search for key. Update value if found; grow table if new. root = put(root, key, val); root.color = BLACK; }</p><p attribs="{'xml:space': 'preserve'}" id="_07758" smilref="Title.smil#_07758"> private Node put(Node h, Key key, Value val) { if (h == null) // Do standard insert, with red link to parent. return new Node(key, val, 1, RED);</p><p attribs="{'xml:space': 'preserve'}" id="_07759" smilref="Title.smil#_07759"> int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else h.val = val;</p><p attribs="{'xml:space': 'preserve'}" id="_07760" smilref="Title.smil#_07760"> if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h); if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h);</p><p attribs="{'xml:space': 'preserve'}" id="_07761" smilref="Title.smil#_07761"> h.N = size(h.left) + size(h.right) + 1; return h; } }</p><p attribs="{'xml:space': 'preserve'}" id="_07762" smilref="Title.smil#_07762"> The code for the recursive put() for red-black BSTs is identical to put() in elementary BSTs except for the three if statements after the recursive calls, which provide near-perfect balance in the tree by maintaining a 1-1 correspondence with 2-3 trees, on the way up the search path. The first rotates left any right-leaning 3-node (or a right-leaning red link at the bottom of a temporary 4-node); the second rotates right the top link in a temporary 4-node with two left-leaning red links; and the third flips colors to pass a red link up the tree (see text).</p><p attribs="{'xml:space': 'preserve'}" id="_07763" smilref="Title.smil#_07763" /><pagenum id="p453" page="normal" smilref="Title.smil#p453" /><p attribs="{'xml:space': 'preserve'}" id="_07764" smilref="Title.smil#_07764"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07765" smilref="Title.smil#_07765"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07766" smilref="Title.smil#_07766"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07767" smilref="Title.smil#_07767"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07768" smilref="Title.smil#_07768"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07769" smilref="Title.smil#_07769"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07770" smilref="Title.smil#_07770"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07771" smilref="Title.smil#_07771"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07772" smilref="Title.smil#_07772"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07773" smilref="Title.smil#_07773"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07774" smilref="Title.smil#_07774"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07775" smilref="Title.smil#_07775"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07776" smilref="Title.smil#_07776"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07777" smilref="Title.smil#_07777"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07778" smilref="Title.smil#_07778"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07779" smilref="Title.smil#_07779"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07780" smilref="Title.smil#_07780"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07781" smilref="Title.smil#_07781"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07782" smilref="Title.smil#_07782"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07783" smilref="Title.smil#_07783"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07784" smilref="Title.smil#_07784"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07785" smilref="Title.smil#_07785"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07786" smilref="Title.smil#_07786"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07787" smilref="Title.smil#_07787"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07788" smilref="Title.smil#_07788"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07789" smilref="Title.smil#_07789"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07790" smilref="Title.smil#_07790"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07791" smilref="Title.smil#_07791"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07792" smilref="Title.smil#_07792"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07793" smilref="Title.smil#_07793"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07794" smilref="Title.smil#_07794"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07795" smilref="Title.smil#_07795"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07796" smilref="Title.smil#_07796"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07797" smilref="Title.smil#_07797"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07798" smilref="Title.smil#_07798"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07799" smilref="Title.smil#_07799"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07800" smilref="Title.smil#_07800"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07801" smilref="Title.smil#_07801"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07802" smilref="Title.smil#_07802"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07803" smilref="Title.smil#_07803"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07804" smilref="Title.smil#_07804"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07805" smilref="Title.smil#_07805"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07806" smilref="Title.smil#_07806"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07807" smilref="Title.smil#_07807"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07808" smilref="Title.smil#_07808"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07809" smilref="Title.smil#_07809"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07810" smilref="Title.smil#_07810"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07811" smilref="Title.smil#_07811"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07812" smilref="Title.smil#_07812"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07813" smilref="Title.smil#_07813"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07814" smilref="Title.smil#_07814"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07815" smilref="Title.smil#_07815"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07816" smilref="Title.smil#_07816"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07817" smilref="Title.smil#_07817"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07818" smilref="Title.smil#_07818"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07819" smilref="Title.smil#_07819"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07820" smilref="Title.smil#_07820"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07821" smilref="Title.smil#_07821"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07822" smilref="Title.smil#_07822"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07823" smilref="Title.smil#_07823"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07824" smilref="Title.smil#_07824"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07825" smilref="Title.smil#_07825"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07826" smilref="Title.smil#_07826"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07827" smilref="Title.smil#_07827"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07828" smilref="Title.smil#_07828"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07829" smilref="Title.smil#_07829"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07830" smilref="Title.smil#_07830"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07831" smilref="Title.smil#_07831"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07832" smilref="Title.smil#_07832"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07833" smilref="Title.smil#_07833"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07834" smilref="Title.smil#_07834"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07835" smilref="Title.smil#_07835"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07836" smilref="Title.smil#_07836"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07837" smilref="Title.smil#_07837"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07838" smilref="Title.smil#_07838"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07839" smilref="Title.smil#_07839"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07840" smilref="Title.smil#_07840"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07841" smilref="Title.smil#_07841"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07842" smilref="Title.smil#_07842"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07843" smilref="Title.smil#_07843"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07844" smilref="Title.smil#_07844"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07845" smilref="Title.smil#_07845"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07846" smilref="Title.smil#_07846"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07847" smilref="Title.smil#_07847"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07848" smilref="Title.smil#_07848"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07849" smilref="Title.smil#_07849"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07850" smilref="Title.smil#_07850"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07851" smilref="Title.smil#_07851"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07852" smilref="Title.smil#_07852"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07853" smilref="Title.smil#_07853"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07854" smilref="Title.smil#_07854"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07855" smilref="Title.smil#_07855"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07856" smilref="Title.smil#_07856"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07857" smilref="Title.smil#_07857"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07858" smilref="Title.smil#_07858"> X</p><p attribs="{'xml:space': 'preserve'}" id="_07859" smilref="Title.smil#_07859"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07860" smilref="Title.smil#_07860"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07861" smilref="Title.smil#_07861"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07862" smilref="Title.smil#_07862"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07863" smilref="Title.smil#_07863"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07864" smilref="Title.smil#_07864"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07865" smilref="Title.smil#_07865"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07866" smilref="Title.smil#_07866"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07867" smilref="Title.smil#_07867"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07868" smilref="Title.smil#_07868"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07869" smilref="Title.smil#_07869"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07870" smilref="Title.smil#_07870"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07871" smilref="Title.smil#_07871"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07872" smilref="Title.smil#_07872"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07873" smilref="Title.smil#_07873"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07874" smilref="Title.smil#_07874"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07875" smilref="Title.smil#_07875"> S</p><p attribs="{'xml:space': 'preserve'}" id="_07876" smilref="Title.smil#_07876"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07877" smilref="Title.smil#_07877"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07878" smilref="Title.smil#_07878"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07879" smilref="Title.smil#_07879"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07880" smilref="Title.smil#_07880"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07881" smilref="Title.smil#_07881"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07882" smilref="Title.smil#_07882"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07883" smilref="Title.smil#_07883"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07884" smilref="Title.smil#_07884"> R</p><p attribs="{'xml:space': 'preserve'}" id="_07885" smilref="Title.smil#_07885"> M</p><p attribs="{'xml:space': 'preserve'}" id="_07886" smilref="Title.smil#_07886"> L</p><p attribs="{'xml:space': 'preserve'}" id="_07887" smilref="Title.smil#_07887"> P</p><p attribs="{'xml:space': 'preserve'}" id="_07888" smilref="Title.smil#_07888"> H</p><p attribs="{'xml:space': 'preserve'}" id="_07889" smilref="Title.smil#_07889"> C</p><p attribs="{'xml:space': 'preserve'}" id="_07890" smilref="Title.smil#_07890"> A</p><p attribs="{'xml:space': 'preserve'}" id="_07891" smilref="Title.smil#_07891"> E</p><p attribs="{'xml:space': 'preserve'}" id="_07892" smilref="Title.smil#_07892"> Red-black BST construction traces</p><p attribs="{'xml:space': 'preserve'}" id="_07893" smilref="Title.smil#_07893"> standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_07894" smilref="Title.smil#_07894"> same keys in increasing order</p><p attribs="{'xml:space': 'preserve'}" id="_07895" smilref="Title.smil#_07895"> insert S</p><p attribs="{'xml:space': 'preserve'}" id="_07896" smilref="Title.smil#_07896"> insert A</p><p attribs="{'xml:space': 'preserve'}" id="_07897" smilref="Title.smil#_07897"> 440</p><p attribs="{'xml:space': 'preserve'}" id="_07898" smilref="Title.smil#_07898"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07899" smilref="Title.smil#_07899" /></level3><level3 id="_00056"><h3 id="ch3-s3-ss10" smilref="Title.smil#ch3-s3-ss10" xml:space="preserve">Deletion</h3><pagenum id="p454" page="normal" smilref="Title.smil#p454" /><p attribs="{'xml:space': 'preserve'}" id="_07900" smilref="Title.smil#_07900"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07901" smilref="Title.smil#_07901"> 441</p><p attribs="{'xml:space': 'preserve'}" id="_07902" smilref="Title.smil#_07902"> Deletion Since put() in Algorithm 3.4 is already one of the most intricate methods that we consider in this book, and the implementations of deleteMin(), deleteMax(), and delete() for red-black BSTs are a bit more complicated, we defer their full implementations to exercises. Still, the basic approach is worthy of study. To describe it, we begin by returning to 2-3 trees. As with insertion, we can define a sequence of local transformations that allow us to delete a node while still maintaining perfect balance. The process is somewhat more complicated than for insertion, because we do the transformations both on the way down the search path, when we introduce temporary 4-nodes (to allow for a node to be deleted), and also on the way up the search path, where we split any leftover 4-nodes (in the same manner as for insertion).</p><p attribs="{'xml:space': 'preserve'}" id="_07903" smilref="Title.smil#_07903"> at the root</p><p attribs="{'xml:space': 'preserve'}" id="_07904" smilref="Title.smil#_07904"> on the way down</p><p attribs="{'xml:space': 'preserve'}" id="_07905" smilref="Title.smil#_07905"> Top-down 2-3-4 trees. As a first warmup for deletion, we consider a simpler algorithm that does transformations both on the way down the path and on the way up the path: an insertion algorithm for 2-3-4 trees, where the temporary 4-nodes that we saw in 2-3 trees can persist in the tree. The insertion algorithm is based on doing transformations on the way down the path to maintain the invariant that the current node is not a 4-node (so we are assured that there will be room to insert the new key at the bottom) and transformations on the way up the path to balance any 4-nodes that may have been created. The transformations on the way down are precisely the same transformations that we used for splitting 4-nodes in 2-3 trees. If the root is a 4-node, we split it into three 2-nodes, increasing the height of the tree by 1. On the way down the tree, if we encounter a 4-node with a 2-node as parent, we split the 4-node into two 2-nodes and pass the middle key to the par- ent, making it a 3-node; if we encounter a 4-node with a 3-node as parent, we split the 4-node into two 2-nodes and pass the middle key to the parent, making it a 4-node. We do not need to worry about encountering a 4-node with a 4-node as parent by virtue of the invariant. At the bottom, we have, again by virtue of the invariant, a 2-node or a 3-node, so we have room to insert the new key. To implement this algorithm with red- black BSTs, we </p><p attribs="{'xml:space': 'preserve'}" id="_07906" smilref="Title.smil#_07906"> at the bottom</p><p attribs="{'xml:space': 'preserve'}" id="_07907" smilref="Title.smil#_07907"> Transformations for insert in top-down 2-3-4 trees</p><p attribs="{'xml:space': 'preserve'}" id="_07908" smilref="Title.smil#_07908" /><pagenum id="p455" page="normal" smilref="Title.smil#p455" /><p attribs="{'xml:space': 'preserve'}" id="_07909" smilref="Title.smil#_07909"> 442</p><p attribs="{'xml:space': 'preserve'}" id="_07910" smilref="Title.smil#_07910"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07911" smilref="Title.smil#_07911"> Remarkably, you can implement top-down 2-3-4 trees by moving one line of code in put() in Algorithm 3.4: move the colorFlip() call (and accompanying test) to before the recursive calls (between the test for null and the comparison). This algorithm has some advantages over 2-3 trees in applications where multiple processes have access to the same tree, because it always is operating within a link or two of the current node. The deletion algorithms that we describe next are based on a similar scheme and are effective for these trees as well as for 2-3 trees.</p><p attribs="{'xml:space': 'preserve'}" id="_07912" smilref="Title.smil#_07912"> at the root</p><p attribs="{'xml:space': 'preserve'}" id="_07913" smilref="Title.smil#_07913"> Delete the minimum. As a second warmup</p><p attribs="{'xml:space': 'preserve'}" id="_07914" smilref="Title.smil#_07914"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07915" smilref="Title.smil#_07915"> b</p><p attribs="{'xml:space': 'preserve'}" id="_07916" smilref="Title.smil#_07916"> b d e</p><p attribs="{'xml:space': 'preserve'}" id="_07917" smilref="Title.smil#_07917"> d e</p><p attribs="{'xml:space': 'preserve'}" id="_07918" smilref="Title.smil#_07918"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07919" smilref="Title.smil#_07919"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07920" smilref="Title.smil#_07920"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07921" smilref="Title.smil#_07921"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07922" smilref="Title.smil#_07922"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07923" smilref="Title.smil#_07923"> b f g</p><p attribs="{'xml:space': 'preserve'}" id="_07924" smilref="Title.smil#_07924"> c f g</p><p attribs="{'xml:space': 'preserve'}" id="_07925" smilref="Title.smil#_07925"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07926" smilref="Title.smil#_07926"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07927" smilref="Title.smil#_07927"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07928" smilref="Title.smil#_07928"> c d e</p><p attribs="{'xml:space': 'preserve'}" id="_07929" smilref="Title.smil#_07929"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07930" smilref="Title.smil#_07930"> c d e</p><p attribs="{'xml:space': 'preserve'}" id="_07931" smilref="Title.smil#_07931"> a b</p><p attribs="{'xml:space': 'preserve'}" id="_07932" smilref="Title.smil#_07932"> d e</p><p attribs="{'xml:space': 'preserve'}" id="_07933" smilref="Title.smil#_07933"> a b</p><p attribs="{'xml:space': 'preserve'}" id="_07934" smilref="Title.smil#_07934"> d e</p><p attribs="{'xml:space': 'preserve'}" id="_07935" smilref="Title.smil#_07935"> on the way down</p><p attribs="{'xml:space': 'preserve'}" id="_07936" smilref="Title.smil#_07936"> for deletion, we consider the operation of deleting the minimum from a 2-3 tree. The basic idea is based on the observation that we can easily delete a key from a 3-node at the bottom of the tree, but not from a 2-node. Deleting the key from a 2-node leaves a node with no keys; the natural thing to do would be to replace the node with a null link, but that operation would violate the perfect balance condition. So, we adopt the following approach: to ensure that we do not end up on a 2-node, we perform appropriate transformations on the way down the tree to preserve the invariant that the current node is not a 2-node (it might be a 3-node or a temporary 4-node). First, at the root, there are two possibilities: if the root is a 2-node and both children are 2-nodes, we can just convert the three nodes to a 4-node; otherwise we can borrow from the right sibling if necessary to ensure that the left child of the root is not a 2-node. Then, on the way down the tree, one of the following cases must hold: </p><p attribs="{'xml:space': 'preserve'}" id="_07937" smilref="Title.smil#_07937"> Transformations for delete the minimum</p><p attribs="{'xml:space': 'preserve'}" id="_07938" smilref="Title.smil#_07938"> at the bottom</p><p attribs="{'xml:space': 'preserve'}" id="_07939" smilref="Title.smil#_07939"> a b c</p><p attribs="{'xml:space': 'preserve'}" id="_07940" smilref="Title.smil#_07940"> b c</p><p attribs="{'xml:space': 'preserve'}" id="_07941" smilref="Title.smil#_07941" /><pagenum id="p456" page="normal" smilref="Title.smil#p456" /><p attribs="{'xml:space': 'preserve'}" id="_07942" smilref="Title.smil#_07942"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07943" smilref="Title.smil#_07943"> 443</p><p attribs="{'xml:space': 'preserve'}" id="_07944" smilref="Title.smil#_07944"> 2-node or the 4-node to a 3-node. Then, on the way up the tree, we split any unused temporary 4-nodes.</p><p attribs="{'xml:space': 'preserve'}" id="_07945" smilref="Title.smil#_07945"> Delete. The same transformations along the search path just described for deleting the minimum are effective to ensure that the current node is not a 2-node during a search for any key. If the search key is at the bottom, we can just remove it. If the key is not at the bottom, then we have to exchange it with its successor as in regular BSTs. Then, since the current node is not a 2-node, we have reduced the problem to deleting the minimum in a subtree whose root is not a 2-node, and we can use the procedure just described for that subtree. After the deletion, as usual, we split any remaining 4-nodes on the search path on the way up the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_07946" smilref="Title.smil#_07946"> Several of the exercises at the end of this section are devoted to examples and implementations related to these deletion algorithms. People with an interest in developing or understanding implementations need to master the details covered in these exercises. People with a general interest in the study of algorithms need to recognize that these methods are important because they represent the first symbol-table implementation that we have seen where search, insert, and delete are all guaranteed to be ef&#64257; cient, as we will establish next.</p><p attribs="{'xml:space': 'preserve'}" id="_07947" smilref="Title.smil#_07947" /><pagenum id="p457" page="normal" smilref="Title.smil#p457" /><p attribs="{'xml:space': 'preserve'}" id="_07948" smilref="Title.smil#_07948"> 444</p><p attribs="{'xml:space': 'preserve'}" id="_07949" smilref="Title.smil#_07949"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07950" smilref="Title.smil#_07950"> Properties of red-black BSTs Studying the properties of red-black BSTs is a matter of checking the correspondence with 2-3 trees and then applying the analysis of 2-3 trees. The end result is that all symbol-table operations in red-black BSTs are guaranteed to be logarithmic in the size of the tree (except for range search, which additionally costs time proportional to the number of keys returned). We repeat and emphasize this point because of its importance.</p><p attribs="{'xml:space': 'preserve'}" id="_07951" smilref="Title.smil#_07951"> Analysis. First, we establish that red-black BSTs, while not perfectly balanced, are always nearly so, regardless of the order in which the keys are inserted. This fact immediately follows from the 1-1 correspondence with 2-3 trees and the defining property of 2-3 trees (perfect balance).</p><p attribs="{'xml:space': 'preserve'}" id="_07952" smilref="Title.smil#_07952"> Proposition G. The height of a red-black BST with N nodes is no more than 2 lg N.</p><p attribs="{'xml:space': 'preserve'}" id="_07953" smilref="Title.smil#_07953"> Proof sketch: The worst case is a 2-3 tree that is all 2-nodes except that the leftmost path is made up of 3-nodes. The path taking left links from the root is twice as long as the paths of length ~ lg N that involve just 2-nodes. It is possible, but not easy, to develop key sequences that cause the construction of red-black BSTs whose average path length is the worst-case 2 lg N. If you are mathematically inclined, you might enjoy exploring this issue by working Exercise 3.3.24.</p><p attribs="{'xml:space': 'preserve'}" id="_07954" smilref="Title.smil#_07954"> This upper bound is conservative: experiments involving both random insertions and insertion sequences found in typical applications support the hypothesis that each search in a red-black BST of N nodes uses about 1.00 lg N &#8211; .5 compares, on the aver- age. Moreover, you are not likely to encounter a substantially higher average number of compares in practice.</p><p attribs="{'xml:space': 'preserve'}" id="_07955" smilref="Title.smil#_07955"> Typical red-black BST built from random keys (null links omitted)</p><p attribs="{'xml:space': 'preserve'}" id="_07956" smilref="Title.smil#_07956" /><pagenum id="p458" page="normal" smilref="Title.smil#p458" /><p attribs="{'xml:space': 'preserve'}" id="_07957" smilref="Title.smil#_07957"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_07958" smilref="Title.smil#_07958"> 445</p><p attribs="{'xml:space': 'preserve'}" id="_07959" smilref="Title.smil#_07959"> leipzig1M.txt</p><p attribs="{'xml:space': 'preserve'}" id="_07960" smilref="Title.smil#_07960"> compares model actual</p><p attribs="{'xml:space': 'preserve'}" id="_07961" smilref="Title.smil#_07961"> 19.4 18.7 17.5</p><p attribs="{'xml:space': 'preserve'}" id="_07962" smilref="Title.smil#_07962"> 19.1 18.4 17.3</p><p attribs="{'xml:space': 'preserve'}" id="_07963" smilref="Title.smil#_07963"> tale.txt</p><p attribs="{'xml:space': 'preserve'}" id="_07964" smilref="Title.smil#_07964"> words</p><p attribs="{'xml:space': 'preserve'}" id="_07965" smilref="Title.smil#_07965"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_07966" smilref="Title.smil#_07966"> compares model actual</p><p attribs="{'xml:space': 'preserve'}" id="_07967" smilref="Title.smil#_07967"> words</p><p attribs="{'xml:space': 'preserve'}" id="_07968" smilref="Title.smil#_07968"> distinct</p><p attribs="{'xml:space': 'preserve'}" id="_07969" smilref="Title.smil#_07969"> all words 8+ letters 10+ letters</p><p attribs="{'xml:space': 'preserve'}" id="_07970" smilref="Title.smil#_07970"> 135,635 14,350 4,582</p><p attribs="{'xml:space': 'preserve'}" id="_07971" smilref="Title.smil#_07971"> 10,679 5,737 2,260</p><p attribs="{'xml:space': 'preserve'}" id="_07972" smilref="Title.smil#_07972"> 13.6 12.6 11.4</p><p attribs="{'xml:space': 'preserve'}" id="_07973" smilref="Title.smil#_07973"> 13.5 12.1 11.5</p><p attribs="{'xml:space': 'preserve'}" id="_07974" smilref="Title.smil#_07974"> 21,191,455 4,239,597 1,610,829</p><p attribs="{'xml:space': 'preserve'}" id="_07975" smilref="Title.smil#_07975"> 534,580 299,593 165,555</p><p attribs="{'xml:space': 'preserve'}" id="_07976" smilref="Title.smil#_07976"> Average number of compares per put() for FrequencyCounter using RedBlackBST</p><p attribs="{'xml:space': 'preserve'}" id="_07977" smilref="Title.smil#_07977"> Property H. The average length of a path from the root to a node in a red-black BST with N nodes is ~1.00 lg N.</p><p attribs="{'xml:space': 'preserve'}" id="_07978" smilref="Title.smil#_07978"> Evidence: Typical trees, such as the one at the bottom of the previous page (and even the one built by inserting keys in increasing order at the bottom of this page) are quite well-balanced, by comparison with typical BSTs (such as the tree depicted on page 405). The table at the top of this page shows that path lengths (search costs) for our FrequencyCounter application are about 40 percent lower than from elementary BSTs, as expected. This performance has been observed in countless applications and experiments since the invention of red-black BSTs.</p><p attribs="{'xml:space': 'preserve'}" id="_07979" smilref="Title.smil#_07979"> For our example study of the cost of the put() operations for FrequencyCounter for words of length 8 or more, we see a further reduction in the average cost, again providing a quick validation of the logarithmic performance predicted by the theoretical model, though this validation is less surprising than for BSTs because of the guarantee provided by Property G. The total savings is less than the 40 per cent savings in the search cost because we count rotations and color flips as well as compares.</p><p attribs="{'xml:space': 'preserve'}" id="_07980" smilref="Title.smil#_07980"> Red-black BST built from ascending keys (null links omitted)</p><p attribs="{'xml:space': 'preserve'}" id="_07981" smilref="Title.smil#_07981" /><pagenum id="p459" page="normal" smilref="Title.smil#p459" /><p attribs="{'xml:space': 'preserve'}" id="_07982" smilref="Title.smil#_07982"> 446</p><p attribs="{'xml:space': 'preserve'}" id="_07983" smilref="Title.smil#_07983"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_07984" smilref="Title.smil#_07984"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_07985" smilref="Title.smil#_07985"> s</p><p attribs="{'xml:space': 'preserve'}" id="_07986" smilref="Title.smil#_07986"> e</p><p attribs="{'xml:space': 'preserve'}" id="_07987" smilref="Title.smil#_07987"> r</p><p attribs="{'xml:space': 'preserve'}" id="_07988" smilref="Title.smil#_07988"> a</p><p attribs="{'xml:space': 'preserve'}" id="_07989" smilref="Title.smil#_07989"> p</p><p attribs="{'xml:space': 'preserve'}" id="_07990" smilref="Title.smil#_07990"> m</p><p attribs="{'xml:space': 'preserve'}" id="_07991" smilref="Title.smil#_07991"> o</p><p attribs="{'xml:space': 'preserve'}" id="_07992" smilref="Title.smil#_07992"> c</p><p attribs="{'xml:space': 'preserve'}" id="_07993" smilref="Title.smil#_07993"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_07994" smilref="Title.smil#_07994"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_07995" smilref="Title.smil#_07995"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_07996" smilref="Title.smil#_07996"> operations Costs for java FrequencyCounter 8 &lt; tale.txt using RedBlackBST</p><p attribs="{'xml:space': 'preserve'}" id="_07997" smilref="Title.smil#_07997"> 14350</p><p attribs="{'xml:space': 'preserve'}" id="_07998" smilref="Title.smil#_07998"> The get() method in red-black BSTs does not examine the node color, so the balancing mechanism adds no overhead; search is faster than in elementary BSTs because the tree is balanced. Each key is inserted just once, but may be involved in many, many search operations, so the end result is that we get search times that are close to optimal (because the trees are nearly balanced and no work for balancing is done during the searches) at relatively little cost (unlike binary search, insertions are guaranteed to be logarithmic). The inner loop of the search is a compare followed by updating a link, which is quite short, like the inner loop of binary search (compare and index arithme- tic). This implementation is the first we have seen with logarithmic guarantees for both search and insert, and it has a tight inner loop, so its use is justified in a broad variety of applications, including library implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_07999" smilref="Title.smil#_07999"> Ordered symbol-table API. One of the most appealing features of red-black BSTs is that the complicated code is limited to the put() (and deletion) methods. Our code for the minimum/maximum, select, rank, fl oor, ceiling and range queries in standard BSTs can be used without any change, since it operates on BSTs and has no need to refer to the node color. Algorithm 3.4, together with these methods (and the deletion methods), leads to a complete implementation of our ordered symbol-table API. Moreover, all of the methods benefit from the near-perfect balance in the tree because they all require time proportional to the tree height, at most. Thus Proposition G, in combination with Proposition E, suffices to establish a logarithmic performance guarantee for all of them.</p><p attribs="{'xml:space': 'preserve'}" id="_08000" smilref="Title.smil#_08000" /><pagenum id="p460" page="normal" smilref="Title.smil#p460" /><p attribs="{'xml:space': 'preserve'}" id="_08001" smilref="Title.smil#_08001"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_08002" smilref="Title.smil#_08002"> 447</p><p attribs="{'xml:space': 'preserve'}" id="_08003" smilref="Title.smil#_08003"> Proposition I. In a red- black BST, the following operations take logarithmic time in the worst case: search, insertion, finding the minimum, finding the maximum, fl oor, ceiling, rank, select, delete the minimum, delete the maximum, delete, and range count.</p><p attribs="{'xml:space': 'preserve'}" id="_08004" smilref="Title.smil#_08004"> Proof : We have just discussed get(), put(), and the deletion operations. For the others, the code from Section 3.2 can be used verbatim (it just ignores the node color). Guaranteed logarithmic performance follows from Propositions E and G, and the fact that each algorithm performs a constant number of operations on each node examined.</p><p attribs="{'xml:space': 'preserve'}" id="_08005" smilref="Title.smil#_08005"> On refl ection, it is quite remarkable that we are able to achieve such guarantees. In a world awash with information, where people maintain tables with trillions or quadrillions of entries, the fact is that we can guarantee to complete any one of these operations in such tables with just a few dozen compares.</p><p attribs="{'xml:space': 'preserve'}" id="_08006" smilref="Title.smil#_08006"> algorithm (data structure)</p><p attribs="{'xml:space': 'preserve'}" id="_08007" smilref="Title.smil#_08007"> sequential search (unordered linked list) binary search (ordered array) binary tree search (BST) 2-3 tree search (red-black BST)</p><p attribs="{'xml:space': 'preserve'}" id="_08008" smilref="Title.smil#_08008"> worst-case cost (after N inserts) search insert</p><p attribs="{'xml:space': 'preserve'}" id="_08009" smilref="Title.smil#_08009"> average-case cost (after N random inserts) search hit insert</p><p attribs="{'xml:space': 'preserve'}" id="_08010" smilref="Title.smil#_08010"> efficiently support ordered operations?</p><p attribs="{'xml:space': 'preserve'}" id="_08011" smilref="Title.smil#_08011"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08012" smilref="Title.smil#_08012"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08013" smilref="Title.smil#_08013"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08014" smilref="Title.smil#_08014"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08015" smilref="Title.smil#_08015"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08016" smilref="Title.smil#_08016"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08017" smilref="Title.smil#_08017"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_08018" smilref="Title.smil#_08018"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08019" smilref="Title.smil#_08019"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08020" smilref="Title.smil#_08020"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_08021" smilref="Title.smil#_08021"> 1.39 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08022" smilref="Title.smil#_08022"> 1.39 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08023" smilref="Title.smil#_08023"> 2 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08024" smilref="Title.smil#_08024"> 2 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08025" smilref="Title.smil#_08025"> 1.00 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08026" smilref="Title.smil#_08026"> 1.00 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08027" smilref="Title.smil#_08027"> no</p><p attribs="{'xml:space': 'preserve'}" id="_08028" smilref="Title.smil#_08028"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_08029" smilref="Title.smil#_08029"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_08030" smilref="Title.smil#_08030"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_08031" smilref="Title.smil#_08031"> Cost summary for symbol-table implementations (updated)</p><p attribs="{'xml:space': 'preserve'}" id="_08032" smilref="Title.smil#_08032" /><pagenum id="p461" page="normal" smilref="Title.smil#p461" /><p attribs="{'xml:space': 'preserve'}" id="_08033" smilref="Title.smil#_08033"> 448</p><p attribs="{'xml:space': 'preserve'}" id="_08034" smilref="Title.smil#_08034"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08035" smilref="Title.smil#_08035"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_08036" smilref="Title.smil#_08036"> Q. Why not let the 3-nodes lean either way and also allow 4-nodes in the trees? A. Those are fine alternatives, used by many for decades. You can learn about several of these alternatives in the exercises. The left-leaning convention reduces the number of cases and therefore requires substantially less code. Q. Why not use an array of Key values to represent 2-, 3-, and 4-nodes with a single Node type? A. Good question. That is precisely what we do for B-trees (see Chapter 6), where we allow many more keys per node. For the small nodes in 2-3 trees, the overhead for the array is too high a price to pay. Q. When we split a 4-node, we sometimes set the color of the right node to RED in rotateRight() and then immediately set it to BLACK in flipColors(). Isn&#8217;t that wasteful? A. Yes, and we also sometimes unnecessarily recolor the middle node. In the grand scheme of things, resetting a few extra bits is not in the same league with the improvement from linear to logarithmic that we get for all operations, but in performance-crit- ical applications, you can put the code for rotateRight() and flipColors() inline and eliminate those extra tests. We use those methods for deletion, as well, and find them slightly easier to use, understand, and maintain by making sure that they preserve perfect black balance.</p><p attribs="{'xml:space': 'preserve'}" id="_08037" smilref="Title.smil#_08037" /><pagenum id="p462" page="normal" smilref="Title.smil#p462" /><p attribs="{'xml:space': 'preserve'}" id="_08038" smilref="Title.smil#_08038"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_08039" smilref="Title.smil#_08039"> 449</p><p attribs="{'xml:space': 'preserve'}" id="_08040" smilref="Title.smil#_08040"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_08041" smilref="Title.smil#_08041"> 3.3.1 Draw the 2-3 tree that results when you insert the keys E A S Y Q U T I O N in that order into an initially empty tree. 3.3.2 Draw the 2-3 tree that results when you insert the keys Y L P M X H C R A E S in that order into an initially empty tree. 3.3.3 Find an insertion order for the keys S E A R C H X M that leads to a 2-3 tree of height 1. 3.3.4 Prove that the height of a 2-3 tree with N keys is between ~ &#9123;log3 N&#9126; &#11015; .63 lg N (for a tree that is all 3-nodes) and ~&#9123;lg N&#9126; (for a tree that is all 2-nodes). 3.3.5 The figure at right shows all the structurally different 2-3 trees with N keys, for N from 1 up to 6 (ignore the order of the subtrees). Draw all the structurally different trees for N = 7, 8, 9, and 10. 3.3.6 Find the probability that each of the 2-3 trees in Exercise 3.3.5 is the result of the insertion of N random distinct keys into an initially empty tree. 3.3.7 Draw diagrams like the one at the top of page 428 for the other five cases in the diagram at the bottom of that page. 3.3.8 Show all possible ways that one might represent a 4-node with three 2-nodes bound together with red links (not necessarily left-leaning). 3.3.9 Which of the following are red-black BSTs?</p><p attribs="{'xml:space': 'preserve'}" id="_08042" smilref="Title.smil#_08042"> C</p><p attribs="{'xml:space': 'preserve'}" id="_08043" smilref="Title.smil#_08043"> (i)</p><p attribs="{'xml:space': 'preserve'}" id="_08044" smilref="Title.smil#_08044"> A</p><p attribs="{'xml:space': 'preserve'}" id="_08045" smilref="Title.smil#_08045"> (ii)</p><p attribs="{'xml:space': 'preserve'}" id="_08046" smilref="Title.smil#_08046"> A</p><p attribs="{'xml:space': 'preserve'}" id="_08047" smilref="Title.smil#_08047"> Y</p><p attribs="{'xml:space': 'preserve'}" id="_08048" smilref="Title.smil#_08048"> H</p><p attribs="{'xml:space': 'preserve'}" id="_08049" smilref="Title.smil#_08049"> D</p><p attribs="{'xml:space': 'preserve'}" id="_08050" smilref="Title.smil#_08050"> E</p><p attribs="{'xml:space': 'preserve'}" id="_08051" smilref="Title.smil#_08051"> (iii)</p><p attribs="{'xml:space': 'preserve'}" id="_08052" smilref="Title.smil#_08052"> D</p><p attribs="{'xml:space': 'preserve'}" id="_08053" smilref="Title.smil#_08053"> H</p><p attribs="{'xml:space': 'preserve'}" id="_08054" smilref="Title.smil#_08054"> C</p><p attribs="{'xml:space': 'preserve'}" id="_08055" smilref="Title.smil#_08055"> F</p><p attribs="{'xml:space': 'preserve'}" id="_08056" smilref="Title.smil#_08056"> G</p><p attribs="{'xml:space': 'preserve'}" id="_08057" smilref="Title.smil#_08057"> Z</p><p attribs="{'xml:space': 'preserve'}" id="_08058" smilref="Title.smil#_08058"> E</p><p attribs="{'xml:space': 'preserve'}" id="_08059" smilref="Title.smil#_08059"> B</p><p attribs="{'xml:space': 'preserve'}" id="_08060" smilref="Title.smil#_08060"> Y</p><p attribs="{'xml:space': 'preserve'}" id="_08061" smilref="Title.smil#_08061"> (iv)</p><p attribs="{'xml:space': 'preserve'}" id="_08062" smilref="Title.smil#_08062"> H</p><p attribs="{'xml:space': 'preserve'}" id="_08063" smilref="Title.smil#_08063"> C</p><p attribs="{'xml:space': 'preserve'}" id="_08064" smilref="Title.smil#_08064"> A</p><p attribs="{'xml:space': 'preserve'}" id="_08065" smilref="Title.smil#_08065"> D</p><p attribs="{'xml:space': 'preserve'}" id="_08066" smilref="Title.smil#_08066"> H</p><p attribs="{'xml:space': 'preserve'}" id="_08067" smilref="Title.smil#_08067"> Z</p><p attribs="{'xml:space': 'preserve'}" id="_08068" smilref="Title.smil#_08068"> A</p><p attribs="{'xml:space': 'preserve'}" id="_08069" smilref="Title.smil#_08069"> Y</p><p attribs="{'xml:space': 'preserve'}" id="_08070" smilref="Title.smil#_08070"> T</p><p attribs="{'xml:space': 'preserve'}" id="_08071" smilref="Title.smil#_08071"> 3.3.10 Draw the red-black BST that results when you insert items with the keys E A S Y Q U T I O N in that order into an initially empty tree. 3.3.11 Draw the red-black BST that results when you insert items with the keys Y L P M X H C R A E S in that order into an initially empty tree.</p><p attribs="{'xml:space': 'preserve'}" id="_08072" smilref="Title.smil#_08072" /><pagenum id="p463" page="normal" smilref="Title.smil#p463" /><p attribs="{'xml:space': 'preserve'}" id="_08073" smilref="Title.smil#_08073"> 450</p><p attribs="{'xml:space': 'preserve'}" id="_08074" smilref="Title.smil#_08074"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08075" smilref="Title.smil#_08075"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08076" smilref="Title.smil#_08076"> 3.3.12 Draw the red-black BST that results after each transformation (color flip or rotation) during the insertion of P for our standard indexing client. 3.3.13 True or false: If you insert keys in increasing order into a red-black BST, the tree height is monotonically increasing. 3.3.14 Draw the red-black BST that results when you insert letters A through K in order into an initially empty tree, then describe what happens in general when trees are built by insertion of keys in ascending order (see also the figure in the text). 3.3.15 Answer the previous two questions for the case when the keys are inserted in descending order. 3.3.16 Show the result of inserting n into the red-black BST drawn at right (only the search path is shown, and you need to include only these nodes in your answer). 3.3.17 Generate two random 16-node red- black BSTs. Draw them (either by hand or with a program). Compare them with the (unbalanced) BSTs built with the same keys. 3.3.18 Draw all the structurally different red-black BSTs with N keys, for N from 2 up</p><p attribs="{'xml:space': 'preserve'}" id="_08077" smilref="Title.smil#_08077"> j</p><p attribs="{'xml:space': 'preserve'}" id="_08078" smilref="Title.smil#_08078"> q</p><p attribs="{'xml:space': 'preserve'}" id="_08079" smilref="Title.smil#_08079"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08080" smilref="Title.smil#_08080"> s</p><p attribs="{'xml:space': 'preserve'}" id="_08081" smilref="Title.smil#_08081"> l</p><p attribs="{'xml:space': 'preserve'}" id="_08082" smilref="Title.smil#_08082"> k</p><p attribs="{'xml:space': 'preserve'}" id="_08083" smilref="Title.smil#_08083"> o</p><p attribs="{'xml:space': 'preserve'}" id="_08084" smilref="Title.smil#_08084"> m</p><p attribs="{'xml:space': 'preserve'}" id="_08085" smilref="Title.smil#_08085"> to 10 (see Exercise 3.3.5).</p><p attribs="{'xml:space': 'preserve'}" id="_08086" smilref="Title.smil#_08086"> u</p><p attribs="{'xml:space': 'preserve'}" id="_08087" smilref="Title.smil#_08087"> r</p><p attribs="{'xml:space': 'preserve'}" id="_08088" smilref="Title.smil#_08088"> p</p><p attribs="{'xml:space': 'preserve'}" id="_08089" smilref="Title.smil#_08089"> 3.3.19 With 1 bit per node for color, we can represent 2-, 3-, and 4-nodes. How many bits per node would we need to represent 5-, 6-, 7-, and 8-nodes with a binary tree? 3.3.20 Compute the internal path length in a perfectly balanced BST of N nodes, when N is a power of 2 minus 1. 3.3.21 Create a test client for RedBlackBST, based on your solution to Exercise 3.2.10. 3.3.22 Find a sequence of keys to insert into a BST and into a red-black BST such that the height of the BST is less than the height of the red-black BST, or prove that no such sequence is possible.</p><p attribs="{'xml:space': 'preserve'}" id="_08090" smilref="Title.smil#_08090" /><pagenum id="p464" page="normal" smilref="Title.smil#p464" /><p attribs="{'xml:space': 'preserve'}" id="_08091" smilref="Title.smil#_08091"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_08092" smilref="Title.smil#_08092"> 451</p><p attribs="{'xml:space': 'preserve'}" id="_08093" smilref="Title.smil#_08093"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_08094" smilref="Title.smil#_08094"> 3.3.23 2-3 trees without balance restriction. Develop an implementation of the basic symbol-table API that uses 2-3 trees that are not necessarily balanced as the underlying data structure. Allow 3-nodes to lean either way. Hook the new node onto the bottom with a black link when inserting into a 3-node at the bottom. Run experiments to develop a hypothesis estimating the average path length in a tree built from N random insertions. 3.3.24 Worst case for red-black BSTs. Show how to construct a red-black BST demonstrating that, in the worst case, almost all the paths from the root to a null link in a red-black BST of N nodes are of length 2 lg N. 3.3.25 Top-down 2-3-4 trees. Develop an implementation of the basic symbol-table API that uses balanced 2-3-4 trees as the underlying data structure, using the red-black representation and the insertion method described in the text, where 4-nodes are split by flipping colors on the way down the search path and balancing on the way up. 3.3.26 Single top-down pass. Develop a modified version of your solution to Exer- cise 3.3.25 that does not use recursion. Complete all the work splitting and balancing 4-nodes (and balancing 3-nodes) on the way down the tree, finishing with an insertion at the bottom. 3.3.27 Allow right-leaning red links. Develop a modified version of your solution to Exercise 3.3.25 that allows right-leaning red links in the tree. 3.3.28 Bottom-up 2-3-4 trees. Develop an implementation of the basic symbol-table API that uses balanced 2-3-4 trees as the underlying data structure, using the red-black representation and a bottom-up insertion method based on the same recursive approach as Algorithm 3.4. Your insertion method should split only the sequence of 4-nodes (if any) on the bottom of the search path. 3.3.29 Optimal storage. Modify RedBlackBST so that it does not use any extra storage for the color bit, based on the following trick: To color a node red, swap its two links. Then, to test whether a node is red, test whether its left child is larger than its right child. You have to modify the compares to accommodate the possible link swap, and this trick replaces bit compares with key compares that are presumably more expensive, but it shows that the bit in the nodes can be eliminated, if necessary. 3.3.30 Sofware caching. Modify RedBlackBST to keep the most recently accessed Node in an instance variable so that it can be accessed in constant time if the next put() or</p><p attribs="{'xml:space': 'preserve'}" id="_08095" smilref="Title.smil#_08095" /><pagenum id="p465" page="normal" smilref="Title.smil#p465" /><p attribs="{'xml:space': 'preserve'}" id="_08096" smilref="Title.smil#_08096"> 452</p><p attribs="{'xml:space': 'preserve'}" id="_08097" smilref="Title.smil#_08097"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08098" smilref="Title.smil#_08098"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08099" smilref="Title.smil#_08099"> get() uses the same key (see Exercise 3.1.25). 3.3.31 Tree drawing. Add a method draw() to RedBlackBST that draws red-black BST figures in the style of the text (see Exercise 3.2.38) 3.3.32 AVL trees. An AVL tree is a BST where the height of every node and that of its sibling differ by at most 1. (The oldest balanced tree algorithms are based on using rotations to maintain height balance in AVL trees.) Show that coloring red links that go from nodes of even height to nodes of odd height in an AVL tree gives a (perfectly balanced) 2-3-4 tree, where red links are not necessarily left-leaning. Extra credit : De- velop an implementation of the symbol-table API that uses this as the underlying data structure. One approach is to keep a height field in each node, using rotations after the recursive calls to adjust the height as necessary ; another is to use the red-black representation and use methods like moveRedLeft() and moveRedRight() in Exercise 3.3.39</p><p attribs="{'xml:space': 'preserve'}" id="_08100" smilref="Title.smil#_08100"> and Exercise 3.3.40.</p><p attribs="{'xml:space': 'preserve'}" id="_08101" smilref="Title.smil#_08101"> 3.3.33 Certi&#64257; cation. Add to RedBlackBST a method is23() to check that no node is connected to two red links and that there are no right-leaing red links and a method isBalanced() to check that all paths from the root to a null link have the same number of black links. Combine these methods with code from isBST() in Exercise 3.2.31 to create a method isRedBlackBST() that checks that the tree is a red-black BST. 3.3.34 All 2-3 trees. Write code to generate all structurally different 2-3 trees of height 2, 3, and 4. There are 2, 7, and 122 such trees, respectively. (Hint : Use a symbol table.) 3.3.35 2-3 trees. Write a program TwoThreeST.java that uses two node types to implement 2-3 search trees directly. 3.3.36 2-3-4-5-6-7-8 trees. Describe algorithms for search and insertion in balanced 2-3-4-5-6-7-8 search trees. 3.3.37 Memoryless. Show that red-black BSTs are not memoryless: for example, if you insert a key that is smaller than all the keys in the tree and then immediately delete the minimum, you may get a different tree. 3.3.38 Fundamental theorem of rotations. Show that any BST can be transformed into any other BST on the same set of keys by a sequence of left and right rotations.</p><p attribs="{'xml:space': 'preserve'}" id="_08102" smilref="Title.smil#_08102" /><pagenum id="p466" page="normal" smilref="Title.smil#p466" /><p attribs="{'xml:space': 'preserve'}" id="_08103" smilref="Title.smil#_08103"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_08104" smilref="Title.smil#_08104"> 453</p><p attribs="{'xml:space': 'preserve'}" id="_08105" smilref="Title.smil#_08105"> 3.3.39 Delete the minimum. Implement the deleteMin() operation for red-black BSTs by maintaining the correspondence with the transformations given in the text for moving down the left spine of the tree while maintaining the invariant that the current node is not a 2-node. Solution:</p><p attribs="{'xml:space': 'preserve'}" id="_08106" smilref="Title.smil#_08106"> private Node moveRedLeft(Node h) { // Assuming that h is red and both h.left and h.left.left // are black, make h.left or one of its children red. flipColors(h); if (isRed(h.right.left)) { h.right = rotateRight(h.right); h = rotateLeft(h); } return h; }</p><p attribs="{'xml:space': 'preserve'}" id="_08107" smilref="Title.smil#_08107"> public void deleteMin() { if (!isRed(root.left) &amp;&amp; !isRed(root.right)) root.color = RED; root = deleteMin(root); if (!isEmpty()) root.color = BLACK; }</p><p attribs="{'xml:space': 'preserve'}" id="_08108" smilref="Title.smil#_08108"> private Node deleteMin(Node h) { if (h.left == null) return null; if (!isRed(h.left) &amp;&amp; !isRed(h.left.left)) h = moveRedLeft(h); h.left = deleteMin(h.left); return balance(h); }</p><p attribs="{'xml:space': 'preserve'}" id="_08109" smilref="Title.smil#_08109"> This code assumes a balance() method that consists of the line of code</p><p attribs="{'xml:space': 'preserve'}" id="_08110" smilref="Title.smil#_08110"> if (isRed(h.right)) h = rotateLeft(h);</p><p attribs="{'xml:space': 'preserve'}" id="_08111" smilref="Title.smil#_08111" /><pagenum id="p467" page="normal" smilref="Title.smil#p467" /><p attribs="{'xml:space': 'preserve'}" id="_08112" smilref="Title.smil#_08112"> 454</p><p attribs="{'xml:space': 'preserve'}" id="_08113" smilref="Title.smil#_08113"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08114" smilref="Title.smil#_08114"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08115" smilref="Title.smil#_08115"> followed by the last five lines of the recursive put() in Algorithm 3.4 and a flipColors() implementation that complements the three colors, instead of the method given in the text for insertion. For deletion, we set the parent to BLACK and the two children to RED.</p><p attribs="{'xml:space': 'preserve'}" id="_08116" smilref="Title.smil#_08116"> 3.3.40 Delete the maximum. Implement the deleteMax() operation for red-black BSTs. Note that the transformations involved differ slightly from those in the previous exercise because red links are left-leaning.</p><p attribs="{'xml:space': 'preserve'}" id="_08117" smilref="Title.smil#_08117"> Solution:</p><p attribs="{'xml:space': 'preserve'}" id="_08118" smilref="Title.smil#_08118"> private Node moveRedRight(Node h) { // Assuming that h is red and both h.right and h.right.left // are black, make h.right or one of its children red. flipColors(h) if (!isRed(h.left.left)) h = rotateRight(h); return h; }</p><p attribs="{'xml:space': 'preserve'}" id="_08119" smilref="Title.smil#_08119"> public void deleteMax() { if (!isRed(root.left) &amp;&amp; !isRed(root.right)) root.color = RED; root = deleteMax(root); if (!isEmpty()) root.color = BLACK; }</p><p attribs="{'xml:space': 'preserve'}" id="_08120" smilref="Title.smil#_08120"> private Node deleteMax(Node h) { if (isRed(h.left)) h = rotateRight(h); if (h.right == null) return null; if (!isRed(h.right) &amp;&amp; !isRed(h.right.left)) h = moveRedRight(h); h.right = deleteMax(h.right); return balance(h); }</p><p attribs="{'xml:space': 'preserve'}" id="_08121" smilref="Title.smil#_08121" /><pagenum id="p468" page="normal" smilref="Title.smil#p468" /><p attribs="{'xml:space': 'preserve'}" id="_08122" smilref="Title.smil#_08122"> 3.3 </p><p attribs="{'xml:space': 'preserve'}" id="_08123" smilref="Title.smil#_08123"> 455</p><p attribs="{'xml:space': 'preserve'}" id="_08124" smilref="Title.smil#_08124"> 3.3.41 Delete. Implement the delete() operation for red-black BSTs, combining the methods of the previous two exercises with the delete() operation for BSTs.</p><p attribs="{'xml:space': 'preserve'}" id="_08125" smilref="Title.smil#_08125"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_08126" smilref="Title.smil#_08126"> public void delete(Key key) { if (!isRed(root.left) &amp;&amp; !isRed(root.right)) root.color = RED; root = delete(root, key); if (!isEmpty()) root.color = BLACK; }</p><p attribs="{'xml:space': 'preserve'}" id="_08127" smilref="Title.smil#_08127"> private Node delete(Node h, Key key) { if (key.compareTo(h.key) &lt; 0) { if (!isRed(h.left) &amp;&amp; !isRed(h.left.left)) h = moveRedLeft(h); h.left = delete(h.left, key); } else { if (isRed(h.left)) h = rotateRight(h); if (key.compareTo(h.key) == 0 &amp;&amp; (h.right == null)) return null; if (!isRed(h.right) &amp;&amp; !isRed(h.right.left)) h = moveRedRight(h); if (key.compareTo(h.key) == 0) { h.val = get(h.right, min(h.right).key); h.key = min(h.right).key; h.right = deleteMin(h.right); } else h.right = delete(h.right, key); }</p><p attribs="{'xml:space': 'preserve'}" id="_08128" smilref="Title.smil#_08128"> return balance(h); }</p><p attribs="{'xml:space': 'preserve'}" id="_08129" smilref="Title.smil#_08129" /><pagenum id="p469" page="normal" smilref="Title.smil#p469" /><p attribs="{'xml:space': 'preserve'}" id="_08130" smilref="Title.smil#_08130"> 456</p><p attribs="{'xml:space': 'preserve'}" id="_08131" smilref="Title.smil#_08131"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08132" smilref="Title.smil#_08132"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_08133" smilref="Title.smil#_08133"> 3.3.42 Count red nodes. Write a program that computes the percentage of red nodes in a given red-black BST. Test your program by running at least 100 trials of the experiment of inserting N random keys into an initially empty tree, for N = 10 4, 10 5, and 10 6, and formulate an hypothesis. 3.3.43 Cost plots. Instrument RedBlackBST so that you can produce plots like the ones in this section showing the cost of each put() operation during the computation</p><p attribs="{'xml:space': 'preserve'}" id="_08134" smilref="Title.smil#_08134"> (see Exercise 3.1.38).</p><p attribs="{'xml:space': 'preserve'}" id="_08135" smilref="Title.smil#_08135"> 3.3.44 Average search time. Run empirical studies to compute the average and standard deviation of the average length of a path to a random node (internal path length divided by tree size) in a red-black BST built by insertion of N random keys into an initially empty tree, for N from 1 to 10,000. Do at least 1,000 trials for each tree size. Plot the results in a Tufte plot, like the one at the bottom of this page, fit with a curve plotting the function lg N &#8211; .5. 3.3.45 Count rotations. Instrument your program for Exercise 3.3.43 to plot the number of rotations and node splits that are used to build the trees. Discuss the results. 3.3.46 Height. Instrument your program for Exercise 3.3.43 to plot the height of red-black BSTs. Discuss the results.</p><p attribs="{'xml:space': 'preserve'}" id="_08136" smilref="Title.smil#_08136"> lg N &#8722; .5</p><p attribs="{'xml:space': 'preserve'}" id="_08137" smilref="Title.smil#_08137"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_08138" smilref="Title.smil#_08138"> Average path length to a random node in a red-black BST built from random keys</p><p attribs="{'xml:space': 'preserve'}" id="_08139" smilref="Title.smil#_08139"> operations</p><p attribs="{'xml:space': 'preserve'}" id="_08140" smilref="Title.smil#_08140"> 10000</p><p attribs="{'xml:space': 'preserve'}" id="_08141" smilref="Title.smil#_08141"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_08142" smilref="Title.smil#_08142"> s</p><p attribs="{'xml:space': 'preserve'}" id="_08143" smilref="Title.smil#_08143"> e</p><p attribs="{'xml:space': 'preserve'}" id="_08144" smilref="Title.smil#_08144"> r</p><p attribs="{'xml:space': 'preserve'}" id="_08145" smilref="Title.smil#_08145"> a</p><p attribs="{'xml:space': 'preserve'}" id="_08146" smilref="Title.smil#_08146"> p</p><p attribs="{'xml:space': 'preserve'}" id="_08147" smilref="Title.smil#_08147"> m</p><p attribs="{'xml:space': 'preserve'}" id="_08148" smilref="Title.smil#_08148"> o</p><p attribs="{'xml:space': 'preserve'}" id="_08149" smilref="Title.smil#_08149"> c</p><p attribs="{'xml:space': 'preserve'}" id="_08150" smilref="Title.smil#_08150"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08151" smilref="Title.smil#_08151"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_08152" smilref="Title.smil#_08152" /><pagenum id="p470" page="normal" smilref="Title.smil#p470" /><p attribs="{'xml:space': 'preserve'}" id="_08153" smilref="Title.smil#_08153"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_08154" smilref="Title.smil#_08154" /></level3><level3 id="_00057"><h3 id="ch3-s4-ss11" smilref="Title.smil#ch3-s4-ss11" xml:space="preserve">Hash functions</h3><pagenum id="p472" page="normal" smilref="Title.smil#p472" /><p attribs="{'xml:space': 'preserve'}" id="_08155" smilref="Title.smil#_08155"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08156" smilref="Title.smil#_08156"> 459</p><p attribs="{'xml:space': 'preserve'}" id="_08157" smilref="Title.smil#_08157"> Hash functions The first problem that we face is the computation of the hash function, which transforms keys into array indices. If we have an array that can hold M key-value pairs, then we need a hash function that can transform any given key into an index into that array : an integer in the range [0, M &#8211; 1]. We seek a hash function that both is easy to compute and uniformly distributes the keys: for each key, every integer between 0 and M &#8211; 1 should be equally likely (independently for every key). This ideal is somewhat mysterious; to understand hashing, we begin by thinking carefully about how to implement such a function. In principle, any key can be represented as a sequence of bits, so we might design a generic hash function that maps sequences of bits to integers in the desired range. In practice, programmers implement hash functions based on higher-level representations. For example, if the key involves a number, such as a social security number, we could start with that number; if the key involves a string, such as a person&#8217;s name, we need to convert the string into a number; and if the key has multiple parts, such as a mailing address, we need to combine the parts somehow. For many common types of keys, we can make use of default implementations provided by Java. We briefly discuss potential implementations for various types of keys so that you can see what is involved because you do need to provide implementations for key types that you create.</p><p attribs="{'xml:space': 'preserve'}" id="_08158" smilref="Title.smil#_08158"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08159" smilref="Title.smil#_08159"> Typical example. Suppose that we have an application where the keys are U.S. social security numbers. A social security number such as 123-45-6789 is a nine-digit number divided into three fi elds. The first field identifies the geographical area where the number was issued (for example, social security numbers whose first field is 035 are from Rhode Island and numbers whose first field is 214 are from Maryland) and the other two fields identify the individual. There are a billion (109) different social security numbers, but suppose that our application will need to process just a few hundred keys, so that we could use a hash table of size M = 1,000. One possible approach to implementing a hash function is to use three digits from the key. Using three digits from the third field is likely to be preferable to using the three digits in the first field (since customers may not be uniformly dispersed over geographic areas), but a better approach is to use all nine digits to make an int value, then consider hash functions for integers, described next.</p><p attribs="{'xml:space': 'preserve'}" id="_08160" smilref="Title.smil#_08160"> hash (M = 100)</p><p attribs="{'xml:space': 'preserve'}" id="_08161" smilref="Title.smil#_08161"> hash (M = 97)</p><p attribs="{'xml:space': 'preserve'}" id="_08162" smilref="Title.smil#_08162"> 212 12 18 618 18 36 302 2 11 940 40 67 702 2 23 704 4 25 612 12 30 606 6 24 772 72 93 510 10 25 423 23 35 650 50 68 317 17 26 907 7 34 507 7 22 304 4 13 714 14 35 857 57 81 801 1 25 900 0 27 413 13 25 701 1 22 418 18 30 601 1 19</p><p attribs="{'xml:space': 'preserve'}" id="_08163" smilref="Title.smil#_08163"> Modular hashing</p><p attribs="{'xml:space': 'preserve'}" id="_08164" smilref="Title.smil#_08164"> Positive integers. The most commonly used method for hashing integers is called modular hashing : we choose the array size M to be prime and, for any positive integer key k, compute the remainder when dividing k by M. This function is very easy to compute (k % M, in Java) and is effective in dispersing the keys evenly between 0 and</p><p attribs="{'xml:space': 'preserve'}" id="_08165" smilref="Title.smil#_08165" /><pagenum id="p473" page="normal" smilref="Title.smil#p473" /><p attribs="{'xml:space': 'preserve'}" id="_08166" smilref="Title.smil#_08166"> 460</p><p attribs="{'xml:space': 'preserve'}" id="_08167" smilref="Title.smil#_08167"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08168" smilref="Title.smil#_08168"> M &#8211; 1. If M is not prime, it may be the case that not all of the bits of the key play a role, which amounts to missing an opportunity to disperse the values evenly. For example, if the keys are base-10 numbers and M is 10 k, then only the k least significant digits are used. As a simple example where such a choice might be problematic, suppose that the keys are telephone area codes and M = 100. For historical reasons, most area codes in the United States have middle digit 0 or 1, so this choice strongly favors the values less than 20, where the use of the prime value 97 better disperses them (a prime value not close to 100 would do even better). Similarly, IP addresses that are used in the internet are binary numbers that are not random for similar historical reasons as for telephone area codes, so we need to use a table size that is a prime (in particular, not a power of 2) if we want to use modular hashing to disperse them.</p><p attribs="{'xml:space': 'preserve'}" id="_08169" smilref="Title.smil#_08169"> Floating-point numbers. If the keys are real numbers between 0 and 1, we might just multiply by M and round off to the nearest integer to get an index between 0 and M &#8211; 1. Although this approach is intuitive, it is defective because it gives more weight to the most significant bits of the keys; the least significant bits play no role. One way to address this situation is to use modular hashing on the binary representation of the key (this is what Java does).</p><p attribs="{'xml:space': 'preserve'}" id="_08170" smilref="Title.smil#_08170"> int hash = 0; for (int i = 0; i &lt; s.length(); i++) hash = (R * hash + s.charAt(i)) % M;</p><p attribs="{'xml:space': 'preserve'}" id="_08171" smilref="Title.smil#_08171"> Strings. Modular hashing works for long keys such as strings, too: we simply treat them as huge integers. For example, the code at left computes a modular hash function for a String s: recall that charAt() returns a char value in Java, which is a 16-bit nonnegative integer. If R is greater than any character value, this computation would be equivalent to treating the String as an N-digit base-R integer, computing the remainder that results when dividing that number by M. A classic algorithm known as Horner&#8217;s method gets the job done with N multiplications, additions, and remainder operations. If the value of R is suf&#64257; - ciently small that no overflow occurs, the result is an integer between 0 and M &#8211; 1, as desired. The use of a small prime integer such as 31 ensures that the bits of all the characters play a role. Java&#8217;s default implementation for String uses a method like this.</p><p attribs="{'xml:space': 'preserve'}" id="_08172" smilref="Title.smil#_08172"> Hashing a string key</p><p attribs="{'xml:space': 'preserve'}" id="_08173" smilref="Title.smil#_08173"> Compound keys. If the key type has multiple integer fi elds, we can typically mix them together in the way just described for String values. For example, suppose that search keys are of type Date, which has three integer fi elds: day (two-digit day), month (two- digit month), and year (four-digit year).We compute the number</p><p attribs="{'xml:space': 'preserve'}" id="_08174" smilref="Title.smil#_08174"> int hash = (((day * R + month) % M ) * R + year) % M;</p><p attribs="{'xml:space': 'preserve'}" id="_08175" smilref="Title.smil#_08175" /><pagenum id="p474" page="normal" smilref="Title.smil#p474" /><p attribs="{'xml:space': 'preserve'}" id="_08176" smilref="Title.smil#_08176"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08177" smilref="Title.smil#_08177"> 461</p><p attribs="{'xml:space': 'preserve'}" id="_08178" smilref="Title.smil#_08178"> which, if the value of R is sufficiently small that no overflow occurs, is an integer between 0 and M &#8211; 1, as desired. In this case, we could save the cost of the inner % M operation by choosing a moderate prime value such as 31 for R. As with strings, this method generalizes to handle any number of fi elds.</p><p attribs="{'xml:space': 'preserve'}" id="_08179" smilref="Title.smil#_08179"> Java conventions. Java helps us address the basic problem that every type of data needs a hash function by ensuring that every data type inherits a method called hashCode() that returns a 32-bit integer. The implementation of hashCode() for a data type must be consistent with equals. That is, if a.equals(b) is true, then a.hashCode() must have the same numerical value as b.hashCode(). Conversely, if the hashCode() values are different, then we know that the objects are not equal. If the hashCode() values are the same, the objects may or may not be equal, and we must use equals() to decide which condition holds. This convention is a basic requirement for clients to be able to use hashCode() for symbol tables. Note that it implies that you must override both hashCode() and equals() if you need to hash with a user-de&#64257; ned type. The default implementation returns the machine address of the key object, which is seldom what you want. Java provides hashCode() implementations that override the defaults for many common types (including String, Integer, Double, File, and URL).</p><p attribs="{'xml:space': 'preserve'}" id="_08180" smilref="Title.smil#_08180"> Converting a hashCode() to an array index. Since our goal is an array index, not a 32-bit integer, we combine hashCode() with modular hashing in our implementations to produce integers between 0 and M &#8211; 1, as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_08181" smilref="Title.smil#_08181"> private int hash(Key x) { return (x.hashCode() &amp; 0x7fffffff) % M; }</p><p attribs="{'xml:space': 'preserve'}" id="_08182" smilref="Title.smil#_08182"> This code masks off the sign bit (to turn the 32-bit number into a 31-bit nonnegative integer) and then computes the remainder when dividing by M, as in modular hashing. Programmers commonly use a prime number for the hash table size M when using code like this, to attempt to make use of all the bits of the hash code. Note: To avoid con- fusion, we omit all of these calculations in our hashing examples and use instead the hash values in the table at right.</p><p attribs="{'xml:space': 'preserve'}" id="_08183" smilref="Title.smil#_08183"> Hash values for keys in examples</p><p attribs="{'xml:space': 'preserve'}" id="_08184" smilref="Title.smil#_08184"> hash (M = 5)</p><p attribs="{'xml:space': 'preserve'}" id="_08185" smilref="Title.smil#_08185"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08186" smilref="Title.smil#_08186"> S E A R C H X M P L</p><p attribs="{'xml:space': 'preserve'}" id="_08187" smilref="Title.smil#_08187"> 2 0 0 4 4 4 2 4 3 3</p><p attribs="{'xml:space': 'preserve'}" id="_08188" smilref="Title.smil#_08188"> hash (M = 16)</p><p attribs="{'xml:space': 'preserve'}" id="_08189" smilref="Title.smil#_08189"> 6 10 4 14 5 4 15 1 14 6</p><p attribs="{'xml:space': 'preserve'}" id="_08190" smilref="Title.smil#_08190"> User-de&#64257; ned hashCode(). Client code expects that hashCode() disperses the keys uniformly among the possible 32-bit result values. That is, for any object x, you can write x.hashCode() and, in principle, expect to get any one of the 232 possible 32-bit values with equal likelihood. Java&#8217;s hashCode() implementations for String, Integer, Double, File, and URL aspire to this functionality ; for your own type, you have to try to do it on your own. The Date example that we considered on page 460 illustrates</p><p attribs="{'xml:space': 'preserve'}" id="_08191" smilref="Title.smil#_08191" /><pagenum id="p475" page="normal" smilref="Title.smil#p475" /><p attribs="{'xml:space': 'preserve'}" id="_08192" smilref="Title.smil#_08192"> 462</p><p attribs="{'xml:space': 'preserve'}" id="_08193" smilref="Title.smil#_08193"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08194" smilref="Title.smil#_08194"> public class Transaction { ... private final String who; private final Date when; private final double amount;</p><p attribs="{'xml:space': 'preserve'}" id="_08195" smilref="Title.smil#_08195"> public int hashCode() { int hash = 17; hash = 31 * hash + who.hashCode(); hash = 31 * hash + when.hashCode(); hash = 31 * hash + ((Double) amount).hashCode(); return hash; } ... }</p><p attribs="{'xml:space': 'preserve'}" id="_08196" smilref="Title.smil#_08196"> one way to proceed: make integers from the instance variables and use modular hashing. In Java, the convention that all data types inherit a hashCode() method enables an even simpler approach: use the hashCode() method for the instance variables to convert each to a 32-bit int value and then do the arithmetic, as illustrated at left for Transaction. For primitive- type instance variables, note that a cast to a wrapper type is necessary to access the hashCode() method. Again, the precise values of the multiplier (31 in our exam- ple) is not particularly important.</p><p attribs="{'xml:space': 'preserve'}" id="_08197" smilref="Title.smil#_08197"> Implementing hashCode() in a user-def ined type</p><p attribs="{'xml:space': 'preserve'}" id="_08198" smilref="Title.smil#_08198"> Software caching. If computing the hash code is expensive, it may be worthwhile to cache the hash for each key. That is, we maintain an instance variable hash in the key type that contains the value of hashCode() for each key object (see Exercise 3.4.25). On the first call to hashCode(), we have to compute the full hash code (and set the value of hash), but subsequent calls on hashCode() simply return the value of hash. Java uses this technique to reduce the cost of computing hashCode() for String objects.</p><p attribs="{'xml:space': 'preserve'}" id="_08199" smilref="Title.smil#_08199"> In summary, we have three primary requirements in implementing a good hash</p><p attribs="{'xml:space': 'preserve'}" id="_08200" smilref="Title.smil#_08200"> function for a given data type: </p><p attribs="{'xml:space': 'preserve'}" id="_08201" smilref="Title.smil#_08201" /><pagenum id="p476" page="normal" smilref="Title.smil#p476" /><p attribs="{'xml:space': 'preserve'}" id="_08202" smilref="Title.smil#_08202"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08203" smilref="Title.smil#_08203"> 463</p><p attribs="{'xml:space': 'preserve'}" id="_08204" smilref="Title.smil#_08204"> 110 &#11015; 10679/97</p><p attribs="{'xml:space': 'preserve'}" id="_08205" smilref="Title.smil#_08205"> y c</p><p attribs="{'xml:space': 'preserve'}" id="_08206" smilref="Title.smil#_08206"> n e u q e</p><p attribs="{'xml:space': 'preserve'}" id="_08207" smilref="Title.smil#_08207"> r f</p><p attribs="{'xml:space': 'preserve'}" id="_08208" smilref="Title.smil#_08208"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08209" smilref="Title.smil#_08209"> Hash value frequencies for words in Tale of Two Cities (10,679 keys, M = 97)</p><p attribs="{'xml:space': 'preserve'}" id="_08210" smilref="Title.smil#_08210"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_08211" smilref="Title.smil#_08211"> 96</p><p attribs="{'xml:space': 'preserve'}" id="_08212" smilref="Title.smil#_08212"> hash function spread a typical set of keys uniformly among the values between 0 and M &#8211; 1? Doing simple experiments that answer these questions can protect future clients from unfortunate surprises. For example, the histogram above shows that our hash() implementation using the hashCode() from Java&#8217;s String data type produces a reasonable dispersion of the words for our Tale of Two Cities example. Underlying this discussion is a fundamental assumption that we make when using hashing; it is an idealized model that we do not actually expect to achieve, but it guides our thinking when implementing hashing algorithms and facilitates their analyses:</p><p attribs="{'xml:space': 'preserve'}" id="_08213" smilref="Title.smil#_08213"> Assumption J (uniform hashing assumption). The hash functions that we use uniformly and independently distribute keys among the integer values between 0 and M &#8211; 1.</p><p attribs="{'xml:space': 'preserve'}" id="_08214" smilref="Title.smil#_08214"> Discussion: With all of the arbitrary choices we have made, the Java hash functions that we have considered do not satisfy these conditions; nor can any deterministic hash function. The idea of constructing hash functions that uniformly and independently distribute keys leads to deep issues in theoretical computer science. In 1977, L. Carter and M. Wegman described how to construct a universal family of hash functions. If a hash function is chosen at random from a universal family, the hash function uniformly distributes the keys, but only with partial independence. Although weaker than full independence, the partial independence is sufficient to establish performance guarantees similar to those stated in Propositions K and M.</p><p attribs="{'xml:space': 'preserve'}" id="_08215" smilref="Title.smil#_08215"> Assumption J is a useful way to think about hashing for two primary reasons. First, it is a worthy goal when designing hash functions that guides us away from making arbitrary decisions that might lead to an excessive number of collisions. Second, we will use it to develop hypotheses about the performance of hashing algorithms&#8212;even when hash functions are not known to satisfy Assumption J, we can perform computational experiments and validate that they achieve the predicted performance.</p><p attribs="{'xml:space': 'preserve'}" id="_08216" smilref="Title.smil#_08216" /></level3><level3 id="_00058"><h3 id="ch3-s4-ss12" smilref="Title.smil#ch3-s4-ss12" xml:space="preserve">Separate chaining</h3><pagenum id="p477" page="normal" smilref="Title.smil#p477" /><p attribs="{'xml:space': 'preserve'}" id="_08217" smilref="Title.smil#_08217"> 464</p><p attribs="{'xml:space': 'preserve'}" id="_08218" smilref="Title.smil#_08218"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08219" smilref="Title.smil#_08219"> Hashing with separate chaining A hash function converts keys into array in- dices. The second component of a hashing algorithm is collision resolution: a strategy for handling the case when two or more keys to be inserted hash to the same index. A straightforward and general approach to collision resolution is to build, for each of the M array indices, a linked list of the key-value pairs whose keys hash to that index. This method is known as separate chaining because items that collide are chained together in separate linked lists. The basic idea is to choose M to be sufficiently large that the lists are sufficiently short to enable efficient search through a two-step process: hash to find the list that could contain the key, then sequentially search through that list for the key. One way to proceed is to ex-</p><p attribs="{'xml:space': 'preserve'}" id="_08220" smilref="Title.smil#_08220"> key hash value</p><p attribs="{'xml:space': 'preserve'}" id="_08221" smilref="Title.smil#_08221"> S 2 0</p><p attribs="{'xml:space': 'preserve'}" id="_08222" smilref="Title.smil#_08222"> E 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_08223" smilref="Title.smil#_08223"> A 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_08224" smilref="Title.smil#_08224"> R 4 3</p><p attribs="{'xml:space': 'preserve'}" id="_08225" smilref="Title.smil#_08225"> C 4 4</p><p attribs="{'xml:space': 'preserve'}" id="_08226" smilref="Title.smil#_08226"> H 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_08227" smilref="Title.smil#_08227"> E 0 6</p><p attribs="{'xml:space': 'preserve'}" id="_08228" smilref="Title.smil#_08228"> X 2 7</p><p attribs="{'xml:space': 'preserve'}" id="_08229" smilref="Title.smil#_08229"> A 0 8</p><p attribs="{'xml:space': 'preserve'}" id="_08230" smilref="Title.smil#_08230"> M 4 9</p><p attribs="{'xml:space': 'preserve'}" id="_08231" smilref="Title.smil#_08231"> P 3 10</p><p attribs="{'xml:space': 'preserve'}" id="_08232" smilref="Title.smil#_08232"> L 3 11</p><p attribs="{'xml:space': 'preserve'}" id="_08233" smilref="Title.smil#_08233"> E 0 12</p><p attribs="{'xml:space': 'preserve'}" id="_08234" smilref="Title.smil#_08234"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08235" smilref="Title.smil#_08235"> first</p><p attribs="{'xml:space': 'preserve'}" id="_08236" smilref="Title.smil#_08236"> A 8</p><p attribs="{'xml:space': 'preserve'}" id="_08237" smilref="Title.smil#_08237"> E 12</p><p attribs="{'xml:space': 'preserve'}" id="_08238" smilref="Title.smil#_08238"> first</p><p attribs="{'xml:space': 'preserve'}" id="_08239" smilref="Title.smil#_08239"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08240" smilref="Title.smil#_08240"> null</p><p attribs="{'xml:space': 'preserve'}" id="_08241" smilref="Title.smil#_08241"> X 7</p><p attribs="{'xml:space': 'preserve'}" id="_08242" smilref="Title.smil#_08242"> S 0</p><p attribs="{'xml:space': 'preserve'}" id="_08243" smilref="Title.smil#_08243"> L 11</p><p attribs="{'xml:space': 'preserve'}" id="_08244" smilref="Title.smil#_08244"> P 10</p><p attribs="{'xml:space': 'preserve'}" id="_08245" smilref="Title.smil#_08245"> first</p><p attribs="{'xml:space': 'preserve'}" id="_08246" smilref="Title.smil#_08246"> first</p><p attribs="{'xml:space': 'preserve'}" id="_08247" smilref="Title.smil#_08247"> first</p><p attribs="{'xml:space': 'preserve'}" id="_08248" smilref="Title.smil#_08248"> independent SequentialSearchST objects</p><p attribs="{'xml:space': 'preserve'}" id="_08249" smilref="Title.smil#_08249"> M 9</p><p attribs="{'xml:space': 'preserve'}" id="_08250" smilref="Title.smil#_08250"> H 5</p><p attribs="{'xml:space': 'preserve'}" id="_08251" smilref="Title.smil#_08251"> C 4</p><p attribs="{'xml:space': 'preserve'}" id="_08252" smilref="Title.smil#_08252"> R 3</p><p attribs="{'xml:space': 'preserve'}" id="_08253" smilref="Title.smil#_08253"> pand SequentialSearchST (Al-</p><p attribs="{'xml:space': 'preserve'}" id="_08254" smilref="Title.smil#_08254"> gorithm 3.1) to implement separate chaining using linked-list primitives (see Exercise 3.4.2). A simpler (though slightly less ef&#64257; cient) way to proceed is to adopt a more general approach: we build, for each of the M array indices, a symbol table of the keys that hash to that index, thus reusing code that we have already developed. The implementa-</p><p attribs="{'xml:space': 'preserve'}" id="_08255" smilref="Title.smil#_08255"> tion SeparateChainingHashST</p><p attribs="{'xml:space': 'preserve'}" id="_08256" smilref="Title.smil#_08256"> in Algorithm 3.5 maintains an</p><p attribs="{'xml:space': 'preserve'}" id="_08257" smilref="Title.smil#_08257"> array of SequentialSearchST</p><p attribs="{'xml:space': 'preserve'}" id="_08258" smilref="Title.smil#_08258"> Hashing with separate chaining for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_08259" smilref="Title.smil#_08259"> objects and implements get() and put() by computing a hash function to choose which SequentialSearchST object can contain the key and then using get() and put() (re- spectively) from SequentialSearchST to complete the job. Since we have M lists and N keys, the average length of the lists is always N &#11408; M, no matter how the keys are distributed among the lists. For example, suppose that all the items fall onto the first list&#8212;the average length of the lists is (N + 0 + 0 + 0 +. . . + 0)/M = N &#11408; M. However the keys are distributed on the lists, the sum of the list lengths is N and the average is N &#11408; M. Separate chaining is useful in practice because each list is extremely likely to have about N &#11408; M key-value pairs. In typical situations, we can verify this consequence of Assumption J and count on fast search and insert.</p><p attribs="{'xml:space': 'preserve'}" id="_08260" smilref="Title.smil#_08260" /><pagenum id="p478" page="normal" smilref="Title.smil#p478" /><p attribs="{'xml:space': 'preserve'}" id="_08261" smilref="Title.smil#_08261"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08262" smilref="Title.smil#_08262"> 465</p><p attribs="{'xml:space': 'preserve'}" id="_08263" smilref="Title.smil#_08263"> ALGORITHM 3.5 Hashing with separate chaining</p><p attribs="{'xml:space': 'preserve'}" id="_08264" smilref="Title.smil#_08264"> public class SeparateChainingHashST&lt;Key, Value&gt; { private int N; // number of key-value pairs private int M; // hash table size private SequentialSearchST&lt;Key, Value&gt;[] st; // array of ST objects</p><p attribs="{'xml:space': 'preserve'}" id="_08265" smilref="Title.smil#_08265"> public SeparateChainingHashST() { this(997); }</p><p attribs="{'xml:space': 'preserve'}" id="_08266" smilref="Title.smil#_08266"> public SeparateChainingHashST(int M) { // Create M linked lists. this.M = M; st = (SequentialSearchST&lt;Key, Value&gt;[]) new SequentialSearchST[M]; for (int i = 0; i &lt; M; i++) st[i] = new SequentialSearchST(); }</p><p attribs="{'xml:space': 'preserve'}" id="_08267" smilref="Title.smil#_08267"> private int hash(Key key) { return (key.hashCode() &amp; 0x7fffffff) % M; }</p><p attribs="{'xml:space': 'preserve'}" id="_08268" smilref="Title.smil#_08268"> public Value get(Key key) { return (Value) st[hash(key)].get(key); }</p><p attribs="{'xml:space': 'preserve'}" id="_08269" smilref="Title.smil#_08269"> public void put(Key key, Value val) { st[hash(key)].put(key, val); }</p><p attribs="{'xml:space': 'preserve'}" id="_08270" smilref="Title.smil#_08270"> public Iterable&lt;Key&gt; keys() // See Exercise 3.4.19.</p><p attribs="{'xml:space': 'preserve'}" id="_08271" smilref="Title.smil#_08271"> }</p><p attribs="{'xml:space': 'preserve'}" id="_08272" smilref="Title.smil#_08272"> This basic symbol-table implementation maintains an array of linked lists, using a hash function to choose a list for each key. For simplicity, we use SequentialSearchST methods. We need a cast when creating st[] because Java prohibits arrays with generics. The default constructor specifies 997 lists, so that for large tables, this code is about a factor of 1,000 faster than SequentialSearchST. This quick solution is an easy way to get good performance when you have some idea of the number of key-value pairs to be put() by a client. A more robust solution is to use array resizing to make sure that the lists are short no matter how many key-value pairs are in the table (see page 474 and Exercise</p><p attribs="{'xml:space': 'preserve'}" id="_08273" smilref="Title.smil#_08273"> 3.4.18).</p><p attribs="{'xml:space': 'preserve'}" id="_08274" smilref="Title.smil#_08274" /><pagenum id="p479" page="normal" smilref="Title.smil#p479" /><p attribs="{'xml:space': 'preserve'}" id="_08275" smilref="Title.smil#_08275"> 466</p><p attribs="{'xml:space': 'preserve'}" id="_08276" smilref="Title.smil#_08276"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08277" smilref="Title.smil#_08277"> Proposition K. In a separate-chaining hash table with M lists and N keys, the probability (under Assumption J) that the number of keys in a list is within a small constant factor of N/M is extremely close to 1. Proof sketch: Assumption J makes this an application of classical probability theory. We sketch the proof, for readers who are familiar with basic probabilistic analysis. The probability that a given list will contain exactly k keys is given by the binomial distribution</p><p attribs="{'xml:space': 'preserve'}" id="_08278" smilref="Title.smil#_08278"> k</p><p attribs="{'xml:space': 'preserve'}" id="_08279" smilref="Title.smil#_08279"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08280" smilref="Title.smil#_08280"> k(cid:51)(cid:0)(cid:36) 1</p><p attribs="{'xml:space': 'preserve'}" id="_08281" smilref="Title.smil#_08281"> M(cid:17)(cid:0)(cid:0)(cid:18) M &#8722; 1 M</p><p attribs="{'xml:space': 'preserve'}" id="_08282" smilref="Title.smil#_08282"> (cid:17)(cid:0)(cid:0)(cid:0)(cid:0)(cid:18)</p><p attribs="{'xml:space': 'preserve'}" id="_08283" smilref="Title.smil#_08283"> N &#8722; k</p><p attribs="{'xml:space': 'preserve'}" id="_08284" smilref="Title.smil#_08284"> (10, .12511...)</p><p attribs="{'xml:space': 'preserve'}" id="_08285" smilref="Title.smil#_08285"> .125</p><p attribs="{'xml:space': 'preserve'}" id="_08286" smilref="Title.smil#_08286"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08287" smilref="Title.smil#_08287"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08288" smilref="Title.smil#_08288"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_08289" smilref="Title.smil#_08289"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_08290" smilref="Title.smil#_08290"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_08291" smilref="Title.smil#_08291"> Binomial distribution (N = 10 4 , M = 10 3 , &#9251; = 10 )</p><p attribs="{'xml:space': 'preserve'}" id="_08292" smilref="Title.smil#_08292"> by the following argument: Choose k out of the N keys. Those k keys hash to the given list with probability 1 &#11408; M, and the other N &#8211; k keys do not hash to the given list with probability 1 &#8211; (1 &#11408; M ). In terms of &#9251; &#11005; N &#11408; M, we can rewrite this expression as</p><p attribs="{'xml:space': 'preserve'}" id="_08293" smilref="Title.smil#_08293"> N &#8722; k</p><p attribs="{'xml:space': 'preserve'}" id="_08294" smilref="Title.smil#_08294"> k</p><p attribs="{'xml:space': 'preserve'}" id="_08295" smilref="Title.smil#_08295"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08296" smilref="Title.smil#_08296"> k(cid:51)(cid:0)(cid:36) (cid:65)</p><p attribs="{'xml:space': 'preserve'}" id="_08297" smilref="Title.smil#_08297"> (cid:17)(cid:0)(cid:0)(cid:18) (cid:17)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:18)</p><p attribs="{'xml:space': 'preserve'}" id="_08298" smilref="Title.smil#_08298"> 1 &#8722;</p><p attribs="{'xml:space': 'preserve'}" id="_08299" smilref="Title.smil#_08299"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08300" smilref="Title.smil#_08300"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08301" smilref="Title.smil#_08301"> (cid:65)</p><p attribs="{'xml:space': 'preserve'}" id="_08302" smilref="Title.smil#_08302"> which (for small &#9251;) is closely approximated by the classical Poisson distribution</p><p attribs="{'xml:space': 'preserve'}" id="_08303" smilref="Title.smil#_08303"> (cid:65)ke &#8722;(cid:65)</p><p attribs="{'xml:space': 'preserve'}" id="_08304" smilref="Title.smil#_08304"> k!</p><p attribs="{'xml:space': 'preserve'}" id="_08305" smilref="Title.smil#_08305"> (10, .12572...)</p><p attribs="{'xml:space': 'preserve'}" id="_08306" smilref="Title.smil#_08306"> .125</p><p attribs="{'xml:space': 'preserve'}" id="_08307" smilref="Title.smil#_08307"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08308" smilref="Title.smil#_08308"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08309" smilref="Title.smil#_08309"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_08310" smilref="Title.smil#_08310"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_08311" smilref="Title.smil#_08311"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_08312" smilref="Title.smil#_08312"> Poisson distribution (N = 10 4 , M = 10 3 , &#9251; = 10 )</p><p attribs="{'xml:space': 'preserve'}" id="_08313" smilref="Title.smil#_08313"> It follows that the probability that a list has more than t &#9251; keys on it is bounded by the quantity (&#9251; e/t)t e &#8211;&#9251;. This probability is extremely small for practical ranges of the parameters. For example, if the average length of the lists is 10, the probability that we will hash to some list with more than 20 keys on it is less than (10 e/2)2 e &#8211;10 &#11015; 0.0084, and if the average length of the lists is 20, the probability that we will hash to some list with more than 40 keys on it is less than (20 e/2)2 e &#8211;20 &#11015; 0.0000016. This concentration result does not guarantee that every list will be short. Indeed it is known that, if &#9251; is a constant, the average length of the longest list grows with log N / log log N.</p><p attribs="{'xml:space': 'preserve'}" id="_08314" smilref="Title.smil#_08314" /><pagenum id="p480" page="normal" smilref="Title.smil#p480" /><p attribs="{'xml:space': 'preserve'}" id="_08315" smilref="Title.smil#_08315"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08316" smilref="Title.smil#_08316"> 467</p><p attribs="{'xml:space': 'preserve'}" id="_08317" smilref="Title.smil#_08317"> This classical mathematical analysis is compelling, but it is important to note that it completely depends on Assumption J. If the hash function is not uniform and inde- pendent, the search and insert cost could be proportional to N, no better than with sequential search. Assumption J is much stronger than the corresponding assumption for other probabilistic algorithms that we have seen, and much more difficult to verify. With hashing, we are assuming that each and every key, no matter how complex, is equally likely to be hashed to one of M indices. We cannot afford to run experiments to test every possible key, so we would have to do more sophisticated experiments involving random sampling from the set of possible keys used in an application, followed by statistical analysis. Better still, we can use the algorithm itself as part of the test, to validate both Assumption J and the mathematical results that we derive from it.</p><p attribs="{'xml:space': 'preserve'}" id="_08318" smilref="Title.smil#_08318"> Property L. In a separate-chaining hash table with M lists and N keys, the number of compares (equality tests) for search miss and insert is ~N/M.</p><p attribs="{'xml:space': 'preserve'}" id="_08319" smilref="Title.smil#_08319"> Evidence: Good performance of the algorithms in practice does not require the hash function to be fully uniform in the technical sense of Assumption J. Count- less programmers since the 1950s have seen the speedups predicted by Proposi- tion K, even for hash functions that are certainly not uniform. For example, the diagram on page 468 shows that list length distribution for our FrequencyCounter example (using our hash() implementation based on the hashCode() from Java&#8217;s String data type) precisely matches the theoretical model. One exception that has been documented on numerous occasions is poor performance due to hash functions not taking all of the bits of the keys into account. Otherwise, the preponderance of the evidence from the experience of practical programmers puts us on solid ground in stating that hashing with separate chaining using an array of size M speeds up search and insert in a symbol table by a factor of M.</p><p attribs="{'xml:space': 'preserve'}" id="_08320" smilref="Title.smil#_08320"> Table size. In a separate-chaining implementation, our goal is to choose the table size M to be sufficiently small that we do not waste a huge area of contiguous memory with empty chains but sufficiently large that we do not waste time searching through long chains. One of the virtues of separate chaining is that this decision is not critical: if more keys arrive than expected, then searches will take a little longer than if we had chosen a bigger table size ahead of time; if fewer keys are in the table, then we have ex- tra-fast search with some wasted space. When space is not a critical resource, M can be chosen sufficiently large that search time is constant; when space is a critical resource, we still can get a factor of M improvement in performance by choosing M to be as</p><p attribs="{'xml:space': 'preserve'}" id="_08321" smilref="Title.smil#_08321" /><pagenum id="p481" page="normal" smilref="Title.smil#p481" /><p attribs="{'xml:space': 'preserve'}" id="_08322" smilref="Title.smil#_08322"> 468</p><p attribs="{'xml:space': 'preserve'}" id="_08323" smilref="Title.smil#_08323"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08324" smilref="Title.smil#_08324"> 125</p><p attribs="{'xml:space': 'preserve'}" id="_08325" smilref="Title.smil#_08325"> y c</p><p attribs="{'xml:space': 'preserve'}" id="_08326" smilref="Title.smil#_08326"> n e u q e</p><p attribs="{'xml:space': 'preserve'}" id="_08327" smilref="Title.smil#_08327"> r f</p><p attribs="{'xml:space': 'preserve'}" id="_08328" smilref="Title.smil#_08328"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08329" smilref="Title.smil#_08329"> &#9251; = 10.711...)</p><p attribs="{'xml:space': 'preserve'}" id="_08330" smilref="Title.smil#_08330"> &#9251;ke &#8722;&#9251;</p><p attribs="{'xml:space': 'preserve'}" id="_08331" smilref="Title.smil#_08331"> k!</p><p attribs="{'xml:space': 'preserve'}" id="_08332" smilref="Title.smil#_08332"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08333" smilref="Title.smil#_08333"> 10 20 list lengths (10,679 keys, M = 997) List lengths for java FrequencyCounter 8 &lt; tale.txt using SeparateChainingHashST</p><p attribs="{'xml:space': 'preserve'}" id="_08334" smilref="Title.smil#_08334"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_08335" smilref="Title.smil#_08335"> large as we can afford. For our example FrequencyCounter study, we see in the figure below a reduction in the average cost from thousands of compares per operation for SequentialSearchST to a small constant for SeparateChainingHashST, as expected. Another option is to use array resizing to keep the lists short (see Exercise 3.4.18).</p><p attribs="{'xml:space': 'preserve'}" id="_08336" smilref="Title.smil#_08336"> Deletion. To delete a key-value pair, simply hash to find the SequentialSearchST containing the key, then invoke the delete() method for that table (see Exercise 3.1.5). Reusing code in this way is preferable to reimplementing this basic operation on linked lists.</p><p attribs="{'xml:space': 'preserve'}" id="_08337" smilref="Title.smil#_08337"> Ordered operations. The whole point of hashing is to uniformly disperse the keys, so any order in the keys is lost when hashing. If you need to quickly find the maximum or minimum key, find keys in a given range, or implement any of the other operations in the ordered symbol-table API on page 366, then hashing is not appropriate, since these operations will all take linear time.</p><p attribs="{'xml:space': 'preserve'}" id="_08338" smilref="Title.smil#_08338"> Hashing with separate chaining is easy to implement and probably the fastest (and most widely used) symbol-table implementation for applications where key order is not important. When your keys are built-in Java types or your own type with well- tested implementations of hashCode(), Algorithm 3.5 provides a quick and easy path to fast search and insert. Next, we consider an alternative scheme for collision resolution that is also effective.</p><p attribs="{'xml:space': 'preserve'}" id="_08339" smilref="Title.smil#_08339"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_08340" smilref="Title.smil#_08340"> s t s</p><p attribs="{'xml:space': 'preserve'}" id="_08341" smilref="Title.smil#_08341"> e</p><p attribs="{'xml:space': 'preserve'}" id="_08342" smilref="Title.smil#_08342"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08343" smilref="Title.smil#_08343"> y</p><p attribs="{'xml:space': 'preserve'}" id="_08344" smilref="Title.smil#_08344"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08345" smilref="Title.smil#_08345"> i l</p><p attribs="{'xml:space': 'preserve'}" id="_08346" smilref="Title.smil#_08346"> a u q e</p><p attribs="{'xml:space': 'preserve'}" id="_08347" smilref="Title.smil#_08347"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08348" smilref="Title.smil#_08348"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08349" smilref="Title.smil#_08349"> cumulative average</p><p attribs="{'xml:space': 'preserve'}" id="_08350" smilref="Title.smil#_08350"> 14350 Costs for java FrequencyCounter 8 &lt; tale.txt using SeparateChainingHashST (M = 997)</p><p attribs="{'xml:space': 'preserve'}" id="_08351" smilref="Title.smil#_08351"> operations</p><p attribs="{'xml:space': 'preserve'}" id="_08352" smilref="Title.smil#_08352"> 3.9</p><p attribs="{'xml:space': 'preserve'}" id="_08353" smilref="Title.smil#_08353" /></level3><level3 id="_00059"><h3 id="ch3-s4-ss13" smilref="Title.smil#ch3-s4-ss13" xml:space="preserve">Linear probing</h3><pagenum id="p482" page="normal" smilref="Title.smil#p482" /><p attribs="{'xml:space': 'preserve'}" id="_08354" smilref="Title.smil#_08354"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08355" smilref="Title.smil#_08355"> 469</p><p attribs="{'xml:space': 'preserve'}" id="_08356" smilref="Title.smil#_08356"> Hashing with linear probing Another approach to implementing hashing is to store N key-value pairs in a hash table of size M &gt; N, relying on empty entries in the table to help with collision resolution. Such methods are called open-addressing hashing methods. The simplest open-addressing method is called linear probing: when there is a collision (when we hash to a table index that is already occupied with a key different from the search key), then we just check the next entry in the table (by incrementing the index). Linear probing is characterized by identifying three possible outcomes: </p><p attribs="{'xml:space': 'preserve'}" id="_08357" smilref="Title.smil#_08357"> key hash value</p><p attribs="{'xml:space': 'preserve'}" id="_08358" smilref="Title.smil#_08358"> S 6 0</p><p attribs="{'xml:space': 'preserve'}" id="_08359" smilref="Title.smil#_08359"> E 10 1</p><p attribs="{'xml:space': 'preserve'}" id="_08360" smilref="Title.smil#_08360"> A 4 2</p><p attribs="{'xml:space': 'preserve'}" id="_08361" smilref="Title.smil#_08361"> R 14 3</p><p attribs="{'xml:space': 'preserve'}" id="_08362" smilref="Title.smil#_08362"> C 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_08363" smilref="Title.smil#_08363"> H 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_08364" smilref="Title.smil#_08364"> E 10 6</p><p attribs="{'xml:space': 'preserve'}" id="_08365" smilref="Title.smil#_08365"> X 15 7</p><p attribs="{'xml:space': 'preserve'}" id="_08366" smilref="Title.smil#_08366"> A 4 8</p><p attribs="{'xml:space': 'preserve'}" id="_08367" smilref="Title.smil#_08367"> M 1 9</p><p attribs="{'xml:space': 'preserve'}" id="_08368" smilref="Title.smil#_08368"> P 14 10</p><p attribs="{'xml:space': 'preserve'}" id="_08369" smilref="Title.smil#_08369"> L 6 11</p><p attribs="{'xml:space': 'preserve'}" id="_08370" smilref="Title.smil#_08370"> E 10 12</p><p attribs="{'xml:space': 'preserve'}" id="_08371" smilref="Title.smil#_08371"> entries in red are new</p><p attribs="{'xml:space': 'preserve'}" id="_08372" smilref="Title.smil#_08372"> keys in black are probes</p><p attribs="{'xml:space': 'preserve'}" id="_08373" smilref="Title.smil#_08373"> entries in gray are untouched</p><p attribs="{'xml:space': 'preserve'}" id="_08374" smilref="Title.smil#_08374"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 S 0 S E 0 1 A S E 2 0 1 A S E R 2 0 1 3 A C S E R 2 4 0 1 3 A C S H E R 2 4 0 5 1 3 A C S H E R 2 4 0 5 6 3 A C S H E R X 2 4 0 5 6 3 7 A C S H E R X 8 4 0 5 6 3 7 M A C S H E R X 9 8 4 0 5 6 3 7 P M A C S H E R X 10 9 8 4 0 5 6 3 7 P M A C S H L E R X 10 9 8 4 0 5 6 3 7 11 P M A C S H L E R X 10 9 8 4 0 5 3 7 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_08375" smilref="Title.smil#_08375"> probe sequence wraps to 0</p><p attribs="{'xml:space': 'preserve'}" id="_08376" smilref="Title.smil#_08376"> Trace of linear-probing ST implementation for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_08377" smilref="Title.smil#_08377"> keys[] vals[]</p><p attribs="{'xml:space': 'preserve'}" id="_08378" smilref="Title.smil#_08378" /><pagenum id="p483" page="normal" smilref="Title.smil#p483" /><p attribs="{'xml:space': 'preserve'}" id="_08379" smilref="Title.smil#_08379"> 470</p><p attribs="{'xml:space': 'preserve'}" id="_08380" smilref="Title.smil#_08380"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08381" smilref="Title.smil#_08381"> ALGORITHM 3.6 Hashing with linear probing</p><p attribs="{'xml:space': 'preserve'}" id="_08382" smilref="Title.smil#_08382"> public class LinearProbingHashST&lt;Key, Value&gt; { private int N; // number of key-value pairs in the table private int M = 16; // size of linear-probing table private Key[] keys; // the keys private Value[] vals; // the values</p><p attribs="{'xml:space': 'preserve'}" id="_08383" smilref="Title.smil#_08383"> public LinearProbingHashST() { keys = (Key[]) new Object[M]; vals = (Value[]) new Object[M]; }</p><p attribs="{'xml:space': 'preserve'}" id="_08384" smilref="Title.smil#_08384"> private int hash(Key key) { return (key.hashCode() &amp; 0x7fffffff) % M; }</p><p attribs="{'xml:space': 'preserve'}" id="_08385" smilref="Title.smil#_08385"> private void resize()</p><p attribs="{'xml:space': 'preserve'}" id="_08386" smilref="Title.smil#_08386"> // See page 474.</p><p attribs="{'xml:space': 'preserve'}" id="_08387" smilref="Title.smil#_08387"> public void put(Key key, Value val) { if (N &gt;= M/2) resize(2*M); // double M (see text)</p><p attribs="{'xml:space': 'preserve'}" id="_08388" smilref="Title.smil#_08388"> int i; for (i = hash(key); keys[i] != null; i = (i + 1) % M) if (keys[i].equals(key)) { vals[i] = val; return; } keys[i] = key; vals[i] = val; N++; }</p><p attribs="{'xml:space': 'preserve'}" id="_08389" smilref="Title.smil#_08389"> public Value get(Key key) { for (int i = hash(key); keys[i] != null; i = (i + 1) % M) if (keys[i].equals(key)) return vals[i]; return null; } }</p><p attribs="{'xml:space': 'preserve'}" id="_08390" smilref="Title.smil#_08390"> This symbol-table implementation keeps keys and values in parallel arrays (as in BinarySearchST) but uses empty spaces (marked by null) to terminate clusters of keys. If a new key hashes to an empty entry, it is stored there; if not, we scan sequentially to find an empty position. To search for a key, we scan sequentially starting at its hash index until finding null (search miss) or the key (search hit). Implementation of keys() is left as Exercise 3.4.19.</p><p attribs="{'xml:space': 'preserve'}" id="_08391" smilref="Title.smil#_08391" /><pagenum id="p484" page="normal" smilref="Title.smil#p484" /><p attribs="{'xml:space': 'preserve'}" id="_08392" smilref="Title.smil#_08392"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08393" smilref="Title.smil#_08393"> 471</p><p attribs="{'xml:space': 'preserve'}" id="_08394" smilref="Title.smil#_08394"> holds an item whose key is equal to the search key as a probe. We use the term interchangeably with the term compare that we have been using, even though some probes are tests for null. The essential idea behind hashing with open addressing is this: rather than using memory space for references in linked lists, we use it for the empty entries in the hash table, which mark the ends of probe sequences. As you can see from LinearProbingHashST (Algorithm 3.6), applying this idea to implement the symbol-table API is quite straightforward. We implement the table with parallel arrays, one for the keys and one for the values, and use the hash function as an index to access the data as just discussed.</p><p attribs="{'xml:space': 'preserve'}" id="_08395" smilref="Title.smil#_08395"> Deletion. How do we delete a key-value pair from a linear-probing table? If you think about the situation for a moment, you will see that setting the key&#8217;s table position to null will not work, because that might prematurely terminate the search for a key that was inserted into the table later. As an example, suppose that we try to delete C in this way in our trace example, then search for H. The hash value for H is 4, but it sits at the end of the cluster, in position 7. If we set position 5 to null, then get() will not find H. As a consequence, we need to reinsert into the table all of the keys in the cluster to the right of the deleted key. This process is trickier than it might seem, so you are encouraged to trace through the code at right for an example that exercises it (see Exercise 3.4.17).</p><p attribs="{'xml:space': 'preserve'}" id="_08396" smilref="Title.smil#_08396"> As with separate chaining, the performance of</p><p attribs="{'xml:space': 'preserve'}" id="_08397" smilref="Title.smil#_08397"> public void delete(Key key) { if (!contains(key)) return; int i = hash(key); while (!key.equals(keys[i])) i = (i + 1) % M; keys[i] = null; vals[i] = null; i = (i + 1) % M; while (keys[i] != null) { Key keyToRedo = keys[i]; Value valToRedo = vals[i]; keys[i] = null; vals[i] = null; N--; put(keyToRedo, valToRedo); i = (i + 1) % M; } N--; if (N &gt; 0 &amp;&amp; N == M/8) resize(M/2); }</p><p attribs="{'xml:space': 'preserve'}" id="_08398" smilref="Title.smil#_08398"> hashing with open addressing depends on the ratio &#9251; &#11005; N &#11408; M, but we interpret it differently. We refer to &#9251; as the load factor of a hash table. For separate chaining, &#9251; is the average number of keys per list and is generally larger than 1; for linear probing, &#9251; is the percentage of table entries that are occu- pied; it cannot be greater than 1. In fact, we cannot let the load factor reach 1 (completely full table) in LinearProbingHashST because a search miss would go into an infinite loop in a full table. Indeed, for the sake of good performance, we use array resizing to guarantee that the load factor is between one-eighth and one-half. This strategy is validated by mathematical analysis, which we consider before we discuss implementation details.</p><p attribs="{'xml:space': 'preserve'}" id="_08399" smilref="Title.smil#_08399"> Deletion for linear probing</p><p attribs="{'xml:space': 'preserve'}" id="_08400" smilref="Title.smil#_08400" /><pagenum id="p485" page="normal" smilref="Title.smil#p485" /><p attribs="{'xml:space': 'preserve'}" id="_08401" smilref="Title.smil#_08401"> 472</p><p attribs="{'xml:space': 'preserve'}" id="_08402" smilref="Title.smil#_08402"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08403" smilref="Title.smil#_08403"> before</p><p attribs="{'xml:space': 'preserve'}" id="_08404" smilref="Title.smil#_08404"> after</p><p attribs="{'xml:space': 'preserve'}" id="_08405" smilref="Title.smil#_08405"> key lands here in that event</p><p attribs="{'xml:space': 'preserve'}" id="_08406" smilref="Title.smil#_08406"> and forms a much longer cluster</p><p attribs="{'xml:space': 'preserve'}" id="_08407" smilref="Title.smil#_08407"> 9/64 chance of new key hitting this cluster</p><p attribs="{'xml:space': 'preserve'}" id="_08408" smilref="Title.smil#_08408"> Clustering. The average cost of linear probing depends on the way in which the entries clump together into contiguous groups of occupied table entries, called clusters, when they are inserted. For example, when the key C is inserted in our example, the result is a cluster ( A C S ) of length 3, which means that four probes are needed to insert H because H hashes to the first position in the cluster. Short clusters are certainly a requirement for efficient perfor- mance. This requirement can be problematic as the table fi lls, because long clusters are common. Moreover, since all table positions are equally likely to be the hash value of the next key to be inserted (under the uniform hashing assumption), long clusters are more likely to increase in length than short ones, because a new key hashing to any entry in the cluster will cause the cluster to increase in length by 1 (and possibly much more, if there is just one table entry separating the cluster from the next one). Next, we turn to the challenge of quantifying the effect of clustering to predict performance in linear probing, and using that knowledge to set design parameters in our implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_08409" smilref="Title.smil#_08409"> Clustering in linear probing (M = 64)</p><p attribs="{'xml:space': 'preserve'}" id="_08410" smilref="Title.smil#_08410"> linear probing</p><p attribs="{'xml:space': 'preserve'}" id="_08411" smilref="Title.smil#_08411"> random</p><p attribs="{'xml:space': 'preserve'}" id="_08412" smilref="Title.smil#_08412"> long clusters are common</p><p attribs="{'xml:space': 'preserve'}" id="_08413" smilref="Title.smil#_08413"> keys[0..127]</p><p attribs="{'xml:space': 'preserve'}" id="_08414" smilref="Title.smil#_08414"> &#9251; = 1/2</p><p attribs="{'xml:space': 'preserve'}" id="_08415" smilref="Title.smil#_08415"> &#9251; = 1/4</p><p attribs="{'xml:space': 'preserve'}" id="_08416" smilref="Title.smil#_08416"> Table occupancy patterns (2,048 keys, tables laid out in 128-position rows)</p><p attribs="{'xml:space': 'preserve'}" id="_08417" smilref="Title.smil#_08417"> keys[8064..8192]</p><p attribs="{'xml:space': 'preserve'}" id="_08418" smilref="Title.smil#_08418" /><pagenum id="p486" page="normal" smilref="Title.smil#p486" /><p attribs="{'xml:space': 'preserve'}" id="_08419" smilref="Title.smil#_08419"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08420" smilref="Title.smil#_08420"> 473</p><p attribs="{'xml:space': 'preserve'}" id="_08421" smilref="Title.smil#_08421"> Analysis of linear probing. Despite the relatively simple form of the results, precise analysis of linear probing is a very challenging task. Knuth&#8217;s derivation of the following formulas in 1962 was a landmark in the analysis of algorithms:</p><p attribs="{'xml:space': 'preserve'}" id="_08422" smilref="Title.smil#_08422"> Proposition M. In a linear-probing hash table with M lists and N = &#9251; M keys, the average number of probes (under Assumption J) required is</p><p attribs="{'xml:space': 'preserve'}" id="_08423" smilref="Title.smil#_08423"> ~</p><p attribs="{'xml:space': 'preserve'}" id="_08424" smilref="Title.smil#_08424"> 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_08425" smilref="Title.smil#_08425"> (cid:17)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:18)</p><p attribs="{'xml:space': 'preserve'}" id="_08426" smilref="Title.smil#_08426"> 1 1 &#8722; (cid:65)</p><p attribs="{'xml:space': 'preserve'}" id="_08427" smilref="Title.smil#_08427"> 1 +</p><p attribs="{'xml:space': 'preserve'}" id="_08428" smilref="Title.smil#_08428"> and</p><p attribs="{'xml:space': 'preserve'}" id="_08429" smilref="Title.smil#_08429"> ~</p><p attribs="{'xml:space': 'preserve'}" id="_08430" smilref="Title.smil#_08430"> 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_08431" smilref="Title.smil#_08431"> (cid:17)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:18)</p><p attribs="{'xml:space': 'preserve'}" id="_08432" smilref="Title.smil#_08432"> 1 1 + (1 &#8722; (cid:65))2</p><p attribs="{'xml:space': 'preserve'}" id="_08433" smilref="Title.smil#_08433"> for search hits and search misses (or inserts), respectively. In particular, when &#9251; is about 1/2, the average number of probes for a search hit is about 3/2 and for a search miss is about 5/2. These estimates lose a bit of precision as &#9251; approaches 1, but we do not need them for that case, because we will only use linear probing for &#9251; less than one-half.</p><p attribs="{'xml:space': 'preserve'}" id="_08434" smilref="Title.smil#_08434"> Discussion: We compute the average by computing the cost of a search miss starting at each position in the table, then dividing the total by M. All search misses take at least 1 probe, so we count the number of probes after the fi rst. Consider the following two extremes in a linear-probing table that is half full (M = 2N): In the best case, table positions with even indices could be empty, and table positions with odd indices could be occupied. In the worst case, the first half of the table positions could be empty, and the second half occupied. The average length of the clusters in both cases is N/(2N) = 1/2, but the average number of probes for a search miss is 1 (all searches take at least 1 probe) plus (0 + 1 + 0 + 1 +. . . )/(2 N) = 1/2 in the best case, and is 1 plus (N + (N &#8211; 1) + . . .) &#11408; (2 N) ~ N/4 in the worst case. This argument generalizes to show that the average number of probes for a search miss is proportional to the squares of the lengths of the clusters: If a cluster is of length t, then the expression (t + (t &#8211; 1) + . . . + 2 + 1) / M = t(t + 1)/(2M) counts the contribution of that cluster to the grand total. The sum of the cluster lengths is N, so, adding this cost for all entries in the table, we find that the total average cost for a search miss is 1 + N &#11408; (2M) plus the sum of the squares of the lengths of the clusters, divided by 2M. Thus, given a table, we can quickly compute the average cost of a search miss in that table (see Exercise 3.4.21). In general, the clusters are formed by a complicated dynamic process (the linear-probing algorithm) that is difficult to characterize analytically, and quite beyond the scope of this book.</p><p attribs="{'xml:space': 'preserve'}" id="_08435" smilref="Title.smil#_08435" /><pagenum id="p487" page="normal" smilref="Title.smil#p487" /><p attribs="{'xml:space': 'preserve'}" id="_08436" smilref="Title.smil#_08436"> 474</p><p attribs="{'xml:space': 'preserve'}" id="_08437" smilref="Title.smil#_08437"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08438" smilref="Title.smil#_08438"> Proposition M tells us (under our usual Assumption J) that we can expect a search to require a huge number of probes in a nearly full table (as &#9251; approaches 1 the values of the formulas describing the number of probes grow very large) but that the expected number of probes is between 1.5 and 2.5 if we can ensure that the load factor &#9251; is less than 1/2. Next, we consider the use of array resizing for this purpose.</p><p attribs="{'xml:space': 'preserve'}" id="_08439" smilref="Title.smil#_08439"> private void resize(int cap) { LinearProbingHashST&lt;Key, Value&gt; t; t = new LinearProbingHashST&lt;Key, Value&gt;(cap); for (int i = 0; i &lt; M; i++) if (keys[i] != null) t.put(keys[i], vals[i]); keys = t.keys; vals = t.vals; M = t.M; }</p><p attribs="{'xml:space': 'preserve'}" id="_08440" smilref="Title.smil#_08440"> Resizing a linear-probing hash table</p><p attribs="{'xml:space': 'preserve'}" id="_08441" smilref="Title.smil#_08441"> Array resizing We can use our standard array-resizing technique from Chapter 1 to ensure that the load factor never exceeds one-half. First, we need a new constructor for LinearProbingHashST that takes a fixed capacity as argument (add a line to the constructor 3.6 that sets M to the given value before creating the arrays). Next, we need the resize() method given at left, which creates a new</p><p attribs="{'xml:space': 'preserve'}" id="_08442" smilref="Title.smil#_08442"> in Algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_08443" smilref="Title.smil#_08443"> LinearProbingHashST of the giv-</p><p attribs="{'xml:space': 'preserve'}" id="_08444" smilref="Title.smil#_08444"> en size, puts all the keys and values in the table in the new one, then rehashes all the keys into the new table. These additions allow us to implement array doubling. The call to resize() in the first statement in put() ensures that the table is at most one-half full. This code builds a hash table twice the size with the same keys, thus halving the value of &#9251;. As in other applications of array resizing, we also need to add</p><p attribs="{'xml:space': 'preserve'}" id="_08445" smilref="Title.smil#_08445"> if (N &gt; 0 &amp;&amp; N &lt;= M/8) resize(M/2);</p><p attribs="{'xml:space': 'preserve'}" id="_08446" smilref="Title.smil#_08446"> as the last statement in delete() to ensure that the table is at least one-eighth full. This ensures that the amount of memory used is always within a constant factor of the number of key-value pairs in the table. With array resizing, we are assured that &#9251; &#11349; 1/2.</p><p attribs="{'xml:space': 'preserve'}" id="_08447" smilref="Title.smil#_08447"> Separate chaining. The same method works to keep lists short (of average length between 2 and 8) in separate chaining: replace LinearProbingHashST by</p><p attribs="{'xml:space': 'preserve'}" id="_08448" smilref="Title.smil#_08448"> SeparateChainingHashST in resize(), call resize(2*M) when (N &gt;= M/2) in put(),</p><p attribs="{'xml:space': 'preserve'}" id="_08449" smilref="Title.smil#_08449"> and call resize(M/2) when (N &gt; 0 &amp;&amp; N &lt;= M/8) in delete(). For separate chain- ing, array resizing is optional and not worth your trouble if you have a decent estimate of the client&#8217;s N: just pick a table size M based on the knowledge that search times are proportional to 1+ N/M. For linear probing, array resizing is necessary. A client that inserts more key-value pairs than you expect will encounter not just excessively long search times, but an infinite loop when the table fi lls.</p><p attribs="{'xml:space': 'preserve'}" id="_08450" smilref="Title.smil#_08450" /><pagenum id="p488" page="normal" smilref="Title.smil#p488" /><p attribs="{'xml:space': 'preserve'}" id="_08451" smilref="Title.smil#_08451"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08452" smilref="Title.smil#_08452"> 475</p><p attribs="{'xml:space': 'preserve'}" id="_08453" smilref="Title.smil#_08453"> Amortized analysis. From a theoretical standpoint, when we use array resizing, we must settle for an amortized bound, since we know that those insertions that cause the table to double will require a large number of probes.</p><p attribs="{'xml:space': 'preserve'}" id="_08454" smilref="Title.smil#_08454"> Proposition N. Suppose a hash table is built with array resizing, starting with an empty table. Under Assumption J, any sequence of t search, insert, and delete symbol-table operations is executed in expected time proportional to t and with memory usage always within a constant factor of the number of keys in the table.</p><p attribs="{'xml:space': 'preserve'}" id="_08455" smilref="Title.smil#_08455"> Proof.: For both separate chaining and linear probing, this fact follows from a simple restatement of the amortized analysis for array growth that we first discussed in</p><p attribs="{'xml:space': 'preserve'}" id="_08456" smilref="Title.smil#_08456"> Chapter 1, coupled with Proposition K and Proposition M.</p><p attribs="{'xml:space': 'preserve'}" id="_08457" smilref="Title.smil#_08457"> cumulative average</p><p attribs="{'xml:space': 'preserve'}" id="_08458" smilref="Title.smil#_08458"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_08459" smilref="Title.smil#_08459"> s t s</p><p attribs="{'xml:space': 'preserve'}" id="_08460" smilref="Title.smil#_08460"> e</p><p attribs="{'xml:space': 'preserve'}" id="_08461" smilref="Title.smil#_08461"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08462" smilref="Title.smil#_08462"> y</p><p attribs="{'xml:space': 'preserve'}" id="_08463" smilref="Title.smil#_08463"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08464" smilref="Title.smil#_08464"> i l</p><p attribs="{'xml:space': 'preserve'}" id="_08465" smilref="Title.smil#_08465"> a u q e</p><p attribs="{'xml:space': 'preserve'}" id="_08466" smilref="Title.smil#_08466"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08467" smilref="Title.smil#_08467"> 0 14350 Costs for java FrequencyCounter 8 &lt; tale.txt using SeparateChainingHashST (with doubling)</p><p attribs="{'xml:space': 'preserve'}" id="_08468" smilref="Title.smil#_08468"> operations</p><p attribs="{'xml:space': 'preserve'}" id="_08469" smilref="Title.smil#_08469"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_08470" smilref="Title.smil#_08470"> s t s</p><p attribs="{'xml:space': 'preserve'}" id="_08471" smilref="Title.smil#_08471"> e</p><p attribs="{'xml:space': 'preserve'}" id="_08472" smilref="Title.smil#_08472"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08473" smilref="Title.smil#_08473"> y</p><p attribs="{'xml:space': 'preserve'}" id="_08474" smilref="Title.smil#_08474"> t</p><p attribs="{'xml:space': 'preserve'}" id="_08475" smilref="Title.smil#_08475"> i l</p><p attribs="{'xml:space': 'preserve'}" id="_08476" smilref="Title.smil#_08476"> a u q e</p><p attribs="{'xml:space': 'preserve'}" id="_08477" smilref="Title.smil#_08477"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08478" smilref="Title.smil#_08478"> cumulative average</p><p attribs="{'xml:space': 'preserve'}" id="_08479" smilref="Title.smil#_08479"> operations 0 14350 Costs for java FrequencyCounter 8 &lt; tale.txt using LinearProbingHashST (with doubling)</p><p attribs="{'xml:space': 'preserve'}" id="_08480" smilref="Title.smil#_08480"> 4.2</p><p attribs="{'xml:space': 'preserve'}" id="_08481" smilref="Title.smil#_08481"> 3.2</p><p attribs="{'xml:space': 'preserve'}" id="_08482" smilref="Title.smil#_08482" /><pagenum id="p489" page="normal" smilref="Title.smil#p489" /><p attribs="{'xml:space': 'preserve'}" id="_08483" smilref="Title.smil#_08483"> 476</p><p attribs="{'xml:space': 'preserve'}" id="_08484" smilref="Title.smil#_08484"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08485" smilref="Title.smil#_08485"> The plots of the cumulative averages for our FrequencyCounter example (shown at the bottom of the previous page) nicely illustrate the dynamic behavior of array resizing in hashing. Each time the array doubles, the cumulative average increases by about 1, because each key in the table needs to be rehashed; then it decreases because about half as many keys hash to each table position, with the rate of decrease slowing as the table fills again.</p><p attribs="{'xml:space': 'preserve'}" id="_08486" smilref="Title.smil#_08486"> Memory As we have indicated, understanding memory usage is an important factor if we want to tune hashing algorithms for optimum performance. While such tuning is for experts, it is a worthwhile exercise to calculate a rough estimate of the amount of memory required, by estimating the number of references used, as follows: Not counting the memory for keys and values, our implementation SeparateChainingHashST uses memory for M references to SequentialSearchST objects plus M SequentialSearchST objects. Each SequentialSearchST object has the usual 16 bytes of object overhead plus one 8-byte reference (first), and there are a total of N Node objects, each with 24 bytes of object overhead plus 3 references (key, value, and next). This compares with an extra reference per node for binary search trees. With array resizing to ensure that the table is between one-eighth and one-half full, linear probing uses between 4N and 16N references. Thus, choosing hashing on the basis of memory usage is not normally justi&#64257; ed. The calculation is a bit different for primitive types (see Exercise 3.4.24)</p><p attribs="{'xml:space': 'preserve'}" id="_08487" smilref="Title.smil#_08487"> method</p><p attribs="{'xml:space': 'preserve'}" id="_08488" smilref="Title.smil#_08488"> space usage for N items (reference types)</p><p attribs="{'xml:space': 'preserve'}" id="_08489" smilref="Title.smil#_08489"> separate chaining</p><p attribs="{'xml:space': 'preserve'}" id="_08490" smilref="Title.smil#_08490"> ~ 48 N + 32 M</p><p attribs="{'xml:space': 'preserve'}" id="_08491" smilref="Title.smil#_08491"> linear probing</p><p attribs="{'xml:space': 'preserve'}" id="_08492" smilref="Title.smil#_08492"> between ~32 N and ~128 N</p><p attribs="{'xml:space': 'preserve'}" id="_08493" smilref="Title.smil#_08493"> BSTs</p><p attribs="{'xml:space': 'preserve'}" id="_08494" smilref="Title.smil#_08494"> ~56 N</p><p attribs="{'xml:space': 'preserve'}" id="_08495" smilref="Title.smil#_08495"> Space usage in symbol tables</p><p attribs="{'xml:space': 'preserve'}" id="_08496" smilref="Title.smil#_08496" /><pagenum id="p490" page="normal" smilref="Title.smil#p490" /><p attribs="{'xml:space': 'preserve'}" id="_08497" smilref="Title.smil#_08497"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08498" smilref="Title.smil#_08498"> 477</p><p attribs="{'xml:space': 'preserve'}" id="_08499" smilref="Title.smil#_08499"> Since the earliest days of computing, researchers have studied (and are study- ing) hashing and have found many ways to improve the basic algorithms that we have discussed. You can find a huge literature on the subject. Most of the improvements push down the space-time curve: you can get the same running time for searches using less space or get faster searches using the same amount of space. Other improvements involve better guarantees, on the expected worst-case cost of a search. Others involve improved hash-function designs. Some of these methods are addressed in the exercises. Detailed comparison of separate chaining and linear probing depends on myriad implementation details and on client space and time requirements. It is not normally justified to choose separate chaining over linear probing on the basis of performance (see Exercise 3.5.31). In practice, the primary performance difference between the two methods has to do with the fact that separate chaining uses a small block of memory for each key-value pair, while linear probing uses two large arrays for the whole table. For huge tables, these needs place quite different burdens on the memory management system. In modern systems, this sort of tradeoff is best addressed by experts in extreme performance-critical situations. With hashing, under generous assumptions, it is not unreasonable to expect to support the search and insert symbol-table operations in constant time, independent of the size of the table. This expectation is the theoretical optimum performance for any symbol-table implementation. Still, hashing is not a panacea, for several reasons, including: </p><p attribs="{'xml:space': 'preserve'}" id="_08500" smilref="Title.smil#_08500" /><pagenum id="p491" page="normal" smilref="Title.smil#p491" /><p attribs="{'xml:space': 'preserve'}" id="_08501" smilref="Title.smil#_08501"> 478</p><p attribs="{'xml:space': 'preserve'}" id="_08502" smilref="Title.smil#_08502"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08503" smilref="Title.smil#_08503"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_08504" smilref="Title.smil#_08504"> Q. How does Java implement hashCode() for Integer, Double, and Long? A. For Integer it just returns the 32-bit value. For Double and Long it returns the exclusive or of the first 32 bits with the second 32 bits of the standard machine representation of the number. These choices may not seem to be very random, but they do serve the purpose of spreading out the values. Q. When using array resizing, the size of the table is always a power of 2. Isn&#8217;t that a potential problem, because it only uses the least significant bits of hashCode()? A. Yes, particularly with the default implementations. One way to address this problem is to first distribute the key values using a prime larger than M, as in the following example:</p><p attribs="{'xml:space': 'preserve'}" id="_08505" smilref="Title.smil#_08505"> primes[k] (2k &#8722; &#9254;</p><p attribs="{'xml:space': 'preserve'}" id="_08506" smilref="Title.smil#_08506"> &#9254;</p><p attribs="{'xml:space': 'preserve'}" id="_08507" smilref="Title.smil#_08507"> k</p><p attribs="{'xml:space': 'preserve'}" id="_08508" smilref="Title.smil#_08508"> k</p><p attribs="{'xml:space': 'preserve'}" id="_08509" smilref="Title.smil#_08509"> k) 5 1 31 6 3 61 7 1 127 8 5 251 9 3 509 10 3 1021 11 9 2039 12 3 4093 13 1 8191 14 3 16381 15 19 32749 16 15 65521 17 1 131071 18 5 262139 19 1 524287 20 3 1048573 21 9 2097143 22 3 4194301 23 15 8388593 24 3 16777213 25 39 33554393 26 5 67108859 27 39 134217689 28 57 268435399 29 3 536870909 30 35 1073741789 31 1 2147483647</p><p attribs="{'xml:space': 'preserve'}" id="_08510" smilref="Title.smil#_08510"> private int hash(Key x) { int t = x.hashCode() &amp; 0x7fffffff; if (lgM &lt; 26) t = t % primes[lgM+5]; return t % M; }</p><p attribs="{'xml:space': 'preserve'}" id="_08511" smilref="Title.smil#_08511"> This code assumes that we maintain an instance variable lgM that is equal to lg M (by initializing to the appropriate value, incrementing when doubling, and decrementing when halving) and an array primes[] of the smallest prime greater than each power of 2 (see the table at right). The constant 5 is an arbitrary choice&#8212;we expect the first % to distribute the values equally among the values less than the prime and the second to map about five of those values to each value less than M. Note that the point is moot for large M. Q. I&#8217;ve forgotten. Why don&#8217;t we implement hash(x) by returning x.hashCode() % M? A. We need a result between 0 and M-1, but in Java, the % function may be negative. Q. So, why not implement hash(x) by returning Math.abs(x.hashcode()) % M?</p><p attribs="{'xml:space': 'preserve'}" id="_08512" smilref="Title.smil#_08512"> Primes for hash table sizes</p><p attribs="{'xml:space': 'preserve'}" id="_08513" smilref="Title.smil#_08513" /><pagenum id="p492" page="normal" smilref="Title.smil#p492" /><p attribs="{'xml:space': 'preserve'}" id="_08514" smilref="Title.smil#_08514"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08515" smilref="Title.smil#_08515"> 479</p><p attribs="{'xml:space': 'preserve'}" id="_08516" smilref="Title.smil#_08516"> A. Nice try. Unfortunately, Math.abs() returns a negative result for the largest negative number. For many typical calculations, this overflow presents no real problem, but for hashing it would leave you with a program that is likely to crash after a few billion inserts, an unsettling possibility. For example, s.hashCode() is &#11002;231 for the Java String value "polygenelubricants". Finding other strings that hash to this value (and to 0) has turned into an amusing algorithm-puzzle pastime. Q. Do Java library hash function satisfy Assumption J? A. No. For example, the hashCode() implementation in the String data type is not only deterministic but it is specified in the API.</p><p attribs="{'xml:space': 'preserve'}" id="_08517" smilref="Title.smil#_08517"> Q. Why not use BinarySearchST or RedBlackBST instead of SequentialSearchST in</p><p attribs="{'xml:space': 'preserve'}" id="_08518" smilref="Title.smil#_08518"> Algorithm 3.5?</p><p attribs="{'xml:space': 'preserve'}" id="_08519" smilref="Title.smil#_08519"> A. Generally, we set parameters so as to make the number of keys hashing to each value small, and elementary symbol tables are generally better for the small tables. In certain situations, slight performance gains may be achieved with such hybrid methods, but such tuning is best left for experts. Q. Is hashing faster than searching in red-black BSTs? A. It depends on the type of the key, which determines the cost of computing hashCode() versus the cost of compareTo(). For typical key types and for Java default implementations, these costs are similar, so hashing will be significantly faster, since it uses only a constant number of operations. But it is important to remember that this question is moot if you need ordered operations, which are not efficiently supported in hash tables. See Section 3.5 for further discussion. Q. Why not let the linear probing table get, say, three-quarters full? A. No particular reason. You can choose any value of &#9251;, using Proposition M to estimate search costs. For &#9251; = 3/4, the average cost of search hits is 2.5 and search misses is 8.5, but if you let &#9251; grow to 7/8, the average cost of a search miss is 32.5, perhaps more than you want to pay. As &#9251; gets close to 1, the estimate in Proposition M becomes in- valid, but you don&#8217;t want your table to get that close to being full.</p><p attribs="{'xml:space': 'preserve'}" id="_08520" smilref="Title.smil#_08520" /><pagenum id="p493" page="normal" smilref="Title.smil#p493" /><p attribs="{'xml:space': 'preserve'}" id="_08521" smilref="Title.smil#_08521"> 480</p><p attribs="{'xml:space': 'preserve'}" id="_08522" smilref="Title.smil#_08522"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08523" smilref="Title.smil#_08523"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_08524" smilref="Title.smil#_08524"> 3.4.1 Insert the keys E A S Y Q U T I O N in that order into an initially empty table of M = 5 lists, using separate chaining. Use the hash function 11 k % M to transform the kth letter of the alphabet into a table index. 3.4.2 Develop an alternate implementation of SeparateChainingHashST that directly uses the linked-list code from SequentialSearchST. 3.4.3 Modify your implementation of the previous exercise to include an integer field for each key-value pair that is set to the number of entries in the table at the time that pair is inserted. Then implement a method that deletes all keys (and associated values) for which the field is greater than a given integer k. Note : This extra functionality is useful in implementing the symbol table for a compiler. 3.4.4 Write a program to find values of a and M, with M as small as possible, such that the hash function (a * k) % M for transforming the kth letter of the alphabet into a table index produces distinct values (no collisions) for the keys S E A R C H X M P L. The result is known as a perfect hash function. 3.4.5 Is the following implementation of hashCode() legal?</p><p attribs="{'xml:space': 'preserve'}" id="_08525" smilref="Title.smil#_08525"> public int hashCode() { return 17; }</p><p attribs="{'xml:space': 'preserve'}" id="_08526" smilref="Title.smil#_08526"> If so, describe the effect of using it. If not, explain why. 3.4.6 Suppose that keys are t-bit integers. For a modular hash function with prime M, prove that each key bit has the property that there exist two keys differing only in that bit that have different hash values. 3.4.7 Consider the idea of implementing modular hashing for integer keys with the code (a * k) % M , where a is an arbitrary fixed prime. Does this change mix up the bits sufficiently well that you can use nonprime M? 3.4.8 How many empty lists do you expect to see when you insert N keys into a hash table with SeparateChainingHashST, for N=10, 102, 103, 104, 105, and 106? Hint : See</p><p attribs="{'xml:space': 'preserve'}" id="_08527" smilref="Title.smil#_08527"> Exercise 2.5.31.</p><p attribs="{'xml:space': 'preserve'}" id="_08528" smilref="Title.smil#_08528"> 3.4.9 Implement an eager delete() method for SeparateChainingHashST. 3.4.10 Insert the keys E A S Y Q U T I O N in that order into an initially empty table</p><p attribs="{'xml:space': 'preserve'}" id="_08529" smilref="Title.smil#_08529" /><pagenum id="p494" page="normal" smilref="Title.smil#p494" /><p attribs="{'xml:space': 'preserve'}" id="_08530" smilref="Title.smil#_08530"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08531" smilref="Title.smil#_08531"> 481</p><p attribs="{'xml:space': 'preserve'}" id="_08532" smilref="Title.smil#_08532"> of size M =16 using linear probing. Use the hash function 11 k % M to transform the kth letter of the alphabet into a table index. Redo this exercise for M = 10. 3.4.11 Give the contents of a linear-probing hash table that results when you insert the keys E A S Y Q U T I O N in that order into an initially empty table of initial size M = 4 that is expanded with doubling whenever half full. Use the hash function 11 k % M to transform the kth letter of the alphabet into a table index. 3.4.12 Suppose that the keys A through G, with the hash values given below, are inserted in some order into an initially empty table of size 7 using a linear-probing table (with no resizing for this problem).</p><p attribs="{'xml:space': 'preserve'}" id="_08533" smilref="Title.smil#_08533"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08534" smilref="Title.smil#_08534"> A B C D E F G</p><p attribs="{'xml:space': 'preserve'}" id="_08535" smilref="Title.smil#_08535"> hash (M = 7)</p><p attribs="{'xml:space': 'preserve'}" id="_08536" smilref="Title.smil#_08536"> 2 0 0 4 4 4 2</p><p attribs="{'xml:space': 'preserve'}" id="_08537" smilref="Title.smil#_08537"> Which of the following could not possibly result from inserting these keys?</p><p attribs="{'xml:space': 'preserve'}" id="_08538" smilref="Title.smil#_08538"> a. E F G A C B D b. C E B G F D A c. B D F A C E G d. C G B A D E F e. F G B D A C E f. G E C A D B F</p><p attribs="{'xml:space': 'preserve'}" id="_08539" smilref="Title.smil#_08539"> Give the minimum and the maximum number of probes that could be required to build a table of size 7 with these keys, and an insertion order that justifies your answer. 3.4.13 Which of the following scenarios leads to expected linear running time for a random search hit in a linear-probing hash table?</p><p attribs="{'xml:space': 'preserve'}" id="_08540" smilref="Title.smil#_08540"> a. All keys hash to the same index. b. All keys hash to different indices. c. All keys hash to an even-numbered index. d. All keys hash to different even-numbered indices. 3.4.14 Answer the previous question for search miss, assuming the search key is equally likely to hash to each table position. 3.4.15 How many compares could it take, in the worst case, to insert N keys into an initially empty table, using linear probing with array resizing?</p><p attribs="{'xml:space': 'preserve'}" id="_08541" smilref="Title.smil#_08541" /><pagenum id="p495" page="normal" smilref="Title.smil#p495" /><p attribs="{'xml:space': 'preserve'}" id="_08542" smilref="Title.smil#_08542"> 482</p><p attribs="{'xml:space': 'preserve'}" id="_08543" smilref="Title.smil#_08543"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08544" smilref="Title.smil#_08544"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08545" smilref="Title.smil#_08545"> 3.4.16 Suppose that a linear-probing table of size 106 is half full, with occupied positions chosen at random. Estimate the probability that all positions with indices divisible by 100 are occupied. 3.4.17 Show the result of using the delete() method on page 471 to delete C from the table resulting from using LinearProbingHashST with our standard indexing client (shown on page 469). 3.4.18 Add a constructor to SeparateChainingHashST that gives the client the ability to specify the average number of probes to be tolerated for searches. Use array resizing to keep the average list size less than the specified value, and use the technique described on page 478 to ensure that the modulus for hash() is prime.</p><p attribs="{'xml:space': 'preserve'}" id="_08546" smilref="Title.smil#_08546"> 3.4.19 Implement keys() for SeparateChainingHashST and LinearProbingHashST.</p><p attribs="{'xml:space': 'preserve'}" id="_08547" smilref="Title.smil#_08547"> 3.4.20 Add a method to LinearProbingHashST that computes the average cost of a search hit in the table, assuming that each key in the table is equally likely to be sought. 3.4.21 Add a method to LinearProbingHashST that computes the average cost of a search miss in the table, assuming a random hash function. Note : You do not have to compute any hash functions to solve this problem. 3.4.22 Implement hashCode() for various types: Point2D, Interval, Interval2D, and Date. 3.4.23 Consider modular hashing for string keys with R = 256 and M = 255. Show that this is a bad choice because any permutation of letters within a string hashes to the same value. 3.4.24 Analyze the space usage of separate chaining, linear probing, and BSTs for double keys. Present your results in a table like the one on page 476.</p><p attribs="{'xml:space': 'preserve'}" id="_08548" smilref="Title.smil#_08548" /><pagenum id="p496" page="normal" smilref="Title.smil#p496" /><p attribs="{'xml:space': 'preserve'}" id="_08549" smilref="Title.smil#_08549"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08550" smilref="Title.smil#_08550"> 483</p><p attribs="{'xml:space': 'preserve'}" id="_08551" smilref="Title.smil#_08551"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_08552" smilref="Title.smil#_08552"> 3.4.25 Hash cache. Modify Transaction on page 462 to maintain an instance variable hash, so that hashCode() can save the hash value the first time it is called for each object and does not have to recompute it on subsequent calls. Note : This idea works only for immutable types. 3.4.26 Lazy delete for linear probing. Add to LinearProbingHashST a delete() method that deletes a key-value pair by setting the value to null (but not removing the key) and later removing the pair from the table in resize(). Your primary challenge is to decide when to call resize(). Note : You should overwrite the null value if a subsequent put() operation associates a new value with the key. Make sure that your program takes into account the number of such tombstone items, as well as the number of empty positions, in making the decision whether to expand or contract the table. 3.4.27 Double probing. Modify SeparateChainingHashST to use a second hash function and pick the shorter of the two lists. Give a trace of the process of inserting the keys E A S Y Q U T I O N in that order into an initially empty table of size M =3 using the function 11 k % M (for the kth letter) as the first hash function and the function 17 k % M (for the kth letter) as the second hash function. Give the average number of probes for random search hit and search miss in this table. 3.4.28 Double hashing. Modify LinearProbingHashST to use a second hash function to define the probe sequence. Speci&#64257; cally, replace (i + 1) % M (both occurrences) by (i + k) % M where k is a nonzero key-dependent integer that is relatively prime to M. Note : You may meet the last condition by assuming that M is prime. Give a trace of the process of inserting the keys E A S Y Q U T I O N in that order into an initially empty table of size M =11, using the hash functions described in the previous exercise. Give the average number of probes for random search hit and search miss in this table. 3.4.29 Deletion. Implement an eager delete() method for the methods described in each of the previous two exercises. 3.4.30 Chi-square statistic. Add a method to SeparateChainingST to compute the &#9273; 2 statistic for the hash table. With N keys and table size M, this number is defined by the equation</p><p attribs="{'xml:space': 'preserve'}" id="_08553" smilref="Title.smil#_08553"> &#9273; 2</p><p attribs="{'xml:space': 'preserve'}" id="_08554" smilref="Title.smil#_08554"> = (M/N) ( (f0 &#11002; N/M)2 + (f1 &#11002; N/M)2 &#11001; . . . (fM &#11002; 1 &#11002; N/M)2 )</p><p attribs="{'xml:space': 'preserve'}" id="_08555" smilref="Title.smil#_08555" /><pagenum id="p497" page="normal" smilref="Title.smil#p497" /><p attribs="{'xml:space': 'preserve'}" id="_08556" smilref="Title.smil#_08556"> 484</p><p attribs="{'xml:space': 'preserve'}" id="_08557" smilref="Title.smil#_08557"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08558" smilref="Title.smil#_08558"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08559" smilref="Title.smil#_08559"> where fi is the number of keys with hash value i. This statistic is one way of checking our assumption that the hash function produces random values. If so, this statistic, for N &gt; cM, should be between M &#11002; &#20881; M and M + &#20881; M with probability 1 &#11002; 1/c. 3.4.31 Cuckoo hashing. Develop a symbol-table implementation that maintains two hash tables and two hash functions. Any given key is in one of the tables, but not both. When inserting a new key, hash to one of the tables; if the table position is occupied, replace that key with the new key and hash the old key into the other table (again kicking out a key that might reside there). If this process cycles, restart. Keep the tables less than half full. This method uses a constant number of equality tests in the worst case for search (trivial) and amortized constant time for insert. 3.4.32 Hash attack. Find 2N strings, each of length 2N, that have the same hashCode() value, supposing that the hashCode() implementation for String is the following:</p><p attribs="{'xml:space': 'preserve'}" id="_08560" smilref="Title.smil#_08560"> public int hashCode() { int hash = 0; for (int i = 0; i &lt; length(); i ++) hash = (hash * 31) + charAt(i); return hash; }</p><p attribs="{'xml:space': 'preserve'}" id="_08561" smilref="Title.smil#_08561"> Strong hint : Aa and BB have the same value. 3.4.33 Bad hash function. Consider the following hashCode() implementation for String, which was used in early versions of Java:</p><p attribs="{'xml:space': 'preserve'}" id="_08562" smilref="Title.smil#_08562"> public int hashCode() { int hash = 0; int skip = Math.max(1, length()/8); for (int i = 0; i &lt; length(); i += skip) hash = (hash * 37) + charAt(i); return hash; }</p><p attribs="{'xml:space': 'preserve'}" id="_08563" smilref="Title.smil#_08563"> Explain why you think the designers chose this implementation and then why you think it was abandoned in favor of the one in the previous exercise.</p><p attribs="{'xml:space': 'preserve'}" id="_08564" smilref="Title.smil#_08564" /><pagenum id="p498" page="normal" smilref="Title.smil#p498" /><p attribs="{'xml:space': 'preserve'}" id="_08565" smilref="Title.smil#_08565"> 3.4 </p><p attribs="{'xml:space': 'preserve'}" id="_08566" smilref="Title.smil#_08566"> 485</p><p attribs="{'xml:space': 'preserve'}" id="_08567" smilref="Title.smil#_08567"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_08568" smilref="Title.smil#_08568"> 3.4.34 Hash cost. Determine empirically the ratio of the time required for hash() to the time required for compareTo(), for as many commonly-used types of keys for which you can get meaningful results. 3.4.35 Chi-square test. Use your solution from Exercise 3.4.30 to check the assumption that the hash functions for commonly-used key types produce random values. 3.4.36 List length range. Write a program that inserts N random int keys into a table of size N / 100 using separate chaining, then finds the length of the shortest and longest lists, for N = 10 3, 10 4, 10 5, 10 6. 3.4.37 Hybrid. Run experimental studies to determine the effect of using RedBlackBST</p><p attribs="{'xml:space': 'preserve'}" id="_08569" smilref="Title.smil#_08569"> instead of SequentialSearchST to handle collisions in SeparateChainingHashST.</p><p attribs="{'xml:space': 'preserve'}" id="_08570" smilref="Title.smil#_08570"> This solution carries the advantage of guaranteeing logarithmic performance even for a bad hash function and the disadvantage of necessitating maintenance of two different symbol-table implementations. What are the practical effects? 3.4.38 Separate-chaining distribution. Write a program that inserts 10 5 random nonnegative integers less than 10 6 into a table of size 10 5 using linear probing, and that plots the total number of probes used for each 10 3 consecutive insertions. Discuss the extent to which your results validate Proposition K. 3.4.39 Linear-probing distribution. Write a program that inserts N/2 random int keys into a table of size N using linear probing, then computes the average cost of a search miss in the resulting table from the cluster lengths, for N = 10 3, 10 4, 10 5, 10 6. Discuss the extent to which your results validate Proposition M.</p><p attribs="{'xml:space': 'preserve'}" id="_08571" smilref="Title.smil#_08571"> 3.4.40 Plots. Instrument LinearProbingHashST and SeparateChainingHashST to</p><p attribs="{'xml:space': 'preserve'}" id="_08572" smilref="Title.smil#_08572"> produce plots like the ones shown in the text. 3.4.41 Double probing. Run experimental studies to evaluate the effectiveness of double probing (see Exercise 3.4.27). 3.4.42 Double hashing. Run experimental studies to evaluate the effectiveness of double hashing (see Exercise 3.4.28). 3.4.43 Parking problem. (D. Knuth) Run experimental studies to validate the hypothesis that the number of compares needed to insert M random keys into a linear-probing table of size M is ~cM 3/2, where c = &#20881;&#9266;/2.</p><p attribs="{'xml:space': 'preserve'}" id="_08573" smilref="Title.smil#_08573" /><pagenum id="p500" page="normal" smilref="Title.smil#p500" /><p attribs="{'xml:space': 'preserve'}" id="_08574" smilref="Title.smil#_08574"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08575" smilref="Title.smil#_08575"> 487</p><p attribs="{'xml:space': 'preserve'}" id="_08576" smilref="Title.smil#_08576"> Which symbol-table implementation should I use? The table at the bottom</p><p attribs="{'xml:space': 'preserve'}" id="_08577" smilref="Title.smil#_08577"> of this page summarizes the performance characteristics of the algorithms that we have considered in propositions and properties in this chapter (with the exception of the worst-case results for hashing, which are from the research literature and unlikely to be experienced in practice). It is clear from the table that, for typical applications, your decision comes down to a choice between hash tables and binary search trees. The advantages of hashing over BST implementations are that the code is simpler and search times are optimal (constant), if the keys are of a standard type or are suf- fi ciently simple that we can be confident of developing an efficient hash function for them that (approximately) satisfies the uniform hashing assumption. The advantages of BSTs over hashing are that they are based on a simpler abstract interface (no hash function need be designed); red-black BSTs can provide guaranteed worst-case perfor- mance; and they support a wider range of operations (such as rank, select, sort, and range search). As a rule of thumb, most programmers will use hashing except when one or more of these factors is important, when red-black BSTs are called for. In Chap- ter 5, we will study one exception to this rule of thumb: when keys are long strings, we can build data structures that are even more flexible than red-black BSTs and even faster than hashing.</p><p attribs="{'xml:space': 'preserve'}" id="_08578" smilref="Title.smil#_08578"> algorithm (data structure)</p><p attribs="{'xml:space': 'preserve'}" id="_08579" smilref="Title.smil#_08579"> sequential search (unordered list) binary search (ordered array) binary tree search (BST) 2-3 tree search (red-black BST) separate chaining&#8224; (array of lists) linear probing&#8224; (parallel arrays)</p><p attribs="{'xml:space': 'preserve'}" id="_08580" smilref="Title.smil#_08580"> worst-case cost (after N inserts) search insert</p><p attribs="{'xml:space': 'preserve'}" id="_08581" smilref="Title.smil#_08581"> average-case cost (after N random inserts) search hit insert</p><p attribs="{'xml:space': 'preserve'}" id="_08582" smilref="Title.smil#_08582"> key interface</p><p attribs="{'xml:space': 'preserve'}" id="_08583" smilref="Title.smil#_08583"> memory (bytes)</p><p attribs="{'xml:space': 'preserve'}" id="_08584" smilref="Title.smil#_08584"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08585" smilref="Title.smil#_08585"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08586" smilref="Title.smil#_08586"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08587" smilref="Title.smil#_08587"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08588" smilref="Title.smil#_08588"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08589" smilref="Title.smil#_08589"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08590" smilref="Title.smil#_08590"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_08591" smilref="Title.smil#_08591"> lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08592" smilref="Title.smil#_08592"> N</p><p attribs="{'xml:space': 'preserve'}" id="_08593" smilref="Title.smil#_08593"> N/2</p><p attribs="{'xml:space': 'preserve'}" id="_08594" smilref="Title.smil#_08594"> equals()</p><p attribs="{'xml:space': 'preserve'}" id="_08595" smilref="Title.smil#_08595"> compareTo()</p><p attribs="{'xml:space': 'preserve'}" id="_08596" smilref="Title.smil#_08596"> 1.39 lg N 1.39 lg N compareTo()</p><p attribs="{'xml:space': 'preserve'}" id="_08597" smilref="Title.smil#_08597"> 2 lg N 2 lg N 1.00 lg N 1.00 lg N compareTo()</p><p attribs="{'xml:space': 'preserve'}" id="_08598" smilref="Title.smil#_08598"> 48 N</p><p attribs="{'xml:space': 'preserve'}" id="_08599" smilref="Title.smil#_08599"> 16 N</p><p attribs="{'xml:space': 'preserve'}" id="_08600" smilref="Title.smil#_08600"> 64 N</p><p attribs="{'xml:space': 'preserve'}" id="_08601" smilref="Title.smil#_08601"> 64 N</p><p attribs="{'xml:space': 'preserve'}" id="_08602" smilref="Title.smil#_08602"> &lt; lg N &lt; lg N N / (2M )</p><p attribs="{'xml:space': 'preserve'}" id="_08603" smilref="Title.smil#_08603"> N / M</p><p attribs="{'xml:space': 'preserve'}" id="_08604" smilref="Title.smil#_08604"> c lg N c lg N</p><p attribs="{'xml:space': 'preserve'}" id="_08605" smilref="Title.smil#_08605"> &lt; 1.50</p><p attribs="{'xml:space': 'preserve'}" id="_08606" smilref="Title.smil#_08606"> &lt; 2.50</p><p attribs="{'xml:space': 'preserve'}" id="_08607" smilref="Title.smil#_08607"> equals() hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_08608" smilref="Title.smil#_08608"> equals() hashCode()</p><p attribs="{'xml:space': 'preserve'}" id="_08609" smilref="Title.smil#_08609"> 48 N + 64 M</p><p attribs="{'xml:space': 'preserve'}" id="_08610" smilref="Title.smil#_08610"> between</p><p attribs="{'xml:space': 'preserve'}" id="_08611" smilref="Title.smil#_08611"> 32 N and 128 N</p><p attribs="{'xml:space': 'preserve'}" id="_08612" smilref="Title.smil#_08612"> &#8224; under uniform hashing assumption</p><p attribs="{'xml:space': 'preserve'}" id="_08613" smilref="Title.smil#_08613"> Asymptotic cost summary for symbol-table implementations</p><p attribs="{'xml:space': 'preserve'}" id="_08614" smilref="Title.smil#_08614" /></level3><level3 id="_00060"><h3 id="ch3-s5-ss14" smilref="Title.smil#ch3-s5-ss14" xml:space="preserve">Set data type</h3><pagenum id="p501" page="normal" smilref="Title.smil#p501" /><p attribs="{'xml:space': 'preserve'}" id="_08615" smilref="Title.smil#_08615"> 488</p><p attribs="{'xml:space': 'preserve'}" id="_08616" smilref="Title.smil#_08616"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08617" smilref="Title.smil#_08617"> Our symbol-table implementations are useful for a wide range of applications, but our algorithms are easily adapted to support several other options that are widely used and worth considering.</p><p attribs="{'xml:space': 'preserve'}" id="_08618" smilref="Title.smil#_08618"> Primitive types. Suppose that we have a symbol table with integer keys and associated fl oating-point numbers. When we use our standard setup, the keys and values are stored as Integer and Double wrapper-type values, so we need two extra memory references to access each key-value pair. These references may be no problem in an application that involves thousands of searches on thousands of keys but may represent excessive cost in an application that involves billions of searches on millions of keys. Us- ing a primitive type instead of Key would save one reference per key-value pair. When the associated value is also primitive, we can eliminate another reference. The situation is diagrammed at right for separate chaining; the same tradeoffs hold for other implementations. For performance-critical applications, it is worthwhile and not difficult to develop versions of our implementations along these lines (see Exercise 3.5.4). Duplicate keys. The possibility of duplicate keys sometimes needs special consideration in symbol- table implementations. In many applications, it is desirable to associate multiple values with the same key. For example, in a transaction-processing sys- tem, numerous transactions may have the same customer key value. Our convention to disallow duplicate keys amounts to leaving duplicate-key management to the client. We will consider an example of such a client later in this section. In many of our implementations, we could consider the alternative of leaving key-value pairs with duplicate keys in the primary search data structure and to return any value with the given key for a search. We might also add methods to return all values with the given key. Our BST and hashing implementations are not difficult to adapt to keep duplicate keys within the data structure; doing so for red-black BSTs is just slightly more challenging (see Ex- ercise 3.5.9 and Exercise 3.5.10). Such implementations are common in the literature (including earlier editions of this book).</p><p attribs="{'xml:space': 'preserve'}" id="_08619" smilref="Title.smil#_08619"> Memory usage for separate chaining</p><p attribs="{'xml:space': 'preserve'}" id="_08620" smilref="Title.smil#_08620"> data is stored in linked-list nodes</p><p attribs="{'xml:space': 'preserve'}" id="_08621" smilref="Title.smil#_08621"> standard implementation</p><p attribs="{'xml:space': 'preserve'}" id="_08622" smilref="Title.smil#_08622"> data is stored in Key and Value objects</p><p attribs="{'xml:space': 'preserve'}" id="_08623" smilref="Title.smil#_08623"> primitive-type implementation</p><p attribs="{'xml:space': 'preserve'}" id="_08624" smilref="Title.smil#_08624" /><pagenum id="p502" page="normal" smilref="Title.smil#p502" /><p attribs="{'xml:space': 'preserve'}" id="_08625" smilref="Title.smil#_08625"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08626" smilref="Title.smil#_08626"> 489</p><p attribs="{'xml:space': 'preserve'}" id="_08627" smilref="Title.smil#_08627"> Java libraries. Java&#8217;s java.util.TreeMap and java.util.HashMap libraries are sym- bol-table implementations based on red-black BSTs and hashing with separate chaining respectively. TreeMap does not directly support rank(), select(), and other operations in our ordered symbol-table API, but it does support operations that enable ef&#64257; - cient implementation of these. HashMap is roughly equivalent to our LinearProbingST implementation&#8212;it uses array resizing to enforce a load factor of about 75 percent.</p><p attribs="{'xml:space': 'preserve'}" id="_08628" smilref="Title.smil#_08628"> To be consistent and specific, we use in this book the symbol-table implementation based on red-black BSTs from Section 3.3 or the one based on linear-probing hashing from Section 3.4. For economy and to emphasize client independence from specific implementations, we use the name ST as shorthand for RedBlackBST for ordered symbol tables in client code and the name HashST as shorthand for LinearProbingHashST when order is not important and hash functions are available. We adopt these conventions with full knowledge that specific applications might have demands that could call for some variation or extension of one of these algorithms and data structures. Which symbol table should you use? Whatever you decide, test your choice to be sure that it is delivering the performance that you expect.</p><p attribs="{'xml:space': 'preserve'}" id="_08629" smilref="Title.smil#_08629"> Set APIs Some symbol-table clients do not need the values, just the ability to insert keys into a table and to test whether a key is in the table. Because we disallow duplicate keys, these operations correspond to the following API where we are just interested in the set of keys in the table, not any associated values:</p><p attribs="{'xml:space': 'preserve'}" id="_08630" smilref="Title.smil#_08630"> public class SET&lt;Key&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_08631" smilref="Title.smil#_08631"> SET()</p><p attribs="{'xml:space': 'preserve'}" id="_08632" smilref="Title.smil#_08632"> void add(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08633" smilref="Title.smil#_08633"> void delete(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08634" smilref="Title.smil#_08634"> boolean contains(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08635" smilref="Title.smil#_08635"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_08636" smilref="Title.smil#_08636"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_08637" smilref="Title.smil#_08637"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_08638" smilref="Title.smil#_08638"> create an empty set add key into the set remove key from the set is key in the set? is the set empty? number of keys in the set string representation of the set</p><p attribs="{'xml:space': 'preserve'}" id="_08639" smilref="Title.smil#_08639"> API for a basic set data type</p><p attribs="{'xml:space': 'preserve'}" id="_08640" smilref="Title.smil#_08640"> You can turn any symbol-table implementation into a SET implementation by ignoring values or by using a simple wrapper class (see Exercises 3.5.1 through 3.5.3).</p><p attribs="{'xml:space': 'preserve'}" id="_08641" smilref="Title.smil#_08641" /></level3><level3 id="_00061"><h3 id="ch3-s5-ss15" smilref="Title.smil#ch3-s5-ss15" xml:space="preserve">Dedup</h3><pagenum id="p503" page="normal" smilref="Title.smil#p503" /><p attribs="{'xml:space': 'preserve'}" id="_08642" smilref="Title.smil#_08642"> 490</p><p attribs="{'xml:space': 'preserve'}" id="_08643" smilref="Title.smil#_08643"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08644" smilref="Title.smil#_08644"> Extending SET to include union, intersection, complement, and other common mathematical set operations requires a more sophisticated API (for example, the complement operation requires some mechanism for specifying a universe of all possible keys) and provides a number of interesting algorithmic challenges, as discussed in Exercise</p><p attribs="{'xml:space': 'preserve'}" id="_08645" smilref="Title.smil#_08645"> 3.5.17.</p><p attribs="{'xml:space': 'preserve'}" id="_08646" smilref="Title.smil#_08646"> As with ST, we have unordered and ordered versions of SET. If keys are Comparable,</p><p attribs="{'xml:space': 'preserve'}" id="_08647" smilref="Title.smil#_08647"> we can include min(), max(), floor(), ceiling(), deleteMin(), deleteMax(),</p><p attribs="{'xml:space': 'preserve'}" id="_08648" smilref="Title.smil#_08648"> rank(), select(), and the two-argument versions of size() and get() to define a full API for ordered keys. To match our ST conventions, we use the name SET in client code for ordered sets and the name HashSET when order is not important. To illustrate uses of SET, we consider filter clients that read a sequence of strings from standard input and write some of them to standard output. Such clients have their origin in early systems where main memory was far too small to hold all the data, and they are still relevant today, when we write programs that take their input from the web. As example input, we use tinyTale.txt (see page 371). For readability, we preserve newlines from the input to the output in examples, even though the code does not do so.</p><p attribs="{'xml:space': 'preserve'}" id="_08649" smilref="Title.smil#_08649"> Dedup. The prototypical filter example is a SET or HashSET client that removes duplicates in the input stream. It is customary to refer to this operation as dedup. We maintain a set of the string keys seen so far. If the next key is in the set, ignore it; if it is not in the set, add it to the set and print it. The keys appear on standard output in the order they appear on standard input, with duplicates removed. This process takes space proportional to the number of distinct keys in the input stream (which is typically far smaller than the total number of keys).</p><p attribs="{'xml:space': 'preserve'}" id="_08650" smilref="Title.smil#_08650"> public class DeDup { public static void main(String[] args) { HashSET&lt;String&gt; set; set = new HashSET&lt;String&gt;(); while (!StdIn.isEmpty()) { String key = StdIn.readString(); if (!set.contains(key)) { set.add(key); StdOut.println(key); } } } }</p><p attribs="{'xml:space': 'preserve'}" id="_08651" smilref="Title.smil#_08651"> Dedup f ilter</p><p attribs="{'xml:space': 'preserve'}" id="_08652" smilref="Title.smil#_08652"> % java DeDup &lt; tinyTale.txt it was the best of times worst age wisdom foolishness epoch belief incredulity season light darkness spring hope winter despair</p><p attribs="{'xml:space': 'preserve'}" id="_08653" smilref="Title.smil#_08653" /></level3><level3 id="_00062"><h3 id="ch3-s5-ss16" smilref="Title.smil#ch3-s5-ss16" xml:space="preserve">Whitelist and blacklist filters</h3><pagenum id="p504" page="normal" smilref="Title.smil#p504" /><p attribs="{'xml:space': 'preserve'}" id="_08654" smilref="Title.smil#_08654"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08655" smilref="Title.smil#_08655"> 491</p><p attribs="{'xml:space': 'preserve'}" id="_08656" smilref="Title.smil#_08656"> public class WhiteFilter { public static void main(String[] args) { HashSET&lt;String&gt; set; set = new HashSET&lt;String&gt;(); In in = new In(args[0]); while (!in.isEmpty()) set.add(in.readString()); while (!StdIn.isEmpty()) { String word = StdIn.readString(); if (set.contains(word)) StdOut.println(word); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_08657" smilref="Title.smil#_08657"> Whitelist and blacklist. Another classic filter uses keys in a separate file to decide which keys from the input stream are passed to the output stream. This general process has many natural applications. The simplest example is a whitelist, where any key that is in the file is identified as &#8220;good.&#8221; The client might choose to pass through to standard output any key that is not in the whitelist and to ignore any key that is in the whitelist (as in the example considered in our first program in Chapter 1); another client might choose to pass through to standard output any key that is in the whitelist and to ignore any key that is not in the whitelist (as shown in the HashSET client WhiteFilter at right). For example, your email application might use such a filter to allow you to specify the addresses of your friends and to direct it to consider emails from anyone else as spam. We build a HashSET of the keys in the specified list, then read the keys from standard input. If the next key is in the set, print it; if it is not in the set, ignore it. A blacklist is the opposite, where any key that is in the file is identified as &#8220;bad.&#8221; Again, there are two natural filters for clients using a blacklist. In our email example, you might specify the addresses of known spammers and direct the email application to let through all mail not from one of those addresses. We can implement a HashSET client BlackFilter that implements this filter by negating the filter test in WhiteFilter. Typical practical situations such as a credit card company using a blacklist to filter out stolen card numbers or an internet router using a whitelist to implement a firewall are likely to involve huge lists, unbounded input streams, and strict response requirements. The sorts of symbol-table implementations that we have considered enable such challenges to easily be met.</p><p attribs="{'xml:space': 'preserve'}" id="_08658" smilref="Title.smil#_08658"> % more list.txt was it the of</p><p attribs="{'xml:space': 'preserve'}" id="_08659" smilref="Title.smil#_08659"> Whitelist f ilter</p><p attribs="{'xml:space': 'preserve'}" id="_08660" smilref="Title.smil#_08660"> % java WhiteFilter list.txt &lt; tinyTale.txt it was the of it was the of it was the of it was the of it was the of it was the of it was the of it was the of it was the of it was the of</p><p attribs="{'xml:space': 'preserve'}" id="_08661" smilref="Title.smil#_08661"> % java BlackFilter list.txt &lt; tinyTale.txt best times worst times age wisdom age foolishness epoch belief epoch incredulity season light season darkness spring hope winter despair</p><p attribs="{'xml:space': 'preserve'}" id="_08662" smilref="Title.smil#_08662" /><pagenum id="p505" page="normal" smilref="Title.smil#p505" /><p attribs="{'xml:space': 'preserve'}" id="_08663" smilref="Title.smil#_08663"> 492</p><p attribs="{'xml:space': 'preserve'}" id="_08664" smilref="Title.smil#_08664"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08665" smilref="Title.smil#_08665"> Dictionary clients The most basic kind of symbol-table client builds a symbol table with successive put operations in order to support get requests. Many applications also take advantage of the idea that a symbol table is a dynamic dictionary, where it is easy to look up information and to update the information in the table. The following list of familiar examples illustrates the utility of this approach: Phone book. When keys are people&#8217;s names and values are their phone num- bers, a symbol table models a phone book. A very significant difference from a printed phone book is that we can add new names or change existing phone numbers. We could also use the phone number as the key and the name as the value&#8212;if you have never done so, try typing your phone number (with area code) into the search field in your browser. </p><p attribs="{'xml:space': 'preserve'}" id="_08666" smilref="Title.smil#_08666"> </p><p attribs="{'xml:space': 'preserve'}" id="_08667" smilref="Title.smil#_08667"> </p><p attribs="{'xml:space': 'preserve'}" id="_08668" smilref="Title.smil#_08668"> </p><p attribs="{'xml:space': 'preserve'}" id="_08669" smilref="Title.smil#_08669" /><pagenum id="p506" page="normal" smilref="Title.smil#p506" /><p attribs="{'xml:space': 'preserve'}" id="_08670" smilref="Title.smil#_08670"> </p><p attribs="{'xml:space': 'preserve'}" id="_08671" smilref="Title.smil#_08671"> </p><p attribs="{'xml:space': 'preserve'}" id="_08672" smilref="Title.smil#_08672"> domain</p><p attribs="{'xml:space': 'preserve'}" id="_08673" smilref="Title.smil#_08673"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08674" smilref="Title.smil#_08674"> memory locations (variable names) was far more convenient. Associating the names with the numbers requires a symbol table. As the size of programs grew, the cost of the symbol-table operations became a bottleneck in program development time, which led to the development of data structures and algorithms like the ones we consider in this chapter. File systems. We use symbol tables regularly to organize data on computer systems. Perhaps the most prominent example is the file system, where we associate a file name (key) with the location of its contents (value). Your music player uses the same system to associate song titles (keys) with the location of the music itself (value). Internet DNS. The domain name system (DNS) that is the basis for organizing information on the internet associates URLs (keys) that humans understand (such as www.princeton.edu or www.wikipedia.org) with IP addresses (values) that computer network routers understand (such</p><p attribs="{'xml:space': 'preserve'}" id="_08675" smilref="Title.smil#_08675"> phone book dictionary</p><p attribs="{'xml:space': 'preserve'}" id="_08676" smilref="Title.smil#_08676"> genomics data</p><p attribs="{'xml:space': 'preserve'}" id="_08677" smilref="Title.smil#_08677"> account</p><p attribs="{'xml:space': 'preserve'}" id="_08678" smilref="Title.smil#_08678"> name</p><p attribs="{'xml:space': 'preserve'}" id="_08679" smilref="Title.smil#_08679"> as 208.216.181.15 or 207.142.131.206). This</p><p attribs="{'xml:space': 'preserve'}" id="_08680" smilref="Title.smil#_08680"> compiler</p><p attribs="{'xml:space': 'preserve'}" id="_08681" smilref="Title.smil#_08681"> fi le share</p><p attribs="{'xml:space': 'preserve'}" id="_08682" smilref="Title.smil#_08682"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08683" smilref="Title.smil#_08683"> 493</p><p attribs="{'xml:space': 'preserve'}" id="_08684" smilref="Title.smil#_08684"> value</p><p attribs="{'xml:space': 'preserve'}" id="_08685" smilref="Title.smil#_08685"> phone number defi nition</p><p attribs="{'xml:space': 'preserve'}" id="_08686" smilref="Title.smil#_08686"> balance</p><p attribs="{'xml:space': 'preserve'}" id="_08687" smilref="Title.smil#_08687"> amino acid results memory location machine IP address</p><p attribs="{'xml:space': 'preserve'}" id="_08688" smilref="Title.smil#_08688"> word account number codon data/time variable name song name website</p><p attribs="{'xml:space': 'preserve'}" id="_08689" smilref="Title.smil#_08689"> Typical dictionary applications</p><p attribs="{'xml:space': 'preserve'}" id="_08690" smilref="Title.smil#_08690"> system is the next-generation &#8220;phone book.&#8221; Thus, humans can use names that are easy to remember and machines can efficiently process the numbers. The number of symbol-table lookups done each second for this purpose on internet routers around the world is huge, so performance is of obvious importance. Millions of new computers and other devices are put onto the internet each year, so these symbol tables on internet routers need to be dynamic. Despite its scope, this list is still just a representative sample, intended to give you a fl a- vor of the scope of applicability of the symbol-table abstraction. Whenever you specify something by name, there is a symbol table at work. Your computer&#8217;s file system or the web might do the work for you, but there is still a symbol table there somewhere. As a specific example, we consider a symbol-table client that you can use to look up information that is kept in a table on a file or a web page using the comma-separated- value (.csv) file format. This simple format achieves the (admittedly modest) goal of keeping tabular data in a form that anyone can read (and is likely to be able to read in the future) without needing to use a particular application: the data is in text form, one row per line, with entries separated by commas. You can find on the booksite</p><p attribs="{'xml:space': 'preserve'}" id="_08691" smilref="Title.smil#_08691" /><pagenum id="p507" page="normal" smilref="Title.smil#p507" /><p attribs="{'xml:space': 'preserve'}" id="_08692" smilref="Title.smil#_08692"> 494</p><p attribs="{'xml:space': 'preserve'}" id="_08693" smilref="Title.smil#_08693"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08694" smilref="Title.smil#_08694"> % more amino.csv TTT,Phe,F,Phenylalanine TTC,Phe,F,Phenylalanine TTA,Leu,L,Leucine TTG,Leu,L,Leucine TCT,Ser,S,Serine TCC,Ser,S,Serine ... GAA,Gly,G,Glutamic Acid GAG,Gly,G,Glutamic Acid GGT,Gly,G,Glycine GGC,Gly,G,Glycine GGA,Gly,G,Glycine GGG,Gly,G,Glycine</p><p attribs="{'xml:space': 'preserve'}" id="_08695" smilref="Title.smil#_08695"> % more DJIA.csv ... 20-Oct-87,1738.74,608099968,1841.01 19-Oct-87,2164.16,604300032,1738.74 16-Oct-87,2355.09,338500000,2246.73 15-Oct-87,2412.70,263200000,2355.09 ... 30-Oct-29,230.98,10730000,258.47 29-Oct-29,252.38,16410000,230.07 28-Oct-29,295.18,9210000,260.64 25-Oct-29,299.47,5920000,301.22 ...</p><p attribs="{'xml:space': 'preserve'}" id="_08696" smilref="Title.smil#_08696"> % more ip.csv ... www.ebay.com,66.135.192.87 www.princeton.edu,128.112.128.15 www.cs.princeton.edu,128.112.136.35 www.harvard.edu,128.103.60.24 www.yale.edu,130.132.51.8 www.cnn.com,64.236.16.20 www.google.com,216.239.41.99 www.nytimes.com,199.239.136.200 www.apple.com,17.112.152.32 www.slashdot.org,66.35.250.151 www.espn.com,199.181.135.201 www.weather.com,63.111.66.11 www.yahoo.com,216.109.118.65 ...</p><p attribs="{'xml:space': 'preserve'}" id="_08697" smilref="Title.smil#_08697"> % more UPC.csv ... 0002058102040,,"1 1/4"" STANDARD STORM DOOR" 0002058102057,,"1 1/4"" STANDARD STORM DOOR" 0002058102125,,"DELUXE STORM DOOR UNIT" 0002082012728,"100/ per box","12 gauge shells" 0002083110812,"Classical CD","'Bits and Pieces'" 002083142882,CD,"Garth Brooks - Ropin' The Wind" 0002094000003,LB,"PATE PARISIEN" 0002098000009,LB,"PATE TRUFFLE COGNAC-M&amp;H 8Z RW" 0002100001086,"16 oz","Kraft Parmesan" 0002100002090,"15 pieces","Wrigley's Gum" 0002100002434,"One pint","Trader Joe's milk" ...</p><p attribs="{'xml:space': 'preserve'}" id="_08698" smilref="Title.smil#_08698"> Typical comma-separated-value (.csv) f iles</p><p attribs="{'xml:space': 'preserve'}" id="_08699" smilref="Title.smil#_08699"> numerous .csv files that are related to various applications that we have described, including amino.csv (codon-to-amino- acid encodings), DJIA.csv (opening price, volume, and closing price of the Dow Jones Industrial Average, for every day in its his- tory), ip.csv (a selection of entries from the DNS database), and upc.csv (the Uni- form Product Code bar codes that are widely used to identify consumer products). Spreadsheet and other data-processing applications programs can read and write .csv fi les, and our example illustrates that you can also write a Java program to process the data any way that you would like. LookupCSV (on the facing page) builds a set of key-value pairs from a file of comma- separated values as specified on the command line and then prints out values corresponding to keys read from standard input. The command-line arguments are the file name and two integers, one specifying the field to serve as the key and the other specifying the field to serve as the value. The purpose of this example is to illustrate the utility and flexibility of the symbol-table abstraction. What website has IP address 128.112.136.35? (www. cs.princeton.edu) What amino acid corresponds to the codon TCA ? (Serine) What was the DJIA on October 29, 1929? (252.38) What product has UPC 0002100001086? (Kraft Parmesan) You can easily look up the answers to questions like these with LookupCSV and the appropriate .csv fi les. Performance is not much of an issue when handling interactive queries (since your computer can look through millions</p><p attribs="{'xml:space': 'preserve'}" id="_08700" smilref="Title.smil#_08700" /></level3><level3 id="_00063"><h3 id="ch3-s5-ss17" smilref="Title.smil#ch3-s5-ss17" xml:space="preserve">Dictionary lookup</h3><pagenum id="p508" page="normal" smilref="Title.smil#p508" /><p attribs="{'xml:space': 'preserve'}" id="_08701" smilref="Title.smil#_08701"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08702" smilref="Title.smil#_08702"> 495</p><p attribs="{'xml:space': 'preserve'}" id="_08703" smilref="Title.smil#_08703"> Dictionary lookup</p><p attribs="{'xml:space': 'preserve'}" id="_08704" smilref="Title.smil#_08704"> public class LookupCSV { public static void main(String[] args) { In in = new In(args[0]); int keyField = Integer.parseInt(args[1]); int valField = Integer.parseInt(args[2]);</p><p attribs="{'xml:space': 'preserve'}" id="_08705" smilref="Title.smil#_08705"> ST&lt;String, String&gt; st = new ST&lt;String, String&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_08706" smilref="Title.smil#_08706"> while (in.hasNextLine()) { String line = in.readLine(); String[] tokens = line.split(","); String key = tokens[keyField]; String val = tokens[valField]; st.put(key, val); }</p><p attribs="{'xml:space': 'preserve'}" id="_08707" smilref="Title.smil#_08707"> while (!StdIn.isEmpty()) { String query = StdIn.readString(); if (st.contains(query)) StdOut.println(st.get(query)); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_08708" smilref="Title.smil#_08708"> This data-driven symbol-table client reads key-value pairs from a fi le, then prints the values corresponding to the keys found on standard input. Both keys and values are strings. The separating delimiter is taken as a command-line argument.</p><p attribs="{'xml:space': 'preserve'}" id="_08709" smilref="Title.smil#_08709"> % java LookupCSV ip.csv 1 0 128.112.136.35 www.cs.princeton.edu</p><p attribs="{'xml:space': 'preserve'}" id="_08710" smilref="Title.smil#_08710"> % java LookupCSV amino.csv 0 3 TCC Serine</p><p attribs="{'xml:space': 'preserve'}" id="_08711" smilref="Title.smil#_08711"> % java LookupCSV DJIA.csv 0 3 29-Oct-29 230.07</p><p attribs="{'xml:space': 'preserve'}" id="_08712" smilref="Title.smil#_08712"> % java LookupCSV UPC.csv 0 2 0002100001086 Kraft Parmesan</p><p attribs="{'xml:space': 'preserve'}" id="_08713" smilref="Title.smil#_08713" /><pagenum id="p509" page="normal" smilref="Title.smil#p509" /><p attribs="{'xml:space': 'preserve'}" id="_08714" smilref="Title.smil#_08714"> 496</p><p attribs="{'xml:space': 'preserve'}" id="_08715" smilref="Title.smil#_08715"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08716" smilref="Title.smil#_08716"> of things in the time it takes to type a query), so fast implementations of ST are not noticeable when you use LookupCSV. However, when a program is doing the lookups (and a huge number of them), performance matters. For example, an internet router might need to look up millions of IP addresses per second. In this book, we have already seen the need for good performance with FrequencyCounter, and we will see several other examples in this section. Examples of similar but more sophisticated test clients for .csv files are described in the exercises. For instance, we could make the dictionary dynamic by also allowing standard-input commands to change the value associated with a key, or we could allow range searching, or we could build multiple dictionaries for the same fi le.</p><p attribs="{'xml:space': 'preserve'}" id="_08717" smilref="Title.smil#_08717"> aminoI.txt</p><p attribs="{'xml:space': 'preserve'}" id="_08718" smilref="Title.smil#_08718"> " ," s e pa ra to r</p><p attribs="{'xml:space': 'preserve'}" id="_08719" smilref="Title.smil#_08719"> Alanine,AAT,AAC,GCT,GCC,GCA,GCG Arginine,CGT,CGC,CGA,CGG,AGA,AGG Aspartic Acid,GAT,GAC Cysteine,TGT,TGC Glutamic Acid,GAA,GAG Glutamine,CAA,CAG Glycine,GGT,GGC,GGA,GGG Histidine,CAT,CAC Isoleucine,ATT,ATC,ATA Leucine,TTA,TTG,CTT,CTC,CTA,CTG Lysine,AAA,AAG Methionine,ATG Phenylalanine,TTT,TTC Proline,CCT,CCC,CCA,CCG Serine,TCT,TCA,TCG,AGT,AGC Stop,TAA,TAG,TGA Threonine,ACT,ACC,ACA,ACG Tyrosine,TAT,TAC Tryptophan,TGG Valine,GTT,GTC,GTA,GTG</p><p attribs="{'xml:space': 'preserve'}" id="_08720" smilref="Title.smil#_08720"> Indexing clients Dictionaries are characterized by the idea that there is one value associated with each key, so the direct use of our ST data type, which is based on the asso- ciative-array abstraction that assigns one value to each key, is appropriate. Each account number uniquely identifies a customer, each UPC uniquely identifies a product, and so forth. In general, of course, there may be multiple values associated with a given key. For example, in our amino.csv example, each codon identifies one amino acid, but each amino acid is associated with a list of codons, as in the example aminoI.csv at right, where each line contains an amino acid and the list of codons associated with it. We use the term index to describe symbol tables that associate multiple values with each key. Here are some more examples: </p><p attribs="{'xml:space': 'preserve'}" id="_08721" smilref="Title.smil#_08721"> A small index file (20 lines)</p><p attribs="{'xml:space': 'preserve'}" id="_08722" smilref="Title.smil#_08722"> key </p><p attribs="{'xml:space': 'preserve'}" id="_08723" smilref="Title.smil#_08723"> va lu e s</p><p attribs="{'xml:space': 'preserve'}" id="_08724" smilref="Title.smil#_08724"> </p><p attribs="{'xml:space': 'preserve'}" id="_08725" smilref="Title.smil#_08725" /><pagenum id="p510" page="normal" smilref="Title.smil#p510" /><p attribs="{'xml:space': 'preserve'}" id="_08726" smilref="Title.smil#_08726"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08727" smilref="Title.smil#_08727"> 497</p><p attribs="{'xml:space': 'preserve'}" id="_08728" smilref="Title.smil#_08728"> </p><p attribs="{'xml:space': 'preserve'}" id="_08729" smilref="Title.smil#_08729"> amino acid account number search key movie</p><p attribs="{'xml:space': 'preserve'}" id="_08730" smilref="Title.smil#_08730"> Typical indexing applications</p><p attribs="{'xml:space': 'preserve'}" id="_08731" smilref="Title.smil#_08731"> domain</p><p attribs="{'xml:space': 'preserve'}" id="_08732" smilref="Title.smil#_08732"> genomics commercial web search IMDB</p><p attribs="{'xml:space': 'preserve'}" id="_08733" smilref="Title.smil#_08733"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08734" smilref="Title.smil#_08734"> value</p><p attribs="{'xml:space': 'preserve'}" id="_08735" smilref="Title.smil#_08735"> list of codons list of transactions list of web pages list of performers</p><p attribs="{'xml:space': 'preserve'}" id="_08736" smilref="Title.smil#_08736"> movies.txt</p><p attribs="{'xml:space': 'preserve'}" id="_08737" smilref="Title.smil#_08737"> ... " /" s e pa ra to r Tin Men (1987)/DeBoy, David/Blumenfeld, Alan/... Tirez sur le pianiste (1960)/Heymann, Claude/... Titanic (1997)/Mazin, Stan/...DiCaprio, Leonardo/... Titus (1999)/Weisskopf, Hermann/Rhys, Matthew/... To Be or Not to Be (1942)/Verebes, Ern&#246; (I)/... To Be or Not to Be (1983)/.../Brooks, Mel (I)/... To Catch a Thief (1955)/Par&#237;s, Manuel/... To Die For (1995)/Smith, Kurtwood/.../Kidman, Nicole/... ...</p><p attribs="{'xml:space': 'preserve'}" id="_08738" smilref="Title.smil#_08738"> key </p><p attribs="{'xml:space': 'preserve'}" id="_08739" smilref="Title.smil#_08739"> va lu e s</p><p attribs="{'xml:space': 'preserve'}" id="_08740" smilref="Title.smil#_08740"> Small portion of a large index file (250,000+ lines)</p><p attribs="{'xml:space': 'preserve'}" id="_08741" smilref="Title.smil#_08741" /></level3><level3 id="_00064"><h3 id="ch3-s5-ss18" smilref="Title.smil#ch3-s5-ss18" xml:space="preserve">Inverted index</h3><pagenum id="p511" page="normal" smilref="Title.smil#p511" /><p attribs="{'xml:space': 'preserve'}" id="_08742" smilref="Title.smil#_08742"> 498</p><p attribs="{'xml:space': 'preserve'}" id="_08743" smilref="Title.smil#_08743"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08744" smilref="Title.smil#_08744"> </p><p attribs="{'xml:space': 'preserve'}" id="_08745" smilref="Title.smil#_08745"> Inverted index. The term inverted index is normally applied to a situation where values are used to locate keys. We have a large amount of data and want to know where certain keys of interest occur. This application is another prototypical example of a symbol- table client that uses an intermixed sequence of calls to get() and put(). Again, we associate each key with a SET of locations, where the occurrences of the key can be found. The nature and use of the location depend on the application: in a book, a location might be a page number; in a program, a location might be a line number; in genomics, a location might be a position in a genetic sequence; and so forth: Internet Movie DataBase (IMDB). In the example just considered, the input is an index that associates each movie with a list of performers. The inverted index associates each performer with a list of movies. </p><p attribs="{'xml:space': 'preserve'}" id="_08746" smilref="Title.smil#_08746"> set of movies set of pages set of places used set of fi les set of locations</p><p attribs="{'xml:space': 'preserve'}" id="_08747" smilref="Title.smil#_08747"> performer term identifier  search term subsequence</p><p attribs="{'xml:space': 'preserve'}" id="_08748" smilref="Title.smil#_08748"> IMDB book compiler fi le search genomics</p><p attribs="{'xml:space': 'preserve'}" id="_08749" smilref="Title.smil#_08749"> domain</p><p attribs="{'xml:space': 'preserve'}" id="_08750" smilref="Title.smil#_08750"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08751" smilref="Title.smil#_08751"> value</p><p attribs="{'xml:space': 'preserve'}" id="_08752" smilref="Title.smil#_08752"> Exercise 3.5.20).</p><p attribs="{'xml:space': 'preserve'}" id="_08753" smilref="Title.smil#_08753"> Typical inverted indices</p><p attribs="{'xml:space': 'preserve'}" id="_08754" smilref="Title.smil#_08754"> </p><p attribs="{'xml:space': 'preserve'}" id="_08755" smilref="Title.smil#_08755"> Compiler. In a large program that uses a large number of symbols, it is useful to know where each name is used. Historically, an explicit printed symbol table was one of the most important tools used by programmers to keep track of where symbols are used in their programs. In modern systems, symbol tables are the basis of software tools that programmers use to manage names. </p><p attribs="{'xml:space': 'preserve'}" id="_08756" smilref="Title.smil#_08756"> </p><p attribs="{'xml:space': 'preserve'}" id="_08757" smilref="Title.smil#_08757" /><pagenum id="p512" page="normal" smilref="Title.smil#p512" /><p attribs="{'xml:space': 'preserve'}" id="_08758" smilref="Title.smil#_08758"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08759" smilref="Title.smil#_08759"> 499</p><p attribs="{'xml:space': 'preserve'}" id="_08760" smilref="Title.smil#_08760"> Index (and inverted index) lookup</p><p attribs="{'xml:space': 'preserve'}" id="_08761" smilref="Title.smil#_08761"> public class LookupIndex { public static void main(String[] args) { In in = new In(args[0]); String sp = args[1];</p><p attribs="{'xml:space': 'preserve'}" id="_08762" smilref="Title.smil#_08762"> // index database // separator</p><p attribs="{'xml:space': 'preserve'}" id="_08763" smilref="Title.smil#_08763"> ST&lt;String, Queue&lt;String&gt;&gt; st = new ST&lt;String, Queue&lt;String&gt;&gt;(); ST&lt;String, Queue&lt;String&gt;&gt; ts = new ST&lt;String, Queue&lt;String&gt;&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_08764" smilref="Title.smil#_08764"> while (in.hasNextLine()) { String[] a = in.readLine().split(sp); String key = a[0]; for (int i = 1; i &lt; a.length; i++) { String val = a[i]; if (!st.contains(key)) st.put(key, new Queue&lt;String&gt;()); if (!ts.contains(val)) ts.put(val, new Queue&lt;String&gt;()); st.get(key).enqueue(val); ts.get(val).enqueue(key); } }</p><p attribs="{'xml:space': 'preserve'}" id="_08765" smilref="Title.smil#_08765"> while (!StdIn.isEmpty()) { String query = StdIn.readLine(); if (st.contains(query)) for (String s : st.get(query)) StdOut.println(" " + s);</p><p attribs="{'xml:space': 'preserve'}" id="_08766" smilref="Title.smil#_08766"> if (ts.contains(query)) for (String s : ts.get(query)) StdOut.println(" " + s); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_08767" smilref="Title.smil#_08767"> This data-driven symbol-table client reads key-value pairs from a fi le, then prints the values corresponding to the keys found on standard input. Keys are strings; values are lists of strings. The separating delimiter is taken as a command- line argument.</p><p attribs="{'xml:space': 'preserve'}" id="_08768" smilref="Title.smil#_08768"> % java LookupIndex aminoI.txt "," Serine TCT TCA TCG AGT AGC TCG Serine</p><p attribs="{'xml:space': 'preserve'}" id="_08769" smilref="Title.smil#_08769"> % java LookupIndex movies.txt "/" Bacon, Kevin Animal House (1978) Apollo 13 (1995) Beauty Shop (2005) Diner (1982) ... Tin Men (1987) DeBoy, David Blumenfeld, Alan ...</p><p attribs="{'xml:space': 'preserve'}" id="_08770" smilref="Title.smil#_08770" /><pagenum id="p513" page="normal" smilref="Title.smil#p513" /><p attribs="{'xml:space': 'preserve'}" id="_08771" smilref="Title.smil#_08771"> 500</p><p attribs="{'xml:space': 'preserve'}" id="_08772" smilref="Title.smil#_08772"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08773" smilref="Title.smil#_08773"> FileIndex (on the facing page) takes file names from the command line and uses a symbol table to build an inverted index associating every word in any of the files with a SET of file names where the word can be found, then takes keyword queries from standard input, and produces its associated list of fi les. This process is similar to that used by familiar software tools for searching the web or for searching for information on your computer; you type a keyword to get a list of places where that keyword occurs. Developers of such tools typically embellish the process by paying careful attention to </p><p attribs="{'xml:space': 'preserve'}" id="_08774" smilref="Title.smil#_08774" /></level3><level3 id="_00065"><h3 id="ch3-s5-ss19" smilref="Title.smil#ch3-s5-ss19" xml:space="preserve">File indexing</h3><pagenum id="p514" page="normal" smilref="Title.smil#p514" /><p attribs="{'xml:space': 'preserve'}" id="_08775" smilref="Title.smil#_08775"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08776" smilref="Title.smil#_08776"> 501</p><p attribs="{'xml:space': 'preserve'}" id="_08777" smilref="Title.smil#_08777"> File indexing</p><p attribs="{'xml:space': 'preserve'}" id="_08778" smilref="Title.smil#_08778"> import java.io.File;</p><p attribs="{'xml:space': 'preserve'}" id="_08779" smilref="Title.smil#_08779"> public class FileIndex { public static void main(String[] args) { ST&lt;String, SET&lt;File&gt;&gt; st = new ST&lt;String, SET&lt;File&gt;&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_08780" smilref="Title.smil#_08780"> for (String filename : args) { File file = new File(filename); In in = new In(file); while (!in.isEmpty()) { String word = in.readString(); if (!st.contains(word)) st.put(word, new SET&lt;File&gt;()); SET&lt;File&gt; set = st.get(word); set.add(file); } }</p><p attribs="{'xml:space': 'preserve'}" id="_08781" smilref="Title.smil#_08781"> while (!StdIn.isEmpty()) { String query = StdIn.readString(); if (st.contains(query)) for (File file : st.get(query)) StdOut.println(" " + file.getName()); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_08782" smilref="Title.smil#_08782"> This symbol-table client indexes a set of fi les. We search for each word in each file in a symbol table, maintaining a SET of file names that contain the word. Names for In can also refer to web pages, so this code can also be used to build an inverted index of web pages.</p><p attribs="{'xml:space': 'preserve'}" id="_08783" smilref="Title.smil#_08783"> % more ex1.txt it was the best of times</p><p attribs="{'xml:space': 'preserve'}" id="_08784" smilref="Title.smil#_08784"> % more ex2.txt it was the worst of times</p><p attribs="{'xml:space': 'preserve'}" id="_08785" smilref="Title.smil#_08785"> % more ex3.txt it was the age of wisdom</p><p attribs="{'xml:space': 'preserve'}" id="_08786" smilref="Title.smil#_08786"> % more ex4.txt it was the age of foolishness</p><p attribs="{'xml:space': 'preserve'}" id="_08787" smilref="Title.smil#_08787"> % java FileIndex ex*.txt age ex3.txt ex4.txt best ex1.txt was ex1.txt ex2.txt ex3.txt ex4.txt</p><p attribs="{'xml:space': 'preserve'}" id="_08788" smilref="Title.smil#_08788" /></level3><level3 id="_00066"><h3 id="ch3-s5-ss20" smilref="Title.smil#ch3-s5-ss20" xml:space="preserve">Sparse matrix-vector multiplication</h3><pagenum id="p515" page="normal" smilref="Title.smil#p515" /><p attribs="{'xml:space': 'preserve'}" id="_08789" smilref="Title.smil#_08789"> 502</p><p attribs="{'xml:space': 'preserve'}" id="_08790" smilref="Title.smil#_08790"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08791" smilref="Title.smil#_08791"> 0 0 0 .90 0</p><p attribs="{'xml:space': 'preserve'}" id="_08792" smilref="Title.smil#_08792"> .90 0 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_08793" smilref="Title.smil#_08793"> .47 0 .47 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_08794" smilref="Title.smil#_08794"> 0 .90 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_08795" smilref="Title.smil#_08795"> 0 0 .36 .36 .18</p><p attribs="{'xml:space': 'preserve'}" id="_08796" smilref="Title.smil#_08796"> a[][]</p><p attribs="{'xml:space': 'preserve'}" id="_08797" smilref="Title.smil#_08797"> x[]</p><p attribs="{'xml:space': 'preserve'}" id="_08798" smilref="Title.smil#_08798"> =</p><p attribs="{'xml:space': 'preserve'}" id="_08799" smilref="Title.smil#_08799"> .297</p><p attribs="{'xml:space': 'preserve'}" id="_08800" smilref="Title.smil#_08800"> .333</p><p attribs="{'xml:space': 'preserve'}" id="_08801" smilref="Title.smil#_08801"> .045</p><p attribs="{'xml:space': 'preserve'}" id="_08802" smilref="Title.smil#_08802"> b[]</p><p attribs="{'xml:space': 'preserve'}" id="_08803" smilref="Title.smil#_08803"> .05</p><p attribs="{'xml:space': 'preserve'}" id="_08804" smilref="Title.smil#_08804"> .04</p><p attribs="{'xml:space': 'preserve'}" id="_08805" smilref="Title.smil#_08805"> .36</p><p attribs="{'xml:space': 'preserve'}" id="_08806" smilref="Title.smil#_08806"> .37</p><p attribs="{'xml:space': 'preserve'}" id="_08807" smilref="Title.smil#_08807"> .19</p><p attribs="{'xml:space': 'preserve'}" id="_08808" smilref="Title.smil#_08808"> .036</p><p attribs="{'xml:space': 'preserve'}" id="_08809" smilref="Title.smil#_08809"> .1927</p><p attribs="{'xml:space': 'preserve'}" id="_08810" smilref="Title.smil#_08810"> Matrix-vector multiplication</p><p attribs="{'xml:space': 'preserve'}" id="_08811" smilref="Title.smil#_08811"> Sparse vectors Our next example illustrates the importance of symbol tables in sci- enti&#64257; c and mathematical calculations. We describe a fundamental and familiar calculation that becomes a bottleneck in typical practical applications, then show how using a symbol table can remove the bottleneck and enable solution of vastly larger problems. Indeed, this particular calculation was at the core of the PageRank algorithm that was developed by S. Brin and L. Page and led to the emergence of Google in the early 2000s (and is a well-known mathematical abstraction that is useful in many other contexts). The basic calculation that we consider is ma- trix-vector multiplication : given a matrix and a vector, compute a result vector whose i th entry is the dot product of the given vector and the i th row of the matrix. For simplicity, we consider the case when the matrix is square with N rows and N columns and the vectors are of size N. This operation is elementary to code in Java, requiring time proportional to N 2, for the N multiplications to compute each of the N entries in the result vector, which also matches the space proportional to N 2 that is required to store the matrix. In practice, it is very often the case that N is huge. For example, in the Google application cited above, N is the number of pages on the web. At the time PageRank was de- veloped, that was in the tens or hundreds of billions and it has skyrocketed since, so the value of N 2 would be far more than 10 20. No one can afford that much time or space, so a better algorithm is needed. Fortunately, it is also often the case that the matrix is sparse: a huge number of its entries are 0. Indeed, for the Google application, the average number of nonzero entries per row is a small constant: virtually all web pages have links to only a few others (not all the pages on the web). Accordingly, we can represent the matrix as an array of sparse vec- tors, using a SparseVector implementation like the HashST client on the facing page. Instead of using the</p><p attribs="{'xml:space': 'preserve'}" id="_08812" smilref="Title.smil#_08812"> ... double[][] a = new double[N][N]; double[] x = new double[N]; double[] b = new double[N]; ... // Initialize a[][] and x[]. ... for (int i = 0; i &lt; N; i++) { sum = 0.0; for (int j = 0; j &lt; N; j++) sum += a[i][j]*x[j]; b[i] = sum; }</p><p attribs="{'xml:space': 'preserve'}" id="_08813" smilref="Title.smil#_08813"> Standard implementation of matrix-vector multiplication</p><p attribs="{'xml:space': 'preserve'}" id="_08814" smilref="Title.smil#_08814" /><pagenum id="p516" page="normal" smilref="Title.smil#p516" /><p attribs="{'xml:space': 'preserve'}" id="_08815" smilref="Title.smil#_08815"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08816" smilref="Title.smil#_08816"> 503</p><p attribs="{'xml:space': 'preserve'}" id="_08817" smilref="Title.smil#_08817"> Sparse vector with dot product</p><p attribs="{'xml:space': 'preserve'}" id="_08818" smilref="Title.smil#_08818"> public class SparseVector { private HashST&lt;Integer, Double&gt; st;</p><p attribs="{'xml:space': 'preserve'}" id="_08819" smilref="Title.smil#_08819"> public SparseVector() { st = new HashST&lt;Integer, Double&gt;(); }</p><p attribs="{'xml:space': 'preserve'}" id="_08820" smilref="Title.smil#_08820"> public int size() { return st.size(); }</p><p attribs="{'xml:space': 'preserve'}" id="_08821" smilref="Title.smil#_08821"> public void put(int i, double x) { st.put(i, x); }</p><p attribs="{'xml:space': 'preserve'}" id="_08822" smilref="Title.smil#_08822"> public double get(int i) { if (!st.contains(i)) return 0.0; else return st.get(i); }</p><p attribs="{'xml:space': 'preserve'}" id="_08823" smilref="Title.smil#_08823"> public double dot(double[] that) { double sum = 0.0; for (int i : st.keys()) sum += that[i]*this.get(i); return sum; }</p><p attribs="{'xml:space': 'preserve'}" id="_08824" smilref="Title.smil#_08824"> }</p><p attribs="{'xml:space': 'preserve'}" id="_08825" smilref="Title.smil#_08825"> This symbol-table client is a bare-bones sparse vector implementation that illustrates an efficient dot product for sparse vectors. We multiply each entry by its counterpart in the other operand and add the result to a running sum. The number of multiplications required is equal to the number of nonzero entries in the sparse vector.</p><p attribs="{'xml:space': 'preserve'}" id="_08826" smilref="Title.smil#_08826" /><pagenum id="p517" page="normal" smilref="Title.smil#p517" /><p attribs="{'xml:space': 'preserve'}" id="_08827" smilref="Title.smil#_08827"> 504</p><p attribs="{'xml:space': 'preserve'}" id="_08828" smilref="Title.smil#_08828"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08829" smilref="Title.smil#_08829"> array of double[]objects</p><p attribs="{'xml:space': 'preserve'}" id="_08830" smilref="Title.smil#_08830"> array of SparseVector objects</p><p attribs="{'xml:space': 'preserve'}" id="_08831" smilref="Title.smil#_08831"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08832" smilref="Title.smil#_08832"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08833" smilref="Title.smil#_08833"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08834" smilref="Title.smil#_08834"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08835" smilref="Title.smil#_08835"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08836" smilref="Title.smil#_08836"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08837" smilref="Title.smil#_08837"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08838" smilref="Title.smil#_08838"> a</p><p attribs="{'xml:space': 'preserve'}" id="_08839" smilref="Title.smil#_08839"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08840" smilref="Title.smil#_08840"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08841" smilref="Title.smil#_08841"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08842" smilref="Title.smil#_08842"> .36</p><p attribs="{'xml:space': 'preserve'}" id="_08843" smilref="Title.smil#_08843"> .36</p><p attribs="{'xml:space': 'preserve'}" id="_08844" smilref="Title.smil#_08844"> .18</p><p attribs="{'xml:space': 'preserve'}" id="_08845" smilref="Title.smil#_08845"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08846" smilref="Title.smil#_08846"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08847" smilref="Title.smil#_08847"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08848" smilref="Title.smil#_08848"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08849" smilref="Title.smil#_08849"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08850" smilref="Title.smil#_08850"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08851" smilref="Title.smil#_08851"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08852" smilref="Title.smil#_08852"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08853" smilref="Title.smil#_08853"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08854" smilref="Title.smil#_08854"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08855" smilref="Title.smil#_08855"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08856" smilref="Title.smil#_08856"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08857" smilref="Title.smil#_08857"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08858" smilref="Title.smil#_08858"> .45</p><p attribs="{'xml:space': 'preserve'}" id="_08859" smilref="Title.smil#_08859"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08860" smilref="Title.smil#_08860"> .45</p><p attribs="{'xml:space': 'preserve'}" id="_08861" smilref="Title.smil#_08861"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08862" smilref="Title.smil#_08862"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_08863" smilref="Title.smil#_08863"> a[4][2]</p><p attribs="{'xml:space': 'preserve'}" id="_08864" smilref="Title.smil#_08864"> a</p><p attribs="{'xml:space': 'preserve'}" id="_08865" smilref="Title.smil#_08865"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_08866" smilref="Title.smil#_08866"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08867" smilref="Title.smil#_08867"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08868" smilref="Title.smil#_08868"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08869" smilref="Title.smil#_08869"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08870" smilref="Title.smil#_08870"> st</p><p attribs="{'xml:space': 'preserve'}" id="_08871" smilref="Title.smil#_08871"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_08872" smilref="Title.smil#_08872"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08873" smilref="Title.smil#_08873"> key</p><p attribs="{'xml:space': 'preserve'}" id="_08874" smilref="Title.smil#_08874"> value</p><p attribs="{'xml:space': 'preserve'}" id="_08875" smilref="Title.smil#_08875"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_08876" smilref="Title.smil#_08876"> .36</p><p attribs="{'xml:space': 'preserve'}" id="_08877" smilref="Title.smil#_08877"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_08878" smilref="Title.smil#_08878"> .36</p><p attribs="{'xml:space': 'preserve'}" id="_08879" smilref="Title.smil#_08879"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_08880" smilref="Title.smil#_08880"> .18</p><p attribs="{'xml:space': 'preserve'}" id="_08881" smilref="Title.smil#_08881"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_08882" smilref="Title.smil#_08882"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08883" smilref="Title.smil#_08883"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08884" smilref="Title.smil#_08884"> .90</p><p attribs="{'xml:space': 'preserve'}" id="_08885" smilref="Title.smil#_08885"> independent symbol-table objects</p><p attribs="{'xml:space': 'preserve'}" id="_08886" smilref="Title.smil#_08886"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_08887" smilref="Title.smil#_08887"> .45</p><p attribs="{'xml:space': 'preserve'}" id="_08888" smilref="Title.smil#_08888"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_08889" smilref="Title.smil#_08889"> .45</p><p attribs="{'xml:space': 'preserve'}" id="_08890" smilref="Title.smil#_08890"> Sparse matrix representations</p><p attribs="{'xml:space': 'preserve'}" id="_08891" smilref="Title.smil#_08891"> code a[i][j] to refer to the element in row i and column j, we use a[i].put(j, val) to set a value in the matrix and a[i].get(j) to retrieve a value. As you can see from the code below, matrix-vector multiplication using this class is even simpler than with the array representation (and it more clearly describes the computation). More important, it only requires time proportional to N plus the number of nonzero elements in the matrix. For small matrices or matrices that are not sparse, the overhead for maintaining symbol tables can be substantial, but it is worth your while to be sure to understand the ramifications of using symbol tables for huge sparse matrices. To fix ideas, consider a huge application (like the one faced by Brin and Page) where N is 10 billion or 100 billion, but the average number of nonzero elements per row is less than 10 . For such an application, using symbol tables speeds up matrix-vector multiplication by a factor of a billion or more. The elementary nature of this application should not detract from its im- portance: programmers who do not take advantage of the potential to save time and space in this way severely limit their potential to solve practical problems, while programmers who do take factor-</p><p attribs="{'xml:space': 'preserve'}" id="_08892" smilref="Title.smil#_08892"> .. SparseVector[] a; a = new SparseVector[N]; double[] x = new double[N]; double[] b = new double[N]; ... // Initialize a[] and x[]. ... for (int i = 0; i &lt; N; i++) b[i] = a[i].dot(x);</p><p attribs="{'xml:space': 'preserve'}" id="_08893" smilref="Title.smil#_08893"> Sparse matrix-vector multiplication</p><p attribs="{'xml:space': 'preserve'}" id="_08894" smilref="Title.smil#_08894" /><pagenum id="p518" page="normal" smilref="Title.smil#p518" /><p attribs="{'xml:space': 'preserve'}" id="_08895" smilref="Title.smil#_08895"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08896" smilref="Title.smil#_08896"> 505</p><p attribs="{'xml:space': 'preserve'}" id="_08897" smilref="Title.smil#_08897"> of-a-billion speedups when they are available are likely to be able to address problems that could not otherwise be contemplated. Building the matrix for the Google application is a graph-processing application (and a symbol-table client!), albeit for a huge sparse matrix. Given the matrix, the Page- Rank calculation is nothing more than doing a matrix-vector multiplication, replacing the source vector with the result vector, and iterating the process until it converges (as guaranteed by fundamental theorems in probability theory). Thus, the use of a class like SparseVector can improve the time and space usage for this application by a factor of 10 billion or 100 billion or more. Similar savings are possible in many scientific calculations, so sparse vectors and matrices are widely used and typically incorporated into specialized systems for scientific computing. When working with huge vectors and matrices, it is wise to run simple performance tests to be sure that the kinds of performance gains that we have illustrated here are not being missed. On the other hand, array processing for primitive types of data is built in to most programming languages, so using arrays for vectors that are not sparse, as we did in this example, may offer further speedups. Developing a good understanding of the underlying costs and making the appropriate implementation decisions is certainly worthwhile for such applications.</p><p attribs="{'xml:space': 'preserve'}" id="_08898" smilref="Title.smil#_08898"> Symbol tables are a primary contribution of algorithmic technology to the</p><p attribs="{'xml:space': 'preserve'}" id="_08899" smilref="Title.smil#_08899"> development of our modern computational infrastructure because of their ability to deliver savings on a huge scale in a vast array of practical applications, making the difference between providing solutions to a wide range of problems and not being able to address them at all. Few fields of science or engineering involve studying the effects of an invention that improves costs by factors of 100 billion&#8212;symbol-table applications put us in just that position, as we have just seen in several examples, and these improvements have had profound effects. The data structures and algorithms that we have considered are certainly not the final word: they were all developed in just a few decades, and their properties are not fully understood. Because of their importance, symbol-table implementations continue to be studied intensely by researchers around the world, and we can look forward to new developments on many fronts as the scale and scope of the applications they address continue to expand.</p><p attribs="{'xml:space': 'preserve'}" id="_08900" smilref="Title.smil#_08900" /><pagenum id="p519" page="normal" smilref="Title.smil#p519" /><p attribs="{'xml:space': 'preserve'}" id="_08901" smilref="Title.smil#_08901"> 506</p><p attribs="{'xml:space': 'preserve'}" id="_08902" smilref="Title.smil#_08902"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08903" smilref="Title.smil#_08903"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_08904" smilref="Title.smil#_08904"> Q. Can a SET contain null? A. No. As with symbol tables, keys are non-null objects. Q. Can a SET be null? A. No. A SET can be empty (contain no objects), but not null. As with any Java data type, a variable of type SET can have the value null, but that just indicates that it does not reference any SET. The result of using new to create a SET is always an object that is not null. Q. If all my data is in memory, there is no real reason to use a fi lter, right? A. Right. Filtering really shines in the case when you have no idea how much data to expect. Otherwise, it may be a useful way of thinking, but not a cure-all. Q. I have data in a spreadsheet. Can I develop something like LookupCSV to search through it? A. Your spreadsheet application probably has an option to export to a .csv fi le, so you can use LookupCSV directly. Q. Why would I need FileIndex? Doesn&#8217;t my operating system solve this problem? A. If you are using an OS that meets your needs, continue to do so, by all means. As with many of our programs, FileIndex is intended to show you the basic underlying mechanisms of such applications and to suggest possibilities to you. Q. Why not have the dot() method in SparseVector take a SparseVector object as argument and return a SparseVector object? A. That is a fine alternate design and a nice programming exercise that requires code that is a bit more intricate than for our design (see Exercise 3.5.16). For general matrix processing, it might be worthwhile to also add a SparseMatrix type.</p><p attribs="{'xml:space': 'preserve'}" id="_08905" smilref="Title.smil#_08905" /><pagenum id="p520" page="normal" smilref="Title.smil#p520" /><p attribs="{'xml:space': 'preserve'}" id="_08906" smilref="Title.smil#_08906"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08907" smilref="Title.smil#_08907"> 507</p><p attribs="{'xml:space': 'preserve'}" id="_08908" smilref="Title.smil#_08908"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_08909" smilref="Title.smil#_08909"> 3.5.1 Implement SET and HashSET as &#8220;wrapper class&#8221; clients of ST and HashST, respectively (provide dummy values and ignore them). 3.5.2 Develop a SET implementation SequentialSearchSET by starting with the code for SequentialSearchST and eliminating all of the code involving values. 3.5.3 Develop a SET implementation BinarySearchSET by starting with the code for BinarySearchST and eliminating all of the code involving values. 3.5.4 Develop classes HashSTint and HashSTdouble for maintaining sets of keys of primitive int and double types, respectively. (Convert generics to primitive types in</p><p attribs="{'xml:space': 'preserve'}" id="_08910" smilref="Title.smil#_08910"> the code of LinearProbingHashST.)</p><p attribs="{'xml:space': 'preserve'}" id="_08911" smilref="Title.smil#_08911"> 3.5.5 Develop classes STint and STdouble for maintaining ordered symbol tables where keys are primitive int and double types, respectively. (Convert generics to primitive types in the code of RedBlackBST.) Test your solution with a version of SparseVector as a client. 3.5.6 Develop classes HashSETint and HashSETdouble for maintaining sets of keys of primitive int and double types, respectively. (Eliminate code involving values in your</p><p attribs="{'xml:space': 'preserve'}" id="_08912" smilref="Title.smil#_08912"> solution to Exercise 3.5.4.)</p><p attribs="{'xml:space': 'preserve'}" id="_08913" smilref="Title.smil#_08913"> 3.5.7 Develop classes SETint and SETdouble for maintaining ordered sets of keys of primitive int and double types, respectively. (Eliminate code involving values in your</p><p attribs="{'xml:space': 'preserve'}" id="_08914" smilref="Title.smil#_08914"> solution to Exercise 3.5.5.)</p><p attribs="{'xml:space': 'preserve'}" id="_08915" smilref="Title.smil#_08915"> 3.5.8 Modify LinearProbingHashST to keep duplicate keys in the table. Return any value associated with the given key for get(), and remove all items in the table that have keys equal to the given key for delete(). 3.5.9 Modify BST to keep duplicate keys in the tree. Return any value associated with the given key for get(), and remove all nodes in the tree that h ave keys equal to the given key for delete(). 3.5.10 Modify RedBlackBST to keep duplicate keys in the tree. Return any value associated with the given key for get(), and remove all nodes in the tree that h ave keys equal to the given key for delete().</p><p attribs="{'xml:space': 'preserve'}" id="_08916" smilref="Title.smil#_08916" /><pagenum id="p521" page="normal" smilref="Title.smil#p521" /><p attribs="{'xml:space': 'preserve'}" id="_08917" smilref="Title.smil#_08917"> 508</p><p attribs="{'xml:space': 'preserve'}" id="_08918" smilref="Title.smil#_08918"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08919" smilref="Title.smil#_08919"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08920" smilref="Title.smil#_08920"> 3.5.11 Develop a MultiSET class that is like SET, but allows equal keys and thus implements a mathematical multiset. 3.5.12 Modify LookupCSV to associate with each key all values that appear in a key- value pair with that key in the input (not just the most recent, as in the associative-array abstraction). 3.5.13 Modify LookupCSV to make a program RangeLookupCSV that takes two key values from the standard input and prints all key-value pairs in the .csv file such that the key falls within the range speci&#64257; ed. 3.5.14 Develop and test a static method invert() that takes as argument an ST&lt;String, Bag&lt;String&gt;&gt; and produces as return value the inverse of the given symbol table (a symbol table of the same type). 3.5.15 Write a program that takes a string on standard input and an integer k as com- mand-line argument and puts on standard output a sorted list of the k-grams found in the string, each followed by its index in the string. 3.5.16 Add a method sum() to SparseVector that takes a SparseVector as argument and returns a SparseVector that is the term-by-term sum of this vector and the argument vector. Note: You need delete() (and special attention to precision) to handle the case where an entry becomes 0.</p><p attribs="{'xml:space': 'preserve'}" id="_08921" smilref="Title.smil#_08921" /><pagenum id="p522" page="normal" smilref="Title.smil#p522" /><p attribs="{'xml:space': 'preserve'}" id="_08922" smilref="Title.smil#_08922"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08923" smilref="Title.smil#_08923"> 509</p><p attribs="{'xml:space': 'preserve'}" id="_08924" smilref="Title.smil#_08924"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_08925" smilref="Title.smil#_08925"> 3.5.17 Mathematical sets. Your goal is to develop an implementation of the following API MathSET for processing (mutable) mathematical sets:</p><p attribs="{'xml:space': 'preserve'}" id="_08926" smilref="Title.smil#_08926"> public class MathSET&lt;Key&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_08927" smilref="Title.smil#_08927"> MathSET(Key[] universe)</p><p attribs="{'xml:space': 'preserve'}" id="_08928" smilref="Title.smil#_08928"> void add(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08929" smilref="Title.smil#_08929"> MathSET&lt;Key&gt; complement()</p><p attribs="{'xml:space': 'preserve'}" id="_08930" smilref="Title.smil#_08930"> void union(MathSET&lt;Key&gt; a)</p><p attribs="{'xml:space': 'preserve'}" id="_08931" smilref="Title.smil#_08931"> void intersection(MathSET&lt;Key&gt; a)</p><p attribs="{'xml:space': 'preserve'}" id="_08932" smilref="Title.smil#_08932"> void delete(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08933" smilref="Title.smil#_08933"> boolean contains(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08934" smilref="Title.smil#_08934"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_08935" smilref="Title.smil#_08935"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_08936" smilref="Title.smil#_08936"> API for a basic set data type</p><p attribs="{'xml:space': 'preserve'}" id="_08937" smilref="Title.smil#_08937"> create a set put key into the set set of keys in the universe that are not in this set put any keys from a into the set that are not already there remove any keys from this set that are not in a remove key from the set is key in the set? is the set empty? number of keys in the set</p><p attribs="{'xml:space': 'preserve'}" id="_08938" smilref="Title.smil#_08938"> Use a symbol table . Extra credit : Represent sets with arrays of boolean values.</p><p attribs="{'xml:space': 'preserve'}" id="_08939" smilref="Title.smil#_08939"> 3.5.18 Multisets. After referring to Exercises 3.5.2 and 3.5.3 and the previous exer- cise, develop APIs MultiHashSET and MultiSET for multisets (sets that can have equal</p><p attribs="{'xml:space': 'preserve'}" id="_08940" smilref="Title.smil#_08940"> keys) and implementations SeparateChainingMultiSET and BinarySearchMultiSET</p><p attribs="{'xml:space': 'preserve'}" id="_08941" smilref="Title.smil#_08941"> for multisets and ordered multisets, respectively. 3.5.19 Equal keys in symbol tables. Consider the API MultiST (unordered or ordered) to be the same as our symbol-table APIs defined on page 363 and page 366, but with equal keys allowed, so that the semantics of get() is to return any value associated with the given key, and we add a new method</p><p attribs="{'xml:space': 'preserve'}" id="_08942" smilref="Title.smil#_08942"> Iterable&lt;Value&gt; getAll(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_08943" smilref="Title.smil#_08943" /><pagenum id="p523" page="normal" smilref="Title.smil#p523" /><p attribs="{'xml:space': 'preserve'}" id="_08944" smilref="Title.smil#_08944"> 510</p><p attribs="{'xml:space': 'preserve'}" id="_08945" smilref="Title.smil#_08945"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08946" smilref="Title.smil#_08946"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08947" smilref="Title.smil#_08947"> that returns all values associated with the given key. Using our code for SeparateChainingST and BinarySearchST as a starting point, develop implementa-</p><p attribs="{'xml:space': 'preserve'}" id="_08948" smilref="Title.smil#_08948"> tions SeparateChainingMultiST and BinarySearchMultiST for these APIs.</p><p attribs="{'xml:space': 'preserve'}" id="_08949" smilref="Title.smil#_08949"> 3.5.20 Concordance. Write an ST client Concordance that puts on standard output a concordance of the strings in the standard input stream (see page 498). 3.5.21 Inverted concordance. Write a program InvertedConcordance that takes a concordance on standard input and puts the original string on standard output stream. Note : This computation is associated with a famous story having to do with the Dead Sea Scrolls. The team that discovered the original tablets enforced a secrecy rule that essentially resulted in their making public only a concordance. After a while, other researchers figured out how to invert the concordance, and the full text was eventually made public. 3.5.22 Fully indexed CSV. Implement an ST client FullLookupCSV that builds an array of ST objects (one for each fi eld), with a test client that allows the user to specify the key and value fields in each query. 3.5.23 Sparse matrices. Develop an API and an implementation for sparse 2D matri- ces. Support matrix addition and matrix multiplication. Include constructors for row and column vectors. 3.5.24 Non-overlapping interval search. Given a list of non-overlapping intervals of items, write a function that takes an item as argument and determines in which, if any, interval that item lies. For example, if the items are integers and the intervals are</p><p attribs="{'xml:space': 'preserve'}" id="_08950" smilref="Title.smil#_08950"> 1643-2033, 5532-7643, 8999-10332, 5666653-5669321, then the query point 9122</p><p attribs="{'xml:space': 'preserve'}" id="_08951" smilref="Title.smil#_08951"> lies in the third interval and 8122 lies in no interval. 3.5.25 Registrar scheduling. The registrar at a prominent northeastern University recently scheduled an instructor to teach two different classes at the same exact time. Help the registrar prevent future mistakes by describing a method to check for such con&#64258; icts. For simplicity, assume all classes run for 50 minutes starting at 9:00, 10:00, 11:00, 1:00, 2:00, or 3:00. 3.5.26 LRU cache. Create a data structure that supports the following operations: access and remove. The access operation inserts the item onto the data structure if it&#8217;s not already present. The remove operation deletes and returns the item that was least</p><p attribs="{'xml:space': 'preserve'}" id="_08952" smilref="Title.smil#_08952" /><pagenum id="p524" page="normal" smilref="Title.smil#p524" /><p attribs="{'xml:space': 'preserve'}" id="_08953" smilref="Title.smil#_08953"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08954" smilref="Title.smil#_08954"> 511</p><p attribs="{'xml:space': 'preserve'}" id="_08955" smilref="Title.smil#_08955"> recently accessed. Hint : Maintain the items in order of access in a doubly linked list, along with pointers to the first and last nodes. Use a symbol table with keys = items, values = location in linked list. When you access an element, delete it from the linked list and reinsert it at the beginning. When you remove an element, delete it from the end and remove it from the symbol table. 3.5.27 List. Develop an implementation of the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_08956" smilref="Title.smil#_08956"> public class List&lt;Item&gt; implements Iterable&lt;Item&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_08957" smilref="Title.smil#_08957"> List()</p><p attribs="{'xml:space': 'preserve'}" id="_08958" smilref="Title.smil#_08958"> void addFront(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_08959" smilref="Title.smil#_08959"> void addBack(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_08960" smilref="Title.smil#_08960"> Item deleteFront()</p><p attribs="{'xml:space': 'preserve'}" id="_08961" smilref="Title.smil#_08961"> Item deleteBack()</p><p attribs="{'xml:space': 'preserve'}" id="_08962" smilref="Title.smil#_08962"> void delete(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_08963" smilref="Title.smil#_08963"> void add(int i, Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_08964" smilref="Title.smil#_08964"> Item delete(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_08965" smilref="Title.smil#_08965"> boolean contains(Item item)</p><p attribs="{'xml:space': 'preserve'}" id="_08966" smilref="Title.smil#_08966"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_08967" smilref="Title.smil#_08967"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_08968" smilref="Title.smil#_08968"> create a list add item to the front add item to the back remove from the front remove from the back remove item from the list add item as the ith in the list remove the ith item from the list is key in the list? is the list empty? number of items in the list</p><p attribs="{'xml:space': 'preserve'}" id="_08969" smilref="Title.smil#_08969"> API for a list data type</p><p attribs="{'xml:space': 'preserve'}" id="_08970" smilref="Title.smil#_08970"> Hint : Use two symbol tables, one to find the ith item in the list ef&#64257; ciently, and the other to efficiently search by item. ( Java&#8217;s java.util.List interface contains methods like these but does not supply any implementation that efficiently supports all operations.) 3.5.28 UniQueue. Create a data type that is a queue, except that an element may only be inserted the queue once. Use an existence symbol table to keep track of all elements that have ever been inserted and ignore requests to re-insert such items.</p><p attribs="{'xml:space': 'preserve'}" id="_08971" smilref="Title.smil#_08971" /><pagenum id="p525" page="normal" smilref="Title.smil#p525" /><p attribs="{'xml:space': 'preserve'}" id="_08972" smilref="Title.smil#_08972"> 512</p><p attribs="{'xml:space': 'preserve'}" id="_08973" smilref="Title.smil#_08973"> CHAPTER 3 </p><p attribs="{'xml:space': 'preserve'}" id="_08974" smilref="Title.smil#_08974"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_08975" smilref="Title.smil#_08975"> 3.5.29 Symbol table with random access. Create a data type that supports inserting a key-value pair, searching for a key and returning the associated value, and deleting and returning a random key. Hint : Combine a symbol table and a randomized queue.</p><p attribs="{'xml:space': 'preserve'}" id="_08976" smilref="Title.smil#_08976" /><pagenum id="p526" page="normal" smilref="Title.smil#p526" /><p attribs="{'xml:space': 'preserve'}" id="_08977" smilref="Title.smil#_08977"> 3.5 </p><p attribs="{'xml:space': 'preserve'}" id="_08978" smilref="Title.smil#_08978"> 513</p><p attribs="{'xml:space': 'preserve'}" id="_08979" smilref="Title.smil#_08979"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_08980" smilref="Title.smil#_08980"> 3.5.30 Duplicates (revisited). Redo Exercise 2.5.31 using the Dedup filter given on page 490. Compare the running times of the two approaches. Then use Dedup to run the experiments for N = 10 7, 10 8, and10 9, repeat the experiments for random long values and discuss the results. 3.5.31 Spell checker. With the file dictionary.txt from the booksite as command- line argument, the BlackFilter client described on page 491 prints all misspelled words in a text file taken from standard input. Compare the performance of RedBlackBST,</p><p attribs="{'xml:space': 'preserve'}" id="_08981" smilref="Title.smil#_08981"> SeparateChainingHashST, and LinearProbingHashST for the file WarAndPeace.txt</p><p attribs="{'xml:space': 'preserve'}" id="_08982" smilref="Title.smil#_08982"> (available on the booksite) with this client and discuss the results. 3.5.32 Dictionary. Study the performance of a client like LookupCSV in a scenario where performance matters. Speci&#64257; cally, design a query-generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries. 3.5.33 Indexing. Study a client like LookupIndex in a scenario where performance matters. Speci&#64257; cally, design a query-generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries. 3.5.34 Sparse vector. Run experiments to compare the performance of matrix-vector multiplication using SparseVector to the standard implementation using arrays. 3.5.35 Primitive types. Evaluate the utility of using primitive types for Integer and Double values, for LinearProbingHashST and RedBlackBST. How much space and time are saved, for large numbers of searches in large tables?</p><p attribs="{'xml:space': 'preserve'}" id="_08983" smilref="Title.smil#_08983" /></level3></level1><level1 id="ch4"><section epub:type="chapter" id="section_00003"><header id="header_00003"><pagenum epub:type="pagebreak" id="p527" page="normal" smilref="Title.smil#p527" /><h1 id="ch4-start" smilref="Title.smil#ch4-start" xml:space="preserve">4 Graphs</h1></header></section><pagenum id="p527" page="normal" smilref="Title.smil#p527" /><p attribs="{'xml:space': 'preserve'}" id="_08984" smilref="Title.smil#_08984"> FO U R</p><p attribs="{'xml:space': 'preserve'}" id="_08985" smilref="Title.smil#_08985"> Graphs</p><p attribs="{'xml:space': 'preserve'}" id="_08986" smilref="Title.smil#_08986"> 4.1 Undirected Graphs . . . . . . . . . . . 518 4.2 Directed Graphs . . . . . . . . . . . . . 566 4.3 Minimum Spanning Trees . . . . . . . 604 4.4 Shortest Paths . . . . . . . . . . . . . . 638</p><p attribs="{'xml:space': 'preserve'}" id="_08987" smilref="Title.smil#_08987" /><pagenum id="p528" page="normal" smilref="Title.smil#p528" /><p attribs="{'xml:space': 'preserve'}" id="_08988" smilref="Title.smil#_08988"> Pairwise connections between items play a critical role in a vast array of computational applications. The relationships implied by these connections lead immediately to a host of natural questions: Is there a way to connect one item to another by following the connections? How many other items are connected to a given item? What is the shortest chain of connections between this item and this other item? To model such situations, we use abstract mathematical objects called graphs. In this chapter, we examine basic properties of graphs in detail, setting the stage for us to study a variety of algorithms that are useful for answering questions of the type just posed. These algorithms serve as the basis for attacking problems in important applications whose solution we could not even contemplate without good algorithmic technology. Graph theory, a major branch of mathematics, has been studied intensively for hundreds of years. Many important and useful properties of graphs have been discovered, many important algorithms have been developed, and many difficult problems are still actively being studied. In this chapter, we introduce a variety of fundamental graph algorithms that are important in diverse applications. Like so many of the other problem domains that we have studied, the algorithmic investigation of graphs is relatively recent. Although a few of the fundamental algorithms are centuries old, the majority of the interesting ones have been discovered within the last several decades and have benefited from the emergence of the algorithmic technology that we have been studying. Even the simplest graph algorithms lead to useful computer programs, and the nontrivial algorithms that we examine are among the most elegant and interesting algorithms known. To illustrate the diversity of applications that involve graph processing, we begin our exploration of algorithms in this fertile area by introducing several examples.</p><p attribs="{'xml:space': 'preserve'}" id="_08989" smilref="Title.smil#_08989"> 515</p><p attribs="{'xml:space': 'preserve'}" id="_08990" smilref="Title.smil#_08990" /><pagenum id="p529" page="normal" smilref="Title.smil#p529" /><p attribs="{'xml:space': 'preserve'}" id="_08991" smilref="Title.smil#_08991"> 516</p><p attribs="{'xml:space': 'preserve'}" id="_08992" smilref="Title.smil#_08992"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_08993" smilref="Title.smil#_08993"> Maps. A person who is planning a trip may need to answer questions such as &#8220;What is the shortest route from Providence to Princeton?&#8221; A seasoned traveler who has experienced traffic delays on the shortest route may ask the question &#8220;What is the fastest way to get from Providence to Princeton?&#8221; To answer such questions, we process information about connections (roads) between items (intersections).</p><p attribs="{'xml:space': 'preserve'}" id="_08994" smilref="Title.smil#_08994"> Web content. When we browse the web, we encounter pages that contain references (links) to other pages and we move from page to page by clicking on the links. The entire web is a graph, where the items are pages and the connections are links. Graph- processing algorithms are essential components of the search engines that help us locate information on the web.</p><p attribs="{'xml:space': 'preserve'}" id="_08995" smilref="Title.smil#_08995"> Circuits. An electric circuit comprises devices such as transistors, resistors, and capacitors that are intricately wired together. We use computers to control machines that make circuits and to check that the circuits perform desired functions. We need to answer simple questions such as &#8220;Is a short-circuit present?&#8221; as well as complicated questions such as &#8220;Can we lay out this circuit on a chip without making any wires cross?&#8221; The answer to the first question depends on only the properties of the connections (wires), whereas the answer to the second question requires detailed information about the wires, the devices that those wires connect, and the physical constraints of the chip.</p><p attribs="{'xml:space': 'preserve'}" id="_08996" smilref="Title.smil#_08996"> Schedules. A manufacturing process requires a variety of jobs to be performed, under a set of constraints that specify that certain tasks cannot be started until certain other tasks have been completed. How do we schedule the tasks such that we both respect the given constraints and complete the whole process in the least amount of time?</p><p attribs="{'xml:space': 'preserve'}" id="_08997" smilref="Title.smil#_08997"> Commerce. Retailers and financial instututions track buy/sell orders in a market. A connection in this situation represents the transfer of cash and goods between an institution and a customer. Knowledge of the nature of the connection structure in this instance may enhance our understanding of the nature of the market.</p><p attribs="{'xml:space': 'preserve'}" id="_08998" smilref="Title.smil#_08998"> Matching. Students apply for positions in selective institutions such as social clubs, universities, or medical schools. Items correspond to the students and the institutions; connections correspond to the applications. We want to discover methods for matching interested students with available positions.</p><p attribs="{'xml:space': 'preserve'}" id="_08999" smilref="Title.smil#_08999"> Computer networks. A computer network consists of interconnected sites that send, forward, and receive messages of various types. We are interested in knowing about the nature of the interconnection structure because we want to lay wires and build switches that can handle the traffic ef&#64257; ciently.</p><p attribs="{'xml:space': 'preserve'}" id="_09000" smilref="Title.smil#_09000" /><pagenum id="p530" page="normal" smilref="Title.smil#p530" /><p attribs="{'xml:space': 'preserve'}" id="_09001" smilref="Title.smil#_09001"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09002" smilref="Title.smil#_09002"> 517</p><p attribs="{'xml:space': 'preserve'}" id="_09003" smilref="Title.smil#_09003"> Software. A compiler builds graphs to represent relationships among modules in a large software system. The items are the various classes or modules that comprise the system; connections are associated either with the possibility that a method in one class might call another (static analysis) or with actual calls while the system is in operation (dynamic analysis). We need to analyze the graph to determine how best to allocate resources to the program most ef&#64257; ciently.</p><p attribs="{'xml:space': 'preserve'}" id="_09004" smilref="Title.smil#_09004"> Social networks. When you use a social network, you build explicit connections with your friends. Items correspond to people; connections are to friends or followers. Un- derstanding the properties of these networks is a modern graph-processing applications of intense interest not just to compaines that support such networks, but also in politics, diplomacy, entertainment, education, marketing, and many other domains.</p><p attribs="{'xml:space': 'preserve'}" id="_09005" smilref="Title.smil#_09005"> These examples indicate the range of applications for which graphs are the ap-</p><p attribs="{'xml:space': 'preserve'}" id="_09006" smilref="Title.smil#_09006"> application</p><p attribs="{'xml:space': 'preserve'}" id="_09007" smilref="Title.smil#_09007"> item</p><p attribs="{'xml:space': 'preserve'}" id="_09008" smilref="Title.smil#_09008"> connection</p><p attribs="{'xml:space': 'preserve'}" id="_09009" smilref="Title.smil#_09009"> propriate abstraction and also the range of computational problems that we might encounter when we work with graphs. Thousands of such problems have been studied, but many problems can be addressed in the context of one of several basic graph mod- els&#8212;we will study the most important ones in this chapter. In practical appli- cations, it is common for the volume of data involved to be truly huge, so that efficient algorithms make the difference between whether or not a solution is at all feasible. To organize the presentation, we progress through the four most important types of graph models: undirected graphs (with simple connections), digraphs (where the direction of each connection is signi&#64257; cant), edge-weighted graphs (where each connection has an associated weight), and edge-weighted digraphs (where each connection has both a direction and a weight).</p><p attribs="{'xml:space': 'preserve'}" id="_09010" smilref="Title.smil#_09010"> map web content circuit schedule commerce matching computer network soft ware social network</p><p attribs="{'xml:space': 'preserve'}" id="_09011" smilref="Title.smil#_09011"> page device job customer student site method person</p><p attribs="{'xml:space': 'preserve'}" id="_09012" smilref="Title.smil#_09012"> link wire constraint transaction application connection call friendship</p><p attribs="{'xml:space': 'preserve'}" id="_09013" smilref="Title.smil#_09013"> intersection</p><p attribs="{'xml:space': 'preserve'}" id="_09014" smilref="Title.smil#_09014"> road</p><p attribs="{'xml:space': 'preserve'}" id="_09015" smilref="Title.smil#_09015"> Typical graph applications</p><p attribs="{'xml:space': 'preserve'}" id="_09016" smilref="Title.smil#_09016" /><level3 id="_00067"><h3 id="ch4-s1-ss1" smilref="Title.smil#ch4-s1-ss1" xml:space="preserve">Glossary</h3><pagenum id="p532" page="normal" smilref="Title.smil#p532" /><p attribs="{'xml:space': 'preserve'}" id="_09017" smilref="Title.smil#_09017"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09018" smilref="Title.smil#_09018"> 519</p><p attribs="{'xml:space': 'preserve'}" id="_09019" smilref="Title.smil#_09019"> Glossary A substantial amount of nomenclature is associated with graphs. Most of the terms have straightforward defi nitions, and, for reference, we consider them in one place: here. When there is an edge connecting two vertices, we say that the vertices are adjacent to one another and that the edge is incident to both vertices. The degree of a vertex is the number of edges incident to it. A subgraph is a subset of a graph&#8217;s edges (and associated vertices) that constitutes a graph. Many computational tasks involve identifying subgraphs of various types. Of particular interest are edges that take us through a sequence of vertices in a graph.</p><p attribs="{'xml:space': 'preserve'}" id="_09020" smilref="Title.smil#_09020"> cycle of length 5</p><p attribs="{'xml:space': 'preserve'}" id="_09021" smilref="Title.smil#_09021"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09022" smilref="Title.smil#_09022"> edge</p><p attribs="{'xml:space': 'preserve'}" id="_09023" smilref="Title.smil#_09023"> Definition. A path in a graph is a sequence of vertices connected by edges. A simple path is one with no repeated vertices. A cycle is a path with at least one edge whose first and last vertices are the same. A simple cycle is a cycle with no repeated edges or vertices (except the requisite repetition of the first and last vertices). The length of a path or a cycle is its number of edges.</p><p attribs="{'xml:space': 'preserve'}" id="_09024" smilref="Title.smil#_09024"> vertex of degree 3</p><p attribs="{'xml:space': 'preserve'}" id="_09025" smilref="Title.smil#_09025"> path of length 4</p><p attribs="{'xml:space': 'preserve'}" id="_09026" smilref="Title.smil#_09026"> connected components</p><p attribs="{'xml:space': 'preserve'}" id="_09027" smilref="Title.smil#_09027"> Most often, we work with simple cycles and simple paths and drop the simple modifer; when we want to allow repeated ver- tices, we refer to general paths and cycles. We say that one vertex is connected to another if there exists a path that contains both of them. We use notation like u-v-w-x to represent a path from u to x and u-v-w-x-u to represent a cycle from u to v to w to x and back to u again. Several of the algorithms that we consider find paths and cycles. Moreover, paths and cycles lead us to consider the structural properties of a graph as a whole:</p><p attribs="{'xml:space': 'preserve'}" id="_09028" smilref="Title.smil#_09028"> Anatomy of a graph</p><p attribs="{'xml:space': 'preserve'}" id="_09029" smilref="Title.smil#_09029"> Definition. A graph is connected if there is a path from every vertex to every other vertex in the graph. A graph that is not connected consists of a set of connected com- ponents, which are maximal connected subgraphs.</p><p attribs="{'xml:space': 'preserve'}" id="_09030" smilref="Title.smil#_09030"> Intuitively, if the vertices were physical objects, such as knots or beads, and the edges were physical connections, such as strings or wires, a connected graph would stay in one piece if picked up by any vertex, and a graph that is not connected comprises two or more such pieces. Generally, processing a graph necessitates processing the connected components one at a time.</p><p attribs="{'xml:space': 'preserve'}" id="_09031" smilref="Title.smil#_09031" /><pagenum id="p533" page="normal" smilref="Title.smil#p533" /><p attribs="{'xml:space': 'preserve'}" id="_09032" smilref="Title.smil#_09032"> 520</p><p attribs="{'xml:space': 'preserve'}" id="_09033" smilref="Title.smil#_09033"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09034" smilref="Title.smil#_09034"> An acyclic graph is a graph with no cycles. Several of the algorithms that we consider are concerned with fi nd- ing acyclic subgraphs of a given graph that satisfy certain properties. We need additional terminology to refer to these structures:</p><p attribs="{'xml:space': 'preserve'}" id="_09035" smilref="Title.smil#_09035"> 18 vertices 17 edges</p><p attribs="{'xml:space': 'preserve'}" id="_09036" smilref="Title.smil#_09036"> acyclic</p><p attribs="{'xml:space': 'preserve'}" id="_09037" smilref="Title.smil#_09037"> Definition. A tree is an acyclic connected graph. A disjoint set of trees is called a forest. A spanning tree of a connected graph is a subgraph that contains all of that graph&#8217;s vertices and is a single tree. A spanning forest of a graph is the union of spanning trees of its connected components.</p><p attribs="{'xml:space': 'preserve'}" id="_09038" smilref="Title.smil#_09038"> connected</p><p attribs="{'xml:space': 'preserve'}" id="_09039" smilref="Title.smil#_09039"> A tree</p><p attribs="{'xml:space': 'preserve'}" id="_09040" smilref="Title.smil#_09040"> A spanning forest</p><p attribs="{'xml:space': 'preserve'}" id="_09041" smilref="Title.smil#_09041"> This definition of tree is quite general: with suitable re&#64257; ne- ments it embraces the trees that we typically use to model program behavior (function-call hierarchies) and data structures (BSTs, 2-3 trees, and so forth). Mathematical properties of trees are well-studied and intuitive, so we state them without proof. For example, a graph G with V vertices is a tree if and only if it satisfies any of the following five conditions: </p><p attribs="{'xml:space': 'preserve'}" id="_09042" smilref="Title.smil#_09042"> Two graphs (V = 50)</p><p attribs="{'xml:space': 'preserve'}" id="_09043" smilref="Title.smil#_09043"> sparse (E = 200)</p><p attribs="{'xml:space': 'preserve'}" id="_09044" smilref="Title.smil#_09044"> dense (E = 1000)</p><p attribs="{'xml:space': 'preserve'}" id="_09045" smilref="Title.smil#_09045" /><pagenum id="p534" page="normal" smilref="Title.smil#p534" /><p attribs="{'xml:space': 'preserve'}" id="_09046" smilref="Title.smil#_09046"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09047" smilref="Title.smil#_09047"> 521</p><p attribs="{'xml:space': 'preserve'}" id="_09048" smilref="Title.smil#_09048"> leaves a gray area (when the number of edges is, say, ~ c V3/2) but the distinction between sparse and dense is typically very clear in applications. The applications that we consider nearly always involve sparse graphs. A bipartite graph is a graph whose vertices we can divide into two sets such that all edges connect a vertex in one set with a vertex in the other set. The figure at right gives an example of a bipartite graph, where one set of vertices is colored red and the other set of vertices is colored black. Bipartite graphs arise in a natural way in many situations, one of which we will consider in detail at the end of this section.</p><p attribs="{'xml:space': 'preserve'}" id="_09049" smilref="Title.smil#_09049"> A bipartite graph</p><p attribs="{'xml:space': 'preserve'}" id="_09050" smilref="Title.smil#_09050"> With these preparations, we are ready to move on to consider graph-processing algorithms. We begin by considering an API and implementation for a graph data type, then we consider classic algorithms for searching graphs and for identifying connected components. To conclude the section, we consider real-world applications where vertex names need not be integers and graphs may have huge numbers of vertices and edges.</p><p attribs="{'xml:space': 'preserve'}" id="_09051" smilref="Title.smil#_09051" /></level3><level3 id="_00068"><h3 id="ch4-s1-ss2" smilref="Title.smil#ch4-s1-ss2" xml:space="preserve">Undirected graph type</h3><pagenum id="p535" page="normal" smilref="Title.smil#p535" /><p attribs="{'xml:space': 'preserve'}" id="_09052" smilref="Title.smil#_09052"> 522</p><p attribs="{'xml:space': 'preserve'}" id="_09053" smilref="Title.smil#_09053"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09054" smilref="Title.smil#_09054"> Undirected graph data type Our starting point for developing graph-process- ing algorithms is an API that defines the fundamental graph operations. This scheme allows us to address graph-processing tasks ranging from elementary maintenance operations to sophisticated solutions of difficult problems.</p><p attribs="{'xml:space': 'preserve'}" id="_09055" smilref="Title.smil#_09055"> public class Graph</p><p attribs="{'xml:space': 'preserve'}" id="_09056" smilref="Title.smil#_09056"> Graph(int V) Graph(In in) int V() int E() void addEdge(int v, int w) add edge v-w to this graph Iterable&lt;Integer&gt; adj(int v) String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_09057" smilref="Title.smil#_09057"> create a V-vertex graph with no edges read a graph from input stream in number of vertices number of edges</p><p attribs="{'xml:space': 'preserve'}" id="_09058" smilref="Title.smil#_09058"> vertices adjacent to v string representation</p><p attribs="{'xml:space': 'preserve'}" id="_09059" smilref="Title.smil#_09059"> API for an undirected graph</p><p attribs="{'xml:space': 'preserve'}" id="_09060" smilref="Title.smil#_09060"> This API contains two constructors, methods to return the number of vertices and edges, a method to add an edge, a toString() method, and a method adj() that allows client code to iterate through the vertices adjacent to a given vertex (the order of iteration is not speci&#64257; ed). Remarkably, we can build all of the algorithms that we consider in this section on the basic abstraction embodied in adj(). The second constructor assumes an input format consisting of 2E + 2 integer values: V, then E, then E pairs of values between 0 and V&#11002;1, each pair denoting an edge. As examples, we use the two graphs tinyG.txt and mediumG.txt that are depicted below. Several examples of Graph client code are shown in the table on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_09061" smilref="Title.smil#_09061"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09062" smilref="Title.smil#_09062"> tinyG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09063" smilref="Title.smil#_09063"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09064" smilref="Title.smil#_09064"> 13 13 0 5 4 3 0 1 9 12 6 4 5 4 0 2 11 12 9 10 0 6 7 8 9 11 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09065" smilref="Title.smil#_09065"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09066" smilref="Title.smil#_09066"> mediumG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09067" smilref="Title.smil#_09067"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09068" smilref="Title.smil#_09068"> 250 1273 244 246 239 240 238 245 235 238 233 240 232 248 231 248 229 249 228 241 226 231 ...</p><p attribs="{'xml:space': 'preserve'}" id="_09069" smilref="Title.smil#_09069"> Input format for Graph constructor (two examples)</p><p attribs="{'xml:space': 'preserve'}" id="_09070" smilref="Title.smil#_09070"> (1263 additional lines)</p><p attribs="{'xml:space': 'preserve'}" id="_09071" smilref="Title.smil#_09071" /><pagenum id="p536" page="normal" smilref="Title.smil#p536" /><p attribs="{'xml:space': 'preserve'}" id="_09072" smilref="Title.smil#_09072"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09073" smilref="Title.smil#_09073"> 523</p><p attribs="{'xml:space': 'preserve'}" id="_09074" smilref="Title.smil#_09074"> task</p><p attribs="{'xml:space': 'preserve'}" id="_09075" smilref="Title.smil#_09075"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_09076" smilref="Title.smil#_09076"> compute the degree of v</p><p attribs="{'xml:space': 'preserve'}" id="_09077" smilref="Title.smil#_09077"> public static int degree(Graph G, int v) { int degree = 0; for (int w : G.adj(v)) degree++; return degree; }</p><p attribs="{'xml:space': 'preserve'}" id="_09078" smilref="Title.smil#_09078"> compute maximum degree</p><p attribs="{'xml:space': 'preserve'}" id="_09079" smilref="Title.smil#_09079"> public static int maxDegree(Graph G) { int max = 0; for (int v = 0; v &lt; G.V(); v++) if (degree(G, v) &gt; max) max = degree(G, v); return max; }</p><p attribs="{'xml:space': 'preserve'}" id="_09080" smilref="Title.smil#_09080"> compute average degree</p><p attribs="{'xml:space': 'preserve'}" id="_09081" smilref="Title.smil#_09081"> public static double averageDegree(Graph G) { return 2.0 * G.E() / G.V(); }</p><p attribs="{'xml:space': 'preserve'}" id="_09082" smilref="Title.smil#_09082"> count self-loops</p><p attribs="{'xml:space': 'preserve'}" id="_09083" smilref="Title.smil#_09083"> public static int numberOfSelfLoops(Graph G) { int count = 0; for (int v = 0; v &lt; G.V(); v++) for (int w : G.adj(v)) if (v == w) count++; return count/2; // each edge counted twice }</p><p attribs="{'xml:space': 'preserve'}" id="_09084" smilref="Title.smil#_09084"> string representation of the graph&#8217;s adjacency lists (instance method in Graph)</p><p attribs="{'xml:space': 'preserve'}" id="_09085" smilref="Title.smil#_09085"> public String toString() { String s = V + " vertices, " + E + " edges\n"; for (int v = 0; v &lt; V; v++) { s += v + ": "; for (int w : this.adj(v)) s += w + " "; s += "\n"; } return s; }</p><p attribs="{'xml:space': 'preserve'}" id="_09086" smilref="Title.smil#_09086"> Typical graph-processing code</p><p attribs="{'xml:space': 'preserve'}" id="_09087" smilref="Title.smil#_09087" /><pagenum id="p537" page="normal" smilref="Title.smil#p537" /><p attribs="{'xml:space': 'preserve'}" id="_09088" smilref="Title.smil#_09088"> 524</p><p attribs="{'xml:space': 'preserve'}" id="_09089" smilref="Title.smil#_09089"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09090" smilref="Title.smil#_09090"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09091" smilref="Title.smil#_09091"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09092" smilref="Title.smil#_09092"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09093" smilref="Title.smil#_09093"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09094" smilref="Title.smil#_09094"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09095" smilref="Title.smil#_09095"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09096" smilref="Title.smil#_09096"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09097" smilref="Title.smil#_09097"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09098" smilref="Title.smil#_09098"> Bag objects</p><p attribs="{'xml:space': 'preserve'}" id="_09099" smilref="Title.smil#_09099"> Representation alternatives. The next decision that we face in graph processing is which graph representation (data structure) to use to implement this API. We have two basic requirements: </p><p attribs="{'xml:space': 'preserve'}" id="_09100" smilref="Title.smil#_09100"> adj[] 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09101" smilref="Title.smil#_09101"> representations of the same edge</p><p attribs="{'xml:space': 'preserve'}" id="_09102" smilref="Title.smil#_09102"> Adjacency-lists representation (undirected graph)</p><p attribs="{'xml:space': 'preserve'}" id="_09103" smilref="Title.smil#_09103"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_09104" smilref="Title.smil#_09104"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09105" smilref="Title.smil#_09105"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09106" smilref="Title.smil#_09106"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09107" smilref="Title.smil#_09107"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09108" smilref="Title.smil#_09108"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09109" smilref="Title.smil#_09109"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09110" smilref="Title.smil#_09110"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09111" smilref="Title.smil#_09111"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09112" smilref="Title.smil#_09112"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09113" smilref="Title.smil#_09113"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_09114" smilref="Title.smil#_09114"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_09115" smilref="Title.smil#_09115"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_09116" smilref="Title.smil#_09116"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_09117" smilref="Title.smil#_09117"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09118" smilref="Title.smil#_09118"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09119" smilref="Title.smil#_09119"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09120" smilref="Title.smil#_09120"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_09121" smilref="Title.smil#_09121" /></level3><level3 id="_00069"><h3 id="ch4-s1-ss3" smilref="Title.smil#ch4-s1-ss3" xml:space="preserve">Adjacency-lists representation</h3><pagenum id="p538" page="normal" smilref="Title.smil#p538" /><p attribs="{'xml:space': 'preserve'}" id="_09122" smilref="Title.smil#_09122"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09123" smilref="Title.smil#_09123"> 525</p><p attribs="{'xml:space': 'preserve'}" id="_09124" smilref="Title.smil#_09124"> Adjacency-lists data structure. The standard graph representation for graphs that are not dense is called the adjacency-lists data structure, where we keep track of all the vertices adjacent to each vertex on a linked list that is associated with that vertex. We maintain an array of lists so that, given a vertex, we can immediately access its list. To implement lists, we use our Bag ADT from Section 1.3 with a linked-list implementa- tion, so that we can add new edges in constant time and iterate through adjacent vertices in constant time per adjacent vertex. The Graph implementation on page 526 is based on this approach, and the figure on the facing page depicts the data structures built by this code for tinyG.txt. To add an edge connecting v and w, we add w to v&#8217;s adjacency list and v to w&#8217;s adjacency list. Thus, each edge appears twice in the data structure. This Graph implementation achieves the following performance characteristics: </p><p attribs="{'xml:space': 'preserve'}" id="_09125" smilref="Title.smil#_09125"> 13 13 0 5 4 3 0 1 9 12 6 4 5 4 0 2 11 12 9 10 0 6 7 8 9 11 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09126" smilref="Title.smil#_09126"> Output for list-of-edges input</p><p attribs="{'xml:space': 'preserve'}" id="_09127" smilref="Title.smil#_09127"> tinyG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09128" smilref="Title.smil#_09128"> f i r s t ad j a c en t v e r tex in input  i s la s t on l i s t</p><p attribs="{'xml:space': 'preserve'}" id="_09129" smilref="Title.smil#_09129"> % java Graph tinyG.txt 13 vertices, 13 edges 0: 6 2 1 5 1: 0 2: 0 3: 5 4 4: 5 6 3 5: 3 4 0 6: 0 4 7: 8 8: 7 9: 11 10 12 10: 9 11: 9 12 12: 11 9</p><p attribs="{'xml:space': 'preserve'}" id="_09130" smilref="Title.smil#_09130"> s e cond re p re s en ta t ion o f ea ch edge  app ea r s in red</p><p attribs="{'xml:space': 'preserve'}" id="_09131" smilref="Title.smil#_09131"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09132" smilref="Title.smil#_09132"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09133" smilref="Title.smil#_09133" /><pagenum id="p539" page="normal" smilref="Title.smil#p539" /><p attribs="{'xml:space': 'preserve'}" id="_09134" smilref="Title.smil#_09134"> 526</p><p attribs="{'xml:space': 'preserve'}" id="_09135" smilref="Title.smil#_09135"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09136" smilref="Title.smil#_09136"> Graph data type</p><p attribs="{'xml:space': 'preserve'}" id="_09137" smilref="Title.smil#_09137"> public class Graph { private final int V; // number of vertices private int E; // number of edges private Bag&lt;Integer&gt;[] adj; // adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_09138" smilref="Title.smil#_09138"> public Graph(int V) { this.V = V; this.E = 0; adj = (Bag&lt;Integer&gt;[]) new Bag[V]; // Create array of lists. for (int v = 0; v &lt; V; v++) // Initialize all lists adj[v] = new Bag&lt;Integer&gt;(); // to empty. }</p><p attribs="{'xml:space': 'preserve'}" id="_09139" smilref="Title.smil#_09139"> public Graph(In in) { this(in.readInt()); // Read V and construct this graph. int E = in.readInt(); // Read E. for (int i = 0; i &lt; E; i++) { // Add an edge. int v = in.readInt(); // Read a vertex, int w = in.readInt(); // read another vertex, addEdge(v, w); // and add edge connecting them. } }</p><p attribs="{'xml:space': 'preserve'}" id="_09140" smilref="Title.smil#_09140"> public int V() { return V; } public int E() { return E; }</p><p attribs="{'xml:space': 'preserve'}" id="_09141" smilref="Title.smil#_09141"> public void addEdge(int v, int w) { adj[v].add(w); // Add w to v&#8217;s list. adj[w].add(v); // Add v to w&#8217;s list. E++; }</p><p attribs="{'xml:space': 'preserve'}" id="_09142" smilref="Title.smil#_09142"> public Iterable&lt;Integer&gt; adj(int v) { return adj[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09143" smilref="Title.smil#_09143"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09144" smilref="Title.smil#_09144"> This Graph implementation maintains a vertex-indexed array of lists of integers. Every edge appears twice: if an edge connects v and w, then w appears in v&#8217;s list and v appears in w&#8217;s list. The second constructor reads a graph from an input stream, in the format V followed by E followed by a list of pairs of int values between 0 and V&#11002;1. See page 523 for toString().</p><p attribs="{'xml:space': 'preserve'}" id="_09145" smilref="Title.smil#_09145" /><pagenum id="p540" page="normal" smilref="Title.smil#p540" /><p attribs="{'xml:space': 'preserve'}" id="_09146" smilref="Title.smil#_09146"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09147" smilref="Title.smil#_09147"> 527</p><p attribs="{'xml:space': 'preserve'}" id="_09148" smilref="Title.smil#_09148"> It is certainly reasonable to contemplate other operations that might be useful in applications, and to consider methods for </p><p attribs="{'xml:space': 'preserve'}" id="_09149" smilref="Title.smil#_09149"> underlying data structure</p><p attribs="{'xml:space': 'preserve'}" id="_09150" smilref="Title.smil#_09150"> list of edges</p><p attribs="{'xml:space': 'preserve'}" id="_09151" smilref="Title.smil#_09151"> adjacency matrix</p><p attribs="{'xml:space': 'preserve'}" id="_09152" smilref="Title.smil#_09152"> adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_09153" smilref="Title.smil#_09153"> adjacency sets</p><p attribs="{'xml:space': 'preserve'}" id="_09154" smilref="Title.smil#_09154"> space</p><p attribs="{'xml:space': 'preserve'}" id="_09155" smilref="Title.smil#_09155"> add edge v-w</p><p attribs="{'xml:space': 'preserve'}" id="_09156" smilref="Title.smil#_09156"> check whether w is adjacent to v</p><p attribs="{'xml:space': 'preserve'}" id="_09157" smilref="Title.smil#_09157"> iterate through vertices adjacent to v</p><p attribs="{'xml:space': 'preserve'}" id="_09158" smilref="Title.smil#_09158"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09159" smilref="Title.smil#_09159"> V 2</p><p attribs="{'xml:space': 'preserve'}" id="_09160" smilref="Title.smil#_09160"> E &#11001; V</p><p attribs="{'xml:space': 'preserve'}" id="_09161" smilref="Title.smil#_09161"> E &#11001; V</p><p attribs="{'xml:space': 'preserve'}" id="_09162" smilref="Title.smil#_09162"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09163" smilref="Title.smil#_09163"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09164" smilref="Title.smil#_09164"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09165" smilref="Title.smil#_09165"> log V</p><p attribs="{'xml:space': 'preserve'}" id="_09166" smilref="Title.smil#_09166"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09167" smilref="Title.smil#_09167"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09168" smilref="Title.smil#_09168"> degree(v)</p><p attribs="{'xml:space': 'preserve'}" id="_09169" smilref="Title.smil#_09169"> log V</p><p attribs="{'xml:space': 'preserve'}" id="_09170" smilref="Title.smil#_09170"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09171" smilref="Title.smil#_09171"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09172" smilref="Title.smil#_09172"> degree(v)</p><p attribs="{'xml:space': 'preserve'}" id="_09173" smilref="Title.smil#_09173"> degree(v)</p><p attribs="{'xml:space': 'preserve'}" id="_09174" smilref="Title.smil#_09174"> Order-of-growth performance for typical Graph implementations</p><p attribs="{'xml:space': 'preserve'}" id="_09175" smilref="Title.smil#_09175" /><pagenum id="p541" page="normal" smilref="Title.smil#p541" /><p attribs="{'xml:space': 'preserve'}" id="_09176" smilref="Title.smil#_09176"> 528</p><p attribs="{'xml:space': 'preserve'}" id="_09177" smilref="Title.smil#_09177"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09178" smilref="Title.smil#_09178"> Design pattern for graph processing. Since we consider a large number of graph-pro- cessing algorithms, our initial design goal is to decouple our implementations from the graph representation. To do so, we develop, for each given task, a task-speci&#64257; c class so that clients can create objects to perform the task. Generally, the constructor does some preprocessing to build data structures so as to efficiently respond to client queries. A typical client program builds a graph, passes that graph to an algorithm implementation class (as argument to a constructor), and then calls client query methods to learn various properties of the graph. As a warmup, consider this API:</p><p attribs="{'xml:space': 'preserve'}" id="_09179" smilref="Title.smil#_09179"> public class Search</p><p attribs="{'xml:space': 'preserve'}" id="_09180" smilref="Title.smil#_09180"> Search(Graph G, int s) fi nd vertices connected to a source vertex s is v connected to s? how many vertices are connected to s?</p><p attribs="{'xml:space': 'preserve'}" id="_09181" smilref="Title.smil#_09181"> boolean marked(int v) int count()</p><p attribs="{'xml:space': 'preserve'}" id="_09182" smilref="Title.smil#_09182"> Graph-processing API (warmup)</p><p attribs="{'xml:space': 'preserve'}" id="_09183" smilref="Title.smil#_09183"> We use the term source to distinguish the vertex provided as argument to the constructor from the other vertices in the graph. In this API, the job of the constructor is to find the vertices in the graph that are connected to the source. Then client code calls the instance methods marked() and count() to learn characteristics of the graph. The name marked() refers to an approach used by the basic algorithms that we consider throughout this chapter: they follow paths from the source to other vertices in the graph, marking each vertex encountered. The example client TestSearch shown on the facing page takes an input stream name and a source vertex number from the command line, reads a graph from the input stream (using the second Graph constructor), builds a Search object for the given graph and source, and uses marked() to print the vertices in that graph that are connected to the source. It also calls count() and prints whether or not the graph is connected (the graph is connected if and only if the search marked all of its vertices).</p><p attribs="{'xml:space': 'preserve'}" id="_09184" smilref="Title.smil#_09184" /><pagenum id="p542" page="normal" smilref="Title.smil#p542" /><p attribs="{'xml:space': 'preserve'}" id="_09185" smilref="Title.smil#_09185"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09186" smilref="Title.smil#_09186"> 529</p><p attribs="{'xml:space': 'preserve'}" id="_09187" smilref="Title.smil#_09187"> We have already seen one way to implement the Search API: the union-&#64257; nd algorithms of Chapter 1. The constructor can build a UF object, do a union() operation for each of the graph&#8217;s edges, and implement marked(v) by calling connected(s, v). Implementing count() requires using a weighted UF implementation and extending its API to use a count() method that returns wt[find(v)] (see Exercise 4.1.8). This implementation is simple and ef&#64257; cient, but the implementation that we consider next is even simpler and more ef&#64257; cient. It is based on depth-&#64257; rst search, a fundamental recursive method that follows the graph&#8217;s edges to find the vertices connected to the source. Depth-&#64257; rst search is the basis for several of the graph-processing algorithms that we consider throughout this chapter.</p><p attribs="{'xml:space': 'preserve'}" id="_09188" smilref="Title.smil#_09188"> public class TestSearch { public static void main(String[] args) { Graph G = new Graph(new In(args[0])); int s = Integer.parseInt(args[1]); Search search = new Search(G, s);</p><p attribs="{'xml:space': 'preserve'}" id="_09189" smilref="Title.smil#_09189"> for (int v = 0; v &lt; G.V(); v++) if (search.marked(v)) StdOut.print(v + " "); StdOut.println();</p><p attribs="{'xml:space': 'preserve'}" id="_09190" smilref="Title.smil#_09190"> if (search.count() != G.V()) StdOut.print("NOT "); StdOut.println("connected"); } }</p><p attribs="{'xml:space': 'preserve'}" id="_09191" smilref="Title.smil#_09191"> Sample graph-processing client (warmup)</p><p attribs="{'xml:space': 'preserve'}" id="_09192" smilref="Title.smil#_09192"> % java TestSearch tinyG.txt 0 0 1 2 3 4 5 6 NOT connected</p><p attribs="{'xml:space': 'preserve'}" id="_09193" smilref="Title.smil#_09193"> % java TestSearch tinyG.txt 9 9 10 11 12 NOT connected</p><p attribs="{'xml:space': 'preserve'}" id="_09194" smilref="Title.smil#_09194"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09195" smilref="Title.smil#_09195"> tinyG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09196" smilref="Title.smil#_09196"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09197" smilref="Title.smil#_09197"> 13 13 0 5 4 3 0 1 9 12 6 4 5 4 0 2 11 12 9 10 0 6 7 8 9 11 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09198" smilref="Title.smil#_09198" /></level3><level3 id="_00070"><h3 id="ch4-s1-ss4" smilref="Title.smil#ch4-s1-ss4" xml:space="preserve">Depth-first search</h3><pagenum id="p543" page="normal" smilref="Title.smil#p543" /><p attribs="{'xml:space': 'preserve'}" id="_09199" smilref="Title.smil#_09199"> 530</p><p attribs="{'xml:space': 'preserve'}" id="_09200" smilref="Title.smil#_09200"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09201" smilref="Title.smil#_09201"> maze</p><p attribs="{'xml:space': 'preserve'}" id="_09202" smilref="Title.smil#_09202"> graph</p><p attribs="{'xml:space': 'preserve'}" id="_09203" smilref="Title.smil#_09203"> intersection passage</p><p attribs="{'xml:space': 'preserve'}" id="_09204" smilref="Title.smil#_09204"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09205" smilref="Title.smil#_09205"> edge</p><p attribs="{'xml:space': 'preserve'}" id="_09206" smilref="Title.smil#_09206"> Equivalent models of a maze</p><p attribs="{'xml:space': 'preserve'}" id="_09207" smilref="Title.smil#_09207"> Depth-&#64257; rst search We often learn properties of a graph by systematically examining each of its vertices and each of its edges. Determining some simple graph proper- ties&#8212;for example, computing the degrees of all the vertices&#8212;is easy if we just examine each edge (in any order whatever). But many other graph properties are related to paths, so a natural way to learn them is to move from vertex to vertex along the graph&#8217;s edges. Nearly all of the graph-processing algorithms that we consider use this same basic abstract model, albeit with various different strategies. The simplest is a classic method that we now consider.</p><p attribs="{'xml:space': 'preserve'}" id="_09208" smilref="Title.smil#_09208"> Searching in a maze. It is instructive to think about the process of searching through a graph in terms of an equivalent problem that has a long and distinguished history&#8212;&#64257; nding our way through a maze that consists of passages connected by inter- sections. Some mazes can be handled with a simple rule, but most mazes require a more sophisticated strategy. Using the terminology maze instead of graph, passage instead of edge, and intersection instead of vertex is making mere semantic distinc- tions, but, for the moment, doing so will help to give us an intuitive feel for the problem. One trick for exploring a maze without getting lost that has been known since antiquity (dating back at least to the legend of Theseus and the Minotaur) is known as Tremaux exploration. To explore all passages in a maze: </p><p attribs="{'xml:space': 'preserve'}" id="_09209" smilref="Title.smil#_09209"> Tremaux exploration</p><p attribs="{'xml:space': 'preserve'}" id="_09210" smilref="Title.smil#_09210" /><pagenum id="p544" page="normal" smilref="Title.smil#p544" /><p attribs="{'xml:space': 'preserve'}" id="_09211" smilref="Title.smil#_09211"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09212" smilref="Title.smil#_09212"> 531</p><p attribs="{'xml:space': 'preserve'}" id="_09213" smilref="Title.smil#_09213"> Warmup. The classic recursive method for searching in a connected graph (visiting all of its vertices and edges) mimics Tremaux maze exploration but is even simpler to de- scribe. To search a graph, invoke a recursive method that visits vertices. To visit a vertex: </p><p attribs="{'xml:space': 'preserve'}" id="_09214" smilref="Title.smil#_09214"> public class DepthFirstSearch { private boolean[] marked; private int count;</p><p attribs="{'xml:space': 'preserve'}" id="_09215" smilref="Title.smil#_09215"> public DepthFirstSearch(Graph G, int s) { marked = new boolean[G.V()]; dfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09216" smilref="Title.smil#_09216"> private void dfs(Graph G, int v) { marked[v] = true; count++; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); }</p><p attribs="{'xml:space': 'preserve'}" id="_09217" smilref="Title.smil#_09217"> public boolean marked(int w) { return marked[w]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09218" smilref="Title.smil#_09218"> public int count() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_09219" smilref="Title.smil#_09219"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09220" smilref="Title.smil#_09220"> Depth-f irst search</p><p attribs="{'xml:space': 'preserve'}" id="_09221" smilref="Title.smil#_09221"> Proposition A. DFS marks all the vertices connected to a given source in time proportional to the sum of their degrees.</p><p attribs="{'xml:space': 'preserve'}" id="_09222" smilref="Title.smil#_09222"> Proof : First, we prove that the algorithm marks all the vertices connected to the source s (and no others). Every marked vertex is connected to s, since the algorithm finds vertices only by following edges. Now, suppose that some unmarked vertex w is connected to s. Since s itself is marked, any path from s to w must have at least one edge from the set of marked vertices to the set of unmarked vertices, say v-x. But the algorithm would have discovered x after marking v, so no such edge can exist, a contradiction. The time bound follows because marking ensures that each vertex is visited once (taking time proportional to its degree to check marks).</p><p attribs="{'xml:space': 'preserve'}" id="_09223" smilref="Title.smil#_09223"> source</p><p attribs="{'xml:space': 'preserve'}" id="_09224" smilref="Title.smil#_09224"> set of marked vertices</p><p attribs="{'xml:space': 'preserve'}" id="_09225" smilref="Title.smil#_09225"> set of unmarked vertices</p><p attribs="{'xml:space': 'preserve'}" id="_09226" smilref="Title.smil#_09226"> s</p><p attribs="{'xml:space': 'preserve'}" id="_09227" smilref="Title.smil#_09227"> v</p><p attribs="{'xml:space': 'preserve'}" id="_09228" smilref="Title.smil#_09228"> x</p><p attribs="{'xml:space': 'preserve'}" id="_09229" smilref="Title.smil#_09229"> w</p><p attribs="{'xml:space': 'preserve'}" id="_09230" smilref="Title.smil#_09230"> no such edge can exist</p><p attribs="{'xml:space': 'preserve'}" id="_09231" smilref="Title.smil#_09231" /><pagenum id="p545" page="normal" smilref="Title.smil#p545" /><p attribs="{'xml:space': 'preserve'}" id="_09232" smilref="Title.smil#_09232"> 532</p><p attribs="{'xml:space': 'preserve'}" id="_09233" smilref="Title.smil#_09233"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09234" smilref="Title.smil#_09234"> tinyCG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09235" smilref="Title.smil#_09235"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09236" smilref="Title.smil#_09236"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09237" smilref="Title.smil#_09237"> standard drawing</p><p attribs="{'xml:space': 'preserve'}" id="_09238" smilref="Title.smil#_09238"> One-way passages. The method call&#8211;return mechanism in the program corresponds to the string in the maze: when we have processed all the edges incident to a vertex (explored all the passages leaving an intersection), we &#8220;return&#8221; (in both senses of the word). To draw a proper correspondence with Tremaux exploration of a maze, we need to imagine a maze constructed entirely of one-way passages (one in each direction). In the same way that we encounter each passage in the maze twice (once in each direction), we encounter each edge in the graph twice (once at each of its vertices). In Tremaux exploration, we either explore a passage for the first time or return along it from a marked vertex; in DFS of an undirected graph, we either do a recursive call when we encounter an edge v-w (if w is not marked) or skip the edge (if w is marked). The second time that we encounter the edge, in the opposite orientation w-v, we always ignore it, because the destination vertex v has certainly already been visited (the first time that we encountered the edge).</p><p attribs="{'xml:space': 'preserve'}" id="_09239" smilref="Title.smil#_09239"> drawing with both edges</p><p attribs="{'xml:space': 'preserve'}" id="_09240" smilref="Title.smil#_09240"> 6 8 0 5 2 4 2 3 1 2 0 1 3 4 3 5 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_09241" smilref="Title.smil#_09241"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09242" smilref="Title.smil#_09242"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09243" smilref="Title.smil#_09243"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09244" smilref="Title.smil#_09244"> adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_09245" smilref="Title.smil#_09245"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09246" smilref="Title.smil#_09246"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09247" smilref="Title.smil#_09247"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09248" smilref="Title.smil#_09248"> adj[] 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09249" smilref="Title.smil#_09249"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09250" smilref="Title.smil#_09250"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09251" smilref="Title.smil#_09251"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09252" smilref="Title.smil#_09252"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09253" smilref="Title.smil#_09253"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09254" smilref="Title.smil#_09254"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09255" smilref="Title.smil#_09255"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09256" smilref="Title.smil#_09256"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09257" smilref="Title.smil#_09257"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09258" smilref="Title.smil#_09258"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09259" smilref="Title.smil#_09259"> Tracing DFS. As usual, one good way to understand an algorithm is to trace its behavior on a small example. This is particularly true of depth- first search. The first thing to bear in mind when doing a trace is that the order in which edges are examined and vertices visited depends upon the representation, not just the graph or the al- gorithm. Since DFS only examines vertices connected to the source, we use the small connected graph depicted at left as an example for traces. In this example, vertex 2 is the first vertex visited after 0 because it happens to be first on 0&#8217;s adjacency list. The second thing to bear in mind when doing a trace is that, as mentioned above, DFS traverses each edge in the graph twice, always finding a marked vertex the second time. One effect of this observation is that tracing a DFS takes twice as long as you might think! Our example graph has only eight edges, but we need to trace the action of the algorithm on the 16 entries on the adjacency lists.</p><p attribs="{'xml:space': 'preserve'}" id="_09260" smilref="Title.smil#_09260"> A connected undirected graph</p><p attribs="{'xml:space': 'preserve'}" id="_09261" smilref="Title.smil#_09261" /><pagenum id="p546" page="normal" smilref="Title.smil#p546" /><p attribs="{'xml:space': 'preserve'}" id="_09262" smilref="Title.smil#_09262"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09263" smilref="Title.smil#_09263"> 533</p><p attribs="{'xml:space': 'preserve'}" id="_09264" smilref="Title.smil#_09264"> marked[]</p><p attribs="{'xml:space': 'preserve'}" id="_09265" smilref="Title.smil#_09265"> adj[]</p><p attribs="{'xml:space': 'preserve'}" id="_09266" smilref="Title.smil#_09266"> 0 T 0 2 1 5 1 1 0 2 2 2 0 1 3 4 3 3 5 4 2 4 4 3 2 5 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09267" smilref="Title.smil#_09267"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09268" smilref="Title.smil#_09268"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09269" smilref="Title.smil#_09269"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09270" smilref="Title.smil#_09270"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09271" smilref="Title.smil#_09271"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09272" smilref="Title.smil#_09272"> dfs(0)</p><p attribs="{'xml:space': 'preserve'}" id="_09273" smilref="Title.smil#_09273"> dfs(3)</p><p attribs="{'xml:space': 'preserve'}" id="_09274" smilref="Title.smil#_09274"> dfs(2) check 0</p><p attribs="{'xml:space': 'preserve'}" id="_09275" smilref="Title.smil#_09275"> dfs(1) check 0 check 2 1 done</p><p attribs="{'xml:space': 'preserve'}" id="_09276" smilref="Title.smil#_09276"> Detailed trace of depth-&#64257; rst search. The figure at right shows the contents of the data structures just after each vertex is marked for our small example, with source 0. The search begins when the constructor calls the recursive dfs() to mark and visit vertex 0 and proceeds as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_09277" smilref="Title.smil#_09277"> dfs(4) check 3 check 2 4 done check 2 3 done check 4 2 done check 1 check 5 0 done</p><p attribs="{'xml:space': 'preserve'}" id="_09278" smilref="Title.smil#_09278"> dfs(5) check 3 check 0 5 done</p><p attribs="{'xml:space': 'preserve'}" id="_09279" smilref="Title.smil#_09279"> 0 T 1 T 2 T 3 T 4 T 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09280" smilref="Title.smil#_09280"> 0 T 1 2 T 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09281" smilref="Title.smil#_09281"> 0 T 1 T 2 T 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09282" smilref="Title.smil#_09282"> 0 T 1 T 2 T 3 T 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09283" smilref="Title.smil#_09283"> 0 T 1 T 2 T 3 T 4 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09284" smilref="Title.smil#_09284"> Trace of depth-first search to find vertices connected to 0</p><p attribs="{'xml:space': 'preserve'}" id="_09285" smilref="Title.smil#_09285" /><pagenum id="p547" page="normal" smilref="Title.smil#p547" /><p attribs="{'xml:space': 'preserve'}" id="_09286" smilref="Title.smil#_09286"> 534</p><p attribs="{'xml:space': 'preserve'}" id="_09287" smilref="Title.smil#_09287"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09288" smilref="Title.smil#_09288"> This basic recursive scheme is just a start&#8212;depth-&#64257; rst search is effective for many</p><p attribs="{'xml:space': 'preserve'}" id="_09289" smilref="Title.smil#_09289"> graph-processing tasks. For example, in this section, we consider the use of depth-&#64257; rst search to address a problem that we first posed in Chapter 1: Connectivity. Given a graph, support queries of the form Are two given vertices connected ? and How many connected components does the graph have ?</p><p attribs="{'xml:space': 'preserve'}" id="_09290" smilref="Title.smil#_09290"> This problem is easily solved within our standard graph-processing design pattern, and we will compare and contrast this solution with the union-&#64257; nd algorithms that we considered in Section 1.5. The question &#8220;Are two given vertices connected?&#8221; is equivalent to the question &#8220;Is there a path connecting two given vertices?&#8221; and might be named the path detection problem. However, the union-&#64257; nd data structures that we considered in Section 1.5 do not address the problems of finding such a path. Depth-&#64257; rst search is the first of several approaches that we consider to solve this problem, as well:</p><p attribs="{'xml:space': 'preserve'}" id="_09291" smilref="Title.smil#_09291"> Single-source paths. Given a graph and a source vertex s, support queries of the form Is there a path from s to a given target vertex v? If so, find such a path.</p><p attribs="{'xml:space': 'preserve'}" id="_09292" smilref="Title.smil#_09292"> DFS is deceptively simple because it is based on a familiar concept and is so easy to implement; in fact, it is a subtle and powerful algorithm that researchers have learned to put to use to solve numerous difficult problems. These two are the first of several that we will consider.</p><p attribs="{'xml:space': 'preserve'}" id="_09293" smilref="Title.smil#_09293" /><pagenum id="p548" page="normal" smilref="Title.smil#p548" /><p attribs="{'xml:space': 'preserve'}" id="_09294" smilref="Title.smil#_09294"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09295" smilref="Title.smil#_09295"> 535</p><p attribs="{'xml:space': 'preserve'}" id="_09296" smilref="Title.smil#_09296"> Finding paths The single-source paths problem is fundamental to graph process- ing. In accordance with our standard design pattern, we use the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_09297" smilref="Title.smil#_09297"> public class Paths</p><p attribs="{'xml:space': 'preserve'}" id="_09298" smilref="Title.smil#_09298"> boolean hasPathTo(int v) Iterable&lt;Integer&gt; pathTo(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_09299" smilref="Title.smil#_09299"> Paths(Graph G, int s) fi nd paths in G from source s is there a path from s to v? path from s to v; null if no such path</p><p attribs="{'xml:space': 'preserve'}" id="_09300" smilref="Title.smil#_09300"> API for paths implementations</p><p attribs="{'xml:space': 'preserve'}" id="_09301" smilref="Title.smil#_09301"> The constructor takes a source vertex s as argument and computes paths from s to each vertex connected to s. After creating a Paths object for a source s, the client can use the instance method pathTo() to iterate through the vertices on a path from s to any vertex connected to s. For the moment, we accept any path; later, we shall develop implementations that find paths having certain properties. The test client at right takes a graph from the input stream and a source from the command line and prints a path from the source to each vertex connected to it.</p><p attribs="{'xml:space': 'preserve'}" id="_09302" smilref="Title.smil#_09302"> public static void main(String[] args) { Graph G = new Graph(new In(args[0])); int s = Integer.parseInt(args[1]); Paths search = new Paths(G, s); for (int v = 0; v &lt; G.V(); v++) { StdOut.print(s + " to " + v + ": "); if (search.hasPathTo(v)) for (int x : search.pathTo(v)) if (x == s) StdOut.print(x); else StdOut.print("-" + x); StdOut.println(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_09303" smilref="Title.smil#_09303"> Test client for paths implementations</p><p attribs="{'xml:space': 'preserve'}" id="_09304" smilref="Title.smil#_09304"> Implementation. Algorithm 4.1 on page 536 is a DFS-based implementation of Paths that extends the DepthFirstSearch warmup on page 531 by adding as an instance variable an array edgeTo[] of int values that serves the purpose of the ball of string in Tremaux exploration: it gives a way to find a path back to s for every vertex connected to s. Instead of just keeping track of the path from the current vertex back to the start, we remember a path from each vertex to the start. To accomplish this, we remember the edge v-w that takes us to each vertex w for the first time, by setting edgeTo[w] to v. In other words, v-w is the last edge on the known path from s to w. The result of the search is a tree rooted at the source; edgeTo[] is a parent-link representation of that tree. A small example is drawn to</p><p attribs="{'xml:space': 'preserve'}" id="_09305" smilref="Title.smil#_09305"> % java Paths tinyCG.txt 0 0 to 0: 0 0 to 1: 0-2-1 0 to 2: 0-2 0 to 3: 0-2-3 0 to 4: 0-2-3-4 0 to 5: 0-2-3-5</p><p attribs="{'xml:space': 'preserve'}" id="_09306" smilref="Title.smil#_09306" /><pagenum id="p549" page="normal" smilref="Title.smil#p549" /><p attribs="{'xml:space': 'preserve'}" id="_09307" smilref="Title.smil#_09307"> 536</p><p attribs="{'xml:space': 'preserve'}" id="_09308" smilref="Title.smil#_09308"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09309" smilref="Title.smil#_09309"> ALGORITHM 4.1 Depth-first search to find paths in a graph</p><p attribs="{'xml:space': 'preserve'}" id="_09310" smilref="Title.smil#_09310"> public class DepthFirstPaths { private boolean[] marked; // Has dfs() been called for this vertex? private int[] edgeTo; // last vertex on known path to this vertex private final int s; // source</p><p attribs="{'xml:space': 'preserve'}" id="_09311" smilref="Title.smil#_09311"> public DepthFirstPaths(Graph G, int s) { marked = new boolean[G.V()]; edgeTo = new int[G.V()]; this.s = s; dfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09312" smilref="Title.smil#_09312"> private void dfs(Graph G, int v) { marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) { edgeTo[w] = v; dfs(G, w); } }</p><p attribs="{'xml:space': 'preserve'}" id="_09313" smilref="Title.smil#_09313"> public boolean hasPathTo(int v) { return marked[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09314" smilref="Title.smil#_09314"> edgeTo[] 0 1 2 2 0 3 2 4 3 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09315" smilref="Title.smil#_09315"> x path</p><p attribs="{'xml:space': 'preserve'}" id="_09316" smilref="Title.smil#_09316"> 5 5 3 3 5 2 2 3 5 0 0 2 3 5</p><p attribs="{'xml:space': 'preserve'}" id="_09317" smilref="Title.smil#_09317"> Trace of pathTo(5) computation</p><p attribs="{'xml:space': 'preserve'}" id="_09318" smilref="Title.smil#_09318"> public Iterable&lt;Integer&gt; pathTo(int v) { if (!hasPathTo(v)) return null; Stack&lt;Integer&gt; path = new Stack&lt;Integer&gt;(); for (int x = v; x != s; x = edgeTo[x]) path.push(x); path.push(s); return path; } }</p><p attribs="{'xml:space': 'preserve'}" id="_09319" smilref="Title.smil#_09319"> This Graph client uses depth-&#64257; rst search to find paths to all the vertices in a graph that are connected to a given start vertex s. Code from DepthFirstSearch (page 531) is printed in gray. To save known paths to each vertex, this code maintains a vertex-indexed array edgeTo[] such that edgeTo[w] = v means that v-w was the edge used to access w for the first time. The edgeTo[] array is a parent-link representation of a tree rooted at s that contains all the vertices connected to s.</p><p attribs="{'xml:space': 'preserve'}" id="_09320" smilref="Title.smil#_09320" /><pagenum id="p550" page="normal" smilref="Title.smil#p550" /><p attribs="{'xml:space': 'preserve'}" id="_09321" smilref="Title.smil#_09321"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09322" smilref="Title.smil#_09322"> 537</p><p attribs="{'xml:space': 'preserve'}" id="_09323" smilref="Title.smil#_09323"> the right of the code in Algorithm 4.1. To recover the path from s to any vertex v, the pathTo() method in Algorithm 4.1 uses a variable x to travel up the tree, setting x to edgeTo[x], just as we did for union- find in Section 1.5, putting each vertex encountered onto a stack until reaching s. Returning the stack to the client as an Iterable enables the client to follow the path from s to v.</p><p attribs="{'xml:space': 'preserve'}" id="_09324" smilref="Title.smil#_09324"> Detailed trace. The figure at right shows the contents of edgeTo[] just after each vertex is marked for our example, with source 0. The contents of marked[] and adj[] are the same as in the trace of DepthFirstSearch on page 533, as is the detailed description of the recursive calls and the edges checked, so these aspects of the trace are omitted. The depth- first search adds the edges 0-2, 2-1, 2-3, 3-5, and 3-4 to edgeTo[], in that order. These edges form a tree rooted at the source and provide the information needed for pathTo() to provide for the client the path from 0 to 1, 2, 3, 4, or 5, as just described.</p><p attribs="{'xml:space': 'preserve'}" id="_09325" smilref="Title.smil#_09325"> The constructor in DepthFirstPaths differs only in a few assignment statements from the constructor in DepthFirstSearch, so Proposition A on page 531 applies. In addition, we have:</p><p attribs="{'xml:space': 'preserve'}" id="_09326" smilref="Title.smil#_09326"> Proposition A (continued). DFS allows us to pro-</p><p attribs="{'xml:space': 'preserve'}" id="_09327" smilref="Title.smil#_09327"> vide clients with a path from a given source to any marked vertex in time proportional its length.</p><p attribs="{'xml:space': 'preserve'}" id="_09328" smilref="Title.smil#_09328"> Proof : By induction on the number of vertices visited, it follows that the edgeTo[] array in DepthFirstPaths represents a tree rooted at the source. The pathTo() method builds the path in time proportional to its length.</p><p attribs="{'xml:space': 'preserve'}" id="_09329" smilref="Title.smil#_09329"> dfs(0)</p><p attribs="{'xml:space': 'preserve'}" id="_09330" smilref="Title.smil#_09330"> dfs(2) check 0</p><p attribs="{'xml:space': 'preserve'}" id="_09331" smilref="Title.smil#_09331"> dfs(1) check 0 check 2 1 done</p><p attribs="{'xml:space': 'preserve'}" id="_09332" smilref="Title.smil#_09332"> dfs(3)</p><p attribs="{'xml:space': 'preserve'}" id="_09333" smilref="Title.smil#_09333"> dfs(5) check 3 check 0 5 done</p><p attribs="{'xml:space': 'preserve'}" id="_09334" smilref="Title.smil#_09334"> dfs(4) check 3 check 2 4 done check 2 3 done check 4 2 done check 1 check 5 0 done</p><p attribs="{'xml:space': 'preserve'}" id="_09335" smilref="Title.smil#_09335"> edgeTo[]</p><p attribs="{'xml:space': 'preserve'}" id="_09336" smilref="Title.smil#_09336"> 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09337" smilref="Title.smil#_09337"> 0 1 2 0 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09338" smilref="Title.smil#_09338"> 0 1 2 2 0 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09339" smilref="Title.smil#_09339"> 0 1 2 2 0 3 2 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09340" smilref="Title.smil#_09340"> 0 1 2 2 0 3 2 4 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09341" smilref="Title.smil#_09341"> 0 1 2 2 0 3 2 4 3 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09342" smilref="Title.smil#_09342"> 0 1 2 2 0 3 2 4 3 5 3</p><p attribs="{'xml:space': 'preserve'}" id="_09343" smilref="Title.smil#_09343"> Trace of depth-first search to find all paths from 0</p><p attribs="{'xml:space': 'preserve'}" id="_09344" smilref="Title.smil#_09344" /></level3><level3 id="_00071"><h3 id="ch4-s1-ss5" smilref="Title.smil#ch4-s1-ss5" xml:space="preserve">Breadth-first search</h3><pagenum id="p551" page="normal" smilref="Title.smil#p551" /><p attribs="{'xml:space': 'preserve'}" id="_09345" smilref="Title.smil#_09345"> 538</p><p attribs="{'xml:space': 'preserve'}" id="_09346" smilref="Title.smil#_09346"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09347" smilref="Title.smil#_09347"> Breadth-&#64257; rst search The paths discovered by depth-&#64257; rst search depend not just on the graph, but also on the representation and the nature of the recursion. Naturally, we are often interested in solving the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_09348" smilref="Title.smil#_09348"> Single-source shortest paths. Given a graph and a source vertex s, support queries of the form Is there a path from s to a given target vertex v? If so, find a shortest such path (one with a minimal number of edges).</p><p attribs="{'xml:space': 'preserve'}" id="_09349" smilref="Title.smil#_09349"> The classical method for accomplishing this task, called breadth-&#64257; rst search (BFS ), is also the basis of numerous algorithms for processing graphs, so we consider it in detail in this section. DFS offers us little assistance in solving this problem, because the order in which it takes us through the graph has no relationship to the goal of fi nd- ing shortest paths. In contrast, BFS is based on this goal. To find a shortest path from s to v, we start at s and check for v among all the vertices that we can reach by following one edge, then we check for v among all the vertices that we can reach from s by following two edges, and so forth. DFS is analogous to one person exploring a maze. BFS is analogous to a group of searchers exploring by fanning out in all directions, each unrolling his or her own ball of string. When more than one passage needs to be explored, we imagine that the searchers split up to expore all of them; when two groups of searchers meet up, they join forces (using the ball of string held by the one getting there fi rst). In a program, when we come to a point during a graph search where we have more than one edge to traverse, we choose one and save the others to be explored later. In DFS, we use a pushdown stack (that is managed by the system to support the recursive search method) for this purpose. Using the LIFO rule that characterizes the pushdown stack corresponds to exploring passages that are close by in a maze. We choose, of the passages yet to be explored, the one that was most recently encountered. In BFS, we want to explore the vertices in order of their distance from the source. It turns out that this order is easily arranged: use a (FIFO) queue instead of a (LIFO) stack. We choose, of the passages yet to be explored, the one that was least recently encountered. Implementation. Algorithm 4.2 on page 540 is an implementation of BFS. It is based on maintaining a queue of all vertices that have been marked but whose adjacency lists have not been checked. We put the source vertex on the queue, then perform the following steps until the queue is empty : </p><p attribs="{'xml:space': 'preserve'}" id="_09350" smilref="Title.smil#_09350"> Breadth-first maze exploration</p><p attribs="{'xml:space': 'preserve'}" id="_09351" smilref="Title.smil#_09351" /><pagenum id="p552" page="normal" smilref="Title.smil#p552" /><p attribs="{'xml:space': 'preserve'}" id="_09352" smilref="Title.smil#_09352"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09353" smilref="Title.smil#_09353"> 539</p><p attribs="{'xml:space': 'preserve'}" id="_09354" smilref="Title.smil#_09354"> edgeTo[] 0 1 0 2 0 3 2 4 2 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09355" smilref="Title.smil#_09355"> Outcome of breadth-first search to find all paths from 0</p><p attribs="{'xml:space': 'preserve'}" id="_09356" smilref="Title.smil#_09356"> marked[]</p><p attribs="{'xml:space': 'preserve'}" id="_09357" smilref="Title.smil#_09357"> edgeTo[]</p><p attribs="{'xml:space': 'preserve'}" id="_09358" smilref="Title.smil#_09358"> adj[]</p><p attribs="{'xml:space': 'preserve'}" id="_09359" smilref="Title.smil#_09359"> 0 T 0 1 1 2 2 3 3 4 4 5 5</p><p attribs="{'xml:space': 'preserve'}" id="_09360" smilref="Title.smil#_09360"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09361" smilref="Title.smil#_09361"> 0 T 1 T 2 T 3 4 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09362" smilref="Title.smil#_09362"> 0 1 0 2 0 3 4 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09363" smilref="Title.smil#_09363"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09364" smilref="Title.smil#_09364"> 0 T 1 T 2 T 3 T 4 T 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09365" smilref="Title.smil#_09365"> 0 T 1 T 2 T 3 T 4 T 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09366" smilref="Title.smil#_09366"> 0 T 1 T 2 T 3 T 4 T 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09367" smilref="Title.smil#_09367"> 0 T 1 T 2 T 3 T 4 T 5 T</p><p attribs="{'xml:space': 'preserve'}" id="_09368" smilref="Title.smil#_09368"> 0 1 0 2 0 3 2 4 2 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09369" smilref="Title.smil#_09369"> 0 1 0 2 0 3 2 4 2 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09370" smilref="Title.smil#_09370"> 0 1 0 2 0 3 2 4 2 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09371" smilref="Title.smil#_09371"> 0 1 0 2 0 3 2 4 2 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_09372" smilref="Title.smil#_09372"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09373" smilref="Title.smil#_09373"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09374" smilref="Title.smil#_09374"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09375" smilref="Title.smil#_09375"> 0 2 1 5 1 0 2 2 0 1 3 4 3 5 4 2 4 3 2 5 3 0</p><p attribs="{'xml:space': 'preserve'}" id="_09376" smilref="Title.smil#_09376"> queue</p><p attribs="{'xml:space': 'preserve'}" id="_09377" smilref="Title.smil#_09377"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09378" smilref="Title.smil#_09378"> 2 1 5</p><p attribs="{'xml:space': 'preserve'}" id="_09379" smilref="Title.smil#_09379"> The bfs() method in Algorithm 4.2 is not re- cursive. Instead of the implicit stack provided by recursion, it uses an explicit queue. The product of the search, as for DFS, is an array edgeTo[], a par- ent-link representation of a tree rooted at s, which defines the shortest paths from s to every vertex that is connected to s. The paths can be constructed for the client using the same pathTo() implementation that we used for DFS in Algorithm 4.1. The figure at right shows the step-by- step development of BFS on our sample graph, showing the contents of the data structures at the beginning of each iteration of the loop. Vertex 0 is put on the queue, then the loop completes the search as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_09380" smilref="Title.smil#_09380"> 1 5 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_09381" smilref="Title.smil#_09381"> 5 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_09382" smilref="Title.smil#_09382"> 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_09383" smilref="Title.smil#_09383"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09384" smilref="Title.smil#_09384"> Trace of breadth-first search to find all paths from 0</p><p attribs="{'xml:space': 'preserve'}" id="_09385" smilref="Title.smil#_09385" /><pagenum id="p553" page="normal" smilref="Title.smil#p553" /><p attribs="{'xml:space': 'preserve'}" id="_09386" smilref="Title.smil#_09386"> 540</p><p attribs="{'xml:space': 'preserve'}" id="_09387" smilref="Title.smil#_09387"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09388" smilref="Title.smil#_09388"> ALGORITHM 4.2 Breadth-first search to find paths in a graph</p><p attribs="{'xml:space': 'preserve'}" id="_09389" smilref="Title.smil#_09389"> public class BreadthFirstPaths</p><p attribs="{'xml:space': 'preserve'}" id="_09390" smilref="Title.smil#_09390"> { private boolean[] marked; // Is a shortest path to this vertex known? private int[] edgeTo; // last vertex on known path to this vertex private final int s; // source</p><p attribs="{'xml:space': 'preserve'}" id="_09391" smilref="Title.smil#_09391"> public BreadthFirstPaths(Graph G, int s) { marked = new boolean[G.V()]; edgeTo = new int[G.V()]; this.s = s; bfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09392" smilref="Title.smil#_09392"> private void bfs(Graph G, int s) { Queue&lt;Integer&gt; queue = new Queue&lt;Integer&gt;(); marked[s] = true; // Mark the source queue.enqueue(s); // and put it on the queue. while (!queue.isEmpty()) { int v = queue.dequeue(); // Remove next vertex from the queue. for (int w : G.adj(v)) if (!marked[w]) { edgeTo[w] = v; // save last edge on a shortest path, marked[w] = true; // mark it because path is known, queue.enqueue(w); // and add it to the queue. } } }</p><p attribs="{'xml:space': 'preserve'}" id="_09393" smilref="Title.smil#_09393"> // For every unmarked adjacent vertex,</p><p attribs="{'xml:space': 'preserve'}" id="_09394" smilref="Title.smil#_09394"> public boolean hasPathTo(int v) { return marked[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09395" smilref="Title.smil#_09395"> public Iterable&lt;Integer&gt; pathTo(int v) // Same as for DFS (see page 536).</p><p attribs="{'xml:space': 'preserve'}" id="_09396" smilref="Title.smil#_09396"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09397" smilref="Title.smil#_09397"> This Graph client uses breadth-&#64257; rst search to find paths in a graph with the fewest number of edges from the source s given in the constructor. The bfs() method marks all vertices connected to s, so clients can use hasPathTo() to determine whether a given vertex v is connected to s and pathTo() to get a path from s to v with the property that no other such path from s to v has fewer edges.</p><p attribs="{'xml:space': 'preserve'}" id="_09398" smilref="Title.smil#_09398" /><pagenum id="p554" page="normal" smilref="Title.smil#p554" /><p attribs="{'xml:space': 'preserve'}" id="_09399" smilref="Title.smil#_09399"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09400" smilref="Title.smil#_09400"> 541</p><p attribs="{'xml:space': 'preserve'}" id="_09401" smilref="Title.smil#_09401"> For this example, the edgeTo[] array is complete after the second step. As with DFS, once all vertices have been marked, the rest of the computation is just checking edges to vertices that have already been marked.</p><p attribs="{'xml:space': 'preserve'}" id="_09402" smilref="Title.smil#_09402"> Proposition B. For any vertex v reachable from s, BFS computes a shortest path from s to v (no path from s to v has fewer edges).</p><p attribs="{'xml:space': 'preserve'}" id="_09403" smilref="Title.smil#_09403"> Proof : It is easy to prove by induction that the queue always consists of zero or more vertices of distance k from the source, followed by zero or more vertices of distance k&#11001;1 from the source, for some integer k, starting with k equal to 0. This property implies, in particular, that vertices enter and leave the queue in order of their distance from s. When a vertex v enters the queue, no shorter path to v will be found before it comes off the queue, and no path to v that is discovered after it comes off the queue can be shorter than v&#8217;s tree path length.</p><p attribs="{'xml:space': 'preserve'}" id="_09404" smilref="Title.smil#_09404"> Proposition B (continued). BFS takes time proportional to V&#11001;E in the worst case. Proof : As for Proposition A (page 531), BFS marks all the vertices connected to s in time proportional to the sum of their degrees. If the graph is connected, this sum is the sum of the degrees of all the vertices, or 2E.</p><p attribs="{'xml:space': 'preserve'}" id="_09405" smilref="Title.smil#_09405"> Note that we can also use BFS to implement the Search API that we implemented with DFS, since the solution depends on only the ability of the search to examine every vertex and edge connected to the source. As implied at the outset, DFS and BFS are the first of several instances that we will examine of a general approach to searching graphs. We put the source vertex on the data structure, then perform the following steps until the data structure is empty : </p><p attribs="{'xml:space': 'preserve'}" id="_09406" smilref="Title.smil#_09406"> % java BreadthFirstPaths tinyCG.txt 0 0 to 0: 0 0 to 1: 0-1 0 to 2: 0-2 0 to 3: 0-2-3 0 to 4: 0-2-4 0 to 5: 0-5</p><p attribs="{'xml:space': 'preserve'}" id="_09407" smilref="Title.smil#_09407" /><pagenum id="p555" page="normal" smilref="Title.smil#p555" /><p attribs="{'xml:space': 'preserve'}" id="_09408" smilref="Title.smil#_09408"> 542</p><p attribs="{'xml:space': 'preserve'}" id="_09409" smilref="Title.smil#_09409"> 20%</p><p attribs="{'xml:space': 'preserve'}" id="_09410" smilref="Title.smil#_09410"> 40%</p><p attribs="{'xml:space': 'preserve'}" id="_09411" smilref="Title.smil#_09411"> 60%</p><p attribs="{'xml:space': 'preserve'}" id="_09412" smilref="Title.smil#_09412"> 80%</p><p attribs="{'xml:space': 'preserve'}" id="_09413" smilref="Title.smil#_09413"> 100%</p><p attribs="{'xml:space': 'preserve'}" id="_09414" smilref="Title.smil#_09414"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09415" smilref="Title.smil#_09415"> The diagrams on either side of</p><p attribs="{'xml:space': 'preserve'}" id="_09416" smilref="Title.smil#_09416"> 20%</p><p attribs="{'xml:space': 'preserve'}" id="_09417" smilref="Title.smil#_09417"> this page, which show the progress of DFS and BFS for our sample graph mediumG.txt, make plain the differences between the paths that are discovered by the two approaches.DFS wends its way through the graph, storing on the stack the points where other paths branch off; BFS sweeps through the graph, using a queue to remember the frontier of visited places. DFS explores the graph by looking for new vertices far away from the start point, taking closer vertices only when dead ends are encountered; BFS completely covers the area close to the starting point, moving farther away only when everything nearby has been examined. DFS paths tend to be long and wind- ing; BFS paths are short and direct. Depending upon the application, one property or the other may be desirable (or properties of paths may be imma- terial). In Section 4.4, we will be considering other implementations of the Paths API that find paths having other specified properties.</p><p attribs="{'xml:space': 'preserve'}" id="_09418" smilref="Title.smil#_09418"> 40%</p><p attribs="{'xml:space': 'preserve'}" id="_09419" smilref="Title.smil#_09419"> 60%</p><p attribs="{'xml:space': 'preserve'}" id="_09420" smilref="Title.smil#_09420"> 80%</p><p attribs="{'xml:space': 'preserve'}" id="_09421" smilref="Title.smil#_09421"> 100%</p><p attribs="{'xml:space': 'preserve'}" id="_09422" smilref="Title.smil#_09422"> DFS for paths (250 vertices)</p><p attribs="{'xml:space': 'preserve'}" id="_09423" smilref="Title.smil#_09423"> BFS for shortest paths (250 vertices)</p><p attribs="{'xml:space': 'preserve'}" id="_09424" smilref="Title.smil#_09424" /></level3><level3 id="_00072"><h3 id="ch4-s1-ss6" smilref="Title.smil#ch4-s1-ss6" xml:space="preserve">Connected components</h3><pagenum id="p556" page="normal" smilref="Title.smil#p556" /><p attribs="{'xml:space': 'preserve'}" id="_09425" smilref="Title.smil#_09425"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09426" smilref="Title.smil#_09426"> 543</p><p attribs="{'xml:space': 'preserve'}" id="_09427" smilref="Title.smil#_09427"> Connected components Our next direct application of depth-&#64257; rst search is to find the connected components of a graph. Recall from Section 1.5 (see page 216) that &#8220;is connected to&#8221; is an equivalence relation that divides the vertices into equivalence classes (the connected components). For this common graph-processing task, we define the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_09428" smilref="Title.smil#_09428"> public class CC</p><p attribs="{'xml:space': 'preserve'}" id="_09429" smilref="Title.smil#_09429"> CC(Graph G) boolean connected(int v, int w) int count()</p><p attribs="{'xml:space': 'preserve'}" id="_09430" smilref="Title.smil#_09430"> int id(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_09431" smilref="Title.smil#_09431"> preprocessing constructor are v and w connected? number of connected components component identifier  for v ( between 0 and count()-1 )</p><p attribs="{'xml:space': 'preserve'}" id="_09432" smilref="Title.smil#_09432"> API for connected components</p><p attribs="{'xml:space': 'preserve'}" id="_09433" smilref="Title.smil#_09433"> The id() method is for client use in indexing an array by component, as in the test client below, which reads a graph and then prints its number of connected components and then the vertices in each component, one component per line. To do so, it builds an array of Bag objects, then uses each vertex&#8217;s component identifier as an index into this array, to add the vertex to the appropriate Bag. This client is a model for the typical situation where we want to independently process connected components.</p><p attribs="{'xml:space': 'preserve'}" id="_09434" smilref="Title.smil#_09434"> public static void main(String[] args) { Graph G = new Graph(new In(args[0])); CC cc = new CC(G);</p><p attribs="{'xml:space': 'preserve'}" id="_09435" smilref="Title.smil#_09435"> Implementation. The</p><p attribs="{'xml:space': 'preserve'}" id="_09436" smilref="Title.smil#_09436"> implementation CC (Algorithm 4.3 on the next page) uses our marked[] array to find a vertex to serve as the starting point for a depth-&#64257; rst search in each component. The first call to the recursive DFS is for vertex 0&#8212; it marks all vertices connected to 0. Then the for loop in the constructor looks for an unmarked vertex and calls the recursive dfs() to mark all vertices connected to that ver- tex. Moreover, it maintains a vertex- indexed array id[] that associates the same int value to every vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09437" smilref="Title.smil#_09437"> int M = cc.count(); StdOut.println(M + " components");</p><p attribs="{'xml:space': 'preserve'}" id="_09438" smilref="Title.smil#_09438"> Queue&lt;Integer&gt;[] components; components = (Queue&lt;Integer&gt;[]) new Queue[M]; for (int i = 0; i &lt; M; i++) components[i] = new Queue&lt;Integer&gt;(); for (int v = 0; v &lt; G.V(); v++) components[cc.id(v)].enqueue(v); for (int i = 0; i &lt; M; i++) { for (int v: components[i]) StdOut.print(v + " "); StdOut.println(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_09439" smilref="Title.smil#_09439"> Test client for connected components API</p><p attribs="{'xml:space': 'preserve'}" id="_09440" smilref="Title.smil#_09440" /><pagenum id="p557" page="normal" smilref="Title.smil#p557" /><p attribs="{'xml:space': 'preserve'}" id="_09441" smilref="Title.smil#_09441"> 544</p><p attribs="{'xml:space': 'preserve'}" id="_09442" smilref="Title.smil#_09442"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09443" smilref="Title.smil#_09443"> ALGORITHM 4.3 Depth-first search to find connected components in a graph</p><p attribs="{'xml:space': 'preserve'}" id="_09444" smilref="Title.smil#_09444"> % more tinyG.txt 13 vertices, 13 edges 0: 6 2 1 5 1: 0 2: 0 3: 5 4 4: 5 6 3 5: 3 4 0 6: 0 4 7: 8 8: 7 9: 11 10 12 10: 9 11: 9 12 12: 11 9</p><p attribs="{'xml:space': 'preserve'}" id="_09445" smilref="Title.smil#_09445"> % java CC tinyG.txt 3 components 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09446" smilref="Title.smil#_09446"> public class CC { private boolean[] marked; private int[] id; private int count;</p><p attribs="{'xml:space': 'preserve'}" id="_09447" smilref="Title.smil#_09447"> public CC(Graph G) { marked = new boolean[G.V()]; id = new int[G.V()]; for (int s = 0; s &lt; G.V(); s++) if (!marked[s]) {</p><p attribs="{'xml:space': 'preserve'}" id="_09448" smilref="Title.smil#_09448"> dfs(G, s); count++;</p><p attribs="{'xml:space': 'preserve'}" id="_09449" smilref="Title.smil#_09449"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09450" smilref="Title.smil#_09450"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09451" smilref="Title.smil#_09451"> private void dfs(Graph G, int v) { marked[v] = true; id[v] = count; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); }</p><p attribs="{'xml:space': 'preserve'}" id="_09452" smilref="Title.smil#_09452"> public boolean connected(int v, int w) { return id[v] == id[w]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09453" smilref="Title.smil#_09453"> public int id(int v) { return id[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09454" smilref="Title.smil#_09454"> public int count() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_09455" smilref="Title.smil#_09455"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09456" smilref="Title.smil#_09456"> This Graph client provides its clients with the ability to independently process a graph&#8217;s connected components. Code from DepthFirstSearch (page 531) is left in gray. The computation is based on a vertex-indexed array id[] such that id[v] is set to i if v is in the ith connected component pro- cessed. The constructor finds an unmarked vertex and calls the recursive dfs() to mark and identify all the vertices connected to it, continuing until all vertices have been marked and identi&#64257; ed. Imple- mentations of the instance methods connected(), id(), and count() are immediate.</p><p attribs="{'xml:space': 'preserve'}" id="_09457" smilref="Title.smil#_09457" /><pagenum id="p558" page="normal" smilref="Title.smil#p558" /><p attribs="{'xml:space': 'preserve'}" id="_09458" smilref="Title.smil#_09458"> tinyG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09459" smilref="Title.smil#_09459"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09460" smilref="Title.smil#_09460"> 545</p><p attribs="{'xml:space': 'preserve'}" id="_09461" smilref="Title.smil#_09461"> count marked[] id[]</p><p attribs="{'xml:space': 'preserve'}" id="_09462" smilref="Title.smil#_09462"> 0 1 2 3 4 5 6 7 8 9 10 11 12 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09463" smilref="Title.smil#_09463"> dfs(0) 0 T 0 dfs(6) 0 T T 0 0 check 0 dfs(4) 0 T T T 0 0 0 dfs(5) 0 T T T T 0 0 0 0 dfs(3) 0 T T T T T 0 0 0 0 0 check 5 check 4 3 done check 4 check 0 5 done check 6 check 3 4 done 6 done dfs(2) 0 T T T T T T 0 0 0 0 0 0 check 0 2 done dfs(1) 0 T T T T T T T 0 0 0 0 0 0 0 check 0 1 done check 5 0 done dfs(7) 1 T T T T T T T T 0 0 0 0 0 0 0 1 dfs(8) 1 T T T T T T T T T 0 0 0 0 0 0 0 1 1 check 7 8 done 7 done dfs(9) 2 T T T T T T T T T T 0 0 0 0 0 0 0 1 1 2 dfs(11) 2 T T T T T T T T T T T 0 0 0 0 0 0 0 1 1 2 2 check 9 dfs(12) 2 T T T T T T T T T T T T 0 0 0 0 0 0 0 1 1 2 2 2 check 11 check 9 12 done 11 done dfs(10) 2 T T T T T T T T T T T T T 0 0 0 0 0 0 0 1 1 2 2 2 2 check 9 10 done check 12 9 done</p><p attribs="{'xml:space': 'preserve'}" id="_09464" smilref="Title.smil#_09464"> Trace of depth-first search to find connected components</p><p attribs="{'xml:space': 'preserve'}" id="_09465" smilref="Title.smil#_09465" /><pagenum id="p559" page="normal" smilref="Title.smil#p559" /><p attribs="{'xml:space': 'preserve'}" id="_09466" smilref="Title.smil#_09466"> 546</p><p attribs="{'xml:space': 'preserve'}" id="_09467" smilref="Title.smil#_09467"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09468" smilref="Title.smil#_09468"> in each component. This array makes the implementation of connected() simple, in precisely the same manner as connected() in Section 1.5 (just check if identifiers are equal). In this case, the identifier 0 is assigned to all the vertices in the first component processed, 1 is assigned to all the vertices in the second component processed, and so forth, so that the identifiers are all between 0 and count()-1, as specified in the API. This convention enables the use of component-indexed arrays, as in the test client on page 543.</p><p attribs="{'xml:space': 'preserve'}" id="_09469" smilref="Title.smil#_09469"> Proposition C. DFS uses preprocessing time and space proportional to V&#11001;E to support constant-time connectivity queries in a graph.</p><p attribs="{'xml:space': 'preserve'}" id="_09470" smilref="Title.smil#_09470"> Proof : Immediate from the code. Each adjacency-list entry is examined exactly once, and there are 2E such entries (two for each edge). Instance methods examine or return one or two instance variables.</p><p attribs="{'xml:space': 'preserve'}" id="_09471" smilref="Title.smil#_09471"> Union-&#64257; nd. How does the DFS-based solution for graph connectivity in CC compare with the union-&#64257; nd approach of Chapter 1? In theory, DFS is faster than union-&#64257; nd because it provides a constant-time guarantee, which union-&#64257; nd does not; in practice, this difference is negligible, and union-&#64257; nd is faster because it does not have to build a full representation of the graph. More important, union-&#64257; nd is an online algorithm (we can check whether two vertices are connected in near-constant time at any point, even while adding edges), whereas the DFS solution must first preprocess the graph. Therefore, for example, we prefer union-&#64257; nd when determining connectivity is our only task or when we have a large number of queries intermixed with edge insertions but may find the DFS solution more appropriate for use in a graph ADT because it makes efficient use of existing infrastructure.</p><p attribs="{'xml:space': 'preserve'}" id="_09472" smilref="Title.smil#_09472"> The problems that we have solved with DFS are fundamental. It is a simple ap- proach, and recursion provides us a way to reason about the computation and develop compact solutions to graph-processing problems. Two additional examples, for solving the following problems, are given in the table on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_09473" smilref="Title.smil#_09473"> Cycle detection. Support this query : Is a given graph acylic ?</p><p attribs="{'xml:space': 'preserve'}" id="_09474" smilref="Title.smil#_09474"> Two-colorability. Support this query : Can the vertices of a given graph be assigned one of two colors in such a way that no edge connects vertices of the same color ? which is equivalent to this question: Is the graph bipartite ? As usual with DFS, the simple code masks a more sophisticated computation, so studying these examples, tracing their behavior on small sample graphs, and extending them to provide a cycle or a coloring, respectively, are worthwhile (and left for exercises).</p><p attribs="{'xml:space': 'preserve'}" id="_09475" smilref="Title.smil#_09475" /><pagenum id="p560" page="normal" smilref="Title.smil#p560" /><p attribs="{'xml:space': 'preserve'}" id="_09476" smilref="Title.smil#_09476"> task</p><p attribs="{'xml:space': 'preserve'}" id="_09477" smilref="Title.smil#_09477"> implementation</p><p attribs="{'xml:space': 'preserve'}" id="_09478" smilref="Title.smil#_09478"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09479" smilref="Title.smil#_09479"> 547</p><p attribs="{'xml:space': 'preserve'}" id="_09480" smilref="Title.smil#_09480"> is G acyclic? (assumes no self-loops or parallel edges)</p><p attribs="{'xml:space': 'preserve'}" id="_09481" smilref="Title.smil#_09481"> public class Cycle { private boolean[] marked; private boolean hasCycle;</p><p attribs="{'xml:space': 'preserve'}" id="_09482" smilref="Title.smil#_09482"> public Cycle(Graph G) { marked = new boolean[G.V()]; for (int s = 0; s &lt; G.V(); s++) if (!marked[s]) dfs(G, s, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09483" smilref="Title.smil#_09483"> private void dfs(Graph G, int v, int u) { marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w, v); else if (w != u) hasCycle = true; }</p><p attribs="{'xml:space': 'preserve'}" id="_09484" smilref="Title.smil#_09484"> public boolean hasCycle() { return hasCycle; } }</p><p attribs="{'xml:space': 'preserve'}" id="_09485" smilref="Title.smil#_09485"> public class TwoColor { private boolean[] marked; private boolean[] color; private boolean isTwoColorable = true;</p><p attribs="{'xml:space': 'preserve'}" id="_09486" smilref="Title.smil#_09486"> public TwoColor(Graph G) { marked = new boolean[G.V()]; color = new boolean[G.V()]; for (int s = 0; s &lt; G.V(); s++) if (!marked[s]) dfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09487" smilref="Title.smil#_09487"> is G bipartite? (two-colorable)</p><p attribs="{'xml:space': 'preserve'}" id="_09488" smilref="Title.smil#_09488"> private void dfs(Graph G, int v) { marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) { color[w] = !color[v]; dfs(G, w); } else if (color[w] == color[v]) isTwoColorable = false; }</p><p attribs="{'xml:space': 'preserve'}" id="_09489" smilref="Title.smil#_09489"> public boolean isBipartite() { return isTwoColorable; }</p><p attribs="{'xml:space': 'preserve'}" id="_09490" smilref="Title.smil#_09490"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09491" smilref="Title.smil#_09491"> More examples of graph processing with DFS</p><p attribs="{'xml:space': 'preserve'}" id="_09492" smilref="Title.smil#_09492" /><pagenum id="p561" page="normal" smilref="Title.smil#p561" /><p attribs="{'xml:space': 'preserve'}" id="_09493" smilref="Title.smil#_09493"> 548</p><p attribs="{'xml:space': 'preserve'}" id="_09494" smilref="Title.smil#_09494"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09495" smilref="Title.smil#_09495"> Symbol graphs Typical applications involve processing graphs defined in files or on web pages, using strings, not integer indices, to define and refer to vertices. To accommodate such applications, we define an input format with the following properties: </p><p attribs="{'xml:space': 'preserve'}" id="_09496" smilref="Title.smil#_09496"> V and E no t exp l i c i t ly sp e c i f i ed</p><p attribs="{'xml:space': 'preserve'}" id="_09497" smilref="Title.smil#_09497"> LAX</p><p attribs="{'xml:space': 'preserve'}" id="_09498" smilref="Title.smil#_09498"> JFK</p><p attribs="{'xml:space': 'preserve'}" id="_09499" smilref="Title.smil#_09499"> PHX</p><p attribs="{'xml:space': 'preserve'}" id="_09500" smilref="Title.smil#_09500"> DFW</p><p attribs="{'xml:space': 'preserve'}" id="_09501" smilref="Title.smil#_09501"> ATL</p><p attribs="{'xml:space': 'preserve'}" id="_09502" smilref="Title.smil#_09502"> HOU</p><p attribs="{'xml:space': 'preserve'}" id="_09503" smilref="Title.smil#_09503"> MCO</p><p attribs="{'xml:space': 'preserve'}" id="_09504" smilref="Title.smil#_09504"> ORD</p><p attribs="{'xml:space': 'preserve'}" id="_09505" smilref="Title.smil#_09505"> DEN</p><p attribs="{'xml:space': 'preserve'}" id="_09506" smilref="Title.smil#_09506"> API. The following API defines a Graph client that allows us to immediately use our graph-processing routines for graphs defined by such fi les:</p><p attribs="{'xml:space': 'preserve'}" id="_09507" smilref="Title.smil#_09507"> routes.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09508" smilref="Title.smil#_09508"> JFK MCO ORD DEN ORD HOU DFW PHX JFK ATL ORD DFW ORD PHX ATL HOU DEN PHX PHX LAX JFK ORD DEN LAS DFW HOU ORD ATL LAS LAX ATL MCO HOU MCO LAS PHX</p><p attribs="{'xml:space': 'preserve'}" id="_09509" smilref="Title.smil#_09509"> LAS</p><p attribs="{'xml:space': 'preserve'}" id="_09510" smilref="Title.smil#_09510"> " " d e l im i t e r</p><p attribs="{'xml:space': 'preserve'}" id="_09511" smilref="Title.smil#_09511"> Symbol graph example (list of edges)</p><p attribs="{'xml:space': 'preserve'}" id="_09512" smilref="Title.smil#_09512"> public class SymbolGraph</p><p attribs="{'xml:space': 'preserve'}" id="_09513" smilref="Title.smil#_09513"> SymbolGraph(String filename, String delim)</p><p attribs="{'xml:space': 'preserve'}" id="_09514" smilref="Title.smil#_09514"> boolean contains(String key) int index(String key) String name(int v) Graph G()</p><p attribs="{'xml:space': 'preserve'}" id="_09515" smilref="Title.smil#_09515"> build graph specified  in</p><p attribs="{'xml:space': 'preserve'}" id="_09516" smilref="Title.smil#_09516"> filename using delim to</p><p attribs="{'xml:space': 'preserve'}" id="_09517" smilref="Title.smil#_09517"> separate vertex names is key a vertex? index associated with key key associated with index v underlying Graph</p><p attribs="{'xml:space': 'preserve'}" id="_09518" smilref="Title.smil#_09518"> API for graphs with symbolic vertex names</p><p attribs="{'xml:space': 'preserve'}" id="_09519" smilref="Title.smil#_09519" /><pagenum id="p562" page="normal" smilref="Title.smil#p562" /><p attribs="{'xml:space': 'preserve'}" id="_09520" smilref="Title.smil#_09520"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09521" smilref="Title.smil#_09521"> 549</p><p attribs="{'xml:space': 'preserve'}" id="_09522" smilref="Title.smil#_09522"> Caligola</p><p attribs="{'xml:space': 'preserve'}" id="_09523" smilref="Title.smil#_09523"> Patrick Allen</p><p attribs="{'xml:space': 'preserve'}" id="_09524" smilref="Title.smil#_09524"> Dial M for Murder</p><p attribs="{'xml:space': 'preserve'}" id="_09525" smilref="Title.smil#_09525"> Grace Kelly</p><p attribs="{'xml:space': 'preserve'}" id="_09526" smilref="Title.smil#_09526"> Glenn Close</p><p attribs="{'xml:space': 'preserve'}" id="_09527" smilref="Title.smil#_09527"> The Stepford Wives</p><p attribs="{'xml:space': 'preserve'}" id="_09528" smilref="Title.smil#_09528"> Nicole Kidman</p><p attribs="{'xml:space': 'preserve'}" id="_09529" smilref="Title.smil#_09529"> The Eagle Has Landed</p><p attribs="{'xml:space': 'preserve'}" id="_09530" smilref="Title.smil#_09530"> To Catch a Thief</p><p attribs="{'xml:space': 'preserve'}" id="_09531" smilref="Title.smil#_09531"> High Noon</p><p attribs="{'xml:space': 'preserve'}" id="_09532" smilref="Title.smil#_09532"> Lloyd Bridges</p><p attribs="{'xml:space': 'preserve'}" id="_09533" smilref="Title.smil#_09533"> John Gielgud</p><p attribs="{'xml:space': 'preserve'}" id="_09534" smilref="Title.smil#_09534"> Portrait of a Lady</p><p attribs="{'xml:space': 'preserve'}" id="_09535" smilref="Title.smil#_09535"> Murder on the Orient Express</p><p attribs="{'xml:space': 'preserve'}" id="_09536" smilref="Title.smil#_09536"> Cold Mountain</p><p attribs="{'xml:space': 'preserve'}" id="_09537" smilref="Title.smil#_09537"> Donald Sutherland</p><p attribs="{'xml:space': 'preserve'}" id="_09538" smilref="Title.smil#_09538"> Kathleen Quinlan</p><p attribs="{'xml:space': 'preserve'}" id="_09539" smilref="Title.smil#_09539"> Joe Versus the Volcano</p><p attribs="{'xml:space': 'preserve'}" id="_09540" smilref="Title.smil#_09540"> An American Haunting</p><p attribs="{'xml:space': 'preserve'}" id="_09541" smilref="Title.smil#_09541"> John Belushi</p><p attribs="{'xml:space': 'preserve'}" id="_09542" smilref="Title.smil#_09542"> Animal House</p><p attribs="{'xml:space': 'preserve'}" id="_09543" smilref="Title.smil#_09543"> The Woodsman</p><p attribs="{'xml:space': 'preserve'}" id="_09544" smilref="Title.smil#_09544"> Wild Things</p><p attribs="{'xml:space': 'preserve'}" id="_09545" smilref="Title.smil#_09545"> Kevin Bacon</p><p attribs="{'xml:space': 'preserve'}" id="_09546" smilref="Title.smil#_09546"> The River Wild</p><p attribs="{'xml:space': 'preserve'}" id="_09547" smilref="Title.smil#_09547"> Meryl Streep</p><p attribs="{'xml:space': 'preserve'}" id="_09548" smilref="Title.smil#_09548"> performer vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09549" smilref="Title.smil#_09549"> Apollo 13</p><p attribs="{'xml:space': 'preserve'}" id="_09550" smilref="Title.smil#_09550"> Bill Paxton</p><p attribs="{'xml:space': 'preserve'}" id="_09551" smilref="Title.smil#_09551"> Tom Hanks</p><p attribs="{'xml:space': 'preserve'}" id="_09552" smilref="Title.smil#_09552"> Paul Herbert</p><p attribs="{'xml:space': 'preserve'}" id="_09553" smilref="Title.smil#_09553"> The Da Vinci Code</p><p attribs="{'xml:space': 'preserve'}" id="_09554" smilref="Title.smil#_09554"> Serretta Wilson</p><p attribs="{'xml:space': 'preserve'}" id="_09555" smilref="Title.smil#_09555"> Titanic</p><p attribs="{'xml:space': 'preserve'}" id="_09556" smilref="Title.smil#_09556"> Yves Aubert</p><p attribs="{'xml:space': 'preserve'}" id="_09557" smilref="Title.smil#_09557"> Shane Zaza</p><p attribs="{'xml:space': 'preserve'}" id="_09558" smilref="Title.smil#_09558"> Vernon Dobtcheff</p><p attribs="{'xml:space': 'preserve'}" id="_09559" smilref="Title.smil#_09559"> Hamlet</p><p attribs="{'xml:space': 'preserve'}" id="_09560" smilref="Title.smil#_09560"> movie vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09561" smilref="Title.smil#_09561"> Enigma</p><p attribs="{'xml:space': 'preserve'}" id="_09562" smilref="Title.smil#_09562"> Eternal Sunshine of the Spotless Mind</p><p attribs="{'xml:space': 'preserve'}" id="_09563" smilref="Title.smil#_09563"> movies.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09564" smilref="Title.smil#_09564"> Jude</p><p attribs="{'xml:space': 'preserve'}" id="_09565" smilref="Title.smil#_09565"> Kate Winslet</p><p attribs="{'xml:space': 'preserve'}" id="_09566" smilref="Title.smil#_09566"> V and E no t exp l i c i t ly sp e c i f i ed</p><p attribs="{'xml:space': 'preserve'}" id="_09567" smilref="Title.smil#_09567"> ... Tin Men (1987)/DeBoy, David/Blumenfeld, Alan/... /Geppi, Cindy/Hershey, Barbara... Tirez sur le pianiste (1960)/Heymann, Claude/.../Berger, Nicole (I)... Titanic (1997)/Mazin, Stan/...DiCaprio, Leonardo/.../Winslet, Kate/... Titus (1999)/Weisskopf, Hermann/Rhys, Matthew/.../McEwan, Geraldine To Be or Not to Be (1942)/Verebes, Ern&#246; (I)/.../Lombard, Carole (I)... To Be or Not to Be (1983)/.../Brooks, Mel (I)/.../Bancroft, Anne/... To Catch a Thief (1955)/Par&#237;s, Manuel/.../Grant, Cary/.../Kelly, Grace/... To Die For (1995)/Smith, Kurtwood/.../Kidman, Nicole/.../ Tucci, Maria... ...</p><p attribs="{'xml:space': 'preserve'}" id="_09568" smilref="Title.smil#_09568"> " /" d e l im i t e r</p><p attribs="{'xml:space': 'preserve'}" id="_09569" smilref="Title.smil#_09569"> mov i e</p><p attribs="{'xml:space': 'preserve'}" id="_09570" smilref="Title.smil#_09570"> p e r fo rm e r s</p><p attribs="{'xml:space': 'preserve'}" id="_09571" smilref="Title.smil#_09571"> Symbol graph example (adjacency lists)</p><p attribs="{'xml:space': 'preserve'}" id="_09572" smilref="Title.smil#_09572" /><pagenum id="p563" page="normal" smilref="Title.smil#p563" /><p attribs="{'xml:space': 'preserve'}" id="_09573" smilref="Title.smil#_09573"> 550</p><p attribs="{'xml:space': 'preserve'}" id="_09574" smilref="Title.smil#_09574"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09575" smilref="Title.smil#_09575"> public static void main(String[] args) { String filename = args[0]; String delim = args[1]; SymbolGraph sg = new SymbolGraph(filename, delim);</p><p attribs="{'xml:space': 'preserve'}" id="_09576" smilref="Title.smil#_09576"> Graph G = sg.G();</p><p attribs="{'xml:space': 'preserve'}" id="_09577" smilref="Title.smil#_09577"> while (StdIn.hasNextLine()) { String source = StdIn.readLine(); for (int v : G.adj(sg.index(source))) StdOut.println(" " + sg.name(v)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_09578" smilref="Title.smil#_09578"> Test client for symbol graph API</p><p attribs="{'xml:space': 'preserve'}" id="_09579" smilref="Title.smil#_09579"> % java SymbolGraph routes.txt " " JFK ORD ATL MCO LAX LAS PHX</p><p attribs="{'xml:space': 'preserve'}" id="_09580" smilref="Title.smil#_09580"> % java SymbolGraph movies.txt "/" Tin Men (1987) Hershey, Barbara Geppi, Cindy ... Blumenfeld, Alan DeBoy, David Bacon, Kevin Woodsman, The (2004) Wild Things (1998) ... Apollo 13 (1995) Animal House (1978)</p><p attribs="{'xml:space': 'preserve'}" id="_09581" smilref="Title.smil#_09581"> This API provides a constructor to read and build the graph and client methods name() and index() for translating vertex names between the strings on the input stream and the integer indices used by our graph- processing methods.</p><p attribs="{'xml:space': 'preserve'}" id="_09582" smilref="Title.smil#_09582"> Test client. The test client at left builds a graph from the file named as the first com- mand-line argument (using the delimiter as specified by the second command-line ar- gument) and then takes queries from standard input. The user specifies a vertex name and gets the list of vertices adjacent to that vertex. This client immediately provides the useful inverted index functionality that we considered in Section 3.5. In the case of routes.txt, you can type an airport code to find the direct flights from that airport, information that is not directly available in the data fi le. In the case of movies.txt, you can type the name of a performer to see the list of the movies in the database in which that performer appeared, or you can type the name of a movie to see the list of performers that appear in that movie. Typing a movie name and getting its cast is not much more than regurgitating the corresponding line in the input fi le, but typing the name of a performer and getting the list of movies in which that performer has appeared is inverting the index. Even though the database is built around connecting movies to performers, the bipartite graph model embraces the idea that it also connects performers to movies. The bipartite graph model automatically serves as an inverted index and also provides the basis for more sophisticated processing, as we will see.</p><p attribs="{'xml:space': 'preserve'}" id="_09583" smilref="Title.smil#_09583" /><pagenum id="p564" page="normal" smilref="Title.smil#p564" /><p attribs="{'xml:space': 'preserve'}" id="_09584" smilref="Title.smil#_09584"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09585" smilref="Title.smil#_09585"> 551</p><p attribs="{'xml:space': 'preserve'}" id="_09586" smilref="Title.smil#_09586"> This approach is clearly effective for any of the graph-processing methods that we consider: any client can use index() when it wants to convert a vertex name to an index for use in graph processing and name() when it wants to convert an index from graph processing into a name for use in the context of the application.</p><p attribs="{'xml:space': 'preserve'}" id="_09587" smilref="Title.smil#_09587"> Implementation. A full SymbolGraph implementation is given on page 552. It builds three data structures: </p><p attribs="{'xml:space': 'preserve'}" id="_09588" smilref="Title.smil#_09588"> symbol  tab le</p><p attribs="{'xml:space': 'preserve'}" id="_09589" smilref="Title.smil#_09589"> inve r ted index</p><p attribs="{'xml:space': 'preserve'}" id="_09590" smilref="Title.smil#_09590"> und i rec ted g raph</p><p attribs="{'xml:space': 'preserve'}" id="_09591" smilref="Title.smil#_09591"> ST&lt;String, Integer&gt; st</p><p attribs="{'xml:space': 'preserve'}" id="_09592" smilref="Title.smil#_09592"> String[] keys</p><p attribs="{'xml:space': 'preserve'}" id="_09593" smilref="Title.smil#_09593"> Graph G</p><p attribs="{'xml:space': 'preserve'}" id="_09594" smilref="Title.smil#_09594"> 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_09595" smilref="Title.smil#_09595"> JFK MCO ORD DEN HOU DFW PHX ATL LAX LAS</p><p attribs="{'xml:space': 'preserve'}" id="_09596" smilref="Title.smil#_09596"> JFK</p><p attribs="{'xml:space': 'preserve'}" id="_09597" smilref="Title.smil#_09597"> MCO</p><p attribs="{'xml:space': 'preserve'}" id="_09598" smilref="Title.smil#_09598"> ORD</p><p attribs="{'xml:space': 'preserve'}" id="_09599" smilref="Title.smil#_09599"> DEN</p><p attribs="{'xml:space': 'preserve'}" id="_09600" smilref="Title.smil#_09600"> HOU</p><p attribs="{'xml:space': 'preserve'}" id="_09601" smilref="Title.smil#_09601"> DFW</p><p attribs="{'xml:space': 'preserve'}" id="_09602" smilref="Title.smil#_09602"> PHX</p><p attribs="{'xml:space': 'preserve'}" id="_09603" smilref="Title.smil#_09603"> ATL</p><p attribs="{'xml:space': 'preserve'}" id="_09604" smilref="Title.smil#_09604"> LAX</p><p attribs="{'xml:space': 'preserve'}" id="_09605" smilref="Title.smil#_09605"> LAS</p><p attribs="{'xml:space': 'preserve'}" id="_09606" smilref="Title.smil#_09606"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09607" smilref="Title.smil#_09607"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09608" smilref="Title.smil#_09608"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09609" smilref="Title.smil#_09609"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09610" smilref="Title.smil#_09610"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09611" smilref="Title.smil#_09611"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09612" smilref="Title.smil#_09612"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09613" smilref="Title.smil#_09613"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09614" smilref="Title.smil#_09614"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_09615" smilref="Title.smil#_09615"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09616" smilref="Title.smil#_09616"> key </p><p attribs="{'xml:space': 'preserve'}" id="_09617" smilref="Title.smil#_09617"> va lu e</p><p attribs="{'xml:space': 'preserve'}" id="_09618" smilref="Title.smil#_09618"> ORD</p><p attribs="{'xml:space': 'preserve'}" id="_09619" smilref="Title.smil#_09619"> JFK</p><p attribs="{'xml:space': 'preserve'}" id="_09620" smilref="Title.smil#_09620"> DEN</p><p attribs="{'xml:space': 'preserve'}" id="_09621" smilref="Title.smil#_09621"> LAS</p><p attribs="{'xml:space': 'preserve'}" id="_09622" smilref="Title.smil#_09622"> LAX</p><p attribs="{'xml:space': 'preserve'}" id="_09623" smilref="Title.smil#_09623"> PHX</p><p attribs="{'xml:space': 'preserve'}" id="_09624" smilref="Title.smil#_09624"> DFW</p><p attribs="{'xml:space': 'preserve'}" id="_09625" smilref="Title.smil#_09625"> ATL</p><p attribs="{'xml:space': 'preserve'}" id="_09626" smilref="Title.smil#_09626"> HOU</p><p attribs="{'xml:space': 'preserve'}" id="_09627" smilref="Title.smil#_09627"> MCO</p><p attribs="{'xml:space': 'preserve'}" id="_09628" smilref="Title.smil#_09628"> int V 10</p><p attribs="{'xml:space': 'preserve'}" id="_09629" smilref="Title.smil#_09629"> Bag[] adj</p><p attribs="{'xml:space': 'preserve'}" id="_09630" smilref="Title.smil#_09630"> 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_09631" smilref="Title.smil#_09631"> Symbol graph data structures</p><p attribs="{'xml:space': 'preserve'}" id="_09632" smilref="Title.smil#_09632"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09633" smilref="Title.smil#_09633"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09634" smilref="Title.smil#_09634"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09635" smilref="Title.smil#_09635"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09636" smilref="Title.smil#_09636"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09637" smilref="Title.smil#_09637"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09638" smilref="Title.smil#_09638"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09639" smilref="Title.smil#_09639"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09640" smilref="Title.smil#_09640"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09641" smilref="Title.smil#_09641"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09642" smilref="Title.smil#_09642"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09643" smilref="Title.smil#_09643"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09644" smilref="Title.smil#_09644"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09645" smilref="Title.smil#_09645"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09646" smilref="Title.smil#_09646"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09647" smilref="Title.smil#_09647"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09648" smilref="Title.smil#_09648"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_09649" smilref="Title.smil#_09649"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09650" smilref="Title.smil#_09650"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09651" smilref="Title.smil#_09651"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_09652" smilref="Title.smil#_09652"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09653" smilref="Title.smil#_09653"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09654" smilref="Title.smil#_09654"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09655" smilref="Title.smil#_09655"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09656" smilref="Title.smil#_09656"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_09657" smilref="Title.smil#_09657"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09658" smilref="Title.smil#_09658"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09659" smilref="Title.smil#_09659"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09660" smilref="Title.smil#_09660"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09661" smilref="Title.smil#_09661"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09662" smilref="Title.smil#_09662"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09663" smilref="Title.smil#_09663"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09664" smilref="Title.smil#_09664"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09665" smilref="Title.smil#_09665"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09666" smilref="Title.smil#_09666"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09667" smilref="Title.smil#_09667"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09668" smilref="Title.smil#_09668" /><pagenum id="p565" page="normal" smilref="Title.smil#p565" /><p attribs="{'xml:space': 'preserve'}" id="_09669" smilref="Title.smil#_09669"> 552</p><p attribs="{'xml:space': 'preserve'}" id="_09670" smilref="Title.smil#_09670"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09671" smilref="Title.smil#_09671"> Symbol graph data type</p><p attribs="{'xml:space': 'preserve'}" id="_09672" smilref="Title.smil#_09672"> public class SymbolGraph { private ST&lt;String, Integer&gt; st; // String -&gt; index private String[] keys; // index -&gt; String private Graph G; // the graph</p><p attribs="{'xml:space': 'preserve'}" id="_09673" smilref="Title.smil#_09673"> public SymbolGraph(String stream, String sp) { st = new ST&lt;String, Integer&gt;(); In in = new In(stream); // First pass while (in.hasNextLine()) // builds the index { String[] a = in.readLine().split(sp); // by reading strings for (int i = 0; i &lt; a.length; i++) // to associate each if (!st.contains(a[i])) // distinct string st.put(a[i], st.size()); // with an index. } keys = new String[st.size()]; // Inverted index for (String name : st.keys()) // to get string keys keys[st.get(name)] = name; // is an array.</p><p attribs="{'xml:space': 'preserve'}" id="_09674" smilref="Title.smil#_09674"> G = new Graph(st.size()); in = new In(stream); // Second pass while (in.hasNextLine()) // builds the graph { String[] a = in.readLine().split(sp); // by connecting the int v = st.get(a[0]); // first vertex for (int i = 1; i &lt; a.length; i++) // on each line G.addEdge(v, st.get(a[i])); // to all the others. } }</p><p attribs="{'xml:space': 'preserve'}" id="_09675" smilref="Title.smil#_09675"> public boolean contains(String s) { return st.contains(s); } public int index(String s) { return st.get(s); } public String name(int v) { return keys[v]; } public Graph G() { return G; } }</p><p attribs="{'xml:space': 'preserve'}" id="_09676" smilref="Title.smil#_09676"> This Graph client allows clients to define graphs with String vertex names instead of integer indices. It maintains instance variables st (a symbol table that maps names to indices), keys (an array that maps indices to names), and G (a graph, with integer vertex names). To build these data structures, it makes two passes through the graph definition (each line has a string and a list of adjacent strings, separated by the delimiter sp).</p><p attribs="{'xml:space': 'preserve'}" id="_09677" smilref="Title.smil#_09677" /></level3><level3 id="_00073"><h3 id="ch4-s1-ss7" smilref="Title.smil#ch4-s1-ss7" xml:space="preserve">Degrees of separation</h3><pagenum id="p566" page="normal" smilref="Title.smil#p566" /><p attribs="{'xml:space': 'preserve'}" id="_09678" smilref="Title.smil#_09678"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09679" smilref="Title.smil#_09679"> 553</p><p attribs="{'xml:space': 'preserve'}" id="_09680" smilref="Title.smil#_09680"> Degrees of separation. One of the classic applications of graph processing is to find the degree of separation between two individuals in a social network. To fix ideas, we discuss this application in terms of a recently popularized pastime known as the Kevin Bacon game, which uses the movie-performer graph that we just considered. Kevin Ba- con is a prolific actor who has appeared in many movies. We assign every performer a Kevin Bacon number as follows: Bacon himself is 0, any performer who has been in the same cast as Bacon has a Kevin Bacon number of 1, any other performer (except Bacon) who has been in the same cast as a performer whose number is 1 has a Kevin Bacon number of 2, and so forth. For example, Meryl Streep has a Kevin Bacon number of 1 because she appeared in The River Wild with Kevin Bacon. Nicole Kidman&#8217;s number is 2: although she did not appear in any movie with Kevin Bacon, she was in Days of Thun- der with Tom Cruise, and Cruise appeared in A Few Good Men with Kevin Bacon. Given the name of a performer, the simplest version of the game is to find some alternating sequence of movies and performers that leads back to Kevin Bacon. For example, a movie buff might know that Tom Hanks was in Joe Versus the Volcano with Lloyd Bridges, who was in High Noon with Grace Kelly, who was in Dial M for Murder with Patrick Allen, who was in The Eagle Has Landed with Donald Sutherland, who was in Animal House with Kevin Bacon. But this knowledge does not suffice to establish Tom Hanks&#8217;s Bacon number (it is actually 1 because he was in Apollo 13 with Kevin Bacon). You can see that the Kevin Bacon number has to be defined by counting the movies in the shortest such sequence, so it is hard to be sure whether someone wins the game without using a computer. Of course, as illustrated in</p><p attribs="{'xml:space': 'preserve'}" id="_09681" smilref="Title.smil#_09681"> % java DegreesOfSeparation movies.txt "/" "Bacon, Kevin" Kidman, Nicole Bacon, Kevin Woodsman, The (2004) Grier, David Alan Bewitched (2005) Kidman, Nicole Grant, Cary Bacon, Kevin Planes, Trains &amp; Automobiles (1987) Martin, Steve (I) Dead Men Don&#8217;t Wear Plaid (1982) Grant, Cary</p><p attribs="{'xml:space': 'preserve'}" id="_09682" smilref="Title.smil#_09682"> the SymbolGraph client DegreesOfSeparation on page 555, BreadthFirstPaths is the</p><p attribs="{'xml:space': 'preserve'}" id="_09683" smilref="Title.smil#_09683"> program we need to find a shortest path that establishes the Kevin Bacon number of any performer in movies.txt. This program takes a source vertex from the command line, then takes queries from standard input and prints a shortest path from the source to the query vertex. Since the graph associated with movies.txt is bipartite, all paths alternate between movies and performers, and the printed path is a &#8220;proof &#8221; that the path is valid (but not a proof that it is the shortest such path&#8212;you need to educate your</p><p attribs="{'xml:space': 'preserve'}" id="_09684" smilref="Title.smil#_09684" /><pagenum id="p567" page="normal" smilref="Title.smil#p567" /><p attribs="{'xml:space': 'preserve'}" id="_09685" smilref="Title.smil#_09685"> 554</p><p attribs="{'xml:space': 'preserve'}" id="_09686" smilref="Title.smil#_09686"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09687" smilref="Title.smil#_09687"> friends about Proposition B for that). DegreesOfSeparation also finds shortest paths in graphs that are not bipartite: for example, it finds a way to get from one airport to another in routes.txt using the fewest connections.</p><p attribs="{'xml:space': 'preserve'}" id="_09688" smilref="Title.smil#_09688"> You might enjoy using DegreesOfSeparation to answer some entertaining questions about the movie business. For example, you can find separations between mov- ies, not just performers. More important, the concept of separation has been widely studied in many other contexts. For example, mathematicians play this same game with the graph defined by paper co-authorship and their connection to P. Erd&#246;s, a prolific 20th-century mathematician. Similarly, everyone in New Jersey seems to have a Bruce Springsteen number of 2, because everyone in the state seems to know someone who claims to know Bruce. To play the Erd&#246;s game, you would need a database of all mathematical papers; playing the Springsteen game is a bit more challenging. On a more serious note, degrees of separation play a crucial role in the design of computer and communications networks, and in our understanding of natural networks in all fields of science.</p><p attribs="{'xml:space': 'preserve'}" id="_09689" smilref="Title.smil#_09689"> % java DegreesOfSeparation movies.txt "/" "Animal House (1978)" Titanic (1997) Animal House (1978) Allen, Karen (I) Raiders of the Lost Ark (1981) Taylor, Rocky (I) Titanic (1997) To Catch a Thief (1955) Animal House (1978) Vernon, John (I) Topaz (1969) Hitchcock, Alfred (I) To Catch a Thief (1955)</p><p attribs="{'xml:space': 'preserve'}" id="_09690" smilref="Title.smil#_09690" /><pagenum id="p568" page="normal" smilref="Title.smil#p568" /><p attribs="{'xml:space': 'preserve'}" id="_09691" smilref="Title.smil#_09691"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09692" smilref="Title.smil#_09692"> 555</p><p attribs="{'xml:space': 'preserve'}" id="_09693" smilref="Title.smil#_09693"> Degrees of separation</p><p attribs="{'xml:space': 'preserve'}" id="_09694" smilref="Title.smil#_09694"> public class DegreesOfSeparation { public static void main(String[] args) { SymbolGraph sg = new SymbolGraph(args[0], args[1]);</p><p attribs="{'xml:space': 'preserve'}" id="_09695" smilref="Title.smil#_09695"> Graph G = sg.G();</p><p attribs="{'xml:space': 'preserve'}" id="_09696" smilref="Title.smil#_09696"> String source = args[2]; if (!sg.contains(source)) { StdOut.println(source + " not in database."); return; }</p><p attribs="{'xml:space': 'preserve'}" id="_09697" smilref="Title.smil#_09697"> int s = sg.index(source); BreadthFirstPaths bfs = new BreadthFirstPaths(G, s);</p><p attribs="{'xml:space': 'preserve'}" id="_09698" smilref="Title.smil#_09698"> while (!StdIn.isEmpty()) { String sink = StdIn.readLine(); if (sg.contains(sink)) { int t = sg.index(sink); if (bfs.hasPathTo(t)) for (int v : bfs.pathTo(t)) StdOut.println(" " + sg.name(v)); else StdOut.println("Not connected"); } else StdOut.println("Not in database."); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_09699" smilref="Title.smil#_09699"> This SymbolGraph and BreadthFirstPaths client finds shortest paths in graphs. For movies.txt, it plays the Kevin Bacon game.</p><p attribs="{'xml:space': 'preserve'}" id="_09700" smilref="Title.smil#_09700"> % java DegreesOfSeparation routes.txt " " JFK LAS JFK ORD PHX LAS DFW JFK ORD DFW</p><p attribs="{'xml:space': 'preserve'}" id="_09701" smilref="Title.smil#_09701" /><pagenum id="p569" page="normal" smilref="Title.smil#p569" /><p attribs="{'xml:space': 'preserve'}" id="_09702" smilref="Title.smil#_09702"> 556</p><p attribs="{'xml:space': 'preserve'}" id="_09703" smilref="Title.smil#_09703"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09704" smilref="Title.smil#_09704"> Summary</p><p attribs="{'xml:space': 'preserve'}" id="_09705" smilref="Title.smil#_09705"> In this section, we have introduced several basic concepts that we will expand upon and further develop throughout the rest of this chapter: </p><p attribs="{'xml:space': 'preserve'}" id="_09706" smilref="Title.smil#_09706"> problem</p><p attribs="{'xml:space': 'preserve'}" id="_09707" smilref="Title.smil#_09707"> solution</p><p attribs="{'xml:space': 'preserve'}" id="_09708" smilref="Title.smil#_09708"> single-source connectivity single-source paths single-source shortest paths connectivity cycle detection two-colorability (bipartiteness)</p><p attribs="{'xml:space': 'preserve'}" id="_09709" smilref="Title.smil#_09709"> DepthFirstSearch</p><p attribs="{'xml:space': 'preserve'}" id="_09710" smilref="Title.smil#_09710"> DepthFirstPaths</p><p attribs="{'xml:space': 'preserve'}" id="_09711" smilref="Title.smil#_09711"> BreadthFirstPaths</p><p attribs="{'xml:space': 'preserve'}" id="_09712" smilref="Title.smil#_09712"> CC</p><p attribs="{'xml:space': 'preserve'}" id="_09713" smilref="Title.smil#_09713"> Cycle</p><p attribs="{'xml:space': 'preserve'}" id="_09714" smilref="Title.smil#_09714"> TwoColor</p><p attribs="{'xml:space': 'preserve'}" id="_09715" smilref="Title.smil#_09715"> reference</p><p attribs="{'xml:space': 'preserve'}" id="_09716" smilref="Title.smil#_09716"> page 531</p><p attribs="{'xml:space': 'preserve'}" id="_09717" smilref="Title.smil#_09717"> page 536 page 540 page 544 page 547 page 547</p><p attribs="{'xml:space': 'preserve'}" id="_09718" smilref="Title.smil#_09718"> (Undirected) graph-processing problems addressed in this section</p><p attribs="{'xml:space': 'preserve'}" id="_09719" smilref="Title.smil#_09719" /><pagenum id="p570" page="normal" smilref="Title.smil#p570" /><p attribs="{'xml:space': 'preserve'}" id="_09720" smilref="Title.smil#_09720"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09721" smilref="Title.smil#_09721"> 557</p><p attribs="{'xml:space': 'preserve'}" id="_09722" smilref="Title.smil#_09722"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_09723" smilref="Title.smil#_09723"> Q. Why not jam all of the algorithms into Graph.java? A. Yes, we might just add query methods (and whatever private fields and methods each might need) to the basic Graph ADT defi nition. While this approach has some of the virtues of data abstraction that we have embraced, it also has some serious draw- backs, because the world of graph processing is significantly more expansive than the kinds of basic data structures treated in Section 1.3. Chief among these drawbacks are the following: </p><p attribs="{'xml:space': 'preserve'}" id="_09724" smilref="Title.smil#_09724"> Q. Does SymbolGraph really need two passes? A. No. You could pay an extra lg N factor and support adj() directly as an ST instead of a Bag. We have an implementation along these lines in our book An Introduction to Programming in Java: An Interdisciplinary Approach.</p><p attribs="{'xml:space': 'preserve'}" id="_09725" smilref="Title.smil#_09725" /><pagenum id="p571" page="normal" smilref="Title.smil#p571" /><p attribs="{'xml:space': 'preserve'}" id="_09726" smilref="Title.smil#_09726"> 558</p><p attribs="{'xml:space': 'preserve'}" id="_09727" smilref="Title.smil#_09727"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09728" smilref="Title.smil#_09728"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_09729" smilref="Title.smil#_09729"> 4.1.1 What is the maximum number of edges in a graph with V vertices and no parallel edges? What is the minimum number of edges in a graph with V vertices, none of which are isolated?</p><p attribs="{'xml:space': 'preserve'}" id="_09730" smilref="Title.smil#_09730"> tinyGex2.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09731" smilref="Title.smil#_09731"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09732" smilref="Title.smil#_09732"> 12 16 8 4 2 3 1 11 0 6 3 6 10 3 7 11 7 8 11 8 2 0 6 2 5 2 5 10 5 0 8 1 4 1</p><p attribs="{'xml:space': 'preserve'}" id="_09733" smilref="Title.smil#_09733"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09734" smilref="Title.smil#_09734"> 4.1.2 Draw, in the style of the figure in the text (page 524), the adjacency lists built by Graph&#8217;s input stream constructor for the file tinyGex2.txt depicted at left. 4.1.3 Create a copy constructor for Graph that takes as input a graph G and creates and initializes a new copy of the graph. Any changes a client makes to G should not affect the newly created graph. 4.1.4 Add a method hasEdge() to Graph which takes two int arguments v and w and returns true if the graph has an edge v-w, false otherwise. 4.1.5 Modify Graph to disallow parallel edges and self-loops. 4.1.6 Consider the four-vertex graph with edges 0-1, 1-2, 2-3, and 3-0. Draw an array of adjacency-lists that could not have been built calling addEdge() for these edges no matter what order. 4.1.7 Develop a test client for Graph that reads a graph from the input stream named as command-line argument and then prints it, relying on toString(). 4.1.8 Develop an implementation for the Search API on page 528 that uses UF, as described in the text. 4.1.9 Show, in the style of the figure on page 533, a detailed trace of the call dfs(0) for the graph built by Graph&#8217;s input stream constructor for the file tinyGex2.txt (see Ex- ercise 4.1.2). Also, draw the tree represented by edgeTo[]. 4.1.10 Prove that every connected graph has a vertex whose removal (including all adjacent edges) will not disconnect the graph, and write a DFS method that finds such a vertex. Hint : Consider a vertex whose adjacent vertices are all marked. 4.1.11 Draw the tree represented by edgeTo[] after the call bfs(G, 0) in Algorithm 4.2 for the graph built by Graph&#8217;s input stream constructor for the file tinyGex2.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09735" smilref="Title.smil#_09735"> (see Exercise 4.1.2).</p><p attribs="{'xml:space': 'preserve'}" id="_09736" smilref="Title.smil#_09736" /><pagenum id="p572" page="normal" smilref="Title.smil#p572" /><p attribs="{'xml:space': 'preserve'}" id="_09737" smilref="Title.smil#_09737"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09738" smilref="Title.smil#_09738"> 559</p><p attribs="{'xml:space': 'preserve'}" id="_09739" smilref="Title.smil#_09739"> sam e l i s t s a s fo r l i s t of - edge  s input  bu t o rd e r w i th in l i s t s i s d i f f e ren t</p><p attribs="{'xml:space': 'preserve'}" id="_09740" smilref="Title.smil#_09740"> l i s t o rd e r i s re v e r s ed f rom input </p><p attribs="{'xml:space': 'preserve'}" id="_09741" smilref="Title.smil#_09741"> 4.1.12 What does the BFS tree tell us about the distance from v to w when neither is at the root?</p><p attribs="{'xml:space': 'preserve'}" id="_09742" smilref="Title.smil#_09742"> 4.1.13 Add</p><p attribs="{'xml:space': 'preserve'}" id="_09743" smilref="Title.smil#_09743"> tinyGadj.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09744" smilref="Title.smil#_09744"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09745" smilref="Title.smil#_09745"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09746" smilref="Title.smil#_09746"> 13 13 0 1 2 5 6 3 4 5 4 5 6 7 8 9 10 11 12 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09747" smilref="Title.smil#_09747"> a distTo() method to the BreadthFirstPaths API and implementation, which returns the number of edges on the shortest path from the source to a given vertex. A distTo() query should run in constant time. 4.1.14 Suppose you use a stack instead of a queue when running breadth-&#64257; rst search. Does it still compute shortest paths? 4.1.15 Modify the input stream constructor for Graph to also allow adjacency lists from standard input (in a manner similar to SymbolGraph), as in the example tinyGadj.txt shown at right. After the number of vertices and edges, each line contains a vertex and its list of adjacent vertices. 4.1.16 The eccentricity of a vertex v is the the length of the shortest path from that vertex to the furthest vertex from v. The diameter of a graph is the maximum eccentricity of any vertex. The radius of a graph is the smallest eccentricity of any vertex. A center is a vertex whose eccentricity is the radius. Implement the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_09748" smilref="Title.smil#_09748"> % java Graph tinyGadj.txt 13 vertices, 13 edges 0: 6 5 2 1 1: 0 2: 0 3: 5 4 4: 6 5 3 5: 4 3 0 6: 4 0 7: 8 8: 7 9: 12 11 10 10: 9 11: 12 9 12: 11 9</p><p attribs="{'xml:space': 'preserve'}" id="_09749" smilref="Title.smil#_09749"> s e cond re p re s en ta t ion o f ea ch edge  app ea r s in red</p><p attribs="{'xml:space': 'preserve'}" id="_09750" smilref="Title.smil#_09750"> public class GraphProperties</p><p attribs="{'xml:space': 'preserve'}" id="_09751" smilref="Title.smil#_09751"> GraphProperties(Graph G) constructor (exception if G not connected) eccentricity of v diameter of G radius of G a center of G</p><p attribs="{'xml:space': 'preserve'}" id="_09752" smilref="Title.smil#_09752"> int eccentricity(int v) int diameter() int radius() int center()</p><p attribs="{'xml:space': 'preserve'}" id="_09753" smilref="Title.smil#_09753"> 4.1.18 The girth of a graph is the length of its shortest cycle. If a graph is acyclic, then its girth is in&#64257; nite. Add a method girth() to GraphProperties that returns the girth of the graph. Hint : Run BFS from each vertex. The shortest cycle containing s is a shortest path from s to some vertex v, plus the edge from v back to s.</p><p attribs="{'xml:space': 'preserve'}" id="_09754" smilref="Title.smil#_09754" /><pagenum id="p573" page="normal" smilref="Title.smil#p573" /><p attribs="{'xml:space': 'preserve'}" id="_09755" smilref="Title.smil#_09755"> 560</p><p attribs="{'xml:space': 'preserve'}" id="_09756" smilref="Title.smil#_09756"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09757" smilref="Title.smil#_09757"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_09758" smilref="Title.smil#_09758"> 4.1.19 Show, in the style of the figure on page 545, a detailed trace of CC for finding the connected components in the graph built by Graph&#8217;s input stream constructor for the file tinyGex2.txt (see Exercise 4.1.2). 4.1.20 Show, in the style of the figures in this section, a detailed trace of Cycle for finding a cycle in the graph built by Graph&#8217;s input stream constructor for the file tinyGex2.txt (see Exercise 4.1.2). What is the order of growth of the running time of the Cycle constructor, in the worst case? 4.1.21 Show, in the style of the figures in this section, a detailed trace of TwoColor for finding a two-coloring of the graph built by Graph&#8217;s input stream constructor for the file tinyGex2.txt (see Exercise 4.1.2). What is the order of growth of the running time of the TwoColor constructor, in the worst case? 4.1.22 Run SymbolGraph with movies.txt to find the Kevin Bacon number of this year&#8217;s Oscar nominees. 4.1.23 Write a program BaconHistogram that prints a histogram of Kevin Bacon numbers, indicating how many performers from movies.txt have a Bacon number of 0, 1, 2, 3, ... . Include a category for those who have an infinite number (not connected to Kevin Bacon). 4.1.24 Compute the number of connected components in movies.txt, the size of the largest component, and the number of components of size less than 10. Find the eccen- tricity, diameter, radius, a center, and the girth of the largest component in the graph. Does it contain Kevin Bacon? 4.1.25 Modify DegreesOfSeparation to take an int value y as a command-line argument and ignore movies that are more than y years old. 4.1.26 Write a SymbolGraph client like DegreesOfSeparation that uses depth-&#64257; rst search instead of breadth-&#64257; rst search to find paths connecting two performers, producing output like that shown on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_09759" smilref="Title.smil#_09759" /><pagenum id="p574" page="normal" smilref="Title.smil#p574" /><p attribs="{'xml:space': 'preserve'}" id="_09760" smilref="Title.smil#_09760"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09761" smilref="Title.smil#_09761"> 561</p><p attribs="{'xml:space': 'preserve'}" id="_09762" smilref="Title.smil#_09762"> 4.1.27 Determine the amount of memory used by Graph to represent a graph with V vertices and E edges, using the memory-cost model of Section 1.4. 4.1.28 Two graphs are isomorphic if there is a way to rename the vertices of one to make it identical to the other. Draw all the nonisomorphic graphs with two, three, four, and five vertices. 4.1.29 Modify Cycle so that it works even if the graph contains self-loops and parallel edges.</p><p attribs="{'xml:space': 'preserve'}" id="_09763" smilref="Title.smil#_09763"> % java DegreesOfSeparationDFS movies.txt "/" "Bacon, Kevin" Kidman, Nicole Bacon, Kevin Woodsman, The (2004) Sedgwick, Kyra Something to Talk About (1995) Gillan, Lisa Roberts Runaway Bride (1999) Schertler, Jean ... [1782 movies ] (!) Eskelson, Dana Interpreter, The (2005) Silver, Tracey (II) Copycat (1995) Chua, Jeni Metro (1997) Ejogo, Carmen Avengers, The (1998) Atkins, Eileen Hours, The (2002) Kidman, Nicole</p><p attribs="{'xml:space': 'preserve'}" id="_09764" smilref="Title.smil#_09764" /><pagenum id="p575" page="normal" smilref="Title.smil#p575" /><p attribs="{'xml:space': 'preserve'}" id="_09765" smilref="Title.smil#_09765"> 562</p><p attribs="{'xml:space': 'preserve'}" id="_09766" smilref="Title.smil#_09766"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09767" smilref="Title.smil#_09767"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_09768" smilref="Title.smil#_09768"> 4.1.30 Eulerian and Hamiltonian cycles. Consider the graphs defined by the following four sets of edges:</p><p attribs="{'xml:space': 'preserve'}" id="_09769" smilref="Title.smil#_09769"> 0-1 0-2 0-3 1-3 1-4 2-5 2-9 3-6 4-7 4-8 5-8 5-9 6-7 6-9 7-8 0-1 0-2 0-3 1-3 0-3 2-5 5-6 3-6 4-7 4-8 5-8 5-9 6-7 6-9 8-8 0-1 1-2 1-3 0-3 0-4 2-5 2-9 3-6 4-7 4-8 5-8 5-9 6-7 6-9 7-8 4-1 7-9 6-2 7-3 5-0 0-2 0-8 1-6 3-9 6-3 2-8 1-5 9-8 4-5 4-7</p><p attribs="{'xml:space': 'preserve'}" id="_09770" smilref="Title.smil#_09770"> Which of these graphs have Euler cycles (cycles that visit each edge exactly once)? Which of them have Hamilton cycles (cycles that visit each vertex exactly once)? 4.1.31 Graph enumeration. How many different undirected graphs are there with V vertices and E edges (and no parallel edges)? 4.1.32 Parallel edge detection. Devise a linear-time algorithm to count the parallel edges in a graph. 4.1.33 Odd cycles. Prove that a graph is two-colorable (bipartite) if and only if it contains no odd-length cycle. 4.1.34 Symbol graph. Implement a one-pass SymbolGraph (it need not be a Graph client). Your implementation may pay an extra log V factor for graph operations, for symbol-table lookups. 4.1.35 Biconnectedness. A graph is biconnected if every pair of vertices is connected by two disjoint paths. An articulation point in a connected graph is a vertex that would disconnect the graph if it (and its adjacent edges) were removed. Prove that any graph with no articulation points is biconnected. Hint : Given a pair of vertices s and t and a path connecting them, use the fact that none of the vertices on the path are articulation points to construct two disjoint paths connecting s and t. 4.1.36 Two-edge connectivity. A bridge in a graph is an edge that, if removed, would increase the number of connected components. A graph that has no bridges is said to be two-edge connected. Develop a DFS-based data type for determining whether a given graph is edge connected. 4.1.37 Euclidean graphs. Design and implement an API EuclideanGraph for graphs whose vertices are points in the plane that include coordinates. Include a method show() that uses StdDraw to draw the graph.</p><p attribs="{'xml:space': 'preserve'}" id="_09771" smilref="Title.smil#_09771" /><pagenum id="p576" page="normal" smilref="Title.smil#p576" /><p attribs="{'xml:space': 'preserve'}" id="_09772" smilref="Title.smil#_09772"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09773" smilref="Title.smil#_09773"> 563</p><p attribs="{'xml:space': 'preserve'}" id="_09774" smilref="Title.smil#_09774"> 4.1.38 Image processing. Implement the flood fill operation on the implicit graph defined by connecting adjacent points that have the same color in an image.</p><p attribs="{'xml:space': 'preserve'}" id="_09775" smilref="Title.smil#_09775" /><pagenum id="p577" page="normal" smilref="Title.smil#p577" /><p attribs="{'xml:space': 'preserve'}" id="_09776" smilref="Title.smil#_09776"> 564</p><p attribs="{'xml:space': 'preserve'}" id="_09777" smilref="Title.smil#_09777"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09778" smilref="Title.smil#_09778"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_09779" smilref="Title.smil#_09779"> 4.1.39 Random graphs. Write a program ErdosRenyiGraph that takes integer values V and E from the command line and builds a graph by generating E random pairs of integers between 0 and V&#11002;1. Note: This generator produces self-loops and parallel edges. 4.1.40 Random simple graphs. Write a program RandomSimpleGraph that takes integer values V and E from the command line and produces, with equal likelihood, each of the possible simple graphs with V vertices and E edges. 4.1.41 Random sparse graphs. Write a program RandomSparseGraph to generate random sparse graphs for a well-chosen set of values of V and E such that you can use it to run meaningful empirical tests on graphs drawn from the Erd&#246;s-Renyi model. 4.1.42 Random Euclidean graphs. Write a EuclideanGraph client (see Exercise 4.1.37) RandomEuclideanGraph that produces random graphs by generating V random points in the plane, then connecting each point with all points that are within a circle of radius d centered at that point. Note : The graph will almost certainly be connected if d is larger than the threshold value &#20906; lg V/&#9266; V and almost certainly disconnected if d is smaller than that value. 4.1.43 Random grid graphs. Write a EuclideanGraph client RandomGridGraph that generates random graphs by connecting vertices arranged in a &#20906; V-by-&#20906; V grid to their neighbors (see Exercise 1.5.15). Augment your program to add R extra random edges. For large R, shrink the grid so that the total number of edges remains about V. Add an option such that an extra edge goes from a vertex s to a vertex t with probability inversely proportional to the Euclidean distance between s and t. 4.1.44 Real-world graphs. Find a large weighted graph on the web&#8212;perhaps a map with distances, telephone connections with costs, or an airline rate schedule. Write a program RandomRealGraph that builds a graph by choosing V vertices at random and E edges at random from the subgraph induced by those vertices. 4.1.45 Random interval graphs. Consider a collection of V intervals on the real line (pairs of real numbers). Such a collection defines an interval graph with one vertex corresponding to each interval, with edges between vertices if the corresponding intervals intersect (have any points in common). Write a program that generates V random intervals in the unit interval, all of length d, then builds the corresponding interval graph. Hint: Use a BST.</p><p attribs="{'xml:space': 'preserve'}" id="_09780" smilref="Title.smil#_09780" /><pagenum id="p578" page="normal" smilref="Title.smil#p578" /><p attribs="{'xml:space': 'preserve'}" id="_09781" smilref="Title.smil#_09781"> 4.1 </p><p attribs="{'xml:space': 'preserve'}" id="_09782" smilref="Title.smil#_09782"> 565</p><p attribs="{'xml:space': 'preserve'}" id="_09783" smilref="Title.smil#_09783"> 4.1.46 Random transportation graphs. One way to define a transportation system is with a set of sequences of vertices, each sequence defining a path connecting the ver- tices. For example, the sequence 0-9-3-2 defines the edges 0-9, 9-3, and 3-2. Write a EuclideanGraph client RandomTransportation that builds a graph from an inputfile consisting of one sequence per line, using symbolic names. Develop input suitable to allow you to use your program to build a graph corresponding to the Paris M&#233;tro system.</p><p attribs="{'xml:space': 'preserve'}" id="_09784" smilref="Title.smil#_09784"> Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</p><p attribs="{'xml:space': 'preserve'}" id="_09785" smilref="Title.smil#_09785"> 4.1.47 Path lengths in DFS. Run experiments to determine empirically the probability that DepthFirstPaths finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various graph models. 4.1.48 Path lengths in BFS. Run experiments to determine empirically the probability that BreadthFirstPaths finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various graph models. 4.1.49 Connected components. Run experiments to determine empirically the distribution of the number of components in random graphs of various types, by generating large numbers of graphs and drawing a histogram. 4.1.50 Two-colorable. Most graphs are not two-colorable, and DFS tends to discover that fact quickly. Run empirical tests to study the number of edges examined by TwoColor, for various graph models.</p><p attribs="{'xml:space': 'preserve'}" id="_09786" smilref="Title.smil#_09786" /></level3><level3 id="_00074"><h3 id="ch4-s2-ss8" smilref="Title.smil#ch4-s2-ss8" xml:space="preserve">Glossary</h3><p attribs="{'xml:space': 'preserve'}" id="_09787" smilref="Title.smil#_09787"> 4.2</p><p attribs="{'xml:space': 'preserve'}" id="_09788" smilref="Title.smil#_09788"> DIRECTED GRAPHS</p><p attribs="{'xml:space': 'preserve'}" id="_09789" smilref="Title.smil#_09789"> edge</p><p attribs="{'xml:space': 'preserve'}" id="_09790" smilref="Title.smil#_09790"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09791" smilref="Title.smil#_09791"> In directed graphs, edges are one-way : the pair of vertices that defines each edge is an ordered pair that specifies a one-way adjacency. Many applications (for example, graphs that represent the web, scheduling constraints, or telephone calls) are naturally expressed in terms of directed graphs. The one-way restriction is natural, easy to enforce in our implementations, and seems in- nocuous; but it implies added combinatorial structure that has profound implications for our algorithms and makes working with directed graphs quite different from working with undirected graphs. In this section, we consider classic algorithms for exploring and processing directed graphs.</p><p attribs="{'xml:space': 'preserve'}" id="_09792" smilref="Title.smil#_09792"> predator-prey</p><p attribs="{'xml:space': 'preserve'}" id="_09793" smilref="Title.smil#_09793"> hyperlink external reference call citation transaction connection</p><p attribs="{'xml:space': 'preserve'}" id="_09794" smilref="Title.smil#_09794"> application</p><p attribs="{'xml:space': 'preserve'}" id="_09795" smilref="Title.smil#_09795"> food web internet content program cellphone scholarship fi nancial internet</p><p attribs="{'xml:space': 'preserve'}" id="_09796" smilref="Title.smil#_09796"> species</p><p attribs="{'xml:space': 'preserve'}" id="_09797" smilref="Title.smil#_09797"> page module phone paper stock machine</p><p attribs="{'xml:space': 'preserve'}" id="_09798" smilref="Title.smil#_09798"> Typical digraph applications</p><p attribs="{'xml:space': 'preserve'}" id="_09799" smilref="Title.smil#_09799"> Glossary Our definitions for directed graphs are nearly identical to those for undirected graphs (as are some of the algorithms and programs that we use), but they are worth restating. The slight differences in the wording to account for edge directions imply structural properties that will be the focus of this section.</p><p attribs="{'xml:space': 'preserve'}" id="_09800" smilref="Title.smil#_09800"> Definition. A directed graph (or digraph) is a set of vertices and a collection of directed edges. Each directed edge connects an ordered pair of vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_09801" smilref="Title.smil#_09801"> We say that a directed edge points from the first vertex in the pair and points to the second vertex in the pair. The outdegree of a vertex in a digraph is the number of edges pointing from it; the indegree of a vertex is the number of edges pointing to it. We drop the modifier directed when referring to edges in digraphs when the distinction is obvious in context. The first vertex in a directed edge is called its head ; the second vertex is called its tail. We draw directed edges as arrows pointing from head to tail. We use the notation v-&gt;w to refer to an edge that points from v to w in a digraph. As with undirected graphs, our code handles parallel edges and self-loops, but they are not present in examples and we generally ignore them in the text. Ignoring anomalies, there are</p><p attribs="{'xml:space': 'preserve'}" id="_09802" smilref="Title.smil#_09802"> 566</p><p attribs="{'xml:space': 'preserve'}" id="_09803" smilref="Title.smil#_09803" /><p attribs="{'xml:space': 'preserve'}" id="_09804" smilref="Title.smil#_09804"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_09805" smilref="Title.smil#_09805"> 567</p><p attribs="{'xml:space': 'preserve'}" id="_09806" smilref="Title.smil#_09806"> four different ways in which two vertices might be related in a digraph: no edge; an edge v-&gt;w from v to w; an edge w-&gt;v from w to v; or two edges v-&gt;w and w-&gt;v, which indicate connections in both directions.</p><p attribs="{'xml:space': 'preserve'}" id="_09807" smilref="Title.smil#_09807"> Definition. A directed path in a digraph is a sequence of vertices in which there is a (directed) edge pointing from each vertex in the sequence to its successor in the sequence. A directed cycle is a directed path with at least one edge whose first and last vertices are the same. A simple cycle is a cycle with no repeated edges or vertices (except the requisite repetition of the first and last vertices). The length of a path or a cycle is its number of edges.</p><p attribs="{'xml:space': 'preserve'}" id="_09808" smilref="Title.smil#_09808"> As for undirected graphs, we assume that directed paths are simple unless we specifically relax this assumption by referring to specific repeated vertices (as in our definition of directed cycle) or to general directed paths. We say that a vertex w is reachable from a vertex v if there is a directed path from v to w. Also, we adopt the convention that each vertex is reachable from itself. Except for this case, the fact that w is reachable from v in a digraph indicates nothing about whether v is reachable from w. This distinction is obvious, but critical, as we shall see.</p><p attribs="{'xml:space': 'preserve'}" id="_09809" smilref="Title.smil#_09809"> directed edge</p><p attribs="{'xml:space': 'preserve'}" id="_09810" smilref="Title.smil#_09810"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09811" smilref="Title.smil#_09811"> directed path of length 4</p><p attribs="{'xml:space': 'preserve'}" id="_09812" smilref="Title.smil#_09812"> directed cycle of length 3</p><p attribs="{'xml:space': 'preserve'}" id="_09813" smilref="Title.smil#_09813"> vertex of indegree 3 and outdegree 2</p><p attribs="{'xml:space': 'preserve'}" id="_09814" smilref="Title.smil#_09814"> Anatomy of a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_09815" smilref="Title.smil#_09815"> w</p><p attribs="{'xml:space': 'preserve'}" id="_09816" smilref="Title.smil#_09816"> Understanding the algorithms in this section requires an appreciation of the distinction between reachability in digraphs and connectivity in undirected graphs. De- veloping such an appreciation is more complicated than you might think. For example, although you are likely to be able to tell at a glance whether two vertices in a small undirected graph are connected, a directed path in a digraph is not so easy to spot, as indicated in the example at left. Processing digraphs is akin to traveling around in a city where all the streets are one-way, with the directions not necessarily assigned in any uniform pattern. Getting from one point to another in such a situation could be a challenge indeed. Counter to this intuition is the fact that the standard data structure that we use for representing digraphs is simpler than the corresponding representation for undirected graphs!</p><p attribs="{'xml:space': 'preserve'}" id="_09817" smilref="Title.smil#_09817"> Is w reachable from v in this digraph?</p><p attribs="{'xml:space': 'preserve'}" id="_09818" smilref="Title.smil#_09818"> v</p><p attribs="{'xml:space': 'preserve'}" id="_09819" smilref="Title.smil#_09819" /></level3><level3 id="_00075"><h3 id="ch4-s2-ss9" smilref="Title.smil#ch4-s2-ss9" xml:space="preserve">Digraph data type</h3><pagenum id="p581" page="normal" smilref="Title.smil#p581" /><p attribs="{'xml:space': 'preserve'}" id="_09820" smilref="Title.smil#_09820"> 568</p><p attribs="{'xml:space': 'preserve'}" id="_09821" smilref="Title.smil#_09821"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09822" smilref="Title.smil#_09822"> Digraph data type The API below and the class Digraph shown on the facing page are virtually identical to those for Graph (page 526).</p><p attribs="{'xml:space': 'preserve'}" id="_09823" smilref="Title.smil#_09823"> public class Digraph</p><p attribs="{'xml:space': 'preserve'}" id="_09824" smilref="Title.smil#_09824"> Digraph(int V) Digraph(In in) int V() int E() void addEdge(int v, int w) add edge v-&gt;w to this digraph</p><p attribs="{'xml:space': 'preserve'}" id="_09825" smilref="Title.smil#_09825"> create a V-vertex digraph with no edges read a digraph from input stream in number of vertices number of edges</p><p attribs="{'xml:space': 'preserve'}" id="_09826" smilref="Title.smil#_09826"> Iterable&lt;Integer&gt; adj(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_09827" smilref="Title.smil#_09827"> Digraph reverse() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_09828" smilref="Title.smil#_09828"> vertices connected to v by edges pointing from v reverse of this digraph string representation</p><p attribs="{'xml:space': 'preserve'}" id="_09829" smilref="Title.smil#_09829"> API for a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_09830" smilref="Title.smil#_09830"> Representation. We use the adjacency-lists representation, where an edge v-&gt;w is represented as a list node containing w in the linked list corresponding to v. This representation is essentially the same as for undirected graphs but is even more straightforward because each edge occurs just once, as shown on the facing page. Input format. The code for the constructor that takes a digraph from an input stream is identical to the corresponding constructor in Graph&#8212;the input format is the same, but all edges are interpreted to be directed edges. In the list-of-edges format, a pair v w is interpreted as an edge v-&gt;w. Reversing a digraph. Digraph also adds to the API a method reverse() which returns a copy of the digraph, with all edges reversed. This method is sometimes needed in digraph processing because it allows clients to find the edges that point to each ver- tex, while adj() gives just vertices connected by edges that point from each vertex. Symbolic names. It is also a simple matter to allow clients to use symbolic names in digraph applications. To implement a class SymbolDigraph like SymbolGraph on page 552, replace Graph by Digraph everywhere. It is worthwhile to take the time to consider carefully the difference, by comparing code and the figure at right with their counterparts for undirected graphs on page 524 and page 526. In the adjacency-lists representation of an undirected graph, we know that if v is on w&#8217;s list, then w will be on v&#8217;s list; the adjacency-lists representation of a digraph has no such symmetry. This difference has profound implications in processing digraphs.</p><p attribs="{'xml:space': 'preserve'}" id="_09831" smilref="Title.smil#_09831" /><pagenum id="p582" page="normal" smilref="Title.smil#p582" /><p attribs="{'xml:space': 'preserve'}" id="_09832" smilref="Title.smil#_09832"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_09833" smilref="Title.smil#_09833"> 569</p><p attribs="{'xml:space': 'preserve'}" id="_09834" smilref="Title.smil#_09834"> Directed graph (digraph) data type</p><p attribs="{'xml:space': 'preserve'}" id="_09835" smilref="Title.smil#_09835"> public class Digraph { private final int V; private int E; private Bag&lt;Integer&gt;[] adj;</p><p attribs="{'xml:space': 'preserve'}" id="_09836" smilref="Title.smil#_09836"> public Digraph(int V) { this.V = V; this.E = 0; adj = (Bag&lt;Integer&gt;[]) new Bag[V]; for (int v = 0; v &lt; V; v++) adj[v] = new Bag&lt;Integer&gt;(); }</p><p attribs="{'xml:space': 'preserve'}" id="_09837" smilref="Title.smil#_09837"> public int V() { return V; } public int E() { return E; }</p><p attribs="{'xml:space': 'preserve'}" id="_09838" smilref="Title.smil#_09838"> public void addEdge(int v, int w) { adj[v].add(w); E++; }</p><p attribs="{'xml:space': 'preserve'}" id="_09839" smilref="Title.smil#_09839"> public Iterable&lt;Integer&gt; adj(int v) { return adj[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09840" smilref="Title.smil#_09840"> public Digraph reverse() { Digraph R = new Digraph(V); for (int v = 0; v &lt; V; v++) for (int w : adj(v)) R.addEdge(w, v); return R; } }</p><p attribs="{'xml:space': 'preserve'}" id="_09841" smilref="Title.smil#_09841"> V</p><p attribs="{'xml:space': 'preserve'}" id="_09842" smilref="Title.smil#_09842"> tinyDG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_09843" smilref="Title.smil#_09843"> E</p><p attribs="{'xml:space': 'preserve'}" id="_09844" smilref="Title.smil#_09844"> 13 22 4 2 2 3 3 2 6 0 0 1 2 0 11 12 12 9 9 10 9 11 7 9 10 12 11 4 4 3 3 5 6 8 8 6 5 4 0 5 6 4 6 9 7 6</p><p attribs="{'xml:space': 'preserve'}" id="_09845" smilref="Title.smil#_09845"> adj[] 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09846" smilref="Title.smil#_09846"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_09847" smilref="Title.smil#_09847"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09848" smilref="Title.smil#_09848"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09849" smilref="Title.smil#_09849"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_09850" smilref="Title.smil#_09850"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09851" smilref="Title.smil#_09851"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09852" smilref="Title.smil#_09852"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_09853" smilref="Title.smil#_09853"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_09854" smilref="Title.smil#_09854"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09855" smilref="Title.smil#_09855"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09856" smilref="Title.smil#_09856"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_09857" smilref="Title.smil#_09857"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_09858" smilref="Title.smil#_09858"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09859" smilref="Title.smil#_09859"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09860" smilref="Title.smil#_09860"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09861" smilref="Title.smil#_09861"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_09862" smilref="Title.smil#_09862"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_09863" smilref="Title.smil#_09863"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_09864" smilref="Title.smil#_09864"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_09865" smilref="Title.smil#_09865"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_09866" smilref="Title.smil#_09866"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_09867" smilref="Title.smil#_09867"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_09868" smilref="Title.smil#_09868"> This Digraph data type is identical to Graph (page 526) except that addEdge() only calls add() once, and it has an instance method reverse() that returns a copy with all its edges reversed. Since the code is easily derived from the corresponding code for Graph, we omit the toString() method (see the table on page 523) and the input stream constructor from (see page 526).</p><p attribs="{'xml:space': 'preserve'}" id="_09869" smilref="Title.smil#_09869"> Digraph input format and adjacency-lists representation</p><p attribs="{'xml:space': 'preserve'}" id="_09870" smilref="Title.smil#_09870" /><pagenum id="p583" page="normal" smilref="Title.smil#p583" /><p attribs="{'xml:space': 'preserve'}" id="_09871" smilref="Title.smil#_09871"> 570</p><p attribs="{'xml:space': 'preserve'}" id="_09872" smilref="Title.smil#_09872"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09873" smilref="Title.smil#_09873"> Reachability in digraphs Our first graph-processing algorithm for undirected graphs was DepthFirstSearch on page 531, which solves the single-source connectivity problem, allowing clients to determine which vertices are connected to a given source. The identical code with Graph changed to Digraph solves the analogous problem for digraphs:</p><p attribs="{'xml:space': 'preserve'}" id="_09874" smilref="Title.smil#_09874"> Single-source reachability. Given a digraph and a source vertex s, support queries of the form Is there a directed path from s to a given target vertex v?</p><p attribs="{'xml:space': 'preserve'}" id="_09875" smilref="Title.smil#_09875"> DirectedDFS on the facing page is a slight embellishment of DepthFirstSearch that implements the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_09876" smilref="Title.smil#_09876"> public class DirectedDFS</p><p attribs="{'xml:space': 'preserve'}" id="_09877" smilref="Title.smil#_09877"> DirectedDFS(Digraph G, int s)</p><p attribs="{'xml:space': 'preserve'}" id="_09878" smilref="Title.smil#_09878"> DirectedDFS(Digraph G, Iterable&lt;Integer&gt; sources)</p><p attribs="{'xml:space': 'preserve'}" id="_09879" smilref="Title.smil#_09879"> boolean marked(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_09880" smilref="Title.smil#_09880"> API for reachability in digraphs</p><p attribs="{'xml:space': 'preserve'}" id="_09881" smilref="Title.smil#_09881"> fi nd vertices in G that are reachable from s fi nd vertices in G that are reachable from sources is v reachable?</p><p attribs="{'xml:space': 'preserve'}" id="_09882" smilref="Title.smil#_09882"> By adding a second constructor that takes a list of vertices, this API supports for clients the following generalization of the problem:</p><p attribs="{'xml:space': 'preserve'}" id="_09883" smilref="Title.smil#_09883"> Multiple-source reachability. Given a digraph and a set of source vertices, support queries of the form Is there a directed path from any vertex in the set to a given target vertex v?</p><p attribs="{'xml:space': 'preserve'}" id="_09884" smilref="Title.smil#_09884"> This problem arises in the solution of a classic string-processing problem that we con-</p><p attribs="{'xml:space': 'preserve'}" id="_09885" smilref="Title.smil#_09885"> sider in Section 5.4.</p><p attribs="{'xml:space': 'preserve'}" id="_09886" smilref="Title.smil#_09886"> DirectedDFS uses our standard graph-processing paradigm and a standard recursive depth-&#64257; rst search to solve these problems. It calls the recursive dfs() for each source, which marks every vertex encountered.</p><p attribs="{'xml:space': 'preserve'}" id="_09887" smilref="Title.smil#_09887"> Proposition D. DFS marks all the vertices in a digraph reachable from a given set of sources in time proportional to the sum of the outdegrees of the vertices marked. Proof : Same as Proposition A on page 531.</p><p attribs="{'xml:space': 'preserve'}" id="_09888" smilref="Title.smil#_09888"> A trace of the operation of this algorithm for our sample digraph appears on page 572. This trace is somewhat simpler than the corresponding trace for undirected graphs,</p><p attribs="{'xml:space': 'preserve'}" id="_09889" smilref="Title.smil#_09889" /><pagenum id="p584" page="normal" smilref="Title.smil#p584" /><p attribs="{'xml:space': 'preserve'}" id="_09890" smilref="Title.smil#_09890"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_09891" smilref="Title.smil#_09891"> 571</p><p attribs="{'xml:space': 'preserve'}" id="_09892" smilref="Title.smil#_09892"> ALGORITHM 4.4 Reachability in digraphs</p><p attribs="{'xml:space': 'preserve'}" id="_09893" smilref="Title.smil#_09893"> public class DirectedDFS { private boolean[] marked;</p><p attribs="{'xml:space': 'preserve'}" id="_09894" smilref="Title.smil#_09894"> public DirectedDFS(Digraph G, int s) { marked = new boolean[G.V()]; dfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09895" smilref="Title.smil#_09895"> public DirectedDFS(Digraph G, Iterable&lt;Integer&gt; sources) { marked = new boolean[G.V()]; for (int s : sources) if (!marked[s]) dfs(G, s); }</p><p attribs="{'xml:space': 'preserve'}" id="_09896" smilref="Title.smil#_09896"> % java DirectedDFS tinyDG.txt 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_09897" smilref="Title.smil#_09897"> private void dfs(Digraph G, int v) { marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); }</p><p attribs="{'xml:space': 'preserve'}" id="_09898" smilref="Title.smil#_09898"> public boolean marked(int v) { return marked[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_09899" smilref="Title.smil#_09899"> % java DirectedDFS tinyDG.txt 2 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_09900" smilref="Title.smil#_09900"> % java DirectedDFS tinyDG.txt 1 2 6 0 1 2 3 4 5 6 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_09901" smilref="Title.smil#_09901"> public static void main(String[] args) { Digraph G = new Digraph(new In(args[0]));</p><p attribs="{'xml:space': 'preserve'}" id="_09902" smilref="Title.smil#_09902"> Bag&lt;Integer&gt; sources = new Bag&lt;Integer&gt;(); for (int i = 1; i &lt; args.length; i++) sources.add(Integer.parseInt(args[i]));</p><p attribs="{'xml:space': 'preserve'}" id="_09903" smilref="Title.smil#_09903"> DirectedDFS reachable = new DirectedDFS(G, sources);</p><p attribs="{'xml:space': 'preserve'}" id="_09904" smilref="Title.smil#_09904"> for (int v = 0; v &lt; G.V(); v++) if (reachable.marked(v)) StdOut.print(v + " "); StdOut.println(); }</p><p attribs="{'xml:space': 'preserve'}" id="_09905" smilref="Title.smil#_09905"> }</p><p attribs="{'xml:space': 'preserve'}" id="_09906" smilref="Title.smil#_09906"> This implementation of depth-&#64257; rst search provides clients the ability to test which vertices are reachable from a given vertex or a given set of vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_09907" smilref="Title.smil#_09907" /><pagenum id="p585" page="normal" smilref="Title.smil#p585" /><p attribs="{'xml:space': 'preserve'}" id="_09908" smilref="Title.smil#_09908"> 572</p><p attribs="{'xml:space': 'preserve'}" id="_09909" smilref="Title.smil#_09909"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09910" smilref="Title.smil#_09910"> dfs(0)</p><p attribs="{'xml:space': 'preserve'}" id="_09911" smilref="Title.smil#_09911"> dfs(5)</p><p attribs="{'xml:space': 'preserve'}" id="_09912" smilref="Title.smil#_09912"> dfs(4)</p><p attribs="{'xml:space': 'preserve'}" id="_09913" smilref="Title.smil#_09913"> dfs(3) check 5</p><p attribs="{'xml:space': 'preserve'}" id="_09914" smilref="Title.smil#_09914"> dfs(2) check 0 check 3 2 done 3 done check 2 4 done 5 done</p><p attribs="{'xml:space': 'preserve'}" id="_09915" smilref="Title.smil#_09915"> dfs(1) 1 done 0 done</p><p attribs="{'xml:space': 'preserve'}" id="_09916" smilref="Title.smil#_09916"> marked[] 0 T 1 2 3 4 5 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09917" smilref="Title.smil#_09917"> 0 T 1 2 3 4 5 T . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09918" smilref="Title.smil#_09918"> 0 T 1 2 3 4 T 5 T . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09919" smilref="Title.smil#_09919"> 0 T 1 2 3 T 4 T 5 T . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09920" smilref="Title.smil#_09920"> 0 T 1 2 T 3 T 4 T 5 T . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09921" smilref="Title.smil#_09921"> 0 T 1 T 2 T 3 T 4 T 5 T . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09922" smilref="Title.smil#_09922"> adj[] 0 5 1 1 2 0 3 3 5 2 4 3 2 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09923" smilref="Title.smil#_09923"> 0 5 1 1 2 0 3 3 5 2 4 3 2 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09924" smilref="Title.smil#_09924"> 0 5 1 1 2 0 3 3 5 2 4 3 2 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09925" smilref="Title.smil#_09925"> 0 5 1 1 2 0 3 3 5 2 4 3 2 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09926" smilref="Title.smil#_09926"> 0 5 1 1 2 0 3 3 5 2 4 3 2 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09927" smilref="Title.smil#_09927"> 0 5 1 1 2 0 3 3 5 2 4 3 5 4 . . .</p><p attribs="{'xml:space': 'preserve'}" id="_09928" smilref="Title.smil#_09928"> Trace of depth-first search to find vertices reachable from vertex 0 in a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_09929" smilref="Title.smil#_09929" /><pagenum id="p586" page="normal" smilref="Title.smil#p586" /><p attribs="{'xml:space': 'preserve'}" id="_09930" smilref="Title.smil#_09930"> because DFS is fundamentally a digraph-processing algorithm, with one representation of each edge. Following this trace is a worthwhile way to help cement your understanding of depth-&#64257; rst search in digraphs.</p><p attribs="{'xml:space': 'preserve'}" id="_09931" smilref="Title.smil#_09931"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_09932" smilref="Title.smil#_09932"> 573</p><p attribs="{'xml:space': 'preserve'}" id="_09933" smilref="Title.smil#_09933"> Mark-and-sweep garbage collection. An im-</p><p attribs="{'xml:space': 'preserve'}" id="_09934" smilref="Title.smil#_09934"> portant application of multiple-source reachability is found in typical memory-management systems, including many implementations of Java. A digraph where each vertex represents an object and each edge represents a reference to an object is an appropriate model for the memory usage of a running Java program. At any point in the execution of a program, certain objects are known to be directly accessible, and any object not reachable from that set of objects can be returned to available memory. A mark- and-sweep garbage collection strategy reserves one bit per object for the purpose of garbage collection, then periodically marks the set of potentially accessible objects by running a digraph reachability algorithm like DirectedDFS and sweeps through all objects, collecting the unmarked ones for use for new objects.</p><p attribs="{'xml:space': 'preserve'}" id="_09935" smilref="Title.smil#_09935"> d i re c t ly a c c e s s ib l e ob j e c t s</p><p attribs="{'xml:space': 'preserve'}" id="_09936" smilref="Title.smil#_09936"> ob j e c t s ava i lab l e fo r co l l e c t ion</p><p attribs="{'xml:space': 'preserve'}" id="_09937" smilref="Title.smil#_09937"> po t en t ia l ly a c c e s s ib l e ob j e c t s</p><p attribs="{'xml:space': 'preserve'}" id="_09938" smilref="Title.smil#_09938"> Garbage collection scenario</p><p attribs="{'xml:space': 'preserve'}" id="_09939" smilref="Title.smil#_09939"> Finding paths in digraphs. DepthFirstPaths (Algorithm 4.1 on page 536) and</p><p attribs="{'xml:space': 'preserve'}" id="_09940" smilref="Title.smil#_09940"> BreadthFirstPaths (Algorithm 4.2 on page 540) are also fundamentally digraph- processing algorithms. Again, the identical APIs and code (with Graph changed to Digraph) effectively solve the following problems:</p><p attribs="{'xml:space': 'preserve'}" id="_09941" smilref="Title.smil#_09941"> Single-source directed paths. Given a digraph and a source vertex s, support queries of the form Is there a directed path from s to a given target vertex v? If so, find such a path.</p><p attribs="{'xml:space': 'preserve'}" id="_09942" smilref="Title.smil#_09942"> Single-source shortest directed paths. Given a digraph and a source vertex s,</p><p attribs="{'xml:space': 'preserve'}" id="_09943" smilref="Title.smil#_09943"> support queries of the form Is there a directed path from s to a given target vertex v? If so, find a shortest such path (one with a minimal number of edges).</p><p attribs="{'xml:space': 'preserve'}" id="_09944" smilref="Title.smil#_09944"> On the booksite and in the exercises at the end of this section, we refer to these solu-</p><p attribs="{'xml:space': 'preserve'}" id="_09945" smilref="Title.smil#_09945"> tions as DepthFirstDirectedPaths and BreadthFirstDirectedPaths, respectively.</p><p attribs="{'xml:space': 'preserve'}" id="_09946" smilref="Title.smil#_09946" /></level3><level3 id="_00076"><h3 id="ch4-s2-ss10" smilref="Title.smil#ch4-s2-ss10" xml:space="preserve">Directed cycle detection</h3><pagenum id="p587" page="normal" smilref="Title.smil#p587" /><p attribs="{'xml:space': 'preserve'}" id="_09947" smilref="Title.smil#_09947"> 574</p><p attribs="{'xml:space': 'preserve'}" id="_09948" smilref="Title.smil#_09948"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09949" smilref="Title.smil#_09949"> Cycles and DAGs Directed cycles are of particular importance in applications that involve processing digraphs. Identifying directed cycles in a typical digraph can be a challenge without the help of a computer, as shown at right. In principle, a digraph might have a huge number of cycles; in practice, we typically focus on a small number of them, or simply are interested in knowing that none are present. To motivate the study of the role of directed cycles in digraph processing we consider, as a running ex- ample, the following prototypical application where digraph models arise directly :</p><p attribs="{'xml:space': 'preserve'}" id="_09950" smilref="Title.smil#_09950"> Does this digraph have a directed cycle?</p><p attribs="{'xml:space': 'preserve'}" id="_09951" smilref="Title.smil#_09951"> Scheduling problems. A widely applicable problem-solving model has to do with arranging for the completion of a set of jobs, under a set of constraints, by specifying when and how the jobs are to be performed. Constraints might involve functions of the time taken or other resources consumed by the jobs. The most important type of constraints is precedence constraints, which specify that certain tasks must be performed before certain others. Different types of additional constraints lead to many different types of scheduling problems, of varying dif&#64257; culty. Literally thousands of different problems have been studied, and researchers still seek better algorithms for many of them. As an example, consider a college student planning a course schedule, under the constraint that certain courses are prerequisite for certain other courses, as in the example below.</p><p attribs="{'xml:space': 'preserve'}" id="_09952" smilref="Title.smil#_09952"> Algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_09953" smilref="Title.smil#_09953"> Linear Algebra</p><p attribs="{'xml:space': 'preserve'}" id="_09954" smilref="Title.smil#_09954"> Calculus</p><p attribs="{'xml:space': 'preserve'}" id="_09955" smilref="Title.smil#_09955"> Databases</p><p attribs="{'xml:space': 'preserve'}" id="_09956" smilref="Title.smil#_09956"> Introduction to CS</p><p attribs="{'xml:space': 'preserve'}" id="_09957" smilref="Title.smil#_09957"> Theoretical CS</p><p attribs="{'xml:space': 'preserve'}" id="_09958" smilref="Title.smil#_09958"> Artificial Intelligence</p><p attribs="{'xml:space': 'preserve'}" id="_09959" smilref="Title.smil#_09959"> Robotics</p><p attribs="{'xml:space': 'preserve'}" id="_09960" smilref="Title.smil#_09960"> Advanced Programming</p><p attribs="{'xml:space': 'preserve'}" id="_09961" smilref="Title.smil#_09961"> Computational Biology</p><p attribs="{'xml:space': 'preserve'}" id="_09962" smilref="Title.smil#_09962"> Machine Learning</p><p attribs="{'xml:space': 'preserve'}" id="_09963" smilref="Title.smil#_09963"> Neural Networks</p><p attribs="{'xml:space': 'preserve'}" id="_09964" smilref="Title.smil#_09964"> Scientific Computing</p><p attribs="{'xml:space': 'preserve'}" id="_09965" smilref="Title.smil#_09965"> A precedence-constrained scheduling problem</p><p attribs="{'xml:space': 'preserve'}" id="_09966" smilref="Title.smil#_09966" /></level3><level3 id="_00077"><h3 id="ch4-s2-ss11" smilref="Title.smil#ch4-s2-ss11" xml:space="preserve">Precedence-constrained scheduling</h3><p attribs="{'xml:space': 'preserve'}" id="_09967" smilref="Title.smil#_09967"> 574</p><p attribs="{'xml:space': 'preserve'}" id="_09968" smilref="Title.smil#_09968"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_09969" smilref="Title.smil#_09969"> Cycles and DAGs Directed cycles are of particular importance in applications that involve processing digraphs. Identifying directed cycles in a typical digraph can be a challenge without the help of a computer, as shown at right. In principle, a digraph might have a huge number of cycles; in practice, we typically focus on a small number of them, or simply are interested in knowing that none are present. To motivate the study of the role of directed cycles in digraph processing we consider, as a running ex- ample, the following prototypical application where digraph models arise directly :</p><p attribs="{'xml:space': 'preserve'}" id="_09970" smilref="Title.smil#_09970"> Does this digraph have a directed cycle?</p><p attribs="{'xml:space': 'preserve'}" id="_09971" smilref="Title.smil#_09971"> Scheduling problems. A widely applicable problem-solving model has to do with arranging for the completion of a set of jobs, under a set of constraints, by specifying when and how the jobs are to be performed. Constraints might involve functions of the time taken or other resources consumed by the jobs. The most important type of constraints is precedence constraints, which specify that certain tasks must be performed before certain others. Different types of additional constraints lead to many different types of scheduling problems, of varying dif&#64257; culty. Literally thousands of different problems have been studied, and researchers still seek better algorithms for many of them. As an example, consider a college student planning a course schedule, under the constraint that certain courses are prerequisite for certain other courses, as in the example below.</p><p attribs="{'xml:space': 'preserve'}" id="_09972" smilref="Title.smil#_09972"> Algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_09973" smilref="Title.smil#_09973"> Linear Algebra</p><p attribs="{'xml:space': 'preserve'}" id="_09974" smilref="Title.smil#_09974"> Calculus</p><p attribs="{'xml:space': 'preserve'}" id="_09975" smilref="Title.smil#_09975"> Databases</p><p attribs="{'xml:space': 'preserve'}" id="_09976" smilref="Title.smil#_09976"> Introduction to CS</p><p attribs="{'xml:space': 'preserve'}" id="_09977" smilref="Title.smil#_09977"> Theoretical CS</p><p attribs="{'xml:space': 'preserve'}" id="_09978" smilref="Title.smil#_09978"> Artificial Intelligence</p><p attribs="{'xml:space': 'preserve'}" id="_09979" smilref="Title.smil#_09979"> Robotics</p><p attribs="{'xml:space': 'preserve'}" id="_09980" smilref="Title.smil#_09980"> Advanced Programming</p><p attribs="{'xml:space': 'preserve'}" id="_09981" smilref="Title.smil#_09981"> Computational Biology</p><p attribs="{'xml:space': 'preserve'}" id="_09982" smilref="Title.smil#_09982"> Machine Learning</p><p attribs="{'xml:space': 'preserve'}" id="_09983" smilref="Title.smil#_09983"> Neural Networks</p><p attribs="{'xml:space': 'preserve'}" id="_09984" smilref="Title.smil#_09984"> Scientific Computing</p><p attribs="{'xml:space': 'preserve'}" id="_09985" smilref="Title.smil#_09985"> A precedence-constrained scheduling problem</p><p attribs="{'xml:space': 'preserve'}" id="_09986" smilref="Title.smil#_09986" /><p attribs="{'xml:space': 'preserve'}" id="_09987" smilref="Title.smil#_09987"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_09988" smilref="Title.smil#_09988"> 575</p><p attribs="{'xml:space': 'preserve'}" id="_09989" smilref="Title.smil#_09989"> If we further assume that the student can take only one course at a time, we have an instance of the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_09990" smilref="Title.smil#_09990"> Precedence-constrained scheduling. Given a set of jobs to be completed, with precedence constraints that specify that certain jobs have to be completed before certain other jobs are begun, how can we schedule the jobs such that they are all completed while still respecting the constraints?</p><p attribs="{'xml:space': 'preserve'}" id="_09991" smilref="Title.smil#_09991"> For any such problem, a digraph model is immediate, with vertices corresponding to jobs and directed edges corresponding to precedence constraints. For economy, we switch the example to our standard model with vertices labeled as integers, as shown at left. In digraphs, prece- dence-constrained scheduling amounts to the following fundamental problem:</p><p attribs="{'xml:space': 'preserve'}" id="_09992" smilref="Title.smil#_09992"> p re requ i s i t e s a l l sa t i s f i ed</p><p attribs="{'xml:space': 'preserve'}" id="_09993" smilref="Title.smil#_09993"> edge  s a l l po in t dow n</p><p attribs="{'xml:space': 'preserve'}" id="_09994" smilref="Title.smil#_09994"> Standard digraph model</p><p attribs="{'xml:space': 'preserve'}" id="_09995" smilref="Title.smil#_09995"> Topological sort. Given a digraph, put the vertices in order such that all its directed edges point from a vertex earlier in the order to a vertex later in the order (or report that doing so is not possible).</p><p attribs="{'xml:space': 'preserve'}" id="_09996" smilref="Title.smil#_09996"> A topological order for our example model is shown at right. All edges point down, so it clearly represents a solution to the precedence-constrained scheduling problem that this digraph models: the student can satisfy all course prerequisites by taking the courses in this order. This application is typical&#8212;some other representative applications are listed in the table below.</p><p attribs="{'xml:space': 'preserve'}" id="_09997" smilref="Title.smil#_09997"> application</p><p attribs="{'xml:space': 'preserve'}" id="_09998" smilref="Title.smil#_09998"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_09999" smilref="Title.smil#_09999"> edge</p><p attribs="{'xml:space': 'preserve'}" id="_10000" smilref="Title.smil#_10000"> job schedule</p><p attribs="{'xml:space': 'preserve'}" id="_10001" smilref="Title.smil#_10001"> job</p><p attribs="{'xml:space': 'preserve'}" id="_10002" smilref="Title.smil#_10002"> precedence constraint</p><p attribs="{'xml:space': 'preserve'}" id="_10003" smilref="Title.smil#_10003"> course schedule</p><p attribs="{'xml:space': 'preserve'}" id="_10004" smilref="Title.smil#_10004"> course</p><p attribs="{'xml:space': 'preserve'}" id="_10005" smilref="Title.smil#_10005"> prerequisite</p><p attribs="{'xml:space': 'preserve'}" id="_10006" smilref="Title.smil#_10006"> inheritance spreadsheet symbolic links</p><p attribs="{'xml:space': 'preserve'}" id="_10007" smilref="Title.smil#_10007"> Java class cell fi le name</p><p attribs="{'xml:space': 'preserve'}" id="_10008" smilref="Title.smil#_10008"> extends</p><p attribs="{'xml:space': 'preserve'}" id="_10009" smilref="Title.smil#_10009"> formula link</p><p attribs="{'xml:space': 'preserve'}" id="_10010" smilref="Title.smil#_10010"> Calculus</p><p attribs="{'xml:space': 'preserve'}" id="_10011" smilref="Title.smil#_10011"> Linear Algeb bra</p><p attribs="{'xml:space': 'preserve'}" id="_10012" smilref="Title.smil#_10012"> Introduction to CS</p><p attribs="{'xml:space': 'preserve'}" id="_10013" smilref="Title.smil#_10013"> Advanced Pr rogramming</p><p attribs="{'xml:space': 'preserve'}" id="_10014" smilref="Title.smil#_10014"> Algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_10015" smilref="Title.smil#_10015"> Theoretical C CS</p><p attribs="{'xml:space': 'preserve'}" id="_10016" smilref="Title.smil#_10016"> Artificial Inte elligence</p><p attribs="{'xml:space': 'preserve'}" id="_10017" smilref="Title.smil#_10017"> Robotics</p><p attribs="{'xml:space': 'preserve'}" id="_10018" smilref="Title.smil#_10018"> Machine Lea</p><p attribs="{'xml:space': 'preserve'}" id="_10019" smilref="Title.smil#_10019"> rning</p><p attribs="{'xml:space': 'preserve'}" id="_10020" smilref="Title.smil#_10020"> Neural Netw orks</p><p attribs="{'xml:space': 'preserve'}" id="_10021" smilref="Title.smil#_10021"> Databases</p><p attribs="{'xml:space': 'preserve'}" id="_10022" smilref="Title.smil#_10022"> Scientific Com mputing</p><p attribs="{'xml:space': 'preserve'}" id="_10023" smilref="Title.smil#_10023"> Computation nal Biology</p><p attribs="{'xml:space': 'preserve'}" id="_10024" smilref="Title.smil#_10024"> Typical topological-sort applications</p><p attribs="{'xml:space': 'preserve'}" id="_10025" smilref="Title.smil#_10025"> Topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_10026" smilref="Title.smil#_10026" /><p attribs="{'xml:space': 'preserve'}" id="_10027" smilref="Title.smil#_10027"> 576</p><p attribs="{'xml:space': 'preserve'}" id="_10028" smilref="Title.smil#_10028"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10029" smilref="Title.smil#_10029"> Cycles in digraphs. If job x must be completed before job y, job y before job z, and job z before job x, then someone has made a mistake, because those three constraints cannot all be satis&#64257; ed. In general, if a precedence-constrained scheduling problem has a directed cycle, then there is no feasible solution. To check for such errors, we need to be able to solve the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_10030" smilref="Title.smil#_10030"> Directed cycle detection. Does a given digraph have a directed cycle? If so, find the vertices on some such cycle, in order from some vertex back to itself. A graph may have an exponential number of cycles (see Exercise 4.2.11) so we only ask for one cycle, not all of them. For job scheduling and many other applications it is required that no directed cycle exists, so digraphs where they are absent play a special role:</p><p attribs="{'xml:space': 'preserve'}" id="_10031" smilref="Title.smil#_10031"> Definition. A directed acyclic graph (DAG) is a digraph with no directed cycles.</p><p attribs="{'xml:space': 'preserve'}" id="_10032" smilref="Title.smil#_10032"> Solving the directed cycle detection problem thus answers the following question: Is a given digraph a DAG ? Developing a depth-&#64257; rst-search-based solution to this problem is not dif&#64257; cult, based on the fact that the recursive call stack maintained by the system represents the &#8220;current&#8221; directed path under consideration (like the string back to the entrance in Tremaux maze exporation). If we ever find a directed edge v-&gt;w to a vertex w that is on that stack, we have found a cycle, since the stack is evidence of a directed path from w to v, and the edge v-&gt;w completes the cycle. Moreover, the absence of any such back edges implies that the graph is acyclic. DirectedCycle on the facing page uses this idea to implement the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_10033" smilref="Title.smil#_10033"> public class DirectedCycle</p><p attribs="{'xml:space': 'preserve'}" id="_10034" smilref="Title.smil#_10034"> DirectedCycle(Digraph G) boolean hasCycle() Iterable&lt;Integer&gt; cycle()</p><p attribs="{'xml:space': 'preserve'}" id="_10035" smilref="Title.smil#_10035"> cycle-fi nding constructor does G have a directed cycle? vertices on a cycle (if one exists)</p><p attribs="{'xml:space': 'preserve'}" id="_10036" smilref="Title.smil#_10036"> API for reachability in digraphs</p><p attribs="{'xml:space': 'preserve'}" id="_10037" smilref="Title.smil#_10037"> dfs(0) dfs(5) dfs(4) dfs(3) check 5</p><p attribs="{'xml:space': 'preserve'}" id="_10038" smilref="Title.smil#_10038"> marked[] edgeTo[] onStack[] 0 1 2 3 4 5 ... 0 1 2 3 4 5 ... 0 1 2 3 4 5 ...</p><p attribs="{'xml:space': 'preserve'}" id="_10039" smilref="Title.smil#_10039"> 1 0 0 0 0 0 - - - - - 0 1 0 0 0 0 0 1 0 0 0 0 1 - - - - 5 0 1 0 0 0 0 1 1 0 0 0 1 1 - - - 4 5 0 1 0 0 0 1 1 1 0 0 1 1 1 - - - 4 5 0 1 0 0 1 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_10040" smilref="Title.smil#_10040"> Finding a directed cycle in a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_10041" smilref="Title.smil#_10041" /><p attribs="{'xml:space': 'preserve'}" id="_10042" smilref="Title.smil#_10042"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10043" smilref="Title.smil#_10043"> 577</p><p attribs="{'xml:space': 'preserve'}" id="_10044" smilref="Title.smil#_10044"> Finding a directed cycle</p><p attribs="{'xml:space': 'preserve'}" id="_10045" smilref="Title.smil#_10045"> public class DirectedCycle { private boolean[] marked; private int[] edgeTo; private Stack&lt;Integer&gt; cycle; private boolean[] onStack;</p><p attribs="{'xml:space': 'preserve'}" id="_10046" smilref="Title.smil#_10046"> // vertices on a cycle (if one exists) // vertices on recursive call stack</p><p attribs="{'xml:space': 'preserve'}" id="_10047" smilref="Title.smil#_10047"> edgeTo[] 0 1 2 3 4 4 5 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_10048" smilref="Title.smil#_10048"> v w x cycle 3 5 3 3 3 5 4 4 3 3 5 5 4 3 3 5 5 5 4 3 3 5 5 3 5 4 3</p><p attribs="{'xml:space': 'preserve'}" id="_10049" smilref="Title.smil#_10049"> Trace of cycle computation</p><p attribs="{'xml:space': 'preserve'}" id="_10050" smilref="Title.smil#_10050"> public DirectedCycle(Digraph G) { onStack = new boolean[G.V()]; edgeTo = new int[G.V()]; marked = new boolean[G.V()]; for (int v = 0; v &lt; G.V(); v++) if (!marked[v]) dfs(G, v); } private void dfs(Digraph G, int v) { onStack[v] = true; marked[v] = true; for (int w : G.adj(v)) if (this.hasCycle()) return; else if (!marked[w]) { edgeTo[w] = v; dfs(G, w); } else if (onStack[w]) { cycle = new Stack&lt;Integer&gt;(); for (int x = v; x != w; x = edgeTo[x]) cycle.push(x); cycle.push(w); cycle.push(v); } onStack[v] = false; }</p><p attribs="{'xml:space': 'preserve'}" id="_10051" smilref="Title.smil#_10051"> public boolean hasCycle() { return cycle != null; }</p><p attribs="{'xml:space': 'preserve'}" id="_10052" smilref="Title.smil#_10052"> public Iterable&lt;Integer&gt; cycle() { return cycle; } }</p><p attribs="{'xml:space': 'preserve'}" id="_10053" smilref="Title.smil#_10053"> This class adds to our standard recursive dfs() a boolean array onStack[] to keep track of the vertices for which the recursive call has not completed. When it finds an edge v-&gt;w to a vertex w that is on the stack, it has discovered a directed cycle, which it can recover by following edgeTo[] links.</p><p attribs="{'xml:space': 'preserve'}" id="_10054" smilref="Title.smil#_10054" /><p attribs="{'xml:space': 'preserve'}" id="_10055" smilref="Title.smil#_10055"> 578</p><p attribs="{'xml:space': 'preserve'}" id="_10056" smilref="Title.smil#_10056"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10057" smilref="Title.smil#_10057"> When executing dfs(G, v), we have followed a directed path from the source to v. To keep track of this path, DirectedCycle maintains a vertex-indexed array onStack[] that marks the vertices on the recursive call stack (by setting onStack[v] to true on entry to dfs(G, v) and to false on exit). DirectedCycle also maintains an edgeTo[] array so that it can return the cycle when it is detected, in the same way as DepthFirstPaths (page 536) and BreadthFirstPaths (page 540) return paths.</p><p attribs="{'xml:space': 'preserve'}" id="_10058" smilref="Title.smil#_10058"> Depth-&#64257; rst orders and topological sort. Precedence-constrained scheduling amounts</p><p attribs="{'xml:space': 'preserve'}" id="_10059" smilref="Title.smil#_10059"> to computing a topological order for the vertices of a DAG, as in this API:</p><p attribs="{'xml:space': 'preserve'}" id="_10060" smilref="Title.smil#_10060"> public class Topological</p><p attribs="{'xml:space': 'preserve'}" id="_10061" smilref="Title.smil#_10061"> Topological(Digraph G) boolean isDAG() Iterable&lt;Integer&gt; order()</p><p attribs="{'xml:space': 'preserve'}" id="_10062" smilref="Title.smil#_10062"> topological-sorting constructor is G a DAG? vertices in topological order</p><p attribs="{'xml:space': 'preserve'}" id="_10063" smilref="Title.smil#_10063"> API for topological sorting</p><p attribs="{'xml:space': 'preserve'}" id="_10064" smilref="Title.smil#_10064"> Proposition E. A digraph has a topological order if and only if it is a DAG.</p><p attribs="{'xml:space': 'preserve'}" id="_10065" smilref="Title.smil#_10065"> Proof : If the digraph has a directed cycle, it has no topological order. Conversely, the algorithm that we are about to examine computes a topological order for any given DAG.</p><p attribs="{'xml:space': 'preserve'}" id="_10066" smilref="Title.smil#_10066"> Remarkably, it turns out that we have already seen an algorithm for topological sort: a one-line addition to our standard recursive DFS does the job! To convince you of this fact, we begin with the class DepthFirstOrder on page 580. It is based on the idea that depth-&#64257; rst search visits each vertex exactly once. If we save the vertex given as argument to the recursive dfs() in a data structure, then iterate through that data structure, we see all the graph vertices, in order determined by the nature of the data structure and by whether we do the save before or after the recursive calls. Three vertex orderings are of interest in typical applications: Preorder : Put the vertex on a queue before the recursive calls. </p><p attribs="{'xml:space': 'preserve'}" id="_10067" smilref="Title.smil#_10067"> </p><p attribs="{'xml:space': 'preserve'}" id="_10068" smilref="Title.smil#_10068"> </p><p attribs="{'xml:space': 'preserve'}" id="_10069" smilref="Title.smil#_10069" /><p attribs="{'xml:space': 'preserve'}" id="_10070" smilref="Title.smil#_10070"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10071" smilref="Title.smil#_10071"> 579</p><p attribs="{'xml:space': 'preserve'}" id="_10072" smilref="Title.smil#_10072"> p reo rd e r i s o rd e r o f dfs() ca l l s</p><p attribs="{'xml:space': 'preserve'}" id="_10073" smilref="Title.smil#_10073"> qu eu e</p><p attribs="{'xml:space': 'preserve'}" id="_10074" smilref="Title.smil#_10074"> pre</p><p attribs="{'xml:space': 'preserve'}" id="_10075" smilref="Title.smil#_10075"> 0 0 5 0 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10076" smilref="Title.smil#_10076"> 0 5 4 1</p><p attribs="{'xml:space': 'preserve'}" id="_10077" smilref="Title.smil#_10077"> 0 5 4 1 6 0 5 4 1 6 9 0 5 4 1 6 9 11 0 5 4 1 6 9 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_10078" smilref="Title.smil#_10078"> 0 5 4 1 6 9 11 12 10</p><p attribs="{'xml:space': 'preserve'}" id="_10079" smilref="Title.smil#_10079"> 0 5 4 1 6 9 11 12 10 2</p><p attribs="{'xml:space': 'preserve'}" id="_10080" smilref="Title.smil#_10080"> 0 5 4 1 6 9 11 12 10 2 3</p><p attribs="{'xml:space': 'preserve'}" id="_10081" smilref="Title.smil#_10081"> po s to rd e r i s o rd e r in wh i ch v e r t i c e s a re done</p><p attribs="{'xml:space': 'preserve'}" id="_10082" smilref="Title.smil#_10082"> post</p><p attribs="{'xml:space': 'preserve'}" id="_10083" smilref="Title.smil#_10083"> 4 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_10084" smilref="Title.smil#_10084"> 4 5 1</p><p attribs="{'xml:space': 'preserve'}" id="_10085" smilref="Title.smil#_10085"> reversePost</p><p attribs="{'xml:space': 'preserve'}" id="_10086" smilref="Title.smil#_10086"> qu eu e</p><p attribs="{'xml:space': 'preserve'}" id="_10087" smilref="Title.smil#_10087"> s ta ck</p><p attribs="{'xml:space': 'preserve'}" id="_10088" smilref="Title.smil#_10088"> 4 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10089" smilref="Title.smil#_10089"> 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10090" smilref="Title.smil#_10090"> 4 5 1 12 4 5 1 12 11</p><p attribs="{'xml:space': 'preserve'}" id="_10091" smilref="Title.smil#_10091"> 12 1 5 4 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10092" smilref="Title.smil#_10092"> 4 5 1 12 11 10</p><p attribs="{'xml:space': 'preserve'}" id="_10093" smilref="Title.smil#_10093"> 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10094" smilref="Title.smil#_10094"> 4 5 1 12 11 10 9</p><p attribs="{'xml:space': 'preserve'}" id="_10095" smilref="Title.smil#_10095"> 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10096" smilref="Title.smil#_10096"> 4 5 1 12 11 10 9 6 4 5 1 12 11 10 9 6 0</p><p attribs="{'xml:space': 'preserve'}" id="_10097" smilref="Title.smil#_10097"> 6 9 10 11 12 1 5 4 0 6 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10098" smilref="Title.smil#_10098"> 4 5 1 12 11 10 9 6 0 3</p><p attribs="{'xml:space': 'preserve'}" id="_10099" smilref="Title.smil#_10099"> 3 0 6 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10100" smilref="Title.smil#_10100"> 4 5 1 12 11 10 9 6 0 3 2</p><p attribs="{'xml:space': 'preserve'}" id="_10101" smilref="Title.smil#_10101"> 2 3 0 6 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10102" smilref="Title.smil#_10102"> 0 5 4 1 6 9 11 12 10 2 3 7</p><p attribs="{'xml:space': 'preserve'}" id="_10103" smilref="Title.smil#_10103"> 0 5 4 1 6 9 11 12 10 2 3 7 8</p><p attribs="{'xml:space': 'preserve'}" id="_10104" smilref="Title.smil#_10104"> 4 5 1 12 11 10 9 6 0 3 2 7</p><p attribs="{'xml:space': 'preserve'}" id="_10105" smilref="Title.smil#_10105"> 7 2 3 0 6 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10106" smilref="Title.smil#_10106"> 4 5 1 12 11 10 9 6 0 3 2 7 8</p><p attribs="{'xml:space': 'preserve'}" id="_10107" smilref="Title.smil#_10107"> 8 7 2 3 0 6 9 10 11 12 1 5 4</p><p attribs="{'xml:space': 'preserve'}" id="_10108" smilref="Title.smil#_10108"> re v e r s e po s to rd e r</p><p attribs="{'xml:space': 'preserve'}" id="_10109" smilref="Title.smil#_10109"> dfs(0) dfs(5) dfs(4) 4 done 5 done dfs(1) 1 done dfs(6) dfs(9) dfs(11) dfs(12) 12 done 11 done dfs(10) 10 done check 12 9 done check 4 6 done 0 done check 1 dfs(2) check 0 dfs(3) check 5 3 done 2 done check 3 check 4 check 5 check 6 dfs(7) check 6 7 done dfs(8) check 7 8 done check 9 check 10 check 11 check 12</p><p attribs="{'xml:space': 'preserve'}" id="_10110" smilref="Title.smil#_10110"> Computing depth-first orders in a digraph (preorder, postorder, and reverse postorder)</p><p attribs="{'xml:space': 'preserve'}" id="_10111" smilref="Title.smil#_10111" /></level3><level3 id="_00078"><h3 id="ch4-s2-ss12" smilref="Title.smil#ch4-s2-ss12" xml:space="preserve">Depth-first search</h3><pagenum id="p593" page="normal" smilref="Title.smil#p593" /><p attribs="{'xml:space': 'preserve'}" id="_10112" smilref="Title.smil#_10112"> 580</p><p attribs="{'xml:space': 'preserve'}" id="_10113" smilref="Title.smil#_10113"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10114" smilref="Title.smil#_10114"> Depth-first search vertex ordering in a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_10115" smilref="Title.smil#_10115"> public class DepthFirstOrder { private boolean[] marked;</p><p attribs="{'xml:space': 'preserve'}" id="_10116" smilref="Title.smil#_10116"> private Queue&lt;Integer&gt; pre; // vertices in preorder private Queue&lt;Integer&gt; post; // vertices in postorder private Stack&lt;Integer&gt; reversePost; // vertices in reverse postorder</p><p attribs="{'xml:space': 'preserve'}" id="_10117" smilref="Title.smil#_10117"> public DepthFirstOrder(Digraph G) { pre = new Queue&lt;Integer&gt;(); post = new Queue&lt;Integer&gt;(); reversePost = new Stack&lt;Integer&gt;(); marked = new boolean[G.V()];</p><p attribs="{'xml:space': 'preserve'}" id="_10118" smilref="Title.smil#_10118"> for (int v = 0; v &lt; G.V(); v++) if (!marked[v]) dfs(G, v); }</p><p attribs="{'xml:space': 'preserve'}" id="_10119" smilref="Title.smil#_10119"> private void dfs(Digraph G, int v) { pre.enqueue(v);</p><p attribs="{'xml:space': 'preserve'}" id="_10120" smilref="Title.smil#_10120"> marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w);</p><p attribs="{'xml:space': 'preserve'}" id="_10121" smilref="Title.smil#_10121"> post.enqueue(v); reversePost.push(v); }</p><p attribs="{'xml:space': 'preserve'}" id="_10122" smilref="Title.smil#_10122"> public Iterable&lt;Integer&gt; pre() { return pre; } public Iterable&lt;Integer&gt; post() { return post; } public Iterable&lt;Integer&gt; reversePost() { return reversePost; }</p><p attribs="{'xml:space': 'preserve'}" id="_10123" smilref="Title.smil#_10123"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10124" smilref="Title.smil#_10124"> This class enables clients to iterate through the vertices in various orders defined by depth-&#64257; rst search. This ability is very useful in the development of advanced digraph-processing algorithms, because the recursive nature of the search enables us to prove properties of the computation (see, for example,</p><p attribs="{'xml:space': 'preserve'}" id="_10125" smilref="Title.smil#_10125"> Proposition F).</p><p attribs="{'xml:space': 'preserve'}" id="_10126" smilref="Title.smil#_10126" /></level3><level3 id="_00079"><h3 id="ch4-s2-ss13" smilref="Title.smil#ch4-s2-ss13" xml:space="preserve">Topological sort</h3><pagenum id="p594" page="normal" smilref="Title.smil#p594" /><p attribs="{'xml:space': 'preserve'}" id="_10127" smilref="Title.smil#_10127"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10128" smilref="Title.smil#_10128"> 581</p><p attribs="{'xml:space': 'preserve'}" id="_10129" smilref="Title.smil#_10129"> ALGORITHM 4.5</p><p attribs="{'xml:space': 'preserve'}" id="_10130" smilref="Title.smil#_10130"> Topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_10131" smilref="Title.smil#_10131"> public class Topological { private Iterable&lt;Integer&gt; order;</p><p attribs="{'xml:space': 'preserve'}" id="_10132" smilref="Title.smil#_10132"> // topological order</p><p attribs="{'xml:space': 'preserve'}" id="_10133" smilref="Title.smil#_10133"> public Topological(Digraph G) { DirectedCycle cyclefinder = new DirectedCycle(G); if (!cyclefinder.hasCycle()) { DepthFirstOrder dfs = new DepthFirstOrder(G); order = dfs.reversePost(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_10134" smilref="Title.smil#_10134"> public Iterable&lt;Integer&gt; order() { return order; }</p><p attribs="{'xml:space': 'preserve'}" id="_10135" smilref="Title.smil#_10135"> public boolean isDAG() { return order != null; }</p><p attribs="{'xml:space': 'preserve'}" id="_10136" smilref="Title.smil#_10136"> public static void main(String[] args) { String filename = args[0]; String separator = args[1]; SymbolDigraph sg = new SymbolDigraph(filename, separator);</p><p attribs="{'xml:space': 'preserve'}" id="_10137" smilref="Title.smil#_10137"> Topological top = new Topological(sg.G());</p><p attribs="{'xml:space': 'preserve'}" id="_10138" smilref="Title.smil#_10138"> for (int v : top.order()) StdOut.println(sg.name(v)); }</p><p attribs="{'xml:space': 'preserve'}" id="_10139" smilref="Title.smil#_10139"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10140" smilref="Title.smil#_10140"> This DepthFirstOrder and DirectedCycle client returns a topological order for a DAG. The test client solves the precedence-constrained scheduling problem for a SymbolDigraph. The instance method order() returns null if the given digraph is not a DAG and an iterator giving the vertices in topological order otherwise. The code for SymbolDigraph is omitted because it is precisely the same as for SymbolGraph (page 552), with Digraph replacing Graph everywhere.</p><p attribs="{'xml:space': 'preserve'}" id="_10141" smilref="Title.smil#_10141" /><pagenum id="p595" page="normal" smilref="Title.smil#p595" /><p attribs="{'xml:space': 'preserve'}" id="_10142" smilref="Title.smil#_10142"> 582</p><p attribs="{'xml:space': 'preserve'}" id="_10143" smilref="Title.smil#_10143"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10144" smilref="Title.smil#_10144"> Proposition F. Reverse postorder in a DAG is a topological sort.</p><p attribs="{'xml:space': 'preserve'}" id="_10145" smilref="Title.smil#_10145"> Proof : Consider any edge v-&gt;w. One of the following three cases must hold when dfs(v) is called (see the diagram on page 583): </p><p attribs="{'xml:space': 'preserve'}" id="_10146" smilref="Title.smil#_10146"> % more jobs.txt Algorithms/Theoretical CS/Databases/Scientific Computing Introduction to CS/Advanced Programming/Algorithms Advanced Programming/Scientific Computing Scientific Computing/Computational Biology Theoretical CS/Computational Biology/Artificial Intelligence Linear Algebra/Theoretical CS Calculus/Linear Algebra Artificial Intelligence/Neural Networks/Robotics/Machine Learning Machine Learning/Neural Networks</p><p attribs="{'xml:space': 'preserve'}" id="_10147" smilref="Title.smil#_10147"> % java Topological jobs.txt "/" Calculus Linear Algebra Introduction to CS Advanced Programming Algorithms Theoretical CS Artificial Intelligence Robotics Machine Learning Neural Networks Databases Scientific Computing Computational Biology</p><p attribs="{'xml:space': 'preserve'}" id="_10148" smilref="Title.smil#_10148" /><pagenum id="p596" page="normal" smilref="Title.smil#p596" /><p attribs="{'xml:space': 'preserve'}" id="_10149" smilref="Title.smil#_10149"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10150" smilref="Title.smil#_10150"> 583</p><p attribs="{'xml:space': 'preserve'}" id="_10151" smilref="Title.smil#_10151"> dfs(5) fo r 0 &#8217;s unmarked  n e ig hbo r 5 i s don e b e fo re dfs(0) i s don e s o 0-&gt;5 po in t s up</p><p attribs="{'xml:space': 'preserve'}" id="_10152" smilref="Title.smil#_10152"> Topological (Algorithm 4.5 on page 581) is an implementation that uses depth-&#64257; rst search to topologically sort a DAG. A trace is given at right.</p><p attribs="{'xml:space': 'preserve'}" id="_10153" smilref="Title.smil#_10153"> Proposition G. With DFS, we can topologically sort a DAG in time proportional to V&#11001;E.</p><p attribs="{'xml:space': 'preserve'}" id="_10154" smilref="Title.smil#_10154"> Proof : Immediate from the code. It uses one depth-&#64257; rst search to ensure that the graph has no directed cycles, and another to do the reverse postorder ordering. Both involve examining all the edges and all the vertices, and thus take time proportional to V&#11001;E.</p><p attribs="{'xml:space': 'preserve'}" id="_10155" smilref="Title.smil#_10155"> Despite the simplicity of this algorithm, it escaped attention for many years, in favor of a more intuitive algorithm based on maintaining a queue of</p><p attribs="{'xml:space': 'preserve'}" id="_10156" smilref="Title.smil#_10156"> sources (see Exercise 4.2.30).</p><p attribs="{'xml:space': 'preserve'}" id="_10157" smilref="Title.smil#_10157"> In practice, topological sorting and cycle detection go hand in hand, with cycle detection playing the role of a debugging tool. For example, in a job-scheduling application, a directed cycle in the underlying digraph represents a mistake that must be corrected, no matter how the schedule was formulated. Thus, a job-scheduling application is typically a three-step process: </p><p attribs="{'xml:space': 'preserve'}" id="_10158" smilref="Title.smil#_10158"> dfs(0) dfs(5) dfs(4) 4 done 5 done dfs(1) 1 done dfs(6) dfs(9) dfs(11) dfs(12) 12 done 11 done dfs(10) 10 done check 12 9 done check 4 6 done 0 done check 1 dfs(2) check 0 dfs(3) check 5 3 done 2 done check 3 check 4 check 5 check 6 dfs(7) check 6 7 done dfs(8) check 7 8 done check 9 check 10 check 11 check 12</p><p attribs="{'xml:space': 'preserve'}" id="_10159" smilref="Title.smil#_10159"> dfs(6) fo r 7 &#8217;s ma rked n e ig hbo r 6 wa s don e b e fo re dfs(7) i s don e s o 7-&gt;6 po in t s up</p><p attribs="{'xml:space': 'preserve'}" id="_10160" smilref="Title.smil#_10160"> a l l edge  s po in t up ; tu rn up s id e dow n fo r a topo log i ca l s o r t</p><p attribs="{'xml:space': 'preserve'}" id="_10161" smilref="Title.smil#_10161"> re v e r s e po s to rd e r i s re v e r s e o f o rd e r in wh i ch v e r t i c e s a re don e ( read up )</p><p attribs="{'xml:space': 'preserve'}" id="_10162" smilref="Title.smil#_10162"> Reverse postorder in a DAG is a topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_10163" smilref="Title.smil#_10163" /></level3><level3 id="_00080"><h3 id="ch4-s2-ss14" smilref="Title.smil#ch4-s2-ss14" xml:space="preserve">Strong connectivity</h3><pagenum id="p597" page="normal" smilref="Title.smil#p597" /><p attribs="{'xml:space': 'preserve'}" id="_10164" smilref="Title.smil#_10164"> 584</p><p attribs="{'xml:space': 'preserve'}" id="_10165" smilref="Title.smil#_10165"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10166" smilref="Title.smil#_10166"> Strong connectivity in digraphs We have been careful to maintain a distinction between reachability in digraphs and connectivity in undirected graphs. In an undirected graph, two vertices v and w are connected if there is a path connecting them&#8212;we can use that path to get from v to w or to get from w to v. In a digraph, by contrast, a vertex w is reachable from a vertex v if there is a directed path from v to w, but there may or may not be a directed path back to v from w. To complete our study of digraphs, we consider the natural analog of connectivity in undirected graphs.</p><p attribs="{'xml:space': 'preserve'}" id="_10167" smilref="Title.smil#_10167"> Definition. Two vertices v and w are strongly connected if they are mutually reachable: that is, if there is a directed path from v to w and a directed path from w to v. A digraph is strongly connected if all its vertices are strongly connected to one another.</p><p attribs="{'xml:space': 'preserve'}" id="_10168" smilref="Title.smil#_10168"> Several examples of strongly connected graphs are given in the figure at left. As you can see from the examples, cycles play an important role in understanding strong connectivity. Indeed, recalling that a general directed cycle is a directed cycle that may have repeated vertices, it is easy to see that two vertices are strongly connected if and only if there exists a general directed cycle that contains them both. (Proof : compose the paths from v to w and from w to v.)</p><p attribs="{'xml:space': 'preserve'}" id="_10169" smilref="Title.smil#_10169"> Strongly connected digraphs</p><p attribs="{'xml:space': 'preserve'}" id="_10170" smilref="Title.smil#_10170"> Strong components. Like connectivity in undirected graphs, strong connectivity in digraphs is an equivalence relation on the set of vertices, as it has the following properties: </p><p attribs="{'xml:space': 'preserve'}" id="_10171" smilref="Title.smil#_10171"> A digraph and its strong components</p><p attribs="{'xml:space': 'preserve'}" id="_10172" smilref="Title.smil#_10172" /><pagenum id="p598" page="normal" smilref="Title.smil#p598" /><p attribs="{'xml:space': 'preserve'}" id="_10173" smilref="Title.smil#_10173"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10174" smilref="Title.smil#_10174"> 585</p><p attribs="{'xml:space': 'preserve'}" id="_10175" smilref="Title.smil#_10175"> connected digraph has 1 strong component and a DAG has V strong components. Note that the strong components are defined in terms of the vertices, not the edges. Some edges connect two vertices in the same strong component; some other edges connect vertices in different strong components. The latter are not found on any directed cycle. Just as identifying connected components is typically important in processing undirected graphs, identifying strong components is typically important in processing digraphs.</p><p attribs="{'xml:space': 'preserve'}" id="_10176" smilref="Title.smil#_10176"> edge</p><p attribs="{'xml:space': 'preserve'}" id="_10177" smilref="Title.smil#_10177"> hyperlink</p><p attribs="{'xml:space': 'preserve'}" id="_10178" smilref="Title.smil#_10178"> reference</p><p attribs="{'xml:space': 'preserve'}" id="_10179" smilref="Title.smil#_10179"> call predator-prey relationship</p><p attribs="{'xml:space': 'preserve'}" id="_10180" smilref="Title.smil#_10180"> Typical strong-component applications</p><p attribs="{'xml:space': 'preserve'}" id="_10181" smilref="Title.smil#_10181"> web</p><p attribs="{'xml:space': 'preserve'}" id="_10182" smilref="Title.smil#_10182"> module</p><p attribs="{'xml:space': 'preserve'}" id="_10183" smilref="Title.smil#_10183"> textbook</p><p attribs="{'xml:space': 'preserve'}" id="_10184" smilref="Title.smil#_10184"> soft ware</p><p attribs="{'xml:space': 'preserve'}" id="_10185" smilref="Title.smil#_10185"> application</p><p attribs="{'xml:space': 'preserve'}" id="_10186" smilref="Title.smil#_10186"> vertex</p><p attribs="{'xml:space': 'preserve'}" id="_10187" smilref="Title.smil#_10187"> page</p><p attribs="{'xml:space': 'preserve'}" id="_10188" smilref="Title.smil#_10188"> topic</p><p attribs="{'xml:space': 'preserve'}" id="_10189" smilref="Title.smil#_10189"> food web</p><p attribs="{'xml:space': 'preserve'}" id="_10190" smilref="Title.smil#_10190"> organism</p><p attribs="{'xml:space': 'preserve'}" id="_10191" smilref="Title.smil#_10191"> Examples of applications. Strong connectivity is a useful abstraction in understanding the structure of a digraph, highlighting interrelated sets of vertices (strong components). For example, strong components can help textbook authors decide which topics should be grouped together and software developers decide how to organize program modules. The figure below shows an example from ecology. It illustrates a digraph that models the food web connecting living organisms, where vertices represent species and an edge from one vertex to another indicates that an organism of the species indicated by the point from vertex consumes organisms of the species indicated by the point to vertex for food. Scienti&#64257; c studies on such digraphs (with carefully chosen sets of species and carefully documented relationships) play an important role in helping ecologists answer basic questions about ecological systems. Strong components in such digraphs can help ecologists understand energy flow in the food web. The figure on page 591 shows a digraph model of web content, where vertices represent pages and edges represent hyperlinks from one page to another. Strong components in such a digraph can help network engineers partition the huge number of pages on the web into more manageable sizes for processing. Further properties of these applications and other examples are addressed in the exercises and on the booksite.</p><p attribs="{'xml:space': 'preserve'}" id="_10192" smilref="Title.smil#_10192"> mosquito</p><p attribs="{'xml:space': 'preserve'}" id="_10193" smilref="Title.smil#_10193"> frog</p><p attribs="{'xml:space': 'preserve'}" id="_10194" smilref="Title.smil#_10194"> salamander</p><p attribs="{'xml:space': 'preserve'}" id="_10195" smilref="Title.smil#_10195"> algae</p><p attribs="{'xml:space': 'preserve'}" id="_10196" smilref="Title.smil#_10196"> worm</p><p attribs="{'xml:space': 'preserve'}" id="_10197" smilref="Title.smil#_10197"> snake</p><p attribs="{'xml:space': 'preserve'}" id="_10198" smilref="Title.smil#_10198"> fox</p><p attribs="{'xml:space': 'preserve'}" id="_10199" smilref="Title.smil#_10199"> egret</p><p attribs="{'xml:space': 'preserve'}" id="_10200" smilref="Title.smil#_10200"> fish</p><p attribs="{'xml:space': 'preserve'}" id="_10201" smilref="Title.smil#_10201"> shrew</p><p attribs="{'xml:space': 'preserve'}" id="_10202" smilref="Title.smil#_10202"> ant</p><p attribs="{'xml:space': 'preserve'}" id="_10203" smilref="Title.smil#_10203"> slug</p><p attribs="{'xml:space': 'preserve'}" id="_10204" smilref="Title.smil#_10204"> grass</p><p attribs="{'xml:space': 'preserve'}" id="_10205" smilref="Title.smil#_10205"> Small subset of food web digraph</p><p attribs="{'xml:space': 'preserve'}" id="_10206" smilref="Title.smil#_10206" /></level3><level3 id="_00081"><h3 id="ch4-s2-ss15" smilref="Title.smil#ch4-s2-ss15" xml:space="preserve">Kosaraju-Sharir algorithm</h3><pagenum id="p599" page="normal" smilref="Title.smil#p599" /><p attribs="{'xml:space': 'preserve'}" id="_10207" smilref="Title.smil#_10207"> 586</p><p attribs="{'xml:space': 'preserve'}" id="_10208" smilref="Title.smil#_10208"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10209" smilref="Title.smil#_10209"> Accordingly, we need the following API, the analog for digraphs of CC (page 543):</p><p attribs="{'xml:space': 'preserve'}" id="_10210" smilref="Title.smil#_10210"> public class SCC</p><p attribs="{'xml:space': 'preserve'}" id="_10211" smilref="Title.smil#_10211"> SCC(Digraph G) boolean stronglyConnected(int v, int w) are v and w strongly connected? int count()</p><p attribs="{'xml:space': 'preserve'}" id="_10212" smilref="Title.smil#_10212"> preprocessing constructor</p><p attribs="{'xml:space': 'preserve'}" id="_10213" smilref="Title.smil#_10213"> int id(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_10214" smilref="Title.smil#_10214"> API for strong components</p><p attribs="{'xml:space': 'preserve'}" id="_10215" smilref="Title.smil#_10215"> number of strong components component identifier  for v ( between 0 and count()-1 )</p><p attribs="{'xml:space': 'preserve'}" id="_10216" smilref="Title.smil#_10216"> A quadratic algorithm to compute strong components is not difficult to develop (see Exercise 4.2.31), but (as usual) quadratic time and space requirements are prohibitive for huge digraphs that arise in practical applications like the ones just described.</p><p attribs="{'xml:space': 'preserve'}" id="_10217" smilref="Title.smil#_10217"> Kosaraju&#8211;Sharir algorithm. We saw in CC (Algorithm 4.3 on page 544) that comput-</p><p attribs="{'xml:space': 'preserve'}" id="_10218" smilref="Title.smil#_10218"> ing connected components in undirected graphs is a simple application of depth-&#64257; rst search. How can we efficiently compute strong components in digraphs? Remarkably, the implementation KosarajuSharirSCC on the facing page does the job with just a few lines of code added to CC, as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_10219" smilref="Title.smil#_10219"> Kernel DAG</p><p attribs="{'xml:space': 'preserve'}" id="_10220" smilref="Title.smil#_10220" /><pagenum id="p600" page="normal" smilref="Title.smil#p600" /><p attribs="{'xml:space': 'preserve'}" id="_10221" smilref="Title.smil#_10221"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10222" smilref="Title.smil#_10222"> 587</p><p attribs="{'xml:space': 'preserve'}" id="_10223" smilref="Title.smil#_10223"> ALGORITHM 4.6 Kosaraju&#8211;Sharir algorithm for computing strong components</p><p attribs="{'xml:space': 'preserve'}" id="_10224" smilref="Title.smil#_10224"> public class KosarajuSharirSCC { private boolean[] marked; // reached vertices private int[] id; // component identifiers private int count; // number of strong components</p><p attribs="{'xml:space': 'preserve'}" id="_10225" smilref="Title.smil#_10225"> public KosarajuSharirSCC(Digraph G) { marked = new boolean[G.V()]; id = new int[G.V()]; DepthFirstOrder order = new DepthFirstOrder(G.reverse()); for (int s : order.reversePost()) if (!marked[s]) { dfs(G, s); count++; }</p><p attribs="{'xml:space': 'preserve'}" id="_10226" smilref="Title.smil#_10226"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10227" smilref="Title.smil#_10227"> private void dfs(Digraph G, int v) { marked[v] = true; id[v] = count; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w); }</p><p attribs="{'xml:space': 'preserve'}" id="_10228" smilref="Title.smil#_10228"> % java KosarajuSCC tinyDG.txt 5 strong components 1 0 2 3 4 5 9 10 11 12 6 8 7</p><p attribs="{'xml:space': 'preserve'}" id="_10229" smilref="Title.smil#_10229"> public boolean stronglyConnected(int v, int w) { return id[v] == id[w]; }</p><p attribs="{'xml:space': 'preserve'}" id="_10230" smilref="Title.smil#_10230"> public int id(int v) { return id[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_10231" smilref="Title.smil#_10231"> public int count() { return count; }</p><p attribs="{'xml:space': 'preserve'}" id="_10232" smilref="Title.smil#_10232"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10233" smilref="Title.smil#_10233"> This implementation differs from CC (Algorithm 4.3) only in the highlighted code (and in the implementation of main() where we use the code on page 543, with Graph changed to Digraph, CC changed</p><p attribs="{'xml:space': 'preserve'}" id="_10234" smilref="Title.smil#_10234"> to KosarajuSharirSCC, and &#8220;components&#8221; changed to &#8220;strong components&#8221;). To find strong com-</p><p attribs="{'xml:space': 'preserve'}" id="_10235" smilref="Title.smil#_10235"> ponents, it does a depth-&#64257; rst search in the reverse digraph to produce a vertex order (reverse postorder of that search) for use in a depth-&#64257; rst search of the given digraph.</p><p attribs="{'xml:space': 'preserve'}" id="_10236" smilref="Title.smil#_10236" /><pagenum id="p601" page="normal" smilref="Title.smil#p601" /><p attribs="{'xml:space': 'preserve'}" id="_10237" smilref="Title.smil#_10237"> 588</p><p attribs="{'xml:space': 'preserve'}" id="_10238" smilref="Title.smil#_10238"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10239" smilref="Title.smil#_10239"> f i r s t v e r t ex i s a s ink (ha s no edge  s po in t ing f rom i t)</p><p attribs="{'xml:space': 'preserve'}" id="_10240" smilref="Title.smil#_10240"> The Kosaraju-Sharir algorithm identifies the strong components in reverse topological order of the kernel DAG. It begins by finding a vertex that is in a sink component of the kernel DAG. When it runs DFS from that vertex, it visits precisely the vertices in that component. The DFS marks those ver- tices, effectively removing them from the digraph. Next, it finds a vertex that is in a sink component in the remaining kernel DAG, visits precisely the vertices in that component, and so forth. The postorder of G R enables us to examine the strong components in the desired order. The first vertex in a reverse postorder of G is in a source component of the kernel DAG; the first vertex in a reverse postorder of the reverse digraph G R is in a sink component of the kernel DAG (see Exercise 4.2.16). More generally, the following lemma relates the reverse postorder of G R to the strong components, based on edges in the kernel DAG: it is the key to establishing the correctness of the Kosaraju&#8211;Sharir algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_10241" smilref="Title.smil#_10241"> Kernel DAG in reverse topological order</p><p attribs="{'xml:space': 'preserve'}" id="_10242" smilref="Title.smil#_10242"> Postorder lemma. Let C be a strong component in a digraph G and let v be any vertex not in C. If there is an edge e pointing from any vertex in C to v, then vertex v appears before every vertex in C in the reverse postorder of G R.</p><p attribs="{'xml:space': 'preserve'}" id="_10243" smilref="Title.smil#_10243"> Proof : See Exercise 4.2.15.</p><p attribs="{'xml:space': 'preserve'}" id="_10244" smilref="Title.smil#_10244"> Proposition H. The Kosaraju&#8211;Sharir algorithm identifies the strong components of a digraph G.</p><p attribs="{'xml:space': 'preserve'}" id="_10245" smilref="Title.smil#_10245"> Proof : By induction on the number of strong components identified in the DFS of G. After the algorithm has identified the first i components, we assume (by our inductive hypothesis) that the vertices in the first i components are marked and the vertices in the remaining components are unmarked. Let s be the unmarked vertex that appears first in the reverse postorder of G R. Then, the constructor call dfs(G, s) will visit every vertex in the strong component containing s (which we refer to as component i+1) and only those vertices because: </p><p attribs="{'xml:space': 'preserve'}" id="_10246" smilref="Title.smil#_10246" /><pagenum id="p602" page="normal" smilref="Title.smil#p602" /><p attribs="{'xml:space': 'preserve'}" id="_10247" smilref="Title.smil#_10247"> DFS in reverse digraph GR</p><p attribs="{'xml:space': 'preserve'}" id="_10248" smilref="Title.smil#_10248"> DFS in original digraph G</p><p attribs="{'xml:space': 'preserve'}" id="_10249" smilref="Title.smil#_10249"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10250" smilref="Title.smil#_10250"> 589</p><p attribs="{'xml:space': 'preserve'}" id="_10251" smilref="Title.smil#_10251"> check unmarked vertices in the order 0 1 2 3 4 5 6 7 8 9 10 11 12</p><p attribs="{'xml:space': 'preserve'}" id="_10252" smilref="Title.smil#_10252"> check unmarked vertices in the order 1 0 2 4 5 3 11 9 12 10 6 7 8</p><p attribs="{'xml:space': 'preserve'}" id="_10253" smilref="Title.smil#_10253"> dfs(0) dfs(6) dfs(8) check 6 8 done dfs(7) 7 done 6 done dfs(2) dfs(4) dfs(11) dfs(9) dfs(12) check 11 dfs(10) check 9 10 done 12 done check 7 check 6 9 done 11 done check 6 dfs(5) dfs(3) check 4 check 2 3 done check 0 5 done 4 done check 3 2 done 0 done dfs(1) check 0 1 done check 2 check 3 check 4 check 5 check 6 check 7 check 8 check 9 check 10 check 11 check 12</p><p attribs="{'xml:space': 'preserve'}" id="_10254" smilref="Title.smil#_10254"> re v e r s e po s to rd e r fo r u s e in s e cond</p><p attribs="{'xml:space': 'preserve'}" id="_10255" smilref="Title.smil#_10255"> dfs()</p><p attribs="{'xml:space': 'preserve'}" id="_10256" smilref="Title.smil#_10256"> ( read up)</p><p attribs="{'xml:space': 'preserve'}" id="_10257" smilref="Title.smil#_10257"> s t rong compon en t s</p><p attribs="{'xml:space': 'preserve'}" id="_10258" smilref="Title.smil#_10258"> dfs(1) 1 done dfs(0) dfs(5) dfs(4) dfs(3) check 5 dfs(2) check 0 check 3 2 done 3 done check 2 4 done 5 done check 1 0 done check 2 check 4 check 5 check 3 dfs(11) check 4 dfs(12) dfs(9) check 11 dfs(10) check 12 10 done 9 done 12 done 11 done check 9 check 12 check 10 dfs(6) check 9 check 4 dfs(8) check 6 8 done check 0 6 done dfs(7) check 6 check 9 7 done check 8</p><p attribs="{'xml:space': 'preserve'}" id="_10259" smilref="Title.smil#_10259"> Kosaraju-Sharir algorithm for finding strong components in a digraph</p><p attribs="{'xml:space': 'preserve'}" id="_10260" smilref="Title.smil#_10260" /><pagenum id="p603" page="normal" smilref="Title.smil#p603" /><p attribs="{'xml:space': 'preserve'}" id="_10261" smilref="Title.smil#_10261"> 590</p><p attribs="{'xml:space': 'preserve'}" id="_10262" smilref="Title.smil#_10262"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10263" smilref="Title.smil#_10263"> A trace of the algorithm for tinyDG.txt is shown on the preceding page. To the right of each DFS trace is a drawing of the digraph, with vertices appearing in the order they are done. Thus, reading up the reverse digraph drawing on the left gives the reverse postorder in G R, the order in which unmarked vertices are checked in the DFS of G. As you can see from the diagram, the second DFS calls dfs(1) (which marks vertex 1) then calls dfs(0) (which marks 5, 4, 3, and 2), then checks 2, 4, 5, and 3, then calls dfs(11) (which marks 11, 12, 9, and 10), then checks 9, 12, and 10, then calls dfs(6) (which marks 6 and 8), and finally dfs(7), which marks 7.</p><p attribs="{'xml:space': 'preserve'}" id="_10264" smilref="Title.smil#_10264"> A larger example, a very small subset of a digraph model of the web, is shown on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_10265" smilref="Title.smil#_10265"> The Kosaraju&#8211;Sharir algorithm solves the following analog of the connectivity problem for undirected graphs that we first posed in Chapter 1 and reintroduced in Section 4.1 (page 534): Strong connectivity. Given a digraph, support queries of the form: Are two given vertices strongly connected ? and How many strong components does the digraph have ?</p><p attribs="{'xml:space': 'preserve'}" id="_10266" smilref="Title.smil#_10266"> That we can solve this problem in digraphs as efficiently as the corresponding connectivity problem in undirected graphs was an open research problem for some time (resolved by R. E. Tarjan in the early 1970s). That such a simple solution is now available is quite surprising.</p><p attribs="{'xml:space': 'preserve'}" id="_10267" smilref="Title.smil#_10267"> Proposition I. The Kosaraju&#8211;Sharir algorithm uses preprocessing time and space proportional to V&#11001;E to support constant-time strong connectivity queries in a digraph.</p><p attribs="{'xml:space': 'preserve'}" id="_10268" smilref="Title.smil#_10268"> Proof : The algorithm computes the reverse of the digraph and does two depth-&#64257; rst searches. Each of these three steps takes time proportional to V&#11001;E. The reverse copy of the digraph uses space proportional to V&#11001;E.</p><p attribs="{'xml:space': 'preserve'}" id="_10269" smilref="Title.smil#_10269" /><pagenum id="p604" page="normal" smilref="Title.smil#p604" /><p attribs="{'xml:space': 'preserve'}" id="_10270" smilref="Title.smil#_10270"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10271" smilref="Title.smil#_10271"> 591</p><p attribs="{'xml:space': 'preserve'}" id="_10272" smilref="Title.smil#_10272"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_10273" smilref="Title.smil#_10273"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_10274" smilref="Title.smil#_10274"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_10275" smilref="Title.smil#_10275"> 29</p><p attribs="{'xml:space': 'preserve'}" id="_10276" smilref="Title.smil#_10276"> 49</p><p attribs="{'xml:space': 'preserve'}" id="_10277" smilref="Title.smil#_10277"> 15</p><p attribs="{'xml:space': 'preserve'}" id="_10278" smilref="Title.smil#_10278"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_10279" smilref="Title.smil#_10279"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_10280" smilref="Title.smil#_10280"> 34</p><p attribs="{'xml:space': 'preserve'}" id="_10281" smilref="Title.smil#_10281"> 40</p><p attribs="{'xml:space': 'preserve'}" id="_10282" smilref="Title.smil#_10282"> 45</p><p attribs="{'xml:space': 'preserve'}" id="_10283" smilref="Title.smil#_10283"> 19</p><p attribs="{'xml:space': 'preserve'}" id="_10284" smilref="Title.smil#_10284"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_10285" smilref="Title.smil#_10285"> 14</p><p attribs="{'xml:space': 'preserve'}" id="_10286" smilref="Title.smil#_10286"> 21</p><p attribs="{'xml:space': 'preserve'}" id="_10287" smilref="Title.smil#_10287"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_10288" smilref="Title.smil#_10288"> 25</p><p attribs="{'xml:space': 'preserve'}" id="_10289" smilref="Title.smil#_10289"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_10290" smilref="Title.smil#_10290"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_10291" smilref="Title.smil#_10291"> 48</p><p attribs="{'xml:space': 'preserve'}" id="_10292" smilref="Title.smil#_10292"> 26</p><p attribs="{'xml:space': 'preserve'}" id="_10293" smilref="Title.smil#_10293"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_10294" smilref="Title.smil#_10294"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_10295" smilref="Title.smil#_10295"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_10296" smilref="Title.smil#_10296"> 43</p><p attribs="{'xml:space': 'preserve'}" id="_10297" smilref="Title.smil#_10297"> 28</p><p attribs="{'xml:space': 'preserve'}" id="_10298" smilref="Title.smil#_10298"> 39</p><p attribs="{'xml:space': 'preserve'}" id="_10299" smilref="Title.smil#_10299"> 18</p><p attribs="{'xml:space': 'preserve'}" id="_10300" smilref="Title.smil#_10300"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_10301" smilref="Title.smil#_10301"> 42</p><p attribs="{'xml:space': 'preserve'}" id="_10302" smilref="Title.smil#_10302"> 31</p><p attribs="{'xml:space': 'preserve'}" id="_10303" smilref="Title.smil#_10303"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_10304" smilref="Title.smil#_10304"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_10305" smilref="Title.smil#_10305"> 24</p><p attribs="{'xml:space': 'preserve'}" id="_10306" smilref="Title.smil#_10306"> 17</p><p attribs="{'xml:space': 'preserve'}" id="_10307" smilref="Title.smil#_10307"> 27</p><p attribs="{'xml:space': 'preserve'}" id="_10308" smilref="Title.smil#_10308"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_10309" smilref="Title.smil#_10309"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_10310" smilref="Title.smil#_10310"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_10311" smilref="Title.smil#_10311"> 36</p><p attribs="{'xml:space': 'preserve'}" id="_10312" smilref="Title.smil#_10312"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_10313" smilref="Title.smil#_10313"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_10314" smilref="Title.smil#_10314"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_10315" smilref="Title.smil#_10315"> 23</p><p attribs="{'xml:space': 'preserve'}" id="_10316" smilref="Title.smil#_10316"> 30</p><p attribs="{'xml:space': 'preserve'}" id="_10317" smilref="Title.smil#_10317"> 47</p><p attribs="{'xml:space': 'preserve'}" id="_10318" smilref="Title.smil#_10318"> 37</p><p attribs="{'xml:space': 'preserve'}" id="_10319" smilref="Title.smil#_10319"> 38</p><p attribs="{'xml:space': 'preserve'}" id="_10320" smilref="Title.smil#_10320"> 35</p><p attribs="{'xml:space': 'preserve'}" id="_10321" smilref="Title.smil#_10321"> 46</p><p attribs="{'xml:space': 'preserve'}" id="_10322" smilref="Title.smil#_10322"> How many strong components are there in this digraph?</p><p attribs="{'xml:space': 'preserve'}" id="_10323" smilref="Title.smil#_10323" /><pagenum id="p605" page="normal" smilref="Title.smil#p605" /><p attribs="{'xml:space': 'preserve'}" id="_10324" smilref="Title.smil#_10324"> 592</p><p attribs="{'xml:space': 'preserve'}" id="_10325" smilref="Title.smil#_10325"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10326" smilref="Title.smil#_10326"> 12 i s rea chab l e f rom 6</p><p attribs="{'xml:space': 'preserve'}" id="_10327" smilref="Title.smil#_10327"> o r ig ina l edge  ( red )</p><p attribs="{'xml:space': 'preserve'}" id="_10328" smilref="Title.smil#_10328"> 0 1 2 3 4 5 6 7 8 9 10 11 12 0 T T T T T T 1 T 2 T T T T T T 3 T T T T T T 4 T T T T T T 5 T T T T T T 6 T T T T T T T T T T T T 7 T T T T T T T T T T T T T 8 T T T T T T T T T T T T 9 T T T T T T T T T T 10 T T T T T T T T T T 11 T T T T T T T T T T 12 T T T T T T T T T T</p><p attribs="{'xml:space': 'preserve'}" id="_10329" smilref="Title.smil#_10329"> s e l f loop (g ray )</p><p attribs="{'xml:space': 'preserve'}" id="_10330" smilref="Title.smil#_10330"> Reachability revisited. With CC for undirected</p><p attribs="{'xml:space': 'preserve'}" id="_10331" smilref="Title.smil#_10331"> graphs, we can infer from the fact that two vertices v and w are connected that there is a path from v to w and a path (the same one) from w to v. With KosarajuSharirCC, we can infer from the fact that v and w are strongly connected that there is a path from v to w and a path (a different one) from w to v. But what about pairs of vertices that are not strongly connected? There may be a path from v to w or a path from w to v or neither, but not both.</p><p attribs="{'xml:space': 'preserve'}" id="_10332" smilref="Title.smil#_10332"> All-pairs reachability. Given a digraph, support</p><p attribs="{'xml:space': 'preserve'}" id="_10333" smilref="Title.smil#_10333"> queries of the form Is there a directed path from a given vertex v to another given vertex w?</p><p attribs="{'xml:space': 'preserve'}" id="_10334" smilref="Title.smil#_10334"> For undirected graphs, the corresponding problem is equivalent to the connectivity problem; for di- graphs, it is quite different from the strong connectivity problem. Our CC implementation uses linear preprocessing time to support constant-time answers to such queries for undirected graphs. Can we achieve this performance for digraphs? This seemingly innocuous question has confounded experts for decades. To better understand the challenge, consider the diagram at left, which illustrates the following fundamental concept:</p><p attribs="{'xml:space': 'preserve'}" id="_10335" smilref="Title.smil#_10335"> Transitive closure</p><p attribs="{'xml:space': 'preserve'}" id="_10336" smilref="Title.smil#_10336"> Definition. The transitive closure of a digraph G is another digraph with the same set of vertices, but with an edge from v to w in the transitive closure if and only if w is reachable from v in G.</p><p attribs="{'xml:space': 'preserve'}" id="_10337" smilref="Title.smil#_10337"> By convention, every vertex is reachable from itself, so the transitive closure has V self- loops. Our sample digraph has just 13 directed edges, but its transitive closure has 108 out of a possible 169 directed edges. Generally, the transitive closure of a digraph has many more edges than the digraph itself, and it is not at all unusual for a sparse graph to have a dense transitive closure. For example, the transitive closure of a V-vertex directed cycle, which has V directed edges, is a complete digraph with V2 directed edges. Since transitive closures are typically dense, we normally represent them with a matrix of boolean values, where the entry in row v and column w is true if and only if w is</p><p attribs="{'xml:space': 'preserve'}" id="_10338" smilref="Title.smil#_10338" /></level3><level3 id="_00082"><h3 id="ch4-s2-ss16" smilref="Title.smil#ch4-s2-ss16" xml:space="preserve">Transitive closure</h3><pagenum id="p606" page="normal" smilref="Title.smil#p606" /><p attribs="{'xml:space': 'preserve'}" id="_10339" smilref="Title.smil#_10339"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10340" smilref="Title.smil#_10340"> 593</p><p attribs="{'xml:space': 'preserve'}" id="_10341" smilref="Title.smil#_10341"> reachable from v. Instead of explicitly computing the transitive closure, we use depth- first search to implement the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_10342" smilref="Title.smil#_10342"> public class TransitiveClosure</p><p attribs="{'xml:space': 'preserve'}" id="_10343" smilref="Title.smil#_10343"> TransitiveClosure(Digraph G) boolean reachable(int v, int w)</p><p attribs="{'xml:space': 'preserve'}" id="_10344" smilref="Title.smil#_10344"> preprocessing constructor is w reachable from v?</p><p attribs="{'xml:space': 'preserve'}" id="_10345" smilref="Title.smil#_10345"> API for all-pairs reachability</p><p attribs="{'xml:space': 'preserve'}" id="_10346" smilref="Title.smil#_10346"> The code below is a straightforward implementation that uses DirectedDFS (Algo- rithm 4.4). This solution is ideal for small or dense digraphs, but it is not a solution for the large digraphs we might encounter in practice because the constructor uses space proportional to V2 and time proportional to V (V&#11001;E): each of the V DirectedDFS objects takes space proportional to V (they all have marked[] arrays of size V and examine E edges to compute the marks). Essentially, TransitiveClosure computes and stores the transitive closure of G, to support constant-time queries&#8212;row v in the transitive closure matrix is the marked[] array for the vth entry in the DirectedDFS[] in TransitiveClosure. Can we support constant-time queries with substantially less preprocessing time and substantially less space? A general solution that achieves con- stant-time queries with substantially less than quadratic space is an unsolved research problem, with important practical implications: for example, until it is solved, we cannot hope to have a practical solution to the all-pairs reachability problem for a giant digraph such as the web graph.</p><p attribs="{'xml:space': 'preserve'}" id="_10347" smilref="Title.smil#_10347"> public class TransitiveClosure { private DirectedDFS[] all; TransitiveClosure(Digraph G) { all = new DirectedDFS[G.V()]; for (int v = 0; v &lt; G.V(); v++) all[v] = new DirectedDFS(G, v); }</p><p attribs="{'xml:space': 'preserve'}" id="_10348" smilref="Title.smil#_10348"> boolean reachable(int v, int w) { return all[v].marked(w); }</p><p attribs="{'xml:space': 'preserve'}" id="_10349" smilref="Title.smil#_10349"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10350" smilref="Title.smil#_10350"> All-pairs reachability</p><p attribs="{'xml:space': 'preserve'}" id="_10351" smilref="Title.smil#_10351" /><pagenum id="p607" page="normal" smilref="Title.smil#p607" /><p attribs="{'xml:space': 'preserve'}" id="_10352" smilref="Title.smil#_10352"> 594</p><p attribs="{'xml:space': 'preserve'}" id="_10353" smilref="Title.smil#_10353"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10354" smilref="Title.smil#_10354"> Summary</p><p attribs="{'xml:space': 'preserve'}" id="_10355" smilref="Title.smil#_10355"> In this section, we have introduced directed edges and digraphs, emphasizing the relationship between digraph processing and corresponding problems for undirected graphs, as summarized in the following list of topics: </p><p attribs="{'xml:space': 'preserve'}" id="_10356" smilref="Title.smil#_10356"> problem</p><p attribs="{'xml:space': 'preserve'}" id="_10357" smilref="Title.smil#_10357"> single- and multiple-source reachability single-source directed paths single-source shortest directed paths directed cycle detection depth-fi rst vertex orders precedence-constrained scheduling topological sort strong connectivity all-pairs reachability</p><p attribs="{'xml:space': 'preserve'}" id="_10358" smilref="Title.smil#_10358"> solution</p><p attribs="{'xml:space': 'preserve'}" id="_10359" smilref="Title.smil#_10359"> DirectedDFS</p><p attribs="{'xml:space': 'preserve'}" id="_10360" smilref="Title.smil#_10360"> DepthFirstDirectedPaths</p><p attribs="{'xml:space': 'preserve'}" id="_10361" smilref="Title.smil#_10361"> reference</p><p attribs="{'xml:space': 'preserve'}" id="_10362" smilref="Title.smil#_10362"> page 571</p><p attribs="{'xml:space': 'preserve'}" id="_10363" smilref="Title.smil#_10363"> page 573</p><p attribs="{'xml:space': 'preserve'}" id="_10364" smilref="Title.smil#_10364"> BreadthFirstDirectedPaths page 573 DirectedCycle</p><p attribs="{'xml:space': 'preserve'}" id="_10365" smilref="Title.smil#_10365"> DepthFirstOrder</p><p attribs="{'xml:space': 'preserve'}" id="_10366" smilref="Title.smil#_10366"> Topological</p><p attribs="{'xml:space': 'preserve'}" id="_10367" smilref="Title.smil#_10367"> Topological</p><p attribs="{'xml:space': 'preserve'}" id="_10368" smilref="Title.smil#_10368"> KosarajuSharirSCC</p><p attribs="{'xml:space': 'preserve'}" id="_10369" smilref="Title.smil#_10369"> TransitiveClosure</p><p attribs="{'xml:space': 'preserve'}" id="_10370" smilref="Title.smil#_10370"> page 577 page 580 page 581 page 581 page 587 page 593</p><p attribs="{'xml:space': 'preserve'}" id="_10371" smilref="Title.smil#_10371"> Digraph-processing problems addressed in this section</p><p attribs="{'xml:space': 'preserve'}" id="_10372" smilref="Title.smil#_10372" /><pagenum id="p608" page="normal" smilref="Title.smil#p608" /><p attribs="{'xml:space': 'preserve'}" id="_10373" smilref="Title.smil#_10373"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10374" smilref="Title.smil#_10374"> 595</p><p attribs="{'xml:space': 'preserve'}" id="_10375" smilref="Title.smil#_10375"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_10376" smilref="Title.smil#_10376"> Q. Is a self-loop a cycle? A. Yes, but no self-loop is needed for a vertex to be reachable from itself.</p><p attribs="{'xml:space': 'preserve'}" id="_10377" smilref="Title.smil#_10377" /><pagenum id="p609" page="normal" smilref="Title.smil#p609" /><p attribs="{'xml:space': 'preserve'}" id="_10378" smilref="Title.smil#_10378"> 596</p><p attribs="{'xml:space': 'preserve'}" id="_10379" smilref="Title.smil#_10379"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10380" smilref="Title.smil#_10380"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_10381" smilref="Title.smil#_10381"> tinyDGex2.txt</p><p attribs="{'xml:space': 'preserve'}" id="_10382" smilref="Title.smil#_10382"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10383" smilref="Title.smil#_10383"> 12 16 8 4 2 3 0 5 0 6 3 6 10 3 7 11 7 8 11 8 2 0 6 2 5 2 5 10 3 10 8 1 4 1</p><p attribs="{'xml:space': 'preserve'}" id="_10384" smilref="Title.smil#_10384"> E</p><p attribs="{'xml:space': 'preserve'}" id="_10385" smilref="Title.smil#_10385"> 4.2.1 What is the maximum number of edges in a digraph with V vertices and no parallel edges? What is the minimum number of edges in a digraph with V vertices, none of which are isolated? 4.2.2 Draw, in the style of the figure in the text (page 524), the adjacency lists built by Digraph&#8217;s input stream constructor for the file tinyDGex2.txt depicted at left. 4.2.3 Create a copy constructor for Digraph that takes as input a digraph G and creates and initializes a new copy of the digraph. Any changes a client makes to G should not affect the newly created digraph. 4.2.4 Add a method hasEdge() to Digraph which takes two int arguments v and w and returns true if the graph has an edge v-&gt;w, false otherwise. 4.2.5 Modify Digraph to disallow parallel edges and self-loops. 4.2.6 Develop a test client for Digraph. 4.2.7 The indegree of a vertex in a digraph is the number of directed edges that point to that vertex. The outdegree of a vertex in a digraph is the number of directed edges that emanate from that vertex. No vertex is reachable from a vertex of outdegree 0, which is called a sink; a vertex of indegree 0, which is called a source, is not reachable from any other vertex. A digraph where self-loops are allowed and every vertex has outdegree 1 is called a map (a function from the set of integers from 0 to V&#8211;1 onto itself ). Write a program Degrees.java that implements the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_10386" smilref="Title.smil#_10386"> public class Degrees</p><p attribs="{'xml:space': 'preserve'}" id="_10387" smilref="Title.smil#_10387"> Degrees(Digraph G) int indegree(int v) int outdegree(int v) Iterable&lt;Integer&gt; sources() Iterable&lt;Integer&gt; sinks() boolean isMap()</p><p attribs="{'xml:space': 'preserve'}" id="_10388" smilref="Title.smil#_10388"> constructor indegree of v outdegree of v sources sinks is G a map?</p><p attribs="{'xml:space': 'preserve'}" id="_10389" smilref="Title.smil#_10389" /><pagenum id="p610" page="normal" smilref="Title.smil#p610" /><p attribs="{'xml:space': 'preserve'}" id="_10390" smilref="Title.smil#_10390"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10391" smilref="Title.smil#_10391"> 597</p><p attribs="{'xml:space': 'preserve'}" id="_10392" smilref="Title.smil#_10392"> 4.2.8 Draw all the nonisomorphic DAGs with two, three, four, and five vertices (see</p><p attribs="{'xml:space': 'preserve'}" id="_10393" smilref="Title.smil#_10393"> Exercise 4.1.28).</p><p attribs="{'xml:space': 'preserve'}" id="_10394" smilref="Title.smil#_10394"> 4.2.9 Write a method that checks whether a given permutation of a DAG&#8217;s vertices is a topological order of that DAG. 4.2.10 Given a DAG, does there exist a topological order that cannot result from applying a DFS-based algorithm, no matter in what order the vertices adjacent to each vertex are chosen? Prove your answer. 4.2.11 Describe a family of sparse digraphs whose number of directed cycles grows exponentially in the number of vertices. 4.2.12 Prove that the strong components in GR are the same as in G. 4.2.13 Prove that two vertices in a digraph G are in the same strong component if and only if there is a directed cycle (not necessarily simple) containing both of them. 4.2.14 Let C be a strong component in a digraph G and let v be any vertex not in C. Prove that if there is an edge e pointing from v to any vertex in C, then vertex v appears before every vertex in C in the reverse postorder of G .</p><p attribs="{'xml:space': 'preserve'}" id="_10395" smilref="Title.smil#_10395"> Solution : If v is visited before every vertex in C, then every vertex in C will be visited and finished before v finishes (because every vertex in C is reachable from v via edge e). If some vertex in C is visited before v, then all vertices in C will be visited and finished before v is visited (because v is not reachable from any vertex in C&#8212;if it were, such a path when combined with edge e would be part of a directed cycle, implying that v is in C). 4.2.15 Let C be a strong component in a digraph G and let v be any vertex not in C. Prove that if there is an edge e pointing from any vertex in C to v, then vertex v appears before every vertex in C in the reverse postorder of G R. Solution : Apply Exercise 4.2.14 to GR. 4.2.16 Given a digraph G, prove that the first vertex in the reverse postorder of G is in a strong component that is a source of G&#8217;s kernel DAG. Then, prove that the first vertex in the reverse postorder of GR is in a strong component that is a sink of G&#8217;s kernel DAG.</p><p attribs="{'xml:space': 'preserve'}" id="_10396" smilref="Title.smil#_10396"> Hint : Apply Exercises 4.2.14 and 4.2.15.</p><p attribs="{'xml:space': 'preserve'}" id="_10397" smilref="Title.smil#_10397" /><pagenum id="p611" page="normal" smilref="Title.smil#p611" /><p attribs="{'xml:space': 'preserve'}" id="_10398" smilref="Title.smil#_10398"> 598</p><p attribs="{'xml:space': 'preserve'}" id="_10399" smilref="Title.smil#_10399"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10400" smilref="Title.smil#_10400"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_10401" smilref="Title.smil#_10401"> 4.2.17 How many strong components are there in the digraph on page 591? 4.2.18 What are the strong components of a DAG? 4.2.19 What happens if you run the Kosaraju&#8211;Sharir algorithm on a DAG? 4.2.20 True or false: The reverse postorder of a digraph&#8217;s reverse is the same as the postorder of the digraph. 4.2.21 True or false: If we consider the vertices of a digraph G (or its reverse GR) in postorder, then vertices in the same strong component will be consecutive in that order.</p><p attribs="{'xml:space': 'preserve'}" id="_10402" smilref="Title.smil#_10402"> Solution : False. In tinyDG.txt, vertices 6 and 8 form a strong component, but they are not consecutive in the postorder of GR. 4.2.22 True or false: If we modify the Kosaraju&#8211;Sharir algorithm to run first depth-&#64257; rst search in the digraph G (instead of the reverse digraph GR) and the second depth-&#64257; rst search in GR (instead of G), then it will still find the strong components. 4.2.23 True or false: If we modify the Kosaraju&#8211;Sharir algorithm to replace the second depth-&#64257; rst search with breadth-&#64257; rst search, then it will still find the strong components. 4.2.24 Compute the memory usage of a Digraph with V vertices and E edges, under the memory cost model of Section 1.4. 4.2.25 How many edges are there in the transitive closure of a digraph that is a simple directed path with V vertices and V&#8211;1 edges? 4.2.26 Give the transitive closure of the digraph with ten vertices and these edges:</p><p attribs="{'xml:space': 'preserve'}" id="_10403" smilref="Title.smil#_10403"> 3-&gt;7 1-&gt;4 7-&gt;8 0-&gt;5 5-&gt;2 3-&gt;8 2-&gt;9 0-&gt;6 4-&gt;9 2-&gt;6 6-&gt;4</p><p attribs="{'xml:space': 'preserve'}" id="_10404" smilref="Title.smil#_10404" /><pagenum id="p612" page="normal" smilref="Title.smil#p612" /><p attribs="{'xml:space': 'preserve'}" id="_10405" smilref="Title.smil#_10405"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10406" smilref="Title.smil#_10406"> 599</p><p attribs="{'xml:space': 'preserve'}" id="_10407" smilref="Title.smil#_10407"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_10408" smilref="Title.smil#_10408"> 4.2.27 Topological sort and BFS. Explain why the following algorithm does not necessarily produce a topological order: Run BFS, and label the vertices by increasing distance to their respective source. 4.2.28 Directed Eulerian cycle. An directed Eulerian cycle is a directed cycle that contains each edge exactly once. Write a digraph client Euler that finds a directed Eulerian cycle or reports that no such cycle exists. Hint : Prove that a digraph G has a directed Eulerian cycle if and only if G is connected and each vertex has its indegree equal to its outdegree. 4.2.29 LCA of a DAG. Given a DAG and two vertices v and w, find the lowest common ancestor (LCA) of v and w. The LCA of v and w is an ancestor of v and w that has no descendants that are also ancestors of v and w. Computing the LCA is useful in multiple inheritance in programming languages, analysis of genealogical data (&#64257; nd degree of inbreeding in a pedigree graph), and other applications. Hint : De&#64257; ne the height of a vertex v in a DAG to be the length of the longest path from a root to v. Among vertices that are ancestors of both v and w, the one with the greatest height is an LCA of v and w. 4.2.30 Shortest ancestral path. Given a DAG and two vertices v and w, find the shortest ancestral path between v and w. An ancestral path between v and w is a common ancestor x along with a shortest path from v to x and a shortest path from w to x. The shortest ancestral path is the ancestral path whose total length is minimized. Warmup: Find a DAG where the shortest ancestral path goes to a common ancestor x that is not an LCA. Hint: Run BFS twice, once from v and once from w. 4.2.31 Strong component. Describe a linear-time algorithm for computing the strong component containing a given vertex v. On the basis of that algorithm, describe a simple quadratic-time algorithm for computing the strong components of a digraph. 4.2.32 Hamiltonian path in DAGs. Given a DAG, design a linear-time algorithm to determine whether there is a directed path that visits each vertex exactly once.</p><p attribs="{'xml:space': 'preserve'}" id="_10409" smilref="Title.smil#_10409"> Solution : Compute a topological sort and check if there is an edge between each consecutive pair of vertices in the topological order.</p><p attribs="{'xml:space': 'preserve'}" id="_10410" smilref="Title.smil#_10410" /><pagenum id="p613" page="normal" smilref="Title.smil#p613" /><p attribs="{'xml:space': 'preserve'}" id="_10411" smilref="Title.smil#_10411"> 600</p><p attribs="{'xml:space': 'preserve'}" id="_10412" smilref="Title.smil#_10412"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10413" smilref="Title.smil#_10413"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_10414" smilref="Title.smil#_10414"> 4.2.33 Unique topological ordering. Design an algorithm to determine whether a digraph has a unique topological ordering. Hint : A digraph has a unique topological ordering if and only if there is a directed edge between each pair of consecutive vertices in the topological order (i.e., the digraph has a Hamiltonian path). If the digraph has multiple topological orderings, then a second topological order can be obtained by swapping a pair of consecutive vertices. 4.2.34 2-satis&#64257; ability. Given a boolean formula in conjunctive normal form with M clauses and N literals such that each clause has exactly two literals, find a satisfying assignment (if one exists). Hint : Form the implication digraph with 2N vertices (one per literal and its negation). For each clause x + y, include edges from y' to x and from x' to y. Claim: The formula is satisfiable if and only if no variable x is in the same strong component as its negation x'. Moreover, a topological sort of the kernel DAG (contract each strong component to a single vertex) yields a satisfying assignment. 4.2.35 Digraph enumeration. Show that the number of different V-vertex digraphs with no parallel edges is 2V 2 . (How many digraphs are there that contain V vertices and E edges?) Then compute an upper bound on the percentage of 20-vertex digraphs that could ever be examined by any computer, under the assumptions that every electron in the universe examines a digraph every nanosecond, that the universe has fewer than 1080 electrons, and that the age of the universe will be less than 1020 years. 4.2.36 DAG enumeration. Give a formula for the number of V-vertex DAGs with E edges. 4.2.37 Arithmetic expressions. Write a class that evaluates DAGs that represent arithmetic expressions. Use a vertex-indexed array to hold values corresponding to each vertex. Assume that values corresponding to leaves have been established. Describe a family of arithmetic expressions with the property that the size of the expression tree is exponentially larger than the size of the corresponding DAG (so the running time of your program for the DAG is proportional to the logarithm of the running time for the tree). 4.2.38 Euclidean digraphs. Modify your solution to Exercise 4.1.37 to create an API EuclideanDigraph for graphs whose vertices are points in the plane, so that you can work with graphical representations.</p><p attribs="{'xml:space': 'preserve'}" id="_10415" smilref="Title.smil#_10415" /><pagenum id="p614" page="normal" smilref="Title.smil#p614" /><p attribs="{'xml:space': 'preserve'}" id="_10416" smilref="Title.smil#_10416"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10417" smilref="Title.smil#_10417"> 601</p><p attribs="{'xml:space': 'preserve'}" id="_10418" smilref="Title.smil#_10418"> 4.2.39 Queue-based topological sort. Develop a topological sort implementation that maintains a vertex-indexed array that keeps track of the indegree of each vertex. Initial- ize the array and a queue of sources in a single pass through all the edges, as in Exercise 4.2.7. Then, perform the following operations until the source queue is empty : </p><p attribs="{'xml:space': 'preserve'}" id="_10419" smilref="Title.smil#_10419" /><pagenum id="p615" page="normal" smilref="Title.smil#p615" /><p attribs="{'xml:space': 'preserve'}" id="_10420" smilref="Title.smil#_10420"> 602</p><p attribs="{'xml:space': 'preserve'}" id="_10421" smilref="Title.smil#_10421"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10422" smilref="Title.smil#_10422"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_10423" smilref="Title.smil#_10423"> 4.2.45 Random digraphs. Write a program ErdosRenyiDigraph that takes integer values V and E from the command line and builds a digraph by generating E random pairs of integers between 0 andV&#11002;1. Note: This generator produces self-loops and parallel edges. 4.2.46 Random simple digraphs. Write a program RandomDigraph that takes integer values V and E from the command line and produces, with equal likelihood, each of the possible simple digraphs with V vertices and E edges. 4.2.47 Random sparse digraphs. Modify your solution to Exercise 4.1.41 to create a program RandomSparseDigraph that generates random sparse digraphs for a wellchosen set of values of V and E that you can use it to run meaningful empirical tests. 4.2.48 Random Euclidean digraphs. Modify your solution to Exercise 4.1.42 to create a EuclideanDigraph client RandomEuclideanDigraph that assigns a random direction to each edge. 4.2.49 Random grid digraphs. Modify your solution to Exercise 4.1.43 to create a EuclideanDiGraph client RandomGridDigraph that assigns a random direction to each edge. 4.2.50 Real-world digraphs. Find a large digraph somewhere online&#8212;perhaps a transaction graph in some online system, or a digraph defined by links on web pages. Write a program RandomRealDigraph that builds a graph by choosing V vertices at random and E directed edges at random from the subgraph induced by those vertices. 4.2.51 Real-world DAG. Find a large DAG somewhere online&#8212;perhaps one defined by class-de&#64257; nition dependencies in a large software system, or by directory links in a large file system. Write a program RandomRealDAG that builds a graph by choosing V vertices at random and E directed edges at random from the subgraph induced by those vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10424" smilref="Title.smil#_10424" /><pagenum id="p616" page="normal" smilref="Title.smil#p616" /><p attribs="{'xml:space': 'preserve'}" id="_10425" smilref="Title.smil#_10425"> 4.2 </p><p attribs="{'xml:space': 'preserve'}" id="_10426" smilref="Title.smil#_10426"> 603</p><p attribs="{'xml:space': 'preserve'}" id="_10427" smilref="Title.smil#_10427"> Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</p><p attribs="{'xml:space': 'preserve'}" id="_10428" smilref="Title.smil#_10428"> 4.2.52 Reachability. Run experiments to determine empirically the average number of vertices that are reachable from a randomly chosen vertex, for various digraph models. 4.2.53 Path lengths in DFS. Run experiments to determine empirically the probability that DepthFirstDirectedPaths finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various random digraph models. 4.2.54 Path lengths in BFS. Run experiments to determine empirically the probability that BreadthFirstDirectedPaths finds a path between two randomly chosen vertices and to calculate the average length of the paths found, for various random digraph models. 4.2.55 Strong components. Run experiments to determine empirically the distribution of the number of strong components in random digraphs of various types, by generating large numbers of digraphs and drawing a histogram.</p><p attribs="{'xml:space': 'preserve'}" id="_10429" smilref="Title.smil#_10429" /><pagenum id="p618" page="normal" smilref="Title.smil#p618" /><p attribs="{'xml:space': 'preserve'}" id="_10430" smilref="Title.smil#_10430"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10431" smilref="Title.smil#_10431"> 605</p><p attribs="{'xml:space': 'preserve'}" id="_10432" smilref="Title.smil#_10432"> no MST if graph is not connected</p><p attribs="{'xml:space': 'preserve'}" id="_10433" smilref="Title.smil#_10433"> 4 5 0.61 4 6 0.62 5 6 0.88 1 5 0.11 2 3 0.35 0 3 0.6 1 6 0.10 0 2 0.22 can independently compute MSTs of components</p><p attribs="{'xml:space': 'preserve'}" id="_10434" smilref="Title.smil#_10434"> weights need not be proportional to distance</p><p attribs="{'xml:space': 'preserve'}" id="_10435" smilref="Title.smil#_10435"> Assumptions. Various anomalous situations, which are generally easy to handle, can arise when computing minimum spanning trees. To streamline the presentation, we adopt the following conventions: </p><p attribs="{'xml:space': 'preserve'}" id="_10436" smilref="Title.smil#_10436"> MST may not be unique when weights have equal values</p><p attribs="{'xml:space': 'preserve'}" id="_10437" smilref="Title.smil#_10437"> weights can be 0 or negative</p><p attribs="{'xml:space': 'preserve'}" id="_10438" smilref="Title.smil#_10438"> 4 6 0.62 5 6 0.88 1 5 0.02 0 4 0.64 1 6 0.90 0 2 0.22 1 2 0.50 1 3 0.97 2 6 0.17</p><p attribs="{'xml:space': 'preserve'}" id="_10439" smilref="Title.smil#_10439"> 4 6 0.62 5 6 0.88 1 5 0.02 0 4 -0.99 1 6 0 0 2 0.22 1 2 0.50 1 3 0.97 2 6 0.17</p><p attribs="{'xml:space': 'preserve'}" id="_10440" smilref="Title.smil#_10440"> 1 2 1.00 1 3 0.50 2 4 1.00 3 4 0.50</p><p attribs="{'xml:space': 'preserve'}" id="_10441" smilref="Title.smil#_10441"> 1 2 1.00 1 3 0.50 2 4 1.00 3 4 0.50</p><p attribs="{'xml:space': 'preserve'}" id="_10442" smilref="Title.smil#_10442"> Various MST anomalies</p><p attribs="{'xml:space': 'preserve'}" id="_10443" smilref="Title.smil#_10443" /></level3><level3 id="_00083"><h3 id="ch4-s3-ss17" smilref="Title.smil#ch4-s3-ss17" xml:space="preserve">Cut property</h3><pagenum id="p619" page="normal" smilref="Title.smil#p619" /><p attribs="{'xml:space': 'preserve'}" id="_10444" smilref="Title.smil#_10444"> 606</p><p attribs="{'xml:space': 'preserve'}" id="_10445" smilref="Title.smil#_10445"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10446" smilref="Title.smil#_10446"> Underlying principles To begin, we recall from Sec-</p><p attribs="{'xml:space': 'preserve'}" id="_10447" smilref="Title.smil#_10447"> tion 4.1 two of the defining properties of a tree: </p><p attribs="{'xml:space': 'preserve'}" id="_10448" smilref="Title.smil#_10448"> Cut property. This property, which we refer to as the cut property, has to do with identifying edges that must be in the MST of a given edge-weighted graph, by dividing vertices into two sets and examining edges that cross the division.</p><p attribs="{'xml:space': 'preserve'}" id="_10449" smilref="Title.smil#_10449"> adding an edge creates a cycle</p><p attribs="{'xml:space': 'preserve'}" id="_10450" smilref="Title.smil#_10450"> removing an edge breaks tree into two parts</p><p attribs="{'xml:space': 'preserve'}" id="_10451" smilref="Title.smil#_10451"> Basic properties of a tree</p><p attribs="{'xml:space': 'preserve'}" id="_10452" smilref="Title.smil#_10452"> Definition. A cut of a graph is a partition of its vertices into two nonempty disjoint sets. A crossing edge of a cut is an edge that connects a vertex in one set with a vertex in the other.</p><p attribs="{'xml:space': 'preserve'}" id="_10453" smilref="Title.smil#_10453"> Typically, we specify a cut by specifying a set of vertices, leaving implicit the assumption that the cut comprises the given vertex set and its complement, so that a crossing edge is an edge from a vertex in the set to a vertex not in the set. In fi gures, we draw vertices on one side of the cut in gray and vertices on the other side in white.</p><p attribs="{'xml:space': 'preserve'}" id="_10454" smilref="Title.smil#_10454"> crossing edges separating gray from white vertices are drawn in red</p><p attribs="{'xml:space': 'preserve'}" id="_10455" smilref="Title.smil#_10455"> f</p><p attribs="{'xml:space': 'preserve'}" id="_10456" smilref="Title.smil#_10456"> e</p><p attribs="{'xml:space': 'preserve'}" id="_10457" smilref="Title.smil#_10457"> minimum-weight crossing edge must be in the MST</p><p attribs="{'xml:space': 'preserve'}" id="_10458" smilref="Title.smil#_10458"> Cut property</p><p attribs="{'xml:space': 'preserve'}" id="_10459" smilref="Title.smil#_10459"> Proposition J. ( Cut property) Given any cut in an edge-</p><p attribs="{'xml:space': 'preserve'}" id="_10460" smilref="Title.smil#_10460"> weighted graph, the crossing edge of minimum weight is in the MST of the graph.</p><p attribs="{'xml:space': 'preserve'}" id="_10461" smilref="Title.smil#_10461"> Proof : Let e be the crossing edge of minimum weight and let T be the MST. The proof is by contradiction: Suppose that T does not contain e. Now consider the graph formed by adding e to T. This graph has a cycle that contains e, and that cycle must contain at least one other crossing edge&#8212; say, f, which has higher weight than e (since e is minimal and all edge weights are different). We can get a spanning tree of strictly lower weight by deleting f and adding e, contradicting the assumed minimality of T.</p><p attribs="{'xml:space': 'preserve'}" id="_10462" smilref="Title.smil#_10462" /></level3><level3 id="_00084"><h3 id="ch4-s3-ss18" smilref="Title.smil#ch4-s3-ss18" xml:space="preserve">Greedy algorithm</h3><pagenum id="p620" page="normal" smilref="Title.smil#p620" /><p attribs="{'xml:space': 'preserve'}" id="_10463" smilref="Title.smil#_10463"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10464" smilref="Title.smil#_10464"> 607</p><p attribs="{'xml:space': 'preserve'}" id="_10465" smilref="Title.smil#_10465"> in MST</p><p attribs="{'xml:space': 'preserve'}" id="_10466" smilref="Title.smil#_10466"> minimum edge in cut</p><p attribs="{'xml:space': 'preserve'}" id="_10467" smilref="Title.smil#_10467"> A cut with two MST edges</p><p attribs="{'xml:space': 'preserve'}" id="_10468" smilref="Title.smil#_10468"> Under our assumption that edge weights are distinct, every connected graph has a unique MST (see Exercise 4.3.3); and the cut property says that the shortest crossing edge for every cut must be in the MST. The figure to the left of Proposition J illustrates the cut property. Note that there is no requirement that the minimal edge be the only MST edge connecting the two sets; indeed, for typical cuts there are several MST edges that connect a vertex in one set with a vertex in the other, as illustrated in the figure above.</p><p attribs="{'xml:space': 'preserve'}" id="_10469" smilref="Title.smil#_10469"> Greedy algorithm. The cut property is the basis for the algorithms that we consider for the MST problem. Speci&#64257; cally, they are special cases of a general paradigm known as the greedy algorithm: apply the cut property to accept an edge as an MST edge, continuing until fi nd- ing all of the MST edges. Our algorithms differ in their approaches to maintaining cuts and identifying the crossing edge of minimum weight, but are special cases of the following:</p><p attribs="{'xml:space': 'preserve'}" id="_10470" smilref="Title.smil#_10470"> Proposition K. ( Greedy MST algorithm) The following method</p><p attribs="{'xml:space': 'preserve'}" id="_10471" smilref="Title.smil#_10471"> colors black all edges in the the MST of any connected edge- weighted graph with V vertices: starting with all edges colored gray, find a cut with no black edges, color its minimum-weight edge black, and continue until V&#11002;1 edges have been colored black.</p><p attribs="{'xml:space': 'preserve'}" id="_10472" smilref="Title.smil#_10472"> Proof : For simplicity, we assume in the discussion that the edge weights are all different, though the proposition is still true when that is not the case (see Exercise 4.3.5). By the cut property, any edge that is colored black is in the MST. If fewer than V&#11002;1 edges are black, a cut with no black edges exists (recall that we assume the graph to be connected). Once V&#11002;1 edges are black, the black edges form a spanning tree.</p><p attribs="{'xml:space': 'preserve'}" id="_10473" smilref="Title.smil#_10473"> The diagram at right is a typical trace of the greedy algorithm. Each drawing depicts a cut and identifies the minimum-weight edge in the cut (thick red) that is added to the MST by the algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_10474" smilref="Title.smil#_10474"> Greedy MST algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10475" smilref="Title.smil#_10475" /></level3><level3 id="_00085"><h3 id="ch4-s3-ss19" smilref="Title.smil#ch4-s3-ss19" xml:space="preserve">Edge-weighted graph data type</h3><pagenum id="p621" page="normal" smilref="Title.smil#p621" /><p attribs="{'xml:space': 'preserve'}" id="_10476" smilref="Title.smil#_10476"> 608</p><p attribs="{'xml:space': 'preserve'}" id="_10477" smilref="Title.smil#_10477"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10478" smilref="Title.smil#_10478"> Edge-weighted graph data type How should we represent edge-weighted graphs? Perhaps the simplest way to proceed is to extend the basic graph representations from Section 4.1: in the adjacency-matrix representation, the matrix can contain edge weights rather than boolean values; in the adjacency-lists representation, we can define a node that contains both a vertex and a weight field to put in the adjacency lists. (As usual, we focus on sparse graphs and leave the adjacency-matrix representation for exercises.) This classic approach is appealing, but we will use a different method that is not much more complicated, will make our programs useful in more general settings, and needs a slightly more general API, which allows us to process Edge objects:</p><p attribs="{'xml:space': 'preserve'}" id="_10479" smilref="Title.smil#_10479"> public class Edge implements Comparable&lt;Edge&gt; Edge(int v, int w, double weight) initializing constructor double weight() int either() int other(int v) int compareTo(Edge that) String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_10480" smilref="Title.smil#_10480"> weight of this edge either of this edge&#8217;s vertices the other vertex compare this edge to e string representation</p><p attribs="{'xml:space': 'preserve'}" id="_10481" smilref="Title.smil#_10481"> API for a weighted edge</p><p attribs="{'xml:space': 'preserve'}" id="_10482" smilref="Title.smil#_10482"> The either() and other() methods for accessing the edge&#8217;s vertices may be a bit puzzling at fi rst&#8212;the need for them will become plain when we examine client code. You can find an implementation of Edge on page 610. It is the basis for this EdgeWeightedGraph API, which refers to Edge objects in a natural manner:</p><p attribs="{'xml:space': 'preserve'}" id="_10483" smilref="Title.smil#_10483"> public class EdgeWeightedGraph</p><p attribs="{'xml:space': 'preserve'}" id="_10484" smilref="Title.smil#_10484"> EdgeWeightedGraph(int V) EdgeWeightedGraph(In in) int V() int E() void addEdge(Edge e) Iterable&lt;Edge&gt; adj(int v) Iterable&lt;Edge&gt; edges() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_10485" smilref="Title.smil#_10485"> create an empty V-vertex graph read graph from input stream number of vertices number of edges add edge e to this graph edges incident to v all of this graph&#8217;s edges string representation</p><p attribs="{'xml:space': 'preserve'}" id="_10486" smilref="Title.smil#_10486"> API for an edge-weighted graph</p><p attribs="{'xml:space': 'preserve'}" id="_10487" smilref="Title.smil#_10487" /><pagenum id="p622" page="normal" smilref="Title.smil#p622" /><p attribs="{'xml:space': 'preserve'}" id="_10488" smilref="Title.smil#_10488"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10489" smilref="Title.smil#_10489"> 609</p><p attribs="{'xml:space': 'preserve'}" id="_10490" smilref="Title.smil#_10490"> This API is very similar to the API for Graph (page 522). The two important differences are that it is based on Edge and that it adds the edges() method at right, which provides clients with the ability to iterate through to all the graph&#8217;s edges (ignoring any self-loops). The rest of the implementation of EdgeWeightedGraph on page 611 is quite similar to the unweighted undirected graph implementation of Section 4.1, but instead of the adjacency lists of integers used in Graph, it uses adjacency lists of Edge objects. The figure at the bottom of this page shows the edge-weighted graph representation that EdgeWeightedGraph builds from the sample file tinyEWG.txt, showing the contents of each Bag as a linked list to reflect the standard implementation of Section 1.3. To reduce clutter in the fi gure, we show each Edge as a pair of int values and a double value. The actual data structure is a linked list of links to objects containing those values. In particular, although there are two references to each Edge (one in the list for each vertex), there is only one Edge object corresponding to each graph edge. In the fi gure, the edges appear in each list in reverse order of the order they are processed, because of the stack-like nature of the standard linked-list imple- mentation. As in Graph, by using a Bag we are making clear that our client code makes no assumptions about the order of objects in the lists.</p><p attribs="{'xml:space': 'preserve'}" id="_10491" smilref="Title.smil#_10491"> public Iterable&lt;Edge&gt; edges() { Bag&lt;Edge&gt; b = new Bag&lt;Edge&gt;(); for (int v = 0; v &lt; V; v++) for (Edge e : adj[v]) if (e.other(v) &gt; v) b.add(e); return b; }</p><p attribs="{'xml:space': 'preserve'}" id="_10492" smilref="Title.smil#_10492"> Gathering all the edges in an edge-weighted graph</p><p attribs="{'xml:space': 'preserve'}" id="_10493" smilref="Title.smil#_10493"> tinyEWG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_10494" smilref="Title.smil#_10494"> 6 0 .58</p><p attribs="{'xml:space': 'preserve'}" id="_10495" smilref="Title.smil#_10495"> 0 2 .26</p><p attribs="{'xml:space': 'preserve'}" id="_10496" smilref="Title.smil#_10496"> 0 4 .38</p><p attribs="{'xml:space': 'preserve'}" id="_10497" smilref="Title.smil#_10497"> 0 7 .16</p><p attribs="{'xml:space': 'preserve'}" id="_10498" smilref="Title.smil#_10498"> Bag objects</p><p attribs="{'xml:space': 'preserve'}" id="_10499" smilref="Title.smil#_10499"> adj[] 0 1 2 3 4 5 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_10500" smilref="Title.smil#_10500"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10501" smilref="Title.smil#_10501"> E</p><p attribs="{'xml:space': 'preserve'}" id="_10502" smilref="Title.smil#_10502"> 8 16 4 5 0.35 4 7 0.37 5 7 0.28 0 7 0.16 1 5 0.32 0 4 0.38 2 3 0.17 1 7 0.19 0 2 0.26 1 2 0.36 1 3 0.29 2 7 0.34 6 2 0.40 3 6 0.52 6 0 0.58 6 4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_10503" smilref="Title.smil#_10503"> 1 3 .29</p><p attribs="{'xml:space': 'preserve'}" id="_10504" smilref="Title.smil#_10504"> 1 2 .36</p><p attribs="{'xml:space': 'preserve'}" id="_10505" smilref="Title.smil#_10505"> 1 7 .19</p><p attribs="{'xml:space': 'preserve'}" id="_10506" smilref="Title.smil#_10506"> 1 5 .32</p><p attribs="{'xml:space': 'preserve'}" id="_10507" smilref="Title.smil#_10507"> 6 2 .40</p><p attribs="{'xml:space': 'preserve'}" id="_10508" smilref="Title.smil#_10508"> 2 7 .34</p><p attribs="{'xml:space': 'preserve'}" id="_10509" smilref="Title.smil#_10509"> 1 2 .36</p><p attribs="{'xml:space': 'preserve'}" id="_10510" smilref="Title.smil#_10510"> 0 2 .26</p><p attribs="{'xml:space': 'preserve'}" id="_10511" smilref="Title.smil#_10511"> 2 3 .17</p><p attribs="{'xml:space': 'preserve'}" id="_10512" smilref="Title.smil#_10512"> 3 6 .52</p><p attribs="{'xml:space': 'preserve'}" id="_10513" smilref="Title.smil#_10513"> 1 3 .29</p><p attribs="{'xml:space': 'preserve'}" id="_10514" smilref="Title.smil#_10514"> 2 3 .17</p><p attribs="{'xml:space': 'preserve'}" id="_10515" smilref="Title.smil#_10515"> 6 4 .93</p><p attribs="{'xml:space': 'preserve'}" id="_10516" smilref="Title.smil#_10516"> 0 4 .38</p><p attribs="{'xml:space': 'preserve'}" id="_10517" smilref="Title.smil#_10517"> 4 7 .37</p><p attribs="{'xml:space': 'preserve'}" id="_10518" smilref="Title.smil#_10518"> 4 5 .35</p><p attribs="{'xml:space': 'preserve'}" id="_10519" smilref="Title.smil#_10519"> 1 5 .32</p><p attribs="{'xml:space': 'preserve'}" id="_10520" smilref="Title.smil#_10520"> 5 7 .28</p><p attribs="{'xml:space': 'preserve'}" id="_10521" smilref="Title.smil#_10521"> 4 5 .35</p><p attribs="{'xml:space': 'preserve'}" id="_10522" smilref="Title.smil#_10522"> references to the same Edge object</p><p attribs="{'xml:space': 'preserve'}" id="_10523" smilref="Title.smil#_10523"> 6 4 .93</p><p attribs="{'xml:space': 'preserve'}" id="_10524" smilref="Title.smil#_10524"> 6 0 .58</p><p attribs="{'xml:space': 'preserve'}" id="_10525" smilref="Title.smil#_10525"> 3 6 .52</p><p attribs="{'xml:space': 'preserve'}" id="_10526" smilref="Title.smil#_10526"> 6 2 .40</p><p attribs="{'xml:space': 'preserve'}" id="_10527" smilref="Title.smil#_10527"> 2 7 .34</p><p attribs="{'xml:space': 'preserve'}" id="_10528" smilref="Title.smil#_10528"> 1 7 .19</p><p attribs="{'xml:space': 'preserve'}" id="_10529" smilref="Title.smil#_10529"> 0 7 .16</p><p attribs="{'xml:space': 'preserve'}" id="_10530" smilref="Title.smil#_10530"> 5 7 .28</p><p attribs="{'xml:space': 'preserve'}" id="_10531" smilref="Title.smil#_10531"> 5 7 .28</p><p attribs="{'xml:space': 'preserve'}" id="_10532" smilref="Title.smil#_10532"> Edge-weighted graph representation</p><p attribs="{'xml:space': 'preserve'}" id="_10533" smilref="Title.smil#_10533" /><pagenum id="p623" page="normal" smilref="Title.smil#p623" /><p attribs="{'xml:space': 'preserve'}" id="_10534" smilref="Title.smil#_10534"> 610</p><p attribs="{'xml:space': 'preserve'}" id="_10535" smilref="Title.smil#_10535"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10536" smilref="Title.smil#_10536"> Weighted edge data type</p><p attribs="{'xml:space': 'preserve'}" id="_10537" smilref="Title.smil#_10537"> public class Edge implements Comparable&lt;Edge&gt; { private final int v; private final int w; private final double weight;</p><p attribs="{'xml:space': 'preserve'}" id="_10538" smilref="Title.smil#_10538"> public Edge(int v, int w, double weight) { this.v = v; this.w = w; this.weight = weight; }</p><p attribs="{'xml:space': 'preserve'}" id="_10539" smilref="Title.smil#_10539"> public double weight() { return weight; }</p><p attribs="{'xml:space': 'preserve'}" id="_10540" smilref="Title.smil#_10540"> public int either() { return v; }</p><p attribs="{'xml:space': 'preserve'}" id="_10541" smilref="Title.smil#_10541"> // one vertex // the other vertex // edge weight</p><p attribs="{'xml:space': 'preserve'}" id="_10542" smilref="Title.smil#_10542"> public int other(int vertex) { if (vertex == v) return w; else if (vertex == w) return v; else throw new RuntimeException("Inconsistent edge");</p><p attribs="{'xml:space': 'preserve'}" id="_10543" smilref="Title.smil#_10543"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10544" smilref="Title.smil#_10544"> public int compareTo(Edge that) { if (this.weight() &lt; that.weight()) return -1; else if (this.weight() &gt; that.weight()) return +1; else return 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_10545" smilref="Title.smil#_10545"> public String toString() { return String.format("%d-%d %.5f", v, w, weight); }</p><p attribs="{'xml:space': 'preserve'}" id="_10546" smilref="Title.smil#_10546"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10547" smilref="Title.smil#_10547"> This data type provides the methods either() and other() so that such clients can use other(v) to find the other vertex when it knows v. When neither vertex is known, our clients use the idiomatic</p><p attribs="{'xml:space': 'preserve'}" id="_10548" smilref="Title.smil#_10548"> code int v = e.either(), w = e.other(v); to access an Edge e&#8217;s two vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10549" smilref="Title.smil#_10549" /><pagenum id="p624" page="normal" smilref="Title.smil#p624" /><p attribs="{'xml:space': 'preserve'}" id="_10550" smilref="Title.smil#_10550"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10551" smilref="Title.smil#_10551"> 611</p><p attribs="{'xml:space': 'preserve'}" id="_10552" smilref="Title.smil#_10552"> Edge-weighted graph data type</p><p attribs="{'xml:space': 'preserve'}" id="_10553" smilref="Title.smil#_10553"> public class EdgeWeightedGraph { private final int V; // number of vertices private int E; // number of edges private Bag&lt;Edge&gt;[] adj; // adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_10554" smilref="Title.smil#_10554"> public EdgeWeightedGraph(int V) { this.V = V; this.E = 0; adj = (Bag&lt;Edge&gt;[]) new Bag[V]; for (int v = 0; v &lt; V; v++) adj[v] = new Bag&lt;Edge&gt;(); }</p><p attribs="{'xml:space': 'preserve'}" id="_10555" smilref="Title.smil#_10555"> public EdgeWeightedGraph(In in) // See Exercise 4.3.9.</p><p attribs="{'xml:space': 'preserve'}" id="_10556" smilref="Title.smil#_10556"> public int V() { return V; } public int E() { return E; }</p><p attribs="{'xml:space': 'preserve'}" id="_10557" smilref="Title.smil#_10557"> public void addEdge(Edge e) { int v = e.either(), w = e.other(v); adj[v].add(e); adj[w].add(e); E++; }</p><p attribs="{'xml:space': 'preserve'}" id="_10558" smilref="Title.smil#_10558"> public Iterable&lt;Edge&gt; adj(int v) { return adj[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_10559" smilref="Title.smil#_10559"> public Iterable&lt;Edge&gt; edges() // See page 609.</p><p attribs="{'xml:space': 'preserve'}" id="_10560" smilref="Title.smil#_10560"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10561" smilref="Title.smil#_10561"> This implementation maintains a vertex-indexed array of lists of edges. As with Graph (see page 526), every edge appears twice: if an edge connects v and w, it appears both in v&#8217;s list and in w&#8217;s list. The edges() method puts all the edges in a Bag (see page 609). The toString() implementation is left as an exercise.</p><p attribs="{'xml:space': 'preserve'}" id="_10562" smilref="Title.smil#_10562" /><pagenum id="p625" page="normal" smilref="Title.smil#p625" /><p attribs="{'xml:space': 'preserve'}" id="_10563" smilref="Title.smil#_10563"> 612</p><p attribs="{'xml:space': 'preserve'}" id="_10564" smilref="Title.smil#_10564"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10565" smilref="Title.smil#_10565"> Comparing edges by weight. The API specifies that the Edge class must implement the Comparable interface and include a compareTo() implementation. The natural ordering for edges in an edge-weighted graph is by weight. Accordingly, the implementation of compareTo() is straightforward.</p><p attribs="{'xml:space': 'preserve'}" id="_10566" smilref="Title.smil#_10566"> Parallel edges. As with our undirected-graph implementations, we allow parallel edges. Alternatively, we could develop a more complicated implementation of EdgeWeightedGraph that disallows them, perhaps keeping the minimum-weight edge from a set of parallel edges.</p><p attribs="{'xml:space': 'preserve'}" id="_10567" smilref="Title.smil#_10567"> Self-loops. We allow self-loops. However, our edges() implementation in EdgeWeightedGraph does not include self-loops even though they might be present in the input or in the data structure. This omission has no effect on our MST algorithms because no MST contains a self-loop. When working with an application where self-loops are signi&#64257; cant, you may need to modify our code as appropriate for the application.</p><p attribs="{'xml:space': 'preserve'}" id="_10568" smilref="Title.smil#_10568"> Our choice to use explicit Edge objects leads to clear and compact client code, as you will see. It carries a small price: each adjacency-list node has a reference to an Edge ob- ject, with redundant information (all the nodes on v&#8217;s adjacency list have a v). We also pay object overhead cost. Although we have only one copy of each Edge, we do have two references to each Edge object. An alternative and widely used approach is to keep two list nodes corresponding to each edge, just as in Graph, each with a vertex and the edge weight in each list node. This alternative also carries a price&#8212;two nodes, including two copies of the weight for each edge.</p><p attribs="{'xml:space': 'preserve'}" id="_10569" smilref="Title.smil#_10569" /><pagenum id="p626" page="normal" smilref="Title.smil#p626" /><p attribs="{'xml:space': 'preserve'}" id="_10570" smilref="Title.smil#_10570"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10571" smilref="Title.smil#_10571"> 613</p><p attribs="{'xml:space': 'preserve'}" id="_10572" smilref="Title.smil#_10572"> MST API and test client As usual, for graph processing, we define an API where the constructor takes an edge-weighted graph as argument and supports client query methods that return the MST and its weight. How should we represent the MST itself? The MST of a graph G is a subgraph of G that is also a tree, so we have numerous op- tions. Chief among them are </p><p attribs="{'xml:space': 'preserve'}" id="_10573" smilref="Title.smil#_10573"> public class MST</p><p attribs="{'xml:space': 'preserve'}" id="_10574" smilref="Title.smil#_10574"> MST(EdgeWeightedGraph G) Iterable&lt;Edge&gt; edges() double weight()</p><p attribs="{'xml:space': 'preserve'}" id="_10575" smilref="Title.smil#_10575"> constructor all of the MST edges weight of MST</p><p attribs="{'xml:space': 'preserve'}" id="_10576" smilref="Title.smil#_10576"> API for MST implementations</p><p attribs="{'xml:space': 'preserve'}" id="_10577" smilref="Title.smil#_10577"> Test client. As usual, we create sample graphs and develop a test client for use in testing our implementations. A sample client is shown below. It reads edges from the input stream, builds an edge-weighted graph, computes the MST of that graph, prints the MST edges, and prints the total weight of the MST.</p><p attribs="{'xml:space': 'preserve'}" id="_10578" smilref="Title.smil#_10578"> public static void main(String[] args) { In in = new In(args[0]); EdgeWeightedGraph G; G = new EdgeWeightedGraph(in);</p><p attribs="{'xml:space': 'preserve'}" id="_10579" smilref="Title.smil#_10579"> MST mst = new MST(G); for (Edge e : mst.edges()) StdOut.println(e); StdOut.printf("%.5f\n", mst.weight()); }</p><p attribs="{'xml:space': 'preserve'}" id="_10580" smilref="Title.smil#_10580"> MST test client</p><p attribs="{'xml:space': 'preserve'}" id="_10581" smilref="Title.smil#_10581" /><pagenum id="p627" page="normal" smilref="Title.smil#p627" /><p attribs="{'xml:space': 'preserve'}" id="_10582" smilref="Title.smil#_10582"> 614</p><p attribs="{'xml:space': 'preserve'}" id="_10583" smilref="Title.smil#_10583"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10584" smilref="Title.smil#_10584"> Test data. You can find the file tinyEWG.txt on the booksite, which defines the small sample graph on page 604 that we use for detailed traces of MST algorithms. You can also find on the booksite the file mediumEWG.txt, which defines the weighted graph with 250 vertices that is drawn on bottom of the the facing page. It is an example of a Euclidean graph, whose vertices are points in the plane and whose edges are lines connecting them with weights equal to their Euclidean distances. Such graphs are useful for gaining insight into the behavior of MST algorithms, and they also model many of the typical practical problems we have mentioned, such as road maps or electric circuits. You can also find on the booksite is a larger example largeEWG.txt that defines a Euclidean graph with 1 million vertices. Our goal is to be able to find the MST of such a graph in a reasonable amount of time.</p><p attribs="{'xml:space': 'preserve'}" id="_10585" smilref="Title.smil#_10585"> % more tinyEWG.txt 8 16 4 5 .35 4 7 .37 5 7 .28 0 7 .16 1 5 .32 0 4 .38 2 3 .17 1 7 .19 0 2 .26 1 2 .36 1 3 .29 2 7 .34 6 2 .40 3 6 .52 6 0 .58 6 4 .93</p><p attribs="{'xml:space': 'preserve'}" id="_10586" smilref="Title.smil#_10586"> % java MST tinyEWG.txt 0-7 0.16000 2-3 0.17000 1-7 0.19000 0-2 0.26000 5-7 0.28000 4-5 0.35000 6-2 0.40000 1.81000</p><p attribs="{'xml:space': 'preserve'}" id="_10587" smilref="Title.smil#_10587" /><pagenum id="p628" page="normal" smilref="Title.smil#p628" /><p attribs="{'xml:space': 'preserve'}" id="_10588" smilref="Title.smil#_10588"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10589" smilref="Title.smil#_10589"> 615</p><p attribs="{'xml:space': 'preserve'}" id="_10590" smilref="Title.smil#_10590"> % more mediumEWG.txt 250 1273 244 246 0.11712 239 240 0.10616 238 245 0.06142 235 238 0.07048 233 240 0.07634 232 248 0.10223 231 248 0.10699 229 249 0.10098 228 241 0.01473 226 231 0.07638 ... [1263 more edges ]</p><p attribs="{'xml:space': 'preserve'}" id="_10591" smilref="Title.smil#_10591"> % java MST mediumEWG.txt 0 225 0.02383 49 225 0.03314 44 49 0.02107 44 204 0.01774 49 97 0.03121 202 204 0.04207 176 202 0.04299 176 191 0.02089 68 176 0.04396 58 68 0.04795 ... [239 more edges ] 10.46351</p><p attribs="{'xml:space': 'preserve'}" id="_10592" smilref="Title.smil#_10592"> graph</p><p attribs="{'xml:space': 'preserve'}" id="_10593" smilref="Title.smil#_10593"> MST</p><p attribs="{'xml:space': 'preserve'}" id="_10594" smilref="Title.smil#_10594"> A 250-node Euclidean graph (with 1,273 edges) and its MST</p><p attribs="{'xml:space': 'preserve'}" id="_10595" smilref="Title.smil#_10595" /></level3><level3 id="_00086"><h3 id="ch4-s3-ss20" smilref="Title.smil#ch4-s3-ss20" xml:space="preserve">Prim's algorithm</h3><pagenum id="p629" page="normal" smilref="Title.smil#p629" /><p attribs="{'xml:space': 'preserve'}" id="_10596" smilref="Title.smil#_10596"> 616</p><p attribs="{'xml:space': 'preserve'}" id="_10597" smilref="Title.smil#_10597"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10598" smilref="Title.smil#_10598"> Prim&#8217;s algorithm Our first MST method, known as Prim&#8217;s algorithm, is to attach a new edge to a single growing tree at each step. Start with any vertex as a single-ver- tex tree; then add V&#11002;1 edges to it, always taking next (coloring black) the minimum- weight edge that connects a vertex on the tree to a vertex not yet on the tree (a crossing edge for the cut defined by tree vertices).</p><p attribs="{'xml:space': 'preserve'}" id="_10599" smilref="Title.smil#_10599"> crossing edge (red)</p><p attribs="{'xml:space': 'preserve'}" id="_10600" smilref="Title.smil#_10600"> ineligible edge (gray)</p><p attribs="{'xml:space': 'preserve'}" id="_10601" smilref="Title.smil#_10601"> Proposition L. Prim&#8217;s algorithm computes the MST of any connected edge-weighted graph. Proof : Immediate from Proposition K. The growing tree defines a cut with no black edges; the algorithm takes the crossing edge of minimal weight, so it is successively coloring edges black in accordance with the greedy algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_10602" smilref="Title.smil#_10602"> minimum-weight crossing edge must be on MST</p><p attribs="{'xml:space': 'preserve'}" id="_10603" smilref="Title.smil#_10603"> tree edge (thick black)</p><p attribs="{'xml:space': 'preserve'}" id="_10604" smilref="Title.smil#_10604"> Prim&#8217;s MST algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10605" smilref="Title.smil#_10605"> The one-sentence description of Prim&#8217;s algorithm just given leaves unanswered a key question: How do we (ef&#64257; ciently) find the crossing edge of minimal weight? Several methods have been proposed&#8212;we will discuss some of them after we have developed a full solution based on a particularly simple approach.</p><p attribs="{'xml:space': 'preserve'}" id="_10606" smilref="Title.smil#_10606"> Data structures. We implement Prim&#8217;s algorithm with the aid of a few simple and familiar data structures. In particular, we represent the vertices on the tree, the edges on the tree, and the crossing edges, as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_10607" smilref="Title.smil#_10607"> Maintaining the set of crossing edges. Each time that we add an edge to the tree, we also add a vertex to the tree. To maintain the set of crossing edges, we need to add to the priority queue all edges from that vertex to any non-tree vertex (using marked[] to identify such edges). But we must do more: any edge connecting the vertex just added to a tree vertex that is already on the priority queue now becomes ineligible (it is no longer a crossing edge because it connects two tree vertices). An eager implementation</p><p attribs="{'xml:space': 'preserve'}" id="_10608" smilref="Title.smil#_10608" /><pagenum id="p630" page="normal" smilref="Title.smil#p630" /><p attribs="{'xml:space': 'preserve'}" id="_10609" smilref="Title.smil#_10609"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10610" smilref="Title.smil#_10610"> 617</p><p attribs="{'xml:space': 'preserve'}" id="_10611" smilref="Title.smil#_10611"> of Prim&#8217;s algorithm would remove such edges from the priority queue; we first consider a simpler lazy implementation of the algorithm where we leave such edges on the priority queue, deferring the eligibility test to when we remove them. The figure at right is a trace for our small sample graph tinyEWG.txt. Each drawing depicts the graph and the priority queue just after a vertex is visited (added to the tree and the edges in its adjacency list processed). The contents of the priority queue are shown in order on the side, with new edges marked with asterisks. The algorithm builds the MST as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_10612" smilref="Title.smil#_10612"> * marks new entries</p><p attribs="{'xml:space': 'preserve'}" id="_10613" smilref="Title.smil#_10613"> * 1-7 0.19 0-2 0.26 * 5-7 0.28 * 2-7 0.34 * 4-7 0.37 0-4 0.38 6-0 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10614" smilref="Title.smil#_10614"> * 2-3 0.17 5-7 0.28 1-3 0.29 1-5 0.32 2-7 0.34 1-2 0.36 4-7 0.37 0-4 0.38 * 6-2 0.40 6-0 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10615" smilref="Title.smil#_10615"> 1-3 0.29 1-5 0.32 2-7 0.34 * 4-5 0.35 1-2 0.36 4-7 0.37 0-4 0.38 6-2 0.40 3-6 0.52 6-0 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10616" smilref="Title.smil#_10616"> 3-6 0.52 6-0 0.58 6-4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_10617" smilref="Title.smil#_10617"> * 0-7 0.16 * 0-2 0.26 * 0-4 0.38 * 6-0 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10618" smilref="Title.smil#_10618"> crossing edges (ordered by weight)</p><p attribs="{'xml:space': 'preserve'}" id="_10619" smilref="Title.smil#_10619"> ineligible edges (gray)</p><p attribs="{'xml:space': 'preserve'}" id="_10620" smilref="Title.smil#_10620"> 0-2 0.26 5-7 0.28 * 1-3 0.29 * 1-5 0.32 2-7 0.34 * 1-2 0.36 4-7 0.37 0-4 0.38 0-6 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10621" smilref="Title.smil#_10621"> 5-7 0.28 1-3 0.29 1-5 0.32 2-7 0.34 1-2 0.36 4-7 0.37 0-4 0.38 6-2 0.40 * 3-6 0.52 6-0 0.58</p><p attribs="{'xml:space': 'preserve'}" id="_10622" smilref="Title.smil#_10622"> 1-2 0.36 4-7 0.37 0-4 0.38 6-2 0.40 3-6 0.52 6-0 0.58 * 6-4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_10623" smilref="Title.smil#_10623"> Trace of Prim&#8217;s algorithm (lazy version)</p><p attribs="{'xml:space': 'preserve'}" id="_10624" smilref="Title.smil#_10624" /><pagenum id="p631" page="normal" smilref="Title.smil#p631" /><p attribs="{'xml:space': 'preserve'}" id="_10625" smilref="Title.smil#_10625"> 618</p><p attribs="{'xml:space': 'preserve'}" id="_10626" smilref="Title.smil#_10626"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10627" smilref="Title.smil#_10627"> After having added V vertices (and V&#11002;1 edges), the MST is complete. The remaining edges on the priority queue are ineligible, so we need not examine them again.</p><p attribs="{'xml:space': 'preserve'}" id="_10628" smilref="Title.smil#_10628"> Implementation. With these preparations, implementing Prim&#8217;s algorithm is straight- forward, as shown in the implementation LazyPrimMST on the facing page. As with our depth-&#64257; rst search and breadth-&#64257; rst search implementations in the previous two sec- tions, it computes the MST in the constructor so that client methods can learn properties of the MST with query methods. We use a private method visit() that puts a vertex on the tree, by marking it as visited and then putting all of its incident edges that are not ineligible onto the priority queue, thus ensuring that the priority queue contains the crossing edges from tree vertices to non-tree vertices (perhaps also some ineligible edges). The inner loop is a rendition in code of the one-sentence description of the al- gorithm: we take an edge from the priority queue and (if it is not ineligible) add it to the tree, and also add to the tree the new vertex that it leads to, updating the set of crossing edges by calling visit() with that vertex as argument. The weight() method requires iterating through the tree edges to add up the edge weights (lazy approach) or keeping a running total in an instance variable (eager approach) and is left as Exercise 4.3.31. Running time. How fast is Prim&#8217;s algorithm? This question is not difficult to answer, given our knowledge of the behavior characteristics of priority queues:</p><p attribs="{'xml:space': 'preserve'}" id="_10629" smilref="Title.smil#_10629"> Proposition M. The lazy version of Prim&#8217;s algorithm uses space proportional to E and time proportional to E log E (in the worst case) to compute the MST of a connected edge-weighted graph with E edges and V vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10630" smilref="Title.smil#_10630"> Proof : The bottleneck in the algorithm is the number of edge-weight comparisons in the priority-queue methods insert() and delMin(). The number of edges on the priority queue is at most E, which gives the space bound. In the worst case, the cost of an insertion is ~lg E and the cost to delete the minimum is ~2 lg E (see Proposition O in Chapter 2). Since at most E edges are inserted and at most E are deleted, the time bound follows.</p><p attribs="{'xml:space': 'preserve'}" id="_10631" smilref="Title.smil#_10631"> In practice, the upper bound on the running time is a bit conservative because the number of edges on the priority queue is typically much less than E. The existence of such a simple, ef&#64257; cient, and useful algorithm for such a challenging task is quite re- markable. Next, we briefly discuss some improvements. As usual, detailed evaluation of such improvements in performance-critical applications is a job for experts.</p><p attribs="{'xml:space': 'preserve'}" id="_10632" smilref="Title.smil#_10632" /><pagenum id="p632" page="normal" smilref="Title.smil#p632" /><p attribs="{'xml:space': 'preserve'}" id="_10633" smilref="Title.smil#_10633"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10634" smilref="Title.smil#_10634"> 619</p><p attribs="{'xml:space': 'preserve'}" id="_10635" smilref="Title.smil#_10635"> Lazy version of Prim&#8217;s MST algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10636" smilref="Title.smil#_10636"> public class LazyPrimMST { private boolean[] marked; // MST vertices private Queue&lt;Edge&gt; mst; // MST edges private MinPQ&lt;Edge&gt; pq; // crossing (and ineligible) edges</p><p attribs="{'xml:space': 'preserve'}" id="_10637" smilref="Title.smil#_10637"> public LazyPrimMST(EdgeWeightedGraph G) { pq = new MinPQ&lt;Edge&gt;(); marked = new boolean[G.V()]; mst = new Queue&lt;Edge&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_10638" smilref="Title.smil#_10638"> visit(G, 0); // assumes G is connected (see Exercise 4.3.22) while (!pq.isEmpty()) { Edge e = pq.delMin(); // Get lowest-weight int v = e.either(), w = e.other(v); // edge from pq. if (marked[v] &amp;&amp; marked[w]) continue; // Skip if ineligible. mst.enqueue(e); // Add edge to tree. if (!marked[v]) visit(G, v); // Add vertex to tree if (!marked[w]) visit(G, w); // (either v or w). } }</p><p attribs="{'xml:space': 'preserve'}" id="_10639" smilref="Title.smil#_10639"> private void visit(EdgeWeightedGraph G, int v) { // Mark v and add to pq all edges from v to unmarked vertices. marked[v] = true; for (Edge e : G.adj(v)) if (!marked[e.other(v)]) pq.insert(e); }</p><p attribs="{'xml:space': 'preserve'}" id="_10640" smilref="Title.smil#_10640"> public Iterable&lt;Edge&gt; edges() { return mst; }</p><p attribs="{'xml:space': 'preserve'}" id="_10641" smilref="Title.smil#_10641"> public double weight() // See Exercise 4.3.31.</p><p attribs="{'xml:space': 'preserve'}" id="_10642" smilref="Title.smil#_10642"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10643" smilref="Title.smil#_10643"> This implementation of Prim&#8217;s algorithm uses a priority queue to hold crossing edges, a vertex-in- dexed arrays to mark tree vertices, and a queue to hold MST edges. This implementation is a lazy approach where we leave ineligible edges in the priority queue.</p><p attribs="{'xml:space': 'preserve'}" id="_10644" smilref="Title.smil#_10644" /><pagenum id="p633" page="normal" smilref="Title.smil#p633" /><p attribs="{'xml:space': 'preserve'}" id="_10645" smilref="Title.smil#_10645"> 620</p><p attribs="{'xml:space': 'preserve'}" id="_10646" smilref="Title.smil#_10646"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10647" smilref="Title.smil#_10647"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10648" smilref="Title.smil#_10648"> w</p><p attribs="{'xml:space': 'preserve'}" id="_10649" smilref="Title.smil#_10649"> connecting v to the tree</p><p attribs="{'xml:space': 'preserve'}" id="_10650" smilref="Title.smil#_10650"> brings w closer to the tree</p><p attribs="{'xml:space': 'preserve'}" id="_10651" smilref="Title.smil#_10651"> Eager version of Prim&#8217;s algorithm To improve the LazyPrimMST, we might try to delete ineligible edges from the priority queue, so that the priority queue contains only the crossing edges between tree vertices and non-tree vertices. But we can eliminate even more edges. The key is to note that our only interest is in the minimal edge from each non-tree vertex to a tree vertex. When we add a vertex v to the tree, the only possible change with respect to each non- tree vertex w is that adding v brings w closer than before to the tree. In short, we do not need to keep on the priority queue all of the edges from w to tree vertices&#8212;we just need to keep track of the minimum-weight edge and check whether the addition of v to the tree necessitates that we update that minimum (be- cause of an edge v-w that has lower weight), which we can do as we process each edge in v&#8217;s adjacency list. In other words, we maintain on the priority queue just one edge for each non-tree vertex w : the shortest edge that connects it to the tree. Any longer edge connecting w to the tree will become ineligible at some point, so there is no need to keep it on the priority queue. PrimMST (Algorithm 4.7 on page 622) implements Prim&#8217;s algorithm using our index priority queue data type from Section 2.4 (see page 320). It replaces the data structures marked[] and mst[] in LazyPrimMST by two vertex-indexed arrays edgeTo[] and distTo[], which have the following properties: </p><p attribs="{'xml:space': 'preserve'}" id="_10652" smilref="Title.smil#_10652" /><pagenum id="p634" page="normal" smilref="Title.smil#p634" /><p attribs="{'xml:space': 'preserve'}" id="_10653" smilref="Title.smil#_10653"> index/value pairs (in red). In the drawings, the shortest edge connecting each non-MST vertex to an MST vertex is drawn in red. The algorithm adds edges to the MST in the same order as the lazy version; the difference is in the priority-queue operations. It builds the MST as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_10654" smilref="Title.smil#_10654"> an essentially identical argument as in</p><p attribs="{'xml:space': 'preserve'}" id="_10655" smilref="Title.smil#_10655"> the proof of Proposition M proves that the eager version of Prim&#8217;s algorithm finds the</p><p attribs="{'xml:space': 'preserve'}" id="_10656" smilref="Title.smil#_10656"> black: on MST</p><p attribs="{'xml:space': 'preserve'}" id="_10657" smilref="Title.smil#_10657"> red: on pq</p><p attribs="{'xml:space': 'preserve'}" id="_10658" smilref="Title.smil#_10658"> gray: not on MST</p><p attribs="{'xml:space': 'preserve'}" id="_10659" smilref="Title.smil#_10659"> thick red: smallest on pq, next to add to MST</p><p attribs="{'xml:space': 'preserve'}" id="_10660" smilref="Title.smil#_10660"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10661" smilref="Title.smil#_10661"> 621</p><p attribs="{'xml:space': 'preserve'}" id="_10662" smilref="Title.smil#_10662"> edgeTo[] distTo[] 0 1 2 0-2 0.26 3 4 0-4 0.38 5 6 6-0 0.58 7 0-7 0.16 0 1 1-7 0.19 2 0-2 0.26 3 4 0-4 0.38 5 5-7 0.28 6 6-0 0.58 7 0-7 0.16</p><p attribs="{'xml:space': 'preserve'}" id="_10663" smilref="Title.smil#_10663"> 0 1 1-7 0.19 2 0-2 0.26 3 1-3 0.29 4 0-4 0.38 5 5-7 0.28 6 6-0 0.58 7 0-7 0.16 0 1 1-7 0.19 2 0-2 0.26 3 2-3 0.17 4 0-4 0.38 5 5-7 0.28 6 6-2 0.40 7 0-7 0.16 0 1 1-7 0.19 2 0-2 0.26 3 2-3 0.17 4 0-4 0.38 5 5-7 0.28 6 6-2 0.40 7 0-7 0.16</p><p attribs="{'xml:space': 'preserve'}" id="_10664" smilref="Title.smil#_10664"> 0 1 1-7 0.19 2 0-2 0.26 3 2-3 0.17 4 4-5 0.35 5 5-7 0.28 6 6-2 0.40 7 0-7 0.16</p><p attribs="{'xml:space': 'preserve'}" id="_10665" smilref="Title.smil#_10665"> 0 1 1-7 0.19 2 0-2 0.26 3 2-3 0.17 4 4-5 0.35 5 5-7 0.28 6 6-2 0.40 7 0-7 0.16</p><p attribs="{'xml:space': 'preserve'}" id="_10666" smilref="Title.smil#_10666"> 0 1 1-7 0.19 2 0-2 0.26 3 2-3 0.17 4 4-5 0.35 5 5-7 0.28 6 6-2 0.40 7 0-7 0.16</p><p attribs="{'xml:space': 'preserve'}" id="_10667" smilref="Title.smil#_10667"> Trace of Prim&#8217;s algorithm (eager version)</p><p attribs="{'xml:space': 'preserve'}" id="_10668" smilref="Title.smil#_10668" /><pagenum id="p635" page="normal" smilref="Title.smil#p635" /><p attribs="{'xml:space': 'preserve'}" id="_10669" smilref="Title.smil#_10669"> 622</p><p attribs="{'xml:space': 'preserve'}" id="_10670" smilref="Title.smil#_10670"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10671" smilref="Title.smil#_10671"> ALGORITHM 4.7 Prim&#8217;s MST algorithm (eager version)</p><p attribs="{'xml:space': 'preserve'}" id="_10672" smilref="Title.smil#_10672"> public class PrimMST { private Edge[] edgeTo; // shortest edge from tree vertex private double[] distTo; // distTo[w] = edgeTo[w].weight() private boolean[] marked; // true if v on tree private IndexMinPQ&lt;Double&gt; pq; // eligible crossing edges</p><p attribs="{'xml:space': 'preserve'}" id="_10673" smilref="Title.smil#_10673"> public PrimMST(EdgeWeightedGraph G) { edgeTo = new Edge[G.V()]; distTo = new double[G.V()]; marked = new boolean[G.V()]; for (int v = 0; v &lt; G.V(); v++) distTo[v] = Double.POSITIVE_INFINITY; pq = new IndexMinPQ&lt;Double&gt;(G.V());</p><p attribs="{'xml:space': 'preserve'}" id="_10674" smilref="Title.smil#_10674"> distTo[0] = 0.0; pq.insert(0, 0.0); // Initialize pq with 0, weight 0. while (!pq.isEmpty()) visit(G, pq.delMin()); // Add closest vertex to tree. }</p><p attribs="{'xml:space': 'preserve'}" id="_10675" smilref="Title.smil#_10675"> private void visit(EdgeWeightedGraph G, int v) { // Add v to tree; update data structures. marked[v] = true; for (Edge e : G.adj(v)) { int w = e.other(v); if (marked[w]) continue; // v-w is ineligible. if (e.weight() &lt; distTo[w]) { // Edge e is new best connection from tree to w. edgeTo[w] = e; distTo[w] = e.weight(); if (pq.contains(w)) pq.change(w, distTo[w]); else pq.insert(w, distTo[w]); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_10676" smilref="Title.smil#_10676"> public Iterable&lt;Edge&gt; edges() // See Exercise 4.3.21. public double weight() // See Exercise 4.3.31. }</p><p attribs="{'xml:space': 'preserve'}" id="_10677" smilref="Title.smil#_10677"> This implementation of Prim&#8217;s algorithm keeps eligible crossing edges on an index priority queue.</p><p attribs="{'xml:space': 'preserve'}" id="_10678" smilref="Title.smil#_10678" /><pagenum id="p636" page="normal" smilref="Title.smil#p636" /><p attribs="{'xml:space': 'preserve'}" id="_10679" smilref="Title.smil#_10679"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10680" smilref="Title.smil#_10680"> 623</p><p attribs="{'xml:space': 'preserve'}" id="_10681" smilref="Title.smil#_10681"> MST of a connected edge-weighted graph in time proportional to E log V and extra space proportional to V (see page 623). For the huge sparse graphs that are typical in practice, there is no asymptotic difference in the time bound (because lg E ~ lg V for sparse graphs); the space bound is a constant-factor (but signi&#64257; cant) improvement. Further analysis and experimentation are best left for experts facing performance-critical applications, where many factors come into play, including the implementations of MinPQ and IndexMinPQ, the graph representation, properties of the ap- plication&#8217;s graph model, and so forth. As usual, such improvements need to be carefully considered, as the increased code complexity is only justified for applications where constant-factor performance gains are important, and might even be counterproductive on complex modern systems.</p><p attribs="{'xml:space': 'preserve'}" id="_10682" smilref="Title.smil#_10682"> Proposition N. The eager version of Prim&#8217;s algorithm uses extra space proportional to V and time proportional to E log V (in the worst case) to compute the MST of a connected edge- weighted graph with E edges and V vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10683" smilref="Title.smil#_10683"> Proof : The number of edges on the priority queue is at most V, and there are three vertex-indexed arrays, which implies the space bound. The algorithm uses V insert operations, V delete the minimum operations, and (in the worst case) E change priority operations. These counts, coupled with the fact that our heap-based implementation of the index priority queue implements all these operations in time proportional to log V (see page 321), imply the time bound.</p><p attribs="{'xml:space': 'preserve'}" id="_10684" smilref="Title.smil#_10684"> 20%</p><p attribs="{'xml:space': 'preserve'}" id="_10685" smilref="Title.smil#_10685"> 40%</p><p attribs="{'xml:space': 'preserve'}" id="_10686" smilref="Title.smil#_10686"> 60%</p><p attribs="{'xml:space': 'preserve'}" id="_10687" smilref="Title.smil#_10687"> 80%</p><p attribs="{'xml:space': 'preserve'}" id="_10688" smilref="Title.smil#_10688"> The diagram at right shows Prim&#8217;s algorithm in operation on our 250-vertex Euclidean graph mediumEWG.txt. It is a fascinating dynamic process (see also Exercise 4.3.27). Most often the tree grows by connecting a new vertex to the vertex just added. When reaching an area with no nearby non-tree vertices, the growth starts from another part of the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_10689" smilref="Title.smil#_10689"> MST</p><p attribs="{'xml:space': 'preserve'}" id="_10690" smilref="Title.smil#_10690"> Prim&#8217;s algorithm (250 vertices)</p><p attribs="{'xml:space': 'preserve'}" id="_10691" smilref="Title.smil#_10691" /></level3><level3 id="_00087"><h3 id="ch4-s3-ss21" smilref="Title.smil#ch4-s3-ss21" xml:space="preserve">Kruskal's algorithm</h3><pagenum id="p637" page="normal" smilref="Title.smil#p637" /><p attribs="{'xml:space': 'preserve'}" id="_10692" smilref="Title.smil#_10692"> 624</p><p attribs="{'xml:space': 'preserve'}" id="_10693" smilref="Title.smil#_10693"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10694" smilref="Title.smil#_10694"> Kruskal&#8217;s algorithm The second MST algorithm that we consider in detail is to process the edges in order of their weight values (smallest to largest), taking for the MST (coloring black) each edge that does not form a cycle with edges previously added, stopping after adding V&#11002;1 edges. The black edges form a forest of trees that evolves gradually into a single tree, the MST. This method is known as Kruskal&#8217;s algorithm:</p><p attribs="{'xml:space': 'preserve'}" id="_10695" smilref="Title.smil#_10695"> the</p><p attribs="{'xml:space': 'preserve'}" id="_10696" smilref="Title.smil#_10696"> Proposition O. Kruskal&#8217;s algorithm computes MST of any connected edge-weighted graph. Proof : Immediate from Proposition K. If the next edge to be considered does not form a cycle with black edges, it crosses a cut defined by the set of vertices connected to one of the edge&#8217;s vertices by tree edges (and its complement). Since the edge does not create a cycle, it is the only crossing edge seen so far, and since we consider the edges in sorted order, it is a crossing edge of minimum weight. Thus, the algorithm is successively taking a minimal-weight crossing edge, in accordance with the greedy algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_10697" smilref="Title.smil#_10697"> Prim&#8217;s algorithm builds the MST one edge at a time, finding a new edge to attach to a single growing tree at each step. Kruskal&#8217;s algorithm also builds the MST one edge at a time; but, by contrast, it finds an edge that connects two trees in a forest of growing trees. We start with a degenerate forest of V single-vertex trees and perform the operation of combining two trees (using the shortest edge possible) until there is just one tree left: the MST. The figure at left shows a step-by-step example of the operation of Kruskal&#8217;s algorithm on tinyEWG.txt. The five lowest-weight edges in the graph are taken for the MST, then 1-3, 1-5, and 2-7 are determined to be ineligible before 4-5 is taken for the MST, and finally 1-2, 4-7, and 0-4 are determined to be ineligible and 6-2 is taken for the MST.</p><p attribs="{'xml:space': 'preserve'}" id="_10698" smilref="Title.smil#_10698"> next MST edge is red</p><p attribs="{'xml:space': 'preserve'}" id="_10699" smilref="Title.smil#_10699"> graph edges sorted by weight</p><p attribs="{'xml:space': 'preserve'}" id="_10700" smilref="Title.smil#_10700"> 0-7 0.16 2-3 0.17 1-7 0.19 0-2 0.26 5-7 0.28 1-3 0.29 1-5 0.32 2-7 0.34 4-5 0.35 1-2 0.36 4-7 0.37 0-4 0.38 6-2 0.40 3-6 0.52 6-0 0.58 6-4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_10701" smilref="Title.smil#_10701"> MST edge (black)</p><p attribs="{'xml:space': 'preserve'}" id="_10702" smilref="Title.smil#_10702"> obsolete edge (gray)</p><p attribs="{'xml:space': 'preserve'}" id="_10703" smilref="Title.smil#_10703"> grey vertices are a cut defined by the vertices connected to one of the red edge&#8217;s vertices</p><p attribs="{'xml:space': 'preserve'}" id="_10704" smilref="Title.smil#_10704"> Trace of Kruskal&#8217;s algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10705" smilref="Title.smil#_10705" /><pagenum id="p638" page="normal" smilref="Title.smil#p638" /><p attribs="{'xml:space': 'preserve'}" id="_10706" smilref="Title.smil#_10706"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10707" smilref="Title.smil#_10707"> 625</p><p attribs="{'xml:space': 'preserve'}" id="_10708" smilref="Title.smil#_10708"> Kruskal&#8217;s algorithm is also not difficult to implement, given the basic algorithmic tools that we have considered in this book: we use a priority queue (Section 2.4) to consider the edges in order by weight, a union-&#64257; nd data structure (Section 1.5) to identify those that cause cycles, and a queue (Section 1.3) to collect the MST edges. Algorithm 4.8 is an implementation along these lines. Note that collecting the MST edges in a Queue means that when a client iterates through the edges it gets them in increasing order of their weight. The weight() method requires iterating through the queue to add the edge weights (or keeping a running total in an instance variable) and is left as an exercise (see Exercise 4.3.31). Analyzing the running time of Kruskal&#8217;s algorithm is a simple matter because we know the running times of its basic operations.</p><p attribs="{'xml:space': 'preserve'}" id="_10709" smilref="Title.smil#_10709"> Proposition N (continued). Kruskal&#8217;s algorithm uses space proportional to E and time proportional to E log E (in the worst case) to compute the MST of an edge- weighted connected graph with E edges and V vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10710" smilref="Title.smil#_10710"> Proof : The implementation uses the priority-queue constructor that initializes the priority queue with all the edges, at a cost of at most E compares (see Section 2.4). After the priority queue is built, the argument is the same as for Prim&#8217;s algorithm. The number of edges on the priority queue is at most E, which gives the space bound, and the cost per operation is at most 2 lg E compares, which gives the time bound. Kruskal&#8217;s algorithm also performs up to E find() and V union() opera- tions, but that cost does not contribute to the E log E order of growth of the total running time (see Section 1.5).</p><p attribs="{'xml:space': 'preserve'}" id="_10711" smilref="Title.smil#_10711"> As with Prim&#8217;s algorithm the cost bound is conservative, since the algorithm terminates after finding the V&#11002;1 MST edges. The order of growth of the actual cost is E + E0 log E, where E0 is the number of edges whose weight is less than the weight of the MST edge with the highest weight. Despite this advantage, Kruskal&#8217;s algorithm is generally slower than Prim&#8217;s algorithm because it has to do a connected() operation for each edge, in addition to the priority-queue operations that both algorithms do for each edge pro-</p><p attribs="{'xml:space': 'preserve'}" id="_10712" smilref="Title.smil#_10712"> cessed (see Exercise 4.3.39).</p><p attribs="{'xml:space': 'preserve'}" id="_10713" smilref="Title.smil#_10713" /><pagenum id="p639" page="normal" smilref="Title.smil#p639" /><p attribs="{'xml:space': 'preserve'}" id="_10714" smilref="Title.smil#_10714"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10715" smilref="Title.smil#_10715"> The figure at left illustrates the algorithm&#8217;s dynamic characteristics on the larger example mediumEWG.txt. The fact that the edges are added to the forest in order of their length is quite apparent.</p><p attribs="{'xml:space': 'preserve'}" id="_10716" smilref="Title.smil#_10716"> 626</p><p attribs="{'xml:space': 'preserve'}" id="_10717" smilref="Title.smil#_10717"> 20%</p><p attribs="{'xml:space': 'preserve'}" id="_10718" smilref="Title.smil#_10718"> 40%</p><p attribs="{'xml:space': 'preserve'}" id="_10719" smilref="Title.smil#_10719"> 60%</p><p attribs="{'xml:space': 'preserve'}" id="_10720" smilref="Title.smil#_10720"> 80%</p><p attribs="{'xml:space': 'preserve'}" id="_10721" smilref="Title.smil#_10721"> MST</p><p attribs="{'xml:space': 'preserve'}" id="_10722" smilref="Title.smil#_10722"> Kruskal&#8217;s algorithm (250 vertices)</p><p attribs="{'xml:space': 'preserve'}" id="_10723" smilref="Title.smil#_10723" /><pagenum id="p640" page="normal" smilref="Title.smil#p640" /><p attribs="{'xml:space': 'preserve'}" id="_10724" smilref="Title.smil#_10724"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10725" smilref="Title.smil#_10725"> 627</p><p attribs="{'xml:space': 'preserve'}" id="_10726" smilref="Title.smil#_10726"> ALGORITHM 4.8 Kruskal&#8217;s MST algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10727" smilref="Title.smil#_10727"> public class KruskalMST { private Queue&lt;Edge&gt; mst;</p><p attribs="{'xml:space': 'preserve'}" id="_10728" smilref="Title.smil#_10728"> public KruskalMST(EdgeWeightedGraph G) { mst = new Queue&lt;Edge&gt;(); MinPQ&lt;Edge&gt; pq = new MinPQ&lt;Edge&gt;(); for (Edge e : G.edges()) pq.insert(e); UF uf = new UF(G.V());</p><p attribs="{'xml:space': 'preserve'}" id="_10729" smilref="Title.smil#_10729"> while (!pq.isEmpty() &amp;&amp; mst.size() &lt; G.V()-1) { Edge e = pq.delMin(); // Get min weight edge on pq int v = e.either(), w = e.other(v); // and its vertices. if (uf.connected(v, w)) continue; // Ignore ineligible edges. uf.union(v, w); // Merge components. mst.enqueue(e); // Add edge to mst. } }</p><p attribs="{'xml:space': 'preserve'}" id="_10730" smilref="Title.smil#_10730"> public Iterable&lt;Edge&gt; edges() { return mst; }</p><p attribs="{'xml:space': 'preserve'}" id="_10731" smilref="Title.smil#_10731"> public double weight()</p><p attribs="{'xml:space': 'preserve'}" id="_10732" smilref="Title.smil#_10732"> // See Exercise 4.3.31.</p><p attribs="{'xml:space': 'preserve'}" id="_10733" smilref="Title.smil#_10733"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10734" smilref="Title.smil#_10734"> This implementation of Kruskal&#8217;s algorithm uses a queue to hold MST edges, a priority queue to hold edges not yet examined, and a union-&#64257; nd data structure for identifying ineligible edges. The MST edges are returned to the client in increasing order of their weights. The weight() method is left as an exercise.</p><p attribs="{'xml:space': 'preserve'}" id="_10735" smilref="Title.smil#_10735"> % java KruskalMST tinyEWG.txt 0-7 0.16000 2-3 0.17000 1-7 0.19000 0-2 0.26000 5-7 0.28000 4-5 0.35000 6-2 0.40000 1.8100</p><p attribs="{'xml:space': 'preserve'}" id="_10736" smilref="Title.smil#_10736" /><pagenum id="p641" page="normal" smilref="Title.smil#p641" /><p attribs="{'xml:space': 'preserve'}" id="_10737" smilref="Title.smil#_10737"> 628</p><p attribs="{'xml:space': 'preserve'}" id="_10738" smilref="Title.smil#_10738"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10739" smilref="Title.smil#_10739"> Perspective The MST problem is one of the most heavily studied problems that we encounter in this book. Basic approaches to solving it were invented long before the development of modern data structures and modern techniques for analyzing the performance of algorithms, at a time when finding the MST of a graph that contained, say, thousands of edges was a daunting task. The MST algorithms that we have considered differ from these old ones essentially in their use and implementation of modern algorithms and data structures for basic tasks, which (coupled with modern computing power) makes it possible for us to compute MSTs with millions or even billions of edges.</p><p attribs="{'xml:space': 'preserve'}" id="_10740" smilref="Title.smil#_10740"> Historical notes. An MST imple-</p><p attribs="{'xml:space': 'preserve'}" id="_10741" smilref="Title.smil#_10741"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_10742" smilref="Title.smil#_10742"> worst-case order of growth for V vertices and E edges</p><p attribs="{'xml:space': 'preserve'}" id="_10743" smilref="Title.smil#_10743"> space</p><p attribs="{'xml:space': 'preserve'}" id="_10744" smilref="Title.smil#_10744"> time</p><p attribs="{'xml:space': 'preserve'}" id="_10745" smilref="Title.smil#_10745"> E log E</p><p attribs="{'xml:space': 'preserve'}" id="_10746" smilref="Title.smil#_10746"> E log V</p><p attribs="{'xml:space': 'preserve'}" id="_10747" smilref="Title.smil#_10747"> Chazelle</p><p attribs="{'xml:space': 'preserve'}" id="_10748" smilref="Title.smil#_10748"> E</p><p attribs="{'xml:space': 'preserve'}" id="_10749" smilref="Title.smil#_10749"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10750" smilref="Title.smil#_10750"> E</p><p attribs="{'xml:space': 'preserve'}" id="_10751" smilref="Title.smil#_10751"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10752" smilref="Title.smil#_10752"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10753" smilref="Title.smil#_10753"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10754" smilref="Title.smil#_10754"> lazy Prim</p><p attribs="{'xml:space': 'preserve'}" id="_10755" smilref="Title.smil#_10755"> eager Prim</p><p attribs="{'xml:space': 'preserve'}" id="_10756" smilref="Title.smil#_10756"> Kruskal Fredman-Tarjan</p><p attribs="{'xml:space': 'preserve'}" id="_10757" smilref="Title.smil#_10757"> E log E E + V log V very, very nearly, but not quite E</p><p attribs="{'xml:space': 'preserve'}" id="_10758" smilref="Title.smil#_10758"> mentation for dense graphs (see Ex- ercise 4.3.29) was first presented by R. Prim in 1961 and, independently, by E. W. Dijkstra soon thereafter. It is usually referred to as Prim&#8217;s algo- rithm, although Dijkstra&#8217;s presentation was more general. But the basic idea was also presented by V. Jarnik in 1939, so some authors refer to the method as Jarnik&#8217;s algorithm, thus characterizing Prim&#8217;s (or Dijkstra&#8217;s) role as finding an efficient implementation of the algorithm for dense graphs. As the priority-queue ADT came into use in the early 1970s, its application to finding MSTs of sparse graphs was straightforward; the fact that MSTs of sparse graphs could be computed in time proportional to E log E became widely known without attribution to any particular researcher. In 1984, M. L. Fredman and R. E. Tarjan developed the Fibonacci heap data structure, which improves the theoretical bound on the order of growth of the running time of Prim&#8217;s algorithm to E + V log V. J. Kruskal presented his algorithm in 1956, but, again, the relevant ADT implementations were not carefully studied for many years. Other interesting historical notes are that Kruskal&#8217;s paper mentioned a version of Prim&#8217;s algorithm and that a 1926 (!) paper by O. Boruvka mentioned both ap- proaches. Boruvka&#8217;s paper addressed a power-distribution application and introduced yet another method that is easily implemented with modern data structures (see Exer- cise 4.3.43 and Exercise 4.3.44). The method was rediscovered by M. Sollin in 1961;</p><p attribs="{'xml:space': 'preserve'}" id="_10759" smilref="Title.smil#_10759"> Performance characteristics of MST algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_10760" smilref="Title.smil#_10760"> impossible ?</p><p attribs="{'xml:space': 'preserve'}" id="_10761" smilref="Title.smil#_10761"> E ?</p><p attribs="{'xml:space': 'preserve'}" id="_10762" smilref="Title.smil#_10762" /><pagenum id="p642" page="normal" smilref="Title.smil#p642" /><p attribs="{'xml:space': 'preserve'}" id="_10763" smilref="Title.smil#_10763"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10764" smilref="Title.smil#_10764"> 629</p><p attribs="{'xml:space': 'preserve'}" id="_10765" smilref="Title.smil#_10765"> it later attracted attention as the basis for MST algorithms with efficient asymptotic performance and as the basis for parallel MST algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_10766" smilref="Title.smil#_10766"> A linear-time algorithm? On the one hand, no theoretical results have been developed that deny the existence of an MST algorithm that is guaranteed to run in linear time for all graphs. On the other hand, the goal of developing algorithms for computing the MST of sparse graphs in linear time remains elusive. Since the 1970s the applicability of the union-&#64257; nd abstraction to Kruskal&#8217;s algorithm and the applicability of the priority-queue abstraction to Prim&#8217;s algorithm have been prime motivations for many researchers to seek better implementations of those ADTs. Many researchers have concentrated on finding efficient priority-queue implementations as the key to fi nd- ing efficient MST algorithms for sparse graphs; many other researchers have studied variations of Boruvka&#8217;s algorithm as the basis for nearly linear-time MST algorithms for sparse graphs. Such research still holds the potential to lead us eventually to a practical linear-time MST algorithm and has even shown the existence of a randomized linear-time algorithm. Also, researchers are getting quite close to the linear-time goal: B. Chazelle exhibited an algorithm in 1997 that certainly could never be distinguished from a linear-time algorithm in any conceivable practical situation (even though it is provably nonlinear), but is so complicated that no one would use it in practice. While the algorithms that have emerged from such research are generally quite complicated, simplified versions of some of them may yet be shown to be useful in practice. In the meantime, we can use the basic algorithms that we have considered here to compute the MST in linear time in most practical situations, perhaps paying an extra factor of log V for some sparse graphs.</p><p attribs="{'xml:space': 'preserve'}" id="_10767" smilref="Title.smil#_10767"> In summary, we can consider the MST problem to be &#8220;solved&#8217;&#8217; for practical purposes. For most graphs, the cost of finding the MST is only slightly higher than the cost of extracting the graph&#8217;s edges. This rule holds except for huge graphs that are extremely sparse, but the available performance improvement over the best-known algorithms even in this case is a small constant factor, perhaps a factor of 10 at best. These conclusions are borne out for many graph models, and practitioners have been using Prim&#8217;s and Kruskal&#8217;s algorithms to find MSTs in huge graphs for decades.</p><p attribs="{'xml:space': 'preserve'}" id="_10768" smilref="Title.smil#_10768" /><pagenum id="p643" page="normal" smilref="Title.smil#p643" /><p attribs="{'xml:space': 'preserve'}" id="_10769" smilref="Title.smil#_10769"> 630</p><p attribs="{'xml:space': 'preserve'}" id="_10770" smilref="Title.smil#_10770"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10771" smilref="Title.smil#_10771"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_10772" smilref="Title.smil#_10772"> Q. Do Prim&#8217;s and Kruskal&#8217;s algorithms work for directed graphs? A. No, not at all. That is a more difficult graph-processing problem known as the minimum cost arborescence problem.</p><p attribs="{'xml:space': 'preserve'}" id="_10773" smilref="Title.smil#_10773" /><pagenum id="p644" page="normal" smilref="Title.smil#p644" /><p attribs="{'xml:space': 'preserve'}" id="_10774" smilref="Title.smil#_10774"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_10775" smilref="Title.smil#_10775"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10776" smilref="Title.smil#_10776"> 631</p><p attribs="{'xml:space': 'preserve'}" id="_10777" smilref="Title.smil#_10777"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_10778" smilref="Title.smil#_10778"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_10779" smilref="Title.smil#_10779"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_10780" smilref="Title.smil#_10780"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_10781" smilref="Title.smil#_10781"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_10782" smilref="Title.smil#_10782"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_10783" smilref="Title.smil#_10783"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_10784" smilref="Title.smil#_10784"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_10785" smilref="Title.smil#_10785"> 4.3.1 Prove that you can rescale the weights by adding a positive constant to all of them or by multiplying them all by a positive constant without affecting the MST. 4.3.2 Draw all of the MSTs of the graph depicted at right (all edge weights are equal). 4.3.3 Show that if a graph&#8217;s edges all have distinct weights, the MST is unique. 4.3.4 Consider the assertion that an edge-weighted graph has a unique MST only if its edge weights are distinct. Give a proof or a counterexample. 4.3.5 Show that the greedy algorithm is valid even when edge weights are not distinct. 4.3.6 Give the MST of the weighted graph obtained by deleting vertex 7 from tinyEWG.txt (see page 604). 4.3.7 How would you find a maximum spanning tree of an edge-weighted graph? 4.3.8 Prove the following, known as the cycle property: Given any cycle in an edge- weighted graph (all edge weights distinct), the edge of maximum weight in the cycle does not belong to the MST of the graph. 4.3.9 Implement the constructor for EdgeWeightedGraph that reads an edge-weighted graph from the input stream, by suitably modifying the constructor from Graph (see page 526). 4.3.10 Develop an EdgeWeightedGraph implementation for dense graphs that uses an adjacency-matrix (two-dimensional array of weights) representation. Disallow parallel edges. 4.3.11 Determine the amount of memory used by EdgeWeightedGraph to represent a graph with V vertices and E edges, using the memory-cost model of Section 1.4. 4.3.12 Suppose that a graph has distinct edge weights. Does its shortest edge have to belong to the MST? Can its longest edge belong to the MST? Does a min-weight edge on every cycle have to belong to the MST? Prove your answer to each question or give a counterexample. 4.3.13 Give a counterexample that shows why the following strategy does not necessarily find the MST: &#8216;Start with any vertex as a single-vertex MST, then add V-1 edges</p><p attribs="{'xml:space': 'preserve'}" id="_10786" smilref="Title.smil#_10786" /><pagenum id="p645" page="normal" smilref="Title.smil#p645" /><p attribs="{'xml:space': 'preserve'}" id="_10787" smilref="Title.smil#_10787"> 632</p><p attribs="{'xml:space': 'preserve'}" id="_10788" smilref="Title.smil#_10788"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10789" smilref="Title.smil#_10789"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_10790" smilref="Title.smil#_10790"> to it, always taking next a min-weight edge incident to the vertex most recently added to the MST.&#8217; 4.3.14 Given an MST for an edge-weighted graph G, suppose that an edge in G that does not disconnect G is deleted. Describe how to find an MST of the new graph in time proportional to E. 4.3.15 Given an MST for an edge-weighted graph G and a new edge e, describe how to find an MST of the new graph in time proportional to V. 4.3.16 Given an MST for an edge-weighted graph G and a new edge e, write a program that determines the range of weights for which e is in an MST.</p><p attribs="{'xml:space': 'preserve'}" id="_10791" smilref="Title.smil#_10791"> 4.3.17 Implement toString() for EdgeWeightedGraph.</p><p attribs="{'xml:space': 'preserve'}" id="_10792" smilref="Title.smil#_10792"> 4.3.18 Give traces that show the process of computing the MST of the graph defined in Exercise 4.3.6 with the lazy version of Prim&#8217;s algorithm, the eager version of Prim&#8217;s algorithm, and Kruskal&#8217;s algorithm. 4.3.19 Suppose that you use a priority-queue implementation that maintains a sorted list. What would be the order of growth of the worst-case running time for Prim&#8217;s algorithm and for Kruskal&#8217;s algorithm for graphs with V vertices and E edges? When would this method be appropriate, if ever? Defend your answer. 4.3.20 True or false: At any point during the execution of Kruskal&#8217;s algorithm, each vertex is closer to some vertex in its subtree than to any vertex not in its subtree. Prove your answer. 4.3.21 Provide an implementation of edges() for PrimMST (page 622).</p><p attribs="{'xml:space': 'preserve'}" id="_10793" smilref="Title.smil#_10793"> Solution :</p><p attribs="{'xml:space': 'preserve'}" id="_10794" smilref="Title.smil#_10794"> public Iterable&lt;Edge&gt; edges() { Queue&lt;Edge&gt; mst = new Queue&lt;Edge&gt;(); for (int v = 1; v &lt; edgeTo.length; v++) mst.enqueue(edgeTo[v]); return mst; }</p><p attribs="{'xml:space': 'preserve'}" id="_10795" smilref="Title.smil#_10795" /><pagenum id="p646" page="normal" smilref="Title.smil#p646" /><p attribs="{'xml:space': 'preserve'}" id="_10796" smilref="Title.smil#_10796"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10797" smilref="Title.smil#_10797"> 633</p><p attribs="{'xml:space': 'preserve'}" id="_10798" smilref="Title.smil#_10798"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_10799" smilref="Title.smil#_10799"> 4.3.22 Minimum spanning forest. Develop versions of Prim&#8217;s and Kruskal&#8217;s algorithms that compute the minimum spanning forest of an edge-weighted graph that is not necessarily connected. Use the connected-components API of Section 4.1 and find MSTs in each component. 4.3.23 Vyssotsky&#8217;s algorithm. Develop an implementation that computes the MST by applying the cycle property (see Exercise 4.3.8) repeatedly : Add edges one at a time to a putative tree, deleting a maximum-weight edge on the cycle if one is formed. Note : This method has received less attention than the others that we consider because of the comparative difficulty of maintaining a data structure that supports efficient implementation of the &#8220;delete the maximum-weight edge on the cycle&#8217;&#8217; operation. 4.3.24 Reverse-delete algorithm. Develop an implementation that computes the MST as follows: Start with a graph containing all of the edges. Then repeatedly go through the edges in decreasing order of weight. For each edge, check if deleting that edge will disconnect the graph; if not, delete it. Prove that this algorithm computes the MST. What is the order of growth of the number of edge-weight compares performed by your implementation? 4.3.25 Worst-case generator. Develop a reasonable generator for edge-weighted graphs with V vertices and E edges such that the running time of the lazy version of Prim&#8217;s algorithm is nonlinear. Answer the same question for the eager version. 4.3.26 Critical edges. An MST edge whose deletion from the graph would cause the MST weight to increase is called a critical edge. Show how to find all critical edges in a graph in time proportional to E log E . Note : This question assumes that edge weights are not necessarily distinct (otherwise all edges in the MST are critical). 4.3.27 Animations. Write a client program that does dynamic graphical animations of MST algorithms. Run your program for mediumEWG.txt to produce images like the figures on page 621 and page 624. 4.3.28 Space-ef&#64257; cient data structures. Develop an implementation of the lazy version of Prim&#8217;s algorithm that saves space by using lower-level data structures for EdgeWeightedGraph and for MinPQ instead of Bag and Edge. Estimate the amount of memory saved as a function of V and E, using the memory-cost model of Section 1.4</p><p attribs="{'xml:space': 'preserve'}" id="_10800" smilref="Title.smil#_10800"> (see Exercise 4.3.11).</p><p attribs="{'xml:space': 'preserve'}" id="_10801" smilref="Title.smil#_10801" /><pagenum id="p647" page="normal" smilref="Title.smil#p647" /><p attribs="{'xml:space': 'preserve'}" id="_10802" smilref="Title.smil#_10802"> 634</p><p attribs="{'xml:space': 'preserve'}" id="_10803" smilref="Title.smil#_10803"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10804" smilref="Title.smil#_10804"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_10805" smilref="Title.smil#_10805"> 4.3.29 Dense graphs. Develop an implementation of Prim&#8217;s algorithm that uses an eager approach (but not a priority queue) and computes the MST using V 2 edge-weight comparisons. 4.3.30 Euclidean weighted graphs. Modify your solution to Exercise 4.1.37 to create an API EuclideanEdgeWeightedGraph for graphs whose vertices are points in the plane, so that you can work with graphical representations. 4.3.31 MST weights. Develop implementations of weight() for LazyPrimMST, PrimMST, and KruskalMST, using a lazy strategy that iterates through the MST edges when the client calls weight().Then develop alternate implementations that use an eager strategy that maintains a running total as the MST is computed. 4.3.32 Speci&#64257; ed set. Given a connected edge-weighted graph G and a specified set of edges S (having no cycles), describe a way to find a minimum-weight spanning tree of G that contains all the edges in S. 4.3.33 Certi&#64257; cation. Write an MST and EdgeWeightedGraph client check() that uses the following cut optimality conditions implied by Proposition J to verify that a proposed set of edges is in fact an MST: A set of edges is an MST if it is a spanning tree and every edge is a minimum-weight edge in the cut defined by removing that edge from the tree. What is the order of growth of the running time of your method?</p><p attribs="{'xml:space': 'preserve'}" id="_10806" smilref="Title.smil#_10806" /><pagenum id="p648" page="normal" smilref="Title.smil#p648" /><p attribs="{'xml:space': 'preserve'}" id="_10807" smilref="Title.smil#_10807"> 4.3 </p><p attribs="{'xml:space': 'preserve'}" id="_10808" smilref="Title.smil#_10808"> 635</p><p attribs="{'xml:space': 'preserve'}" id="_10809" smilref="Title.smil#_10809"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_10810" smilref="Title.smil#_10810"> 4.3.34 Random sparse edge-weighted graphs. Write a random-sparse-edge-weighted- graph generator based on your solution to Exercise 4.1.41. To assign edge weights, define a random-edge-weighted digraph ADT and write two implementations: one that generates uniformly distributed weights, another that generates weights according to a Gaussian distribution. Write client programs to generate sparse random edge-weighted graphs for both weight distributions with a well-chosen set of values of V and E so that you can use them to run empirical tests on graphs drawn from various distributions of edge weights. 4.3.35 Random Euclidean edge-weighted graphs. Modify your solution to Exercise 4.1.42 to assign the distance between vertices as each edge&#8217;s weight. 4.3.36 Random grid edge-weighted graphs. Modify your your solution to Exercise 4.1.43 to assign a random weight (between 0 and 1) to each edge. 4.3.37 Real edge-weighted graphs. Find a large weighted graph somewhere online&#8212; perhaps a map with distances, telephone connections with costs, or an airline rate schedule. Write a program RandomRealEdgeWeightedGraph that builds a weighted graph by choosing V vertices at random and E weighted edges at random from the subgraph induced by those vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10811" smilref="Title.smil#_10811"> Testing all algorithms and studying all parameters against all graph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input graph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</p><p attribs="{'xml:space': 'preserve'}" id="_10812" smilref="Title.smil#_10812"> 4.3.38 Cost of laziness. Run empirical studies to compare the performance of the lazy version of Prim&#8217;s algorithm with the eager version, for various types of graphs. 4.3.39 Prim versus Kruskal. Run empirical studies to compare the performance of the lazy and eager versions of Prim&#8217;s algorithm with Kruskal&#8217;s algorithm. 4.3.40 Reduced overhead. Run empirical studies to determine the effect of using primitive types instead of Edge values in EdgeWeightedGraph, as described in Exer-</p><p attribs="{'xml:space': 'preserve'}" id="_10813" smilref="Title.smil#_10813"> cise 4.3.28.</p><p attribs="{'xml:space': 'preserve'}" id="_10814" smilref="Title.smil#_10814" /><pagenum id="p649" page="normal" smilref="Title.smil#p649" /><p attribs="{'xml:space': 'preserve'}" id="_10815" smilref="Title.smil#_10815"> 636</p><p attribs="{'xml:space': 'preserve'}" id="_10816" smilref="Title.smil#_10816"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10817" smilref="Title.smil#_10817"> EXPERIMENTS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_10818" smilref="Title.smil#_10818"> 4.3.41 Longest MST edge. Run empirical studies to analyze the length of the longest edge in the MST and the number of graph edges that are not longer than that one. 4.3.42 Partitioning. Develop an implementation based on integrating Kruskal&#8217;s algorithm with quicksort partitioning (instead of using a priority queue) so as to check MST membership of each edge as soon as all smaller edges have been checked. 4.3.43 Boruvka&#8217;s algorithm. Develop an implementation of Boruvka&#8217;s algorithm: Build an MST by adding edges to a growing forest of trees, as in Kruskal&#8217;s algorithm, but in stages. At each stage, find the minimum-weight edge that connects each tree to a different one, then add all such edges to the MST. Assume that the edge weights are all different, to avoid cycles. Hint : Maintain in a vertex-indexed array to identify the edge that connects each component to its nearest neighbor, and use the union-&#64257; nd data structure. 4.3.44 Improved Boruvka. Develop an implementation of Boruvka&#8217;s algorithm that uses doubly-linked circular lists to represent MST subtrees so that subtrees can be merged and renamed in time proportional to E during each stage (and the union-&#64257; nd ADT is therefore not needed). 4.3.45 External MST. Describe how you would find the MST of a graph so large that only V edges can fit into main memory at once. 4.3.46 Johnson&#8217;s algorithm. Develop a priority-queue implementation that uses a d- way heap (see Exercise 2.4.41). Find the best value of d for various weighted graph models.</p><p attribs="{'xml:space': 'preserve'}" id="_10819" smilref="Title.smil#_10819" /><pagenum id="p650" page="normal" smilref="Title.smil#p650" /><p attribs="{'xml:space': 'preserve'}" id="_10820" smilref="Title.smil#_10820"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_10821" smilref="Title.smil#_10821" /></level3><level3 id="_00088"><h3 id="ch4-s4-ss22" smilref="Title.smil#ch4-s4-ss22" xml:space="preserve">Properties of shortest paths</h3><pagenum id="p652" page="normal" smilref="Title.smil#p652" /><p attribs="{'xml:space': 'preserve'}" id="_10822" smilref="Title.smil#_10822"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10823" smilref="Title.smil#_10823"> 639</p><p attribs="{'xml:space': 'preserve'}" id="_10824" smilref="Title.smil#_10824"> Thus, in this section, we consider classic algorithms for the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_10825" smilref="Title.smil#_10825"> Single-source shortest paths. Given an edge-weighted digraph and a source vertex s, support queries of the form Is there a directed path from s to a given target vertex t? If so, find a shortest such path (one whose total weight is minimal).</p><p attribs="{'xml:space': 'preserve'}" id="_10826" smilref="Title.smil#_10826"> The plan of the section is to cover the following list of topics: </p><p attribs="{'xml:space': 'preserve'}" id="_10827" smilref="Title.smil#_10827"> Properties of shortest paths The basic definition of the shortest-paths problem is succinct, but its brevity masks several points worth examining before we begin to formulate algorithms and data structures for solving it: </p><p attribs="{'xml:space': 'preserve'}" id="_10828" smilref="Title.smil#_10828" /><pagenum id="p653" page="normal" smilref="Title.smil#p653" /><p attribs="{'xml:space': 'preserve'}" id="_10829" smilref="Title.smil#_10829"> 640</p><p attribs="{'xml:space': 'preserve'}" id="_10830" smilref="Title.smil#_10830"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10831" smilref="Title.smil#_10831"> parent-edge array representation</p><p attribs="{'xml:space': 'preserve'}" id="_10832" smilref="Title.smil#_10832"> 0 null 1 5-&gt;1 2 0-&gt;2 3 7-&gt;3 4 0-&gt;4 5 4-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10833" smilref="Title.smil#_10833"> est weight from one vertex to another; we are content to find any one of them. </p><p attribs="{'xml:space': 'preserve'}" id="_10834" smilref="Title.smil#_10834"> 0 6-&gt;0 1 5-&gt;1 2 null 3 1-&gt;3 4 5-&gt;4 5 7-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10835" smilref="Title.smil#_10835"> Shortest-paths tree We focus on the single-source shortest-paths problem, where we are given a source vertex s. The result of the computation is a tree known as the shortest-paths tree (SPT), which gives a shortest path from s to every vertex reachable from s.</p><p attribs="{'xml:space': 'preserve'}" id="_10836" smilref="Title.smil#_10836"> 0 6-&gt;0 1 null 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 7-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10837" smilref="Title.smil#_10837"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 null 4 6-&gt;4 5 7-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10838" smilref="Title.smil#_10838"> 0 6-&gt;1 1 5-&gt;1 2 6-&gt;2 3 1-&gt;3 4 5-&gt;4 5 null 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10839" smilref="Title.smil#_10839"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 7-&gt;3 4 5-&gt;4 5 7-&gt;5 6 3-&gt;6 7 null</p><p attribs="{'xml:space': 'preserve'}" id="_10840" smilref="Title.smil#_10840"> source</p><p attribs="{'xml:space': 'preserve'}" id="_10841" smilref="Title.smil#_10841"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 7-&gt;3 4 null 5 4-&gt;5 6 3-&gt;6 7 4-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10842" smilref="Title.smil#_10842"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 7-&gt;3 4 6-&gt;4 5 7-&gt;5 6 null 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_10843" smilref="Title.smil#_10843"> Shortest-paths trees</p><p attribs="{'xml:space': 'preserve'}" id="_10844" smilref="Title.smil#_10844"> Definition. Given an edge-weighted digraph and a designated vertex s, a shortest-paths tree for a source s is a subgraph containing s and all the vertices reachable from s that forms a directed tree rooted at s such that every tree path is a shortest path in the digraph.</p><p attribs="{'xml:space': 'preserve'}" id="_10845" smilref="Title.smil#_10845"> Such a tree always exists: in general there may be two paths of the same length connecting s to a vertex; if that is the case, we can delete the final edge on one of them, continuing until we have only one path connecting the source to each vertex (a rooted tree). By building a shortest-paths tree, we can provide clients with the shortest path from s to any vertex in the graph, using a parent-link represen- tation, in precisely the same manner as for paths in graphs</p><p attribs="{'xml:space': 'preserve'}" id="_10846" smilref="Title.smil#_10846"> edges point away from the source</p><p attribs="{'xml:space': 'preserve'}" id="_10847" smilref="Title.smil#_10847"> source</p><p attribs="{'xml:space': 'preserve'}" id="_10848" smilref="Title.smil#_10848"> in Section 4.1.</p><p attribs="{'xml:space': 'preserve'}" id="_10849" smilref="Title.smil#_10849"> An SPT with 250 vertices</p><p attribs="{'xml:space': 'preserve'}" id="_10850" smilref="Title.smil#_10850" /></level3><level3 id="_00089"><h3 id="ch4-s4-ss23" smilref="Title.smil#ch4-s4-ss23" xml:space="preserve">Edge-weighted digraph data types</h3><pagenum id="p654" page="normal" smilref="Title.smil#p654" /><p attribs="{'xml:space': 'preserve'}" id="_10851" smilref="Title.smil#_10851"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10852" smilref="Title.smil#_10852"> 641</p><p attribs="{'xml:space': 'preserve'}" id="_10853" smilref="Title.smil#_10853"> Edge-weighted digraph data types Our data type for directed edges is simpler than for undirected edges because we follow directed edges in just one direction. Instead of the either() and other() methods in Edge, we have from() and to() methods:</p><p attribs="{'xml:space': 'preserve'}" id="_10854" smilref="Title.smil#_10854"> public class DirectedEdge</p><p attribs="{'xml:space': 'preserve'}" id="_10855" smilref="Title.smil#_10855"> DirectedEdge(int v, int w, double weight) double weight() int from() int to() String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_10856" smilref="Title.smil#_10856"> weight of this edge vertex this edge points from vertex this edge points to string representation</p><p attribs="{'xml:space': 'preserve'}" id="_10857" smilref="Title.smil#_10857"> Weighted directed-edge API</p><p attribs="{'xml:space': 'preserve'}" id="_10858" smilref="Title.smil#_10858"> As with our transition from Graph to EdgeWeightedGraph from Section 4.1 to Sec- tion 4.3, we include an edges() method and use DirectedEdge instead of integers:</p><p attribs="{'xml:space': 'preserve'}" id="_10859" smilref="Title.smil#_10859"> public class EdgeWeightedDigraph</p><p attribs="{'xml:space': 'preserve'}" id="_10860" smilref="Title.smil#_10860"> EdgeWeightedDigraph(int V) empty V-vertex digraph EdgeWeightedDigraph(In in) construct from in int V() int E() void addEdge(DirectedEdge e) Iterable&lt;DirectedEdge&gt; adj(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_10861" smilref="Title.smil#_10861"> number of vertices number of edges add e to this digraph edges pointing from v all edges in this digraph string representation</p><p attribs="{'xml:space': 'preserve'}" id="_10862" smilref="Title.smil#_10862"> Iterable&lt;DirectedEdge&gt; edges()</p><p attribs="{'xml:space': 'preserve'}" id="_10863" smilref="Title.smil#_10863"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_10864" smilref="Title.smil#_10864"> Edge-weighted digraph API</p><p attribs="{'xml:space': 'preserve'}" id="_10865" smilref="Title.smil#_10865"> You can find implementations of these two APIs on the following two pages. These are natural extensions of the implementations of Section 4.2 and Section 4.3. Instead of the adjacency lists of integers used in Digraph, we have adjacency lists of DirectedEdge objects in EdgeWeightedDigraph. As with the transition from Graph to Digraph from Section 4.1 to Section 4.2, the transition from EdgeWeightedGraph in Section 4.3 to EdgeWeightedDigraph in this section simplifies the code, since each edge appears only once in the data structure.</p><p attribs="{'xml:space': 'preserve'}" id="_10866" smilref="Title.smil#_10866" /><pagenum id="p655" page="normal" smilref="Title.smil#p655" /><p attribs="{'xml:space': 'preserve'}" id="_10867" smilref="Title.smil#_10867"> 642</p><p attribs="{'xml:space': 'preserve'}" id="_10868" smilref="Title.smil#_10868"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10869" smilref="Title.smil#_10869"> Directed weighted edge data type</p><p attribs="{'xml:space': 'preserve'}" id="_10870" smilref="Title.smil#_10870"> public class DirectedEdge { private final int v; private final int w; private final double weight;</p><p attribs="{'xml:space': 'preserve'}" id="_10871" smilref="Title.smil#_10871"> // edge source // edge target // edge weight</p><p attribs="{'xml:space': 'preserve'}" id="_10872" smilref="Title.smil#_10872"> public DirectedEdge(int v, int w, double weight) { this.v = v; this.w = w; this.weight = weight; }</p><p attribs="{'xml:space': 'preserve'}" id="_10873" smilref="Title.smil#_10873"> public double weight() { return weight; }</p><p attribs="{'xml:space': 'preserve'}" id="_10874" smilref="Title.smil#_10874"> public int from() { return v; }</p><p attribs="{'xml:space': 'preserve'}" id="_10875" smilref="Title.smil#_10875"> public int to() { return w; }</p><p attribs="{'xml:space': 'preserve'}" id="_10876" smilref="Title.smil#_10876"> public String toString() { return String.format("%d-&gt;%d %.2f", v, w, weight); }</p><p attribs="{'xml:space': 'preserve'}" id="_10877" smilref="Title.smil#_10877"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10878" smilref="Title.smil#_10878"> This DirectedEdge implementation is simpler than the undirected weighted Edge implementation of Section 4.3 (see page 610) because the two vertices are distinguished. Our clients use the idiomatic</p><p attribs="{'xml:space': 'preserve'}" id="_10879" smilref="Title.smil#_10879"> code int v = e.to(), w = e.from(); to access a DirectedEdge e&#8217;s two vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_10880" smilref="Title.smil#_10880" /><pagenum id="p656" page="normal" smilref="Title.smil#p656" /><p attribs="{'xml:space': 'preserve'}" id="_10881" smilref="Title.smil#_10881"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10882" smilref="Title.smil#_10882"> 643</p><p attribs="{'xml:space': 'preserve'}" id="_10883" smilref="Title.smil#_10883"> Edge-weighted digraph data type</p><p attribs="{'xml:space': 'preserve'}" id="_10884" smilref="Title.smil#_10884"> public class EdgeWeightedDigraph { private final int V; // number of vertices private int E; // number of edges private Bag&lt;DirectedEdge&gt;[] adj; // adjacency lists</p><p attribs="{'xml:space': 'preserve'}" id="_10885" smilref="Title.smil#_10885"> public EdgeWeightedDigraph(int V) { this.V = V; this.E = 0; adj = (Bag&lt;DirectedEdge&gt;[]) new Bag[V]; for (int v = 0; v &lt; V; v++) adj[v] = new Bag&lt;DirectedEdge&gt;(); }</p><p attribs="{'xml:space': 'preserve'}" id="_10886" smilref="Title.smil#_10886"> public EdgeWeightedDigraph(In in) // See Exercise 4.4.2.</p><p attribs="{'xml:space': 'preserve'}" id="_10887" smilref="Title.smil#_10887"> public int V() { return V; } public int E() { return E; }</p><p attribs="{'xml:space': 'preserve'}" id="_10888" smilref="Title.smil#_10888"> public void addEdge(DirectedEdge e) { adj[e.from()].add(e); E++; }</p><p attribs="{'xml:space': 'preserve'}" id="_10889" smilref="Title.smil#_10889"> public Iterable&lt;Edge&gt; adj(int v) { return adj[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_10890" smilref="Title.smil#_10890"> public Iterable&lt;DirectedEdge&gt; edges() { Bag&lt;DirectedEdge&gt; bag = new Bag&lt;DirectedEdge&gt;(); for (int v = 0; v &lt; V; v++) for (DirectedEdge e : adj[v]) bag.add(e); return bag; }</p><p attribs="{'xml:space': 'preserve'}" id="_10891" smilref="Title.smil#_10891"> }</p><p attribs="{'xml:space': 'preserve'}" id="_10892" smilref="Title.smil#_10892"> This EdgeWeightedDigraph implementation is an amalgam of EdgeWeightedGraph and Digraph that maintains a vertex-indexed array of bags of DirectedEdge objects. As with Digraph, every edge appears just once: if an edge connects v to w, it appears in v&#8217;s adjacency list. Self-loops and parallel edges are allowed. The toString() implementation is left as Exercise 4.4.2.</p><p attribs="{'xml:space': 'preserve'}" id="_10893" smilref="Title.smil#_10893" /><pagenum id="p657" page="normal" smilref="Title.smil#p657" /><p attribs="{'xml:space': 'preserve'}" id="_10894" smilref="Title.smil#_10894"> 644</p><p attribs="{'xml:space': 'preserve'}" id="_10895" smilref="Title.smil#_10895"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10896" smilref="Title.smil#_10896"> V</p><p attribs="{'xml:space': 'preserve'}" id="_10897" smilref="Title.smil#_10897"> tinyEWD.txt</p><p attribs="{'xml:space': 'preserve'}" id="_10898" smilref="Title.smil#_10898"> E</p><p attribs="{'xml:space': 'preserve'}" id="_10899" smilref="Title.smil#_10899"> 8 15 4 5 0.35 5 4 0.35 4 7 0.37 5 7 0.28 7 5 0.28 5 1 0.32 0 4 0.38 0 2 0.26 7 3 0.39 1 3 0.29 2 7 0.34 6 2 0.40 3 6 0.52 6 0 0.58 6 4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_10900" smilref="Title.smil#_10900"> adj[] 0 1 2 3 4 5 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_10901" smilref="Title.smil#_10901"> 0 2 .26</p><p attribs="{'xml:space': 'preserve'}" id="_10902" smilref="Title.smil#_10902"> 0 4 .38</p><p attribs="{'xml:space': 'preserve'}" id="_10903" smilref="Title.smil#_10903"> 1 3 .29</p><p attribs="{'xml:space': 'preserve'}" id="_10904" smilref="Title.smil#_10904"> 2 7 .34</p><p attribs="{'xml:space': 'preserve'}" id="_10905" smilref="Title.smil#_10905"> 3 6 .52</p><p attribs="{'xml:space': 'preserve'}" id="_10906" smilref="Title.smil#_10906"> Bag objects</p><p attribs="{'xml:space': 'preserve'}" id="_10907" smilref="Title.smil#_10907"> reference to a DirectedEdge object</p><p attribs="{'xml:space': 'preserve'}" id="_10908" smilref="Title.smil#_10908"> 4 7 .37</p><p attribs="{'xml:space': 'preserve'}" id="_10909" smilref="Title.smil#_10909"> 4 5 .35</p><p attribs="{'xml:space': 'preserve'}" id="_10910" smilref="Title.smil#_10910"> 5 1 .32</p><p attribs="{'xml:space': 'preserve'}" id="_10911" smilref="Title.smil#_10911"> 5 7 .28</p><p attribs="{'xml:space': 'preserve'}" id="_10912" smilref="Title.smil#_10912"> 5 4 .35</p><p attribs="{'xml:space': 'preserve'}" id="_10913" smilref="Title.smil#_10913"> 6 4 .93</p><p attribs="{'xml:space': 'preserve'}" id="_10914" smilref="Title.smil#_10914"> 6 0 .58</p><p attribs="{'xml:space': 'preserve'}" id="_10915" smilref="Title.smil#_10915"> 6 2 .40</p><p attribs="{'xml:space': 'preserve'}" id="_10916" smilref="Title.smil#_10916"> 7 3 .39</p><p attribs="{'xml:space': 'preserve'}" id="_10917" smilref="Title.smil#_10917"> 7 5 .28</p><p attribs="{'xml:space': 'preserve'}" id="_10918" smilref="Title.smil#_10918"> Edge-weighted digraph representation</p><p attribs="{'xml:space': 'preserve'}" id="_10919" smilref="Title.smil#_10919"> The figure above shows the data structure that EdgeWeightedDigraph builds to represent the digraph defined by the edges at left when they are added in the order they appear. As usual, we use Bag to represent adjacency lists and depict them as linked lists, the standard representation. As with the unweighted digraphs of Section 4.2, only one representation of each edge appears in the data structure.</p><p attribs="{'xml:space': 'preserve'}" id="_10920" smilref="Title.smil#_10920"> Shortest-paths API. For shortest paths, we use the same design paradigm as for the DepthFirstPaths and BreadthFirstPaths APIs in Section 4.1. Our algorithms implement the following API to provide clients with shortest paths and their lengths:</p><p attribs="{'xml:space': 'preserve'}" id="_10921" smilref="Title.smil#_10921"> public class SP SP(EdgeWeightedDigraph G, int s) constructor</p><p attribs="{'xml:space': 'preserve'}" id="_10922" smilref="Title.smil#_10922"> double distTo(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_10923" smilref="Title.smil#_10923"> boolean hasPathTo(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_10924" smilref="Title.smil#_10924"> Iterable&lt;DirectedEdge&gt; pathTo(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_10925" smilref="Title.smil#_10925"> API for shortest-paths implementations</p><p attribs="{'xml:space': 'preserve'}" id="_10926" smilref="Title.smil#_10926"> distance from s to v, &#8734; if no path path from s to v? path from s to v, null if none</p><p attribs="{'xml:space': 'preserve'}" id="_10927" smilref="Title.smil#_10927"> The constructor builds the shortest-paths tree and computes shortest-paths distances; the client query methods use those data structures to provide distances and iterable paths to the client.</p><p attribs="{'xml:space': 'preserve'}" id="_10928" smilref="Title.smil#_10928" /><pagenum id="p658" page="normal" smilref="Title.smil#p658" /><p attribs="{'xml:space': 'preserve'}" id="_10929" smilref="Title.smil#_10929"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10930" smilref="Title.smil#_10930"> 645</p><p attribs="{'xml:space': 'preserve'}" id="_10931" smilref="Title.smil#_10931"> public static void main(String[] args) { EdgeWeightedDigraph G; G = new EdgeWeightedDigraph(new In(args[0])); int s = Integer.parseInt(args[1]); SP sp = new SP(G, s);</p><p attribs="{'xml:space': 'preserve'}" id="_10932" smilref="Title.smil#_10932"> Test client. A sample client is shown below. It takes an input stream and source vertex index as command-line arguments, reads the edge-weighted digraph from the input stream, computes the SPT of that digraph for the source, and prints the shortest path from the source to each of the other vertices. We assume that all of our shortest-paths implementations include this test client. Our examples use the file tinyEWD.txt shown on the facing page, which defines the edges and weights that are used in the small sample digraph that we use for detailed traces of shortest- paths algorithms. It uses the same file format that we used for MST al- gorithms: the number of vertices V and the number of edges E followed by E lines, each with two vertex indices and a weight. You can also find on the booksite files that define several larger edge-weighted digraphs, including the file mediumEWD.txt which defines the 250-vertex graph drawn on page 640. In the drawing of the graph, every line represents edges in both directions, so this file has twice as many lines as the corresponding file mediumEWG.txt that we examined for MSTs. In the drawing of the SPT, each line represents a directed edge pointing away from the source.</p><p attribs="{'xml:space': 'preserve'}" id="_10933" smilref="Title.smil#_10933"> for (int t = 0; t &lt; G.V(); t++) { StdOut.print(s + " to " + t); StdOut.printf(" (%4.2f): ", sp.distTo(t)); if (sp.hasPathTo(t)) for (DirectedEdge e : sp.pathTo(t)) StdOut.print(e + " "); StdOut.println(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_10934" smilref="Title.smil#_10934"> Shortest paths test client</p><p attribs="{'xml:space': 'preserve'}" id="_10935" smilref="Title.smil#_10935"> % java SP tinyEWD.txt 0 0 to 0 (0.00): 0 to 1 (1.05): 0-&gt;4 0.38 4-&gt;5 0.35 5-&gt;1 0.32 0 to 2 (0.26): 0-&gt;2 0.26 0 to 3 (0.99): 0-&gt;2 0.26 2-&gt;7 0.34 7-&gt;3 0.39 0 to 4 (0.38): 0-&gt;4 0.38 0 to 5 (0.73): 0-&gt;4 0.38 4-&gt;5 0.35 0 to 6 (1.51): 0-&gt;2 0.26 2-&gt;7 0.34 7-&gt;3 0.39 3-&gt;6 0.52 0 to 7 (0.60): 0-&gt;2 0.26 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_10936" smilref="Title.smil#_10936" /><pagenum id="p659" page="normal" smilref="Title.smil#p659" /><p attribs="{'xml:space': 'preserve'}" id="_10937" smilref="Title.smil#_10937"> 646</p><p attribs="{'xml:space': 'preserve'}" id="_10938" smilref="Title.smil#_10938"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10939" smilref="Title.smil#_10939"> Data structures for shortest paths. The data structures that we need to represent shortest paths are straightforward: </p><p attribs="{'xml:space': 'preserve'}" id="_10940" smilref="Title.smil#_10940"> Edge relaxation. Our shortest-paths</p><p attribs="{'xml:space': 'preserve'}" id="_10941" smilref="Title.smil#_10941"> edgeTo[] distTo[] 0 null 0 1 5-&gt;1 0.32 1.05 2 0-&gt;2 0.26 0.26 3 7-&gt;3 0.37 0.97 4 0-&gt;4 0.38 0.38 5 4-&gt;5 0.35 0.73 6 3-&gt;6 0.52 1.49 7 2-&gt;7 0.34 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_10942" smilref="Title.smil#_10942"> Shortest-paths data structures</p><p attribs="{'xml:space': 'preserve'}" id="_10943" smilref="Title.smil#_10943"> implementations are based on a simple operation known as relaxation. We start knowing only the graph&#8217;s edges and weights, with the distTo[] entry for the source initialized to 0 and all of the other distTo[] entries initialized to Double.POSITIVE_INFINITY. As an algorithm proceeds, it gathers information about the shortest paths that connect the source to each vertex encountered in our edgeTo[] and distTo[] data structures. By updating this information when we encounter edges, we can make new inferences about shortest paths. Speci&#64257; cally, we use edge relaxation, defined as follows: to relax an edge v-&gt;w means to test whether the best known way from s to w is to go from s to v, then take the edge from v to w, and, if so, update our data structures to indicate that to be the case. The code at the right implements this opera- tion. The best known distance to w through v is the sum of</p><p attribs="{'xml:space': 'preserve'}" id="_10944" smilref="Title.smil#_10944"> private void relax(DirectedEdge e) { int v = e.from(), w = e.to(); if (distTo[w] &gt; distTo[v] + e.weight()) { distTo[w] = distTo[v] + e.weight(); edgeTo[w] = e; } }</p><p attribs="{'xml:space': 'preserve'}" id="_10945" smilref="Title.smil#_10945"> distTo[v] and e.weight()&#8212;</p><p attribs="{'xml:space': 'preserve'}" id="_10946" smilref="Title.smil#_10946"> if that value is not smaller than distTo[w], we say the edge is ineligible, and we ignore it; if it is smaller, we update the data</p><p attribs="{'xml:space': 'preserve'}" id="_10947" smilref="Title.smil#_10947"> Edge relaxation</p><p attribs="{'xml:space': 'preserve'}" id="_10948" smilref="Title.smil#_10948" /><pagenum id="p660" page="normal" smilref="Title.smil#p660" /><p attribs="{'xml:space': 'preserve'}" id="_10949" smilref="Title.smil#_10949"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10950" smilref="Title.smil#_10950"> 647</p><p attribs="{'xml:space': 'preserve'}" id="_10951" smilref="Title.smil#_10951"> structures. The figure at the bottom of this page illustrates the two possible outcomes of an edge-relaxation operation. Either the edge is ineligible (as in the example at left) and no changes are made, or the edge v-&gt;w leads to a shorter path to w (as in the example at right) and we update edgeTo[w] and distTo[w] (which might render some other edges ineligible and might create some new eligible edges). The term relaxation follows from the idea of a rubber band stretched tight on a path connecting two vertices: relaxing an edge is akin to relaxing the tension on the rubber band along a shorter path, if possible. We say that an edge e can be successfully relaxed if relax() would change the</p><p attribs="{'xml:space': 'preserve'}" id="_10952" smilref="Title.smil#_10952"> values of distTo[e.to()] and edgeTo[e.to()].</p><p attribs="{'xml:space': 'preserve'}" id="_10953" smilref="Title.smil#_10953"> v-&gt;w is ineligible</p><p attribs="{'xml:space': 'preserve'}" id="_10954" smilref="Title.smil#_10954"> distTo[v]</p><p attribs="{'xml:space': 'preserve'}" id="_10955" smilref="Title.smil#_10955"> v-&gt;w is eligible</p><p attribs="{'xml:space': 'preserve'}" id="_10956" smilref="Title.smil#_10956"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10957" smilref="Title.smil#_10957"> 3.1</p><p attribs="{'xml:space': 'preserve'}" id="_10958" smilref="Title.smil#_10958"> weight of v-&gt;w is 1.3</p><p attribs="{'xml:space': 'preserve'}" id="_10959" smilref="Title.smil#_10959"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10960" smilref="Title.smil#_10960"> black edges are in edgeTo[]</p><p attribs="{'xml:space': 'preserve'}" id="_10961" smilref="Title.smil#_10961"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10962" smilref="Title.smil#_10962"> w</p><p attribs="{'xml:space': 'preserve'}" id="_10963" smilref="Title.smil#_10963"> 3.3</p><p attribs="{'xml:space': 'preserve'}" id="_10964" smilref="Title.smil#_10964"> distTo[w]</p><p attribs="{'xml:space': 'preserve'}" id="_10965" smilref="Title.smil#_10965"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10966" smilref="Title.smil#_10966"> no changes</p><p attribs="{'xml:space': 'preserve'}" id="_10967" smilref="Title.smil#_10967"> w</p><p attribs="{'xml:space': 'preserve'}" id="_10968" smilref="Title.smil#_10968"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10969" smilref="Title.smil#_10969"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10970" smilref="Title.smil#_10970"> Edge relaxation (two cases)</p><p attribs="{'xml:space': 'preserve'}" id="_10971" smilref="Title.smil#_10971"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10972" smilref="Title.smil#_10972"> 3.1</p><p attribs="{'xml:space': 'preserve'}" id="_10973" smilref="Title.smil#_10973"> w</p><p attribs="{'xml:space': 'preserve'}" id="_10974" smilref="Title.smil#_10974"> 7.2</p><p attribs="{'xml:space': 'preserve'}" id="_10975" smilref="Title.smil#_10975"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10976" smilref="Title.smil#_10976"> 3.1</p><p attribs="{'xml:space': 'preserve'}" id="_10977" smilref="Title.smil#_10977"> edgeTo[w]</p><p attribs="{'xml:space': 'preserve'}" id="_10978" smilref="Title.smil#_10978"> w</p><p attribs="{'xml:space': 'preserve'}" id="_10979" smilref="Title.smil#_10979"> 4.4</p><p attribs="{'xml:space': 'preserve'}" id="_10980" smilref="Title.smil#_10980"> no longer in SPT</p><p attribs="{'xml:space': 'preserve'}" id="_10981" smilref="Title.smil#_10981" /><pagenum id="p661" page="normal" smilref="Title.smil#p661" /><p attribs="{'xml:space': 'preserve'}" id="_10982" smilref="Title.smil#_10982"> 648</p><p attribs="{'xml:space': 'preserve'}" id="_10983" smilref="Title.smil#_10983"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_10984" smilref="Title.smil#_10984"> Vertex relaxation. All of our implementations actually relax all the edges pointing from a given vertex as shown in the (overloaded) implementation of relax() below. Note that any edge from a vertex whose distTo[v] entry is finite to a vertex whose distTo[] entry is infinite is eligible and will be added to edgeTo[] if relaxed. In particu- lar, some edge leaving the source is the first to be added to edgeTo[]. Our algorithms choose vertices judiciously, so that each vertex relaxation finds a shorter path than the best known so far to some vertex, incrementally progressing toward the goal of finding shortest paths to every vertex.</p><p attribs="{'xml:space': 'preserve'}" id="_10985" smilref="Title.smil#_10985"> before</p><p attribs="{'xml:space': 'preserve'}" id="_10986" smilref="Title.smil#_10986"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10987" smilref="Title.smil#_10987"> after</p><p attribs="{'xml:space': 'preserve'}" id="_10988" smilref="Title.smil#_10988"> s</p><p attribs="{'xml:space': 'preserve'}" id="_10989" smilref="Title.smil#_10989"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10990" smilref="Title.smil#_10990"> v</p><p attribs="{'xml:space': 'preserve'}" id="_10991" smilref="Title.smil#_10991"> still ineligible</p><p attribs="{'xml:space': 'preserve'}" id="_10992" smilref="Title.smil#_10992"> now ineligible</p><p attribs="{'xml:space': 'preserve'}" id="_10993" smilref="Title.smil#_10993"> Vertex relaxation</p><p attribs="{'xml:space': 'preserve'}" id="_10994" smilref="Title.smil#_10994"> private void relax(EdgeWeightedDigraph G, int v) { for (DirectedEdge e : G.adj(v)) { int w = e.to(); if (distTo[w] &gt; distTo[v] + e.weight()) { distTo[w] = distTo[v] + e.weight(); edgeTo[w] = e; } } }</p><p attribs="{'xml:space': 'preserve'}" id="_10995" smilref="Title.smil#_10995"> Vertex relaxation</p><p attribs="{'xml:space': 'preserve'}" id="_10996" smilref="Title.smil#_10996" /><pagenum id="p662" page="normal" smilref="Title.smil#p662" /><p attribs="{'xml:space': 'preserve'}" id="_10997" smilref="Title.smil#_10997"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_10998" smilref="Title.smil#_10998"> 649</p><p attribs="{'xml:space': 'preserve'}" id="_10999" smilref="Title.smil#_10999"> Client query methods. In a manner similar to our implementations for pathfinding APIs in Section 4.1 (and Exercise 4.1.13), the edgeTo[] and distTo[] data structures directly support the pathTo(), hasPathTo(), and distTo() client query meth- ods, as shown below. This code is included in all of our shortest-paths implementa- tions. As we have noted already, distTo[v] is only meaningful when v is reachable from s and we adopt the convention that distTo() should return infinity for vertices that are not reachable from s. To implement this convention, we initialize all distTo[] entries to Double.POSITIVE_INFINITY and distTo[s] to 0; then our shortest-paths implementations will set distTo[v] to a finite value for all vertices v that are reachable from the source. Thus, we can dispense with the marked[] array that we normally use to mark reachable vertices in a graph search and implement hasPathTo(v) by testing</p><p attribs="{'xml:space': 'preserve'}" id="_11000" smilref="Title.smil#_11000"> whether distTo[v] equals Double.POSITIVE_INFINITY. For pathTo(), we use the</p><p attribs="{'xml:space': 'preserve'}" id="_11001" smilref="Title.smil#_11001"> convention that pathTo(v) returns null if v is not reachable from the source and a path with no edges if v is the source. For reachable vertices, we travel up the tree, pushing the edges that we find on a stack, in the same manner as we did</p><p attribs="{'xml:space': 'preserve'}" id="_11002" smilref="Title.smil#_11002"> for DepthFirstPaths and BreadthFirstPaths.</p><p attribs="{'xml:space': 'preserve'}" id="_11003" smilref="Title.smil#_11003"> The figure at right shows the discovery of the path 0-&gt;2-&gt;7-&gt;3-&gt;6 for our example.</p><p attribs="{'xml:space': 'preserve'}" id="_11004" smilref="Title.smil#_11004"> SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11005" smilref="Title.smil#_11005"> pathTo(6)</p><p attribs="{'xml:space': 'preserve'}" id="_11006" smilref="Title.smil#_11006"> e path</p><p attribs="{'xml:space': 'preserve'}" id="_11007" smilref="Title.smil#_11007"> v edgeTo[] 0 null 1 5-&gt;1 2 0-&gt;2 3 7-&gt;3 4 0-&gt;4 5 4-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11008" smilref="Title.smil#_11008"> 3-&gt;6 7-&gt;3 3-&gt;6 2-&gt;7 7-&gt;3 3-&gt;6 0-&gt;2 2-&gt;7 7-&gt;3 3-&gt;6 0-&gt;2 2-&gt;7 7-&gt;3 3-&gt;6</p><p attribs="{'xml:space': 'preserve'}" id="_11009" smilref="Title.smil#_11009"> null</p><p attribs="{'xml:space': 'preserve'}" id="_11010" smilref="Title.smil#_11010"> Trace of pathTo() computation</p><p attribs="{'xml:space': 'preserve'}" id="_11011" smilref="Title.smil#_11011"> public double distTo(int v) { return distTo[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_11012" smilref="Title.smil#_11012"> public boolean hasPathTo(int v) { return distTo[v] &lt; Double.POSITIVE_INFINITY; }</p><p attribs="{'xml:space': 'preserve'}" id="_11013" smilref="Title.smil#_11013"> public Iterable&lt;DirectedEdge&gt; pathTo(int v) { if (!hasPathTo(v)) return null; Stack&lt;DirectedEdge&gt; path = new Stack&lt;DirectedEdge&gt;(); for (DirectedEdge e = edgeTo[v]; e != null; e = edgeTo[e.from()]) path.push(e); return path; }</p><p attribs="{'xml:space': 'preserve'}" id="_11014" smilref="Title.smil#_11014"> Client query methods for shortest paths</p><p attribs="{'xml:space': 'preserve'}" id="_11015" smilref="Title.smil#_11015" /><pagenum id="p663" page="normal" smilref="Title.smil#p663" /><p attribs="{'xml:space': 'preserve'}" id="_11016" smilref="Title.smil#_11016"> 650</p><p attribs="{'xml:space': 'preserve'}" id="_11017" smilref="Title.smil#_11017"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11018" smilref="Title.smil#_11018"> Theoretical basis for shortest-paths algorithms. Edge relaxation is an easy-</p><p attribs="{'xml:space': 'preserve'}" id="_11019" smilref="Title.smil#_11019"> to-implement fundamental operation that provides a practical basis for our shortest- paths implementations. It also provides a theoretical basis for understanding the algorithms and an opportunity for us to do our algorithm correctness proofs at the outset.</p><p attribs="{'xml:space': 'preserve'}" id="_11020" smilref="Title.smil#_11020"> Optimality conditions. The following proposition shows an equivalence between the global condition that the distances are shortest-paths distances, and the local condition that we test to relax an edge.</p><p attribs="{'xml:space': 'preserve'}" id="_11021" smilref="Title.smil#_11021"> Proposition P. ( Shortest-paths optimality conditions) Let G be an edge-weighted</p><p attribs="{'xml:space': 'preserve'}" id="_11022" smilref="Title.smil#_11022"> digraph, with s a source vertex in G and distTo[] a vertex-indexed array of path lengths in G such that, for all v reachable from s, the value of distTo[v] is the length of some path from s to v with distTo[v] equal to infinity for all v not reachable from s. These values are the lengths of shortest paths if and only if they satisfy</p><p attribs="{'xml:space': 'preserve'}" id="_11023" smilref="Title.smil#_11023"> distTo[w] &lt;= distTo[v] + e.weight() for each edge e from v to w (or, in</p><p attribs="{'xml:space': 'preserve'}" id="_11024" smilref="Title.smil#_11024"> other words, no edge is eligible).</p><p attribs="{'xml:space': 'preserve'}" id="_11025" smilref="Title.smil#_11025"> Proof : Suppose that distTo[w] is the length of a shortest path from s to w. If</p><p attribs="{'xml:space': 'preserve'}" id="_11026" smilref="Title.smil#_11026"> distTo[w] &gt; distTo[v] + e.weight() for some edge e from v to w, then e</p><p attribs="{'xml:space': 'preserve'}" id="_11027" smilref="Title.smil#_11027"> would give a path from s to w (through v) of length less than distTo[w], a contra- diction. Thus the optimality conditions are necessary. To prove that the optimality conditions are suf&#64257; cient, suppose that w is reachable from s and that s = v0-&gt;v1-&gt;v2...-&gt;vk = w is a shortest path from s to w, of weight OPTsw. For i from 1 to k, denote the edge from vi-1 to vi by ei. By the optimality conditions, we have the following sequence of inequalities:</p><p attribs="{'xml:space': 'preserve'}" id="_11028" smilref="Title.smil#_11028"> distTo[w] = distTo[vk] &lt;= distTo[vk-1] + ek.weight() distTo[vk-1] &lt;= distTo[vk-2] + ek-1.weight() ... distTo[v2] &lt;= distTo[v1] + e2.weight() distTo[v1] &lt;= distTo[s] + e1.weight()</p><p attribs="{'xml:space': 'preserve'}" id="_11029" smilref="Title.smil#_11029"> Collapsing these inequalities and eliminating distTo[s] = 0.0, we have</p><p attribs="{'xml:space': 'preserve'}" id="_11030" smilref="Title.smil#_11030"> distTo[w] &lt;= e1.weight() + ... + ek.weight() = OPTsw.</p><p attribs="{'xml:space': 'preserve'}" id="_11031" smilref="Title.smil#_11031"> Now, distTo[w] is the length of some path from s to w, so it cannot be smaller than the length of a shortest path. Thus, we have shown that</p><p attribs="{'xml:space': 'preserve'}" id="_11032" smilref="Title.smil#_11032"> OPTsw &lt;= distTo[w] &lt;= OPTsw</p><p attribs="{'xml:space': 'preserve'}" id="_11033" smilref="Title.smil#_11033"> and equality must hold.</p><p attribs="{'xml:space': 'preserve'}" id="_11034" smilref="Title.smil#_11034" /></level3><level3 id="_00090"><h3 id="ch4-s4-ss24" smilref="Title.smil#ch4-s4-ss24" xml:space="preserve">Generic shortest paths algorithm</h3><pagenum id="p664" page="normal" smilref="Title.smil#p664" /><p attribs="{'xml:space': 'preserve'}" id="_11035" smilref="Title.smil#_11035"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11036" smilref="Title.smil#_11036"> 651</p><p attribs="{'xml:space': 'preserve'}" id="_11037" smilref="Title.smil#_11037"> Certi&#64257; cation. An important practical consequence of Proposition P is its applicability to certi&#64257; cation. However an algorithm computes distTo[], we can check whether it contains shortest-path lengths in a single pass through the edges of the graph, checking whether the optimality conditions are satis&#64257; ed. Shortest-paths algorithms can be com- plicated, and this ability to efficiently test their outcome is crucial. We include a method check() in our implementations on the booksite for this purpose. This method also checks that edgeTo[] specifies paths from the source and is consistent with distTo[].</p><p attribs="{'xml:space': 'preserve'}" id="_11038" smilref="Title.smil#_11038"> Generic algorithm. The optimality conditions lead immediately to a generic algorithm that encompasses all of the shortest-paths algorithms that we consider. For the moment, we restrict attention to nonnegative weights.</p><p attribs="{'xml:space': 'preserve'}" id="_11039" smilref="Title.smil#_11039"> Proposition Q. ( Generic shortest-paths algorithm) Initialize distTo[s] to 0 and</p><p attribs="{'xml:space': 'preserve'}" id="_11040" smilref="Title.smil#_11040"> all other distTo[] values to in&#64257; nity, and proceed as follows: Relax any edge in G, continuing until no edge is eligible. For all vertices w reachable from s, the value of distTo[w] after this computation is the length of a shortest path from s to w (and the value of edgeTo[] is the last edge on that path).</p><p attribs="{'xml:space': 'preserve'}" id="_11041" smilref="Title.smil#_11041"> Proof : Relaxing an edge v-&gt;w always sets distTo[w] to the length of some path from s (and edgeTo[w] to the last edge on that path). For any vertex w reachable from s, some edge on the shortest path to w is eligible as long as distTo[w] remains in&#64257; nite, so the algorithm continues until the distTo[] value of each vertex reachable from s is the length of some path to that vertex. For any vertex v for which the shortest path is well-de&#64257; ned, throughout the algorithm distTo[v] is the length of some (simple) path from s to v and is strictly monotonically decreasing. Thus, it can decrease at most a finite number of times (once for each simple path from s to v). When no edge is eligible, Proposition P applies.</p><p attribs="{'xml:space': 'preserve'}" id="_11042" smilref="Title.smil#_11042"> The key reason for considering the optimality conditions and the generic algorithm is that the generic algorithm does not specify in which order the edges are to be relaxed. Thus, all that we need to do to prove that any algorithm computes shortest paths is to prove that it relaxes edges until no edge is eligible.</p><p attribs="{'xml:space': 'preserve'}" id="_11043" smilref="Title.smil#_11043" /></level3><level3 id="_00091"><h3 id="ch4-s4-ss25" smilref="Title.smil#ch4-s4-ss25" xml:space="preserve">Dijkstra's algorithm</h3><pagenum id="p665" page="normal" smilref="Title.smil#p665" /><p attribs="{'xml:space': 'preserve'}" id="_11044" smilref="Title.smil#_11044"> 652</p><p attribs="{'xml:space': 'preserve'}" id="_11045" smilref="Title.smil#_11045"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11046" smilref="Title.smil#_11046"> Dijkstra&#8217;s algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11047" smilref="Title.smil#_11047"> In Section 4.3, we discussed Prim&#8217;s algorithm for finding the minimum spanning tree (MST) of an edge-weighted undirected graph: we build the MST by attaching a new edge to a single growing tree at each step. Dijkstra&#8217;s algorithm is an analogous scheme to compute an SPT. We begin by initializing dist[s] to 0 and all other distTo[] entries to positive in&#64257; nity, then we relax and add to the tree a non-tree vertex with the lowest distTo[] value, continuing until all vertices are on the tree or no non-tree vertex has a finite distTo[] value.</p><p attribs="{'xml:space': 'preserve'}" id="_11048" smilref="Title.smil#_11048"> Proposition R. Dijkstra&#8217;s algorithm solves the single-source shortest-paths problem in edge-weighted digraphs with nonnegative weights.</p><p attribs="{'xml:space': 'preserve'}" id="_11049" smilref="Title.smil#_11049"> Proof : If v is reachable from the source, every edge v-&gt;w is relaxed exactly once, when v is relaxed, leaving distTo[w] &lt;= distTo[v] + e.weight(). This inequality holds until the algorithm completes, since distTo[w] can only decrease (any relaxation can only decrease a distTo[] value) and distTo[v] never changes (because edge weights are nonnegative and we choose the lowest distTo[] value at each step, no subsequent relaxation can set any distTo[] entry to a lower value than distTo[v]). Thus, after all vertices reachable from s have been added to the tree, the shortest-paths optimality conditions hold, and Proposition P applies.</p><p attribs="{'xml:space': 'preserve'}" id="_11050" smilref="Title.smil#_11050"> tree edge (black)</p><p attribs="{'xml:space': 'preserve'}" id="_11051" smilref="Title.smil#_11051"> crossing edge (red)</p><p attribs="{'xml:space': 'preserve'}" id="_11052" smilref="Title.smil#_11052"> Data structures. To implement Dijkstra&#8217;s algorithm we add to our distTo[] and edgeTo[] data structures an index priority queue pq to keep track of vertices that are candidates for being the next to be relaxed. Recall that an IndexMinPQ allows us to associate indices with keys (priorities) and to remove and return the index corresponding to the lowest key. For this application, we always associate a vertex v with distTo[v], and we have a direct and immediate implementation of Dijkstra&#8217;s algorithm as stated. Moreover, it is immediate by induction that the edgeTo[] entries corresponding to reachable vertices form a tree, the SPT. Alternative viewpoint. Another way to understand the dynamics of the algorithm derives from the proof, diagrammed at left: we have the invariant that distTo[] entries for tree vertices are shortest-paths distances and for each vertex w on the priority queue, distTo[w] is the weight of a shortest path from s to w that uses only</p><p attribs="{'xml:space': 'preserve'}" id="_11053" smilref="Title.smil#_11053"> crossing edge on shortest path from s having just one crossing edge must be on SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11054" smilref="Title.smil#_11054"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11055" smilref="Title.smil#_11055"> v</p><p attribs="{'xml:space': 'preserve'}" id="_11056" smilref="Title.smil#_11056"> w</p><p attribs="{'xml:space': 'preserve'}" id="_11057" smilref="Title.smil#_11057"> Dijkstra&#8217;s shortest-paths algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11058" smilref="Title.smil#_11058" /><pagenum id="p666" page="normal" smilref="Title.smil#p666" /><p attribs="{'xml:space': 'preserve'}" id="_11059" smilref="Title.smil#_11059"> intermediate vertices in the tree and ends in the crossing edge edgeTo[w]. The distTo[] entry for the vertex with the smallest priority is a shortest- path weight, not smaller than the shortest-path weight to any vertex already relaxed, and not larger than the shortest-path weight to any vertex not yet relaxed. That vertex is next to be relaxed. Reachable vertices are relaxed in order of the weight of their shortest path from s. The figure at right is a trace for our small sample graph tinyEWD.txt. For this example, the algorithm builds the SPT as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_11060" smilref="Title.smil#_11060"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11061" smilref="Title.smil#_11061"> 653</p><p attribs="{'xml:space': 'preserve'}" id="_11062" smilref="Title.smil#_11062"> red: on pq</p><p attribs="{'xml:space': 'preserve'}" id="_11063" smilref="Title.smil#_11063"> black: on SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11064" smilref="Title.smil#_11064"> edgeTo[] 0 1 2 0-&gt;2 0.26 3 4 0-&gt;4 0.38 5 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_11065" smilref="Title.smil#_11065"> index</p><p attribs="{'xml:space': 'preserve'}" id="_11066" smilref="Title.smil#_11066"> 0 1 2 0-&gt;2 0.26 3 4 0-&gt;4 0.38 5 6 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11067" smilref="Title.smil#_11067"> distTo[] 0.00</p><p attribs="{'xml:space': 'preserve'}" id="_11068" smilref="Title.smil#_11068"> 0.26</p><p attribs="{'xml:space': 'preserve'}" id="_11069" smilref="Title.smil#_11069"> 0.38</p><p attribs="{'xml:space': 'preserve'}" id="_11070" smilref="Title.smil#_11070"> priority</p><p attribs="{'xml:space': 'preserve'}" id="_11071" smilref="Title.smil#_11071"> 0.00</p><p attribs="{'xml:space': 'preserve'}" id="_11072" smilref="Title.smil#_11072"> 0.26</p><p attribs="{'xml:space': 'preserve'}" id="_11073" smilref="Title.smil#_11073"> 0.38</p><p attribs="{'xml:space': 'preserve'}" id="_11074" smilref="Title.smil#_11074"> 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11075" smilref="Title.smil#_11075"> 0 1 2 0-&gt;2 0.26 3 4 0-&gt;4 0.38 5 4-&gt;5 0.35 6 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11076" smilref="Title.smil#_11076"> 0.00</p><p attribs="{'xml:space': 'preserve'}" id="_11077" smilref="Title.smil#_11077"> 0.26</p><p attribs="{'xml:space': 'preserve'}" id="_11078" smilref="Title.smil#_11078"> 0.38 0.73</p><p attribs="{'xml:space': 'preserve'}" id="_11079" smilref="Title.smil#_11079"> 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11080" smilref="Title.smil#_11080"> 0 1 2 0-&gt;2 0.26 3 7-&gt;3 0.37 4 0-&gt;4 0.38 5 4-&gt;5 0.35 6 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11081" smilref="Title.smil#_11081"> 0.00</p><p attribs="{'xml:space': 'preserve'}" id="_11082" smilref="Title.smil#_11082"> 0.26 0.97 0.38 0.73</p><p attribs="{'xml:space': 'preserve'}" id="_11083" smilref="Title.smil#_11083"> 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11084" smilref="Title.smil#_11084"> 0 1 5-&gt;1 0.32 2 0-&gt;2 0.26 3 7-&gt;3 0.37 4 0-&gt;4 0.38 5 4-&gt;5 0.35 6 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11085" smilref="Title.smil#_11085"> 0.00 1.05 0.26 0.97 0.38 0.73</p><p attribs="{'xml:space': 'preserve'}" id="_11086" smilref="Title.smil#_11086"> 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11087" smilref="Title.smil#_11087"> 0 0.00 1 5-&gt;1 0.32 1.05 2 0-&gt;2 0.26 0.26 3 7-&gt;3 0.37 0.97 4 0-&gt;4 0.38 0.38 5 4-&gt;5 0.35 0.73 6 3-&gt;6 0.52 1.49 7 2-&gt;7 0.34 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11088" smilref="Title.smil#_11088"> 0 1 5-&gt;1 0.32 2 0-&gt;2 0.26 3 7-&gt;3 0.37 4 0-&gt;4 0.38 5 4-&gt;5 0.35 6 3-&gt;6 0.52 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11089" smilref="Title.smil#_11089"> 0 1 5-&gt;1 0.32 2 0-&gt;2 0.26 3 7-&gt;3 0.37 4 0-&gt;4 0.38 5 4-&gt;5 0.35 6 3-&gt;6 0.52 7 2-&gt;7 0.34</p><p attribs="{'xml:space': 'preserve'}" id="_11090" smilref="Title.smil#_11090"> 0.00 1.05 0.26 0.97 0.38 0.73 1.49 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11091" smilref="Title.smil#_11091"> 0.00 1.05 0.26 0.97 0.38 0.73 1.49 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11092" smilref="Title.smil#_11092"> Trace of Dijkstra&#8217;s algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11093" smilref="Title.smil#_11093" /><pagenum id="p667" page="normal" smilref="Title.smil#p667" /><p attribs="{'xml:space': 'preserve'}" id="_11094" smilref="Title.smil#_11094"> 654</p><p attribs="{'xml:space': 'preserve'}" id="_11095" smilref="Title.smil#_11095"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11096" smilref="Title.smil#_11096"> The implementation of Dijkstra&#8217;s algorithm in DijkstraSP (Algorithm 4.9) is a rendition in code of the one-sentence description of the algorithm, enabled by adding one statement to relax() to handle two cases: either the to() vertex on an edge is not yet on the priority queue, in which case we use insert() to add it to the priority queue, or it is already on the priority queue and its priority lowered, in which case change() does so.</p><p attribs="{'xml:space': 'preserve'}" id="_11097" smilref="Title.smil#_11097"> Proposition R (continued). Dijkstra&#8217;s algorithm uses extra space proportional to V and time proportional to E log V (in the worst case) to solve the single-source shortest paths problem in an edge-weighted digraph with E edges and V vertices. Proof : Same as for Prim&#8217;s algorithm (see Proposition N).</p><p attribs="{'xml:space': 'preserve'}" id="_11098" smilref="Title.smil#_11098"> As we have indicated, another way to think about Dijkstra&#8217;s algorithm is to</p><p attribs="{'xml:space': 'preserve'}" id="_11099" smilref="Title.smil#_11099"> compare it to Prim&#8217;s MST algorithm from Section 4.3 (see page 622). Both algorithms build a rooted tree by adding an edge to a growing tree: Prim&#8217;s adds next the non-tree vertex that is closest to the tree; Dijkstra&#8217;s adds next the non-tree vertex that is closest to the source. The marked[] array is not needed, because the condition !marked[w] is equivalent to the condition that distTo[w] is in&#64257; nite. In other words, switching to undirected graphs and edges and omitting the references to distTo[v] in the relax() code in Algorithm 4.9 gives an implementation of Algorithm 4.7, the eager version of Prim&#8217;s algorithm (!). Also, a lazy version of Dijkstra&#8217;s algorithm along the lines of LazyPrimMST (page 619) is not difficult to develop.</p><p attribs="{'xml:space': 'preserve'}" id="_11100" smilref="Title.smil#_11100"> Variants. Our implementation of Dijkstra&#8217;s algorithm, with suitable modi&#64257; cations, is effective for solving other versions of the problem, such as the following:</p><p attribs="{'xml:space': 'preserve'}" id="_11101" smilref="Title.smil#_11101"> Single-source shortest paths in undirected graphs. Given an edge-weighted un-</p><p attribs="{'xml:space': 'preserve'}" id="_11102" smilref="Title.smil#_11102"> directed graph and a source vertex s, support queries of the form Is there a path from s to a given target vertex v? If so, find a shortest such path (one whose total weight is minimal).</p><p attribs="{'xml:space': 'preserve'}" id="_11103" smilref="Title.smil#_11103"> The solution to this problem is immediate if we view the undirected graph as a digraph. That is, given an undirected graph, build an edge-weighted digraph with the same vertices and with two directed edges (one in each direction) corresponding to each edge in the graph. There is a one-to-one correspondence between paths in the digraph and paths in the graph, and the costs of the paths are the same&#8212;the shortest-paths problems are equivalent.</p><p attribs="{'xml:space': 'preserve'}" id="_11104" smilref="Title.smil#_11104" /><pagenum id="p668" page="normal" smilref="Title.smil#p668" /><p attribs="{'xml:space': 'preserve'}" id="_11105" smilref="Title.smil#_11105"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11106" smilref="Title.smil#_11106"> 655</p><p attribs="{'xml:space': 'preserve'}" id="_11107" smilref="Title.smil#_11107"> ALGORITHM 4.9 Dijkstra&#8217;s shortest-paths algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11108" smilref="Title.smil#_11108"> public class DijkstraSP { private DirectedEdge[] edgeTo; private double[] distTo; private IndexMinPQ&lt;Double&gt; pq;</p><p attribs="{'xml:space': 'preserve'}" id="_11109" smilref="Title.smil#_11109"> public DijkstraSP(EdgeWeightedDigraph G, int s) { edgeTo = new DirectedEdge[G.V()]; distTo = new double[G.V()]; pq = new IndexMinPQ&lt;Double&gt;(G.V());</p><p attribs="{'xml:space': 'preserve'}" id="_11110" smilref="Title.smil#_11110"> for (int v = 0; v &lt; G.V(); v++) distTo[v] = Double.POSITIVE_INFINITY; distTo[s] = 0.0;</p><p attribs="{'xml:space': 'preserve'}" id="_11111" smilref="Title.smil#_11111"> pq.insert(s, 0.0); while (!pq.isEmpty()) relax(G, pq.delMin()) }</p><p attribs="{'xml:space': 'preserve'}" id="_11112" smilref="Title.smil#_11112"> private void relax(EdgeWeightedDigraph G, int v) { for(DirectedEdge e : G.adj(v)) { int w = e.to(); if (distTo[w] &gt; distTo[v] + e.weight()) { distTo[w] = distTo[v] + e.weight(); edgeTo[w] = e; if (pq.contains(w)) pq.change(w, distTo[w]); else pq.insert(w, distTo[w]); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_11113" smilref="Title.smil#_11113"> public double distTo(int v) // standard client query methods public boolean hasPathTo(int v) // for SPT implementatations public Iterable&lt;Edge&gt; pathTo(int v) // (See page 649.) }</p><p attribs="{'xml:space': 'preserve'}" id="_11114" smilref="Title.smil#_11114"> This implementation of Dijkstra&#8217;s algorithm grows the SPT by adding an edge at a time, always choosing the edge from a tree vertex to a non-tree vertex whose destination w is closest to s.</p><p attribs="{'xml:space': 'preserve'}" id="_11115" smilref="Title.smil#_11115" /><pagenum id="p669" page="normal" smilref="Title.smil#p669" /><p attribs="{'xml:space': 'preserve'}" id="_11116" smilref="Title.smil#_11116"> 656</p><p attribs="{'xml:space': 'preserve'}" id="_11117" smilref="Title.smil#_11117"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11118" smilref="Title.smil#_11118"> Source-sink shortest paths. Given an edge-weighted digraph, a source vertex s, and a target vertex t, find the shortest path from s to t. To solve this problem, use Dijkstra&#8217;s algorithm, but terminate the search as soon as t comes off the priority queue.</p><p attribs="{'xml:space': 'preserve'}" id="_11119" smilref="Title.smil#_11119"> All-pairs shortest paths. Given an edge-weighted digraph, support queries of the form Given a source vertex s and a target vertex t, is there a path from s to t? If so, find a shortest such path (one whose total weight is minimal).</p><p attribs="{'xml:space': 'preserve'}" id="_11120" smilref="Title.smil#_11120"> The surprisingly compact implementation at right below solves the all-pairs shortest paths problem, using time and space proportional to E V log V. It builds an array of DijkstraSP objects, one for each vertex as the source. To answer a client query, it uses the source to access the corresponding single-source shortest-paths object and then passes the target as argument to the query.</p><p attribs="{'xml:space': 'preserve'}" id="_11121" smilref="Title.smil#_11121"> Shortest paths in Euclidean graphs. Solve the single-source, source-sink, and all-pairs shortest-paths problems in graphs where vertices are points in the plane and edge weights are proportional to Euclidean distances between vertices.</p><p attribs="{'xml:space': 'preserve'}" id="_11122" smilref="Title.smil#_11122"> A simple modification considerably speeds up Dijkstra&#8217;s algorithm in this case (see</p><p attribs="{'xml:space': 'preserve'}" id="_11123" smilref="Title.smil#_11123"> Exercise 4.4.27).</p><p attribs="{'xml:space': 'preserve'}" id="_11124" smilref="Title.smil#_11124"> public class DijkstraAllPairsSP { private DijkstraSP[] all;</p><p attribs="{'xml:space': 'preserve'}" id="_11125" smilref="Title.smil#_11125"> The figures on the faCING page show the emergence of the SPT as computed by Di- jkstra&#8217;s algorithm for the Euclidean graph defined by our test file mediumEWD.txt (see page 645) for several different sources. Re- call that line segments in this graph represent directed edges in both directions. Again, these figures illustrate a fascinating dynamic process. Next, we consider shortest-paths algorithms for acyclic edge-weighted graphs, where we can solve the problem in linear time (faster than Dijkstra&#8217;s algorithm) and then for edge-weighted digraphs with negative weights, where Dijkstra&#8217;s algorithm does not apply.</p><p attribs="{'xml:space': 'preserve'}" id="_11126" smilref="Title.smil#_11126"> DijkstraAllPairsSP(EdgeWeightedDigraph G) { all = new DijkstraSP[G.V()] for (int v = 0; v &lt; G.V(); v++) all[v] = new DijkstraSP(G, v); }</p><p attribs="{'xml:space': 'preserve'}" id="_11127" smilref="Title.smil#_11127"> Iterable&lt;DirectedEdge&gt; path(int s, int t) { return all[s].pathTo(t); }</p><p attribs="{'xml:space': 'preserve'}" id="_11128" smilref="Title.smil#_11128"> double dist(int s, int t) { return all[s].distTo(t); }</p><p attribs="{'xml:space': 'preserve'}" id="_11129" smilref="Title.smil#_11129"> }</p><p attribs="{'xml:space': 'preserve'}" id="_11130" smilref="Title.smil#_11130"> All-pairs shortest paths</p><p attribs="{'xml:space': 'preserve'}" id="_11131" smilref="Title.smil#_11131" /><pagenum id="p670" page="normal" smilref="Title.smil#p670" /><p attribs="{'xml:space': 'preserve'}" id="_11132" smilref="Title.smil#_11132"> 20%</p><p attribs="{'xml:space': 'preserve'}" id="_11133" smilref="Title.smil#_11133"> source</p><p attribs="{'xml:space': 'preserve'}" id="_11134" smilref="Title.smil#_11134"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11135" smilref="Title.smil#_11135"> 657</p><p attribs="{'xml:space': 'preserve'}" id="_11136" smilref="Title.smil#_11136"> 40%</p><p attribs="{'xml:space': 'preserve'}" id="_11137" smilref="Title.smil#_11137"> 60%</p><p attribs="{'xml:space': 'preserve'}" id="_11138" smilref="Title.smil#_11138"> 80%</p><p attribs="{'xml:space': 'preserve'}" id="_11139" smilref="Title.smil#_11139"> SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11140" smilref="Title.smil#_11140"> Dijkstra&#8217;s algorithm (250 vertices, various sources)</p><p attribs="{'xml:space': 'preserve'}" id="_11141" smilref="Title.smil#_11141" /><pagenum id="p671" page="normal" smilref="Title.smil#p671" /><p attribs="{'xml:space': 'preserve'}" id="_11142" smilref="Title.smil#_11142"> 658</p><p attribs="{'xml:space': 'preserve'}" id="_11143" smilref="Title.smil#_11143"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11144" smilref="Title.smil#_11144"> Acyclic edge-weighted digraphs For many natural applications, edge-weighted digraphs are known to have no directed cycles. For economy, we use the equivalent term edge-weighted DAG to refer to an acyclic edge-weighted digraph. We now consider an algorithm for finding shortest paths that is simpler and faster than Dijkstra&#8217;s algorithm for edge-weighted DAGs. Speci&#64257; cally, it </p><p attribs="{'xml:space': 'preserve'}" id="_11145" smilref="Title.smil#_11145"> 8 13 5 4 0.35 4 7 0.37 5 7 0.28 5 1 0.32 4 0 0.38 0 2 0.26 3 7 0.39 1 3 0.29 7 2 0.34 6 2 0.40 3 6 0.52 6 0 0.58 6 4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_11146" smilref="Title.smil#_11146"> E</p><p attribs="{'xml:space': 'preserve'}" id="_11147" smilref="Title.smil#_11147"> tinyEWDAG.txt</p><p attribs="{'xml:space': 'preserve'}" id="_11148" smilref="Title.smil#_11148"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11149" smilref="Title.smil#_11149"> An acyclic edge-weighted digraph with an SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11150" smilref="Title.smil#_11150"> Proposition S. By relaxing vertices in topological order, we can solve the single- source shortest-paths problem for edge-weighted DAGs in time proportional to E + V.</p><p attribs="{'xml:space': 'preserve'}" id="_11151" smilref="Title.smil#_11151"> Proof : Every edge v-&gt;w is relaxed exactly once, when v is relaxed, leaving distTo[w] &lt;= distTo[v] + e.weight(). This inequality holds until the algorithm completes, since distTo[v] never changes (because of the topological or- der, no edge pointing to v will be processed after v is relaxed) and distTo[w] can only decrease (any relaxation can only decrease a distTo[] value). Thus, after all vertices reachable from s have been added to the tree, the shortest-paths optimality conditions hold, and Proposition Q applies. The time bound is immediate: Proposition G on page 583 tells us that the topological sort takes time proportional to E + V, and the second relaxation pass completes the job by relaxing each edge once, again in time proportional to E + V.</p><p attribs="{'xml:space': 'preserve'}" id="_11152" smilref="Title.smil#_11152" /><pagenum id="p672" page="normal" smilref="Title.smil#p672" /><p attribs="{'xml:space': 'preserve'}" id="_11153" smilref="Title.smil#_11153"> The figure at right is a trace for a sample acyclic edge-weighted digraph tinyEWDAG.txt. For this exam- ple, the algorithm builds the shortest-paths tree from vertex 5 as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_11154" smilref="Title.smil#_11154"> 5 1 3 6 4 7 0 2.</p><p attribs="{'xml:space': 'preserve'}" id="_11155" smilref="Title.smil#_11155"> </p><p attribs="{'xml:space': 'preserve'}" id="_11156" smilref="Title.smil#_11156"> EdgeWeightedDigraph and DirectedEdge APIs of this</p><p attribs="{'xml:space': 'preserve'}" id="_11157" smilref="Title.smil#_11157"> section (see Exercise 4.4.12). Note that our boolean array marked[] is not needed in this implementation: since we are processing vertices in an acyclic digraph in topological order, we never re-encounter a vertex that we have already relaxed. Algorithm 4.10 could hardly be more ef&#64257; cient: after the topological sort, the constructor scans the graph, relaxing each edge exactly once. It is the method of choice for finding shortest paths in edge-weighted graphs that are known to be acyclic.</p><p attribs="{'xml:space': 'preserve'}" id="_11158" smilref="Title.smil#_11158"> Proposition S</p><p attribs="{'xml:space': 'preserve'}" id="_11159" smilref="Title.smil#_11159"> is significant because it provides a concrete example where the absence of cycles</p><p attribs="{'xml:space': 'preserve'}" id="_11160" smilref="Title.smil#_11160"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11161" smilref="Title.smil#_11161"> 659</p><p attribs="{'xml:space': 'preserve'}" id="_11162" smilref="Title.smil#_11162"> topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_11163" smilref="Title.smil#_11163"> 5 1 3 6 4 7 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_11164" smilref="Title.smil#_11164"> thick black: on tree</p><p attribs="{'xml:space': 'preserve'}" id="_11165" smilref="Title.smil#_11165"> red: add to tree</p><p attribs="{'xml:space': 'preserve'}" id="_11166" smilref="Title.smil#_11166"> gray: ineligible</p><p attribs="{'xml:space': 'preserve'}" id="_11167" smilref="Title.smil#_11167"> edgeTo[] 0 1 5-&gt;1 2 3 4 5-&gt;4 5 6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11168" smilref="Title.smil#_11168"> 0 1 5-&gt;1 2 3 1-&gt;3 4 5-&gt;4 5 6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11169" smilref="Title.smil#_11169"> 0 1 5-&gt;1 2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11170" smilref="Title.smil#_11170"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11171" smilref="Title.smil#_11171"> 0 4-&gt;0 1 5-&gt;1 2 6-&gt;2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11172" smilref="Title.smil#_11172"> 0 4-&gt;0 1 5-&gt;1 2 7-&gt;2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11173" smilref="Title.smil#_11173"> 0 4-&gt;0 1 5-&gt;1 2 7-&gt;2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11174" smilref="Title.smil#_11174"> Trace for shortest paths in an edge-weighted DAG</p><p attribs="{'xml:space': 'preserve'}" id="_11175" smilref="Title.smil#_11175" /></level3><level3 id="_00092"><h3 id="ch4-s4-ss26" smilref="Title.smil#ch4-s4-ss26" xml:space="preserve">Shortest paths in edgeweighted DAGs</h3><pagenum id="p673" page="normal" smilref="Title.smil#p673" /><p attribs="{'xml:space': 'preserve'}" id="_11176" smilref="Title.smil#_11176"> 660</p><p attribs="{'xml:space': 'preserve'}" id="_11177" smilref="Title.smil#_11177"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11178" smilref="Title.smil#_11178"> ALGORITHM 4.10 Shortest paths in edge-weighted DAGs</p><p attribs="{'xml:space': 'preserve'}" id="_11179" smilref="Title.smil#_11179"> public class AcyclicSP { private DirectedEdge[] edgeTo; private double[] distTo;</p><p attribs="{'xml:space': 'preserve'}" id="_11180" smilref="Title.smil#_11180"> public AcyclicSP(EdgeWeightedDigraph G, int s) { edgeTo = new DirectedEdge[G.V()]; distTo = new double[G.V()];</p><p attribs="{'xml:space': 'preserve'}" id="_11181" smilref="Title.smil#_11181"> for (int v = 0; v &lt; G.V(); v++) distTo[v] = Double.POSITIVE_INFINITY; distTo[s] = 0.0;</p><p attribs="{'xml:space': 'preserve'}" id="_11182" smilref="Title.smil#_11182"> Topological top = new Topological(G);</p><p attribs="{'xml:space': 'preserve'}" id="_11183" smilref="Title.smil#_11183"> for (int v : top.order()) relax(G, v); }</p><p attribs="{'xml:space': 'preserve'}" id="_11184" smilref="Title.smil#_11184"> private void relax(EdgeWeightedDigraph G, int v) // See page 648.</p><p attribs="{'xml:space': 'preserve'}" id="_11185" smilref="Title.smil#_11185"> public double distTo(int v) // standard client query methods public boolean hasPathTo(int v) // for SPT implementatations public Iterable&lt;Edge&gt; pathTo(int v) // (See page 649.) }</p><p attribs="{'xml:space': 'preserve'}" id="_11186" smilref="Title.smil#_11186"> This shortest-paths algorithm for edge-weighted DAGs uses a topological sort (Algorithm 4.5, adapted to use EdgeWeightedDigraph and DirectedEdge) to enable it to relax the vertices in topological order, which is all that is needed to compute shortest paths.</p><p attribs="{'xml:space': 'preserve'}" id="_11187" smilref="Title.smil#_11187"> % java AcyclicSP tinyEWDAG.txt 5 5 to 0 (0.73): 5-&gt;4 0.35 4-&gt;0 0.38 5 to 1 (0.32): 5-&gt;1 0.32 5 to 2 (0.62): 5-&gt;7 0.28 7-&gt;2 0.34 5 to 3 (0.62): 5-&gt;1 0.32 1-&gt;3 0.29 5 to 4 (0.35): 5-&gt;4 0.35 5 to 5 (0.00): 5 to 6 (1.13): 5-&gt;1 0.32 1-&gt;3 0.29 3-&gt;6 0.52 5 to 7 (0.28): 5-&gt;7 0.28</p><p attribs="{'xml:space': 'preserve'}" id="_11188" smilref="Title.smil#_11188" /><pagenum id="p674" page="normal" smilref="Title.smil#p674" /><p attribs="{'xml:space': 'preserve'}" id="_11189" smilref="Title.smil#_11189"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11190" smilref="Title.smil#_11190"> 661</p><p attribs="{'xml:space': 'preserve'}" id="_11191" smilref="Title.smil#_11191"> considerably simplifies a problem. For shortest paths, the topological-sort-based method is faster than Dijkstra&#8217;s algorithm by a factor proportional to the cost of the priority- queue operations in Dijkstra&#8217;s algorithm. Moreover, the proof of Proposition S does not depend on the edge weights being nonnegative, so we can remove that restriction for edge-weighted DAGs. Next, we consider implications of this ability to allow negative edge weights, by considering the use of the shortest-paths model to solve two other problems, one of which seems at first blush to be quite removed from graph processing.</p><p attribs="{'xml:space': 'preserve'}" id="_11192" smilref="Title.smil#_11192"> Longest paths. Consider the problem of finding the longest path in an edge-weighted DAG with edge weights that may be positive or negative.</p><p attribs="{'xml:space': 'preserve'}" id="_11193" smilref="Title.smil#_11193"> Single-source longest paths in edge-weighted DAGs. Given an edge-weighted</p><p attribs="{'xml:space': 'preserve'}" id="_11194" smilref="Title.smil#_11194"> DAG (with negative weights allowed) and a source vertex s, support queries of the form: Is there a directed path from s to a given target vertex v? If so, find a longest such path (one whose total weight is maximal).</p><p attribs="{'xml:space': 'preserve'}" id="_11195" smilref="Title.smil#_11195"> The algorithm just considered provides a quick solution to this problem:</p><p attribs="{'xml:space': 'preserve'}" id="_11196" smilref="Title.smil#_11196"> Proposition T. We can solve the longest-paths problem in edge-weighted DAGs in time proportional to E + V.</p><p attribs="{'xml:space': 'preserve'}" id="_11197" smilref="Title.smil#_11197"> Proof : Given a longest-paths problem, create a copy of the given edge-weighted DAG that is identical to the original, except that all edge weights are negated. Then the shortest path in this copy is the longest path in the original. To transform the solution of the shortest-paths problem to a solution of the longest-paths problem, negate the weights in the solution. The running time follows immediately from</p><p attribs="{'xml:space': 'preserve'}" id="_11198" smilref="Title.smil#_11198"> Proposition S.</p><p attribs="{'xml:space': 'preserve'}" id="_11199" smilref="Title.smil#_11199"> Using this transformation to develop a class AcyclicLP that finds longest paths in edge-weighted DAGs is straightforward. An even simpler way to implement such a class is to copy AcyclicSP, then switch the distTo[] initialization to Double.NEGA- TIVE_INFINITY and switch the sense of the inequality in relax(). Either way, we get an efficient solution to the longest-paths problem in edge-weighted DAGs. This result is to be compared with the fact that the best known algorithm for finding longest simple paths in general edge-weighted digraphs (where edge weights may be negative) requires exponential time in the worst case (see Chapter 6)! The possibility of cycles seems to make the problem exponentially more dif&#64257; cult.</p><p attribs="{'xml:space': 'preserve'}" id="_11200" smilref="Title.smil#_11200" /><pagenum id="p675" page="normal" smilref="Title.smil#p675" /><p attribs="{'xml:space': 'preserve'}" id="_11201" smilref="Title.smil#_11201"> topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_11202" smilref="Title.smil#_11202"> 5 1 3 6 4 7 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_11203" smilref="Title.smil#_11203"> 662</p><p attribs="{'xml:space': 'preserve'}" id="_11204" smilref="Title.smil#_11204"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11205" smilref="Title.smil#_11205"> The figure at right is a trace of the process of finding longest paths in our sample edge- weighted DAG tinyEWDAG.txt, for comparison with the shortest-paths trace for the same DAG on page 659. For this example, the algorithm builds the longest-paths tree (LPT) from vertex 5 as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_11206" smilref="Title.smil#_11206"> order 5 1 3 6 4 7 0 2.</p><p attribs="{'xml:space': 'preserve'}" id="_11207" smilref="Title.smil#_11207"> </p><p attribs="{'xml:space': 'preserve'}" id="_11208" smilref="Title.smil#_11208"> now ineligible</p><p attribs="{'xml:space': 'preserve'}" id="_11209" smilref="Title.smil#_11209"> edgeTo[] 0 1 5-&gt;1 2 3 4 5-&gt;4 5 6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11210" smilref="Title.smil#_11210"> 0 1 5-&gt;1 2 3 1-&gt;3 4 5-&gt;4 5 6 7 5-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11211" smilref="Title.smil#_11211"> 0 1 5-&gt;1 2 3 1-&gt;3 4 5-&gt;4 5 6 3-&gt;6 7 3-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11212" smilref="Title.smil#_11212"> 0 6-&gt;0 1 5-&gt;1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 6 3-&gt;6 7 3-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11213" smilref="Title.smil#_11213"> 0 4-&gt;0 1 5-&gt;1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 6 3-&gt;6 7 4-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11214" smilref="Title.smil#_11214"> 0 4-&gt;0 1 5-&gt;1 2 7-&gt;2 3 1-&gt;3 4 6-&gt;4 5 6 3-&gt;6 7 4-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11215" smilref="Title.smil#_11215"> 0 4-&gt;0 1 5-&gt;1 2 7-&gt;2 3 1-&gt;3 4 6-&gt;4 5 6 3-&gt;6 7 4-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11216" smilref="Title.smil#_11216"> Trace for longest paths in an acyclic network</p><p attribs="{'xml:space': 'preserve'}" id="_11217" smilref="Title.smil#_11217" /><pagenum id="p676" page="normal" smilref="Title.smil#p676" /><p attribs="{'xml:space': 'preserve'}" id="_11218" smilref="Title.smil#_11218"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11219" smilref="Title.smil#_11219"> 663</p><p attribs="{'xml:space': 'preserve'}" id="_11220" smilref="Title.smil#_11220"> Parallel job scheduling. As an example application, we revisit the class of scheduling problems that we first considered in Section 4.2 (page 574). Speci&#64257; cally, consider the following scheduling problem (differences from the problem on page 575 are italicized):</p><p attribs="{'xml:space': 'preserve'}" id="_11221" smilref="Title.smil#_11221"> Parallel precedence-constrained scheduling. Given a set of jobs of specified du-</p><p attribs="{'xml:space': 'preserve'}" id="_11222" smilref="Title.smil#_11222"> ration to be completed, with precedence constraints that specify that certain jobs have to be completed before certain other jobs are begun, how can we schedule the jobs on identical processors (as many as needed ) such that they are all completed in the minimum amount of time while still respecting the constraints? Implicit in the model of Section 4.2 is a single processor: we schedule the jobs in topological order and the total time required is the total duration of the jobs. Now, we assume that we have sufficient processors to perform as many jobs as possible, limited only by precedence constraints. Again, thousands or even millions of jobs might be involved, so we require an efficient algorithm. Remarkably, a linear- time algorithm is available&#8212;an approach known as the critical path method demonstrates that the problem is equivalent to a longest- paths problem in an edge-weighted DAG. This method has been used successfully in countless industrial applications. We focus on the earliest possible time that we can schedule each job, assuming that any available processor can handle the job for its duration. For example, consider the problem instance specified in the table at right. The solution below shows that 173.0 is the minimum possible completion time for any schedule for this problem: the schedule satisfies all the constraints, and no schedule can complete before time 173.0 because of the job sequence 0-&gt;9-&gt;6-&gt;8-&gt;2. This sequence is known as a critical path for this problem. Every sequence of jobs, each constrained to follow the job just preceding it in the se- quence, represents a lower bound on the length of the schedule. If we define the length of such a sequence to be its earliest possible completion time (total of the durations of its jobs), the longest sequence is known as a critical path because any delay in the starting time of any job delays the best achievable completion time of the entire project.</p><p attribs="{'xml:space': 'preserve'}" id="_11223" smilref="Title.smil#_11223"> job</p><p attribs="{'xml:space': 'preserve'}" id="_11224" smilref="Title.smil#_11224"> 0 41.0 1 7 9 1 51.0 2 2 50.0 3 36.0 4 38.0 5 45.0 6 21.0 3 8 7 32.0 3 8 8 32.0 2 9 29.0 4 6</p><p attribs="{'xml:space': 'preserve'}" id="_11225" smilref="Title.smil#_11225"> A job-scheduling problem</p><p attribs="{'xml:space': 'preserve'}" id="_11226" smilref="Title.smil#_11226"> duration must complete before</p><p attribs="{'xml:space': 'preserve'}" id="_11227" smilref="Title.smil#_11227"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11228" smilref="Title.smil#_11228"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11229" smilref="Title.smil#_11229"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11230" smilref="Title.smil#_11230"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11231" smilref="Title.smil#_11231"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11232" smilref="Title.smil#_11232"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11233" smilref="Title.smil#_11233"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11234" smilref="Title.smil#_11234"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11235" smilref="Title.smil#_11235"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11236" smilref="Title.smil#_11236"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11237" smilref="Title.smil#_11237"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_11238" smilref="Title.smil#_11238"> 70</p><p attribs="{'xml:space': 'preserve'}" id="_11239" smilref="Title.smil#_11239"> Parallel job-scheduling solution</p><p attribs="{'xml:space': 'preserve'}" id="_11240" smilref="Title.smil#_11240"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11241" smilref="Title.smil#_11241"> 91</p><p attribs="{'xml:space': 'preserve'}" id="_11242" smilref="Title.smil#_11242"> 123</p><p attribs="{'xml:space': 'preserve'}" id="_11243" smilref="Title.smil#_11243"> 173</p><p attribs="{'xml:space': 'preserve'}" id="_11244" smilref="Title.smil#_11244" /><pagenum id="p677" page="normal" smilref="Title.smil#p677" /><p attribs="{'xml:space': 'preserve'}" id="_11245" smilref="Title.smil#_11245"> 664</p><p attribs="{'xml:space': 'preserve'}" id="_11246" smilref="Title.smil#_11246"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11247" smilref="Title.smil#_11247"> job start</p><p attribs="{'xml:space': 'preserve'}" id="_11248" smilref="Title.smil#_11248"> job finish</p><p attribs="{'xml:space': 'preserve'}" id="_11249" smilref="Title.smil#_11249"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_11250" smilref="Title.smil#_11250"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11251" smilref="Title.smil#_11251"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11252" smilref="Title.smil#_11252"> duration zero-weight edge to each job start</p><p attribs="{'xml:space': 'preserve'}" id="_11253" smilref="Title.smil#_11253"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11254" smilref="Title.smil#_11254"> 29</p><p attribs="{'xml:space': 'preserve'}" id="_11255" smilref="Title.smil#_11255"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11256" smilref="Title.smil#_11256"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11257" smilref="Title.smil#_11257"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11258" smilref="Title.smil#_11258"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11259" smilref="Title.smil#_11259"> 21</p><p attribs="{'xml:space': 'preserve'}" id="_11260" smilref="Title.smil#_11260"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11261" smilref="Title.smil#_11261"> 38</p><p attribs="{'xml:space': 'preserve'}" id="_11262" smilref="Title.smil#_11262"> 45</p><p attribs="{'xml:space': 'preserve'}" id="_11263" smilref="Title.smil#_11263"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11264" smilref="Title.smil#_11264"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11265" smilref="Title.smil#_11265"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11266" smilref="Title.smil#_11266"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11267" smilref="Title.smil#_11267"> 51</p><p attribs="{'xml:space': 'preserve'}" id="_11268" smilref="Title.smil#_11268"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11269" smilref="Title.smil#_11269"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11270" smilref="Title.smil#_11270"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11271" smilref="Title.smil#_11271"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11272" smilref="Title.smil#_11272"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11273" smilref="Title.smil#_11273"> 36</p><p attribs="{'xml:space': 'preserve'}" id="_11274" smilref="Title.smil#_11274"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11275" smilref="Title.smil#_11275"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11276" smilref="Title.smil#_11276"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11277" smilref="Title.smil#_11277"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11278" smilref="Title.smil#_11278"> precedence constraint (zero weight)</p><p attribs="{'xml:space': 'preserve'}" id="_11279" smilref="Title.smil#_11279"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_11280" smilref="Title.smil#_11280"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11281" smilref="Title.smil#_11281"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11282" smilref="Title.smil#_11282"> zero-weight edge from each job finish</p><p attribs="{'xml:space': 'preserve'}" id="_11283" smilref="Title.smil#_11283"> t</p><p attribs="{'xml:space': 'preserve'}" id="_11284" smilref="Title.smil#_11284"> Edge-weighted DAG representation of job scheduling</p><p attribs="{'xml:space': 'preserve'}" id="_11285" smilref="Title.smil#_11285"> Definition. The critical path method for parallel scheduling is to proceed as follows: Create an edge-weighted DAG with a source s, a sink t, and two vertices for each job (a start vertex and an end vertex). For each job, add an edge from its start vertex to its end vertex with weight equal to its duration. For each precedence constraint v-&gt;w, add a zero-weight edge from the end vertex corresponding to v to the beginning vertex corresponding to w. Also add zero-weight edges from the source to each job&#8217;s start vertex and from each job&#8217;s end vertex to the sink. Now, schedule each job at the time given by the length of its longest path from the source.</p><p attribs="{'xml:space': 'preserve'}" id="_11286" smilref="Title.smil#_11286"> The figure at the top of this page depicts this correspondence for our sample problem, and the figure at the bottom of the page gives the longest-paths solution. As speci&#64257; ed, the graph has three edges for each job (zero-weight edges from the source to the start and from the finish to the sink, and an edge from start to fi nish) and one edge for each precedence constraint. The class CPM on the facing page is a straightforward implementation of the critical path method. It transforms any instance of the job-scheduling problem into an instance of the longest-paths problem in an edge-weighted DAG, uses AcyclicLP to solve it, then prints the job start times and schedule finish time.</p><p attribs="{'xml:space': 'preserve'}" id="_11287" smilref="Title.smil#_11287"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_11288" smilref="Title.smil#_11288"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11289" smilref="Title.smil#_11289"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11290" smilref="Title.smil#_11290"> duration</p><p attribs="{'xml:space': 'preserve'}" id="_11291" smilref="Title.smil#_11291"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11292" smilref="Title.smil#_11292"> 29</p><p attribs="{'xml:space': 'preserve'}" id="_11293" smilref="Title.smil#_11293"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11294" smilref="Title.smil#_11294"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11295" smilref="Title.smil#_11295"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11296" smilref="Title.smil#_11296"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11297" smilref="Title.smil#_11297"> 36</p><p attribs="{'xml:space': 'preserve'}" id="_11298" smilref="Title.smil#_11298"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11299" smilref="Title.smil#_11299"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11300" smilref="Title.smil#_11300"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11301" smilref="Title.smil#_11301"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11302" smilref="Title.smil#_11302"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11303" smilref="Title.smil#_11303"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11304" smilref="Title.smil#_11304"> 21</p><p attribs="{'xml:space': 'preserve'}" id="_11305" smilref="Title.smil#_11305"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11306" smilref="Title.smil#_11306"> 38</p><p attribs="{'xml:space': 'preserve'}" id="_11307" smilref="Title.smil#_11307"> 45</p><p attribs="{'xml:space': 'preserve'}" id="_11308" smilref="Title.smil#_11308"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11309" smilref="Title.smil#_11309"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11310" smilref="Title.smil#_11310"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11311" smilref="Title.smil#_11311"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11312" smilref="Title.smil#_11312"> 51</p><p attribs="{'xml:space': 'preserve'}" id="_11313" smilref="Title.smil#_11313"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11314" smilref="Title.smil#_11314"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11315" smilref="Title.smil#_11315"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11316" smilref="Title.smil#_11316"> Longest-paths solution to job-scheduling example</p><p attribs="{'xml:space': 'preserve'}" id="_11317" smilref="Title.smil#_11317"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_11318" smilref="Title.smil#_11318"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11319" smilref="Title.smil#_11319"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11320" smilref="Title.smil#_11320"> critical path</p><p attribs="{'xml:space': 'preserve'}" id="_11321" smilref="Title.smil#_11321"> t</p><p attribs="{'xml:space': 'preserve'}" id="_11322" smilref="Title.smil#_11322" /></level3><level3 id="_00093"><h3 id="ch4-s4-ss27" smilref="Title.smil#ch4-s4-ss27" xml:space="preserve">Critical-path method</h3><pagenum id="p678" page="normal" smilref="Title.smil#p678" /><p attribs="{'xml:space': 'preserve'}" id="_11323" smilref="Title.smil#_11323"> Critical path method for parallel precedence-constrained job scheduling</p><p attribs="{'xml:space': 'preserve'}" id="_11324" smilref="Title.smil#_11324"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11325" smilref="Title.smil#_11325"> 665</p><p attribs="{'xml:space': 'preserve'}" id="_11326" smilref="Title.smil#_11326"> public class CPM { public static void main(String[] args) { int N = StdIn.readInt(); StdIn.readLine(); EdgeWeightedDigraph G; G = new EdgeWeightedDigraph(2*N+2);</p><p attribs="{'xml:space': 'preserve'}" id="_11327" smilref="Title.smil#_11327"> int s = 2*N, t = 2*N+1; for (int i = 0; i &lt; N; i++) { String[] a = StdIn.readLine().split("\\s+"); double duration = Double.parseDouble(a[0]); G.addEdge(new DirectedEdge(i, i+N, duration)); G.addEdge(new DirectedEdge(s, i, 0.0)); G.addEdge(new DirectedEdge(i+N, t, 0.0)); for (int j = 1; j &lt; a.length; j++) { int successor = Integer.parseInt(a[j]); G.addEdge(new DirectedEdge(i+N, successor, 0.0)); } }</p><p attribs="{'xml:space': 'preserve'}" id="_11328" smilref="Title.smil#_11328"> % more jobsPC.txt 10 41.0 1 7 9 51.0 2 50.0 36.0 38.0 45.0 21.0 3 8 32.0 3 8 32.0 2 29.0 4 6</p><p attribs="{'xml:space': 'preserve'}" id="_11329" smilref="Title.smil#_11329"> AcyclicLP lp = new AcyclicLP(G, s);</p><p attribs="{'xml:space': 'preserve'}" id="_11330" smilref="Title.smil#_11330"> StdOut.println("Start times:"); for (int i = 0; i &lt; N; i++) StdOut.printf("%4d: %5.1f\n", i, lp.distTo(i)); StdOut.printf("Finish time: %5.1f\n", lp.distTo(t)); }</p><p attribs="{'xml:space': 'preserve'}" id="_11331" smilref="Title.smil#_11331"> }</p><p attribs="{'xml:space': 'preserve'}" id="_11332" smilref="Title.smil#_11332"> This implementation of the critical path method for job scheduling reduces the problem directly to the longest-paths problem in edge- weighted DAGs. It builds an edge-weighted digraph (which must be a DAG) from the job-scheduling problem speci&#64257; cation, as prescribed by the critical path method, then uses AcyclicLP (see Proposition T) to find the longest-paths tree and to print the longest-paths lengths, which are precisely the start times for each job.</p><p attribs="{'xml:space': 'preserve'}" id="_11333" smilref="Title.smil#_11333"> % java CPM &lt; jobsPC.txt Start times: 0: 0.0 1: 41.0 2: 123.0 3: 91.0 4: 70.0 5: 0.0 6: 70.0 7: 41.0 8: 91.0 9: 41.0 Finish time: 173.0</p><p attribs="{'xml:space': 'preserve'}" id="_11334" smilref="Title.smil#_11334" /><pagenum id="p679" page="normal" smilref="Title.smil#p679" /><p attribs="{'xml:space': 'preserve'}" id="_11335" smilref="Title.smil#_11335"> 666</p><p attribs="{'xml:space': 'preserve'}" id="_11336" smilref="Title.smil#_11336"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11337" smilref="Title.smil#_11337"> original</p><p attribs="{'xml:space': 'preserve'}" id="_11338" smilref="Title.smil#_11338"> job</p><p attribs="{'xml:space': 'preserve'}" id="_11339" smilref="Title.smil#_11339"> start</p><p attribs="{'xml:space': 'preserve'}" id="_11340" smilref="Title.smil#_11340"> 0 0.0 1 41.0 2 123.0 3 91.0 4 70.0 5 0.0 6 70.0 7 41.0 8 91.0 9 41.0</p><p attribs="{'xml:space': 'preserve'}" id="_11341" smilref="Title.smil#_11341"> 2 by 12.0 after 4</p><p attribs="{'xml:space': 'preserve'}" id="_11342" smilref="Title.smil#_11342"> job</p><p attribs="{'xml:space': 'preserve'}" id="_11343" smilref="Title.smil#_11343"> start</p><p attribs="{'xml:space': 'preserve'}" id="_11344" smilref="Title.smil#_11344"> 0 0.0 1 41.0 2 123.0 3 91.0 4 111.0 5 0.0 6 70.0 7 41.0 8 91.0 9 41.0</p><p attribs="{'xml:space': 'preserve'}" id="_11345" smilref="Title.smil#_11345"> 2 by 70.0 after 7</p><p attribs="{'xml:space': 'preserve'}" id="_11346" smilref="Title.smil#_11346"> job</p><p attribs="{'xml:space': 'preserve'}" id="_11347" smilref="Title.smil#_11347"> start</p><p attribs="{'xml:space': 'preserve'}" id="_11348" smilref="Title.smil#_11348"> 0 0.0 1 41.0 2 123.0 3 91.0 4 111.0 5 0.0 6 70.0 7 53.0 8 91.0 9 41.0</p><p attribs="{'xml:space': 'preserve'}" id="_11349" smilref="Title.smil#_11349"> 4 by 80.0 after 0</p><p attribs="{'xml:space': 'preserve'}" id="_11350" smilref="Title.smil#_11350"> infeasible!</p><p attribs="{'xml:space': 'preserve'}" id="_11351" smilref="Title.smil#_11351"> Relative deadlines in job scheduling</p><p attribs="{'xml:space': 'preserve'}" id="_11352" smilref="Title.smil#_11352"> Proposition U. The critical path method solves the parallel precedence- constrained scheduling problem in linear time.</p><p attribs="{'xml:space': 'preserve'}" id="_11353" smilref="Title.smil#_11353"> Proof : Why does the CPM approach work? The correctness of the algorithm rests on two facts. First, every path in the DAG is a sequence of job starts and job fi nishes, separated by zero-weight precedence constraints&#8212; the length of any path from the source s to any vertex v in the graph is a lower bound on the start/&#64257; nish time represented by v, because we could not do better than scheduling those jobs one after another on the same ma- chine. In particular, the length of the longest path from s to the sink t is a lower bound on the finish time of all the jobs. Second, all the start and finish times implied by longest paths are feasible&#8212;every job starts after the finish of all the jobs where it appears as a successor in a precedence constraint, because the start time is the length of the longest path from the source to it. In particular, the length of the longest path from s to t is an upper bound on the finish time of all the jobs. The linear-time performance is immediate</p><p attribs="{'xml:space': 'preserve'}" id="_11354" smilref="Title.smil#_11354"> from Proposition T.</p><p attribs="{'xml:space': 'preserve'}" id="_11355" smilref="Title.smil#_11355"> Parallel job scheduling with relative deadlines. Conventional deadlines are</p><p attribs="{'xml:space': 'preserve'}" id="_11356" smilref="Title.smil#_11356"> job</p><p attribs="{'xml:space': 'preserve'}" id="_11357" smilref="Title.smil#_11357"> time</p><p attribs="{'xml:space': 'preserve'}" id="_11358" smilref="Title.smil#_11358"> relative to</p><p attribs="{'xml:space': 'preserve'}" id="_11359" smilref="Title.smil#_11359"> 2 12.0 4 2 70.0 7 4 80.0 0</p><p attribs="{'xml:space': 'preserve'}" id="_11360" smilref="Title.smil#_11360"> relative to the start time of the first job. Suppose that we allow an additional type of constraint in the job-scheduling problem to specify that a job must begin before a specified amount of time has elapsed, relative to the start time of another job. Such constraints are commonly needed in time-critical manufacturing processes and in many other applications, but they can make the job-scheduling problem considerably more dif&#64257; cult to solve. For example, as shown at left, suppose that we need to add a constraint to our example that job 2 must start no later than 12 time units after job 4 starts. This deadline is actually a constraint on the start time of job 4: it must be no earlier than 12 time units before the start time of job 2. In our example, there is room in the schedule to meet the deadline: we can move the start time of job 4 to 111, 12 time units before the scheduled start time of job 2. Note that, if job 4 were a long job, this change would increase the finish time of the whole schedule. Similarly, if we add to the schedule a deadline that job 2 must start no later than 70 time units after job 7 starts, there is room in the schedule to change the start time of job 7 to 53, without having to reschedule jobs 3 and 8. But if we add a deadline that job 4 must start no later</p><p attribs="{'xml:space': 'preserve'}" id="_11361" smilref="Title.smil#_11361"> Added deadlines for job scheduling</p><p attribs="{'xml:space': 'preserve'}" id="_11362" smilref="Title.smil#_11362" /><pagenum id="p680" page="normal" smilref="Title.smil#p680" /><p attribs="{'xml:space': 'preserve'}" id="_11363" smilref="Title.smil#_11363"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11364" smilref="Title.smil#_11364"> 667</p><p attribs="{'xml:space': 'preserve'}" id="_11365" smilref="Title.smil#_11365"> than 80 time units after job 0, the schedule becomes infeasible: the constraints that 4 must start no more than 80 time units after job 0 and that job 2 must start no more than 12 units after job 4 imply that job 2 must start no more than 93 time units after job 0, but job 2 must start at least 123 time units after job 0 because of the chain 0 (41 time units) precedes 9 (29 time units) precedes 6 (21 time units) precedes 8 (32 time units) precedes 2. Adding more deadlines of course multiplies the possibilities and turns an easy problem into a difficult one.</p><p attribs="{'xml:space': 'preserve'}" id="_11366" smilref="Title.smil#_11366"> Proposition V. Parallel job scheduling with relative deadlines is a shortest-paths problem in edge-weighted digraphs (with cycles and negative weights allowed). Proof : Use the same construction as in Proposition U, adding an edge for each deadline: if job v has to start within d time units of the start of job w, add an edge from v to w with negative weight d. Then convert to a shortest-paths problem by negating all the weights in the digraph. The proof of correctness applies, provided that the schedule is feasible. Determining whether a schedule is feasible is part of the computational burden, as you will see.</p><p attribs="{'xml:space': 'preserve'}" id="_11367" smilref="Title.smil#_11367"> This example illustrates that negative weights can play a critical role in practical application models. It says that if we can find an efficient solution to the shortest-paths problem with negative weights, then we can find an efficient solution to the parallel job scheduling problem with relative deadlines. Neither of the algorithms we have considered can do the job: Dijkstra&#8217;s algorithm requires that weights be positive (or zero), and Algorithm 4.10 requires that the digraph be acyclic. Next, we consider the problem of coping with negative edge weights in digraphs that are not necessarily acyclic.</p><p attribs="{'xml:space': 'preserve'}" id="_11368" smilref="Title.smil#_11368"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_11369" smilref="Title.smil#_11369"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11370" smilref="Title.smil#_11370"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11371" smilref="Title.smil#_11371"> zero-weight edge to each job start</p><p attribs="{'xml:space': 'preserve'}" id="_11372" smilref="Title.smil#_11372"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11373" smilref="Title.smil#_11373"> deadline</p><p attribs="{'xml:space': 'preserve'}" id="_11374" smilref="Title.smil#_11374"> 29</p><p attribs="{'xml:space': 'preserve'}" id="_11375" smilref="Title.smil#_11375"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11376" smilref="Title.smil#_11376"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11377" smilref="Title.smil#_11377"> -80</p><p attribs="{'xml:space': 'preserve'}" id="_11378" smilref="Title.smil#_11378"> -70</p><p attribs="{'xml:space': 'preserve'}" id="_11379" smilref="Title.smil#_11379"> 51</p><p attribs="{'xml:space': 'preserve'}" id="_11380" smilref="Title.smil#_11380"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11381" smilref="Title.smil#_11381"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11382" smilref="Title.smil#_11382"> 21</p><p attribs="{'xml:space': 'preserve'}" id="_11383" smilref="Title.smil#_11383"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11384" smilref="Title.smil#_11384"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11385" smilref="Title.smil#_11385"> 38</p><p attribs="{'xml:space': 'preserve'}" id="_11386" smilref="Title.smil#_11386"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11387" smilref="Title.smil#_11387"> 45</p><p attribs="{'xml:space': 'preserve'}" id="_11388" smilref="Title.smil#_11388"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11389" smilref="Title.smil#_11389"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11390" smilref="Title.smil#_11390"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11391" smilref="Title.smil#_11391"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11392" smilref="Title.smil#_11392"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11393" smilref="Title.smil#_11393"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11394" smilref="Title.smil#_11394"> 32</p><p attribs="{'xml:space': 'preserve'}" id="_11395" smilref="Title.smil#_11395"> 36</p><p attribs="{'xml:space': 'preserve'}" id="_11396" smilref="Title.smil#_11396"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11397" smilref="Title.smil#_11397"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11398" smilref="Title.smil#_11398"> -12</p><p attribs="{'xml:space': 'preserve'}" id="_11399" smilref="Title.smil#_11399"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11400" smilref="Title.smil#_11400"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11401" smilref="Title.smil#_11401"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_11402" smilref="Title.smil#_11402"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11403" smilref="Title.smil#_11403"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11404" smilref="Title.smil#_11404"> zero-weight edge from each job finish</p><p attribs="{'xml:space': 'preserve'}" id="_11405" smilref="Title.smil#_11405"> t</p><p attribs="{'xml:space': 'preserve'}" id="_11406" smilref="Title.smil#_11406"> Edge-weighted digraph representation of parallel precedence-constrained scheduling with relative deadlines</p><p attribs="{'xml:space': 'preserve'}" id="_11407" smilref="Title.smil#_11407" /><pagenum id="p681" page="normal" smilref="Title.smil#p681" /><p attribs="{'xml:space': 'preserve'}" id="_11408" smilref="Title.smil#_11408"> 668</p><p attribs="{'xml:space': 'preserve'}" id="_11409" smilref="Title.smil#_11409"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11410" smilref="Title.smil#_11410"> Shortest paths in general edge-weighted digraphs Our job-scheduling-</p><p attribs="{'xml:space': 'preserve'}" id="_11411" smilref="Title.smil#_11411"> tinyEWDn.txt</p><p attribs="{'xml:space': 'preserve'}" id="_11412" smilref="Title.smil#_11412"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11413" smilref="Title.smil#_11413"> E</p><p attribs="{'xml:space': 'preserve'}" id="_11414" smilref="Title.smil#_11414"> 8 15 4-&gt;5 0.35 5-&gt;4 0.35 4-&gt;7 0.37 5-&gt;7 0.28 7-&gt;5 0.28 5-&gt;1 0.32 0-&gt;4 0.38 0-&gt;2 0.26 7-&gt;3 0.39 1-&gt;3 0.29 2-&gt;7 0.34 6-&gt;2 -1.20 3-&gt;6 0.52 6-&gt;0 -1.40 6-&gt;4 -1.25</p><p attribs="{'xml:space': 'preserve'}" id="_11415" smilref="Title.smil#_11415"> shortest-paths tree from 0</p><p attribs="{'xml:space': 'preserve'}" id="_11416" smilref="Title.smil#_11416"> negative weights are dashed lines</p><p attribs="{'xml:space': 'preserve'}" id="_11417" smilref="Title.smil#_11417"> with-deadlines example just discussed demonstrates that negative weights are not merely a mathematical curiosity ; on the contrary, they significantly extend the applicability of the shortest-paths problem as a problem-solving model. Accordingly we now consider algorithms for edge-weighted digraphs that may have both cycles and negative weights. Before doing so, we consider some basic properties of such digraphs to reset our intuition about shortest paths. The figure at left is a small example that illustrates the effects of introducing negative weights on a digraph&#8217;s shortest paths. Perhaps the most important effect is that when negative weights are present, low- weight shortest paths tend to have more edges than higher-weight paths. For positive weights, our emphasis was on looking for shortcuts; but when negative weights are present, we seek detours that use negative-weight edges. This effect turns our intuition in seeking &#8220;short&#8217;&#8217; paths into a liability in understanding the algorithms, so we need to suppress that line of intuition and consider the problem on a basic abstract level. Strawman I. The first idea that suggests itself is to find the smallest (most negative) edge weight, then to add the absolute value of that number to all the edge weights to transform the digraph into one with no negative weights. This naive approach does not work at all, because shortest paths in the new digraph bear little relation to shortest paths in the old one. The more edges a path has, the more it is penalized by this transformation (see Exercise 4.4.14). Strawman II. The second idea that suggests itself is to try to adapt Dijkstra&#8217;s algorithm in some way. The fundamental difficulty with this approach is that the algorithm depends on examining paths in increasing order of their distance from the source. The proof in Proposition R that the algorithm is correct assumes that adding an edge to a path makes that path longer. But any edge with negative weight makes the path shorter, so that assumption is unfounded (see Exercise 4.4.14). Negative cycles. When we consider digraphs that could have negative edge weights, the concept of a shortest path is meaningless if there is a cycle in the digraph that</p><p attribs="{'xml:space': 'preserve'}" id="_11418" smilref="Title.smil#_11418"> edgeTo[] distTo[] 0 1 5-&gt;1 0.93 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 6-&gt;4 0.26 5 4-&gt;5 0.61 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11419" smilref="Title.smil#_11419"> An edge-weighted digraph with negative weights</p><p attribs="{'xml:space': 'preserve'}" id="_11420" smilref="Title.smil#_11420" /><pagenum id="p682" page="normal" smilref="Title.smil#p682" /><p attribs="{'xml:space': 'preserve'}" id="_11421" smilref="Title.smil#_11421"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11422" smilref="Title.smil#_11422"> tinyEWDnc.txt</p><p attribs="{'xml:space': 'preserve'}" id="_11423" smilref="Title.smil#_11423"> E</p><p attribs="{'xml:space': 'preserve'}" id="_11424" smilref="Title.smil#_11424"> 8 15 4 5 0.35 5 4 -0.66 4 7 0.37 5 7 0.28 7 5 0.28 5 1 0.32 0 4 0.38 0 2 0.26 7 3 0.39 1 3 0.29 2 7 0.34 6 2 0.40 3 6 0.52 6 0 0.58 6 4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_11425" smilref="Title.smil#_11425"> shortest path from 0 to 6 0-&gt;4-&gt;7-&gt;5-&gt;4-&gt;7-&gt;5...-&gt;1-&gt;3-&gt;6</p><p attribs="{'xml:space': 'preserve'}" id="_11426" smilref="Title.smil#_11426"> An edge-weighted digraph with a negative cycle</p><p attribs="{'xml:space': 'preserve'}" id="_11427" smilref="Title.smil#_11427"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11428" smilref="Title.smil#_11428"> 669</p><p attribs="{'xml:space': 'preserve'}" id="_11429" smilref="Title.smil#_11429"> has negative weight. For example, consider the digraph at left, which is identical to our first example except that edge 5-&gt;4 has weight -.66. Then, the weight of the cycle</p><p attribs="{'xml:space': 'preserve'}" id="_11430" smilref="Title.smil#_11430"> 4-&gt;7-&gt;5-&gt;4 is 37+.28-.66 = -.01</p><p attribs="{'xml:space': 'preserve'}" id="_11431" smilref="Title.smil#_11431"> We can spin around that cycle to generate arbitrarily short paths! Note that it is not necessary for all the edges on a directed cycle to be of negative weight; what matters is the sum of the edge weights.</p><p attribs="{'xml:space': 'preserve'}" id="_11432" smilref="Title.smil#_11432"> Definition. A negative cycle in an edge- weighted digraph is a directed cycle whose total weight (sum of the weights of its edges) is negative.</p><p attribs="{'xml:space': 'preserve'}" id="_11433" smilref="Title.smil#_11433"> Now, suppose that some vertex on a path from s to a reachable vertex v is also on a negative cycle. In this case, the existence of a shortest path from s to v would be a contradiction, because we could use the cycle to construct a path with weight lower than any given value. In other words, shortest paths can be an ill-posed problem if negative cycles are present.</p><p attribs="{'xml:space': 'preserve'}" id="_11434" smilref="Title.smil#_11434"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11435" smilref="Title.smil#_11435"> Proposition W. There exists a shortest path from s to v in an edge-weighted digraph if and only if there exists at least one directed path from s to v and no vertex on any directed path from s to v is on a negative cycle. Proof : See discussion above and Exercise 4.4.29.</p><p attribs="{'xml:space': 'preserve'}" id="_11436" smilref="Title.smil#_11436"> gray: not reachable from s</p><p attribs="{'xml:space': 'preserve'}" id="_11437" smilref="Title.smil#_11437"> white: reachable from s</p><p attribs="{'xml:space': 'preserve'}" id="_11438" smilref="Title.smil#_11438"> black outline: shortest path from s exists</p><p attribs="{'xml:space': 'preserve'}" id="_11439" smilref="Title.smil#_11439"> negative cycle</p><p attribs="{'xml:space': 'preserve'}" id="_11440" smilref="Title.smil#_11440"> Note that the requirement that shortest paths have no vertices on negative cycles implies that shortest paths are simple and that we can compute a shortest-paths tree for such vertices, as we have done for positive edge weights.</p><p attribs="{'xml:space': 'preserve'}" id="_11441" smilref="Title.smil#_11441"> red outline: no shortest path from s exists</p><p attribs="{'xml:space': 'preserve'}" id="_11442" smilref="Title.smil#_11442"> Shortest-paths possibilities</p><p attribs="{'xml:space': 'preserve'}" id="_11443" smilref="Title.smil#_11443" /><pagenum id="p683" page="normal" smilref="Title.smil#p683" /><p attribs="{'xml:space': 'preserve'}" id="_11444" smilref="Title.smil#_11444"> 670</p><p attribs="{'xml:space': 'preserve'}" id="_11445" smilref="Title.smil#_11445"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11446" smilref="Title.smil#_11446"> Strawman III. Whether or not there are negative cycles, there exists a shortest simple path connecting the source to each vertex reachable from the source. Why not define shortest paths so that we seek such paths? Unfortunately, the best known algorithm for solving this problem takes exponential time in the worst case (see Chapter 6). Gener- ally, we consider such problems &#8220;too difficult to solve&#8221; and study simpler versions.</p><p attribs="{'xml:space': 'preserve'}" id="_11447" smilref="Title.smil#_11447"> Thus, a well-posed and tractable version of the shortest paths problem in edge-</p><p attribs="{'xml:space': 'preserve'}" id="_11448" smilref="Title.smil#_11448"> weighted digraphs is to require algorithms to </p><p attribs="{'xml:space': 'preserve'}" id="_11449" smilref="Title.smil#_11449"> Negative cycle detection. Does a given edge-weighted digraph have a negative cycle? If it does, find one such cycle.</p><p attribs="{'xml:space': 'preserve'}" id="_11450" smilref="Title.smil#_11450"> Single-source shortest paths when negative cycles are not reachable. Given an</p><p attribs="{'xml:space': 'preserve'}" id="_11451" smilref="Title.smil#_11451"> edge-weighted digraph and a source s with no negative cycles reachable from s, support queries of the form Is there a directed path from s to a given target vertex v? If so, find a shortest such path (one whose total weight is minimal).</p><p attribs="{'xml:space': 'preserve'}" id="_11452" smilref="Title.smil#_11452"> To summarize: while shortest paths in digraphs with directed cycles is an ill-posed problem and we cannot efficiently solve the problem of finding simple shortest paths in such digraphs, we can identify negative cycles in practical situations. For example, in a job-scheduling-with-deadlines problem, we might expect negative cycles to be relatively rare: constraints and deadlines derive from logical real-world constraints, so any negative cycles are likely to stem from an error in the problem statement. Finding negative cycles, correcting errors, and then finding the schedule in a problem with no negative cycles is a reasonable way to proceed. In other cases, finding a negative cycle is the goal of the computation. The following approach, developed by R. Bellman and L. Ford in the late 1950s, provides a simple and effective basis for attacking both of these problems and is also effective for digraphs with positive weights:</p><p attribs="{'xml:space': 'preserve'}" id="_11453" smilref="Title.smil#_11453" /><pagenum id="p684" page="normal" smilref="Title.smil#p684" /><p attribs="{'xml:space': 'preserve'}" id="_11454" smilref="Title.smil#_11454"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11455" smilref="Title.smil#_11455"> 671</p><p attribs="{'xml:space': 'preserve'}" id="_11456" smilref="Title.smil#_11456"> Proposition X. ( Bellman-Ford algorithm) The following method solves the single-</p><p attribs="{'xml:space': 'preserve'}" id="_11457" smilref="Title.smil#_11457"> source shortest-paths problem from a given source s for any edge-weighted digraph with V vertices and no negative cycles reachable from s: Initialize distTo[s] to 0 and all other distTo[] values to in&#64257; nity. Then, considering the digraph&#8217;s edges in any order, relax all edges. Make V such passes.</p><p attribs="{'xml:space': 'preserve'}" id="_11458" smilref="Title.smil#_11458"> Proof : For any vertex t that is reachable from s consider a specific shortest path from s to t: v0-&gt;v1-&gt;...-&gt;vk, where v0 is s and vk is t. Since there are no negative cycles, such a path exists and k can be no larger than V&#11002;1. We show by induction on i that after the ith pass the algorithm computes a shortest path from s to vi. The base case (i = 0) is trivial. Assuming the claim to be true for i, v0-&gt;v1-&gt;...-&gt;vi is a shortest path from s to vi, and distTo[vi] is its length. Now, we relax every vertex in the ith pass, including vi, so distTo[vi+1] is no greater than distTo[vi] plus the weight of vi-&gt;vi+1. Now, after the ith pass, distTo[vi+1] must be equal to distTo[vi] plus the weight of vi-&gt;vi+1. It cannot be greater because we relax every vertex in the ith pass, in particular vi, and it cannot be less because that is the length of v0-&gt;v1-&gt;...-&gt;vi+1, a shortest path. Thus the algorithm computes a shortest path from s to vi+1 after the (i+1)st pass.</p><p attribs="{'xml:space': 'preserve'}" id="_11459" smilref="Title.smil#_11459"> Proposition W (continued). The Bellman-Ford algorithm takes time proportional to EV and extra space proportional to V.</p><p attribs="{'xml:space': 'preserve'}" id="_11460" smilref="Title.smil#_11460"> Proof : Each of the V passes relaxes E edges.</p><p attribs="{'xml:space': 'preserve'}" id="_11461" smilref="Title.smil#_11461"> This method is very general, since it does not specify the order in which the edges are relaxed. We now restrict attention to a less general method where we always relax all the edges leaving any vertex (in any order). The following code exhibits the simplicity of the approach:</p><p attribs="{'xml:space': 'preserve'}" id="_11462" smilref="Title.smil#_11462"> for (int pass = 0; pass &lt; G.V(); pass++) for (v = 0; v &lt; G.V(); v++) for (DirectedEdge e : G.adj(v)) relax(e);</p><p attribs="{'xml:space': 'preserve'}" id="_11463" smilref="Title.smil#_11463"> We do not consider this version in detail because it always relaxes VE edges, and a simple modification makes the algorithm much more efficient for typical applications.</p><p attribs="{'xml:space': 'preserve'}" id="_11464" smilref="Title.smil#_11464" /><pagenum id="p685" page="normal" smilref="Title.smil#p685" /><p attribs="{'xml:space': 'preserve'}" id="_11465" smilref="Title.smil#_11465"> 672</p><p attribs="{'xml:space': 'preserve'}" id="_11466" smilref="Title.smil#_11466"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11467" smilref="Title.smil#_11467"> Queue-based Bellman-Ford. Speci&#64257; cally, we</p><p attribs="{'xml:space': 'preserve'}" id="_11468" smilref="Title.smil#_11468"> q</p><p attribs="{'xml:space': 'preserve'}" id="_11469" smilref="Title.smil#_11469"> source</p><p attribs="{'xml:space': 'preserve'}" id="_11470" smilref="Title.smil#_11470"> 1 3</p><p attribs="{'xml:space': 'preserve'}" id="_11471" smilref="Title.smil#_11471"> 3 6</p><p attribs="{'xml:space': 'preserve'}" id="_11472" smilref="Title.smil#_11472"> 6 4 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_11473" smilref="Title.smil#_11473"> can easily determine a priori that numerous edges are not going to lead to a successful relaxation in any given pass: the only edges that could lead to a change in distTo[] are those leaving a vertex whose distTo[] value changed in the previous pass. To keep track of such vertices, we use a FIFO queue. The operation of the algorithm for our standard example with positive weights is shown at right. Shown at the left of the figure are the queue entries for each pass (in red), followed by the queue entries for the next pass (in black). We start with the source on the queue and then compute the SPT as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_11474" smilref="Title.smil#_11474"> Implementation. Implementing</p><p attribs="{'xml:space': 'preserve'}" id="_11475" smilref="Title.smil#_11475"> the Bell- man-Ford algorithm along these lines requires remarkably little code, as shown in Algo- rithm 4.11. It is based on two additional data structures: </p><p attribs="{'xml:space': 'preserve'}" id="_11476" smilref="Title.smil#_11476"> red: this pass</p><p attribs="{'xml:space': 'preserve'}" id="_11477" smilref="Title.smil#_11477"> black: next pass</p><p attribs="{'xml:space': 'preserve'}" id="_11478" smilref="Title.smil#_11478"> 4 0 2 7 5</p><p attribs="{'xml:space': 'preserve'}" id="_11479" smilref="Title.smil#_11479"> 7 5</p><p attribs="{'xml:space': 'preserve'}" id="_11480" smilref="Title.smil#_11480"> recolored edge</p><p attribs="{'xml:space': 'preserve'}" id="_11481" smilref="Title.smil#_11481"> queue vertices for each phase are in red</p><p attribs="{'xml:space': 'preserve'}" id="_11482" smilref="Title.smil#_11482"> edgeTo[] 0 1 2 3 1-&gt;3 4 5 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_11483" smilref="Title.smil#_11483"> edgeTo[] 0 1 2 3 4 5 6 3-&gt;6 7</p><p attribs="{'xml:space': 'preserve'}" id="_11484" smilref="Title.smil#_11484"> edgeTo[] 0 6-&gt;0 1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 6 3-&gt;6 7</p><p attribs="{'xml:space': 'preserve'}" id="_11485" smilref="Title.smil#_11485"> edgeTo[] 0 6-&gt;0 1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 4-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11486" smilref="Title.smil#_11486"> edgeTo[] 0 6-&gt;0 1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 7-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11487" smilref="Title.smil#_11487"> edgeTo[] 0 6-&gt;0 1 2 6-&gt;2 3 1-&gt;3 4 6-&gt;4 5 7-&gt;5 6 3-&gt;6 7 2-&gt;7</p><p attribs="{'xml:space': 'preserve'}" id="_11488" smilref="Title.smil#_11488"> Trace of the Bellman-Ford algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11489" smilref="Title.smil#_11489" /><pagenum id="p686" page="normal" smilref="Title.smil#p686" /><p attribs="{'xml:space': 'preserve'}" id="_11490" smilref="Title.smil#_11490"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11491" smilref="Title.smil#_11491"> 673</p><p attribs="{'xml:space': 'preserve'}" id="_11492" smilref="Title.smil#_11492"> We start by putting the source s on the queue, then enter a loop where we take a vertex off the queue and relax it. To add vertices to the queue, we augement our relax() implementation from page 646 to put the vertex pointed to by any edge that successfully relaxes onto the queue, as shown in the code at right. The data structures ensure that </p><p attribs="{'xml:space': 'preserve'}" id="_11493" smilref="Title.smil#_11493"> private void relax(EdgeWeightedDigraph G, int v) { for (DirectedEdge e : G.adj(v) { int w = e.to(); if (distTo[w] &gt; distTo[v] + e.weight()) { distTo[w] = distTo[v] + e.weight(); edgeTo[w] = e; if (!onQ[w]) { q.enqueue(w); onQ[w] = true; } } if (cost++ % G.V() == 0) findNegativeCycle(); }</p><p attribs="{'xml:space': 'preserve'}" id="_11494" smilref="Title.smil#_11494"> }</p><p attribs="{'xml:space': 'preserve'}" id="_11495" smilref="Title.smil#_11495"> Relaxation for Bellman-Ford</p><p attribs="{'xml:space': 'preserve'}" id="_11496" smilref="Title.smil#_11496"> Proposition Y. The queue-based implementation of the Bellman-Ford algorithm solves the single-source shortest-paths problem from a given source s (or finds a negative cycle reachable from s) for any edge-weighted digraph with E edges and V vertices, in time proportional to EV and extra space proportional to V, in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_11497" smilref="Title.smil#_11497"> Proof : If there is no negative cycle reachable from s, the algorithm terminates after relaxations corresponding to the (V&#8211;1)st pass of the generic algorithm described in Proposition X (since all shortest paths have fewer than V&#8211;1 edges). If there does exist a negative cycle reachable from s, the queue never empties. After relaxations corresponding to the Vth pass of the generic algorithm described in Proposition X the edgeTo[] array has a path with a cycle (connects some vertex w to itself ) and that cycle must be negative, since the path from s to the second occurrence of w must be shorter that the path from s to the first occurrence of w for w to be included on the path the second time. In the worst case, the algorithm mimics the general algorithm and relaxes all E edges in each of V passes.</p><p attribs="{'xml:space': 'preserve'}" id="_11498" smilref="Title.smil#_11498" /></level3><level3 id="_00094"><h3 id="ch4-s4-ss28" smilref="Title.smil#ch4-s4-ss28" xml:space="preserve">Bellman-Ford algorithm</h3><pagenum id="p687" page="normal" smilref="Title.smil#p687" /><p attribs="{'xml:space': 'preserve'}" id="_11499" smilref="Title.smil#_11499"> 674</p><p attribs="{'xml:space': 'preserve'}" id="_11500" smilref="Title.smil#_11500"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11501" smilref="Title.smil#_11501"> ALGORITHM 4.11 Bellman-Ford algorithm (queue-based)</p><p attribs="{'xml:space': 'preserve'}" id="_11502" smilref="Title.smil#_11502"> public class BellmanFordSP { private double[] distTo; // length of path to v private DirectedEdge[] edgeTo; // last edge on path to v private boolean[] onQ; // Is this vertex on the queue? private Queue&lt;Integer&gt; queue; // vertices being relaxed private int cost; // number of calls to relax() private Iterable&lt;DirectedEdge&gt; cycle; // negative cycle in edgeTo[]?</p><p attribs="{'xml:space': 'preserve'}" id="_11503" smilref="Title.smil#_11503"> public BellmanFordSP(EdgeWeightedDigraph G, int s) { distTo = new double[G.V()]; edgeTo = new DirectedEdge[G.V()]; onQ = new boolean[G.V()]; queue = new Queue&lt;Integer&gt;(); for (int v = 0; v &lt; G.V(); v++) distTo[v] = Double.POSITIVE_INFINITY; distTo[s] = 0.0; queue.enqueue(s); onQ[s] = true; while (!queue.isEmpty() &amp;&amp; !this.hasNegativeCycle()) { int v = queue.dequeue(); onQ[v] = false; relax(v); } }</p><p attribs="{'xml:space': 'preserve'}" id="_11504" smilref="Title.smil#_11504"> private void relax(int v) // See page 673.</p><p attribs="{'xml:space': 'preserve'}" id="_11505" smilref="Title.smil#_11505"> public double distTo(int v) // standard client query methods public boolean hasPathTo(int v) // for SPT implementatations public Iterable&lt;Edge&gt; pathTo(int v) // (See page 649.)</p><p attribs="{'xml:space': 'preserve'}" id="_11506" smilref="Title.smil#_11506"> private void findNegativeCycle() public boolean hasNegativeCycle() public Iterable&lt;Edge&gt; negativeCycle() // See page 677. }</p><p attribs="{'xml:space': 'preserve'}" id="_11507" smilref="Title.smil#_11507"> This implementation of the Bellman-Ford algorithm uses a version of relax() that puts vertices pointed to by edges that successfully relax on a FIFO queue (avoiding duplicates) and periodically checks for a negative cycle in edgeTo[] (see text).</p><p attribs="{'xml:space': 'preserve'}" id="_11508" smilref="Title.smil#_11508" /><pagenum id="p688" page="normal" smilref="Title.smil#p688" /><p attribs="{'xml:space': 'preserve'}" id="_11509" smilref="Title.smil#_11509"> The queue-based Bellman-Ford algorithm is an effective and efficient method for solving the shortest-paths problem that is widely used in practice, even for the case when edge weights are positive. For example, as shown in the diagram at right, our 250-vertex example is complete in 14 passes and requires fewer path-length compares than Dijkstra&#8217;s algorithm for the same problem.</p><p attribs="{'xml:space': 'preserve'}" id="_11510" smilref="Title.smil#_11510"> Negative weights. The example on the next page traces the progress of the Bellman-Ford algorithm in a digraph with negative weights. We start with the source on q and then compute the SPT as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_11511" smilref="Title.smil#_11511"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11512" smilref="Title.smil#_11512"> 675</p><p attribs="{'xml:space': 'preserve'}" id="_11513" smilref="Title.smil#_11513"> passes 4</p><p attribs="{'xml:space': 'preserve'}" id="_11514" smilref="Title.smil#_11514"> edges on queue in red</p><p attribs="{'xml:space': 'preserve'}" id="_11515" smilref="Title.smil#_11515"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11516" smilref="Title.smil#_11516"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_11517" smilref="Title.smil#_11517"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_11518" smilref="Title.smil#_11518"> SPT</p><p attribs="{'xml:space': 'preserve'}" id="_11519" smilref="Title.smil#_11519"> Bellman-Ford (250 vertices)</p><p attribs="{'xml:space': 'preserve'}" id="_11520" smilref="Title.smil#_11520" /><pagenum id="p689" page="normal" smilref="Title.smil#p689" /><p attribs="{'xml:space': 'preserve'}" id="_11521" smilref="Title.smil#_11521"> 676</p><p attribs="{'xml:space': 'preserve'}" id="_11522" smilref="Title.smil#_11522"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11523" smilref="Title.smil#_11523"> tinyEWDn.txt 4-&gt;5 0.35 5-&gt;4 0.35 4-&gt;7 0.37 5-&gt;7 0.28 7-&gt;5 0.28 5-&gt;1 0.32 0-&gt;4 0.38 0-&gt;2 0.26 7-&gt;3 0.39 1-&gt;3 0.29 2-&gt;7 0.34 6-&gt;2 -1.20 3-&gt;6 0.52 6-&gt;0 -1.40 6-&gt;4 -1.25</p><p attribs="{'xml:space': 'preserve'}" id="_11524" smilref="Title.smil#_11524"> source</p><p attribs="{'xml:space': 'preserve'}" id="_11525" smilref="Title.smil#_11525"> queue</p><p attribs="{'xml:space': 'preserve'}" id="_11526" smilref="Title.smil#_11526"> 2 4 7 5</p><p attribs="{'xml:space': 'preserve'}" id="_11527" smilref="Title.smil#_11527"> 7 5 3 1</p><p attribs="{'xml:space': 'preserve'}" id="_11528" smilref="Title.smil#_11528"> 3 1 6</p><p attribs="{'xml:space': 'preserve'}" id="_11529" smilref="Title.smil#_11529"> 6 4</p><p attribs="{'xml:space': 'preserve'}" id="_11530" smilref="Title.smil#_11530"> 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_11531" smilref="Title.smil#_11531"> 5 1</p><p attribs="{'xml:space': 'preserve'}" id="_11532" smilref="Title.smil#_11532"> edgeTo[] distTo[] 0 1 2 0-&gt;2 0.26 3 4 0-&gt;4 0.38 5 4-&gt;5 0.73 6 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11533" smilref="Title.smil#_11533"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 0-&gt;4 0.38 5 4-&gt;5 0.73 6 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11534" smilref="Title.smil#_11534"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 0-&gt;4 0.38 5 4-&gt;5 0.73 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11535" smilref="Title.smil#_11535"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 6-&gt;4 0.26 5 4-&gt;5 0.73 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11536" smilref="Title.smil#_11536"> no longer eligible!</p><p attribs="{'xml:space': 'preserve'}" id="_11537" smilref="Title.smil#_11537"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 6-&gt;4 0.26 5 4-&gt;5 0.61 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11538" smilref="Title.smil#_11538"> edgeTo[] distTo[] 0 1 5-&gt;1 0.93 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 6-&gt;4 0.26 5 4-&gt;5 0.61 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11539" smilref="Title.smil#_11539"> Trace of the Bellman-Ford algorithm (negative weights)</p><p attribs="{'xml:space': 'preserve'}" id="_11540" smilref="Title.smil#_11540" /></level3><level3 id="_00095"><h3 id="ch4-s4-ss29" smilref="Title.smil#ch4-s4-ss29" xml:space="preserve">Negative cycle detection</h3><pagenum id="p690" page="normal" smilref="Title.smil#p690" /><p attribs="{'xml:space': 'preserve'}" id="_11541" smilref="Title.smil#_11541"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11542" smilref="Title.smil#_11542"> 677</p><p attribs="{'xml:space': 'preserve'}" id="_11543" smilref="Title.smil#_11543"> Negative cycle detection. Our implementation BellmanFordSP checks for negative cycles to avoid an infinite loop. We can apply the code that does this check to provide clients with the capability to check for and extract negative cycles, as well. We do so by adding the following methods to the SP API on page 644:</p><p attribs="{'xml:space': 'preserve'}" id="_11544" smilref="Title.smil#_11544"> boolean hasNegativeCycle()</p><p attribs="{'xml:space': 'preserve'}" id="_11545" smilref="Title.smil#_11545"> Iterable&lt;DirectedEdge&gt; negativeCycle()</p><p attribs="{'xml:space': 'preserve'}" id="_11546" smilref="Title.smil#_11546"> has a negative cycle? a negative cycle (null if no negative cycles)</p><p attribs="{'xml:space': 'preserve'}" id="_11547" smilref="Title.smil#_11547"> Shortest -paths API extensions for handling negative cycles</p><p attribs="{'xml:space': 'preserve'}" id="_11548" smilref="Title.smil#_11548"> Implementing these methods is not dif&#64257; cult, as shown in the code below. After running the constructor in BellmanFordSP, the proof of Proposition Y tells us that the digraph has a negative cycle reachable from the source if and only if the queue is nonempty after the Vth pass through all the edges. Moreover, the subgraph of edges in our edgeTo[] array must contain a negative cycle. Accordingly, to implement negativeCycle() we build an edge-weighted digraph from the edges in edgeTo[] and look for a cycle in that digraph. To find the cycle, we use a version of DirectedCycle from Section 4.3, adapted to work for edge-weighted digraphs (see Exercise 4.4.12). We amortize the cost of this check by </p><p attribs="{'xml:space': 'preserve'}" id="_11549" smilref="Title.smil#_11549"> private void findNegativeCycle() { int V = edgeTo.length; EdgeWeightedDigraph spt; spt = new EdgeWeightedDigraph(V); for (int v = 0; v &lt; V; v++) if (edgeTo[v] != null) spt.addEdge(edgeTo[v]);</p><p attribs="{'xml:space': 'preserve'}" id="_11550" smilref="Title.smil#_11550"> </p><p attribs="{'xml:space': 'preserve'}" id="_11551" smilref="Title.smil#_11551"> every Vth call to relax() This approach ensures that the loop in the constructor terminates. Moreover, clients can call hasNegativeCycle() to learn whether there is a negative cycle reachable from the source (and negativeCycle() to get one such cycle. Adding the capability to detect any negative cycle in the digraph is also a simple extension (see</p><p attribs="{'xml:space': 'preserve'}" id="_11552" smilref="Title.smil#_11552"> Exercise 4.4.43).</p><p attribs="{'xml:space': 'preserve'}" id="_11553" smilref="Title.smil#_11553"> EdgeWeightedCycleFinder cf; cf = new EdgeWeightedCycleFinder(spt);</p><p attribs="{'xml:space': 'preserve'}" id="_11554" smilref="Title.smil#_11554"> cycle = cf.cycle(); }</p><p attribs="{'xml:space': 'preserve'}" id="_11555" smilref="Title.smil#_11555"> public boolean hasNegativeCycle() { return cycle != null; }</p><p attribs="{'xml:space': 'preserve'}" id="_11556" smilref="Title.smil#_11556"> public Iterable&lt;Edge&gt; negativeCycle() { return cycle; }</p><p attribs="{'xml:space': 'preserve'}" id="_11557" smilref="Title.smil#_11557"> Negative cycle detection methods for Bellman-Ford algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11558" smilref="Title.smil#_11558" /><pagenum id="p691" page="normal" smilref="Title.smil#p691" /><p attribs="{'xml:space': 'preserve'}" id="_11559" smilref="Title.smil#_11559"> 678</p><p attribs="{'xml:space': 'preserve'}" id="_11560" smilref="Title.smil#_11560"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11561" smilref="Title.smil#_11561"> The example below traces the progress of the Bellman-Ford algorithm in a digraph with a negative cycle. The first two passes are the same as for tinyEWDn.txt. In the third pass, after relaxing 7-&gt;3 and 5-&gt;1 and putting 3 and 1 on queue, it relaxes the negative-weight edge 5-&gt;4. This relaxation discovers the negative cycle 4-&gt;5-&gt;4. It puts 5-&gt;4 on the tree and cuts the cycle off from the source 0 in edgeTo[]. From that point on, the algorithm spins through the cycle, lowering the distances to all the vertices touched, until finishing when the cycle is detected, with the queue not empty. The cycle is in the edgeTo[] array, for discovery by findNegativeCycle().</p><p attribs="{'xml:space': 'preserve'}" id="_11562" smilref="Title.smil#_11562"> source</p><p attribs="{'xml:space': 'preserve'}" id="_11563" smilref="Title.smil#_11563"> tinyEWDnc.txt 4-&gt;5 0.35 5-&gt;4 -0.66 4-&gt;7 0.37 5-&gt;7 0.28 7-&gt;5 0.28 5-&gt;1 0.32 0-&gt;4 0.38 0-&gt;2 0.26 7-&gt;3 0.39 1-&gt;3 0.29 2-&gt;7 0.34 6-&gt;2 0.40 3-&gt;6 0.52 6-&gt;0 0.58 6-&gt;4 0.93</p><p attribs="{'xml:space': 'preserve'}" id="_11564" smilref="Title.smil#_11564"> queue</p><p attribs="{'xml:space': 'preserve'}" id="_11565" smilref="Title.smil#_11565"> 2 4 7 5</p><p attribs="{'xml:space': 'preserve'}" id="_11566" smilref="Title.smil#_11566"> 7 5 3 1 4</p><p attribs="{'xml:space': 'preserve'}" id="_11567" smilref="Title.smil#_11567"> 3 1 4 6 7 5</p><p attribs="{'xml:space': 'preserve'}" id="_11568" smilref="Title.smil#_11568"> 6 7 5 3 1 4</p><p attribs="{'xml:space': 'preserve'}" id="_11569" smilref="Title.smil#_11569"> edgeTo[] distTo[] 0 1 2 0-&gt;2 0.26 3 4 0-&gt;4 0.38 5 4-&gt;5 0.73 6 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11570" smilref="Title.smil#_11570"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 5-&gt;4 0.07 5 4-&gt;5 0.73 6 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11571" smilref="Title.smil#_11571"> edgeTo[] distTo[] 0 1 5-&gt;1 1.05 2 0-&gt;2 0.26 3 7-&gt;3 0.99 4 0-&gt;4 0.07 5 4-&gt;5 0.42 6 3-&gt;6 1.51 7 2-&gt;7 0.44</p><p attribs="{'xml:space': 'preserve'}" id="_11572" smilref="Title.smil#_11572"> edgeTo[] distTo[] 0 1 5-&gt;1 0.74 2 0-&gt;2 0.26 3 7-&gt;3 0.83 4 5-&gt;4 -0.59 5 4-&gt;5 0.73 6 3-&gt;6 1.51 7 2-&gt;7 0.60</p><p attribs="{'xml:space': 'preserve'}" id="_11573" smilref="Title.smil#_11573"> length of</p><p attribs="{'xml:space': 'preserve'}" id="_11574" smilref="Title.smil#_11574"> 0-&gt;4-&gt;5-&gt;4</p><p attribs="{'xml:space': 'preserve'}" id="_11575" smilref="Title.smil#_11575"> length of</p><p attribs="{'xml:space': 'preserve'}" id="_11576" smilref="Title.smil#_11576"> 0-&gt;4-&gt;5-&gt;4-&gt;5-&gt;4</p><p attribs="{'xml:space': 'preserve'}" id="_11577" smilref="Title.smil#_11577"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_11578" smilref="Title.smil#_11578"> Trace of the Bellman-Ford algorithm (negative cycle)</p><p attribs="{'xml:space': 'preserve'}" id="_11579" smilref="Title.smil#_11579" /></level3><level3 id="_00096"><h3 id="ch4-s4-ss30" smilref="Title.smil#ch4-s4-ss30" xml:space="preserve">Arbitrage</h3><pagenum id="p692" page="normal" smilref="Title.smil#p692" /><p attribs="{'xml:space': 'preserve'}" id="_11580" smilref="Title.smil#_11580"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11581" smilref="Title.smil#_11581"> 679</p><p attribs="{'xml:space': 'preserve'}" id="_11582" smilref="Title.smil#_11582"> % more rates.txt 5 USD 1 0.741 0.657 1.061 1.005 EUR 1.349 1 0.888 1.433 1.366 GBP 1.521 1.126 1 1.614 1.538 CHF 0.942 0.698 0.619 1 0.953 CAD 0.995 0.732 0.650 1.049 1</p><p attribs="{'xml:space': 'preserve'}" id="_11583" smilref="Title.smil#_11583"> Arbitrage. Consider a market for financial transactions that is based on trading com- modities. You can find a familiar example in tables that show conversion rates among currencies, such as the one in our sample file rates.txt shown here. The first line in the file is the number V of currencies; then the file has one line per currency, giving its name followed by the conversion rates to the other currencies. For brevity, this example includes just five of the hundreds of currencies that are traded on modern markets: U.S. dollars (USD), Euros (EUR), British pounds (GBP), Swiss francs (CHF), and Canadian dollars (CAD). The tth number on line s represents a conversion rate: the number of units of the currency named on row t that can be bought with 1 unit of the currency named on row s. For example, our table says that 1,000 U.S. dollars will buy 741 euros. This table is equivalent to a complete edge-weighted digraph with a vertex corresponding to each currency and an edge corresponding to each conversion rate. An edge s-&gt;t with weight x corresponds to a conversion from s to t at exchange rate x. Paths in the digraph specify multistep conversions. For example, combining the conversion just mentioned with an edge t-&gt;u with weight y gives a path s-&gt;t-&gt;u that represents a way to convert 1 unit of currency s into xy units of currency u. For example, we might buy 1,012.206 = 741 &#215; 1.366 Canadian dollars with our euros. Note that this gives a better rate than directly converting from U.S. dollars to Canadian dollars. You might expect xy to be equal to the weight of s-&gt;u in all such cases, but such tables represent a complex financial system where such consistency cannot be guaranteed. Thus, finding the path from s to u such that the product of the weights is maximal is certainly of interest. Even more interesting is a case where the product of the edge weights is smaller than the weight of the edge from the last vertex back to the fi rst. In our example, suppose that the weight of u-&gt;s is z and xyz &gt; 1. Then cycle s-&gt;t-&gt;u-&gt;s gives a way to convert 1 unit of currency s into more than 1 unit (xyz) of currency s. In other words, we can make a 100(xyz - 1) percent profit by converting from s to t to u back to s. For example, if we convert our 1,012.206 Canadian dollars back to US dollars, we get 1,012.206 &#215; .995 = 1,007.14497 dollars, a 7.14497-dollar pro&#64257; t. That might not seem</p><p attribs="{'xml:space': 'preserve'}" id="_11584" smilref="Title.smil#_11584"> 0 . 9 4 2</p><p attribs="{'xml:space': 'preserve'}" id="_11585" smilref="Title.smil#_11585"> 0 . 8 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_11586" smilref="Title.smil#_11586"> 1 . 0 6 1</p><p attribs="{'xml:space': 'preserve'}" id="_11587" smilref="Title.smil#_11587"> 0 . 6 5 0</p><p attribs="{'xml:space': 'preserve'}" id="_11588" smilref="Title.smil#_11588"> 0 . 7 4 1</p><p attribs="{'xml:space': 'preserve'}" id="_11589" smilref="Title.smil#_11589"> 1 . 3 4 9</p><p attribs="{'xml:space': 'preserve'}" id="_11590" smilref="Title.smil#_11590"> 2 3 7 . 0</p><p attribs="{'xml:space': 'preserve'}" id="_11591" smilref="Title.smil#_11591"> 6 6 3 . 1</p><p attribs="{'xml:space': 'preserve'}" id="_11592" smilref="Title.smil#_11592"> 1.049</p><p attribs="{'xml:space': 'preserve'}" id="_11593" smilref="Title.smil#_11593"> 0.953</p><p attribs="{'xml:space': 'preserve'}" id="_11594" smilref="Title.smil#_11594"> 0.657</p><p attribs="{'xml:space': 'preserve'}" id="_11595" smilref="Title.smil#_11595"> CAD</p><p attribs="{'xml:space': 'preserve'}" id="_11596" smilref="Title.smil#_11596"> USD</p><p attribs="{'xml:space': 'preserve'}" id="_11597" smilref="Title.smil#_11597"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11598" smilref="Title.smil#_11598"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11599" smilref="Title.smil#_11599"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11600" smilref="Title.smil#_11600"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11601" smilref="Title.smil#_11601"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11602" smilref="Title.smil#_11602"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11603" smilref="Title.smil#_11603"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11604" smilref="Title.smil#_11604"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11605" smilref="Title.smil#_11605"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11606" smilref="Title.smil#_11606"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11607" smilref="Title.smil#_11607"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11608" smilref="Title.smil#_11608"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11609" smilref="Title.smil#_11609"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11610" smilref="Title.smil#_11610"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11611" smilref="Title.smil#_11611"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11612" smilref="Title.smil#_11612"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11613" smilref="Title.smil#_11613"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11614" smilref="Title.smil#_11614"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11615" smilref="Title.smil#_11615"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11616" smilref="Title.smil#_11616"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11617" smilref="Title.smil#_11617"> EUR</p><p attribs="{'xml:space': 'preserve'}" id="_11618" smilref="Title.smil#_11618"> 0.741 * 1.366 * .995 = 1.00714497</p><p attribs="{'xml:space': 'preserve'}" id="_11619" smilref="Title.smil#_11619"> An arbitrage opportunity</p><p attribs="{'xml:space': 'preserve'}" id="_11620" smilref="Title.smil#_11620"> GBP</p><p attribs="{'xml:space': 'preserve'}" id="_11621" smilref="Title.smil#_11621"> 4 1 6 . 1</p><p attribs="{'xml:space': 'preserve'}" id="_11622" smilref="Title.smil#_11622"> 1 . 1 2 6</p><p attribs="{'xml:space': 'preserve'}" id="_11623" smilref="Title.smil#_11623"> 1.521</p><p attribs="{'xml:space': 'preserve'}" id="_11624" smilref="Title.smil#_11624"> 1 . 5 3 8</p><p attribs="{'xml:space': 'preserve'}" id="_11625" smilref="Title.smil#_11625"> 9 1 6 . 0</p><p attribs="{'xml:space': 'preserve'}" id="_11626" smilref="Title.smil#_11626"> CHF</p><p attribs="{'xml:space': 'preserve'}" id="_11627" smilref="Title.smil#_11627" /><pagenum id="p693" page="normal" smilref="Title.smil#p693" /><p attribs="{'xml:space': 'preserve'}" id="_11628" smilref="Title.smil#_11628"> 680</p><p attribs="{'xml:space': 'preserve'}" id="_11629" smilref="Title.smil#_11629"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11630" smilref="Title.smil#_11630"> Arbitrage in currency exchange</p><p attribs="{'xml:space': 'preserve'}" id="_11631" smilref="Title.smil#_11631"> public class Arbitrage { public static void main(String[] args) { int V = StdIn.readInt(); String[] name = new String[V]; EdgeWeightedDigraph G = new EdgeWeightedDigraph(V); for (int v = 0; v &lt; V; v++) { name[v] = StdIn.readString(); for (int w = 0; w &lt; V; w++) { double rate = StdIn.readDouble(); DirectedEdge e = new DirectedEdge(v, w, -Math.log(rate)); G.addEdge(e); } }</p><p attribs="{'xml:space': 'preserve'}" id="_11632" smilref="Title.smil#_11632"> BellmanFordSP spt = new BellmanFordSP(G, 0); if (spt.hasNegativeCycle()) { double stake = 1000.0; for (DirectedEdge e : spt.negativeCycle()) { StdOut.printf("%10.5f %s ", stake, name[e.from()]); stake *= Math.exp(-e.weight()); StdOut.printf("= %10.5f %s\n", stake, name[e.to()]); } } else StdOut.println("No arbitrage opportunity"); } }</p><p attribs="{'xml:space': 'preserve'}" id="_11633" smilref="Title.smil#_11633"> This BellmanFordSP client finds an arbitrage opportunity in a currency exchange table by constructing a complete-graph representation of the exchange table and then using the Bellman-Ford algorithm to find a negative cycle in the graph.</p><p attribs="{'xml:space': 'preserve'}" id="_11634" smilref="Title.smil#_11634"> % java Arbitrage &lt; rates.txt 1000.00000 USD = 741.00000 EUR 741.00000 EUR = 1012.20600 CAD 1012.20600 CAD = 1007.14497 USD</p><p attribs="{'xml:space': 'preserve'}" id="_11635" smilref="Title.smil#_11635" /><pagenum id="p694" page="normal" smilref="Title.smil#p694" /><p attribs="{'xml:space': 'preserve'}" id="_11636" smilref="Title.smil#_11636"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11637" smilref="Title.smil#_11637"> 681</p><p attribs="{'xml:space': 'preserve'}" id="_11638" smilref="Title.smil#_11638"> like much, but a currency trader might have 1 million dollars and be able to execute these transactions every minute, which would lead to profits of over $7,000 per minute, or $420,000 per hour! This situation is an example of an arbitrage opportunity that would allow traders to make unlimited profits were it not for forces outside the model, such as transaction fees or limitations on the size of transactions. Even with these forc- es, arbitrage is plenty profitable in the real world. What does this problem have to do with shortest paths? The answer to this question is remarkably simple:</p><p attribs="{'xml:space': 'preserve'}" id="_11639" smilref="Title.smil#_11639"> Proposition Z. The arbitrage problem is a negative-cycle-detection problem in edge-weighted digraphs.</p><p attribs="{'xml:space': 'preserve'}" id="_11640" smilref="Title.smil#_11640"> Proof : Replace each weight by its logarithm, negated. With this change, computing path weights by multiplying edge weights in the original problem corresponds to adding them in the transformed problem. Speci&#64257; cally, any product w1w2 . . . wk corresponds to a sum &#11002;ln(w1) &#11002; ln(w2) &#11002; . . . &#11002; ln(wk). The transformed edge weights might be negative or positive, a path from v to w gives a way of converting from currency v to currency w, and any negative cycle is an arbitrage opportunity.</p><p attribs="{'xml:space': 'preserve'}" id="_11641" smilref="Title.smil#_11641"> In our example, where all transactions are possible, the digraph is a complete graph, so any negative cycle is reachable from any vertex. In general commodity exchanges, some edges may be absent, so the one-argument constructor described in Exercise 4.4.43 is needed. No efficient algorithm for finding the best arbitrage opportunity (the most negative cycle in a digraph) is known (and the graph does not have to be very big for this computational burden to be overwhelming), but the fastest algorithm to find any arbitrage opportunity is crucial&#8212;a trader with that algorithm is likely to systematically wipe out numerous opportunities before the second-fastest algorithm finds any.</p><p attribs="{'xml:space': 'preserve'}" id="_11642" smilref="Title.smil#_11642"> .2998 - .3119 + .0050 = -.0071</p><p attribs="{'xml:space': 'preserve'}" id="_11643" smilref="Title.smil#_11643"> -ln(.741) -ln(1.366) -ln(.995)</p><p attribs="{'xml:space': 'preserve'}" id="_11644" smilref="Title.smil#_11644"> - . 2 9 9 9</p><p attribs="{'xml:space': 'preserve'}" id="_11645" smilref="Title.smil#_11645"> 9 1 1 3 . -</p><p attribs="{'xml:space': 'preserve'}" id="_11646" smilref="Title.smil#_11646"> . 1 1 8 8</p><p attribs="{'xml:space': 'preserve'}" id="_11647" smilref="Title.smil#_11647"> . 2 9 9 8</p><p attribs="{'xml:space': 'preserve'}" id="_11648" smilref="Title.smil#_11648"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11649" smilref="Title.smil#_11649"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11650" smilref="Title.smil#_11650"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11651" smilref="Title.smil#_11651"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11652" smilref="Title.smil#_11652"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11653" smilref="Title.smil#_11653"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11654" smilref="Title.smil#_11654"> EUR</p><p attribs="{'xml:space': 'preserve'}" id="_11655" smilref="Title.smil#_11655"> The transformation in the proof of Proposition Z</p><p attribs="{'xml:space': 'preserve'}" id="_11656" smilref="Title.smil#_11656"> is useful even in the absence of arbitrage, because it reduces currency conversion to a shortest-paths problem. Since the logarithm function is monotonic (and we negated the logarithms), the product is maximized precisely when the sum is minimized. The edge weights might be negative or positive, and a shortest path from v to w gives a best way of converting from currency v to currency w.</p><p attribs="{'xml:space': 'preserve'}" id="_11657" smilref="Title.smil#_11657"> - . 1 1 8 7</p><p attribs="{'xml:space': 'preserve'}" id="_11658" smilref="Title.smil#_11658"> replace each weight w with &#11002;ln(w)</p><p attribs="{'xml:space': 'preserve'}" id="_11659" smilref="Title.smil#_11659"> -.4914</p><p attribs="{'xml:space': 'preserve'}" id="_11660" smilref="Title.smil#_11660"> - . 4 3 0 5</p><p attribs="{'xml:space': 'preserve'}" id="_11661" smilref="Title.smil#_11661"> GBP</p><p attribs="{'xml:space': 'preserve'}" id="_11662" smilref="Title.smil#_11662"> 7 8 7 4 . -</p><p attribs="{'xml:space': 'preserve'}" id="_11663" smilref="Title.smil#_11663"> .4201</p><p attribs="{'xml:space': 'preserve'}" id="_11664" smilref="Title.smil#_11664"> USD</p><p attribs="{'xml:space': 'preserve'}" id="_11665" smilref="Title.smil#_11665"> - . 0 5 9 2</p><p attribs="{'xml:space': 'preserve'}" id="_11666" smilref="Title.smil#_11666"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11667" smilref="Title.smil#_11667"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11668" smilref="Title.smil#_11668"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11669" smilref="Title.smil#_11669"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11670" smilref="Title.smil#_11670"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11671" smilref="Title.smil#_11671"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11672" smilref="Title.smil#_11672"> 0 2 1 3 .</p><p attribs="{'xml:space': 'preserve'}" id="_11673" smilref="Title.smil#_11673"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11674" smilref="Title.smil#_11674"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11675" smilref="Title.smil#_11675"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11676" smilref="Title.smil#_11676"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11677" smilref="Title.smil#_11677"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_11678" smilref="Title.smil#_11678"> . 4 3 0 8</p><p attribs="{'xml:space': 'preserve'}" id="_11679" smilref="Title.smil#_11679"> -.0478</p><p attribs="{'xml:space': 'preserve'}" id="_11680" smilref="Title.smil#_11680"> CAD</p><p attribs="{'xml:space': 'preserve'}" id="_11681" smilref="Title.smil#_11681"> .</p><p attribs="{'xml:space': 'preserve'}" id="_11682" smilref="Title.smil#_11682"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11683" smilref="Title.smil#_11683"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11684" smilref="Title.smil#_11684"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_11685" smilref="Title.smil#_11685"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11686" smilref="Title.smil#_11686"> . 0 5 9 8</p><p attribs="{'xml:space': 'preserve'}" id="_11687" smilref="Title.smil#_11687"> .0481</p><p attribs="{'xml:space': 'preserve'}" id="_11688" smilref="Title.smil#_11688"> 7 9 7 4 .</p><p attribs="{'xml:space': 'preserve'}" id="_11689" smilref="Title.smil#_11689"> CHF</p><p attribs="{'xml:space': 'preserve'}" id="_11690" smilref="Title.smil#_11690"> A negative cycle that represents an arbitrage opportunity</p><p attribs="{'xml:space': 'preserve'}" id="_11691" smilref="Title.smil#_11691" /><pagenum id="p695" page="normal" smilref="Title.smil#p695" /><p attribs="{'xml:space': 'preserve'}" id="_11692" smilref="Title.smil#_11692"> 682</p><p attribs="{'xml:space': 'preserve'}" id="_11693" smilref="Title.smil#_11693"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11694" smilref="Title.smil#_11694"> Perspective The table below summarizes the important characteristics of the shortest-paths algorithms that we have considered in this section. The first reason to choose among the algorithms has to do with basic properties of the digraph at hand. Does it have negative weights? Does it have cycles? Does it have negative cycles? Be- yond these basic characteristics, the characteristics of edge-weighted digraphs can vary widely, so choosing among the algorithms requires some experimentation when more than one can apply.</p><p attribs="{'xml:space': 'preserve'}" id="_11695" smilref="Title.smil#_11695"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11696" smilref="Title.smil#_11696"> restriction</p><p attribs="{'xml:space': 'preserve'}" id="_11697" smilref="Title.smil#_11697"> Dijkstra (eager)</p><p attribs="{'xml:space': 'preserve'}" id="_11698" smilref="Title.smil#_11698"> topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_11699" smilref="Title.smil#_11699"> Bellman-Ford (queue-based)</p><p attribs="{'xml:space': 'preserve'}" id="_11700" smilref="Title.smil#_11700"> positive edge weights edge-weighted DAGs no negative cycles</p><p attribs="{'xml:space': 'preserve'}" id="_11701" smilref="Title.smil#_11701"> path length compares (order of growth)</p><p attribs="{'xml:space': 'preserve'}" id="_11702" smilref="Title.smil#_11702"> typical</p><p attribs="{'xml:space': 'preserve'}" id="_11703" smilref="Title.smil#_11703"> worst case</p><p attribs="{'xml:space': 'preserve'}" id="_11704" smilref="Title.smil#_11704"> extra space</p><p attribs="{'xml:space': 'preserve'}" id="_11705" smilref="Title.smil#_11705"> E log V</p><p attribs="{'xml:space': 'preserve'}" id="_11706" smilref="Title.smil#_11706"> E log V</p><p attribs="{'xml:space': 'preserve'}" id="_11707" smilref="Title.smil#_11707"> E + V</p><p attribs="{'xml:space': 'preserve'}" id="_11708" smilref="Title.smil#_11708"> E + V</p><p attribs="{'xml:space': 'preserve'}" id="_11709" smilref="Title.smil#_11709"> E + V</p><p attribs="{'xml:space': 'preserve'}" id="_11710" smilref="Title.smil#_11710"> VE</p><p attribs="{'xml:space': 'preserve'}" id="_11711" smilref="Title.smil#_11711"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11712" smilref="Title.smil#_11712"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11713" smilref="Title.smil#_11713"> V</p><p attribs="{'xml:space': 'preserve'}" id="_11714" smilref="Title.smil#_11714"> sweet spot</p><p attribs="{'xml:space': 'preserve'}" id="_11715" smilref="Title.smil#_11715"> worst-case guarantee</p><p attribs="{'xml:space': 'preserve'}" id="_11716" smilref="Title.smil#_11716"> optimal for acyclic</p><p attribs="{'xml:space': 'preserve'}" id="_11717" smilref="Title.smil#_11717"> widely applicable</p><p attribs="{'xml:space': 'preserve'}" id="_11718" smilref="Title.smil#_11718"> Performance characteristics of shortest-paths algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_11719" smilref="Title.smil#_11719"> Historical notes. Shortest-paths problems have been intensively studied and widely used since the 1950s. The history of Dijkstra&#8217;s algorithm for computing shortest paths is similar (and related) to the history of Prim&#8217;s algorithm for computing the MST. The name Dijkstra&#8217;s algorithm is commonly used to refer both to the abstract method of building an SPT by adding vertices in order of their distance from the source and to its implementation as the optimal algorithm for the adjacency-matrix representation, because E. W. Dijkstra presented both in his 1959 paper (and also showed that the same approach could compute the MST). Performance improvements for sparse graphs are dependent on later improvements in priority-queue implementations that are not spe- ci&#64257; c to the shortest-paths problem. Improved performance of Dijkstra&#8217;s algorithm is one of the most important applications of that technology (for example, with a data structure known as a Fibonacci heap, the worst-case bound can be reduced to E + V log V). The Bellman-Ford algorithm has proven to be useful in practice and has found wide application, particularly for general edge-weighted digraphs. While the running time of the Bellman-Ford algorithm is likely to be linear for typical applications, its worst-case running time is VE. The development of a worst-case linear-time shortest-paths algorithm for sparse graphs remains an open problem. The basic Bellman-Ford algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_11720" smilref="Title.smil#_11720" /><pagenum id="p696" page="normal" smilref="Title.smil#p696" /><p attribs="{'xml:space': 'preserve'}" id="_11721" smilref="Title.smil#_11721"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11722" smilref="Title.smil#_11722"> 683</p><p attribs="{'xml:space': 'preserve'}" id="_11723" smilref="Title.smil#_11723"> was developed in the 1950s by L. Ford and R. Bellman; despite the dramatic strides in performance that we have seen for many other graph problems, we have not yet seen algorithms with better worst-case performance for digraphs with negative edge weights (but no negative cycles).</p><p attribs="{'xml:space': 'preserve'}" id="_11724" smilref="Title.smil#_11724" /><pagenum id="p697" page="normal" smilref="Title.smil#p697" /><p attribs="{'xml:space': 'preserve'}" id="_11725" smilref="Title.smil#_11725"> 684</p><p attribs="{'xml:space': 'preserve'}" id="_11726" smilref="Title.smil#_11726"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11727" smilref="Title.smil#_11727"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_11728" smilref="Title.smil#_11728"> Q. Why define separate data types for undirected graphs, directed graphs, edge-weight- ed undirected graphs, and edge-weighted digraphs? A. We do so both for clarity in client code and for simpler and more efficient implementation code in unweighted graphs. In applications or systems where all types of graphs are to be processed, it is a textbook exercise in software engineering to define an ADT from which ADTs can be derived for Graph, the unweighted undirected graphs of Section 4.1; Digraph, the unweighted digraphs of Section 4.2; EdgeWeightedGraph, the edge-weighted undirected graphs of Section 4.3; or EdgeWeightedDigraph, the edge-weighted directed graphs of this section. Q. How can we find shortest paths in undirected (edge-weighted) graphs? A. For positive edge weights, Dijkstra&#8217;s algorithm does the job. We just build an EdgeWeightedDigraph corresponding to the given EdgeWeightedGraph (by adding two directed edges corresponding to each undirected edge, one in each direction) and then run Dijkstra&#8217;s algorithm. If edge weights can be negative, efficient algorithms are available, but they are more complicated than the Bellman-Ford algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_11729" smilref="Title.smil#_11729" /><pagenum id="p698" page="normal" smilref="Title.smil#p698" /><p attribs="{'xml:space': 'preserve'}" id="_11730" smilref="Title.smil#_11730"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11731" smilref="Title.smil#_11731"> 685</p><p attribs="{'xml:space': 'preserve'}" id="_11732" smilref="Title.smil#_11732"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_11733" smilref="Title.smil#_11733"> 4.4.1 True or false: Adding a constant to every edge weight does not change the solution to the single-source shortest-paths problem. 4.4.2 Provide an implementation of toString() for EdgeWeightedDigraph. 4.4.3 Develop an implementation of EdgeWeightedDigraph for dense graphs that uses an adjacency-matrix (two-dimensional array of weights) representation (see Ex- ercise 4.3.9). Ignore parallel edges. 4.4.4 Draw the SPT for source 0 of the edge-weighted digraph obtained by deleting vertex 7 from tinyEWD.txt (see page 644), and give the parent-link representation of the SPT. Answer the question for the same graph with all edge reversed. 4.4.5 Change the direction of edge 0-&gt;2 in tinyEWD.txt (see page 644). Draw two different SPTs that are rooted at 2 for this modified edge-weighted digraph. 4.4.6 Give a trace that shows the process of computing the SPT of the digraph defined in Exercise 4.4.5 with the eager version of Dijkstra&#8217;s algorithm. 4.4.7 Develop a version of DijkstraSP that supports a client method that returns a second shortest path from s to t in an edge-weighted digraph (and returns null if there is only one shortest path from s to t). 4.4.8 The diameter of a digraph is the length of the maximum-length shortest path connecting two vertices. Write a DijkstraSP client that finds the diameter of a given EdgeWeightedDigraph that has nonnegative weights. 4.4.9 The table below, from an old published road map, purports to give the length of the shortest routes connecting the cities. It contains an error. Correct the table. Also, add a table that shows how to achieve the shortest routes.</p><p attribs="{'xml:space': 'preserve'}" id="_11734" smilref="Title.smil#_11734"> Providence</p><p attribs="{'xml:space': 'preserve'}" id="_11735" smilref="Title.smil#_11735"> Westerly</p><p attribs="{'xml:space': 'preserve'}" id="_11736" smilref="Title.smil#_11736"> New London</p><p attribs="{'xml:space': 'preserve'}" id="_11737" smilref="Title.smil#_11737"> Norwich</p><p attribs="{'xml:space': 'preserve'}" id="_11738" smilref="Title.smil#_11738"> Providence</p><p attribs="{'xml:space': 'preserve'}" id="_11739" smilref="Title.smil#_11739"> Westerly</p><p attribs="{'xml:space': 'preserve'}" id="_11740" smilref="Title.smil#_11740"> New London</p><p attribs="{'xml:space': 'preserve'}" id="_11741" smilref="Title.smil#_11741"> Norwich</p><p attribs="{'xml:space': 'preserve'}" id="_11742" smilref="Title.smil#_11742"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11743" smilref="Title.smil#_11743"> 53</p><p attribs="{'xml:space': 'preserve'}" id="_11744" smilref="Title.smil#_11744"> 54</p><p attribs="{'xml:space': 'preserve'}" id="_11745" smilref="Title.smil#_11745"> 48</p><p attribs="{'xml:space': 'preserve'}" id="_11746" smilref="Title.smil#_11746"> 53</p><p attribs="{'xml:space': 'preserve'}" id="_11747" smilref="Title.smil#_11747"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11748" smilref="Title.smil#_11748"> 18</p><p attribs="{'xml:space': 'preserve'}" id="_11749" smilref="Title.smil#_11749"> 101</p><p attribs="{'xml:space': 'preserve'}" id="_11750" smilref="Title.smil#_11750"> 54</p><p attribs="{'xml:space': 'preserve'}" id="_11751" smilref="Title.smil#_11751"> 18</p><p attribs="{'xml:space': 'preserve'}" id="_11752" smilref="Title.smil#_11752"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11753" smilref="Title.smil#_11753"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_11754" smilref="Title.smil#_11754"> 48</p><p attribs="{'xml:space': 'preserve'}" id="_11755" smilref="Title.smil#_11755"> 101</p><p attribs="{'xml:space': 'preserve'}" id="_11756" smilref="Title.smil#_11756"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_11757" smilref="Title.smil#_11757"> -</p><p attribs="{'xml:space': 'preserve'}" id="_11758" smilref="Title.smil#_11758" /><pagenum id="p699" page="normal" smilref="Title.smil#p699" /><p attribs="{'xml:space': 'preserve'}" id="_11759" smilref="Title.smil#_11759"> 686</p><p attribs="{'xml:space': 'preserve'}" id="_11760" smilref="Title.smil#_11760"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11761" smilref="Title.smil#_11761"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_11762" smilref="Title.smil#_11762"> 4.4.10 Consider the edges in the digraph defined in Exercise 4.4.4 to be undirected edges such that each edge corresponds to equal-weight edges in both directions in the edge-weighted digraph. Answer Exercise 4.4.6 for this corresponding edge-weighted digraph. 4.4.11 Use the memory-cost model of Section 1.4 to determine the amount of memory used by EdgeWeightedDigraph to represent a graph with V vertices and E edges,. 4.4.12 Adapt the DirectedCycle and Topological classes from Section 4.2 to use the EdgeweightedDigraph and DirectedEdge APIs of this section, thus implementing</p><p attribs="{'xml:space': 'preserve'}" id="_11763" smilref="Title.smil#_11763"> EdgeWeightedDirectedCycle and Topological classes.</p><p attribs="{'xml:space': 'preserve'}" id="_11764" smilref="Title.smil#_11764"> 4.4.13 Show, in the style of the trace in the text, the process of computing the SPT with Dijkstra&#8217;s algorithm for the digraph obtained by removing the edge 5-&gt;7 from tinyEWD.txt (see page 644). 4.4.14 Show the paths that would be discovered by the two strawman approaches described on page 668 for the example tinyEWDn.txt shown on that page. 4.4.15 What happens to Bellman-Ford if there is a negative cycle on the path from s to v and then you call pathTo(v)? 4.4.16 Suppose that we convert an EdgeWeightedGraph into an EdgeWeightedDigraph by creating two DirectedEdge objects in the EdgeWeightedDigraph (one in each di- rection) for each Edge in the EdgeWeightedGraph (as described for Dijkstra&#8217;s algorithm in the Q&amp;A on page 684) and then use the Bellman-Ford algorithm. Explain why this approach fails spectacularly. 4.4.17 What happens if you allow a vertex to be enqueued more than once in the same pass in the Bellman-Ford algorithm?</p><p attribs="{'xml:space': 'preserve'}" id="_11765" smilref="Title.smil#_11765"> Answer : The running time of the algorithm can go exponential. For example, consider what happens for the complete edge-weighted digraph whose edge weights are all -1.</p><p attribs="{'xml:space': 'preserve'}" id="_11766" smilref="Title.smil#_11766"> 4.4.18 Write a CPM client that prints all critical paths. 4.4.19 Find the lowest-weight cycle (best arbitrage opportunity) in the example shown in the text.</p><p attribs="{'xml:space': 'preserve'}" id="_11767" smilref="Title.smil#_11767" /><pagenum id="p700" page="normal" smilref="Title.smil#p700" /><p attribs="{'xml:space': 'preserve'}" id="_11768" smilref="Title.smil#_11768"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11769" smilref="Title.smil#_11769"> 687</p><p attribs="{'xml:space': 'preserve'}" id="_11770" smilref="Title.smil#_11770"> 4.4.20 Find a currency-conversion table online or in a newspaper. Use it to build an arbitrage table. Note : Avoid tables that are derived (calculated) from a few values and that therefore do not give sufficiently accurate conversion information to be interesting. Extra credit : Make a killing in the money-exchange market! 4.4.21 Show, in the style of the trace in the text, the process of computing the SPT with the Bellman-Ford algorithm for the edge-weighted digraph of Exercise 4.4.5.</p><p attribs="{'xml:space': 'preserve'}" id="_11771" smilref="Title.smil#_11771" /><pagenum id="p701" page="normal" smilref="Title.smil#p701" /><p attribs="{'xml:space': 'preserve'}" id="_11772" smilref="Title.smil#_11772"> 688</p><p attribs="{'xml:space': 'preserve'}" id="_11773" smilref="Title.smil#_11773"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11774" smilref="Title.smil#_11774"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_11775" smilref="Title.smil#_11775"> 4.4.22 Vertex weights. Show that shortest-paths computations in edge-weighted digraphs with nonnegative weights on vertices (where the weight of a path is defined to be the sum of the weights of the vertices) can be handled by building an edge-weighted digraph that has weights on only the edges. 4.4.23 Source-sink shortest paths. Develop an API and implementation that use a version of Dijkstra&#8217;s algorithm to solve the source-sink shortest path problem on edge- weighted digraphs. 4.4.24 Multisource shortest paths. Develop an API and implementation that uses Di- jkstra&#8217;s algorithm to solve the multisource shortest-paths problem on edge-weighted digraphs with positive edge weights: given a set of sources, find a shortest-paths forest that enables implementation of a method that returns to clients the shortest path from any source to each vertex. Hint : Add a dummy vertex with a zero-weight edge to each source, or initialize the priority queue with all sources, with their distTo[] entries set to 0. 4.4.25 Shortest path between two subsets. Given a digraph with positive edge weights, and two distinguished subsets of vertices S and T, find a shortest path from any vertex in S to any vertex in T. Your algorithm should run in time proportional to E log V, in the worst case. 4.4.26 Single-source shortest paths in dense graphs. Develop a version of Dijkstra&#8217;s algorithm that can find the SPT from a given vertex in a dense edge-weighted digraph in time proportional to V 2. Use an adjacency-matrix representation (see Exercise 4.4.3</p><p attribs="{'xml:space': 'preserve'}" id="_11776" smilref="Title.smil#_11776"> and Exercise 4.3.29).</p><p attribs="{'xml:space': 'preserve'}" id="_11777" smilref="Title.smil#_11777"> 4.4.27 Shortest paths in Euclidean graphs. Adapt our APIs to speed up Dijkstra&#8217;s algorithm in the case where it is known that vertices are points in the plane. 4.4.28 Longest paths in DAGs. Develop an implementation AcyclicLP that can solve the longest-paths problem in edge-weighted DAGs, as described in Proposition T. 4.4.29 General optimality. Complete the proof of Proposition W by showing that if there exists a directed path from s to v and no vertex on any path from s to v is on a negative cycle, then there exists a shortest path from s to v (Hint : See Proposition P.) 4.4.30 All-pairs shortest paths in digraphs with negative cycles. Articulate an API like the one implemented on page 656 for the all-pairs shortest-paths problem in graphs with</p><p attribs="{'xml:space': 'preserve'}" id="_11778" smilref="Title.smil#_11778" /><pagenum id="p702" page="normal" smilref="Title.smil#p702" /><p attribs="{'xml:space': 'preserve'}" id="_11779" smilref="Title.smil#_11779"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11780" smilref="Title.smil#_11780"> 689</p><p attribs="{'xml:space': 'preserve'}" id="_11781" smilref="Title.smil#_11781"> no negative cycles. Develop an implementation that runs a version of Bellman-Ford to identify weights pi[v] such that for any edge v-&gt;w, the edge weight plus the difference between pi[v] and pi[w] is nonnegative. Then use these weights to reweight the graph, so that Dijkstra&#8217;s algorithm is effective for finding all shortest paths in the reweighted graph. 4.4.31 All-pairs shortest paths on a line. Given a weighted line graph (undirected connected graph, all vertices of degree 2, except two endpoints which have degree 1), devise an algorithm that preprocesses the graph in linear time and can return the distance of the shortest path between any two vertices in constant time. 4.4.32 Parent-checking heuristic. Modify Bellman-Ford to visit a vertex v only if its SPT parent edgeTo[v] is not currently on the queue. This heuristic has been reported by Cherkassky, Goldberg, and Radzik to be useful in practice. Prove that it correctly computes shortest paths and that the worst-case running time is proportional to EV. 4.4.33 Shortest path in a grid. Given an N-by-N matrix of positive integers, find the shortest path from the (0, 0) entry to the (N&#11002;1, N&#11002;1) entry, where the length of the path is the sum of the integers in the path. Repeat the problem but assume you can only move right and down. 4.4.34 Monotonic shortest path. Given an edge-weighted digraph, find a monotonic shortest path from s to every other vertex. A path is monotonic if the weight of every edge on the path is either strictly increasing or strictly decreasing. Hint : Relax edges in ascending order and find a best path; then relax edges in descending order and find a best path. 4.4.35 Bitonic shortest path. Given an edge-weighted digraph, find a bitonic shortest path from s to every other vertex (if one exists). A path is bitonic if there is an intermediate vertex v such that the weighs of the edges on the path from s to v are strictly increasing and the weights of the edges on the path from v to t are strictly decreasing. The path should be simple (no repeated vertices). 4.4.36 Neighbors. Develop an SP client that finds all vertices within a given distance d of a given vertex in a given edge-weighted digraph.The running time of your method should be proportional to the size of the subgraph induced by those vertices and the vertices incident on them, or V (to initialize data structures), whichever is larger.</p><p attribs="{'xml:space': 'preserve'}" id="_11782" smilref="Title.smil#_11782" /><pagenum id="p703" page="normal" smilref="Title.smil#p703" /><p attribs="{'xml:space': 'preserve'}" id="_11783" smilref="Title.smil#_11783"> 690</p><p attribs="{'xml:space': 'preserve'}" id="_11784" smilref="Title.smil#_11784"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11785" smilref="Title.smil#_11785"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_11786" smilref="Title.smil#_11786"> 4.4.37 Critical edges. Develop an algorithm for finding an edge whose removal causes maximal increase in the shortest-paths length from one given vertex to another given vertex in a given edge-weighted digraph. 4.4.38 Sensitivity. Develop an SP client that performs a sensitivity analysis on the edge-weighted digraph&#8217;s edges with respect to a given pair of vertices s and t: Compute a V-by-V boolean matrix such that, for every v and w, the entry in row v and column w is true if v-&gt;w is an edge in the edge-weighted digraphs whose weight can be increased without the shortest-path length from v to w being increased and is false otherwise. 4.4.39 Lazy implementation of Dijkstra&#8217;s algorithm. Develop an implementation of the lazy version of Dijkstra&#8217;s algorithm that is described in the text. 4.4.40 Bottleneck SPT. Show that an MST of an undirected graph is equivalent to a bottleneck SPT of the graph: For every pair of vertices v and w, it gives the path connecting them whose longest edge is as short as possible. 4.4.41 Bidirectional search. Develop a class for the source-sink shortest-paths problem that is based on code like Algorithm 4.9 but that initializes the priority queue with both the source and the sink. Doing so leads to the growth of an SPT from each vertex; your main task is to decide precisely what to do when the two SPTs collide. 4.4.42 Worst case (Dijkstra). Describe a family of graphs with V vertices and E edges for which the worst-case running time of Dijkstra&#8217;s algorithm is achieved. 4.4.43 Negative cycle detection. Suppose that we add a constructor to Algorithm 4.11 that differs from the constructor given only in that it omits the second argument and that it initializes all distTo[] entries to 0. Show that, if a client uses that constructor, a client call to hasNegativeCycle() returns true if and only if the graph has a negative cycle (and negativeCycle() returns that cycle).</p><p attribs="{'xml:space': 'preserve'}" id="_11787" smilref="Title.smil#_11787"> Answer : Consider a digraph formed from the original by adding a new source with an edge of weight 0 to all the other vertices. After one pass, all distTo[] entries are 0, and finding a negative cycle reachable from that source is the same as finding a negative cycle anywhere in the original graph. 4.4.44 Worst case (Bellman-Ford). Describe a family of graphs for which Algorithm 4.11 takes time proportional to VE.</p><p attribs="{'xml:space': 'preserve'}" id="_11788" smilref="Title.smil#_11788" /><pagenum id="p704" page="normal" smilref="Title.smil#p704" /><p attribs="{'xml:space': 'preserve'}" id="_11789" smilref="Title.smil#_11789"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11790" smilref="Title.smil#_11790"> 691</p><p attribs="{'xml:space': 'preserve'}" id="_11791" smilref="Title.smil#_11791"> 4.4.45 Fast Bellman-Ford. Develop an algorithm that breaks the linearithmic running time barrier for the single-source shortest-paths problem in general edge-weighted digraphs for the special case where the weights are integers known to be bounded in absolute value by a constant. 4.4.46 Animate. Write a client program that does dynamic graphical animations of Dijkstra&#8217;s algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_11792" smilref="Title.smil#_11792" /><pagenum id="p705" page="normal" smilref="Title.smil#p705" /><p attribs="{'xml:space': 'preserve'}" id="_11793" smilref="Title.smil#_11793"> 692</p><p attribs="{'xml:space': 'preserve'}" id="_11794" smilref="Title.smil#_11794"> CHAPTER 4 </p><p attribs="{'xml:space': 'preserve'}" id="_11795" smilref="Title.smil#_11795"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_11796" smilref="Title.smil#_11796"> 4.4.47 Random sparse edge-weighted digraphs. Modify your solution to Exercise 4.3.34 to assign a random direction to each edge. 4.4.48 Random Euclidean edge-weighted digraphs. Modify your solution to Exercise 4.3.35 to assign a random direction to each edge. 4.4.49 Random grid edge-weighted digraphs. Modify your solution to Exercise 4.3.36 to assign a random direction to each edge. 4.4.50 Negative weights I. Modify your random edge-weighted digraph generators to generate weights between x and y (where x and y are both between &#11002;1 and 1) by rescaling. 4.4.51 Negative weights II. Modify your random edge-weighted digraph generators to generate negative weights by negating a fixed percentage (whose value is supplied by the client) of the edge weights. 4.4.52 Negative weights III. Develop client programs that use your edge-weighted digraph to produce edge-weighted digraphs that have a large percentage of negative weights but have at most a few negative cycles, for as large a range of values of V and E as possible.</p><p attribs="{'xml:space': 'preserve'}" id="_11797" smilref="Title.smil#_11797" /><pagenum id="p706" page="normal" smilref="Title.smil#p706" /><p attribs="{'xml:space': 'preserve'}" id="_11798" smilref="Title.smil#_11798"> 4.4 </p><p attribs="{'xml:space': 'preserve'}" id="_11799" smilref="Title.smil#_11799"> 693</p><p attribs="{'xml:space': 'preserve'}" id="_11800" smilref="Title.smil#_11800"> Testing all algorithms and studying all parameters against all edge-weighted digraph models is unrealistic. For each problem listed below, write a client that addresses the problem for any given input digraph, then choose among the generators above to run experiments for that graph model. Use your judgment in selecting experiments, perhaps in response to results of previous experiments. Write a narrative explaining your results and any conclusions that might be drawn.</p><p attribs="{'xml:space': 'preserve'}" id="_11801" smilref="Title.smil#_11801"> 4.4.53 Prediction. Estimate, to within a factor of 10, the largest graph with E = 10V that your computer and programming system could handle if you were to use Dijkstra&#8217;s algorithm to compute all its shortest paths in 10 seconds. 4.4.54 Cost of laziness. Run empirical studies to compare the performance of the lazy version of Dijkstra&#8217;s algorithm with the eager version, for various edge-weighted digraph models. 4.4.55 Johnson&#8217;s algorithm. Develop a priority-queue implementation that uses a d- way heap. Find the best value of d for various edge-weighted digraph models. 4.4.56 Arbitrage model. Develop a model for generating random arbitrage problems. Your goal is to generate tables that are as similar as possible to the tables that you used</p><p attribs="{'xml:space': 'preserve'}" id="_11802" smilref="Title.smil#_11802"> in Exercise 4.4.20.</p><p attribs="{'xml:space': 'preserve'}" id="_11803" smilref="Title.smil#_11803"> 4.4.57 Parallel job-scheduling-with-deadlines model. Develop a model for generating random instances of the parallel job-scheduling-with-deadlines problem. Your goal is to generate nontrivial problems that are likely to be feasible.</p><p attribs="{'xml:space': 'preserve'}" id="_11804" smilref="Title.smil#_11804" /></level3></level1><level1 id="ch5"><section epub:type="chapter" id="section_00004"><header id="header_00004"><pagenum epub:type="pagebreak" id="p707" page="normal" smilref="Title.smil#p707" /><h1 id="ch5-start" smilref="Title.smil#ch5-start" xml:space="preserve">5 Strings</h1></header></section><pagenum id="p707" page="normal" smilref="Title.smil#p707" /><p attribs="{'xml:space': 'preserve'}" id="_11805" smilref="Title.smil#_11805"> F I V E</p><p attribs="{'xml:space': 'preserve'}" id="_11806" smilref="Title.smil#_11806"> Strings</p><p attribs="{'xml:space': 'preserve'}" id="_11807" smilref="Title.smil#_11807"> String Sorts . . . . . . . . . . . . . . . . 702</p><p attribs="{'xml:space': 'preserve'}" id="_11808" smilref="Title.smil#_11808"> Substring Search . . . . . . . . . . . . . 758</p><p attribs="{'xml:space': 'preserve'}" id="_11809" smilref="Title.smil#_11809"> Tries . . . . . . . . . . . . . . . . . . . . . 730</p><p attribs="{'xml:space': 'preserve'}" id="_11810" smilref="Title.smil#_11810"> 5.1 5.2 5.3 5.4 Regular Expressions . . . . . . . . . . . 788 5.5 Data Compression . . . . . . . . . . . . 810</p><p attribs="{'xml:space': 'preserve'}" id="_11811" smilref="Title.smil#_11811" /><pagenum id="p708" page="normal" smilref="Title.smil#p708" /><p attribs="{'xml:space': 'preserve'}" id="_11812" smilref="Title.smil#_11812"> We communicate by exchanging strings of characters. Accordingly, numerous important and familiar applications are based on processing strings. In this chapter, we consider classic algorithms for addressing the underlying computational challenges surrounding applications such as the following: Information processing. When you search for web pages containing a given keyword, you are using a string-processing application. In the modern world, virtually all information is encoded as a sequence of strings, and the applications that process it are string-processing applications of crucial importance. Genomics. Computational biologists work with a genetic code that reduces DNA to (very long) strings formed from four characters (A, C, T, and G). Vast databases giving codes describing all manner of living organisms have been developed in recent years, so that string processing is a cornerstone of modern research in computational biology. Communications systems. When you send a text message or an email or download an ebook, you are transmitting a string from one place to another. Applications that process strings for this purpose were an original motivation for the development of string-processing algorithms. Programming systems. Programs are strings. Compilers, interpreters, and other applications that convert programs into machine instructions are critical applications that use sophisticated string-processing techniques. Indeed, all written languages are expressed as strings, and another motivation for the development of string-processing algorithms was the theory of formal languages, the study of describing sets of strings.</p><p attribs="{'xml:space': 'preserve'}" id="_11813" smilref="Title.smil#_11813"> This list of a few significant examples illustrates the diversity and importance of string- processing algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_11814" smilref="Title.smil#_11814"> 695</p><p attribs="{'xml:space': 'preserve'}" id="_11815" smilref="Title.smil#_11815" /><pagenum id="p709" page="normal" smilref="Title.smil#p709" /><p attribs="{'xml:space': 'preserve'}" id="_11816" smilref="Title.smil#_11816"> 696</p><p attribs="{'xml:space': 'preserve'}" id="_11817" smilref="Title.smil#_11817"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11818" smilref="Title.smil#_11818"> The plan of this chapter is as follows: After addressing basic properties of strings, we revisit in Sections 5.1 and 5.2 the sorting and search ing APIs from Chapters 2 and 3. Algorithms that exploit special properties of string keys are faster and more flexible than the algorithms that we considered earlier. In Section 5.3 we consider algorithms for substring search, including a famous algorithm due to Knuth, Morris, and Pratt. In Section 5.4 we introduce regular expressions, the basis of the pattern-matching problem, a generalization of substring search, and a quintes sential search tool known as grep. These classic algorithms are based on the related con ceptual devices known as formal languages and finite automata. Section 5.5 is devoted to a central application: data compression, where we try to reduce the size of a string as much as possible.</p><p attribs="{'xml:space': 'preserve'}" id="_11819" smilref="Title.smil#_11819"> Rules of the game For clarity and ef&#64257; ciency, our implementations are expressed in terms of the Java String class, but we intentionally use as few operations as possible from that class to make it easier to adapt our algorithms for use on other string-like types of data and to other programming languages. We introduced strings in detail in Section 1.2 but briefly review here their most important characteristics. Characters. A String is a sequence of characters. Characters are of type char and can have one of 216 possible values. For many decades, programmers restricted attention to characters encoded in 7-bit ASCII (see page 815 for a conversion table) or 8-bit extended ASCII, but many modern applications call for 16-bit Unicode.</p><p attribs="{'xml:space': 'preserve'}" id="_11820" smilref="Title.smil#_11820"> Immutability. String objects are immutable, so that we can use them in assignment statements and as arguments and return values from methods without having to worry about their values changing.</p><p attribs="{'xml:space': 'preserve'}" id="_11821" smilref="Title.smil#_11821"> Indexing. The operation that we perform most often is extract a specified character from a string that the charAt() method in Java&#8217;s String class provides. We expect charAt() to complete its work in constant time, as if the string were stored in a char[] array. As discussed in Chapter 1, this expectation is quite reasonable. Length. In Java, the find the length of a string operation is implemented in the length() method in String. Again, we expect length() to complete its work in constant time, and again, this expectation is reasonable, although some care is needed in some programming environments.</p><p attribs="{'xml:space': 'preserve'}" id="_11822" smilref="Title.smil#_11822"> Substring. Java&#8217;s substring() method implements the extract a specified substring op- eration. Again, we expect a constant-time implementation of this method, as in Java&#8217;s standard implementation. If you are not familiar with substring() and the reason that it is constant-time, be sure to reread our discussion of Java&#8217;s standard string implementation in Section 1.2 (see page 80 and page 204).</p><p attribs="{'xml:space': 'preserve'}" id="_11823" smilref="Title.smil#_11823" /><pagenum id="p710" page="normal" smilref="Title.smil#p710" /><p attribs="{'xml:space': 'preserve'}" id="_11824" smilref="Title.smil#_11824"> Concatenation. In Java, the create a new string formed by appending one string to another operation is a built-in operation (using the + operator) that takes time proportional to the length of the result. For example, we avoid forming a string by appending one character at a time because that is a quadratic process in Java. ( Java has a StringBuilder class for that use.)</p><p attribs="{'xml:space': 'preserve'}" id="_11825" smilref="Title.smil#_11825"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11826" smilref="Title.smil#_11826"> 697</p><p attribs="{'xml:space': 'preserve'}" id="_11827" smilref="Title.smil#_11827"> s.length()</p><p attribs="{'xml:space': 'preserve'}" id="_11828" smilref="Title.smil#_11828"> 0 1 2 3 4 5 6 7 8 9 10 11 12 A T T A C K A T D A W N</p><p attribs="{'xml:space': 'preserve'}" id="_11829" smilref="Title.smil#_11829"> s</p><p attribs="{'xml:space': 'preserve'}" id="_11830" smilref="Title.smil#_11830"> s.charAt(3)</p><p attribs="{'xml:space': 'preserve'}" id="_11831" smilref="Title.smil#_11831"> s.substring(7, 11)</p><p attribs="{'xml:space': 'preserve'}" id="_11832" smilref="Title.smil#_11832"> Fundamental constant-time String operations</p><p attribs="{'xml:space': 'preserve'}" id="_11833" smilref="Title.smil#_11833"> Character arrays. The Java String is decidedly not a primitive type. The standard implementation provides the operations just described to facilitate client program- ming. By contrast, many of the algorithms that we consider can work with a low-level representation such as an array of char values, and many clients might prefer such a representation, because it consumes less space and takes less time. For several of the algorithms that we consider, the cost of converting from one representation to the other would be higher than the cost of running the algorithm. As indicated in the table below, the differences in code that processes the two representations are minor (substring() is more complicated and is omitted), so use of one representation or the other is no barrier to understanding the algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_11834" smilref="Title.smil#_11834"> Understanding the efficiency of these operations is a key ingredient in under-</p><p attribs="{'xml:space': 'preserve'}" id="_11835" smilref="Title.smil#_11835"> standing the efficiency of several string-processing algorithms. Not all programming languages provide String implementations with these performance characteristics. For example, the substring operation and determining the length of a string take time proportional to the number of characters in the string in the widely used C programming language. Adapting the algorithms that we describe to such languages is always possible (implement an ADT like Java&#8217;s String), but also might present different challenges and opportunities.</p><p attribs="{'xml:space': 'preserve'}" id="_11836" smilref="Title.smil#_11836"> operation</p><p attribs="{'xml:space': 'preserve'}" id="_11837" smilref="Title.smil#_11837"> declare</p><p attribs="{'xml:space': 'preserve'}" id="_11838" smilref="Title.smil#_11838"> indexed character access</p><p attribs="{'xml:space': 'preserve'}" id="_11839" smilref="Title.smil#_11839"> length convert</p><p attribs="{'xml:space': 'preserve'}" id="_11840" smilref="Title.smil#_11840"> array of characters</p><p attribs="{'xml:space': 'preserve'}" id="_11841" smilref="Title.smil#_11841"> char[] a</p><p attribs="{'xml:space': 'preserve'}" id="_11842" smilref="Title.smil#_11842"> a[i]</p><p attribs="{'xml:space': 'preserve'}" id="_11843" smilref="Title.smil#_11843"> a.length</p><p attribs="{'xml:space': 'preserve'}" id="_11844" smilref="Title.smil#_11844"> Java string</p><p attribs="{'xml:space': 'preserve'}" id="_11845" smilref="Title.smil#_11845"> String s</p><p attribs="{'xml:space': 'preserve'}" id="_11846" smilref="Title.smil#_11846"> s.charAt(i)</p><p attribs="{'xml:space': 'preserve'}" id="_11847" smilref="Title.smil#_11847"> s.length()</p><p attribs="{'xml:space': 'preserve'}" id="_11848" smilref="Title.smil#_11848"> a = s.toCharArray();</p><p attribs="{'xml:space': 'preserve'}" id="_11849" smilref="Title.smil#_11849"> s = new String(a);</p><p attribs="{'xml:space': 'preserve'}" id="_11850" smilref="Title.smil#_11850"> Two ways to represent strings in Java</p><p attribs="{'xml:space': 'preserve'}" id="_11851" smilref="Title.smil#_11851" /><pagenum id="p711" page="normal" smilref="Title.smil#p711" /><p attribs="{'xml:space': 'preserve'}" id="_11852" smilref="Title.smil#_11852"> 698</p><p attribs="{'xml:space': 'preserve'}" id="_11853" smilref="Title.smil#_11853"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11854" smilref="Title.smil#_11854"> We primarily use the String data type in the text, with liberal use of indexing and length and occasional use of substring extraction and concatenation. When appropri- ate, we also provide on the booksite the corresponding code for char arrays. In perfor- mance-critical applications, the primary consideration in choosing between the two for clients is often the cost of accessing a character (a[i] is likely to be much faster than s.charAt(i) in typical Java implementations).</p><p attribs="{'xml:space': 'preserve'}" id="_11855" smilref="Title.smil#_11855"> Alphabets Some applications involve strings taken from a restricted alphabet. In such applications, it often makes sense to use an Alphabet class with the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_11856" smilref="Title.smil#_11856"> public class Alphabet</p><p attribs="{'xml:space': 'preserve'}" id="_11857" smilref="Title.smil#_11857"> Alphabet(String s)</p><p attribs="{'xml:space': 'preserve'}" id="_11858" smilref="Title.smil#_11858"> char toChar(int index)</p><p attribs="{'xml:space': 'preserve'}" id="_11859" smilref="Title.smil#_11859"> int toIndex(char c) boolean contains(char c) int R() int lgR() int[] toIndices(String s) String toChars(int[] indices)</p><p attribs="{'xml:space': 'preserve'}" id="_11860" smilref="Title.smil#_11860"> create a new alphabet from chars in s convert index to corresponding alphabet char convert c to an index between 0 and R-1 is c in the alphabet? radix (number of characters in alphabet) number of bits to represent an index convert s to base-R integer convert base-R integer to string over this alphabet</p><p attribs="{'xml:space': 'preserve'}" id="_11861" smilref="Title.smil#_11861"> Alphabet API</p><p attribs="{'xml:space': 'preserve'}" id="_11862" smilref="Title.smil#_11862"> This API is based on a constructor that takes as argument an R-character string that specifies the alphabet and the toChar() and toIndex() methods for converting (in constant time) between string characters and int values between 0 and R-1. It also includes a contains() method for checking whether a given character is in the alpha- bet, the methods R() and lgR() for finding the number of characters in the alphabet and the number of bits needed to represent them, and the methods toIndices() and toChars() for converting between strings of characters in the alphabet and int arrays. For convenience, we also include the built-in alphabets in the table at the top of the next page, which you can access with code such as Alphabet.UNICODE. Implementing Alphabet is a straightforward exercise (see Exercise 5.1.12). We will examine a sample client on page 699.</p><p attribs="{'xml:space': 'preserve'}" id="_11863" smilref="Title.smil#_11863"> Character-indexed arrays. One of the most important reasons to use Alphabet is that many algorithms gain efficiency through the use of character-indexed arrays, where we associate information with each character that we can retrieve with a single array</p><p attribs="{'xml:space': 'preserve'}" id="_11864" smilref="Title.smil#_11864" /><pagenum id="p712" page="normal" smilref="Title.smil#p712" /><p attribs="{'xml:space': 'preserve'}" id="_11865" smilref="Title.smil#_11865"> name</p><p attribs="{'xml:space': 'preserve'}" id="_11866" smilref="Title.smil#_11866"> BINARY</p><p attribs="{'xml:space': 'preserve'}" id="_11867" smilref="Title.smil#_11867"> DNA</p><p attribs="{'xml:space': 'preserve'}" id="_11868" smilref="Title.smil#_11868"> OCTAL</p><p attribs="{'xml:space': 'preserve'}" id="_11869" smilref="Title.smil#_11869"> DECIMAL</p><p attribs="{'xml:space': 'preserve'}" id="_11870" smilref="Title.smil#_11870"> HEXADECIMAL</p><p attribs="{'xml:space': 'preserve'}" id="_11871" smilref="Title.smil#_11871"> PROTEIN</p><p attribs="{'xml:space': 'preserve'}" id="_11872" smilref="Title.smil#_11872"> LOWERCASE</p><p attribs="{'xml:space': 'preserve'}" id="_11873" smilref="Title.smil#_11873"> UPPERCASE</p><p attribs="{'xml:space': 'preserve'}" id="_11874" smilref="Title.smil#_11874"> BASE64</p><p attribs="{'xml:space': 'preserve'}" id="_11875" smilref="Title.smil#_11875"> ASCII</p><p attribs="{'xml:space': 'preserve'}" id="_11876" smilref="Title.smil#_11876"> EXTENDED_ASCII</p><p attribs="{'xml:space': 'preserve'}" id="_11877" smilref="Title.smil#_11877"> R()</p><p attribs="{'xml:space': 'preserve'}" id="_11878" smilref="Title.smil#_11878"> lgR()</p><p attribs="{'xml:space': 'preserve'}" id="_11879" smilref="Title.smil#_11879"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11880" smilref="Title.smil#_11880"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11881" smilref="Title.smil#_11881"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11882" smilref="Title.smil#_11882"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_11883" smilref="Title.smil#_11883"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_11884" smilref="Title.smil#_11884"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_11885" smilref="Title.smil#_11885"> 26</p><p attribs="{'xml:space': 'preserve'}" id="_11886" smilref="Title.smil#_11886"> 26</p><p attribs="{'xml:space': 'preserve'}" id="_11887" smilref="Title.smil#_11887"> 64</p><p attribs="{'xml:space': 'preserve'}" id="_11888" smilref="Title.smil#_11888"> 128</p><p attribs="{'xml:space': 'preserve'}" id="_11889" smilref="Title.smil#_11889"> 256</p><p attribs="{'xml:space': 'preserve'}" id="_11890" smilref="Title.smil#_11890"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_11891" smilref="Title.smil#_11891"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_11892" smilref="Title.smil#_11892"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_11893" smilref="Title.smil#_11893"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11894" smilref="Title.smil#_11894"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_11895" smilref="Title.smil#_11895"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11896" smilref="Title.smil#_11896"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11897" smilref="Title.smil#_11897"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_11898" smilref="Title.smil#_11898"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_11899" smilref="Title.smil#_11899"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_11900" smilref="Title.smil#_11900"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_11901" smilref="Title.smil#_11901"> UNICODE16</p><p attribs="{'xml:space': 'preserve'}" id="_11902" smilref="Title.smil#_11902"> 65536</p><p attribs="{'xml:space': 'preserve'}" id="_11903" smilref="Title.smil#_11903"> 16</p><p attribs="{'xml:space': 'preserve'}" id="_11904" smilref="Title.smil#_11904"> Standard alphabets</p><p attribs="{'xml:space': 'preserve'}" id="_11905" smilref="Title.smil#_11905"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11906" smilref="Title.smil#_11906"> 699</p><p attribs="{'xml:space': 'preserve'}" id="_11907" smilref="Title.smil#_11907"> characters</p><p attribs="{'xml:space': 'preserve'}" id="_11908" smilref="Title.smil#_11908"> 01</p><p attribs="{'xml:space': 'preserve'}" id="_11909" smilref="Title.smil#_11909"> ACTG</p><p attribs="{'xml:space': 'preserve'}" id="_11910" smilref="Title.smil#_11910"> 01234567</p><p attribs="{'xml:space': 'preserve'}" id="_11911" smilref="Title.smil#_11911"> 0123456789</p><p attribs="{'xml:space': 'preserve'}" id="_11912" smilref="Title.smil#_11912"> 0123456789ABCDEF</p><p attribs="{'xml:space': 'preserve'}" id="_11913" smilref="Title.smil#_11913"> ACDEFGHIKLMNPQRSTVWY</p><p attribs="{'xml:space': 'preserve'}" id="_11914" smilref="Title.smil#_11914"> abcdefghijklmnopqrstuvwxyz</p><p attribs="{'xml:space': 'preserve'}" id="_11915" smilref="Title.smil#_11915"> ABCDEFGHIJKLMNOPQRSTUVWXYZ</p><p attribs="{'xml:space': 'preserve'}" id="_11916" smilref="Title.smil#_11916"> ABCDEFGHIJKLMNOPQRSTUVWXYZabcdef ghijklmnopqrstuvwxyz0123456789+/</p><p attribs="{'xml:space': 'preserve'}" id="_11917" smilref="Title.smil#_11917"> ASCII characters extended ASCII characters Unicode characters</p><p attribs="{'xml:space': 'preserve'}" id="_11918" smilref="Title.smil#_11918"> public class Count { public static void main(String[] args) { Alphabet alpha = new Alphabet(args[0]); int R = alpha.R(); int[] count = new int[R];</p><p attribs="{'xml:space': 'preserve'}" id="_11919" smilref="Title.smil#_11919"> String s = StdIn.readAll(); int N = s.length(); for (int i = 0; i &lt; N; i++) if (alpha.contains(s.charAt(i))) count[alpha.toIndex(s.charAt(i))]++;</p><p attribs="{'xml:space': 'preserve'}" id="_11920" smilref="Title.smil#_11920"> for (int c = 0; c &lt; R; c++) StdOut.println(alpha.toChar(c) + " " + count[c]);</p><p attribs="{'xml:space': 'preserve'}" id="_11921" smilref="Title.smil#_11921"> } }</p><p attribs="{'xml:space': 'preserve'}" id="_11922" smilref="Title.smil#_11922"> Typical Alphabet client</p><p attribs="{'xml:space': 'preserve'}" id="_11923" smilref="Title.smil#_11923"> % more abra.txt ABRACADABRA!</p><p attribs="{'xml:space': 'preserve'}" id="_11924" smilref="Title.smil#_11924"> % java Count ABCDR &lt; abra.txt A 5 B 2 C 1 D 1 R 2</p><p attribs="{'xml:space': 'preserve'}" id="_11925" smilref="Title.smil#_11925" /><pagenum id="p713" page="normal" smilref="Title.smil#p713" /><p attribs="{'xml:space': 'preserve'}" id="_11926" smilref="Title.smil#_11926"> 700</p><p attribs="{'xml:space': 'preserve'}" id="_11927" smilref="Title.smil#_11927"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11928" smilref="Title.smil#_11928"> access. With a Java String, we have to use an array of size 65,536; with Alphabet, we just need an array with one entry for each alphabet character. Some of the algorithms that we consider can produce huge numbers of such arrays, and in such cases, the space for arrays of size 65,536 can be prohibitive. As an example, consider the class Count at the bottom of the previous page, which takes a string of characters from the command line and prints a table of the frequency of occurrence of those characters that appear on standard input. The count[] array that holds the frequencies in Count is an example of a character-indexed array. This calculation may seem to you to be a bit frivolous; actu- ally, it is the basis for a family of fast sorting methods that we will consider in Section</p><p attribs="{'xml:space': 'preserve'}" id="_11929" smilref="Title.smil#_11929"> 5.1.</p><p attribs="{'xml:space': 'preserve'}" id="_11930" smilref="Title.smil#_11930"> Numbers. As you can see from several of the standard Alphabet examples, we often represent numbers as strings. The method toIndices() converts any String over a given Alphabet into a base-R number represented as an int[] array with all values between 0 and R&#11002;1. In some situations, doing this conversion at the start leads to compact code, because any digit can be used as an index in a character-indexed array. For example, if we know that the input consists only of characters from the alphabet, we could replace the inner loop in Count with the more compact code</p><p attribs="{'xml:space': 'preserve'}" id="_11931" smilref="Title.smil#_11931"> int[] a = alpha.toIndices(s); for (int i = 0; i &lt; N; i++) count[a[i]]++;</p><p attribs="{'xml:space': 'preserve'}" id="_11932" smilref="Title.smil#_11932"> In this context, we refer to R as the radix, the base of the number system. Several of the algorithms that we consider are often referred to as &#8220;radix&#8221; methods because they work with one digit at a time.</p><p attribs="{'xml:space': 'preserve'}" id="_11933" smilref="Title.smil#_11933"> % more pi.txt 3141592653 5897932384 6264338327 9502884197 ... [100,000 digits of pi]</p><p attribs="{'xml:space': 'preserve'}" id="_11934" smilref="Title.smil#_11934"> % java Count 0123456789 &lt; pi.txt 0 9999 1 10137 2 9908 3 10026 4 9971 5 10026 6 10028 7 10025 8 9978 9 9902</p><p attribs="{'xml:space': 'preserve'}" id="_11935" smilref="Title.smil#_11935" /><pagenum id="p714" page="normal" smilref="Title.smil#p714" /><p attribs="{'xml:space': 'preserve'}" id="_11936" smilref="Title.smil#_11936"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11937" smilref="Title.smil#_11937"> 701</p><p attribs="{'xml:space': 'preserve'}" id="_11938" smilref="Title.smil#_11938"> Despite the advantages of using a data type such as Alphabet in string-processing algorithms (particularly for small alphabets), we do not develop our implementations in the book for strings taken from a general Alphabet because </p><p attribs="{'xml:space': 'preserve'}" id="_11939" smilref="Title.smil#_11939" /><level3 id="_00097"><h3 id="ch5-s1-ss1" smilref="Title.smil#ch5-s1-ss1" xml:space="preserve">Key-indexed counting</h3><pagenum id="p716" page="normal" smilref="Title.smil#p716" /><p attribs="{'xml:space': 'preserve'}" id="_11940" smilref="Title.smil#_11940"> Key-indexed counting As a warmup, we consider a simple method for sorting that is effective whenever the keys are small integers. This method, known as key-indexed counting, is useful in its own right and is also the basis for two of the three string sorts that we consider in this section. Consider the following data-processing problem, which might be faced by a teacher maintaining grades for a class with students assigned to sections, which are numbered 1, 2, 3, and so forth. On some occasions, it is necessary to have the class listed by section. Since the section numbers are small integers, sorting by key-indexed counting is appropriate. To describe the method, we assume that the information is kept in an array a[] of items that each contain a name and a section number, that section numbers are integers between 0 and R-1, and that the code a[i].key() returns the section number for the indicated student. The method breaks down into four steps, which we describe in turn.</p><p attribs="{'xml:space': 'preserve'}" id="_11941" smilref="Title.smil#_11941"> for (i = 0; i &lt; N; i++) count[a[i].key() + 1]++;</p><p attribs="{'xml:space': 'preserve'}" id="_11942" smilref="Title.smil#_11942"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_11943" smilref="Title.smil#_11943"> 703</p><p attribs="{'xml:space': 'preserve'}" id="_11944" smilref="Title.smil#_11944"> input name</p><p attribs="{'xml:space': 'preserve'}" id="_11945" smilref="Title.smil#_11945"> section</p><p attribs="{'xml:space': 'preserve'}" id="_11946" smilref="Title.smil#_11946"> sorted result (by section)</p><p attribs="{'xml:space': 'preserve'}" id="_11947" smilref="Title.smil#_11947"> Anderson 2 Harris 1 Brown 3 Martin 1 Davis 3 Moore 1 Garcia 4 Anderson 2 Harris 1 Martinez 2 Jackson 3 Miller 2 Johnson 4 Robinson 2 Jones 3 White 2 Martin 1 Brown 3 Martinez 2 Davis 3 Miller 2 Jackson 3 Moore 1 Jones 3 Robinson 2 Taylor 3 Smith 4 Williams 3 Taylor 3 Garcia 4 Thomas 4 Johnson 4 Thompson 4 Smith 4 White 2 Thomas 4 Williams 3 Thompson 4 Wilson 4 Wilson 4</p><p attribs="{'xml:space': 'preserve'}" id="_11948" smilref="Title.smil#_11948"> keys are small integers</p><p attribs="{'xml:space': 'preserve'}" id="_11949" smilref="Title.smil#_11949"> Typical candidate for key-indexed counting</p><p attribs="{'xml:space': 'preserve'}" id="_11950" smilref="Title.smil#_11950"> Compute frequency counts. The first step is to count the frequency of occurrence of each key value, using an int array count[]. For each item, we use the key to access an entry in count[] and increment that entry. If the key value is r, we increment count[r+1]. (Why +1? The reason for that will become clear in the next step.) In the example at left, we first increment count[3] because Anderson is in section 2, then we increment count[4] twice because Brown and Davis are in section 3, and so forth. Note that count[0] is always 0, and that count[1] is 0 in this example (no students are in section 0).</p><p attribs="{'xml:space': 'preserve'}" id="_11951" smilref="Title.smil#_11951"> always 0</p><p attribs="{'xml:space': 'preserve'}" id="_11952" smilref="Title.smil#_11952"> count[] 0 1 2 3 4 5 0 0 0 0 0 0 Anderson 2 0 0 0 1 0 0 Brown 3 0 0 0 1 1 0 Davis 3 0 0 0 1 2 0 Garcia 4 0 0 0 1 2 1 Harris 1 0 0 1 1 2 1 Jackson 3 0 0 1 1 3 1 Johnson 4 0 0 1 1 3 2 Jones 3 0 0 1 1 4 2 Martin 1 0 0 2 1 4 2 Martinez 2 0 0 2 2 4 2 Miller 2 0 0 2 3 4 2 Moore 1 0 0 3 3 4 2 Robinson 2 0 0 3 4 4 2 Smith 4 0 0 3 4 4 3 Taylor 3 0 0 3 4 5 3 Thomas 4 0 0 3 4 5 4 Thompson 4 0 0 3 4 5 5 White 2 0 0 3 5 5 5 Williams 3 0 0 3 5 6 5 Wilson 4 0 0 3 5 6 6</p><p attribs="{'xml:space': 'preserve'}" id="_11953" smilref="Title.smil#_11953"> number of 3s</p><p attribs="{'xml:space': 'preserve'}" id="_11954" smilref="Title.smil#_11954"> Computing frequency counts</p><p attribs="{'xml:space': 'preserve'}" id="_11955" smilref="Title.smil#_11955" /><pagenum id="p717" page="normal" smilref="Title.smil#p717" /><p attribs="{'xml:space': 'preserve'}" id="_11956" smilref="Title.smil#_11956"> 704</p><p attribs="{'xml:space': 'preserve'}" id="_11957" smilref="Title.smil#_11957"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_11958" smilref="Title.smil#_11958"> Transform counts to indices. Next, we use count[]</p><p attribs="{'xml:space': 'preserve'}" id="_11959" smilref="Title.smil#_11959"> to compute, for each key value, the starting index positions in the sorted order of items with that key. In our example, since there are three items with key 1 and five items with key 2, then the items with key 3 start at position 8 in the sorted array. In general, to get the starting index for items with any given key value we sum the frequency counts of smaller val- ues. For each key value r, the sum of the counts for key values less than r+1 is equal to the sum of the counts for key values less than r plus count[r], so it is easy to proceed from left to right to transform count[] into an index table that we can use to sort the data.</p><p attribs="{'xml:space': 'preserve'}" id="_11960" smilref="Title.smil#_11960"> for (int r = 0; r &lt; R; r++) count[r+1] += count[r];</p><p attribs="{'xml:space': 'preserve'}" id="_11961" smilref="Title.smil#_11961"> always 0</p><p attribs="{'xml:space': 'preserve'}" id="_11962" smilref="Title.smil#_11962"> r 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_11963" smilref="Title.smil#_11963"> count[] 0 1 2 3 4 5 0 0 3 5 6 6 0 0 3 5 6 6 0 0 3 5 6 6 0 0 3 8 6 6 0 0 3 8 14 6 0 0 3 8 14 20 0 0 3 8 14 20</p><p attribs="{'xml:space': 'preserve'}" id="_11964" smilref="Title.smil#_11964"> number of keys less than 3 (start index of 3s in output)</p><p attribs="{'xml:space': 'preserve'}" id="_11965" smilref="Title.smil#_11965"> Transforming counts to start indices</p><p attribs="{'xml:space': 'preserve'}" id="_11966" smilref="Title.smil#_11966"> for (int i = 0; i &lt; N; i++) aux[count[a[i].key()]++] = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_11967" smilref="Title.smil#_11967"> i 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</p><p attribs="{'xml:space': 'preserve'}" id="_11968" smilref="Title.smil#_11968"> count[] 1 2 3 4 0 3 8 14 0 4 8 14 0 4 9 14 0 4 10 14 0 4 10 15 1 4 10 15 1 4 11 15 1 4 11 16 1 4 12 16 2 4 12 16 2 5 12 16 2 6 12 16 3 6 12 16 3 7 12 16 3 7 12 17 3 7 13 17 3 7 13 18 3 7 13 19 3 8 13 19 3 8 14 19 3 8 14 20 3 8 14 20</p><p attribs="{'xml:space': 'preserve'}" id="_11969" smilref="Title.smil#_11969"> a[0]</p><p attribs="{'xml:space': 'preserve'}" id="_11970" smilref="Title.smil#_11970"> a[1]</p><p attribs="{'xml:space': 'preserve'}" id="_11971" smilref="Title.smil#_11971"> a[2]</p><p attribs="{'xml:space': 'preserve'}" id="_11972" smilref="Title.smil#_11972"> a[3]</p><p attribs="{'xml:space': 'preserve'}" id="_11973" smilref="Title.smil#_11973"> a[4]</p><p attribs="{'xml:space': 'preserve'}" id="_11974" smilref="Title.smil#_11974"> a[5]</p><p attribs="{'xml:space': 'preserve'}" id="_11975" smilref="Title.smil#_11975"> a[6]</p><p attribs="{'xml:space': 'preserve'}" id="_11976" smilref="Title.smil#_11976"> a[7]</p><p attribs="{'xml:space': 'preserve'}" id="_11977" smilref="Title.smil#_11977"> a[8]</p><p attribs="{'xml:space': 'preserve'}" id="_11978" smilref="Title.smil#_11978"> a[9]</p><p attribs="{'xml:space': 'preserve'}" id="_11979" smilref="Title.smil#_11979"> a[10]</p><p attribs="{'xml:space': 'preserve'}" id="_11980" smilref="Title.smil#_11980"> a[11]</p><p attribs="{'xml:space': 'preserve'}" id="_11981" smilref="Title.smil#_11981"> a[12]</p><p attribs="{'xml:space': 'preserve'}" id="_11982" smilref="Title.smil#_11982"> a[13]</p><p attribs="{'xml:space': 'preserve'}" id="_11983" smilref="Title.smil#_11983"> a[14]</p><p attribs="{'xml:space': 'preserve'}" id="_11984" smilref="Title.smil#_11984"> a[15]</p><p attribs="{'xml:space': 'preserve'}" id="_11985" smilref="Title.smil#_11985"> a[16]</p><p attribs="{'xml:space': 'preserve'}" id="_11986" smilref="Title.smil#_11986"> a[17]</p><p attribs="{'xml:space': 'preserve'}" id="_11987" smilref="Title.smil#_11987"> a[18]</p><p attribs="{'xml:space': 'preserve'}" id="_11988" smilref="Title.smil#_11988"> a[19]</p><p attribs="{'xml:space': 'preserve'}" id="_11989" smilref="Title.smil#_11989"> Anderson 2 Harris 1 Brown 3 Martin 1 Davis 3 Moore 1 Garcia 4 Anderson 2 Harris 1 Martinez 2 Jackson 3 Miller 2 Johnson 4 Robinson 2 Jones 3 White 2 Martin 1 Brown 3 Martinez 2 Davis 3 Miller 2 Jackson 3 Moore 1 Jones 3 Robinson 2 Taylor 3 Smith 4 Williams 3 Taylor 3 Garcia 4 Thomas 4 Johnson 4 Thompson 4 Smith 4 White 2 Thomas 4 Williams 3 Thompson 4 Wilson 4 Wilson 4</p><p attribs="{'xml:space': 'preserve'}" id="_11990" smilref="Title.smil#_11990"> aux[0]</p><p attribs="{'xml:space': 'preserve'}" id="_11991" smilref="Title.smil#_11991"> aux[1]</p><p attribs="{'xml:space': 'preserve'}" id="_11992" smilref="Title.smil#_11992"> aux[2]</p><p attribs="{'xml:space': 'preserve'}" id="_11993" smilref="Title.smil#_11993"> aux[3]</p><p attribs="{'xml:space': 'preserve'}" id="_11994" smilref="Title.smil#_11994"> aux[4]</p><p attribs="{'xml:space': 'preserve'}" id="_11995" smilref="Title.smil#_11995"> aux[5]</p><p attribs="{'xml:space': 'preserve'}" id="_11996" smilref="Title.smil#_11996"> aux[6]</p><p attribs="{'xml:space': 'preserve'}" id="_11997" smilref="Title.smil#_11997"> aux[7]</p><p attribs="{'xml:space': 'preserve'}" id="_11998" smilref="Title.smil#_11998"> aux[8]</p><p attribs="{'xml:space': 'preserve'}" id="_11999" smilref="Title.smil#_11999"> aux[9]</p><p attribs="{'xml:space': 'preserve'}" id="_12000" smilref="Title.smil#_12000"> aux[10]</p><p attribs="{'xml:space': 'preserve'}" id="_12001" smilref="Title.smil#_12001"> aux[11]</p><p attribs="{'xml:space': 'preserve'}" id="_12002" smilref="Title.smil#_12002"> aux[12]</p><p attribs="{'xml:space': 'preserve'}" id="_12003" smilref="Title.smil#_12003"> aux[13]</p><p attribs="{'xml:space': 'preserve'}" id="_12004" smilref="Title.smil#_12004"> aux[14]</p><p attribs="{'xml:space': 'preserve'}" id="_12005" smilref="Title.smil#_12005"> aux[15]</p><p attribs="{'xml:space': 'preserve'}" id="_12006" smilref="Title.smil#_12006"> aux[16]</p><p attribs="{'xml:space': 'preserve'}" id="_12007" smilref="Title.smil#_12007"> aux[17]</p><p attribs="{'xml:space': 'preserve'}" id="_12008" smilref="Title.smil#_12008"> aux[18]</p><p attribs="{'xml:space': 'preserve'}" id="_12009" smilref="Title.smil#_12009"> aux[19]</p><p attribs="{'xml:space': 'preserve'}" id="_12010" smilref="Title.smil#_12010"> Distributing the data (records with key 3 highlighted)</p><p attribs="{'xml:space': 'preserve'}" id="_12011" smilref="Title.smil#_12011"> Distribute the data. With the</p><p attribs="{'xml:space': 'preserve'}" id="_12012" smilref="Title.smil#_12012"> count[] array transformed into an index table, we accomplish the actual sort by moving the items to an auxiliary array aux[]. We move each item to the position in aux[] indicated by the count[] entry corresponding to its key, and then increment that entry to maintain the following invariant for count[]: for each key value r, count[r] is the index of the position in aux[] where the next item with key value r (if any) should be placed. This process produces a sorted result with one pass through the data, as illustrated at left. Note : In one of our applications, the fact that this implementation is stable is critical: items with equal keys are brought together but kept in the same relative order.</p><p attribs="{'xml:space': 'preserve'}" id="_12013" smilref="Title.smil#_12013" /><pagenum id="p718" page="normal" smilref="Title.smil#p718" /><p attribs="{'xml:space': 'preserve'}" id="_12014" smilref="Title.smil#_12014"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12015" smilref="Title.smil#_12015"> 705</p><p attribs="{'xml:space': 'preserve'}" id="_12016" smilref="Title.smil#_12016"> before</p><p attribs="{'xml:space': 'preserve'}" id="_12017" smilref="Title.smil#_12017"> aux[]</p><p attribs="{'xml:space': 'preserve'}" id="_12018" smilref="Title.smil#_12018"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12019" smilref="Title.smil#_12019"> count[0]</p><p attribs="{'xml:space': 'preserve'}" id="_12020" smilref="Title.smil#_12020"> count[1]</p><p attribs="{'xml:space': 'preserve'}" id="_12021" smilref="Title.smil#_12021"> count[2]</p><p attribs="{'xml:space': 'preserve'}" id="_12022" smilref="Title.smil#_12022"> count[R-1]</p><p attribs="{'xml:space': 'preserve'}" id="_12023" smilref="Title.smil#_12023"> during</p><p attribs="{'xml:space': 'preserve'}" id="_12024" smilref="Title.smil#_12024"> aux[]</p><p attribs="{'xml:space': 'preserve'}" id="_12025" smilref="Title.smil#_12025"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12026" smilref="Title.smil#_12026"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12027" smilref="Title.smil#_12027"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12028" smilref="Title.smil#_12028"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12029" smilref="Title.smil#_12029"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12030" smilref="Title.smil#_12030"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12031" smilref="Title.smil#_12031"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12032" smilref="Title.smil#_12032"> R-1 R-1 R-1</p><p attribs="{'xml:space': 'preserve'}" id="_12033" smilref="Title.smil#_12033"> count[0]</p><p attribs="{'xml:space': 'preserve'}" id="_12034" smilref="Title.smil#_12034"> count[1]</p><p attribs="{'xml:space': 'preserve'}" id="_12035" smilref="Title.smil#_12035"> count[2]</p><p attribs="{'xml:space': 'preserve'}" id="_12036" smilref="Title.smil#_12036"> count[R-1]</p><p attribs="{'xml:space': 'preserve'}" id="_12037" smilref="Title.smil#_12037"> after</p><p attribs="{'xml:space': 'preserve'}" id="_12038" smilref="Title.smil#_12038"> aux[]</p><p attribs="{'xml:space': 'preserve'}" id="_12039" smilref="Title.smil#_12039"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12040" smilref="Title.smil#_12040"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_12041" smilref="Title.smil#_12041"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12042" smilref="Title.smil#_12042"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12043" smilref="Title.smil#_12043"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12044" smilref="Title.smil#_12044"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12045" smilref="Title.smil#_12045"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_12046" smilref="Title.smil#_12046"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12047" smilref="Title.smil#_12047"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12048" smilref="Title.smil#_12048"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12049" smilref="Title.smil#_12049"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_12050" smilref="Title.smil#_12050"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12051" smilref="Title.smil#_12051"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12052" smilref="Title.smil#_12052"> R-1 R-1 R-1</p><p attribs="{'xml:space': 'preserve'}" id="_12053" smilref="Title.smil#_12053"> R-1</p><p attribs="{'xml:space': 'preserve'}" id="_12054" smilref="Title.smil#_12054"> count[0]</p><p attribs="{'xml:space': 'preserve'}" id="_12055" smilref="Title.smil#_12055"> count[1]</p><p attribs="{'xml:space': 'preserve'}" id="_12056" smilref="Title.smil#_12056"> count[2]</p><p attribs="{'xml:space': 'preserve'}" id="_12057" smilref="Title.smil#_12057"> count[R-1]</p><p attribs="{'xml:space': 'preserve'}" id="_12058" smilref="Title.smil#_12058"> Key-indexed counting (distribution phase)</p><p attribs="{'xml:space': 'preserve'}" id="_12059" smilref="Title.smil#_12059"> Copy back. Since we accomplished the sort by moving the items to an auxiliary array, the last step is to copy the sorted result back to the original array.</p><p attribs="{'xml:space': 'preserve'}" id="_12060" smilref="Title.smil#_12060"> Proposition A. Key-indexed counting uses 8N &#11001; 3 R &#11001; 1 array accesses to stably sort N items whose keys are integers between 0 and R &#11002; 1. Proof : Immediate from the code. Initializing the arrays uses N &#11001; R &#11001; 1 array ac- cesses. The first loop increments a counter for each of the N items (2N array ac- cesses); the second loop does R additions (2R array accesses); the third loop does N counter increments and N data moves (3N array accesses); and the fourth loop does N data moves (2N array accesses). Both moves preserve the relative order of equal keys.</p><p attribs="{'xml:space': 'preserve'}" id="_12061" smilref="Title.smil#_12061"> Key-indexed counting is an extremely effective and often overlooked sorting method for applications where keys are small integers. Understand- ing how it works is a first step toward understanding string sorting. Proposition A implies that key-indexed counting breaks through the N log N lower bound that we proved for sorting. How does it manage to do so? Proposition I in SEc- tion 2.2 is a lower bound on the number of compares needed (when data is accessed only through compareTo())&#8212;key-indexed counting does no compares (it accesses data only through key()). When R is within a constant factor of N, we have a linear-time sort.</p><p attribs="{'xml:space': 'preserve'}" id="_12062" smilref="Title.smil#_12062"> int N = a.length;</p><p attribs="{'xml:space': 'preserve'}" id="_12063" smilref="Title.smil#_12063"> String[] aux = new String[N]; int[] count = new int[R+1];</p><p attribs="{'xml:space': 'preserve'}" id="_12064" smilref="Title.smil#_12064"> // Compute frequency counts. for (int i = 0; i &lt; N; i++) count[a[i].key() + 1]++; // Transform counts to indices. for (int r = 0; r &lt; R; r++) count[r+1] += count[r]; // Distribute the records. for (int i = 0; i &lt; N; i++) aux[count[a[i].key()]++] = a[i]; // Copy back. for (int i = 0; i &lt; N; i++) a[i] = aux[i];</p><p attribs="{'xml:space': 'preserve'}" id="_12065" smilref="Title.smil#_12065"> Key-indexed counting (a[].key is an int in [0, R).</p><p attribs="{'xml:space': 'preserve'}" id="_12066" smilref="Title.smil#_12066" /></level3><level3 id="_00098"><h3 id="ch5-s1-ss2" smilref="Title.smil#ch5-s1-ss2" xml:space="preserve">LSD string sort</h3><pagenum id="p719" page="normal" smilref="Title.smil#p719" /><p attribs="{'xml:space': 'preserve'}" id="_12067" smilref="Title.smil#_12067"> 706</p><p attribs="{'xml:space': 'preserve'}" id="_12068" smilref="Title.smil#_12068"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12069" smilref="Title.smil#_12069"> input</p><p attribs="{'xml:space': 'preserve'}" id="_12070" smilref="Title.smil#_12070"> sorted result</p><p attribs="{'xml:space': 'preserve'}" id="_12071" smilref="Title.smil#_12071"> LSD string sort The first string-sorting method that we consider is known as least- signi&#64257; cant-digit first (LSD) string sort. Consider the following motivating application: Suppose that a highway engineer sets up a device that records the license plate numbers of all vehicles using a busy highway for a given period of time and wants to know the number of different vehicles that used the highway. As you know from Section 2.1, one easy way to solve this problem is to sort the numbers, then make a pass through to count the different val- ues, as in Dedup (page 490). License plates are a mixture of numbers and letters, so it is natural to represent them as strings. In the simplest situation (such as the California license plate examples at right) the strings all have the same number of char- acters. This situation is often found in sort applications&#8212;for example, telephone numbers, bank account numbers, and IP addresses are typically fi xed-length strings. Sorting such strings can be done with key-indexed count- ing, as shown in Algorithm 5.1 (LSD) and the example below it on the facing page. If the strings are each of length W, we sort the strings W times with key-indexed counting, using each of the positions as the key, proceeding from right to left. It is not easy, at fi rst, to be convinced that the method produces a sorted array&#8212;in fact, it does not work at all unless the key-indexed count implementation is stable. Keep this fact in mind and refer to the example when studying this proof of correctness :</p><p attribs="{'xml:space': 'preserve'}" id="_12072" smilref="Title.smil#_12072"> 4PGC938 2IYE230 3CIO720 1ICK750 1OHV845 4JZY524 1ICK750 3CIO720 1OHV845 1OHV845 2RLA629 2RLA629 3ATW723</p><p attribs="{'xml:space': 'preserve'}" id="_12073" smilref="Title.smil#_12073"> 1ICK750 1ICK750 1OHV845 1OHV845 1OHV845 2IYE230 2RLA629 2RLA629 3ATW723 3CIO720 3CIO720 4JZY524 4PGC938</p><p attribs="{'xml:space': 'preserve'}" id="_12074" smilref="Title.smil#_12074"> keys are all the same length</p><p attribs="{'xml:space': 'preserve'}" id="_12075" smilref="Title.smil#_12075"> Typical candidate for LSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12076" smilref="Title.smil#_12076"> Proposition B. LSD string sort stably sorts fi xed-length strings.</p><p attribs="{'xml:space': 'preserve'}" id="_12077" smilref="Title.smil#_12077"> Proof : This fact depends crucially on the key-indexed counting implementation being stable, as indicated in Proposition A. After sorting keys on their i trailing characters (in a stable manner), we know that any two keys appear in proper order in the array (considering just those characters) either because the first of their i trailing characters is different, in which case the sort on that character puts them in order, or because the first of their ith trailing characters is the same, in which case they are in order because of stability (and by induction, for i-1).</p><p attribs="{'xml:space': 'preserve'}" id="_12078" smilref="Title.smil#_12078"> Another way to state the proof is to think about the future: if the characters that have not been examined for a pair of keys are identical, any difference between the keys is restricted to the characters already examined, so the keys have been properly ordered and will remain so because of stability. If, on the other hand, the characters that have not</p><p attribs="{'xml:space': 'preserve'}" id="_12079" smilref="Title.smil#_12079" /><pagenum id="p720" page="normal" smilref="Title.smil#p720" /><p attribs="{'xml:space': 'preserve'}" id="_12080" smilref="Title.smil#_12080"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12081" smilref="Title.smil#_12081"> 707</p><p attribs="{'xml:space': 'preserve'}" id="_12082" smilref="Title.smil#_12082"> ALGORITHM 5.1 LSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12083" smilref="Title.smil#_12083"> public class LSD { public static void sort(String[] a, int W) { // Sort a[] on leading W characters. int N = a.length; int R = 256; String[] aux = new String[N];</p><p attribs="{'xml:space': 'preserve'}" id="_12084" smilref="Title.smil#_12084"> for (int d = W-1; d &gt;= 0; d--) { // Sort by key-indexed counting on dth char.</p><p attribs="{'xml:space': 'preserve'}" id="_12085" smilref="Title.smil#_12085"> int[] count = new int[R+1]; // Compute frequency counts. for (int i = 0; i &lt; N; i++) count[a[i].charAt(d) + 1]++;</p><p attribs="{'xml:space': 'preserve'}" id="_12086" smilref="Title.smil#_12086"> for (int r = 0; r &lt; R; r++) // Transform counts to indices. count[r+1] += count[r];</p><p attribs="{'xml:space': 'preserve'}" id="_12087" smilref="Title.smil#_12087"> for (int i = 0; i &lt; N; i++) // Distribute. aux[count[a[i].charAt(d)]++] = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_12088" smilref="Title.smil#_12088"> for (int i = 0; i &lt; N; i++) // Copy back. a[i] = aux[i]; } } }</p><p attribs="{'xml:space': 'preserve'}" id="_12089" smilref="Title.smil#_12089"> To sort an array a[] of strings that each have exactly W characters, we do W key-indexed counting sorts: one for each character position, proceeding from right to left.</p><p attribs="{'xml:space': 'preserve'}" id="_12090" smilref="Title.smil#_12090"> input (W = 7)</p><p attribs="{'xml:space': 'preserve'}" id="_12091" smilref="Title.smil#_12091"> d = 6</p><p attribs="{'xml:space': 'preserve'}" id="_12092" smilref="Title.smil#_12092"> d = 5</p><p attribs="{'xml:space': 'preserve'}" id="_12093" smilref="Title.smil#_12093"> d = 4</p><p attribs="{'xml:space': 'preserve'}" id="_12094" smilref="Title.smil#_12094"> d = 3</p><p attribs="{'xml:space': 'preserve'}" id="_12095" smilref="Title.smil#_12095"> d = 2</p><p attribs="{'xml:space': 'preserve'}" id="_12096" smilref="Title.smil#_12096"> d = 1</p><p attribs="{'xml:space': 'preserve'}" id="_12097" smilref="Title.smil#_12097"> d = 0</p><p attribs="{'xml:space': 'preserve'}" id="_12098" smilref="Title.smil#_12098"> output</p><p attribs="{'xml:space': 'preserve'}" id="_12099" smilref="Title.smil#_12099"> 4PGC938 2IYE230 3CIO720 1ICK750 1OHV845 4JZY524 1ICK750 3CIO720 1OHV845 1OHV845 2RLA629 2RLA629 3ATW723</p><p attribs="{'xml:space': 'preserve'}" id="_12100" smilref="Title.smil#_12100"> 2IYE230 3CIO720 1ICK750 1ICK750 3CIO720 3ATW723 4JZY524 1OHV845 1OHV845 1OHV845 4PGC938 2RLA629 2RLA629</p><p attribs="{'xml:space': 'preserve'}" id="_12101" smilref="Title.smil#_12101"> 3CIO720 3CIO720 3ATW723 4JZY524 2RLA629 2RLA629 2IYE230 4PGC938 1OHV845 1OHV845 1OHV845 1ICK750 1ICK750</p><p attribs="{'xml:space': 'preserve'}" id="_12102" smilref="Title.smil#_12102"> 2IYE230 4JZY524 2RLA629 2RLA629 3CIO720 3CIO720 3ATW723 1ICK750 1ICK750 1OHV845 1OHV845 1OHV845 4PGC938</p><p attribs="{'xml:space': 'preserve'}" id="_12103" smilref="Title.smil#_12103"> 2RLA629 2RLA629 4PGC938 2IYE230 1ICK750 1ICK750 3CIO720 3CIO720 1OHV845 1OHV845 1OHV845 3ATW723 4JZY524</p><p attribs="{'xml:space': 'preserve'}" id="_12104" smilref="Title.smil#_12104"> 1ICK750 1ICK750 4PGC938 1OHV845 1OHV845 1OHV845 3CIO720 3CIO720 2RLA629 2RLA629 3ATW723 2IYE230 4JZY524</p><p attribs="{'xml:space': 'preserve'}" id="_12105" smilref="Title.smil#_12105"> 3ATW723 3CIO720 3CIO720 1ICK750 1ICK750 2IYE230 4JZY524 1OHV845 1OHV845 1OHV845 4PGC938 2RLA629 2RLA629</p><p attribs="{'xml:space': 'preserve'}" id="_12106" smilref="Title.smil#_12106"> 1ICK750 1ICK750 1OHV845 1OHV845 1OHV845 2IYE230 2RLA629 2RLA629 3ATW723 3CIO720 3CIO720 4JZY524 4PGC938</p><p attribs="{'xml:space': 'preserve'}" id="_12107" smilref="Title.smil#_12107"> 1ICK750 1ICK750 1OHV845 1OHV845 1OHV845 2IYE230 2RLA629 2RLA629 3ATW723 3CIO720 3CIO720 4JZY524 4PGC938</p><p attribs="{'xml:space': 'preserve'}" id="_12108" smilref="Title.smil#_12108" /><pagenum id="p721" page="normal" smilref="Title.smil#p721" /><p attribs="{'xml:space': 'preserve'}" id="_12109" smilref="Title.smil#_12109"> 708</p><p attribs="{'xml:space': 'preserve'}" id="_12110" smilref="Title.smil#_12110"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12111" smilref="Title.smil#_12111"> been examined are different, the characters already examined do not matter, and a later pass will correctly order the pair based on the more significant differences. LSD radix sorting is the method used by the old punched-card-sorting machines that were developed at the beginning of the 20th century and thus predated the use of computers in commercial data processing by several de- cades. Such machines had the capability of distributing a deck of punched cards among 10 bins, according to the pattern of holes punched in the selected columns. If a deck of cards had numbers punched in a particular set of columns, an operator could sort the cards by running them through the machine on the rightmost digit, then picking up and stacking the output decks in order, then running them through the machine on the next-to-rightmost digit, and so forth, until getting to the first digit. The physical stacking of the cards is a stable process, which is mimicked by key-indexed counting sort. Not only was this version of LSD radix sorting important in commercial applications up through the 1970s, but it was also used by many cautious programmers (and students!), who would have to keep their programs on punched cards (one line per card) and would punch sequence numbers in the final few columns of a program deck so as to be able to put the deck back in order mechanically if it were accidentally dropped. This method is also a neat way to sort a deck of playing cards: deal them into thirteen piles (one for each value), pick up the piles in order, then deal into four piles (one for each suit). The (stable) dealing process keeps the cards in order within each suit, so picking up the piles in suit order yields a sorted deck. In many string-sorting applications (even license plates, for some states), the keys are not all be the same length. It is possible to adapt LSD string sort to work for such applications, but we leave this task for exercises because we will next consider two other methods that are specifically designed for variable-length keys. From a theoretical standpoint, LSD string sort is significant because it is a linear-time sort for typical applications. No matter how large the value of N, it makes W passes through the data. Speci&#64257; cally :</p><p attribs="{'xml:space': 'preserve'}" id="_12112" smilref="Title.smil#_12112"> (cid:121) J (cid:120) 6 (cid:122) A (cid:120) A (cid:123) K (cid:120) J (cid:122) Q (cid:121) 6 (cid:123) J (cid:121) A (cid:122) 9 (cid:120) 9 (cid:122) 8 (cid:123) 9 (cid:121) K (cid:122) 4 (cid:123) 5 (cid:121) Q (cid:120) 3 (cid:123) 2 (cid:121)10 (cid:121) 9 (cid:120) 7 (cid:121) 4 (cid:120) 4 (cid:122)10 (cid:123) A (cid:122) 5 (cid:123) 3 (cid:120) 8 (cid:121) 2 (cid:122) K (cid:123) 4 (cid:121) 7 (cid:120) Q (cid:122) J (cid:123) 6 (cid:121) 3 (cid:123) 7 (cid:123) 8 (cid:123)10 (cid:122) 3 (cid:120)10 (cid:122) 7 (cid:123) Q (cid:120) 2 (cid:122) 2 (cid:121) 5 (cid:120) K (cid:120) 5 (cid:122) 6 (cid:121) 8</p><p attribs="{'xml:space': 'preserve'}" id="_12113" smilref="Title.smil#_12113"> (cid:122) A (cid:120) A (cid:121) A (cid:123) A (cid:123) 2 (cid:121) 2 (cid:120) 2 (cid:122) 2 (cid:120) 3 (cid:123) 3 (cid:121) 3 (cid:122) 3 (cid:122) 4 (cid:121) 4 (cid:120) 4 (cid:123) 4 (cid:123) 5 (cid:122) 5 (cid:121) 5 (cid:120) 5 (cid:120) 6 (cid:121) 6 (cid:123) 6 (cid:122) 6 (cid:120) 7 (cid:121) 7 (cid:123) 7 (cid:122) 7 (cid:122) 8 (cid:120) 8 (cid:123) 8 (cid:121) 8 (cid:122) 9 (cid:120) 9 (cid:123) 9 (cid:121) 9 (cid:121)10 (cid:122)10 (cid:123)10 (cid:120)10 (cid:121) J (cid:120) J (cid:123) J (cid:122) J (cid:122) Q (cid:121) Q (cid:120) Q (cid:123) Q (cid:123) K (cid:121) K (cid:122) K (cid:120) K</p><p attribs="{'xml:space': 'preserve'}" id="_12114" smilref="Title.smil#_12114"> (cid:123) A (cid:123) 2 (cid:123) 3 (cid:123) 4 (cid:123) 5 (cid:123) 6 (cid:123) 7 (cid:123) 8 (cid:123) 9 (cid:123)10 (cid:123) J (cid:123) Q (cid:123) K (cid:120) A (cid:120) 2 (cid:120) 3 (cid:120) 4 (cid:120) 5 (cid:120) 6 (cid:120) 7 (cid:120) 8 (cid:120) 9 (cid:120)10 (cid:120) J (cid:120) Q (cid:120) K (cid:122) A (cid:122) 2 (cid:122) 3 (cid:122) 4 (cid:122) 5 (cid:122) 6 (cid:122) 7 (cid:122) 8 (cid:122) 9 (cid:122)10 (cid:122) J (cid:122) Q (cid:122) K (cid:121) A (cid:121) 2 (cid:121) 3 (cid:121) 4 (cid:121) 5 (cid:121) 6 (cid:121) 7 (cid:121) 8 (cid:121) 9 (cid:121)10 (cid:121) J (cid:121) Q (cid:121) K</p><p attribs="{'xml:space': 'preserve'}" id="_12115" smilref="Title.smil#_12115"> Sorting a card deck with LSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12116" smilref="Title.smil#_12116" /><pagenum id="p722" page="normal" smilref="Title.smil#p722" /><p attribs="{'xml:space': 'preserve'}" id="_12117" smilref="Title.smil#_12117"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12118" smilref="Title.smil#_12118"> 709</p><p attribs="{'xml:space': 'preserve'}" id="_12119" smilref="Title.smil#_12119"> Proposition B (continued). LSD string sort uses ~7WN &#11001; 3WR array accesses and extra space proportional to N &#11001; R to sort N items whose keys are W-character strings taken from an R-character alphabet.</p><p attribs="{'xml:space': 'preserve'}" id="_12120" smilref="Title.smil#_12120"> Proof : The method is W passes of key-indexed counting, except that the aux[] array is initialized just once. The total is immediate from the code and Proposition A.</p><p attribs="{'xml:space': 'preserve'}" id="_12121" smilref="Title.smil#_12121"> For typical applications, R is far smaller than N, so Proposition B implies that the total running time is proportional to WN. An input array of N strings that each have W characters has a total of WN characters, so the running time of LSD string sort is linear in the size of the input.</p><p attribs="{'xml:space': 'preserve'}" id="_12122" smilref="Title.smil#_12122" /></level3><level3 id="_00099"><h3 id="ch5-s1-ss3" smilref="Title.smil#ch5-s1-ss3" xml:space="preserve">MSD string sort</h3><pagenum id="p723" page="normal" smilref="Title.smil#p723" /><p attribs="{'xml:space': 'preserve'}" id="_12123" smilref="Title.smil#_12123"> 710</p><p attribs="{'xml:space': 'preserve'}" id="_12124" smilref="Title.smil#_12124"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12125" smilref="Title.smil#_12125"> (cid:121) J (cid:120) 6 (cid:122) A (cid:120) A (cid:123) K (cid:120) J (cid:122) Q (cid:121) 6 (cid:123) J (cid:121) A (cid:122) 9 (cid:120) 9 (cid:122) 8 (cid:123) 9 (cid:121) K (cid:122) 4 (cid:123) 5 (cid:121) Q (cid:120) 3 (cid:123) 2 (cid:121)10 (cid:121) 9 (cid:120) 7 (cid:121) 4 (cid:120) 4 (cid:122)10 (cid:123) A (cid:122) 5 (cid:123) 3 (cid:120) 8 (cid:121) 2 (cid:122) K (cid:123) 4 (cid:121) 7 (cid:120) Q (cid:122) J (cid:123) 6 (cid:121) 3 (cid:123) 7 (cid:123) 8 (cid:123)10 (cid:122) 3 (cid:120)10 (cid:122) 7 (cid:123) Q (cid:120) 2 (cid:122) 2 (cid:121) 5 (cid:120) K (cid:120) 5 (cid:122) 6 (cid:121) 8</p><p attribs="{'xml:space': 'preserve'}" id="_12126" smilref="Title.smil#_12126"> (cid:123) K (cid:123) J (cid:123) 9 (cid:123) 5 (cid:123) 2 (cid:123) A (cid:123) 3 (cid:123) 4 (cid:123) 6 (cid:123) 7 (cid:123) 8 (cid:123)10 (cid:123) Q (cid:120) 6 (cid:120) A (cid:120) J (cid:120) 9 (cid:120) 3 (cid:120) 7 (cid:120) 4 (cid:120) 8 (cid:120) Q (cid:120)10 (cid:120) 2 (cid:120) K (cid:120) 5 (cid:122) A (cid:122) Q (cid:122) 9 (cid:122) 8 (cid:122) 4 (cid:122)10 (cid:122) 5 (cid:122) K (cid:122) J (cid:122) 3 (cid:122) 7 (cid:122) 2 (cid:122) 6 (cid:121) J (cid:121) 6 (cid:121) A (cid:121) K (cid:121) Q (cid:121)10 (cid:121) 9 (cid:121) 4 (cid:121) 2 (cid:121) 7 (cid:121) 3 (cid:121) 5 (cid:121) 8</p><p attribs="{'xml:space': 'preserve'}" id="_12127" smilref="Title.smil#_12127"> (cid:123) A (cid:123) 2 (cid:123) 3 (cid:123) 4 (cid:123) 5 (cid:123) 6 (cid:123) 7 (cid:123) 8 (cid:123) 9 (cid:123)10 (cid:123) J (cid:123) Q (cid:123) K (cid:120) A (cid:120) 2 (cid:120) 3 (cid:120) 4 (cid:120) 5 (cid:120) 6 (cid:120) 7 (cid:120) 8 (cid:120) 9 (cid:120)10 (cid:120) J (cid:120) Q (cid:120) K (cid:122) A (cid:122) 2 (cid:122) 3 (cid:122) 4 (cid:122) 5 (cid:122) 6 (cid:122) 7 (cid:122) 8 (cid:122) 9 (cid:122)10 (cid:122) J (cid:122) Q (cid:122) K (cid:121) A (cid:121) 2 (cid:121) 3 (cid:121) 4 (cid:121) 5 (cid:121) 6 (cid:121) 7 (cid:121) 8 (cid:121) 9 (cid:121)10 (cid:121) J (cid:121) Q (cid:121) K</p><p attribs="{'xml:space': 'preserve'}" id="_12128" smilref="Title.smil#_12128"> Sorting a card deck with MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12129" smilref="Title.smil#_12129"> MSD string sort To implement a general-purpose string sort, where strings are not necessarily all the same length, we consider the characters in left-to-right order. We know that strings that start with a should appear before strings that start with b, and so forth. The natural way to implement this idea is a recursive method known as most-signi&#64257; cant-digit-&#64257; rst (MSD) string sort. We use key-indexed counting to sort the strings according to their first character, then (recursively) sort the subarrays corresponding to each character (excluding the first character, which we know to be the same for each string in each subarray). Like quicksort, MSD string sort partitions the array into subarrays that can be sorted independently to complete the job, but it partitions the array into one subarray for each possible value of the first character, instead of the two or three partitions in quicksort.</p><p attribs="{'xml:space': 'preserve'}" id="_12130" smilref="Title.smil#_12130"> 0 0 0 . . . 0 0 1 1 1 . . . 1 1 2 2 2 . . . 2 2</p><p attribs="{'xml:space': 'preserve'}" id="_12131" smilref="Title.smil#_12131"> recursively sort subarrays (excluding first character)</p><p attribs="{'xml:space': 'preserve'}" id="_12132" smilref="Title.smil#_12132"> sort on first character value to partition into subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_12133" smilref="Title.smil#_12133"> End-of-string convention. We need to pay particular attention to reaching the ends of strings in MSD string sort. For a proper sort, we need the sub- array for strings whose characters have all been examined to appear as the first subarray, and we do not want to recursively sort this subarray. To facilitate these two parts of the computation we use a private two- argument charAt() method to convert from an indexed string character to an array index that returns -1 if the specified character position is past the end of the string. Then, we just add 1 to each returned value, to get a nonnegative int that we can use to index count[]. This convention means that we have R+1 different possible character values at each string posi- tion: 0 to signify end of string, 1 for the first alphabet charac- ter, 2 for the second alphabet character, and so forth. Since</p><p attribs="{'xml:space': 'preserve'}" id="_12134" smilref="Title.smil#_12134"> r r r . . . r r</p><p attribs="{'xml:space': 'preserve'}" id="_12135" smilref="Title.smil#_12135"> 0 0 0 . . . 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_12136" smilref="Title.smil#_12136"> 1 1 1 . . . 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_12137" smilref="Title.smil#_12137"> 2 2 2 . . . 2 2</p><p attribs="{'xml:space': 'preserve'}" id="_12138" smilref="Title.smil#_12138"> r r r . . . r r</p><p attribs="{'xml:space': 'preserve'}" id="_12139" smilref="Title.smil#_12139"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12140" smilref="Title.smil#_12140"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12141" smilref="Title.smil#_12141"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12142" smilref="Title.smil#_12142"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_12143" smilref="Title.smil#_12143"> Overview of MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12144" smilref="Title.smil#_12144" /><pagenum id="p724" page="normal" smilref="Title.smil#p724" /><p attribs="{'xml:space': 'preserve'}" id="_12145" smilref="Title.smil#_12145"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12146" smilref="Title.smil#_12146"> 711</p><p attribs="{'xml:space': 'preserve'}" id="_12147" smilref="Title.smil#_12147"> input she sells seashells by the seashore the shells she sells are surely seashells</p><p attribs="{'xml:space': 'preserve'}" id="_12148" smilref="Title.smil#_12148"> various key lengths</p><p attribs="{'xml:space': 'preserve'}" id="_12149" smilref="Title.smil#_12149"> sorted result are by seashells seashells seashore sells sells she she shells surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12150" smilref="Title.smil#_12150"> Typical candidate for MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12151" smilref="Title.smil#_12151"> key-indexed counting already needs one extra position, we use the code int count[] = new int[R+2]; to create the array of frequency counts (and set all of its values to 0). Note : Some languages, notably C and C++, have a built-in end-of-string convention, so our code needs to be adjusted accordingly for such languages.</p><p attribs="{'xml:space': 'preserve'}" id="_12152" smilref="Title.smil#_12152"> With these preparations, the implementation of MSD string sort, in Algorithm 5.2, requires very little new code. We add a test to cutoff to insertion sort for small subarrays (using a specialized insertion sort that we will consider later), and we add a loop to key-indexed counting to do the recursive calls. As summarized in the table at the bottom of this page, the values in the count[] array (after serving to count the frequencies, transform counts to indices, and distribute the data) give us precisely the information that we need to (recursively) sort the subarrays corresponding to each character value.</p><p attribs="{'xml:space': 'preserve'}" id="_12153" smilref="Title.smil#_12153"> Speci&#64257; ed alphabet. The cost of MSD string sort depends strongly on the number of possible characters in the alphabet. It is easy to modify our sort method to take an Alphabet as argument, to allow for improved efficiency in clients involving strings taken from relatively small alphabets. The following changes will do the job: </p><p attribs="{'xml:space': 'preserve'}" id="_12154" smilref="Title.smil#_12154"> </p><p attribs="{'xml:space': 'preserve'}" id="_12155" smilref="Title.smil#_12155"> at completion of phase for dth character</p><p attribs="{'xml:space': 'preserve'}" id="_12156" smilref="Title.smil#_12156"> count frequencies</p><p attribs="{'xml:space': 'preserve'}" id="_12157" smilref="Title.smil#_12157"> transform counts to indices</p><p attribs="{'xml:space': 'preserve'}" id="_12158" smilref="Title.smil#_12158"> distribute</p><p attribs="{'xml:space': 'preserve'}" id="_12159" smilref="Title.smil#_12159"> value of count[r] is</p><p attribs="{'xml:space': 'preserve'}" id="_12160" smilref="Title.smil#_12160"> r = 0</p><p attribs="{'xml:space': 'preserve'}" id="_12161" smilref="Title.smil#_12161"> r = 1</p><p attribs="{'xml:space': 'preserve'}" id="_12162" smilref="Title.smil#_12162"> r between 2 and R-1</p><p attribs="{'xml:space': 'preserve'}" id="_12163" smilref="Title.smil#_12163"> r = R</p><p attribs="{'xml:space': 'preserve'}" id="_12164" smilref="Title.smil#_12164"> r = R+1</p><p attribs="{'xml:space': 'preserve'}" id="_12165" smilref="Title.smil#_12165"> 0 (not used)</p><p attribs="{'xml:space': 'preserve'}" id="_12166" smilref="Title.smil#_12166"> number of strings of length d</p><p attribs="{'xml:space': 'preserve'}" id="_12167" smilref="Title.smil#_12167"> number of strings whose dth character value is r-2</p><p attribs="{'xml:space': 'preserve'}" id="_12168" smilref="Title.smil#_12168"> start index of subarray for strings of length d</p><p attribs="{'xml:space': 'preserve'}" id="_12169" smilref="Title.smil#_12169"> start index of subarray for strings whose dth character value is r-1</p><p attribs="{'xml:space': 'preserve'}" id="_12170" smilref="Title.smil#_12170"> not used</p><p attribs="{'xml:space': 'preserve'}" id="_12171" smilref="Title.smil#_12171"> start index of subarray for strings whose dth character value is r 1 + end index of subarray 1 + end index of subarray for strings for strings of length d whose dth character value is r-1</p><p attribs="{'xml:space': 'preserve'}" id="_12172" smilref="Title.smil#_12172"> not used</p><p attribs="{'xml:space': 'preserve'}" id="_12173" smilref="Title.smil#_12173"> not used</p><p attribs="{'xml:space': 'preserve'}" id="_12174" smilref="Title.smil#_12174"> Interpretation of count[] values during MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12175" smilref="Title.smil#_12175" /><pagenum id="p725" page="normal" smilref="Title.smil#p725" /><p attribs="{'xml:space': 'preserve'}" id="_12176" smilref="Title.smil#_12176"> 712</p><p attribs="{'xml:space': 'preserve'}" id="_12177" smilref="Title.smil#_12177"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12178" smilref="Title.smil#_12178"> ALGORITHM 5.2 MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12179" smilref="Title.smil#_12179"> public class MSD { private static int R = 256; // radix private static final int M = 15; // cutoff for small subarrays private static String[] aux; // auxiliary array for distribution</p><p attribs="{'xml:space': 'preserve'}" id="_12180" smilref="Title.smil#_12180"> private static int charAt(String s, int d) { if (d &lt; s.length()) return s.charAt(d); else return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_12181" smilref="Title.smil#_12181"> public static void sort(String[] a) { int N = a.length; aux = new String[N]; sort(a, 0, N-1, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_12182" smilref="Title.smil#_12182"> private static void sort(String[] a, int lo, int hi, int d) { // Sort from a[lo] to a[hi], starting at the dth character.</p><p attribs="{'xml:space': 'preserve'}" id="_12183" smilref="Title.smil#_12183"> if (hi &lt;= lo + M) { Insertion.sort(a, lo, hi, d); return; }</p><p attribs="{'xml:space': 'preserve'}" id="_12184" smilref="Title.smil#_12184"> int[] count = new int[R+2]; // Compute frequency counts. for (int i = lo; i &lt;= hi; i++) count[charAt(a[i], d) + 2]++;</p><p attribs="{'xml:space': 'preserve'}" id="_12185" smilref="Title.smil#_12185"> for (int r = 0; r &lt; R+1; r++) // Transform counts to indices. count[r+1] += count[r];</p><p attribs="{'xml:space': 'preserve'}" id="_12186" smilref="Title.smil#_12186"> for (int i = lo; i &lt;= hi; i++) // Distribute. aux[count[charAt(a[i], d) + 1]++] = a[i];</p><p attribs="{'xml:space': 'preserve'}" id="_12187" smilref="Title.smil#_12187"> for (int i = lo; i &lt;= hi; i++) // Copy back. a[i] = aux[i - lo];</p><p attribs="{'xml:space': 'preserve'}" id="_12188" smilref="Title.smil#_12188"> // Recursively sort for each character value. for (int r = 0; r &lt; R; r++) sort(a, lo + count[r], lo + count[r+1] - 1, d+1);</p><p attribs="{'xml:space': 'preserve'}" id="_12189" smilref="Title.smil#_12189"> }</p><p attribs="{'xml:space': 'preserve'}" id="_12190" smilref="Title.smil#_12190"> }</p><p attribs="{'xml:space': 'preserve'}" id="_12191" smilref="Title.smil#_12191"> To sort an array a[] of strings, we sort them on their first character using key-indexed counting, then (recursively) sort the subarrays corresponding to each fi rst-character value.</p><p attribs="{'xml:space': 'preserve'}" id="_12192" smilref="Title.smil#_12192" /><pagenum id="p726" page="normal" smilref="Title.smil#p726" /><p attribs="{'xml:space': 'preserve'}" id="_12193" smilref="Title.smil#_12193"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12194" smilref="Title.smil#_12194"> 713</p><p attribs="{'xml:space': 'preserve'}" id="_12195" smilref="Title.smil#_12195"> In our running examples, we use strings made up of lowercase letters. It is also easy to extend LSD string sort to provide this feature, but typically with much less impact on performance than for MSD string sort.</p><p attribs="{'xml:space': 'preserve'}" id="_12196" smilref="Title.smil#_12196"> The code in Algorithm 5.2 is deceptively simple, masking a rather sophisticated computation. It is definitely worth your while to study the trace of the top level at the bottom of this page and the trace of recursive calls on the next page, to be sure that you understand the intricacies of the algorithm. This trace uses a cutoff-for-small- subarrays threshold value (M) of 0, so that you can see the sort to completion for this small example. The strings in this example are taken from Alphabet.LOWERCASE, with R = 26; bear in mind that typical applications might use Alphabet.EXTENDED.ASCII, with R = 256, or Alphabet.UNICODE, with R = 65536. For large alphabets, MSD string sort is so simple as to be dangerous&#8212;improperly used, it can consume outrageous amounts of time and space. Before considering performance characteristics in detail, we shall discuss three important issues (all of which we have considered before, in Chapter 2) that must be addressed in any application. Small subarrays. The basic idea behind MSD string sort is quite effective: in typical applications, the strings will be in order after examining only a few characters in the key. Put another way, the method quickly divides the array to be sorted into small</p><p attribs="{'xml:space': 'preserve'}" id="_12197" smilref="Title.smil#_12197"> use key-indexed counting on first character</p><p attribs="{'xml:space': 'preserve'}" id="_12198" smilref="Title.smil#_12198"> recursively sort subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_12199" smilref="Title.smil#_12199"> count frequencies</p><p attribs="{'xml:space': 'preserve'}" id="_12200" smilref="Title.smil#_12200"> transform counts to indices</p><p attribs="{'xml:space': 'preserve'}" id="_12201" smilref="Title.smil#_12201"> indices at completion of distribute phase</p><p attribs="{'xml:space': 'preserve'}" id="_12202" smilref="Title.smil#_12202"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12203" smilref="Title.smil#_12203"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12204" smilref="Title.smil#_12204"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12205" smilref="Title.smil#_12205"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_12206" smilref="Title.smil#_12206"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_12207" smilref="Title.smil#_12207"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_12208" smilref="Title.smil#_12208"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_12209" smilref="Title.smil#_12209"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_12210" smilref="Title.smil#_12210"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_12211" smilref="Title.smil#_12211"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_12212" smilref="Title.smil#_12212"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_12213" smilref="Title.smil#_12213"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_12214" smilref="Title.smil#_12214"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_12215" smilref="Title.smil#_12215"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_12216" smilref="Title.smil#_12216"> she sells seashells by the sea shore the shells she sells are surely seashells</p><p attribs="{'xml:space': 'preserve'}" id="_12217" smilref="Title.smil#_12217"> 0 0 1 a 0 2 b 1 3 c 1 4 d 0 5 e 0 6 f 0 7 g 0 8 h 0 9 i 0 10 j 0 11 k 0 12 l 0 13 m 0 14 n 0 15 o 0 16 p 0 17 q 0 18 r 0 19 s 0 20 t 10 21 u 2 22 v 0 23 w 0 24 x 0 25 y 0 26 z 0 27 0</p><p attribs="{'xml:space': 'preserve'}" id="_12218" smilref="Title.smil#_12218"> 0 0 1 a 0 2 b 1 3 c 2 4 d 2 5 e 2 6 f 2 7 g 2 8 h 2 9 i 2 10 j 2 11 k 2 12 l 2 13 m 2 14 n 2 15 o 2 16 p 2 17 q 2 18 r 2 19 s 2 20 t 12 21 u 14 22 v 14 23 w 14 24 x 14 25 y 14 26 z 14 27 14</p><p attribs="{'xml:space': 'preserve'}" id="_12219" smilref="Title.smil#_12219"> distribute and copy back</p><p attribs="{'xml:space': 'preserve'}" id="_12220" smilref="Title.smil#_12220"> are by she sells seashells sea shore shells she sells surely seashells the the</p><p attribs="{'xml:space': 'preserve'}" id="_12221" smilref="Title.smil#_12221"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12222" smilref="Title.smil#_12222"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12223" smilref="Title.smil#_12223"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12224" smilref="Title.smil#_12224"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_12225" smilref="Title.smil#_12225"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_12226" smilref="Title.smil#_12226"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_12227" smilref="Title.smil#_12227"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_12228" smilref="Title.smil#_12228"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_12229" smilref="Title.smil#_12229"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_12230" smilref="Title.smil#_12230"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_12231" smilref="Title.smil#_12231"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_12232" smilref="Title.smil#_12232"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_12233" smilref="Title.smil#_12233"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_12234" smilref="Title.smil#_12234"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_12235" smilref="Title.smil#_12235"> start of s subarray 1 + end of s subarray</p><p attribs="{'xml:space': 'preserve'}" id="_12236" smilref="Title.smil#_12236"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12237" smilref="Title.smil#_12237"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12238" smilref="Title.smil#_12238"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12239" smilref="Title.smil#_12239"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_12240" smilref="Title.smil#_12240"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_12241" smilref="Title.smil#_12241"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_12242" smilref="Title.smil#_12242"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_12243" smilref="Title.smil#_12243"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_12244" smilref="Title.smil#_12244"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_12245" smilref="Title.smil#_12245"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_12246" smilref="Title.smil#_12246"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_12247" smilref="Title.smil#_12247"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_12248" smilref="Title.smil#_12248"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_12249" smilref="Title.smil#_12249"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_12250" smilref="Title.smil#_12250"> are by sea seashells seashells sells sells she she shells shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12251" smilref="Title.smil#_12251"> 0 0 0 1 a 1 2 b 2 3 c 2 4 d 2 5 e 2 6 f 2 7 g 2 8 h 2 9 i 2 10 j 2 11 k 2 12 l 2 13 m 2 14 n 2 15 o 2 16 p 2 17 q 2 18 r 2 19 s 12 20 t 14 21 u 14 22 v 14 23 w 14 24 x 14 25 y 14 26 z 14 27 14</p><p attribs="{'xml:space': 'preserve'}" id="_12252" smilref="Title.smil#_12252"> sort(a, 0, 0, 1); sort(a, 1, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 1, 1); sort(a, 2, 11, 1); sort(a, 12, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1); sort(a, 14, 13, 1);</p><p attribs="{'xml:space': 'preserve'}" id="_12253" smilref="Title.smil#_12253"> Trace of MSD string sort: top level of sort(a, 0, 13, 0)</p><p attribs="{'xml:space': 'preserve'}" id="_12254" smilref="Title.smil#_12254" /><pagenum id="p727" page="normal" smilref="Title.smil#p727" /><p attribs="{'xml:space': 'preserve'}" id="_12255" smilref="Title.smil#_12255"> 714</p><p attribs="{'xml:space': 'preserve'}" id="_12256" smilref="Title.smil#_12256"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12257" smilref="Title.smil#_12257"> input</p><p attribs="{'xml:space': 'preserve'}" id="_12258" smilref="Title.smil#_12258"> she sells seashells by the sea shore the shells she sells are surely seashells</p><p attribs="{'xml:space': 'preserve'}" id="_12259" smilref="Title.smil#_12259"> lo</p><p attribs="{'xml:space': 'preserve'}" id="_12260" smilref="Title.smil#_12260"> are by she sells seashells sea shore shells she sells surely seashells the the</p><p attribs="{'xml:space': 'preserve'}" id="_12261" smilref="Title.smil#_12261"> hi</p><p attribs="{'xml:space': 'preserve'}" id="_12262" smilref="Title.smil#_12262"> d</p><p attribs="{'xml:space': 'preserve'}" id="_12263" smilref="Title.smil#_12263"> are by sells seashells sea sells seashells she shore shells she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12264" smilref="Title.smil#_12264"> are by seashells sea seashells sells sells she shore shells she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12265" smilref="Title.smil#_12265"> are by sea seashells seashells sells sells she shore shells she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12266" smilref="Title.smil#_12266"> are by sea seashells seashells sells sells she shore shells she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12267" smilref="Title.smil#_12267"> are by sea seashells seashells sells sells she shore shells she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12268" smilref="Title.smil#_12268"> are by seas seashells seashells sells sells she shells shore she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12269" smilref="Title.smil#_12269"> are by sea seashells seashells sells sells she shells shore she surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12270" smilref="Title.smil#_12270"> are by sea seashells seashells sells sells she shells she shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12271" smilref="Title.smil#_12271"> are by sea seashells seashells sells sells she shells she shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12272" smilref="Title.smil#_12272"> need to examine every character in equal keys</p><p attribs="{'xml:space': 'preserve'}" id="_12273" smilref="Title.smil#_12273"> are by sea seashells seashells sells sells she shells she shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12274" smilref="Title.smil#_12274"> end of string goes before any char value</p><p attribs="{'xml:space': 'preserve'}" id="_12275" smilref="Title.smil#_12275"> are by sea seashells seashells sells sells she shells she shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12276" smilref="Title.smil#_12276"> are by sea seashells seashells sells sells she she shells shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12277" smilref="Title.smil#_12277"> are by sea seashells seashells sells sells she she shells shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12278" smilref="Title.smil#_12278"> are by sea seashells seashells sells sells she she shells shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12279" smilref="Title.smil#_12279"> output</p><p attribs="{'xml:space': 'preserve'}" id="_12280" smilref="Title.smil#_12280"> are by sea seashells seashells sells sells she she shells shore surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12281" smilref="Title.smil#_12281"> Trace of recursive calls for MSD string sort (no cutoff for small subarrays, subarrays of size 0 and 1 omitted)</p><p attribs="{'xml:space': 'preserve'}" id="_12282" smilref="Title.smil#_12282"> subarrays. But this is a double-edged sword: we are certain to have to handle huge numbers of tiny subarrays, so we had better be sure that we handle them ef&#64257; ciently. Small subarrays are of critical importance in the performance of MSD string sort. We have seen this situation for other recursive sorts (quicksort and mergesort), but it is much more dramatic for MSD string sort. For example, suppose that you are sorting millions of ASCII strings (R = 256) that are all different, with no cutoff for small subarrays. Each string eventually finds its way to its own subarray, so you will sort millions of subarrays of size 1. But each such sort involves initializing the 258 entries of the count[] array to 0 and transforming them all to indices. This cost is likely to dominate the rest of the sort. With Unicode (R = 65536) the sort might be thousands of times slower. Indeed, many unsuspecting sort clients have seen their running times explode from minutes to</p><p attribs="{'xml:space': 'preserve'}" id="_12283" smilref="Title.smil#_12283" /><pagenum id="p728" page="normal" smilref="Title.smil#p728" /><p attribs="{'xml:space': 'preserve'}" id="_12284" smilref="Title.smil#_12284"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12285" smilref="Title.smil#_12285"> 715</p><p attribs="{'xml:space': 'preserve'}" id="_12286" smilref="Title.smil#_12286"> public static void sort(String[] a, int lo, int hi, int d) { // Sort from a[lo] to a[hi], starting at the dth character.</p><p attribs="{'xml:space': 'preserve'}" id="_12287" smilref="Title.smil#_12287"> for (int i = lo; i &lt;= hi; i++) for (int j = i; j &gt; lo &amp;&amp; less(a[j], a[j-1], d); j--) exch(a, j, j-1); }</p><p attribs="{'xml:space': 'preserve'}" id="_12288" smilref="Title.smil#_12288"> private static boolean less(String v, String w, int d) { return v.substring(d).compareTo(w.substring(d)) &lt; 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_12289" smilref="Title.smil#_12289"> Insertion sort for strings whose f irst d characters are equal</p><p attribs="{'xml:space': 'preserve'}" id="_12290" smilref="Title.smil#_12290"> hours on switching from ASCII to Unicode, for precisely this reason. Accordingly, the switch to insertion sort for small subarrays is a must for MSD string sort. To avoid the cost of reexamining characters that we know to be equal, we use the version of insertion sort given at the top of the page, which takes an extra argument d and assumes that the first d characters of all the strings to be sorted are known to be equal. The efficiency of this code depends on substring() being a constant-time operation. As with quicksort and mergesort, most of the benefit of this improvement is achieved with a small value of the cutoff, but the savings here are much more dramat- ic. The diagram at right shows the results of experiments where using a cutoff to insertion sort for subarrays of size 10 or less decreases the running time by a factor of 10 for a typical application.</p><p attribs="{'xml:space': 'preserve'}" id="_12291" smilref="Title.smil#_12291"> 100%</p><p attribs="{'xml:space': 'preserve'}" id="_12292" smilref="Title.smil#_12292"> o n h</p><p attribs="{'xml:space': 'preserve'}" id="_12293" smilref="Title.smil#_12293"> ff o</p><p attribs="{'xml:space': 'preserve'}" id="_12294" smilref="Title.smil#_12294"> m</p><p attribs="{'xml:space': 'preserve'}" id="_12295" smilref="Title.smil#_12295"> w</p><p attribs="{'xml:space': 'preserve'}" id="_12296" smilref="Title.smil#_12296"> u</p><p attribs="{'xml:space': 'preserve'}" id="_12297" smilref="Title.smil#_12297"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12298" smilref="Title.smil#_12298"> c</p><p attribs="{'xml:space': 'preserve'}" id="_12299" smilref="Title.smil#_12299"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12300" smilref="Title.smil#_12300"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12301" smilref="Title.smil#_12301"> N = 100,000 N random CA plates 100 trials per point</p><p attribs="{'xml:space': 'preserve'}" id="_12302" smilref="Title.smil#_12302"> i</p><p attribs="{'xml:space': 'preserve'}" id="_12303" smilref="Title.smil#_12303"> i</p><p attribs="{'xml:space': 'preserve'}" id="_12304" smilref="Title.smil#_12304"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12305" smilref="Title.smil#_12305"> f</p><p attribs="{'xml:space': 'preserve'}" id="_12306" smilref="Title.smil#_12306"> o e g a</p><p attribs="{'xml:space': 'preserve'}" id="_12307" smilref="Title.smil#_12307"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12308" smilref="Title.smil#_12308"> n e c</p><p attribs="{'xml:space': 'preserve'}" id="_12309" smilref="Title.smil#_12309"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12310" smilref="Title.smil#_12310"> e p</p><p attribs="{'xml:space': 'preserve'}" id="_12311" smilref="Title.smil#_12311"> a</p><p attribs="{'xml:space': 'preserve'}" id="_12312" smilref="Title.smil#_12312"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12313" smilref="Title.smil#_12313"> a e</p><p attribs="{'xml:space': 'preserve'}" id="_12314" smilref="Title.smil#_12314"> m</p><p attribs="{'xml:space': 'preserve'}" id="_12315" smilref="Title.smil#_12315"> i</p><p attribs="{'xml:space': 'preserve'}" id="_12316" smilref="Title.smil#_12316"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12317" smilref="Title.smil#_12317"> i</p><p attribs="{'xml:space': 'preserve'}" id="_12318" smilref="Title.smil#_12318"> g n n n u</p><p attribs="{'xml:space': 'preserve'}" id="_12319" smilref="Title.smil#_12319"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12320" smilref="Title.smil#_12320"> Equal keys. A second pitfall for MSD string sort is that it can be relatively slow for subarrays containing large numbers of equal keys. If a substring occurs sufficiently often that the cutoff for small subarrays does not ap- ply, then a recursive call is needed for every character in all of the equal keys. Moreover, key-indexed counting is an inefficient way to determine that the characters are all equal: not only does each character need to be examined and each string moved, but all the counts have to be initialized, converted to indices, and so forth. Thus, the worst case for MSD string sorting is when all keys are equal. The same problem arises when large numbers of keys have long common pre&#64257; xes, a situation often found in applications.</p><p attribs="{'xml:space': 'preserve'}" id="_12321" smilref="Title.smil#_12321"> 50%</p><p attribs="{'xml:space': 'preserve'}" id="_12322" smilref="Title.smil#_12322"> 25%</p><p attribs="{'xml:space': 'preserve'}" id="_12323" smilref="Title.smil#_12323"> 10%</p><p attribs="{'xml:space': 'preserve'}" id="_12324" smilref="Title.smil#_12324"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12325" smilref="Title.smil#_12325"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_12326" smilref="Title.smil#_12326"> cutoff value</p><p attribs="{'xml:space': 'preserve'}" id="_12327" smilref="Title.smil#_12327"> 50</p><p attribs="{'xml:space': 'preserve'}" id="_12328" smilref="Title.smil#_12328"> Effect of cutoff for small subarrays in MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12329" smilref="Title.smil#_12329" /><pagenum id="p729" page="normal" smilref="Title.smil#p729" /><p attribs="{'xml:space': 'preserve'}" id="_12330" smilref="Title.smil#_12330"> 716</p><p attribs="{'xml:space': 'preserve'}" id="_12331" smilref="Title.smil#_12331"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12332" smilref="Title.smil#_12332"> Extra space. To do the partitioning, MSD uses two auxiliary arrays: the temporary array for distributing keys (aux[]) and the array that holds the counts that are transformed into partition indices (count[]). The aux[] array is of size N and can be created outside the recursive sort() method. This extra space can be eliminated by sac- ri&#64257; cing stability (see Exercise 5.1.17), but it is often not a major concern in practical applications of MSD string sort. Space for the count[] array, on the other hand, can be an important issue (because it cannot be created outside the recursive sort() method) as addressed in Proposition D below. Random string model. To study the performance of MSD string sort, we use a random string model, where each string consists of (independently) random characters, with no bound on their length. Long equal keys are essentially ignored, because they are extremely unlikely. The behavior of MSD string sort in this model is similar to its behavior in a model where we consider random fi xed-length keys and also to its performance for typical real data; in all three, MSD string sort tends to examine just a few characters at the beginning of each key, as we will see.</p><p attribs="{'xml:space': 'preserve'}" id="_12333" smilref="Title.smil#_12333"> nonrandom with duplicates (nearly linear)</p><p attribs="{'xml:space': 'preserve'}" id="_12334" smilref="Title.smil#_12334"> Performance. The running time of MSD string sort depends on the data. For compare- based methods, we were primarily concerned with the order of the keys; for MSD string sort, the order of the keys is immaterial, but we are concerned with the values of the keys. </p><p attribs="{'xml:space': 'preserve'}" id="_12335" smilref="Title.smil#_12335"> random (sublinear)</p><p attribs="{'xml:space': 'preserve'}" id="_12336" smilref="Title.smil#_12336"> worst case (linear)</p><p attribs="{'xml:space': 'preserve'}" id="_12337" smilref="Title.smil#_12337"> 1EIO402 are 1DNB377 1HYL490 by 1DNB377 1ROZ572 sea 1DNB377 2HXE734 seashells 1DNB377 2IYE230 seashells 1DNB377 2XOR846 sells 1DNB377 3CDB573 sells 1DNB377 3CVP720 she 1DNB377 3IGJ319 she 1DNB377 3KNA382 shells 1DNB377 3TAV879 shore 1DNB377 4CQP781 surely 1DNB377 4QGI284 the 1DNB377 4YHV229 the 1DNB377 Characters examined by MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12338" smilref="Title.smil#_12338" /><pagenum id="p730" page="normal" smilref="Title.smil#p730" /><p attribs="{'xml:space': 'preserve'}" id="_12339" smilref="Title.smil#_12339"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12340" smilref="Title.smil#_12340"> 717</p><p attribs="{'xml:space': 'preserve'}" id="_12341" smilref="Title.smil#_12341"> Some applications involve distinct keys that are well-modeled by the random string model; others have significant numbers of equal keys or long common pre&#64257; xes, so the sort time is closer to the worst case. Our license-plate-processing application, for ex- ample, can fall anywhere between these extremes: if our engineer takes an hour of data from a busy interstate, there will not be many duplicates and the random model will apply ; for a week&#8217;s worth of data on a local road, there will be numerous duplicates and performance will be closer to the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_12342" smilref="Title.smil#_12342"> Proposition C. To sort N random strings from an R-character alphabet, MSD string sort examines about N log R N characters, on average. Proof sketch: We expect the subarrays to be all about the same size, so the recurrence CN = RCN/R + N approximately describes the performance, which leads to the stated result, generalizing our argument for quicksort in Chapter 2. Again, this description of the situation is not entirely accurate, because N/R is not necessarily an integer, and the subarrays are the same size only on the average (and because the number of characters in real keys is fi nite). These effects turn out to be less significant for MSD string sort than for standard quicksort, so the leading term of the running time is the solution to this recurrence. The detailed analysis that proves this fact is a classical example in the analysis of algorithms, first done by Knuth in the early 1970s.</p><p attribs="{'xml:space': 'preserve'}" id="_12343" smilref="Title.smil#_12343"> As food for thought and to indicate why the proof is beyond the scope of this book, note that key length does not play a role. Indeed, the random-string model allows key length to approach in&#64257; nity. There is a nonzero probability that two keys will match for any specified number of characters, but this probability is so small as to not play a role in our performance estimates. As we have discussed, the number of characters examined is not the full story for MSD string sort. We also have to take into account the time and space required to count frequencies and turn the counts into indices.</p><p attribs="{'xml:space': 'preserve'}" id="_12344" smilref="Title.smil#_12344"> Proposition D. MSD string sort uses between 8N &#11001; 3R and ~7wN &#11001; 3WR array accesses to sort N strings taken from an R-character alphabet, where w is the average string length. Proof : Immediate from the code, Proposition A, and Proposition B. In the best case MSD sort uses just one pass; in the worst case, it performs like LSD string sort.</p><p attribs="{'xml:space': 'preserve'}" id="_12345" smilref="Title.smil#_12345" /><pagenum id="p731" page="normal" smilref="Title.smil#p731" /><p attribs="{'xml:space': 'preserve'}" id="_12346" smilref="Title.smil#_12346"> 718</p><p attribs="{'xml:space': 'preserve'}" id="_12347" smilref="Title.smil#_12347"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12348" smilref="Title.smil#_12348"> When N is small, the factor of R dominates. Though precise analysis of the total cost becomes difficult and complicated, you can estimate the effect of this cost just by considering small subarrays when keys are distinct. With no cutoff for small subarrays, each key appears in its own subarray, so NR array accesses are needed for just these subarrays. If we cut off to small subarrays of size M, we have about N/M subarrays of size M, so we are trading off NR/M array accesses with NM/4 compares, which tells us that we should choose M to be proportional to the square root of R.</p><p attribs="{'xml:space': 'preserve'}" id="_12349" smilref="Title.smil#_12349"> Proposition D (continued). To sort N strings taken from an R-character alphabet, the amount of space needed by MSD string sort is proportional to R times the length of the longest string (plus N ), in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_12350" smilref="Title.smil#_12350"> Proof : The count[] array must be created within sort(), so the total amount of space needed is proportional to R times the depth of recursion (plus N for the auxiliary array). Precisely, the depth of the recursion is the length of the longest string that is a prefix of two or more of the strings to be sorted.</p><p attribs="{'xml:space': 'preserve'}" id="_12351" smilref="Title.smil#_12351"> As just discussed, equal keys cause the depth of the recursion to be proportional to the length of the keys. The immediate practical lesson to be drawn from Proposition D is that it is quite possible for MSD string sort to run out of time or space when sorting long strings taken from large alphabets, particularly if long equal keys are to be ex- pected. For example, with Alphabet.UNICODE and more than M equal 1,000-character strings, MSD.sort() would require space for over 65 million counters!</p><p attribs="{'xml:space': 'preserve'}" id="_12352" smilref="Title.smil#_12352"> The main challenge in getting maximum efficiency from MSD string sort on keys that are long strings is to deal with lack of randomness in the data. Typically, keys may have long stretches of equal data, or parts of them might fall in only a narrow range. For example, an information-processing application for student data might have keys that include graduation year (4 bytes, but one of four different values), state names (perhaps 10 bytes, but one of 50 different values), and gender (1 byte with one of two given values), as well as a person&#8217;s name (more similar to random strings, but probably not short, with nonuniform letter distributions, and with trailing blanks in a fi xed- length fi eld). Restrictions like these lead to large numbers of empty subarrays during the MSD string sort. Next, we consider a graceful way to adapt to such situations.</p><p attribs="{'xml:space': 'preserve'}" id="_12353" smilref="Title.smil#_12353" /></level3><level3 id="_00100"><h3 id="ch5-s1-ss4" smilref="Title.smil#ch5-s1-ss4" xml:space="preserve">3-way string quicksort</h3><pagenum id="p732" page="normal" smilref="Title.smil#p732" /><p attribs="{'xml:space': 'preserve'}" id="_12354" smilref="Title.smil#_12354"> Three-way string quicksort We can also</p><p attribs="{'xml:space': 'preserve'}" id="_12355" smilref="Title.smil#_12355"> use first character value to partition into &#8220;less,&#8221; &#8220;equal,&#8221; and &#8220;greater&#8221; subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_12356" smilref="Title.smil#_12356"> recursively sort subarrays (excluding first character for &#8220;equal&#8217; subarray)</p><p attribs="{'xml:space': 'preserve'}" id="_12357" smilref="Title.smil#_12357"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12358" smilref="Title.smil#_12358"> 719</p><p attribs="{'xml:space': 'preserve'}" id="_12359" smilref="Title.smil#_12359"> &lt;v &lt;v &lt;v . . . &lt;v &lt;v &lt;v &lt;v &lt;v . . . &lt;v &lt;v v v v . . . v v &gt;v &gt;v &gt;v . . . &gt;v &gt;v &gt;v &gt;v &gt;v . . . &gt;v &gt;v</p><p attribs="{'xml:space': 'preserve'}" id="_12360" smilref="Title.smil#_12360"> adapt quicksort to MSD string sorting by using 3-way partitioning on the leading character of the keys, moving to the next character on only the middle subarray (keys with leading character equal to the partitioning character). This method is not dif&#64257; cult to implement, as you can see in Algorithm 5.3: we just add an argument to the recursive method in Algorithm 2.5 that keeps track of the current character, adapt the 3-way partitioning code to use that character, and appropriately modify the recursive calls. Although it does the computation in a different order, 3-way string quicksort amounts to sorting the array on the leading characters of the keys (using quicksort), then applying the method recursively on the remainder of the keys. For sorting strings, the method compares favorably with normal quicksort and with MSD string sort. Indeed, it is a hybrid of these two algorithms. Three-way string quicksort divides the array into only three parts, so it involves more data movement than MSD string sort when the number of nonempty partitions is large because it has to do a series of 3-way partitions to get the effect of the multiway partition. On the other hand, MSD string sort can create large numbers of (empty) sub- arrays, whereas 3-way string quicksort always has just three. Thus, 3-way string quicksort adapts well to handling equal keys, keys with long common pre&#64257; xes, keys that fall into a small range, and small arrays&#8212; all situations where MSD string sort runs slowly. Of particular importance is that the</p><p attribs="{'xml:space': 'preserve'}" id="_12361" smilref="Title.smil#_12361"> edu.princeton.cs com.apple edu.princeton.cs com.cnn com.google edu.uva.cs edu.princeton.cs edu.princeton.cs.www edu.uva.cs edu.uva.cs edu.uva.cs com.adobe edu.princeton.ee</p><p attribs="{'xml:space': 'preserve'}" id="_12362" smilref="Title.smil#_12362"> com.adobe com.apple com.cnn com.google edu.princeton.cs edu.princeton.cs edu.princeton.cs edu.princeton.cs.www edu.princeton.ee edu.uva.cs edu.uva.cs edu.uva.cs edu.uva.cs</p><p attribs="{'xml:space': 'preserve'}" id="_12363" smilref="Title.smil#_12363"> long prefix match</p><p attribs="{'xml:space': 'preserve'}" id="_12364" smilref="Title.smil#_12364"> duplicate keys</p><p attribs="{'xml:space': 'preserve'}" id="_12365" smilref="Title.smil#_12365"> input</p><p attribs="{'xml:space': 'preserve'}" id="_12366" smilref="Title.smil#_12366"> sorted result</p><p attribs="{'xml:space': 'preserve'}" id="_12367" smilref="Title.smil#_12367"> Typical 3-way string quicksort candidate</p><p attribs="{'xml:space': 'preserve'}" id="_12368" smilref="Title.smil#_12368"> v v v . . . v v</p><p attribs="{'xml:space': 'preserve'}" id="_12369" smilref="Title.smil#_12369"> Overview of 3-way string quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_12370" smilref="Title.smil#_12370" /><pagenum id="p733" page="normal" smilref="Title.smil#p733" /><p attribs="{'xml:space': 'preserve'}" id="_12371" smilref="Title.smil#_12371"> 720</p><p attribs="{'xml:space': 'preserve'}" id="_12372" smilref="Title.smil#_12372"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12373" smilref="Title.smil#_12373"> ALGORITHM 5.3 Three-way string quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_12374" smilref="Title.smil#_12374"> public class Quick3string {</p><p attribs="{'xml:space': 'preserve'}" id="_12375" smilref="Title.smil#_12375"> private static int charAt(String s, int d) { if (d &lt; s.length()) return s.charAt(d); else return -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_12376" smilref="Title.smil#_12376"> public static void sort(String[] a) { sort(a, 0, a.length - 1, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_12377" smilref="Title.smil#_12377"> private static void sort(String[] a, int lo, int hi, int d) { if (hi &lt;= lo) return;</p><p attribs="{'xml:space': 'preserve'}" id="_12378" smilref="Title.smil#_12378"> int lt = lo, gt = hi; int v = charAt(a[lo], d); int i = lo + 1; while (i &lt;= gt) { int t = charAt(a[i], d); if (t &lt; v) exch(a, lt++, i++); else if (t &gt; v) exch(a, i, gt--); else i++; }</p><p attribs="{'xml:space': 'preserve'}" id="_12379" smilref="Title.smil#_12379"> // a[lo..lt-1] &lt; v = a[lt..gt] &lt; a[gt+1..hi]</p><p attribs="{'xml:space': 'preserve'}" id="_12380" smilref="Title.smil#_12380"> sort(a, lo, lt-1, d); if (v &gt;= 0) sort(a, lt, gt, d+1); sort(a, gt+1, hi, d); }</p><p attribs="{'xml:space': 'preserve'}" id="_12381" smilref="Title.smil#_12381"> }</p><p attribs="{'xml:space': 'preserve'}" id="_12382" smilref="Title.smil#_12382"> To sort an array a[] of strings, we 3-way partition them on their first character, then (recursively) sort the three resulting subarrays: the strings whose first character is less than the partitioning character, the strings whose first character is equal to the partitioning character (excluding their first character in the sort), and the strings whose first character is greater than the partitioning character.</p><p attribs="{'xml:space': 'preserve'}" id="_12383" smilref="Title.smil#_12383" /><pagenum id="p734" page="normal" smilref="Title.smil#p734" /><p attribs="{'xml:space': 'preserve'}" id="_12384" smilref="Title.smil#_12384"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12385" smilref="Title.smil#_12385"> 721</p><p attribs="{'xml:space': 'preserve'}" id="_12386" smilref="Title.smil#_12386"> partitioning adapts to different kinds of structure in different parts of the key. Also, like quicksort, 3-way string quicksort does not use extra space (other than the implicit stack to support recursion), which is an important advantage over MSD string sort, which requires space for both frequency counts and an auxiliary array. The figure at the bottom of this page shows all of the recursive calls that Quick3string makes for our example. Each subarray is sorted using precisely three recursive calls, except when we skip the recursive call on reaching the ends of the (equal) string(s) in the middle subarray. As usual, in practice, it is worthwhile to consider various standard improvements to the implementation in Algorithm 5.3: Small subarrays. In any recursive algorithm, we can gain efficiency by treating small subarrays differently. In this case, we use the insertion sort from page 715, which skips the characters that are known to be equal. The improvement due to this change is likely to be signi&#64257; cant, though not nearly as important as for MSD string sort. Restricted alphabet. To handle specialized alphabets, we could add an Alphabet argument alpha to each of the methods and replace s.charAt(d) with alpha.toIndex(s.charAt(d)) in charAt(). In this case, there is no benefit to doing so, and adding this code is likely to substantially slow the algorithm down because this code is in the inner loop.</p><p attribs="{'xml:space': 'preserve'}" id="_12387" smilref="Title.smil#_12387"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12388" smilref="Title.smil#_12388"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12389" smilref="Title.smil#_12389"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12390" smilref="Title.smil#_12390"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_12391" smilref="Title.smil#_12391"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_12392" smilref="Title.smil#_12392"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_12393" smilref="Title.smil#_12393"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_12394" smilref="Title.smil#_12394"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_12395" smilref="Title.smil#_12395"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_12396" smilref="Title.smil#_12396"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_12397" smilref="Title.smil#_12397"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_12398" smilref="Title.smil#_12398"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_12399" smilref="Title.smil#_12399"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_12400" smilref="Title.smil#_12400"> 13</p><p attribs="{'xml:space': 'preserve'}" id="_12401" smilref="Title.smil#_12401"> she sells seashells by the sea shore the shells she sells are surely seashells</p><p attribs="{'xml:space': 'preserve'}" id="_12402" smilref="Title.smil#_12402"> by are seashells she seashells sea shore surely shells she sells sells the the</p><p attribs="{'xml:space': 'preserve'}" id="_12403" smilref="Title.smil#_12403"> are by seashells sells seashells sea sells shells she surely shore she the the</p><p attribs="{'xml:space': 'preserve'}" id="_12404" smilref="Title.smil#_12404"> are by sea shells sea sea shells sel ls sel ls she she lls she sho re surely the the</p><p attribs="{'xml:space': 'preserve'}" id="_12405" smilref="Title.smil#_12405"> gray bars represent empty subarrays</p><p attribs="{'xml:space': 'preserve'}" id="_12406" smilref="Title.smil#_12406"> two more passes to reach end</p><p attribs="{'xml:space': 'preserve'}" id="_12407" smilref="Title.smil#_12407"> sea seashells  seashells  sell s sell s she she shells  shore</p><p attribs="{'xml:space': 'preserve'}" id="_12408" smilref="Title.smil#_12408"> sea seashells  seashells  sells sells</p><p attribs="{'xml:space': 'preserve'}" id="_12409" smilref="Title.smil#_12409"> shells</p><p attribs="{'xml:space': 'preserve'}" id="_12410" smilref="Title.smil#_12410"> the the</p><p attribs="{'xml:space': 'preserve'}" id="_12411" smilref="Title.smil#_12411"> the the</p><p attribs="{'xml:space': 'preserve'}" id="_12412" smilref="Title.smil#_12412"> seashells  seashells  sells sells</p><p attribs="{'xml:space': 'preserve'}" id="_12413" smilref="Title.smil#_12413"> seashell s seashell s sells sells</p><p attribs="{'xml:space': 'preserve'}" id="_12414" smilref="Title.smil#_12414"> no recursive calls (end of string)</p><p attribs="{'xml:space': 'preserve'}" id="_12415" smilref="Title.smil#_12415"> Trace of recursive calls for 3-way string quicksort (no cutoff for small subarrays)</p><p attribs="{'xml:space': 'preserve'}" id="_12416" smilref="Title.smil#_12416" /><pagenum id="p735" page="normal" smilref="Title.smil#p735" /><p attribs="{'xml:space': 'preserve'}" id="_12417" smilref="Title.smil#_12417"> 722</p><p attribs="{'xml:space': 'preserve'}" id="_12418" smilref="Title.smil#_12418"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12419" smilref="Title.smil#_12419"> Randomization. As with any quicksort, it is generally worthwhile to shuffle the array beforehand or to use a random paritioning item by swapping the first item with a random one. The primary reason to do so is to protect against worst-case performance in the case that the array is already sorted or nearly sorted.</p><p attribs="{'xml:space': 'preserve'}" id="_12420" smilref="Title.smil#_12420"> For string keys, standard quicksort and all the other sorts in Chapter 2 are actually MSD string sorts, because the compareTo() method in String accesses the characters in left-to-right order. That is, compareTo() accesses only the leading characters if they are different, the leading two characters if the first characters are the same and the second different, and so forth. For example, if the first characters of the strings are all different, the standard sorts will examine just those characters, thus automatically realizing some of the same performance gain that we seek in MSD string sorting. The essential idea behind 3-way quicksort is to take special action when the leading characters are equal. Indeed, one way to think of Algorithm 5.3 is as a way for standard quicksort to keep track of leading characters that are known to be equal. In the small subarrays, where most of the compares in the sort are done, the strings are likely to have numerous equal leading characters. The standard algorithm has to scan over all those characters for each compare; the 3-way algorithm avoids doing so.</p><p attribs="{'xml:space': 'preserve'}" id="_12421" smilref="Title.smil#_12421"> Performance. Consider a case where the string keys are long (and are all the same length, for simplicity), but most of the leading characters are equal. In such a situa- tion, the running time of standard quicksort is proportional to the string length times 2N ln N, whereas the running time of 3-way string quicksort is proportional to N times the string length (to discover all the leading equal characters) plus 2N ln N character comparisons (to do the sort on the remaining short keys). That is, 3-way string quick- sort requires up to a factor of 2 ln N fewer character compares than normal quicksort. It is not unusual for keys in practical sorting applications to have characteristics similar to this artificial example.</p><p attribs="{'xml:space': 'preserve'}" id="_12422" smilref="Title.smil#_12422" /><pagenum id="p736" page="normal" smilref="Title.smil#p736" /><p attribs="{'xml:space': 'preserve'}" id="_12423" smilref="Title.smil#_12423"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12424" smilref="Title.smil#_12424"> 723</p><p attribs="{'xml:space': 'preserve'}" id="_12425" smilref="Title.smil#_12425"> Proposition E. To sort an array of N random strings, 3-way string quicksort uses ~ 2N ln N character compares, on the average.</p><p attribs="{'xml:space': 'preserve'}" id="_12426" smilref="Title.smil#_12426"> Proof : There are two instructive ways to understand this result. First, considering the method to be equivalent to quicksort partitioning on the leading char- acter, then (recursively) using the same method on the subarrays, we should not be surprised that the total number of operations is about the same as for normal quicksort&#8212;but they are single-character compares, not full-key compares. Second, considering the method as replacing key-indexed counting by quicksort, we expect that the N log R N running time from Proposition D should be multiplied by a factor of 2 ln R because it takes quicksort 2R ln R steps to sort R characters, as opposed to R steps for the same characters in the MSD string sort. We omit the full proof.</p><p attribs="{'xml:space': 'preserve'}" id="_12427" smilref="Title.smil#_12427"> As emphasized on page 716, considering random strings is instructive, but more detailed analysis is needed to predict performance for practical situations. Researchers have studied this algorithm in depth and have proved that no algorithm can beat 3-way string quicksort (measured by number of character compares) by more than a constant factor, under very general assumptions. To appreciate its versatility, note that 3-way string quicksort has no direct dependencies on the size of the alphabet.</p><p attribs="{'xml:space': 'preserve'}" id="_12428" smilref="Title.smil#_12428"> Example: web logs. As an example where 3-way string quicksort shines, we can consider a typical modern data-processing task. Suppose that you have built a website and want to analyze the traffic that it generates. You can have your system administrator supply you with a web log of all transactions on your site. Among the information associated with a transaction is the domain name of the originating machine. For example, the file week.log.txt on the booksite is a log of one week&#8217;s transactions on our book- site. Why does 3-way string quicksort do well on such a fi le? Because the sorted result is replete with long common prefixes that this method does not have to reexamine.</p><p attribs="{'xml:space': 'preserve'}" id="_12429" smilref="Title.smil#_12429" /><pagenum id="p737" page="normal" smilref="Title.smil#p737" /><p attribs="{'xml:space': 'preserve'}" id="_12430" smilref="Title.smil#_12430"> 724</p><p attribs="{'xml:space': 'preserve'}" id="_12431" smilref="Title.smil#_12431"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12432" smilref="Title.smil#_12432"> Which string-sorting algorithm should I use? Naturally, we are interested</p><p attribs="{'xml:space': 'preserve'}" id="_12433" smilref="Title.smil#_12433"> in how the string-sorting methods that we have considered compare to the general- purpose methods that we considered in Chapter 2. The following table summarizes the important characteristics of the string-sort algorithms that we have discussed in this section (the rows for quicksort, mergesort, and 3-way quicksort are included from Chapter 2, for comparison).</p><p attribs="{'xml:space': 'preserve'}" id="_12434" smilref="Title.smil#_12434"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_12435" smilref="Title.smil#_12435"> stable?</p><p attribs="{'xml:space': 'preserve'}" id="_12436" smilref="Title.smil#_12436"> inplace?</p><p attribs="{'xml:space': 'preserve'}" id="_12437" smilref="Title.smil#_12437"> order of growth of typical number calls to charAt() to sort N strings from an R-character alphabet (average length w, max length W)</p><p attribs="{'xml:space': 'preserve'}" id="_12438" smilref="Title.smil#_12438"> running time</p><p attribs="{'xml:space': 'preserve'}" id="_12439" smilref="Title.smil#_12439"> extra space</p><p attribs="{'xml:space': 'preserve'}" id="_12440" smilref="Title.smil#_12440"> sweet spot</p><p attribs="{'xml:space': 'preserve'}" id="_12441" smilref="Title.smil#_12441"> small arrays, arrays in order general-purpose when space is tight general-purpose stable sort large numbers of equal keys short fi xed-length strings</p><p attribs="{'xml:space': 'preserve'}" id="_12442" smilref="Title.smil#_12442"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12443" smilref="Title.smil#_12443"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_12444" smilref="Title.smil#_12444"> N</p><p attribs="{'xml:space': 'preserve'}" id="_12445" smilref="Title.smil#_12445"> log N</p><p attribs="{'xml:space': 'preserve'}" id="_12446" smilref="Title.smil#_12446"> N</p><p attribs="{'xml:space': 'preserve'}" id="_12447" smilref="Title.smil#_12447"> N + WR</p><p attribs="{'xml:space': 'preserve'}" id="_12448" smilref="Title.smil#_12448"> random strings</p><p attribs="{'xml:space': 'preserve'}" id="_12449" smilref="Title.smil#_12449"> W + log N</p><p attribs="{'xml:space': 'preserve'}" id="_12450" smilref="Title.smil#_12450"> general-purpose, strings with long prefix  matches</p><p attribs="{'xml:space': 'preserve'}" id="_12451" smilref="Title.smil#_12451"> insertion sort for strings</p><p attribs="{'xml:space': 'preserve'}" id="_12452" smilref="Title.smil#_12452"> quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_12453" smilref="Title.smil#_12453"> mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_12454" smilref="Title.smil#_12454"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12455" smilref="Title.smil#_12455"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12456" smilref="Title.smil#_12456"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12457" smilref="Title.smil#_12457"> 3-way quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_12458" smilref="Title.smil#_12458"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12459" smilref="Title.smil#_12459"> LSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12460" smilref="Title.smil#_12460"> MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_12461" smilref="Title.smil#_12461"> 3-way string quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_12462" smilref="Title.smil#_12462"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12463" smilref="Title.smil#_12463"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12464" smilref="Title.smil#_12464"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12465" smilref="Title.smil#_12465"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12466" smilref="Title.smil#_12466"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12467" smilref="Title.smil#_12467"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12468" smilref="Title.smil#_12468"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12469" smilref="Title.smil#_12469"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12470" smilref="Title.smil#_12470"> no</p><p attribs="{'xml:space': 'preserve'}" id="_12471" smilref="Title.smil#_12471"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_12472" smilref="Title.smil#_12472"> between N and N 2</p><p attribs="{'xml:space': 'preserve'}" id="_12473" smilref="Title.smil#_12473"> N log 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_12474" smilref="Title.smil#_12474"> N log 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_12475" smilref="Title.smil#_12475"> between N and N log N</p><p attribs="{'xml:space': 'preserve'}" id="_12476" smilref="Title.smil#_12476"> NW</p><p attribs="{'xml:space': 'preserve'}" id="_12477" smilref="Title.smil#_12477"> between N and Nw</p><p attribs="{'xml:space': 'preserve'}" id="_12478" smilref="Title.smil#_12478"> between N and Nw</p><p attribs="{'xml:space': 'preserve'}" id="_12479" smilref="Title.smil#_12479"> Performance characteristics of string-sorting algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_12480" smilref="Title.smil#_12480"> As in Chapter 2, multiplying these growth rates by appropriate algorithm- and data- dependent constants gives an effective way to predict running time. As explored in the examples that we have already considered and in many other examples in the exercises, different specific situations call for different methods, with appropriate parameter settings. In the hands of an expert (maybe that&#8217;s you, by now), dramatic savings can be realized for certain situations.</p><p attribs="{'xml:space': 'preserve'}" id="_12481" smilref="Title.smil#_12481" /><pagenum id="p738" page="normal" smilref="Title.smil#p738" /><p attribs="{'xml:space': 'preserve'}" id="_12482" smilref="Title.smil#_12482"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12483" smilref="Title.smil#_12483"> 725</p><p attribs="{'xml:space': 'preserve'}" id="_12484" smilref="Title.smil#_12484"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_12485" smilref="Title.smil#_12485"> Q. Does the Java system sort use one of these methods for String sorts? A. No, but the standard implementation includes a fast string compare that makes standard sorts competitive with the methods considered here. Q. So, I should just use the system sort for String keys? A. Probably yes in Java, though if you have huge numbers of strings or need an exceptionally fast sort, you may wish to switch to char arrays instead of String values and use a radix sort. Q. What is explanation of the log2 N factors on the table in the previous page? A. They reflect the idea that most of the comparisons for these algorithms wind up being between keys with a common prefix of length log N. Recent research has established this fact for random strings with careful mathematical analysis (see booksite for reference).</p><p attribs="{'xml:space': 'preserve'}" id="_12486" smilref="Title.smil#_12486" /><pagenum id="p739" page="normal" smilref="Title.smil#p739" /><p attribs="{'xml:space': 'preserve'}" id="_12487" smilref="Title.smil#_12487"> 726</p><p attribs="{'xml:space': 'preserve'}" id="_12488" smilref="Title.smil#_12488"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12489" smilref="Title.smil#_12489"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_12490" smilref="Title.smil#_12490"> 5.1.1 Develop a sort implementation that counts the number of different key values, then uses a symbol table to apply key-indexed counting to sort the array. (This method is not for use when the number of different key values is large.) 5.1.2 Give a trace for LSD string sort for the keys</p><p attribs="{'xml:space': 'preserve'}" id="_12491" smilref="Title.smil#_12491"> no is th ti fo al go pe to co to th ai of th pa</p><p attribs="{'xml:space': 'preserve'}" id="_12492" smilref="Title.smil#_12492"> 5.1.3 Give a trace for MSD string sort for the keys</p><p attribs="{'xml:space': 'preserve'}" id="_12493" smilref="Title.smil#_12493"> no is th ti fo al go pe to co to th ai of th pa</p><p attribs="{'xml:space': 'preserve'}" id="_12494" smilref="Title.smil#_12494"> 5.1.4 Give a trace for 3-way string quicksort for the keys</p><p attribs="{'xml:space': 'preserve'}" id="_12495" smilref="Title.smil#_12495"> no is th ti fo al go pe to co to th ai of th pa</p><p attribs="{'xml:space': 'preserve'}" id="_12496" smilref="Title.smil#_12496"> 5.1.5 Give a trace for MSD string sort for the keys</p><p attribs="{'xml:space': 'preserve'}" id="_12497" smilref="Title.smil#_12497"> now is the time for all good people to come to the aid of</p><p attribs="{'xml:space': 'preserve'}" id="_12498" smilref="Title.smil#_12498"> 5.1.6 Give a trace for 3-way string quicksort for the keys</p><p attribs="{'xml:space': 'preserve'}" id="_12499" smilref="Title.smil#_12499"> now is the time for all good people to come to the aid of</p><p attribs="{'xml:space': 'preserve'}" id="_12500" smilref="Title.smil#_12500"> 5.1.7 Develop an implementation of key-indexed counting that makes use of an array of Queue objects. 5.1.8 Give the number of characters examined by MSD string sort and 3-way string quicksort for a file of N keys a, aa, aaa, aaaa, aaaaa, . . . 5.1.9 Develop an implementation of LSD string sort that works for variable-length strings. 5.1.10 What is the total number of characters examined by 3-way string quicksort when sorting N fi xed-length strings (all of length W), in the worst case?</p><p attribs="{'xml:space': 'preserve'}" id="_12501" smilref="Title.smil#_12501" /><pagenum id="p740" page="normal" smilref="Title.smil#p740" /><p attribs="{'xml:space': 'preserve'}" id="_12502" smilref="Title.smil#_12502"> 5.1 </p><p attribs="{'xml:space': 'preserve'}" id="_12503" smilref="Title.smil#_12503"> 727</p><p attribs="{'xml:space': 'preserve'}" id="_12504" smilref="Title.smil#_12504"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_12505" smilref="Title.smil#_12505"> 5.1.11 Queue sort. Implement MSD string sorting using queues, as follows: Keep one queue for each bin. On a first pass through the items to be sorted, insert each item into the appropriate queue, according to its leading character value. Then, sort the sublists and stitch together all the queues to make a sorted whole. Note that this method does not involve keeping the count[] arrays within the recursive method. 5.1.12 Alphabet. Develop an implementation of the Alphabet API that is given on page 698 and use it to develop LSD and MSD sorts for general alphabets. 5.1.13 Hybrid sort. Investigate the idea of using standard MSD string sort for large ar- rays, in order to get the advantage of multiway partitioning, and 3-way string quicksort for smaller arrays, in order to avoid the negative effects of large numbers of empty bins. 5.1.14 Array sort. Develop a method that uses 3-way string quicksort for keys that are arrays of int values. 5.1.15 Sublinear sort. Develop a sort implementation for int values that makes two passes through the array to do an LSD sort on the leading 16 bits of the keys, then does an insertion sort. 5.1.16 Linked-list sort. Develop a sort implementation that takes a linked list of nodes with String key values as argument and rearranges the nodes so that they appear in sorted order (returning a link to the node with the smallest key). Use 3-way string quicksort. 5.1.17 In-place key-indexed counting. Develop a version of key-indexed counting that uses only a constant amount of extra space. Prove that your version is stable or provide a counterexample.</p><p attribs="{'xml:space': 'preserve'}" id="_12506" smilref="Title.smil#_12506" /><pagenum id="p741" page="normal" smilref="Title.smil#p741" /><p attribs="{'xml:space': 'preserve'}" id="_12507" smilref="Title.smil#_12507"> 728</p><p attribs="{'xml:space': 'preserve'}" id="_12508" smilref="Title.smil#_12508"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12509" smilref="Title.smil#_12509"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_12510" smilref="Title.smil#_12510"> 5.1.18 Random decimal keys. Write a static method randomDecimalKeys that takes int values N and W as arguments and returns an array of N string values that are each W-digit decimal numbers. 5.1.19 Random CA license plates. Write a static method randomPlatesCA that takes an int value N as argument and returns an array of N String values that represent CA license plates as in the examples in this section. 5.1.20 Random fi xed-length words. Write a static method randomFixedLengthWords that takes int values N and W as arguments and returns an array of N string values that are each strings of W characters from the alphabet. 5.1.21 Random items. Write a static method randomItems that takes an int value N as argument and returns an array of N string values that are each strings of length between 15 and 30 made up of three fi elds: a 4-character field with one of a set of 10 fixed strings; a 10-char field with one of a set of 50 fixed strings; a 1-character field with one of two given values; and a 15-byte field with random left-justi&#64257; ed strings of letters equally likely to be 4 through 15 characters long. 5.1.22 Timings. Compare the running times of MSD string sort and 3-way string quicksort, using various key generators. For fi xed-length keys, include LSD string sort. 5.1.23 Array accesses. Compare the number of array accesses used by MSD string sort and 3-way string sort, using various key generators. For fi xed-length keys, include LSD string sort. 5.1.24 Rightmost character accessed. Compare the position of the rightmost character accessed for MSD string sort and 3-way string quicksort, using various key generators.</p><p attribs="{'xml:space': 'preserve'}" id="_12511" smilref="Title.smil#_12511" /><pagenum id="p742" page="normal" smilref="Title.smil#p742" /><p attribs="{'xml:space': 'preserve'}" id="_12512" smilref="Title.smil#_12512"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_12513" smilref="Title.smil#_12513" /><pagenum id="p744" page="normal" smilref="Title.smil#p744" /><p attribs="{'xml:space': 'preserve'}" id="_12514" smilref="Title.smil#_12514"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12515" smilref="Title.smil#_12515"> 731</p><p attribs="{'xml:space': 'preserve'}" id="_12516" smilref="Title.smil#_12516"> This API differs from the symbol-table API introduced in Chapter 3 in the following aspects: </p><p attribs="{'xml:space': 'preserve'}" id="_12517" smilref="Title.smil#_12517"> keysThatMatch().</p><p attribs="{'xml:space': 'preserve'}" id="_12518" smilref="Title.smil#_12518"> We retain the basic conventions of our symbol-table implementations in Chapter 3 (no duplicate or null keys and no null values). As we saw for sorting with string keys, it is often quite important to be able to work with strings from a specified alphabet. Simple and efficient implementations that are the method of choice for small alphabets turn out to be useless for large alphabets because they consume too much space. In such cases, it is certainly worthwhile to add a constructor that allows clients to specify the alphabet. We will consider the implementation of such a constructor later in this section but omit it from the API for now, in order to concentrate on string keys. The following descriptions of the three new methods use the keys she sells sea</p><p attribs="{'xml:space': 'preserve'}" id="_12519" smilref="Title.smil#_12519"> shells by the sea shore to give examples:</p><p attribs="{'xml:space': 'preserve'}" id="_12520" smilref="Title.smil#_12520"> </p><p attribs="{'xml:space': 'preserve'}" id="_12521" smilref="Title.smil#_12521"> longestPrefixOf("shell") is she and longestPrefixOf("shellsort") is shells.</p><p attribs="{'xml:space': 'preserve'}" id="_12522" smilref="Title.smil#_12522"> </p><p attribs="{'xml:space': 'preserve'}" id="_12523" smilref="Title.smil#_12523"> keysWithPrefix("she") is she and shells, and keysWithPrefix("se") is sells and sea.</p><p attribs="{'xml:space': 'preserve'}" id="_12524" smilref="Title.smil#_12524"> </p><p attribs="{'xml:space': 'preserve'}" id="_12525" smilref="Title.smil#_12525" /><pagenum id="p745" page="normal" smilref="Title.smil#p745" /><p attribs="{'xml:space': 'preserve'}" id="_12526" smilref="Title.smil#_12526"> 732</p><p attribs="{'xml:space': 'preserve'}" id="_12527" smilref="Title.smil#_12527"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12528" smilref="Title.smil#_12528"> Tries</p><p attribs="{'xml:space': 'preserve'}" id="_12529" smilref="Title.smil#_12529"> In this section, we consider a search tree known as a trie, a data structure built from the characters of the string keys that allows us to use the characters of the search key to guide the search. The name &#8220;trie&#8221; is a bit of wordplay introduced by E. Fredkin in 1960 because the data structure is used for retrieval, but we pronounce it &#8220;try&#8221; to avoid confusion with &#8220;tree.&#8221; We begin with a high-level description of the basic properties of tries, including search and insert algorithms, and then proceed to the details of the representation and Java implementation.</p><p attribs="{'xml:space': 'preserve'}" id="_12530" smilref="Title.smil#_12530"> Basic properties. As with search trees, tries are data structures composed of nodes that contain links that are either null or references to other nodes. Each node is pointed to by just one other node, which is called its parent (except for one node, the root, which has no nodes pointing to it), and each node has R links, where R is the alphabet size. Often, tries have a substantial number of null links, so when we draw a trie, we typically omit null links. Although links point to nodes, we can view each link as pointing to a trie, the trie whose root is the referenced node. Each link corresponds to a character value&#8212;since each link points to exactly one node, we label each node with the character value corresponding to the link that points to it (except for the root, which has no link pointing to it). Each node also has a corresponding value, which may be null or the value associated with one of the string keys in the symbol table. Speci&#64257; cally, we store the value associated with each key in the node corresponding to its last character. It is very important to bear in mind the following fact: nodes with null values exist to facilitate search in the trie and do not correspond to keys. An example of a trie is shown at right.</p><p attribs="{'xml:space': 'preserve'}" id="_12531" smilref="Title.smil#_12531"> key by sea sells she shells the</p><p attribs="{'xml:space': 'preserve'}" id="_12532" smilref="Title.smil#_12532"> value for she in node corresponding to last key character</p><p attribs="{'xml:space': 'preserve'}" id="_12533" smilref="Title.smil#_12533"> label each node with character associated with incoming link</p><p attribs="{'xml:space': 'preserve'}" id="_12534" smilref="Title.smil#_12534"> value 4 2 1 0 3 5</p><p attribs="{'xml:space': 'preserve'}" id="_12535" smilref="Title.smil#_12535"> link to trie for all keys that start with s</p><p attribs="{'xml:space': 'preserve'}" id="_12536" smilref="Title.smil#_12536"> link to trie for all keys that start with she</p><p attribs="{'xml:space': 'preserve'}" id="_12537" smilref="Title.smil#_12537"> Anatomy of a trie</p><p attribs="{'xml:space': 'preserve'}" id="_12538" smilref="Title.smil#_12538"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12539" smilref="Title.smil#_12539"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12540" smilref="Title.smil#_12540"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12541" smilref="Title.smil#_12541"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12542" smilref="Title.smil#_12542"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12543" smilref="Title.smil#_12543"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12544" smilref="Title.smil#_12544"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12545" smilref="Title.smil#_12545"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12546" smilref="Title.smil#_12546"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12547" smilref="Title.smil#_12547"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12548" smilref="Title.smil#_12548"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12549" smilref="Title.smil#_12549"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12550" smilref="Title.smil#_12550"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12551" smilref="Title.smil#_12551"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12552" smilref="Title.smil#_12552"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12553" smilref="Title.smil#_12553"> root</p><p attribs="{'xml:space': 'preserve'}" id="_12554" smilref="Title.smil#_12554"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12555" smilref="Title.smil#_12555"> Search in a trie. Finding the value associated with a given string key in a trie is a simple process, guided by the characters in the search key. Each node in the trie has a link corresponding to each possible string character. We start at the root, then follow the link associated with the first character in the key ; from that node we follow the link associated with the second character in the key ; from that node we follow the link associated with the third character in the key and</p><p attribs="{'xml:space': 'preserve'}" id="_12556" smilref="Title.smil#_12556" /><pagenum id="p746" page="normal" smilref="Title.smil#p746" /><p attribs="{'xml:space': 'preserve'}" id="_12557" smilref="Title.smil#_12557"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12558" smilref="Title.smil#_12558"> 733</p><p attribs="{'xml:space': 'preserve'}" id="_12559" smilref="Title.smil#_12559"> hits</p><p attribs="{'xml:space': 'preserve'}" id="_12560" smilref="Title.smil#_12560"> misses</p><p attribs="{'xml:space': 'preserve'}" id="_12561" smilref="Title.smil#_12561"> get("shells")</p><p attribs="{'xml:space': 'preserve'}" id="_12562" smilref="Title.smil#_12562"> get("shell")</p><p attribs="{'xml:space': 'preserve'}" id="_12563" smilref="Title.smil#_12563"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12564" smilref="Title.smil#_12564"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12565" smilref="Title.smil#_12565"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12566" smilref="Title.smil#_12566"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12567" smilref="Title.smil#_12567"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12568" smilref="Title.smil#_12568"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12569" smilref="Title.smil#_12569"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12570" smilref="Title.smil#_12570"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12571" smilref="Title.smil#_12571"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12572" smilref="Title.smil#_12572"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12573" smilref="Title.smil#_12573"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12574" smilref="Title.smil#_12574"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12575" smilref="Title.smil#_12575"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12576" smilref="Title.smil#_12576"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12577" smilref="Title.smil#_12577"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12578" smilref="Title.smil#_12578"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12579" smilref="Title.smil#_12579"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12580" smilref="Title.smil#_12580"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12581" smilref="Title.smil#_12581"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12582" smilref="Title.smil#_12582"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12583" smilref="Title.smil#_12583"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12584" smilref="Title.smil#_12584"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12585" smilref="Title.smil#_12585"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12586" smilref="Title.smil#_12586"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12587" smilref="Title.smil#_12587"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12588" smilref="Title.smil#_12588"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12589" smilref="Title.smil#_12589"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12590" smilref="Title.smil#_12590"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12591" smilref="Title.smil#_12591"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12592" smilref="Title.smil#_12592"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12593" smilref="Title.smil#_12593"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12594" smilref="Title.smil#_12594"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12595" smilref="Title.smil#_12595"> return the value in the node corresponding to the last key character</p><p attribs="{'xml:space': 'preserve'}" id="_12596" smilref="Title.smil#_12596"> the value in the node corresponding to the last key character is null, so return null</p><p attribs="{'xml:space': 'preserve'}" id="_12597" smilref="Title.smil#_12597"> get("she")</p><p attribs="{'xml:space': 'preserve'}" id="_12598" smilref="Title.smil#_12598"> get("shore")</p><p attribs="{'xml:space': 'preserve'}" id="_12599" smilref="Title.smil#_12599"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12600" smilref="Title.smil#_12600"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12601" smilref="Title.smil#_12601"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12602" smilref="Title.smil#_12602"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12603" smilref="Title.smil#_12603"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12604" smilref="Title.smil#_12604"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12605" smilref="Title.smil#_12605"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12606" smilref="Title.smil#_12606"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12607" smilref="Title.smil#_12607"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12608" smilref="Title.smil#_12608"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12609" smilref="Title.smil#_12609"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12610" smilref="Title.smil#_12610"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12611" smilref="Title.smil#_12611"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12612" smilref="Title.smil#_12612"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12613" smilref="Title.smil#_12613"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12614" smilref="Title.smil#_12614"> search may terminate at an internal node</p><p attribs="{'xml:space': 'preserve'}" id="_12615" smilref="Title.smil#_12615"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12616" smilref="Title.smil#_12616"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12617" smilref="Title.smil#_12617"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12618" smilref="Title.smil#_12618"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12619" smilref="Title.smil#_12619"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12620" smilref="Title.smil#_12620"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12621" smilref="Title.smil#_12621"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12622" smilref="Title.smil#_12622"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12623" smilref="Title.smil#_12623"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12624" smilref="Title.smil#_12624"> Trie search examples</p><p attribs="{'xml:space': 'preserve'}" id="_12625" smilref="Title.smil#_12625"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12626" smilref="Title.smil#_12626"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12627" smilref="Title.smil#_12627"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12628" smilref="Title.smil#_12628"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12629" smilref="Title.smil#_12629"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12630" smilref="Title.smil#_12630"> no link for the o, so return null</p><p attribs="{'xml:space': 'preserve'}" id="_12631" smilref="Title.smil#_12631"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12632" smilref="Title.smil#_12632"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12633" smilref="Title.smil#_12633"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12634" smilref="Title.smil#_12634"> so forth, until reaching the last character of the key or a null link. At this point, one of the following three conditions holds (refer to the figure above for examples): </p><p attribs="{'xml:space': 'preserve'}" id="_12635" smilref="Title.smil#_12635" /><pagenum id="p747" page="normal" smilref="Title.smil#p747" /><p attribs="{'xml:space': 'preserve'}" id="_12636" smilref="Title.smil#_12636"> 734</p><p attribs="{'xml:space': 'preserve'}" id="_12637" smilref="Title.smil#_12637"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12638" smilref="Title.smil#_12638"> Insertion into a trie. As with binary search trees, we insert by first doing a search: in a trie that means using the characters of the key to guide us down the trie until reaching the last character of the key or a null link. At this point, one of the following two conditions holds: </p><p attribs="{'xml:space': 'preserve'}" id="_12639" smilref="Title.smil#_12639"> she sells sea shells by the sea shore</p><p attribs="{'xml:space': 'preserve'}" id="_12640" smilref="Title.smil#_12640"> is shown on the facing page.</p><p attribs="{'xml:space': 'preserve'}" id="_12641" smilref="Title.smil#_12641"> Node representation. As mentioned at the outset, our trie diagrams do not quite correspond to the data structures our programs will build, because we do not draw null links. Taking null links into account emphasizes the following important characteristics of tries: </p><p attribs="{'xml:space': 'preserve'}" id="_12642" smilref="Title.smil#_12642"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12643" smilref="Title.smil#_12643"> a</p><p attribs="{'xml:space': 'preserve'}" id="_12644" smilref="Title.smil#_12644"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12645" smilref="Title.smil#_12645"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12646" smilref="Title.smil#_12646"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12647" smilref="Title.smil#_12647"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12648" smilref="Title.smil#_12648"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12649" smilref="Title.smil#_12649"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12650" smilref="Title.smil#_12650"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12651" smilref="Title.smil#_12651"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12652" smilref="Title.smil#_12652"> characters are implicitly defined by link index</p><p attribs="{'xml:space': 'preserve'}" id="_12653" smilref="Title.smil#_12653"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12654" smilref="Title.smil#_12654"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12655" smilref="Title.smil#_12655"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12656" smilref="Title.smil#_12656"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12657" smilref="Title.smil#_12657"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12658" smilref="Title.smil#_12658"> a</p><p attribs="{'xml:space': 'preserve'}" id="_12659" smilref="Title.smil#_12659"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12660" smilref="Title.smil#_12660"> Trie representation (R = 26)</p><p attribs="{'xml:space': 'preserve'}" id="_12661" smilref="Title.smil#_12661"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12662" smilref="Title.smil#_12662"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12663" smilref="Title.smil#_12663"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12664" smilref="Title.smil#_12664"> each node has an array of links and a value</p><p attribs="{'xml:space': 'preserve'}" id="_12665" smilref="Title.smil#_12665" /><pagenum id="p748" page="normal" smilref="Title.smil#p748" /><p attribs="{'xml:space': 'preserve'}" id="_12666" smilref="Title.smil#_12666"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12667" smilref="Title.smil#_12667"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12668" smilref="Title.smil#_12668"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12669" smilref="Title.smil#_12669"> Trie construction trace for standard indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_12670" smilref="Title.smil#_12670"> key</p><p attribs="{'xml:space': 'preserve'}" id="_12671" smilref="Title.smil#_12671"> value</p><p attribs="{'xml:space': 'preserve'}" id="_12672" smilref="Title.smil#_12672"> key</p><p attribs="{'xml:space': 'preserve'}" id="_12673" smilref="Title.smil#_12673"> value</p><p attribs="{'xml:space': 'preserve'}" id="_12674" smilref="Title.smil#_12674"> root</p><p attribs="{'xml:space': 'preserve'}" id="_12675" smilref="Title.smil#_12675"> one node for each key character</p><p attribs="{'xml:space': 'preserve'}" id="_12676" smilref="Title.smil#_12676"> value is in node corresponding to last character</p><p attribs="{'xml:space': 'preserve'}" id="_12677" smilref="Title.smil#_12677"> key is sequence of characters from root to value</p><p attribs="{'xml:space': 'preserve'}" id="_12678" smilref="Title.smil#_12678"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12679" smilref="Title.smil#_12679"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12680" smilref="Title.smil#_12680"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12681" smilref="Title.smil#_12681"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12682" smilref="Title.smil#_12682"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12683" smilref="Title.smil#_12683"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12684" smilref="Title.smil#_12684"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12685" smilref="Title.smil#_12685"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12686" smilref="Title.smil#_12686"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12687" smilref="Title.smil#_12687"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12688" smilref="Title.smil#_12688"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12689" smilref="Title.smil#_12689"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12690" smilref="Title.smil#_12690"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12691" smilref="Title.smil#_12691"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12692" smilref="Title.smil#_12692"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12693" smilref="Title.smil#_12693"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12694" smilref="Title.smil#_12694"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12695" smilref="Title.smil#_12695"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12696" smilref="Title.smil#_12696"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12697" smilref="Title.smil#_12697"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12698" smilref="Title.smil#_12698"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12699" smilref="Title.smil#_12699"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12700" smilref="Title.smil#_12700"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12701" smilref="Title.smil#_12701"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12702" smilref="Title.smil#_12702"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12703" smilref="Title.smil#_12703"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12704" smilref="Title.smil#_12704"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12705" smilref="Title.smil#_12705"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12706" smilref="Title.smil#_12706"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12707" smilref="Title.smil#_12707"> o</p><p attribs="{'xml:space': 'preserve'}" id="_12708" smilref="Title.smil#_12708"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12709" smilref="Title.smil#_12709"> e 7</p><p attribs="{'xml:space': 'preserve'}" id="_12710" smilref="Title.smil#_12710"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12711" smilref="Title.smil#_12711"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_12712" smilref="Title.smil#_12712"> she</p><p attribs="{'xml:space': 'preserve'}" id="_12713" smilref="Title.smil#_12713"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_12714" smilref="Title.smil#_12714"> sells</p><p attribs="{'xml:space': 'preserve'}" id="_12715" smilref="Title.smil#_12715"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_12716" smilref="Title.smil#_12716"> sea</p><p attribs="{'xml:space': 'preserve'}" id="_12717" smilref="Title.smil#_12717"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_12718" smilref="Title.smil#_12718"> shells</p><p attribs="{'xml:space': 'preserve'}" id="_12719" smilref="Title.smil#_12719"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12720" smilref="Title.smil#_12720"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12721" smilref="Title.smil#_12721"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12722" smilref="Title.smil#_12722"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12723" smilref="Title.smil#_12723"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12724" smilref="Title.smil#_12724"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12725" smilref="Title.smil#_12725"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12726" smilref="Title.smil#_12726"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12727" smilref="Title.smil#_12727"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12728" smilref="Title.smil#_12728"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12729" smilref="Title.smil#_12729"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12730" smilref="Title.smil#_12730"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12731" smilref="Title.smil#_12731"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12732" smilref="Title.smil#_12732"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_12733" smilref="Title.smil#_12733"> by</p><p attribs="{'xml:space': 'preserve'}" id="_12734" smilref="Title.smil#_12734"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12735" smilref="Title.smil#_12735"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12736" smilref="Title.smil#_12736"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12737" smilref="Title.smil#_12737"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12738" smilref="Title.smil#_12738"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12739" smilref="Title.smil#_12739"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12740" smilref="Title.smil#_12740"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12741" smilref="Title.smil#_12741"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12742" smilref="Title.smil#_12742"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12743" smilref="Title.smil#_12743"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12744" smilref="Title.smil#_12744"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12745" smilref="Title.smil#_12745"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12746" smilref="Title.smil#_12746"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12747" smilref="Title.smil#_12747"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12748" smilref="Title.smil#_12748"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12749" smilref="Title.smil#_12749"> e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12750" smilref="Title.smil#_12750"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12751" smilref="Title.smil#_12751"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12752" smilref="Title.smil#_12752"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12753" smilref="Title.smil#_12753"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12754" smilref="Title.smil#_12754"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12755" smilref="Title.smil#_12755"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12756" smilref="Title.smil#_12756"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12757" smilref="Title.smil#_12757"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12758" smilref="Title.smil#_12758"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12759" smilref="Title.smil#_12759"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12760" smilref="Title.smil#_12760"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12761" smilref="Title.smil#_12761"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12762" smilref="Title.smil#_12762"> a 6</p><p attribs="{'xml:space': 'preserve'}" id="_12763" smilref="Title.smil#_12763"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_12764" smilref="Title.smil#_12764"> the</p><p attribs="{'xml:space': 'preserve'}" id="_12765" smilref="Title.smil#_12765"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_12766" smilref="Title.smil#_12766"> sea</p><p attribs="{'xml:space': 'preserve'}" id="_12767" smilref="Title.smil#_12767"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12768" smilref="Title.smil#_12768"> h e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12769" smilref="Title.smil#_12769"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12770" smilref="Title.smil#_12770"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12771" smilref="Title.smil#_12771"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12772" smilref="Title.smil#_12772"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12773" smilref="Title.smil#_12773"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12774" smilref="Title.smil#_12774"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12775" smilref="Title.smil#_12775"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12776" smilref="Title.smil#_12776"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12777" smilref="Title.smil#_12777"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12778" smilref="Title.smil#_12778"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12779" smilref="Title.smil#_12779"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12780" smilref="Title.smil#_12780"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12781" smilref="Title.smil#_12781"> a 6</p><p attribs="{'xml:space': 'preserve'}" id="_12782" smilref="Title.smil#_12782"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_12783" smilref="Title.smil#_12783"> shore</p><p attribs="{'xml:space': 'preserve'}" id="_12784" smilref="Title.smil#_12784"> node corresponding to the last key character exists, so reset its value</p><p attribs="{'xml:space': 'preserve'}" id="_12785" smilref="Title.smil#_12785"> nodes corresponding to characters at the end of the key do not exist, so create them and set the value of the last one</p><p attribs="{'xml:space': 'preserve'}" id="_12786" smilref="Title.smil#_12786"> 735</p><p attribs="{'xml:space': 'preserve'}" id="_12787" smilref="Title.smil#_12787"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12788" smilref="Title.smil#_12788" /><pagenum id="p749" page="normal" smilref="Title.smil#p749" /><p attribs="{'xml:space': 'preserve'}" id="_12789" smilref="Title.smil#_12789"> 736</p><p attribs="{'xml:space': 'preserve'}" id="_12790" smilref="Title.smil#_12790"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12791" smilref="Title.smil#_12791"> Keys in the trie are implicitly represented by paths from the root that end at nodes with non-null values. For example, the string sea is associated with the value 2 in the trie because the 19th link in the root (which points to the trie for all keys that start with s) is not null and the 5th link in the node that link refers to (which points to the trie for all keys that start with se) is not null, and the first link in the node that link refers to (which points to the trie for all keys that starts with sea) has the value 2. Neither the string sea nor the characters s, e, and a are stored in the data structure. Indeed, the data structure contains no characters or strings, just links and values. Since the parameter R plays such a critical role, we refer to a trie for an R-character alphabet as an R-way trie.</p><p attribs="{'xml:space': 'preserve'}" id="_12792" smilref="Title.smil#_12792"> With these preparations, the symbol-table implementation TrieST on the facing page is straightforward. It uses recursive methods like those that we used for search trees in Chapter 3, based on a private Node class with instance variable val for client values and an array next[] of Node references. The methods are compact recursive implementations that are worthy of careful study. Next, we discuss implementations of the constructor that takes an Alphabet as argument and the methods size(), keys(),</p><p attribs="{'xml:space': 'preserve'}" id="_12793" smilref="Title.smil#_12793"> longestPrefixOf(), keysWithPrefix(), keysThatMatch(), and delete(). These</p><p attribs="{'xml:space': 'preserve'}" id="_12794" smilref="Title.smil#_12794"> are also easily understood recursive methods, each slightly more complicated than the last. Size. As for the binary search trees of Chapter 3, three straightforward options are available for implementing size(): </p><p attribs="{'xml:space': 'preserve'}" id="_12795" smilref="Title.smil#_12795"> delete().</p><p attribs="{'xml:space': 'preserve'}" id="_12796" smilref="Title.smil#_12796"> </p><p attribs="{'xml:space': 'preserve'}" id="_12797" smilref="Title.smil#_12797"> public int size() { return size(root); }</p><p attribs="{'xml:space': 'preserve'}" id="_12798" smilref="Title.smil#_12798"> private int size(Node x) { if (x == null) return 0;</p><p attribs="{'xml:space': 'preserve'}" id="_12799" smilref="Title.smil#_12799"> int cnt = 0; if (x.val != null) cnt++; for (char c = 0; c &lt; R; c++) cnt += size(next[c]);</p><p attribs="{'xml:space': 'preserve'}" id="_12800" smilref="Title.smil#_12800"> return cnt; }</p><p attribs="{'xml:space': 'preserve'}" id="_12801" smilref="Title.smil#_12801"> Lazy recursive size() for tries</p><p attribs="{'xml:space': 'preserve'}" id="_12802" smilref="Title.smil#_12802" /></level3><level3 id="_00101"><h3 id="ch5-s2-ss5" smilref="Title.smil#ch5-s2-ss5" xml:space="preserve">String symbol table API</h3><pagenum id="p750" page="normal" smilref="Title.smil#p750" /><p attribs="{'xml:space': 'preserve'}" id="_12803" smilref="Title.smil#_12803"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12804" smilref="Title.smil#_12804"> 737</p><p attribs="{'xml:space': 'preserve'}" id="_12805" smilref="Title.smil#_12805"> ALGORITHM 5.4 Trie symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_12806" smilref="Title.smil#_12806"> public class TrieST&lt;Value&gt; { private static int R = 256; // radix private Node root; // root of trie</p><p attribs="{'xml:space': 'preserve'}" id="_12807" smilref="Title.smil#_12807"> private static class Node { private Object val; private Node[] next = new Node[R]; }</p><p attribs="{'xml:space': 'preserve'}" id="_12808" smilref="Title.smil#_12808"> public Value get(String key) { Node x = get(root, key, 0); if (x == null) return null; return (Value) x.val; }</p><p attribs="{'xml:space': 'preserve'}" id="_12809" smilref="Title.smil#_12809"> private Node get(Node x, String key, int d) { // Return value associated with key in the subtrie rooted at x. if (x == null) return null; if (d == key.length()) return x; char c = key.charAt(d); // Use dth key char to identify subtrie. return get(x.next[c], key, d+1); }</p><p attribs="{'xml:space': 'preserve'}" id="_12810" smilref="Title.smil#_12810"> public void put(String key, Value val) { root = put(root, key, val, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_12811" smilref="Title.smil#_12811"> private Node put(Node x, String key, Value val, int d) { // Change value associated with key if in subtrie rooted at x. if (x == null) x = new Node(); if (d == key.length()) { x.val = val; return x; } char c = key.charAt(d); // Use dth key char to identify subtrie. x.next[c] = put(x.next[c], key, val, d+1); return x; } }</p><p attribs="{'xml:space': 'preserve'}" id="_12812" smilref="Title.smil#_12812"> This code uses an R-way trie to implement a symbol table. Additional methods in the string symbol- table API of page 730 are presented in the next several pages. Modifying this code to handle keys from specialized alphabets is straighforward (see page 740). The value in Node has to be an Object because Java does not support arrays of generics; we cast values back to Value in get().</p><p attribs="{'xml:space': 'preserve'}" id="_12813" smilref="Title.smil#_12813" /><pagenum id="p751" page="normal" smilref="Title.smil#p751" /><p attribs="{'xml:space': 'preserve'}" id="_12814" smilref="Title.smil#_12814"> 738</p><p attribs="{'xml:space': 'preserve'}" id="_12815" smilref="Title.smil#_12815"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12816" smilref="Title.smil#_12816"> public Iterable&lt;String&gt; keys() { return keysWithPrefix(""); }</p><p attribs="{'xml:space': 'preserve'}" id="_12817" smilref="Title.smil#_12817"> Collecting keys. Because characters and keys are represented implicitly in tries, providing clients with the ability to iterate through the keys presents a challenge. As with binary search trees, we accumulate the string keys in a Queue, but for tries we need to create explicit representations of all of the string keys, not just find them in the data structure. We do so with a recursive private method collect() that is similar to size() but also maintains a string with the sequence of characters on the path from the root. Each time that we visit a node via a call to collect() with that node as first argument, the second argument is the string associated with that node (the sequence of characters on the path from the root to the node). To visit a node, we add its associated string to the queue if its value is not null, then visit (recursively) all the nodes in its array of links, one for each possible character. To create the key for each call, we append the character corresponding to the link to the current key. We use this collect() method to collect keys for both the keys() and</p><p attribs="{'xml:space': 'preserve'}" id="_12818" smilref="Title.smil#_12818"> private void collect(Node x, String pre, Queue&lt;String&gt; q) { if (x == null) return; if (x.val != null) q.enqueue(pre); for (char c = 0; c &lt; R; c++) collect(x.next[c], pre + c, q); }</p><p attribs="{'xml:space': 'preserve'}" id="_12819" smilref="Title.smil#_12819"> public Iterable&lt;String&gt; keysWithPrefix(String pre) { Queue&lt;String&gt; q = new Queue&lt;String&gt;(); collect(get(root, pre, 0), pre, q); return q; }</p><p attribs="{'xml:space': 'preserve'}" id="_12820" smilref="Title.smil#_12820"> Collecting the keys in a trie</p><p attribs="{'xml:space': 'preserve'}" id="_12821" smilref="Title.smil#_12821"> keysWithPrefix("");</p><p attribs="{'xml:space': 'preserve'}" id="_12822" smilref="Title.smil#_12822"> key b by s se sea sel sell sells sh she shell shells sho shor shore t th the</p><p attribs="{'xml:space': 'preserve'}" id="_12823" smilref="Title.smil#_12823"> q</p><p attribs="{'xml:space': 'preserve'}" id="_12824" smilref="Title.smil#_12824"> by</p><p attribs="{'xml:space': 'preserve'}" id="_12825" smilref="Title.smil#_12825"> by sea</p><p attribs="{'xml:space': 'preserve'}" id="_12826" smilref="Title.smil#_12826"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12827" smilref="Title.smil#_12827"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12828" smilref="Title.smil#_12828"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12829" smilref="Title.smil#_12829"> a 6</p><p attribs="{'xml:space': 'preserve'}" id="_12830" smilref="Title.smil#_12830"> by sea sells</p><p attribs="{'xml:space': 'preserve'}" id="_12831" smilref="Title.smil#_12831"> by sea sells she</p><p attribs="{'xml:space': 'preserve'}" id="_12832" smilref="Title.smil#_12832"> by sea sells she shells</p><p attribs="{'xml:space': 'preserve'}" id="_12833" smilref="Title.smil#_12833"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12834" smilref="Title.smil#_12834"> h e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12835" smilref="Title.smil#_12835"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12836" smilref="Title.smil#_12836"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12837" smilref="Title.smil#_12837"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12838" smilref="Title.smil#_12838"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12839" smilref="Title.smil#_12839"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12840" smilref="Title.smil#_12840"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12841" smilref="Title.smil#_12841"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12842" smilref="Title.smil#_12842"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12843" smilref="Title.smil#_12843"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12844" smilref="Title.smil#_12844"> o</p><p attribs="{'xml:space': 'preserve'}" id="_12845" smilref="Title.smil#_12845"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12846" smilref="Title.smil#_12846"> e 7</p><p attribs="{'xml:space': 'preserve'}" id="_12847" smilref="Title.smil#_12847"> by sea sells she shells shore</p><p attribs="{'xml:space': 'preserve'}" id="_12848" smilref="Title.smil#_12848"> by sea sells she shells shore the</p><p attribs="{'xml:space': 'preserve'}" id="_12849" smilref="Title.smil#_12849"> Collecting the keys in a trie (trace)</p><p attribs="{'xml:space': 'preserve'}" id="_12850" smilref="Title.smil#_12850"> the keysWithPrefix() methods</p><p attribs="{'xml:space': 'preserve'}" id="_12851" smilref="Title.smil#_12851"> in the API. To implement keys()</p><p attribs="{'xml:space': 'preserve'}" id="_12852" smilref="Title.smil#_12852"> we call keysWithPrefix() with</p><p attribs="{'xml:space': 'preserve'}" id="_12853" smilref="Title.smil#_12853"> the empty string as argument; to implement keysWithPrefix(), we call get() to find the trie node corresponding to the given prefix (null if there is no such node), then use the collect() method to complete the job. The diagram at left shows a trace of collect() (or keysWithPrefix("")) for an example trie, giving the value of the second argument key and the contents of the queue for each call to collect(). The diagram at the top of the facing page illustrates the process for</p><p attribs="{'xml:space': 'preserve'}" id="_12854" smilref="Title.smil#_12854"> keysWithPrefix("sh").</p><p attribs="{'xml:space': 'preserve'}" id="_12855" smilref="Title.smil#_12855" /><pagenum id="p752" page="normal" smilref="Title.smil#p752" /><p attribs="{'xml:space': 'preserve'}" id="_12856" smilref="Title.smil#_12856"> keysWithPrefix("sh");</p><p attribs="{'xml:space': 'preserve'}" id="_12857" smilref="Title.smil#_12857"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12858" smilref="Title.smil#_12858"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12859" smilref="Title.smil#_12859"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12860" smilref="Title.smil#_12860"> a 6</p><p attribs="{'xml:space': 'preserve'}" id="_12861" smilref="Title.smil#_12861"> find subtrie for all keys beginning with "sh"</p><p attribs="{'xml:space': 'preserve'}" id="_12862" smilref="Title.smil#_12862"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12863" smilref="Title.smil#_12863"> h e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12864" smilref="Title.smil#_12864"> b</p><p attribs="{'xml:space': 'preserve'}" id="_12865" smilref="Title.smil#_12865"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_12866" smilref="Title.smil#_12866"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12867" smilref="Title.smil#_12867"> a 6</p><p attribs="{'xml:space': 'preserve'}" id="_12868" smilref="Title.smil#_12868"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12869" smilref="Title.smil#_12869"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12870" smilref="Title.smil#_12870"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12871" smilref="Title.smil#_12871"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12872" smilref="Title.smil#_12872"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12873" smilref="Title.smil#_12873"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12874" smilref="Title.smil#_12874"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12875" smilref="Title.smil#_12875"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12876" smilref="Title.smil#_12876"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12877" smilref="Title.smil#_12877"> o</p><p attribs="{'xml:space': 'preserve'}" id="_12878" smilref="Title.smil#_12878"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12879" smilref="Title.smil#_12879"> e 7</p><p attribs="{'xml:space': 'preserve'}" id="_12880" smilref="Title.smil#_12880"> t</p><p attribs="{'xml:space': 'preserve'}" id="_12881" smilref="Title.smil#_12881"> h e 5</p><p attribs="{'xml:space': 'preserve'}" id="_12882" smilref="Title.smil#_12882"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12883" smilref="Title.smil#_12883"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12884" smilref="Title.smil#_12884"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12885" smilref="Title.smil#_12885"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12886" smilref="Title.smil#_12886"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12887" smilref="Title.smil#_12887"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12888" smilref="Title.smil#_12888"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12889" smilref="Title.smil#_12889"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12890" smilref="Title.smil#_12890"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12891" smilref="Title.smil#_12891"> o</p><p attribs="{'xml:space': 'preserve'}" id="_12892" smilref="Title.smil#_12892"> r</p><p attribs="{'xml:space': 'preserve'}" id="_12893" smilref="Title.smil#_12893"> e 7</p><p attribs="{'xml:space': 'preserve'}" id="_12894" smilref="Title.smil#_12894"> Prefix match in a trie</p><p attribs="{'xml:space': 'preserve'}" id="_12895" smilref="Title.smil#_12895"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12896" smilref="Title.smil#_12896"> 739</p><p attribs="{'xml:space': 'preserve'}" id="_12897" smilref="Title.smil#_12897"> key sh she shel shell shells sho shor shore</p><p attribs="{'xml:space': 'preserve'}" id="_12898" smilref="Title.smil#_12898"> q</p><p attribs="{'xml:space': 'preserve'}" id="_12899" smilref="Title.smil#_12899"> she</p><p attribs="{'xml:space': 'preserve'}" id="_12900" smilref="Title.smil#_12900"> she shells</p><p attribs="{'xml:space': 'preserve'}" id="_12901" smilref="Title.smil#_12901"> she shells shore</p><p attribs="{'xml:space': 'preserve'}" id="_12902" smilref="Title.smil#_12902"> collect keys in that subtrie</p><p attribs="{'xml:space': 'preserve'}" id="_12903" smilref="Title.smil#_12903"> Wildcard match. To implement keysThatMatch(), we use a similar process, but add an argument specifying the pattern to collect() and add a test to make a recursive call for all links when the pattern character is a wildcard or only for the link corresponding to the pattern character otherwise, as in the code below. Note also that we do not need to consider keys longer than the pattern.</p><p attribs="{'xml:space': 'preserve'}" id="_12904" smilref="Title.smil#_12904"> Longest pre&#64257; x. To find the longest key that is a prefix of a given string, we use a recursive method like get() that keeps track of the length of the longest key found on the search path (by passing it as a parameter to the recursive method, updating the value</p><p attribs="{'xml:space': 'preserve'}" id="_12905" smilref="Title.smil#_12905"> public Iterable&lt;String&gt; keysThatMatch(String pat) { Queue&lt;String&gt; q = new Queue&lt;String&gt;(); collect(root, "", pat, q); return q; }</p><p attribs="{'xml:space': 'preserve'}" id="_12906" smilref="Title.smil#_12906"> public void collect(Node x, String pre, String pat, Queue&lt;String&gt; q) { int d = pre.length(); if (x == null) return; if (d == pat.length() &amp;&amp; x.val != null) q.enqueue(pre); if (d == pat.length()) return;</p><p attribs="{'xml:space': 'preserve'}" id="_12907" smilref="Title.smil#_12907"> char next = pat.charAt(d); for (char c = 0; c &lt; R; c++) if (next == '.' || next == c) collect(x.next[c], pre + c, pat, q); }</p><p attribs="{'xml:space': 'preserve'}" id="_12908" smilref="Title.smil#_12908"> Wildcard match in a trie</p><p attribs="{'xml:space': 'preserve'}" id="_12909" smilref="Title.smil#_12909" /><pagenum id="p753" page="normal" smilref="Title.smil#p753" /><p attribs="{'xml:space': 'preserve'}" id="_12910" smilref="Title.smil#_12910"> 740</p><p attribs="{'xml:space': 'preserve'}" id="_12911" smilref="Title.smil#_12911"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_12912" smilref="Title.smil#_12912"> public String longestPrefixOf(String s) { int length = search(root, s, 0, 0); return s.substring(0, length); }</p><p attribs="{'xml:space': 'preserve'}" id="_12913" smilref="Title.smil#_12913"> private int search(Node x, String s, int d, int length) { if (x == null) return length; if (x.val != null) length = d; if (d == s.length()) return length; char c = s.charAt(d); return search(x.next[c], s, d+1, length); }</p><p attribs="{'xml:space': 'preserve'}" id="_12914" smilref="Title.smil#_12914"> Matching the longest pref ix of a given string</p><p attribs="{'xml:space': 'preserve'}" id="_12915" smilref="Title.smil#_12915"> whenever a node with a non-null value is encountered). The search ends when the end of the string or a null link is en- countered, whichever comes fi rst.</p><p attribs="{'xml:space': 'preserve'}" id="_12916" smilref="Title.smil#_12916"> Deletion. The first step needed to delete a key-value pair from a trie is to use a normal search to find the node corresponding to the key and set the corresponding value to null. If that node has a non-null link to a child, then no more work is required; if all the links are null, we need to remove the node from the data structure. If doing so leaves all the links null in its parent, we need to remove that node, and so forth. The implementation on the facing page demonstrates that this action can be accomplished with remarkably little code, using our standard recursive setup: after the recursive calls for a node x, we return null if the client value and all of the links in a node are null; otherwise we return x.</p><p attribs="{'xml:space': 'preserve'}" id="_12917" smilref="Title.smil#_12917"> "she"</p><p attribs="{'xml:space': 'preserve'}" id="_12918" smilref="Title.smil#_12918"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12919" smilref="Title.smil#_12919"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12920" smilref="Title.smil#_12920"> "shell"</p><p attribs="{'xml:space': 'preserve'}" id="_12921" smilref="Title.smil#_12921"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12922" smilref="Title.smil#_12922"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12923" smilref="Title.smil#_12923"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12924" smilref="Title.smil#_12924"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12925" smilref="Title.smil#_12925"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12926" smilref="Title.smil#_12926"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12927" smilref="Title.smil#_12927"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12928" smilref="Title.smil#_12928"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12929" smilref="Title.smil#_12929"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12930" smilref="Title.smil#_12930"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12931" smilref="Title.smil#_12931"> "shellsort"</p><p attribs="{'xml:space': 'preserve'}" id="_12932" smilref="Title.smil#_12932"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12933" smilref="Title.smil#_12933"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12934" smilref="Title.smil#_12934"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12935" smilref="Title.smil#_12935"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12936" smilref="Title.smil#_12936"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12937" smilref="Title.smil#_12937"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12938" smilref="Title.smil#_12938"> "shelters"</p><p attribs="{'xml:space': 'preserve'}" id="_12939" smilref="Title.smil#_12939"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12940" smilref="Title.smil#_12940"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12941" smilref="Title.smil#_12941"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12942" smilref="Title.smil#_12942"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12943" smilref="Title.smil#_12943"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12944" smilref="Title.smil#_12944"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12945" smilref="Title.smil#_12945"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12946" smilref="Title.smil#_12946"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12947" smilref="Title.smil#_12947"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12948" smilref="Title.smil#_12948"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12949" smilref="Title.smil#_12949"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12950" smilref="Title.smil#_12950"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12951" smilref="Title.smil#_12951"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12952" smilref="Title.smil#_12952"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12953" smilref="Title.smil#_12953"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12954" smilref="Title.smil#_12954"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12955" smilref="Title.smil#_12955"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12956" smilref="Title.smil#_12956"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12957" smilref="Title.smil#_12957"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12958" smilref="Title.smil#_12958"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12959" smilref="Title.smil#_12959"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12960" smilref="Title.smil#_12960"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12961" smilref="Title.smil#_12961"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12962" smilref="Title.smil#_12962"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12963" smilref="Title.smil#_12963"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12964" smilref="Title.smil#_12964"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12965" smilref="Title.smil#_12965"> search ends at end of string value is not null return she</p><p attribs="{'xml:space': 'preserve'}" id="_12966" smilref="Title.smil#_12966"> search ends at end of string value is null return she (last key on path)</p><p attribs="{'xml:space': 'preserve'}" id="_12967" smilref="Title.smil#_12967"> search ends at null link return shells (last key on path)</p><p attribs="{'xml:space': 'preserve'}" id="_12968" smilref="Title.smil#_12968"> search ends at null link return she (last key on path)</p><p attribs="{'xml:space': 'preserve'}" id="_12969" smilref="Title.smil#_12969"> Possibilities for longestPrefixOf()</p><p attribs="{'xml:space': 'preserve'}" id="_12970" smilref="Title.smil#_12970" /><pagenum id="p754" page="normal" smilref="Title.smil#p754" /><p attribs="{'xml:space': 'preserve'}" id="_12971" smilref="Title.smil#_12971"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_12972" smilref="Title.smil#_12972"> 741</p><p attribs="{'xml:space': 'preserve'}" id="_12973" smilref="Title.smil#_12973"> Alphabet. As usual, Algorithm 5.4</p><p attribs="{'xml:space': 'preserve'}" id="_12974" smilref="Title.smil#_12974"> public void delete(String key) { root = delete(root, key, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_12975" smilref="Title.smil#_12975"> private Node delete(Node x, String key, int d) { if (x == null) return null; if (d == key.length()) x.val = null; else { char c = key.charAt(d); x.next[c] = delete(x.next[c], key, d+1); }</p><p attribs="{'xml:space': 'preserve'}" id="_12976" smilref="Title.smil#_12976"> is coded for Java String keys, but it is a simple matter to modify the implementation to handle keys taken from any alphabet, as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_12977" smilref="Title.smil#_12977"> Deleting a key (and its associated value) from a trie</p><p attribs="{'xml:space': 'preserve'}" id="_12978" smilref="Title.smil#_12978"> if (x.val != null) return x;</p><p attribs="{'xml:space': 'preserve'}" id="_12979" smilref="Title.smil#_12979"> for (char c = 0; c &lt; R; c++) if (x.next[c] != null) return x; return null; }</p><p attribs="{'xml:space': 'preserve'}" id="_12980" smilref="Title.smil#_12980"> keys(), keysWithPrefix(), and keysThatMatch().</p><p attribs="{'xml:space': 'preserve'}" id="_12981" smilref="Title.smil#_12981"> With these changes, you can save a considerable amount of space (use only R links per node) when you know that your keys are taken from a small alphabet, at the cost of the time required to do the conversions between characters and indices.</p><p attribs="{'xml:space': 'preserve'}" id="_12982" smilref="Title.smil#_12982"> delete("shells");</p><p attribs="{'xml:space': 'preserve'}" id="_12983" smilref="Title.smil#_12983"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12984" smilref="Title.smil#_12984"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12985" smilref="Title.smil#_12985"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12986" smilref="Title.smil#_12986"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12987" smilref="Title.smil#_12987"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12988" smilref="Title.smil#_12988"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_12989" smilref="Title.smil#_12989"> e</p><p attribs="{'xml:space': 'preserve'}" id="_12990" smilref="Title.smil#_12990"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_12991" smilref="Title.smil#_12991"> set value to null</p><p attribs="{'xml:space': 'preserve'}" id="_12992" smilref="Title.smil#_12992"> h</p><p attribs="{'xml:space': 'preserve'}" id="_12993" smilref="Title.smil#_12993"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_12994" smilref="Title.smil#_12994"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12995" smilref="Title.smil#_12995"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12996" smilref="Title.smil#_12996"> s 3</p><p attribs="{'xml:space': 'preserve'}" id="_12997" smilref="Title.smil#_12997"> s</p><p attribs="{'xml:space': 'preserve'}" id="_12998" smilref="Title.smil#_12998"> l</p><p attribs="{'xml:space': 'preserve'}" id="_12999" smilref="Title.smil#_12999"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13000" smilref="Title.smil#_13000"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13001" smilref="Title.smil#_13001"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13002" smilref="Title.smil#_13002"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13003" smilref="Title.smil#_13003"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13004" smilref="Title.smil#_13004"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_13005" smilref="Title.smil#_13005"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13006" smilref="Title.smil#_13006"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13007" smilref="Title.smil#_13007"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13008" smilref="Title.smil#_13008"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13009" smilref="Title.smil#_13009"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13010" smilref="Title.smil#_13010"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13011" smilref="Title.smil#_13011"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13012" smilref="Title.smil#_13012"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13013" smilref="Title.smil#_13013"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13014" smilref="Title.smil#_13014"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13015" smilref="Title.smil#_13015"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13016" smilref="Title.smil#_13016"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_13017" smilref="Title.smil#_13017"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13018" smilref="Title.smil#_13018"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13019" smilref="Title.smil#_13019"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13020" smilref="Title.smil#_13020"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13021" smilref="Title.smil#_13021"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_13022" smilref="Title.smil#_13022"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13023" smilref="Title.smil#_13023"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13024" smilref="Title.smil#_13024"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13025" smilref="Title.smil#_13025"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13026" smilref="Title.smil#_13026"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13027" smilref="Title.smil#_13027"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13028" smilref="Title.smil#_13028"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_13029" smilref="Title.smil#_13029"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13030" smilref="Title.smil#_13030"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13031" smilref="Title.smil#_13031"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13032" smilref="Title.smil#_13032"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13033" smilref="Title.smil#_13033"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13034" smilref="Title.smil#_13034"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13035" smilref="Title.smil#_13035"> a 2</p><p attribs="{'xml:space': 'preserve'}" id="_13036" smilref="Title.smil#_13036"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13037" smilref="Title.smil#_13037"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13038" smilref="Title.smil#_13038"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13039" smilref="Title.smil#_13039"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13040" smilref="Title.smil#_13040"> e 0</p><p attribs="{'xml:space': 'preserve'}" id="_13041" smilref="Title.smil#_13041"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13042" smilref="Title.smil#_13042"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13043" smilref="Title.smil#_13043"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13044" smilref="Title.smil#_13044"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13045" smilref="Title.smil#_13045"> s 1</p><p attribs="{'xml:space': 'preserve'}" id="_13046" smilref="Title.smil#_13046"> non-null value so do not remove node (return link to node)</p><p attribs="{'xml:space': 'preserve'}" id="_13047" smilref="Title.smil#_13047"> non-null link so do not remove node (return link to node)</p><p attribs="{'xml:space': 'preserve'}" id="_13048" smilref="Title.smil#_13048"> null value and links, so remove node (return null link)</p><p attribs="{'xml:space': 'preserve'}" id="_13049" smilref="Title.smil#_13049"> Deleting a key (and its associated value) from a trie</p><p attribs="{'xml:space': 'preserve'}" id="_13050" smilref="Title.smil#_13050" /></level3><level3 id="_00102"><h3 id="ch5-s2-ss6" smilref="Title.smil#ch5-s2-ss6" xml:space="preserve">R-way tries</h3><pagenum id="p755" page="normal" smilref="Title.smil#p755" /><p attribs="{'xml:space': 'preserve'}" id="_13051" smilref="Title.smil#_13051"> 742</p><p attribs="{'xml:space': 'preserve'}" id="_13052" smilref="Title.smil#_13052"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13053" smilref="Title.smil#_13053"> The code that we have considered is a compact and complete implementation of the string symbol-table API that has broadly useful practical applications. Several variations and extensions are discussed in the exercises. Next, we consider basic properties of tries, and some limitations on their utility.</p><p attribs="{'xml:space': 'preserve'}" id="_13054" smilref="Title.smil#_13054"> Properties of tries As usual, we are interested in knowing the amount of time and space required to use tries in typical applications. Tries have been extensively studied and analyzed, and their basic properties are relatively easy to understand and to apply.</p><p attribs="{'xml:space': 'preserve'}" id="_13055" smilref="Title.smil#_13055"> Proposition F. The linked structure (shape) of a trie is independent of the key in- sertion/deletion order: there is a unique trie for any given set of keys.</p><p attribs="{'xml:space': 'preserve'}" id="_13056" smilref="Title.smil#_13056"> Proof : Immediate, by induction on the subtries.</p><p attribs="{'xml:space': 'preserve'}" id="_13057" smilref="Title.smil#_13057"> This fundamental fact is a distinctive feature of tries: for all of the other search tree structures that we have considered so far, the tree that we construct depends both on the set of keys and on the order in which we insert those keys.</p><p attribs="{'xml:space': 'preserve'}" id="_13058" smilref="Title.smil#_13058"> Worst-case time bound for search and insert. How long does it take to find the value</p><p attribs="{'xml:space': 'preserve'}" id="_13059" smilref="Title.smil#_13059"> associated with a key? For BSTs, hashing, and other methods in Chapter 4, we needed mathematical analysis to study this question, but for tries it is very easy to answer:</p><p attribs="{'xml:space': 'preserve'}" id="_13060" smilref="Title.smil#_13060"> Proposition G. The number of array accesses when searching in a trie or inserting a key into a trie is at most 1 plus the length of the key.</p><p attribs="{'xml:space': 'preserve'}" id="_13061" smilref="Title.smil#_13061"> Proof : Immediate from the code. The recursive get() and put() implementations carry an argument d that starts at 0, increments for each call, and is used to stop the recursion when it reaches the key length.</p><p attribs="{'xml:space': 'preserve'}" id="_13062" smilref="Title.smil#_13062"> From a theoretical standpoint, the implication of Proposition G is that tries are optimal for search hit&#8212;we could not expect to do better than search time proportional to the length of the search key. Whatever algorithm or data structure we are using, we cannot know that we have found a key that we seek without examining all of its characters. From a practical standpoint this guarantee is important because it does not depend on the number of keys : when we are working with 7-character keys like license plate num- bers, we know that we need to examine at most 8 nodes to search or insert; when we are working with 20-digit account numbers, we only need to examine at most 21 nodes to search or insert.</p><p attribs="{'xml:space': 'preserve'}" id="_13063" smilref="Title.smil#_13063" /><pagenum id="p756" page="normal" smilref="Title.smil#p756" /><p attribs="{'xml:space': 'preserve'}" id="_13064" smilref="Title.smil#_13064"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13065" smilref="Title.smil#_13065"> 743</p><p attribs="{'xml:space': 'preserve'}" id="_13066" smilref="Title.smil#_13066"> Expected time bound for search miss. Suppose that we are searching for a key in a trie and find that the link in the root node that corresponds to its first character is null. In this case, we know that the key is not in the table on the basis of examining just one node. This case is typical: one of the most important properties of tries is that search misses typically require examining just a few nodes. If we assume that the keys are drawn from the random string model (each character is equally likely to have any one of the R different character values) we can prove this fact:</p><p attribs="{'xml:space': 'preserve'}" id="_13067" smilref="Title.smil#_13067"> Proposition H. The average number of nodes examined for search miss in a trie built from N random keys over an alphabet of size R is ~log R N . Proof sketch (for readers who are familiar with probabilistic analysis): The probability that each of the N keys in a random trie differs from a random search key in at least one of the leading t characters is (1 &#11002; R&#11002;t )N. Subtracting this quantity from 1 gives the probability that one of the keys in the trie matches the search key in all of the leading t characters. In other words, 1 &#11002; (1 &#11002; R&#11002;t )N is the probability that the search requires more than t character compares. From probabilistic analysis, the sum for t = 0, 1, 2, . . . of the probabilities that an integer random variable is &gt;t is the average value of that random variable, so the average search cost is 1 &#11002; (1 &#11002; R&#11002;1)N &#11001; 1 &#11002; (1 &#11002; R&#11002;2)N &#11001;. . .&#11001; 1 &#11002; (1 &#11002; R&#11002;t )N &#11001;. . . Using the elementary approximation (1&#11002;1/x)x ~ e&#11002;1, we find the search cost to be approximately (1 &#11002; e &#11002;N/R1) &#11001; (1 &#11002; e &#11002;N/R2) &#11001;. . .&#11001; (1 &#11002; e &#11002;N/Rt) &#11001;. . .</p><p attribs="{'xml:space': 'preserve'}" id="_13068" smilref="Title.smil#_13068"> The summand is extremely close to 1 for approximately ln R N terms with Rt substantially smaller than N; it is extremely close to 0 for all the terms with Rt substantially greater than N; and it is somewhere between 0 and 1 for the few terms with Rt &#33360; N. So the grand total is about log R N.</p><p attribs="{'xml:space': 'preserve'}" id="_13069" smilref="Title.smil#_13069"> From a practical standpoint, the most important implication of this proposition is that search miss does not depend on the key length. For example, it says that unsuccessful search in a trie built with 1 million random keys will require examining only three or four nodes, whether the keys are 7-digit license plates or 20-digit account numbers. While it is unreasonable to expect truly random keys in practical applications, it is reasonable to hypothesize that the behavior of trie algorithms for keys in typical applica-</p><p attribs="{'xml:space': 'preserve'}" id="_13070" smilref="Title.smil#_13070" /><pagenum id="p757" page="normal" smilref="Title.smil#p757" /><p attribs="{'xml:space': 'preserve'}" id="_13071" smilref="Title.smil#_13071"> 744</p><p attribs="{'xml:space': 'preserve'}" id="_13072" smilref="Title.smil#_13072"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13073" smilref="Title.smil#_13073"> tions is described by this model. Indeed, this sort of behavior is widely seen in practice and is an important reason for the widespread use of tries.</p><p attribs="{'xml:space': 'preserve'}" id="_13074" smilref="Title.smil#_13074"> Space. How much space is needed for a trie? Addressing this question (and understanding how much space is available) is critical to using tries effectively.</p><p attribs="{'xml:space': 'preserve'}" id="_13075" smilref="Title.smil#_13075"> Proposition I. The number of links in a trie is between RN and RNw, where w is the average key length.</p><p attribs="{'xml:space': 'preserve'}" id="_13076" smilref="Title.smil#_13076"> Proof : Every key in the trie has a node containing its associated value that also has R links, so the number of links is at least RN. If the first characters of all the keys are different, then there is a node with R links for every key character, so the number of links is R times the total number of key characters, or RNw.</p><p attribs="{'xml:space': 'preserve'}" id="_13077" smilref="Title.smil#_13077"> The table on the facing page shows the costs for some typical applications that we have considered. It illustrates the following rules of thumb for tries: </p><p attribs="{'xml:space': 'preserve'}" id="_13078" smilref="Title.smil#_13078"> put("shells", 1); put("shellfish", 2);</p><p attribs="{'xml:space': 'preserve'}" id="_13079" smilref="Title.smil#_13079"> no one-way branching</p><p attribs="{'xml:space': 'preserve'}" id="_13080" smilref="Title.smil#_13080"> standard trie</p><p attribs="{'xml:space': 'preserve'}" id="_13081" smilref="Title.smil#_13081"> s h e l l</p><p attribs="{'xml:space': 'preserve'}" id="_13082" smilref="Title.smil#_13082"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13083" smilref="Title.smil#_13083"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13084" smilref="Title.smil#_13084"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13085" smilref="Title.smil#_13085"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13086" smilref="Title.smil#_13086"> f i s h</p><p attribs="{'xml:space': 'preserve'}" id="_13087" smilref="Title.smil#_13087"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13088" smilref="Title.smil#_13088"> One-way branching. The primary reason</p><p attribs="{'xml:space': 'preserve'}" id="_13089" smilref="Title.smil#_13089"> that trie space is excessive for long keys is that long keys tend to have long tails in the trie, with each node having a single link to the next node (and, therefore, R&#11002;1 null links). This situation is not difficult to correct (see Exer- cise 5.2.11). A trie might also have internal one-way branching. For example, two long keys may be equal except for their last charac- ter. This situation is a bit more difficult to address (see Exercise 5.2.12). These changes can make trie space usage a less important factor</p><p attribs="{'xml:space': 'preserve'}" id="_13090" smilref="Title.smil#_13090"> internal one-way branching</p><p attribs="{'xml:space': 'preserve'}" id="_13091" smilref="Title.smil#_13091"> external one-way branching</p><p attribs="{'xml:space': 'preserve'}" id="_13092" smilref="Title.smil#_13092"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13093" smilref="Title.smil#_13093"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13094" smilref="Title.smil#_13094"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13095" smilref="Title.smil#_13095"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13096" smilref="Title.smil#_13096"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13097" smilref="Title.smil#_13097"> f</p><p attribs="{'xml:space': 'preserve'}" id="_13098" smilref="Title.smil#_13098"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13099" smilref="Title.smil#_13099"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13100" smilref="Title.smil#_13100"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13101" smilref="Title.smil#_13101"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13102" smilref="Title.smil#_13102"> Removing one-way branching in a trie</p><p attribs="{'xml:space': 'preserve'}" id="_13103" smilref="Title.smil#_13103" /><pagenum id="p758" page="normal" smilref="Title.smil#p758" /><p attribs="{'xml:space': 'preserve'}" id="_13104" smilref="Title.smil#_13104"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13105" smilref="Title.smil#_13105"> 745</p><p attribs="{'xml:space': 'preserve'}" id="_13106" smilref="Title.smil#_13106"> than for the straightforward implementation that we have considered, but they are not necessarily effective in practical applications. Next, we consider an alternative approach to reducing space usage for tries.</p><p attribs="{'xml:space': 'preserve'}" id="_13107" smilref="Title.smil#_13107"> The bottom line is this: do not try to use Algorithm 5.4 for large numbers of long keys taken from large alphabets, because it will require space proportional to R times the total number of key characters. Otherwise, if you can afford the space, trie performance is difficult to beat.</p><p attribs="{'xml:space': 'preserve'}" id="_13108" smilref="Title.smil#_13108"> application</p><p attribs="{'xml:space': 'preserve'}" id="_13109" smilref="Title.smil#_13109"> typical key</p><p attribs="{'xml:space': 'preserve'}" id="_13110" smilref="Title.smil#_13110"> CA license plates</p><p attribs="{'xml:space': 'preserve'}" id="_13111" smilref="Title.smil#_13111"> 4PGC938</p><p attribs="{'xml:space': 'preserve'}" id="_13112" smilref="Title.smil#_13112"> account numbers</p><p attribs="{'xml:space': 'preserve'}" id="_13113" smilref="Title.smil#_13113"> 02400019992993299111</p><p attribs="{'xml:space': 'preserve'}" id="_13114" smilref="Title.smil#_13114"> URLs</p><p attribs="{'xml:space': 'preserve'}" id="_13115" smilref="Title.smil#_13115"> www.cs.princeton.edu</p><p attribs="{'xml:space': 'preserve'}" id="_13116" smilref="Title.smil#_13116"> text processing</p><p attribs="{'xml:space': 'preserve'}" id="_13117" smilref="Title.smil#_13117"> proteins in genomic data</p><p attribs="{'xml:space': 'preserve'}" id="_13118" smilref="Title.smil#_13118"> seashells</p><p attribs="{'xml:space': 'preserve'}" id="_13119" smilref="Title.smil#_13119"> ACTGACTG</p><p attribs="{'xml:space': 'preserve'}" id="_13120" smilref="Title.smil#_13120"> average length w</p><p attribs="{'xml:space': 'preserve'}" id="_13121" smilref="Title.smil#_13121"> alphabet size R</p><p attribs="{'xml:space': 'preserve'}" id="_13122" smilref="Title.smil#_13122"> links in trie built from 1 million keys</p><p attribs="{'xml:space': 'preserve'}" id="_13123" smilref="Title.smil#_13123"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_13124" smilref="Title.smil#_13124"> 20</p><p attribs="{'xml:space': 'preserve'}" id="_13125" smilref="Title.smil#_13125"> 28</p><p attribs="{'xml:space': 'preserve'}" id="_13126" smilref="Title.smil#_13126"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_13127" smilref="Title.smil#_13127"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_13128" smilref="Title.smil#_13128"> 256</p><p attribs="{'xml:space': 'preserve'}" id="_13129" smilref="Title.smil#_13129"> 256 10</p><p attribs="{'xml:space': 'preserve'}" id="_13130" smilref="Title.smil#_13130"> 256</p><p attribs="{'xml:space': 'preserve'}" id="_13131" smilref="Title.smil#_13131"> 256 256 4</p><p attribs="{'xml:space': 'preserve'}" id="_13132" smilref="Title.smil#_13132"> 256 million</p><p attribs="{'xml:space': 'preserve'}" id="_13133" smilref="Title.smil#_13133"> 4 billion 256 million</p><p attribs="{'xml:space': 'preserve'}" id="_13134" smilref="Title.smil#_13134"> 4 billion</p><p attribs="{'xml:space': 'preserve'}" id="_13135" smilref="Title.smil#_13135"> 256 million 256 million 4 million</p><p attribs="{'xml:space': 'preserve'}" id="_13136" smilref="Title.smil#_13136"> Space requirements for typical tries</p><p attribs="{'xml:space': 'preserve'}" id="_13137" smilref="Title.smil#_13137" /></level3><level3 id="_00103"><h3 id="ch5-s2-ss7" smilref="Title.smil#ch5-s2-ss7" xml:space="preserve">Ternary search tries</h3><pagenum id="p759" page="normal" smilref="Title.smil#p759" /><p attribs="{'xml:space': 'preserve'}" id="_13138" smilref="Title.smil#_13138"> 746</p><p attribs="{'xml:space': 'preserve'}" id="_13139" smilref="Title.smil#_13139"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13140" smilref="Title.smil#_13140"> Ternary search tries (TSTs) To help us</p><p attribs="{'xml:space': 'preserve'}" id="_13141" smilref="Title.smil#_13141"> avoid the excessive space cost associated with R-way tries, we now consider an alternative representation: the ternary search trie (TST). In a TST, each node has a character, three links, and a value. The three links correspond to keys whose current characters are less than, equal to, or greater than the node&#8217;s character. In the R-way tries of Algorithm 5.4, trie nodes are represented by R links, with the character corresponding to each non-null link implictly represented by its index. In the corresponding TST, characters appear explicitly in nodes&#8212;we find characters corresponding to keys only when we are traversing the middle links.</p><p attribs="{'xml:space': 'preserve'}" id="_13142" smilref="Title.smil#_13142"> a</p><p attribs="{'xml:space': 'preserve'}" id="_13143" smilref="Title.smil#_13143"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13144" smilref="Title.smil#_13144"> b</p><p attribs="{'xml:space': 'preserve'}" id="_13145" smilref="Title.smil#_13145"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13146" smilref="Title.smil#_13146"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_13147" smilref="Title.smil#_13147"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13148" smilref="Title.smil#_13148"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13149" smilref="Title.smil#_13149"> u</p><p attribs="{'xml:space': 'preserve'}" id="_13150" smilref="Title.smil#_13150"> t</p><p attribs="{'xml:space': 'preserve'}" id="_13151" smilref="Title.smil#_13151"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13152" smilref="Title.smil#_13152"> e 12</p><p attribs="{'xml:space': 'preserve'}" id="_13153" smilref="Title.smil#_13153"> a 14</p><p attribs="{'xml:space': 'preserve'}" id="_13154" smilref="Title.smil#_13154"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13155" smilref="Title.smil#_13155"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13156" smilref="Title.smil#_13156"> s 11</p><p attribs="{'xml:space': 'preserve'}" id="_13157" smilref="Title.smil#_13157"> e 10</p><p attribs="{'xml:space': 'preserve'}" id="_13158" smilref="Title.smil#_13158"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13159" smilref="Title.smil#_13159"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13160" smilref="Title.smil#_13160"> o</p><p attribs="{'xml:space': 'preserve'}" id="_13161" smilref="Title.smil#_13161"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13162" smilref="Title.smil#_13162"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13163" smilref="Title.smil#_13163"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_13164" smilref="Title.smil#_13164"> r 0</p><p attribs="{'xml:space': 'preserve'}" id="_13165" smilref="Title.smil#_13165"> e 8</p><p attribs="{'xml:space': 'preserve'}" id="_13166" smilref="Title.smil#_13166"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13167" smilref="Title.smil#_13167"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13168" smilref="Title.smil#_13168"> s 15</p><p attribs="{'xml:space': 'preserve'}" id="_13169" smilref="Title.smil#_13169"> y 13</p><p attribs="{'xml:space': 'preserve'}" id="_13170" smilref="Title.smil#_13170"> link to TST for all keys that start with a letter before s</p><p attribs="{'xml:space': 'preserve'}" id="_13171" smilref="Title.smil#_13171"> b</p><p attribs="{'xml:space': 'preserve'}" id="_13172" smilref="Title.smil#_13172"> a</p><p attribs="{'xml:space': 'preserve'}" id="_13173" smilref="Title.smil#_13173"> link to TST for all keys that start with s</p><p attribs="{'xml:space': 'preserve'}" id="_13174" smilref="Title.smil#_13174"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13175" smilref="Title.smil#_13175"> t</p><p attribs="{'xml:space': 'preserve'}" id="_13176" smilref="Title.smil#_13176"> o</p><p attribs="{'xml:space': 'preserve'}" id="_13177" smilref="Title.smil#_13177"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13178" smilref="Title.smil#_13178"> s 11</p><p attribs="{'xml:space': 'preserve'}" id="_13179" smilref="Title.smil#_13179"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13180" smilref="Title.smil#_13180"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_13181" smilref="Title.smil#_13181"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13182" smilref="Title.smil#_13182"> e 10</p><p attribs="{'xml:space': 'preserve'}" id="_13183" smilref="Title.smil#_13183"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13184" smilref="Title.smil#_13184"> u</p><p attribs="{'xml:space': 'preserve'}" id="_13185" smilref="Title.smil#_13185"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13186" smilref="Title.smil#_13186"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_13187" smilref="Title.smil#_13187"> 14</p><p attribs="{'xml:space': 'preserve'}" id="_13188" smilref="Title.smil#_13188"> a</p><p attribs="{'xml:space': 'preserve'}" id="_13189" smilref="Title.smil#_13189"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13190" smilref="Title.smil#_13190"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13191" smilref="Title.smil#_13191"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13192" smilref="Title.smil#_13192"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13193" smilref="Title.smil#_13193"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13194" smilref="Title.smil#_13194"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13195" smilref="Title.smil#_13195"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13196" smilref="Title.smil#_13196"> s 15</p><p attribs="{'xml:space': 'preserve'}" id="_13197" smilref="Title.smil#_13197"> r 0</p><p attribs="{'xml:space': 'preserve'}" id="_13198" smilref="Title.smil#_13198"> e 8</p><p attribs="{'xml:space': 'preserve'}" id="_13199" smilref="Title.smil#_13199"> e 12</p><p attribs="{'xml:space': 'preserve'}" id="_13200" smilref="Title.smil#_13200"> each node has three links</p><p attribs="{'xml:space': 'preserve'}" id="_13201" smilref="Title.smil#_13201"> match: take middle link, move to next char</p><p attribs="{'xml:space': 'preserve'}" id="_13202" smilref="Title.smil#_13202"> Search and insert. The search and insert code for implementing our symbol-table API with TSTs writes itself. To search, we compare the first character in the key with the character at the root. If it is less, we take the left link; if it is greater, we take the right link; and if it is equal, we take the middle link and move to the next search key character. In each case, we apply the algorithm recursively. We terminate with a search miss if we encounter a null link or if the node where the search ends has a null value, and we terminate with a search hit if the node where the search ends has a non-null value. To insert a new key, we search, then add new nodes for the characters in the tail of the key, just as we did for tries. Algorithm 5.5 gives the details of the implementation of these methods. Using this arrangement is equivalent to implementing each R-way trie node as a binary search tree that uses as keys the characters corresponding to non-null links. By contrast, Algorithm 5.4 uses a key-indexed array. A</p><p attribs="{'xml:space': 'preserve'}" id="_13203" smilref="Title.smil#_13203"> TST representation of a trie</p><p attribs="{'xml:space': 'preserve'}" id="_13204" smilref="Title.smil#_13204"> e 10</p><p attribs="{'xml:space': 'preserve'}" id="_13205" smilref="Title.smil#_13205"> s 11</p><p attribs="{'xml:space': 'preserve'}" id="_13206" smilref="Title.smil#_13206"> s 15</p><p attribs="{'xml:space': 'preserve'}" id="_13207" smilref="Title.smil#_13207"> y 13</p><p attribs="{'xml:space': 'preserve'}" id="_13208" smilref="Title.smil#_13208"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13209" smilref="Title.smil#_13209"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13210" smilref="Title.smil#_13210"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13211" smilref="Title.smil#_13211"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13212" smilref="Title.smil#_13212"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13213" smilref="Title.smil#_13213"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13214" smilref="Title.smil#_13214"> l</p><p attribs="{'xml:space': 'preserve'}" id="_13215" smilref="Title.smil#_13215"> t</p><p attribs="{'xml:space': 'preserve'}" id="_13216" smilref="Title.smil#_13216"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13217" smilref="Title.smil#_13217"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13218" smilref="Title.smil#_13218"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13219" smilref="Title.smil#_13219"> o</p><p attribs="{'xml:space': 'preserve'}" id="_13220" smilref="Title.smil#_13220"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13221" smilref="Title.smil#_13221"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13222" smilref="Title.smil#_13222"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_13223" smilref="Title.smil#_13223"> u</p><p attribs="{'xml:space': 'preserve'}" id="_13224" smilref="Title.smil#_13224"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13225" smilref="Title.smil#_13225"> e 8</p><p attribs="{'xml:space': 'preserve'}" id="_13226" smilref="Title.smil#_13226"> y 13</p><p attribs="{'xml:space': 'preserve'}" id="_13227" smilref="Title.smil#_13227"> TST search example</p><p attribs="{'xml:space': 'preserve'}" id="_13228" smilref="Title.smil#_13228"> get("sea")</p><p attribs="{'xml:space': 'preserve'}" id="_13229" smilref="Title.smil#_13229"> mismatch: take left or right link, do not move to next char</p><p attribs="{'xml:space': 'preserve'}" id="_13230" smilref="Title.smil#_13230"> b</p><p attribs="{'xml:space': 'preserve'}" id="_13231" smilref="Title.smil#_13231"> y 4</p><p attribs="{'xml:space': 'preserve'}" id="_13232" smilref="Title.smil#_13232"> a</p><p attribs="{'xml:space': 'preserve'}" id="_13233" smilref="Title.smil#_13233"> r</p><p attribs="{'xml:space': 'preserve'}" id="_13234" smilref="Title.smil#_13234"> e 12</p><p attribs="{'xml:space': 'preserve'}" id="_13235" smilref="Title.smil#_13235"> a14</p><p attribs="{'xml:space': 'preserve'}" id="_13236" smilref="Title.smil#_13236"> return value associated with last key character</p><p attribs="{'xml:space': 'preserve'}" id="_13237" smilref="Title.smil#_13237" /><pagenum id="p760" page="normal" smilref="Title.smil#p760" /><p attribs="{'xml:space': 'preserve'}" id="_13238" smilref="Title.smil#_13238"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13239" smilref="Title.smil#_13239"> 747</p><p attribs="{'xml:space': 'preserve'}" id="_13240" smilref="Title.smil#_13240"> ALGORITHM 5.5 TST symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_13241" smilref="Title.smil#_13241"> public class TST&lt;Value&gt; { private Node root; // root of trie</p><p attribs="{'xml:space': 'preserve'}" id="_13242" smilref="Title.smil#_13242"> private class Node { char c; // character Node left, mid, right; // left, middle, and right subtries Value val; // value associated with string }</p><p attribs="{'xml:space': 'preserve'}" id="_13243" smilref="Title.smil#_13243"> public Value get(String key) // same as for tries (See page 737).</p><p attribs="{'xml:space': 'preserve'}" id="_13244" smilref="Title.smil#_13244"> private Node get(Node x, String key, int d) { if (x == null) return null; char c = key.charAt(d); if (c &lt; x.c) return get(x.left, key, d); else if (c &gt; x.c) return get(x.right, key, d); else if (d &lt; key.length() - 1) return get(x.mid, key, d+1); else return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_13245" smilref="Title.smil#_13245"> public void put(String key, Value val) { root = put(root, key, val, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_13246" smilref="Title.smil#_13246"> private Node put(Node x, String key, Value val, int d) { char c = key.charAt(d); if (x == null) { x = new Node(); x.c = c; } if (c &lt; x.c) x.left = put(x.left, key, val, d); else if (c &gt; x.c) x.right = put(x.right, key, val, d); else if (d &lt; key.length() - 1) x.mid = put(x.mid, key, val, d+1); else x.val = val; return x; }</p><p attribs="{'xml:space': 'preserve'}" id="_13247" smilref="Title.smil#_13247"> }</p><p attribs="{'xml:space': 'preserve'}" id="_13248" smilref="Title.smil#_13248"> This implementation uses a char value c and three links per node to build string search tries where subtries have keys whose first character is less than c (left), equal to c (middle), and greater than c (right).</p><p attribs="{'xml:space': 'preserve'}" id="_13249" smilref="Title.smil#_13249" /><pagenum id="p761" page="normal" smilref="Title.smil#p761" /><p attribs="{'xml:space': 'preserve'}" id="_13250" smilref="Title.smil#_13250"> 748</p><p attribs="{'xml:space': 'preserve'}" id="_13251" smilref="Title.smil#_13251"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13252" smilref="Title.smil#_13252"> TST and its corresponding trie are illustrated above. Continuing the correspondence described in Chapter 3 between binary search trees and sorting algorithms, we see that TSTs correspond to 3-way string quicksort in the same way that BSTs correspond to quicksort and tries correspond to MSD sorting. The figures on page 714 and 721, which show the recursive call structure for MSD and 3-way three-way string quicksort (respectively), correspond precisely to the trie and TST drawn on page 746 for that set of keys. Space for links in tries corresponds to the space for counters in string sorting; 3-way branching provides an effective solution to both problems.</p><p attribs="{'xml:space': 'preserve'}" id="_13253" smilref="Title.smil#_13253"> standard array of links (R = 26)</p><p attribs="{'xml:space': 'preserve'}" id="_13254" smilref="Title.smil#_13254"> ternary search tree (TST )</p><p attribs="{'xml:space': 'preserve'}" id="_13255" smilref="Title.smil#_13255"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13256" smilref="Title.smil#_13256"> link for keys that start with s</p><p attribs="{'xml:space': 'preserve'}" id="_13257" smilref="Title.smil#_13257"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13258" smilref="Title.smil#_13258"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13259" smilref="Title.smil#_13259"> u</p><p attribs="{'xml:space': 'preserve'}" id="_13260" smilref="Title.smil#_13260"> Trie node representations</p><p attribs="{'xml:space': 'preserve'}" id="_13261" smilref="Title.smil#_13261"> s</p><p attribs="{'xml:space': 'preserve'}" id="_13262" smilref="Title.smil#_13262"> h</p><p attribs="{'xml:space': 'preserve'}" id="_13263" smilref="Title.smil#_13263"> e</p><p attribs="{'xml:space': 'preserve'}" id="_13264" smilref="Title.smil#_13264"> u</p><p attribs="{'xml:space': 'preserve'}" id="_13265" smilref="Title.smil#_13265"> link for keys that start with su</p><p attribs="{'xml:space': 'preserve'}" id="_13266" smilref="Title.smil#_13266" /><pagenum id="p762" page="normal" smilref="Title.smil#p762" /><p attribs="{'xml:space': 'preserve'}" id="_13267" smilref="Title.smil#_13267"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13268" smilref="Title.smil#_13268"> 749</p><p attribs="{'xml:space': 'preserve'}" id="_13269" smilref="Title.smil#_13269"> Properties of TSTs A TST is a compact representation of an R-way trie, but the two data structures have remarkably different properties. Perhaps the most important difference is that Property A does not hold for TSTs: the BST representations of each trie node depend on the order of key insertion, as with any other BST.</p><p attribs="{'xml:space': 'preserve'}" id="_13270" smilref="Title.smil#_13270"> Space. The most important property of TSTs is that they have just three links in each node, so a TST requires far less space than the corresponding trie.</p><p attribs="{'xml:space': 'preserve'}" id="_13271" smilref="Title.smil#_13271"> Proposition J. The number of links in a TST built from N string keys of average length w is between 3N and 3Nw. Proof. Immediate, by the same argument as for Proposition I.</p><p attribs="{'xml:space': 'preserve'}" id="_13272" smilref="Title.smil#_13272"> Actual space usage is generally less than the upper bound of three links per character, because keys with common prefixes share nodes at high levels in the tree.</p><p attribs="{'xml:space': 'preserve'}" id="_13273" smilref="Title.smil#_13273"> Search cost. To determine the cost of search (and insert) in a TST, we multiply the cost for the corresponding trie by the cost of traversing the BST representation of each trie node..</p><p attribs="{'xml:space': 'preserve'}" id="_13274" smilref="Title.smil#_13274"> Proposition K. A search miss in a TST built from N random string keys requires ~ln N character compares, on the average. A search hit or an insertion in a TST uses a character compare for each character in the search key.</p><p attribs="{'xml:space': 'preserve'}" id="_13275" smilref="Title.smil#_13275"> Proof : The search hit/insertion cost is immediate from the code. The search miss cost is a consequence of the same arguments discussed in the proof sketch of Prop- osition H. We assume that all but a constant number of the nodes on the search path (a few at the top) act as random BSTs on R character values with average path length ln R, so we multiply the time cost logR N = ln N / ln R by ln R.</p><p attribs="{'xml:space': 'preserve'}" id="_13276" smilref="Title.smil#_13276"> In the worst case, a node might be a full R-way node that is unbalanced, stretched out like a singly linked list, so we would need to multiply by a factor of R. More typically, we might expect to do ln R or fewer character compares at the first level (since the root node behaves like a random BST on the R different character values) and perhaps at a few other levels (if there are keys with a common prefix and up to R different values on the character following the pre&#64257; x), and to do only a few compares for most characters (since most trie nodes are sparsely populated with non-null links). Search misses are likely to involve only a few character compares, ending at a null link high in the trie,</p><p attribs="{'xml:space': 'preserve'}" id="_13277" smilref="Title.smil#_13277" /><pagenum id="p763" page="normal" smilref="Title.smil#p763" /><p attribs="{'xml:space': 'preserve'}" id="_13278" smilref="Title.smil#_13278"> 750</p><p attribs="{'xml:space': 'preserve'}" id="_13279" smilref="Title.smil#_13279"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13280" smilref="Title.smil#_13280"> and search hits involve only about one compare per search key character, since most of them are in nodes with one-way branching at the bottom of the trie.</p><p attribs="{'xml:space': 'preserve'}" id="_13281" smilref="Title.smil#_13281"> Alphabet. The prime virtue of using TSTs is that they adapt gracefully to irregularities in search keys that are likely to appear in practical applications. In particular, note that there is no reason to allow for strings to be built from a client-supplied alphabet, as was crucial for tries. There are two main effects. First, keys in practical applications come from large alphabets, and usage of particular characters in the character sets is far from uniform. With TSTs, we can use a 256-character ASCII encoding or a 65,536-character Unicode encoding without having to worry about the excessive costs of nodes with 256- or 65,536-way branching, and without having to determine which sets of characters are relevant. Unicode strings in non-Roman alphabets can have thousands of characters&#8212; TSTs are especially appropriate for standard Java String keys that consist of such char- acters. Second, keys in practical applications often have a structured format, differing from application to application, perhaps using only letters in one part of the key, only digits in another part of the key. In our CA license plate example, the second, third, and fourth characters are uppercase letter (R = 26) and the other characters are decimal digits (R = 10). In a TST for such keys, some of the trie nodes will be represented as 10-node BSTs (for places where all keys have digits) and others will be represented as 26-node BSTs (for places where all keys have letters). This structure develops automati- cally, without any need for special analysis of the keys.</p><p attribs="{'xml:space': 'preserve'}" id="_13282" smilref="Title.smil#_13282"> Pre&#64257; x match, collecting keys, and wildcard match. Since a TST represents a</p><p attribs="{'xml:space': 'preserve'}" id="_13283" smilref="Title.smil#_13283"> trie, implementations of longestPrefixOf(), keys(), keysWithPrefix(), and</p><p attribs="{'xml:space': 'preserve'}" id="_13284" smilref="Title.smil#_13284"> keysThatMatch() are easily adapted from the corresponding code for tries in the previous section, and a worthwhile exercise for you to cement your understanding of both tries and TSTs (see Exercise 5.2.9). The same tradeoff as for search (linear memory usage but an extra ln R multiplicative factor per character compare) holds.</p><p attribs="{'xml:space': 'preserve'}" id="_13285" smilref="Title.smil#_13285"> Deletion. The delete() method for TSTs requires more work. Essentially, each character in the key to be deleted belongs to a BST. In a trie, we could remove the link corresponding to a character by setting the corresponding entry in the array of links to null; in a TST, we have to use BST node deletion to remove the node corresponding to the character.</p><p attribs="{'xml:space': 'preserve'}" id="_13286" smilref="Title.smil#_13286"> Hybrid TSTs. An easy improvement to TST-based search is to use a large explicit multiway node at the root. The simplest way to proceed is to keep a table of R TSTs: one for each possible value of the first character in the keys. If R is not large, we might use the first two letters of the keys (and a table of size R 2). For this method to be effec- tive, the leading digits of the keys must be well-distributed. The resulting hybrid search</p><p attribs="{'xml:space': 'preserve'}" id="_13287" smilref="Title.smil#_13287" /><pagenum id="p764" page="normal" smilref="Title.smil#p764" /><p attribs="{'xml:space': 'preserve'}" id="_13288" smilref="Title.smil#_13288"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13289" smilref="Title.smil#_13289"> 751</p><p attribs="{'xml:space': 'preserve'}" id="_13290" smilref="Title.smil#_13290"> algorithm corresponds to the way that a human might search for names in a telephone book. The first step is a multiway decision (&#8220;Let&#8217;s see, it starts with &#8216;A&#8217;,&#8217;&#8217;), followed perhaps by some two-way decisions (&#8220;It&#8217;s before &#8216;Andrews,&#8217; but after &#8216;Aitken,&#8217;&#8217;&#8217;), followed by sequential character matching (&#8220;&#8216;Algonquin,&#8217; ... No, &#8216;Algorithms&#8217; isn&#8217;t listed, because nothing starts with &#8216;Algor&#8217;!&#8217;&#8217;). These programs are likely to be among the fastest available for searching with string keys.</p><p attribs="{'xml:space': 'preserve'}" id="_13291" smilref="Title.smil#_13291"> One-way branching. Just as with tries, we can make TSTs more efficient in their use of space by putting keys in leaves at the point where they are distinguished and by eliminating one-way branching between internal nodes.</p><p attribs="{'xml:space': 'preserve'}" id="_13292" smilref="Title.smil#_13292"> Proposition L. A search or an insertion in a TST built from N random string keys with no external one-way branching and R t-way branching at the root requires roughly ln N &#11002; t ln R character compares, on the average.</p><p attribs="{'xml:space': 'preserve'}" id="_13293" smilref="Title.smil#_13293"> Proof : These rough estimates follow from the same argument we used to prove Proposition K. We assume that all but a constant number of the nodes on the search path (a few at the top) act as random BSTs on R character values, so we multiply the time cost by ln R.</p><p attribs="{'xml:space': 'preserve'}" id="_13294" smilref="Title.smil#_13294"> Despite the temptation to tune the algorithm to peak performance, we should not lose sight of the fact that one of the most attractive features of TSTs is that they free us from having to worry about application-speci&#64257; c dependencies, often providing good performance without any tuning.</p><p attribs="{'xml:space': 'preserve'}" id="_13295" smilref="Title.smil#_13295" /><pagenum id="p765" page="normal" smilref="Title.smil#p765" /><p attribs="{'xml:space': 'preserve'}" id="_13296" smilref="Title.smil#_13296"> 752</p><p attribs="{'xml:space': 'preserve'}" id="_13297" smilref="Title.smil#_13297"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13298" smilref="Title.smil#_13298"> Which string symbol-table implementation should I use? As with string</p><p attribs="{'xml:space': 'preserve'}" id="_13299" smilref="Title.smil#_13299"> sorting, we are naturally interested in how the string-searching methods that we have considered compare to the general-purpose methods that we considered in Chapter 3. The following table summarizes the important characteristics of the algorithms that we have discussed in this section (the rows for BSTs, red-black BSTs and hashing are included from Chapter 3, for comparison). For a particular application, these entries must be taken as indicative, not defi nitive, since so many factors (such as characteristics of keys and mix of operations) come into play when studying symbol-table implementations.</p><p attribs="{'xml:space': 'preserve'}" id="_13300" smilref="Title.smil#_13300"> algorithm (data structure)</p><p attribs="{'xml:space': 'preserve'}" id="_13301" smilref="Title.smil#_13301"> binary tree search (BST) 2-3 tree search (red-black BST) linear probing&#8224; (parallel arrays) trie search (R-way trie)</p><p attribs="{'xml:space': 'preserve'}" id="_13302" smilref="Title.smil#_13302"> trie search (TST)</p><p attribs="{'xml:space': 'preserve'}" id="_13303" smilref="Title.smil#_13303"> typical growth rate for N strings from an R-character alphabet (average length w)</p><p attribs="{'xml:space': 'preserve'}" id="_13304" smilref="Title.smil#_13304"> characters examined for search miss</p><p attribs="{'xml:space': 'preserve'}" id="_13305" smilref="Title.smil#_13305"> c1 (lg N )2</p><p attribs="{'xml:space': 'preserve'}" id="_13306" smilref="Title.smil#_13306"> c2 (lg N )2</p><p attribs="{'xml:space': 'preserve'}" id="_13307" smilref="Title.smil#_13307"> memory usage</p><p attribs="{'xml:space': 'preserve'}" id="_13308" smilref="Title.smil#_13308"> 64N</p><p attribs="{'xml:space': 'preserve'}" id="_13309" smilref="Title.smil#_13309"> 64N</p><p attribs="{'xml:space': 'preserve'}" id="_13310" smilref="Title.smil#_13310"> w</p><p attribs="{'xml:space': 'preserve'}" id="_13311" smilref="Title.smil#_13311"> 32N to 128N</p><p attribs="{'xml:space': 'preserve'}" id="_13312" smilref="Title.smil#_13312"> log R N</p><p attribs="{'xml:space': 'preserve'}" id="_13313" smilref="Title.smil#_13313"> (8R&#11001;56)N to (8R&#11001;56)Nw</p><p attribs="{'xml:space': 'preserve'}" id="_13314" smilref="Title.smil#_13314"> sweet spot</p><p attribs="{'xml:space': 'preserve'}" id="_13315" smilref="Title.smil#_13315"> randomly ordered keys guaranteed performance built-in types cached hash values short keys small alphabets</p><p attribs="{'xml:space': 'preserve'}" id="_13316" smilref="Title.smil#_13316"> 1.39 lg N</p><p attribs="{'xml:space': 'preserve'}" id="_13317" smilref="Title.smil#_13317"> 64N to 64Nw</p><p attribs="{'xml:space': 'preserve'}" id="_13318" smilref="Title.smil#_13318"> nonrandom keys</p><p attribs="{'xml:space': 'preserve'}" id="_13319" smilref="Title.smil#_13319"> Performance characteristics of string-searching algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_13320" smilref="Title.smil#_13320"> If space is available, R-way tries provide the fastest search, essentially completing the job with a constant number of character compares. For large alphabets, where space may not be available for R-way tries, TSTs are preferable, since they use a logarithmic number of character compares, while BSTs use a logarithmic number of key compares. Hashing can be competitive, but, as usual, cannot support ordered symbol-table operations or extended character-based API operations such as prefix or wildcard match.</p><p attribs="{'xml:space': 'preserve'}" id="_13321" smilref="Title.smil#_13321" /><pagenum id="p766" page="normal" smilref="Title.smil#p766" /><p attribs="{'xml:space': 'preserve'}" id="_13322" smilref="Title.smil#_13322"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13323" smilref="Title.smil#_13323"> 753</p><p attribs="{'xml:space': 'preserve'}" id="_13324" smilref="Title.smil#_13324"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_13325" smilref="Title.smil#_13325"> Q. Does the Java system sort use one of these methods for searching with String keys? A. No.</p><p attribs="{'xml:space': 'preserve'}" id="_13326" smilref="Title.smil#_13326" /><pagenum id="p767" page="normal" smilref="Title.smil#p767" /><p attribs="{'xml:space': 'preserve'}" id="_13327" smilref="Title.smil#_13327"> 754</p><p attribs="{'xml:space': 'preserve'}" id="_13328" smilref="Title.smil#_13328"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13329" smilref="Title.smil#_13329"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_13330" smilref="Title.smil#_13330"> 5.2.1 Draw the R-way trie that results when the keys</p><p attribs="{'xml:space': 'preserve'}" id="_13331" smilref="Title.smil#_13331"> no is th ti fo al go pe to co to th ai of th pa</p><p attribs="{'xml:space': 'preserve'}" id="_13332" smilref="Title.smil#_13332"> are inserted in that order into an initially empty trie (do not draw null links). 5.2.2 Draw the TST that results when the keys</p><p attribs="{'xml:space': 'preserve'}" id="_13333" smilref="Title.smil#_13333"> no is th ti fo al go pe to co to th ai of th pa</p><p attribs="{'xml:space': 'preserve'}" id="_13334" smilref="Title.smil#_13334"> are inserted in that order into an initially empty TST. 5.2.3 Draw the R-way trie that results when the keys</p><p attribs="{'xml:space': 'preserve'}" id="_13335" smilref="Title.smil#_13335"> now is the time for all good people to come to the aid of</p><p attribs="{'xml:space': 'preserve'}" id="_13336" smilref="Title.smil#_13336"> are inserted in that order into an initially empty trie (do not draw null links). 5.2.4 Draw the TST that results when the keys</p><p attribs="{'xml:space': 'preserve'}" id="_13337" smilref="Title.smil#_13337"> now is the time for all good people to come to the aid of</p><p attribs="{'xml:space': 'preserve'}" id="_13338" smilref="Title.smil#_13338"> are inserted in that order into an initially empty TST. 5.2.5 Develop nonrecursive versions of TrieST and TST. 5.2.6 Implement the following API, for a StringSET data type:</p><p attribs="{'xml:space': 'preserve'}" id="_13339" smilref="Title.smil#_13339"> public class StringSET</p><p attribs="{'xml:space': 'preserve'}" id="_13340" smilref="Title.smil#_13340"> StringSET()</p><p attribs="{'xml:space': 'preserve'}" id="_13341" smilref="Title.smil#_13341"> void add(String key)</p><p attribs="{'xml:space': 'preserve'}" id="_13342" smilref="Title.smil#_13342"> void delete(String key)</p><p attribs="{'xml:space': 'preserve'}" id="_13343" smilref="Title.smil#_13343"> boolean contains(String key)</p><p attribs="{'xml:space': 'preserve'}" id="_13344" smilref="Title.smil#_13344"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_13345" smilref="Title.smil#_13345"> int size()</p><p attribs="{'xml:space': 'preserve'}" id="_13346" smilref="Title.smil#_13346"> int toString()</p><p attribs="{'xml:space': 'preserve'}" id="_13347" smilref="Title.smil#_13347"> create a string set put key into the set remove key from the set is key in the set? is the set empty? number of keys in the set string representation of the set</p><p attribs="{'xml:space': 'preserve'}" id="_13348" smilref="Title.smil#_13348"> API for a string set data type</p><p attribs="{'xml:space': 'preserve'}" id="_13349" smilref="Title.smil#_13349" /><pagenum id="p768" page="normal" smilref="Title.smil#p768" /><p attribs="{'xml:space': 'preserve'}" id="_13350" smilref="Title.smil#_13350"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13351" smilref="Title.smil#_13351"> 755</p><p attribs="{'xml:space': 'preserve'}" id="_13352" smilref="Title.smil#_13352"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_13353" smilref="Title.smil#_13353"> 5.2.7 Empty string in TSTs. The code in TST does not handle the empty string prop- erly. Explain the problem and suggest a correction. 5.2.8 Ordered operations for tries. Implement the floor(), ceil(), rank(), and select() (from our standard ordered ST API from Chapter 3) for TrieST. 5.2.9 Extended operations for TSTs. Implement keys() and the extended operations introduced in this section&#8212;longestPrefixOf(), keysWithPrefix(), and</p><p attribs="{'xml:space': 'preserve'}" id="_13354" smilref="Title.smil#_13354"> keysThatMatch()&#8212;for TST.</p><p attribs="{'xml:space': 'preserve'}" id="_13355" smilref="Title.smil#_13355"> 5.2.10 Size. Implement very eager size() (that keeps in each node the number of keys in its subtree) for TrieST and TST. 5.2.11 External one-way branching. Add code to TrieST and TST to eliminate external one-way branching. 5.2.12 Internal one-way branching. Add code to TrieST and TST to eliminate internal one-way branching. 5.2.13 Hybrid TST with R2-way branching at the root. Add code to TST to do multiway branching at the first two levels, as described in the text. 5.2.14 Unique substrings of length L. Write a TST client that reads in text from standard input and calculates the number of unique substrings of length L that it contains. For example, if the input is cgcgggcgcg, then there are five unique substrings of length 3: cgc, cgg, gcg, ggc, and ggg. Hint : Use the string method substring(i, i + L) to extract the ith substring, then insert it into a symbol table. 5.2.15 Unique substrings. Write a TST client that reads in text from standard input and calculates the number of distinct substrings of any length. This can be done very efficiently with a suffix tree&#8212;see Chapter 6 5.2.16 Document similarity. Write a TST client with a static method that takes an int value L and two file names as command-line arguments and computes the L-similarity of the two documents: the Euclidean distance between the frequency vectors defined by the number of occurrences of each trigram divided by the number of trigrams. Include a static method main() that takes an int value L as command-line argument and a list of file names from standard input and prints a matrix showing the L-similarity of all pairs of documents.</p><p attribs="{'xml:space': 'preserve'}" id="_13356" smilref="Title.smil#_13356" /><pagenum id="p769" page="normal" smilref="Title.smil#p769" /><p attribs="{'xml:space': 'preserve'}" id="_13357" smilref="Title.smil#_13357"> 756</p><p attribs="{'xml:space': 'preserve'}" id="_13358" smilref="Title.smil#_13358"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13359" smilref="Title.smil#_13359"> CREATIVE PROBLEMS (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_13360" smilref="Title.smil#_13360"> 5.2.17 Spell checking. Write a TST client SpellChecker that takes as command-line argument the name of a file containing a dictionary of words in the English language, and then reads a string from standard input and prints out any word that is not in the dictionary. Use a string set. 5.2.18 Whitelist. Write a TST client that solves the whitelisting problem presented in Section 1.1 and revisited in Section 3.5 (see page 491). 5.2.19 Random phone numbers. Write a TrieST client (with R = 10) that takes as command line argument an int value N and prints N random phone numbers of the form (xxx) xxx-xxxx. Use a symbol table to avoid choosing the same number more than once. Use the file AreaCodes.txt from the booksite to avoid printing out bogus area codes. 5.2.20 Contains pre&#64257; x. Add a method containsPrefix() to StringSET (see Exer- cise 5.2.6) that takes a string s as input and returns true if there is a string in the set that contains s as a pre&#64257; x. 5.2.21 Substring matches. Given a list of (short) strings, your goal is to support queries where the user looks up a string s and your job is to report back all strings in the list that contain s. Design an API for this task and develop a TST client that implements your API. Hint : Insert the suffixes of each word (e.g., string, tring, ring, ing, ng, g) into the TST. 5.2.22 Typing monkeys. Suppose that a typing monkey creates random words by appending each of 26 possible letter with probability p to the current word and finishes the word with probability 1 &#11002; 26p. Write a program to estimate the frequency distribution of the lengths of words produced. If "abc" is produced more than once, count it only once.</p><p attribs="{'xml:space': 'preserve'}" id="_13361" smilref="Title.smil#_13361" /><pagenum id="p770" page="normal" smilref="Title.smil#p770" /><p attribs="{'xml:space': 'preserve'}" id="_13362" smilref="Title.smil#_13362"> 5.2 </p><p attribs="{'xml:space': 'preserve'}" id="_13363" smilref="Title.smil#_13363"> 757</p><p attribs="{'xml:space': 'preserve'}" id="_13364" smilref="Title.smil#_13364"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_13365" smilref="Title.smil#_13365"> 5.2.23 Duplicates (revisited again). Redo Exercise 3.5.30 using StringSET (see Ex- ercise 5.2.6) instead of HashSET. Compare the running times of the two approaches. Then use Dedup to run the experiments for N = 10 7, 10 8, and10 9, repeat the experiments for random long values and discuss the results. 5.2.24 Spell checker. Redo Exercise 3.5.31, which uses the file dictionary.txt from the booksite and the BlackFilter client on page 491 to print all misspelled words in a text fi le. Compare the performance of TrieST and TST for the file war.txt with this client and discuss the results. 5.2.25 Dictionary. Redo Exercise 3.5.32: Study the performance of a client like LookupCSV (using TrieST and TST) in a scenario where performance matters. Speci&#64257; - cally, design a query-generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries. 5.2.26 Indexing. Redo Exercise 3.5.33: Study a client like LookupIndex (using TrieST and TST) in a scenario where performance matters. Speci&#64257; cally, design a query- generation scenario instead of taking commands from standard input, and run performance tests for large inputs and large numbers of queries.</p><p attribs="{'xml:space': 'preserve'}" id="_13366" smilref="Title.smil#_13366" /><pagenum id="p772" page="normal" smilref="Title.smil#p772" /><p attribs="{'xml:space': 'preserve'}" id="_13367" smilref="Title.smil#_13367"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13368" smilref="Title.smil#_13368"> 759</p><p attribs="{'xml:space': 'preserve'}" id="_13369" smilref="Title.smil#_13369"> A short history The algorithms that we examine have an interesting history ; we summarize it here to help place the various methods in perspective. There is a simple brute-force algorithm for substring search that is in widespread use. While it has a worst-case running time proportional to MN, the strings that arise in many applications lead to a running time that is (except in pathological cases) proportional to M &#11001; N. Furthermore, it is well-suited to standard architectural features on most computer systems, so an optimized version provides a standard benchmark that is difficult to beat, even with a clever algorithm. In 1970, S. Cook proved a theoretical result about a particular type of abstract machine that implied the existence of an algorithm that solves the substring search problem in time proportional to M &#11001; N in the worst case. D. E. Knuth and V. R. Pratt laboriously followed through the construction Cook used to prove his theorem (which was not intended to be practical) and refined it into a relatively simple and practical algo- rithm. This seemed a rare and satisfying example of a theoretical result with immediate (and unexpected) practical applicability. But it turned out that J. H. Morris had discovered virtually the same algorithm as a solution to an annoying problem confronting him when implementing a text editor (he wanted to avoid having to &#8220;back up&#8217;&#8217; in the text string). The fact that the same algorithm arose from two such different approaches lends it credibility as a fundamental solution to the problem. Knuth, Morris, and Pratt didn&#8217;t get around to publishing their algorithm until 1976, and in the meantime R. S. Boyer and J. S. Moore (and, independently, R. W. Gosper) discovered an algorithm that is much faster in many applications, since it often examines only a fraction of the characters in the text string. Many text editors use this algorithm to achieve a noticeable decrease in response time for substring search. Both the Knuth-Morris-Pratt (KMP) and the Boyer-Moore algorithms require some complicated preprocessing on the pattern that is difficult to understand and has limited the extent to which they are used. (In fact, the story goes that an unknown systems programmer found Morris&#8217;s algorithm too difficult to understand and replaced it with a brute-force implementation.) In 1980, M. O. Rabin and R. M. Karp used hashing to develop an algorithm almost as simple as the brute-force algorithm that runs in time proportional to M &#11001; N with very high probability. Furthermore, their algorithm extends to two-dimensional patterns and text, which makes it more useful than the others for image processing. This story illustrates that the search for a better algorithm is still very often justi&#64257; ed; indeed, one suspects that there are still more developments on the horizon even for this classic problem.</p><p attribs="{'xml:space': 'preserve'}" id="_13370" smilref="Title.smil#_13370" /></level3><level3 id="_00104"><h3 id="ch5-s3-ss8" smilref="Title.smil#ch5-s3-ss8" xml:space="preserve">Brute-force algorithm</h3><pagenum id="p773" page="normal" smilref="Title.smil#p773" /><p attribs="{'xml:space': 'preserve'}" id="_13371" smilref="Title.smil#_13371"> 760</p><p attribs="{'xml:space': 'preserve'}" id="_13372" smilref="Title.smil#_13372"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13373" smilref="Title.smil#_13373"> public static int search(String pat, String txt) { int M = pat.length(); int N = txt.length(); for (int i = 0; i &lt;= N - M; i++) { int j; for (j = 0; j &lt; M; j++) if (txt.charAt(i+j) != pat.charAt(j)) break; if (j == M) return i; // found } return N; // not found }</p><p attribs="{'xml:space': 'preserve'}" id="_13374" smilref="Title.smil#_13374"> Brute-force substring search An obvious method for substring search is to check, for each possible position in the text at which the pattern could match, whether it does in fact match. The search() method below operates in this way to find the first occurrence of a pattern string pat in a text string txt. The program keeps one pointer (i) into the text and another pointer (j) into the pattern. For each i, it resets j to 0 and increments it until finding a mismatch or the end of the pattern (j == M). If we reach the end of the text (i == N-M+1) before the end of the pattern, then there is no match: the pattern does not occur in the text. Our convention is to return the value N to indicate a mismatch. In a typical text-processing ap- plication, the j index rarely increments so the running time is proportional to N. Nearly all of the compares find a mismatch with the first character of the pattern. For example, suppose that you search for the pattern pattern in the text of this paragraph. There are 191 characters up to the end of the first occurrence of the pattern, only 7 of which are the character p (and there are no occurrences of pa), so the total number of character compares is 191+7, for an average of 1.036 compares per character in the text. On the other hand, there is no guarantee that the algorithm will always be so ef&#64257; cient. For example, a pattern might begin with a long string of As. If it does, and the text also has long strings of As, then the substring search will be slow.</p><p attribs="{'xml:space': 'preserve'}" id="_13375" smilref="Title.smil#_13375"> Brute-force substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13376" smilref="Title.smil#_13376"> txt</p><p attribs="{'xml:space': 'preserve'}" id="_13377" smilref="Title.smil#_13377"> pat</p><p attribs="{'xml:space': 'preserve'}" id="_13378" smilref="Title.smil#_13378"> i j i+j 0 1 2 3 4 5 6 7 8 9 10 A B A C A D A B R A C 0 2 2 A B R A 1 0 1 A B R A 2 1 3 A B R A 3 0 3 A B R A 4 1 5 A B R A 5 0 5 A B R A 6 4 10 A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_13379" smilref="Title.smil#_13379"> entries in red are mismatches</p><p attribs="{'xml:space': 'preserve'}" id="_13380" smilref="Title.smil#_13380"> entries in black match the text</p><p attribs="{'xml:space': 'preserve'}" id="_13381" smilref="Title.smil#_13381"> entries in gray are for reference only</p><p attribs="{'xml:space': 'preserve'}" id="_13382" smilref="Title.smil#_13382"> return i when j is M</p><p attribs="{'xml:space': 'preserve'}" id="_13383" smilref="Title.smil#_13383"> match</p><p attribs="{'xml:space': 'preserve'}" id="_13384" smilref="Title.smil#_13384"> Brute-force substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13385" smilref="Title.smil#_13385" /><pagenum id="p774" page="normal" smilref="Title.smil#p774" /><p attribs="{'xml:space': 'preserve'}" id="_13386" smilref="Title.smil#_13386"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13387" smilref="Title.smil#_13387"> 761</p><p attribs="{'xml:space': 'preserve'}" id="_13388" smilref="Title.smil#_13388"> Proposition M. Brute-force substring search requires ~NM character compares to search for a pattern of length M in a text of length N, in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_13389" smilref="Title.smil#_13389"> Proof : A worst-case input is when both pattern and text are all As followed by a B. Then for each of the N &#11002; M &#11001; 1 possible match positions, all the characters in the pattern are checked against the text, for a total cost of M(N &#11002; M &#11001; 1). Normally M is very small compared to N, so the total is ~NM.</p><p attribs="{'xml:space': 'preserve'}" id="_13390" smilref="Title.smil#_13390"> txt</p><p attribs="{'xml:space': 'preserve'}" id="_13391" smilref="Title.smil#_13391"> pat</p><p attribs="{'xml:space': 'preserve'}" id="_13392" smilref="Title.smil#_13392"> i j i+j 0 1 2 3 4 5 6 7 8 9 A A A A A A A A A B 0 4 4 A A A A B 1 4 5 A A A A B 2 4 6 A A A A B 3 4 7 A A A A B 4 4 8 A A A A B 5 5 10 A A A A B</p><p attribs="{'xml:space': 'preserve'}" id="_13393" smilref="Title.smil#_13393"> Such degenerate strings are not likely to appear in English text, but they may well occur in other applications (for example, in binary texts), so we seek better algorithms. The alternate implementation at the bottom of this page is instructive. As before, the program keeps one pointer (i) into the text and another pointer (j) into the pattern. As long as they point to matching characters, both pointers are incremented. This code performs precisely the same character compares as the previous implementation. To understand it, note that i in this code maintains the value of i+j in the previous code: it points to the end of the sequence of already-matched characters in the text (where i pointed to the beginning of the sequence before). If i and j point to mismatching characters, then we back up both pointers: j to point to the beginning of the pattern and i to correspond to moving the pattern to the right one position for matching against the text.</p><p attribs="{'xml:space': 'preserve'}" id="_13394" smilref="Title.smil#_13394"> Brute-force substring search (worst case)</p><p attribs="{'xml:space': 'preserve'}" id="_13395" smilref="Title.smil#_13395"> public static int search(String pat, String txt) { int j, M = pat.length(); int i, N = txt.length(); for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) { if (txt.charAt(i) == pat.charAt(j)) j++; else { i -= j; j = 0; } } if (j == M) return i - M; // found else return N; // not found }</p><p attribs="{'xml:space': 'preserve'}" id="_13396" smilref="Title.smil#_13396"> Alternate implementation of brute-force substring search (explicit backup)</p><p attribs="{'xml:space': 'preserve'}" id="_13397" smilref="Title.smil#_13397" /></level3><level3 id="_00105"><h3 id="ch5-s3-ss9" smilref="Title.smil#ch5-s3-ss9" xml:space="preserve">Knuth-Morric-Pratt algorithm</h3><pagenum id="p775" page="normal" smilref="Title.smil#p775" /><p attribs="{'xml:space': 'preserve'}" id="_13398" smilref="Title.smil#_13398"> 762</p><p attribs="{'xml:space': 'preserve'}" id="_13399" smilref="Title.smil#_13399"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13400" smilref="Title.smil#_13400"> Knuth-Morris-Pratt substring search The basic idea behind the algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_13401" smilref="Title.smil#_13401"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13402" smilref="Title.smil#_13402"> text</p><p attribs="{'xml:space': 'preserve'}" id="_13403" smilref="Title.smil#_13403"> after mismatch on sixth char</p><p attribs="{'xml:space': 'preserve'}" id="_13404" smilref="Title.smil#_13404"> brute-force backs up to try this</p><p attribs="{'xml:space': 'preserve'}" id="_13405" smilref="Title.smil#_13405"> pattern</p><p attribs="{'xml:space': 'preserve'}" id="_13406" smilref="Title.smil#_13406"> B A A A A A A A A A</p><p attribs="{'xml:space': 'preserve'}" id="_13407" smilref="Title.smil#_13407"> and this and this and this and this</p><p attribs="{'xml:space': 'preserve'}" id="_13408" smilref="Title.smil#_13408"> A B A A A A B A A A A A A A A A B A A A A A A A A A B A A A A A A A A A B A A A A A A A A A B A A A A A A A A A B A A A A A A A A A B A A A A A A A A A</p><p attribs="{'xml:space': 'preserve'}" id="_13409" smilref="Title.smil#_13409"> discovered by Knuth, Morris, and Pratt is this: whenever we detect a mismatch, we already know some of the characters in the text (since they matched the pattern characters prior to the mismatch). We can take advantage of this information to avoid backing up the text pointer over all those known characters. As a specific example, suppose that we have a two-character alphabet and are searching for the pattern B A A A A A A A A A. Now, suppose that we match five characters in the pattern, with a mismatch on the sixth. When the mismatch is detected, we know that the six previous characters in the text must be B A A A A B (the first five match and the sixth does not), with the text pointer now pointing at the B at the end. The key observation is that we need not back up the text pointer i, since the previous four characters in the text are all As and do not match the first character in the pat- tern. Furthermore, the character currently pointed to by i is a B and does match the first character in the pattern, so we can increment i and compare the next character in the text with the second character in the pattern. This argument leads to the observation that, for this pattern, we can change the else clause in the alternate brute-force implementation to just set j = 1 (and not decrement i). Since the value of i does not change within the loop, this method does at most N character compares. The practical effect of this particular change is limited to this particular pattern, but the idea is worth thinking about&#8212;the Knuth-Morris-Pratt algorithm is a generalization of it. Surprisingly, it is always possible to find a value to set the j pointer to on a mismatch, so that the i pointer is never decremented. Fully skipping past all the matched characters when detecting a mismatch will not work when the pattern could match itself at any position overlapping the point of the mismatch. For example, when searching for the pattern A A B A A A in the text A A B A A B A A A A, we first detect the mismatch at position 5, but we had better restart at position 3 to continue the search, since otherwise we would miss the match. The insight of the KMP algorithm is that we can decide ahead of time exactly how to restart the search, because that decision depends only on the pattern.</p><p attribs="{'xml:space': 'preserve'}" id="_13410" smilref="Title.smil#_13410"> but no backup is needed</p><p attribs="{'xml:space': 'preserve'}" id="_13411" smilref="Title.smil#_13411"> Text pointer backup in substring searching</p><p attribs="{'xml:space': 'preserve'}" id="_13412" smilref="Title.smil#_13412" /><pagenum id="p776" page="normal" smilref="Title.smil#p776" /><p attribs="{'xml:space': 'preserve'}" id="_13413" smilref="Title.smil#_13413"> Backing up the pattern pointer. In KMP sub-</p><p attribs="{'xml:space': 'preserve'}" id="_13414" smilref="Title.smil#_13414"> string search, we never back up the text pointer i, and we use an array dfa[][] to record how far to back up the pattern pointer j when a mismatch is detected. For every character c, dfa[c][j] is the pattern position to compare against the next text position after comparing c with pat.charAt(j). During the search, dfa[txt.charAt(i)][j] is the pattern position to compare with txt.charAt(i+1) after com-</p><p attribs="{'xml:space': 'preserve'}" id="_13415" smilref="Title.smil#_13415"> paring txt.charAt(i) with pat.charAt(j).</p><p attribs="{'xml:space': 'preserve'}" id="_13416" smilref="Title.smil#_13416"> For a match, we want to just move on to the next character, so dfa[pat.charAt(j)][j] is always j+1. For a mismatch, we know not just txt.charAt(i), but also the j-1 previous characters in the text: they are the first j-1 characters in the pattern. For each character c, imagine that we slide a copy of the pattern over these j characters (the first j-1 characters in the pattern followed by c&#8212;we are deciding what to do when these characters are txt.charAt(i-j+1..i)), from left to right, stopping when all overlapping characters match (or there are none). This gives the next possible place the pattern could match. The index of the pattern character to compare with txt.charAt(i+1) is precisely the number of overlapping characters.</p><p attribs="{'xml:space': 'preserve'}" id="_13417" smilref="Title.smil#_13417"> (dfa[txt.charAt(i)][j])</p><p attribs="{'xml:space': 'preserve'}" id="_13418" smilref="Title.smil#_13418"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13419" smilref="Title.smil#_13419"> 763</p><p attribs="{'xml:space': 'preserve'}" id="_13420" smilref="Title.smil#_13420"> j pat.charAt(j) dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13421" smilref="Title.smil#_13421"> A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13422" smilref="Title.smil#_13422"> text (pattern itself )</p><p attribs="{'xml:space': 'preserve'}" id="_13423" smilref="Title.smil#_13423"> A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13424" smilref="Title.smil#_13424"> 0 A 1</p><p attribs="{'xml:space': 'preserve'}" id="_13425" smilref="Title.smil#_13425"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13426" smilref="Title.smil#_13426"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13427" smilref="Title.smil#_13427"> 1 B 2</p><p attribs="{'xml:space': 'preserve'}" id="_13428" smilref="Title.smil#_13428"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13429" smilref="Title.smil#_13429"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13430" smilref="Title.smil#_13430"> 2 A 3</p><p attribs="{'xml:space': 'preserve'}" id="_13431" smilref="Title.smil#_13431"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13432" smilref="Title.smil#_13432"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13433" smilref="Title.smil#_13433"> 3 B 4</p><p attribs="{'xml:space': 'preserve'}" id="_13434" smilref="Title.smil#_13434"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13435" smilref="Title.smil#_13435"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13436" smilref="Title.smil#_13436"> 4 A 5</p><p attribs="{'xml:space': 'preserve'}" id="_13437" smilref="Title.smil#_13437"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13438" smilref="Title.smil#_13438"> match (move to next char)</p><p attribs="{'xml:space': 'preserve'}" id="_13439" smilref="Title.smil#_13439"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13440" smilref="Title.smil#_13440"> set dfa[pat.charAt(j)][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13441" smilref="Title.smil#_13441"> to j+1</p><p attribs="{'xml:space': 'preserve'}" id="_13442" smilref="Title.smil#_13442"> A B A B A B A C C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13443" smilref="Title.smil#_13443"> A B A A A B A B A C A C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13444" smilref="Title.smil#_13444"> A B A A B B A B A B A C A B C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13445" smilref="Title.smil#_13445"> A B A B A B A A A B A B A C A B A C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13446" smilref="Title.smil#_13446"> A B A B A A B A B B A B A B A C A B A B C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13447" smilref="Title.smil#_13447"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13448" smilref="Title.smil#_13448"> 5 C 6 A B A B A C A B A B A A A B A B A C A B A B A B A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13449" smilref="Title.smil#_13449"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13450" smilref="Title.smil#_13450"> mismatch (back up in pattern)</p><p attribs="{'xml:space': 'preserve'}" id="_13451" smilref="Title.smil#_13451"> known text char on mismatch</p><p attribs="{'xml:space': 'preserve'}" id="_13452" smilref="Title.smil#_13452"> KMP search method. Once we have computed the dfa[][] array, we have the substring search method at the top of the next page: when i and j point to mismatching characters (testing for a pattern match beginning at position i-j+1 in the text string), then the next possible position for a pattern match is beginning at position i-dfa[txt.charAt(i)][j]. But by construction, the first dfa[txt.charAt(i)][j] characters at that position match the first dfa[txt.charAt(i)][j] characters of the pattern, so there is no need to back up the i pointer: we can simply set j to dfa[txt.charAt(i)][j] and increment i, which is precisely what we do when i and j point to matching characters.</p><p attribs="{'xml:space': 'preserve'}" id="_13453" smilref="Title.smil#_13453"> Pattern backup for A B A B A C in KMP substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13454" smilref="Title.smil#_13454"> backup is length of max overlap of beginning of pattern with known text chars</p><p attribs="{'xml:space': 'preserve'}" id="_13455" smilref="Title.smil#_13455" /><pagenum id="p777" page="normal" smilref="Title.smil#p777" /><p attribs="{'xml:space': 'preserve'}" id="_13456" smilref="Title.smil#_13456"> 764</p><p attribs="{'xml:space': 'preserve'}" id="_13457" smilref="Title.smil#_13457"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13458" smilref="Title.smil#_13458"> KMP substring search (DFA simulation)</p><p attribs="{'xml:space': 'preserve'}" id="_13459" smilref="Title.smil#_13459"> public int search(String txt) { // Simulate operation of DFA on txt. int i, j, N = txt.length(); for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) j = dfa[txt.charAt(i)][j]; if (j == M) return i - M; // found else return N; // not found }</p><p attribs="{'xml:space': 'preserve'}" id="_13460" smilref="Title.smil#_13460"> DFA simulation. A useful way to describe this process is in terms of a deterministic fi nite-state automaton (DFA). Indeed, as indicated by its name, our dfa[][] array precisely defines a DFA. The graphical DFA represention shown at the bottom of this page consists of states (indicated by circled numbers) and transitions (indicated by labeled lines). There is one state for each character in the pattern, each such state having one transition leaving it for each character in the alphabet. For the sub- string-matching DFAs that we are con- sidering, one of the transitions is a match transition (going from j to j+1 and labeled with pat.charAt(j)) and all the others are mismatch transition (going left). The states correspond to character compares, one for each value of the pattern index. The transitions correspond to changing the value of the pattern index. When examining the text character i when in the state labeled j, the machine does the following: &#8220;Take the transition to dfa[txt.charAt(i)][j] and move to the next character (by incrementing i).&#8217;&#8217; For a match transition, we move to the right one position because dfa[pat.charAt(j)][j] is always j+1; for a mismatch transition we move to the left. The automaton reads the text characters one at a time, from left to right, moving to a new state each time it reads a character. We also include a halt state M that has no transitions. We start the machine at state 0: if the machine reaches state M, then a substring of the text matching the pattern has been found (and we say that the DFA recognizes the pattern); if the machine reaches the end of the text before reaching state M, then we know the pattern does not appear as a substring of the text. Each pattern corresponds to an automaton (which is represented by the dfa[][] array that gives the transitions). The KMP substring search() method is a Java program that simulates the operation of such an automaton. To get a feeling for the operation of a substring search DFA, consider two of the simplest things that it does. At</p><p attribs="{'xml:space': 'preserve'}" id="_13461" smilref="Title.smil#_13461"> 0 1 2 3 4 5 A B A B A C 1 1 3 1 5 1 0 2 0 4 0 4 0 0 0 0 0 6</p><p attribs="{'xml:space': 'preserve'}" id="_13462" smilref="Title.smil#_13462"> DFA corresponding to the string A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13463" smilref="Title.smil#_13463"> match transition (increment)</p><p attribs="{'xml:space': 'preserve'}" id="_13464" smilref="Title.smil#_13464"> mismatch transition (back up)</p><p attribs="{'xml:space': 'preserve'}" id="_13465" smilref="Title.smil#_13465"> halt state</p><p attribs="{'xml:space': 'preserve'}" id="_13466" smilref="Title.smil#_13466"> A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13467" smilref="Title.smil#_13467"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13468" smilref="Title.smil#_13468"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13469" smilref="Title.smil#_13469"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13470" smilref="Title.smil#_13470"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13471" smilref="Title.smil#_13471"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13472" smilref="Title.smil#_13472"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13473" smilref="Title.smil#_13473"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13474" smilref="Title.smil#_13474"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13475" smilref="Title.smil#_13475"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_13476" smilref="Title.smil#_13476"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13477" smilref="Title.smil#_13477"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_13478" smilref="Title.smil#_13478"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13479" smilref="Title.smil#_13479"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13480" smilref="Title.smil#_13480"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13481" smilref="Title.smil#_13481"> A B</p><p attribs="{'xml:space': 'preserve'}" id="_13482" smilref="Title.smil#_13482"> internal representation</p><p attribs="{'xml:space': 'preserve'}" id="_13483" smilref="Title.smil#_13483"> j pat.charAt(j)</p><p attribs="{'xml:space': 'preserve'}" id="_13484" smilref="Title.smil#_13484"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13485" smilref="Title.smil#_13485"> graphical representation</p><p attribs="{'xml:space': 'preserve'}" id="_13486" smilref="Title.smil#_13486"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13487" smilref="Title.smil#_13487"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13488" smilref="Title.smil#_13488"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13489" smilref="Title.smil#_13489"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13490" smilref="Title.smil#_13490"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13491" smilref="Title.smil#_13491"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13492" smilref="Title.smil#_13492" /><pagenum id="p778" page="normal" smilref="Title.smil#p778" /><p attribs="{'xml:space': 'preserve'}" id="_13493" smilref="Title.smil#_13493"> read this char</p><p attribs="{'xml:space': 'preserve'}" id="_13494" smilref="Title.smil#_13494"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 B C B A A B A C A A B A B A C A A 0 0 0 0 1 1 2 3 0 1 1 2 3 4 5 6</p><p attribs="{'xml:space': 'preserve'}" id="_13495" smilref="Title.smil#_13495"> in this state</p><p attribs="{'xml:space': 'preserve'}" id="_13496" smilref="Title.smil#_13496"> i txt.charAt(i) j</p><p attribs="{'xml:space': 'preserve'}" id="_13497" smilref="Title.smil#_13497"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13498" smilref="Title.smil#_13498"> 765</p><p attribs="{'xml:space': 'preserve'}" id="_13499" smilref="Title.smil#_13499"> go to this state</p><p attribs="{'xml:space': 'preserve'}" id="_13500" smilref="Title.smil#_13500"> found</p><p attribs="{'xml:space': 'preserve'}" id="_13501" smilref="Title.smil#_13501"> return i - M = 9</p><p attribs="{'xml:space': 'preserve'}" id="_13502" smilref="Title.smil#_13502"> A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13503" smilref="Title.smil#_13503"> pat.charAt(j) with txt.charAt(i+1)</p><p attribs="{'xml:space': 'preserve'}" id="_13504" smilref="Title.smil#_13504"> set j to dfa[txt.charAt(i)][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13505" smilref="Title.smil#_13505"> implies pattern shift to align</p><p attribs="{'xml:space': 'preserve'}" id="_13506" smilref="Title.smil#_13506"> mismatch:</p><p attribs="{'xml:space': 'preserve'}" id="_13507" smilref="Title.smil#_13507"> match:</p><p attribs="{'xml:space': 'preserve'}" id="_13508" smilref="Title.smil#_13508"> set j to dfa[txt.charAt(i)][j] = dfa[pat.charAt(j)][j] = j+1</p><p attribs="{'xml:space': 'preserve'}" id="_13509" smilref="Title.smil#_13509"> Trace of KMP substring search (DFA simulation) for A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13510" smilref="Title.smil#_13510"> the beginning of the process, when started in state 0 at the beginning of the text, it stays in state 0, scanning text characters, until it finds a text character that is equal to the first pattern character, when it moves to the next state and is off and running. At the end of the process, when it finds a match, it matches pattern characters with the right end of the text, incrementing the state until reaching state M. The trace at the top of this page gives a typical example of the operation of our example DFA. Each match moves the DFA to the next state (which is equivalent to incrementing the pattern index j); each mismatch moves the DFA to an earlier state (which is equivalent to setting the pattern index j to a smaller value). The text index i marches from left to right, one position at a time, while the pattern index j bounces around in the pattern as directed by the DFA.</p><p attribs="{'xml:space': 'preserve'}" id="_13511" smilref="Title.smil#_13511"> Constructing the DFA. Now that you understand the mechanism, we are ready to address the key question for the KMP algorithm: How do we compute the dfa[][] array corresponding to a given pattern? Remarkably, the answer to this question lies in the DFA itself (!) using the ingenious (and rather tricky) construction that was developed by Knuth, Morris, and Pratt. When we have a mismatch at pat.charAt(j), our interest is in knowing in what state the DFA would be if we were to back up the text index and rescan the text characters that we just saw after shifting to the right one position. We do not want to actually do the backup, just restart the DFA as if we had done the backup.</p><p attribs="{'xml:space': 'preserve'}" id="_13512" smilref="Title.smil#_13512" /><pagenum id="p779" page="normal" smilref="Title.smil#p779" /><p attribs="{'xml:space': 'preserve'}" id="_13513" smilref="Title.smil#_13513"> 766</p><p attribs="{'xml:space': 'preserve'}" id="_13514" smilref="Title.smil#_13514"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13515" smilref="Title.smil#_13515"> A 0</p><p attribs="{'xml:space': 'preserve'}" id="_13516" smilref="Title.smil#_13516"> A B 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13517" smilref="Title.smil#_13517"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13518" smilref="Title.smil#_13518"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13519" smilref="Title.smil#_13519"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13520" smilref="Title.smil#_13520"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13521" smilref="Title.smil#_13521"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_13522" smilref="Title.smil#_13522"> A B A 0 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_13523" smilref="Title.smil#_13523"> A B A B 0 0 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_13524" smilref="Title.smil#_13524"> A B A B A 0 0 1 2 3</p><p attribs="{'xml:space': 'preserve'}" id="_13525" smilref="Title.smil#_13525"> DFA simulations to compute restart states for A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13526" smilref="Title.smil#_13526"> restart states X</p><p attribs="{'xml:space': 'preserve'}" id="_13527" smilref="Title.smil#_13527"> The key observation is that the characters in the text that would need to be rescanned are precisely pat.charAt(1) through pat.charAt(j-1): we drop the first character to shift right one position and the last character because of the mismatch. These are pattern characters that we know, so we can figure out ahead of time, for each possible mismatch position, the state where we need to restart the DFA. The figure at left shows the possibilities for our example. Be sure that you understand this concept. What should the DFA do with the next character? Exactly what it would have done if we had backed up, except if it finds a match with pat.charAt(j), when it should go to state j+1. For example, to decide what the DFA should do when we have a mismatch at j = 5 for A B A B A C, we use the DFA to learn that a full backup would leave us in state 3 for B A B A, so we can copy dfa[][3] to dfa[][5], then set the entry for C to 6 because pat.charAt(5) is C (a match). Since we only need to know how the DFA runs for j-1 characters when we are building the jth state, we can always get the information that we need from the partially built DFA. The final crucial detail to the computation is to observe that maintaining the restart position X when working on column j of dfa[][] is easy because X &lt; j so that we can use the partially built DFA to do the job&#8212;the next value of X is dfa[pat.charAt(j)][X]). Continuing our example from the previous paragraph, we would update the value of X to dfa['C'][3] = 0 (but we do not use that value because the DFA construction is complete). The discussion above leads to the remarkably compact code below for constructing the DFA corresponding to a given pattern. For each j, it </p><p attribs="{'xml:space': 'preserve'}" id="_13528" smilref="Title.smil#_13528"> dfa[pat.charAt(0)][0] = 1; for (int X = 0, j = 1; j &lt; M; j++) { // Compute dfa[][j]. for (int c = 0; c &lt; R; c++) dfa[c][j] = dfa[c][X]; dfa[pat.charAt(j)][j] = j+1;</p><p attribs="{'xml:space': 'preserve'}" id="_13529" smilref="Title.smil#_13529"> 5.3.2 and Exercise 5.3.3.</p><p attribs="{'xml:space': 'preserve'}" id="_13530" smilref="Title.smil#_13530"> X = dfa[pat.charAt(j)][X]; }</p><p attribs="{'xml:space': 'preserve'}" id="_13531" smilref="Title.smil#_13531"> Constructing the DFA for KMP substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13532" smilref="Title.smil#_13532" /><pagenum id="p780" page="normal" smilref="Title.smil#p780" /><p attribs="{'xml:space': 'preserve'}" id="_13533" smilref="Title.smil#_13533"> Constructing the DFA for KMP substring search for A B A B A C</p><p attribs="{'xml:space': 'preserve'}" id="_13534" smilref="Title.smil#_13534"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13535" smilref="Title.smil#_13535"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13536" smilref="Title.smil#_13536"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13537" smilref="Title.smil#_13537"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13538" smilref="Title.smil#_13538"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13539" smilref="Title.smil#_13539"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_13540" smilref="Title.smil#_13540"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_13541" smilref="Title.smil#_13541"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13542" smilref="Title.smil#_13542"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13543" smilref="Title.smil#_13543"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13544" smilref="Title.smil#_13544"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13545" smilref="Title.smil#_13545"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13546" smilref="Title.smil#_13546"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13547" smilref="Title.smil#_13547"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13548" smilref="Title.smil#_13548"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13549" smilref="Title.smil#_13549"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13550" smilref="Title.smil#_13550"> A B</p><p attribs="{'xml:space': 'preserve'}" id="_13551" smilref="Title.smil#_13551"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13552" smilref="Title.smil#_13552"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13553" smilref="Title.smil#_13553"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13554" smilref="Title.smil#_13554"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13555" smilref="Title.smil#_13555"> 0 1 2 3 4 5 A B A B A C 1 1 3 1 5 1 0 2 0 4 0 4 0 0 0 0 0 6</p><p attribs="{'xml:space': 'preserve'}" id="_13556" smilref="Title.smil#_13556"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13557" smilref="Title.smil#_13557"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13558" smilref="Title.smil#_13558"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13559" smilref="Title.smil#_13559"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13560" smilref="Title.smil#_13560"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13561" smilref="Title.smil#_13561"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13562" smilref="Title.smil#_13562"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13563" smilref="Title.smil#_13563"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13564" smilref="Title.smil#_13564"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13565" smilref="Title.smil#_13565"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13566" smilref="Title.smil#_13566"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13567" smilref="Title.smil#_13567"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13568" smilref="Title.smil#_13568"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13569" smilref="Title.smil#_13569"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13570" smilref="Title.smil#_13570"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13571" smilref="Title.smil#_13571"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13572" smilref="Title.smil#_13572"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13573" smilref="Title.smil#_13573"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13574" smilref="Title.smil#_13574"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13575" smilref="Title.smil#_13575"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_13576" smilref="Title.smil#_13576"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13577" smilref="Title.smil#_13577"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13578" smilref="Title.smil#_13578"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13579" smilref="Title.smil#_13579"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13580" smilref="Title.smil#_13580"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13581" smilref="Title.smil#_13581"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13582" smilref="Title.smil#_13582"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13583" smilref="Title.smil#_13583"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13584" smilref="Title.smil#_13584"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13585" smilref="Title.smil#_13585"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13586" smilref="Title.smil#_13586"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13587" smilref="Title.smil#_13587"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13588" smilref="Title.smil#_13588"> 0 1 2 3 4 A B A B A 1 1 3 1 5 0 2 0 4 0 0 0 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13589" smilref="Title.smil#_13589"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13590" smilref="Title.smil#_13590"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13591" smilref="Title.smil#_13591"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13592" smilref="Title.smil#_13592"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13593" smilref="Title.smil#_13593"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13594" smilref="Title.smil#_13594"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13595" smilref="Title.smil#_13595"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13596" smilref="Title.smil#_13596"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_13597" smilref="Title.smil#_13597"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13598" smilref="Title.smil#_13598"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13599" smilref="Title.smil#_13599"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13600" smilref="Title.smil#_13600"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13601" smilref="Title.smil#_13601"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13602" smilref="Title.smil#_13602"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13603" smilref="Title.smil#_13603"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13604" smilref="Title.smil#_13604"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13605" smilref="Title.smil#_13605"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13606" smilref="Title.smil#_13606"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13607" smilref="Title.smil#_13607"> 0 1 2 3 A B A B 1 1 3 1 0 2 0 4 0 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13608" smilref="Title.smil#_13608"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13609" smilref="Title.smil#_13609"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13610" smilref="Title.smil#_13610"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13611" smilref="Title.smil#_13611"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13612" smilref="Title.smil#_13612"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13613" smilref="Title.smil#_13613"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13614" smilref="Title.smil#_13614"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_13615" smilref="Title.smil#_13615"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13616" smilref="Title.smil#_13616"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13617" smilref="Title.smil#_13617"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13618" smilref="Title.smil#_13618"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13619" smilref="Title.smil#_13619"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13620" smilref="Title.smil#_13620"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13621" smilref="Title.smil#_13621"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13622" smilref="Title.smil#_13622"> 0 1 2 A B A 1 1 3 0 2 0 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13623" smilref="Title.smil#_13623"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13624" smilref="Title.smil#_13624"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13625" smilref="Title.smil#_13625"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13626" smilref="Title.smil#_13626"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13627" smilref="Title.smil#_13627"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13628" smilref="Title.smil#_13628"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_13629" smilref="Title.smil#_13629"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13630" smilref="Title.smil#_13630"> B</p><p attribs="{'xml:space': 'preserve'}" id="_13631" smilref="Title.smil#_13631"> C</p><p attribs="{'xml:space': 'preserve'}" id="_13632" smilref="Title.smil#_13632"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13633" smilref="Title.smil#_13633"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13634" smilref="Title.smil#_13634"> 0 1 A B 1 1 0 2 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13635" smilref="Title.smil#_13635"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13636" smilref="Title.smil#_13636"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13637" smilref="Title.smil#_13637"> X</p><p attribs="{'xml:space': 'preserve'}" id="_13638" smilref="Title.smil#_13638"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_13639" smilref="Title.smil#_13639"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13640" smilref="Title.smil#_13640"> A</p><p attribs="{'xml:space': 'preserve'}" id="_13641" smilref="Title.smil#_13641"> B,C</p><p attribs="{'xml:space': 'preserve'}" id="_13642" smilref="Title.smil#_13642"> 0 A 1 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_13643" smilref="Title.smil#_13643"> dfa[][j]</p><p attribs="{'xml:space': 'preserve'}" id="_13644" smilref="Title.smil#_13644"> j pat.charAt(j) A B C</p><p attribs="{'xml:space': 'preserve'}" id="_13645" smilref="Title.smil#_13645"> copy dfa[][X] to dfa[][j] dfa[pat.charAt(j)][j] = j+1; X = dfa[pat.charAt(j)][X];</p><p attribs="{'xml:space': 'preserve'}" id="_13646" smilref="Title.smil#_13646"> 767</p><p attribs="{'xml:space': 'preserve'}" id="_13647" smilref="Title.smil#_13647"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13648" smilref="Title.smil#_13648" /><pagenum id="p781" page="normal" smilref="Title.smil#p781" /><p attribs="{'xml:space': 'preserve'}" id="_13649" smilref="Title.smil#_13649"> 768</p><p attribs="{'xml:space': 'preserve'}" id="_13650" smilref="Title.smil#_13650"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13651" smilref="Title.smil#_13651"> ALGORITHM 5.6 Knuth-Morris-Pratt substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13652" smilref="Title.smil#_13652"> public class KMP { private String pat; private int[][] dfa;</p><p attribs="{'xml:space': 'preserve'}" id="_13653" smilref="Title.smil#_13653"> public KMP(String pat) { // Build DFA from pattern. this.pat = pat; int M = pat.length(); int R = 256; dfa = new int[R][M]; dfa[pat.charAt(0)][0] = 1; for (int X = 0, j = 1; j &lt; M; j++) { // Compute dfa[][j]. for (int c = 0; c &lt; R; c++) dfa[c][j] = dfa[c][X]; // Copy mismatch cases. dfa[pat.charAt(j)][j] = j+1; // Set match case. X = dfa[pat.charAt(j)][X]; // Update restart state. } }</p><p attribs="{'xml:space': 'preserve'}" id="_13654" smilref="Title.smil#_13654"> public int search(String txt) { // Simulate operation of DFA on txt. int i, j, N = txt.length(), M = pat.length(); for (i = 0, j = 0; i &lt; N &amp;&amp; j &lt; M; i++) j = dfa[txt.charAt(i)][j]; if (j == M) return i - M; // found (hit end of pattern) else return N; // not found (hit end of text) }</p><p attribs="{'xml:space': 'preserve'}" id="_13655" smilref="Title.smil#_13655"> public static void main(String[] args) // See page 769. }</p><p attribs="{'xml:space': 'preserve'}" id="_13656" smilref="Title.smil#_13656"> The constructor in this implementation of the Knuth-Morris-Pratt algorithm for substring search builds a DFA from a pattern string, to support a search() method that can find the pattern in a given text string. This program does the same job as the brute-force method, but it runs faster for patterns that are self-repetitive.</p><p attribs="{'xml:space': 'preserve'}" id="_13657" smilref="Title.smil#_13657"> % java KMP AACAA AABRAACADABRAACAADABRA text: AABRAACADABRAACAADABRA pattern: AACAA</p><p attribs="{'xml:space': 'preserve'}" id="_13658" smilref="Title.smil#_13658" /><pagenum id="p782" page="normal" smilref="Title.smil#p782" /><p attribs="{'xml:space': 'preserve'}" id="_13659" smilref="Title.smil#_13659"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13660" smilref="Title.smil#_13660"> 769</p><p attribs="{'xml:space': 'preserve'}" id="_13661" smilref="Title.smil#_13661"> Algorithm 5.6 on the facing page implements the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_13662" smilref="Title.smil#_13662"> public class KMP</p><p attribs="{'xml:space': 'preserve'}" id="_13663" smilref="Title.smil#_13663"> KMP(String pat)</p><p attribs="{'xml:space': 'preserve'}" id="_13664" smilref="Title.smil#_13664"> int search(String txt)</p><p attribs="{'xml:space': 'preserve'}" id="_13665" smilref="Title.smil#_13665"> create a DFA that can search for pat fi nd index of pat in txt</p><p attribs="{'xml:space': 'preserve'}" id="_13666" smilref="Title.smil#_13666"> Substring search API</p><p attribs="{'xml:space': 'preserve'}" id="_13667" smilref="Title.smil#_13667"> You can see a typical test client at the bottom of this page. The constructor builds a DFA from a pattern that the search() method uses to search for the pattern in a given text.</p><p attribs="{'xml:space': 'preserve'}" id="_13668" smilref="Title.smil#_13668"> Proposition N. Knuth-Morris-Pratt substring search accesses no more than M &#11001; N characters to search for a pattern of length M in a text of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_13669" smilref="Title.smil#_13669"> Proof. Immediate from the code: we access each pattern character once when computing dfa[][] and each text character once (in the worst case) in search().</p><p attribs="{'xml:space': 'preserve'}" id="_13670" smilref="Title.smil#_13670"> Another parameter comes into play : for an R-character alphabet, the total running time (and space) required to build the DFA is proportional to MR. It is possible to remove the factor of R by building a DFA where each state has a match transition and a mismatch transition (not transitions for each possible character), though the construction is somewhat more intricate. The linear-time worst-case guarantee provided by the KMP algorithm is a significant theoretical result. In practice, the speedup over the brute-force method is not often important because few applications involve searching for highly self-repetitive patterns in highly self-repetitive text. Still, the method has the practical advantage that it never backs up in the input. This property makes KMP substring search more convenient for use on an input stream of undetermined length (such as standard input) than algorithms requiring backup, which need some complicated buffering in this situation. Ironically, when backup is easy, we can do significantly better than KMP. Next, we consider a method that generally leads to substantial performance gains precisely because it can back up in the text.</p><p attribs="{'xml:space': 'preserve'}" id="_13671" smilref="Title.smil#_13671"> public static void main(String[] args) { String pat = args[0]; String txt = args[1]; KMP kmp = new KMP(pat); StdOut.println("text: " + txt); int offset = kmp.search(txt); StdOut.print("pattern: "); for (int i = 0; i &lt; offset; i++) StdOut.print(" "); StdOut.println(pat);</p><p attribs="{'xml:space': 'preserve'}" id="_13672" smilref="Title.smil#_13672"> }</p><p attribs="{'xml:space': 'preserve'}" id="_13673" smilref="Title.smil#_13673"> KMP substring search test client</p><p attribs="{'xml:space': 'preserve'}" id="_13674" smilref="Title.smil#_13674" /></level3><level3 id="_00106"><h3 id="ch5-s3-ss10" smilref="Title.smil#ch5-s3-ss10" xml:space="preserve">Boyer-Moore algorithm</h3><pagenum id="p783" page="normal" smilref="Title.smil#p783" /><p attribs="{'xml:space': 'preserve'}" id="_13675" smilref="Title.smil#_13675"> 770</p><p attribs="{'xml:space': 'preserve'}" id="_13676" smilref="Title.smil#_13676"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13677" smilref="Title.smil#_13677"> Boyer-Moore substring search When backup in the text string is not a prob- lem, we can develop a significantly faster substring-searching method by scanning the pattern from right to left when trying to match it against the text. For example, when searching for the substring B A A B B A A , if we find matches on the seventh and sixth characters but not on the fi fth, then we can immediately slide the pattern seven positions to the right, and check the 14th character in the text next, because our partial match found X A A where X is not B , which does not appear elsewhere in the pattern. In general, the pattern at the end might appear elsewhere, so we need an array of restart positions as for Knuth-Morris-Pratt. We will not explore this approach in further detail because it is quite similar to our implementation of the Knuth-Morris-Pratt method. Instead, we will consider another suggestion by Boyer and Moore that is typically even more effective in right-to-left pattern scanning. As with our implementation of KMP substring search, we decide what to do next on the basis of the character that caused the mismatch in the text as well as the pattern. The preprocessing step is to decide, for each possible character that could occur in the text, what we would do if that character were to cause the mismatch. The simplest realization of this idea leads immediately to an efficient and useful substring search method.</p><p attribs="{'xml:space': 'preserve'}" id="_13678" smilref="Title.smil#_13678"> Mismatched character heuristic. Consider the figure at the bottom of this page, which shows a search for the pattern N E E D L E in the text F I N D I N A H A Y S T A C K N E E D L E . Proceeding from right to left to match the pattern, we first compare the rightmost E in the pattern with the N (the character at position 5) in the text. Since N appears in the pattern, we slide the pattern five positions to the right to line up the N in the text with the (rightmost) N in the pattern. Then we compare the rightmost E in the pattern with the S (the character at position 10) in the text. This is also a mismatch, but S does not appear in the pattern, so we can slide the pattern six positions to the right.We match the rightmost E in the pattern against the E at position 16 in the text, then find a mismatch and discover the N at position 15 and slide to the right five positions, as at the beginning. Finally, we verify, moving from right to left starting at position 20, that the pattern is in the text. This method brings us to the match position at a cost of only four character compares (and six more to verify the match)!</p><p attribs="{'xml:space': 'preserve'}" id="_13679" smilref="Title.smil#_13679"> text</p><p attribs="{'xml:space': 'preserve'}" id="_13680" smilref="Title.smil#_13680"> i j 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 F I N D I N A H A Y S T A C K N E E D L E I N A 0 5 N E E D L E 5 5 N E E D L E 11 4 N E E D L E 15 0 N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13681" smilref="Title.smil#_13681"> pattern</p><p attribs="{'xml:space': 'preserve'}" id="_13682" smilref="Title.smil#_13682"> return i = 15</p><p attribs="{'xml:space': 'preserve'}" id="_13683" smilref="Title.smil#_13683"> Mismatched character heuristic for right-to-left (Boyer-Moore) substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13684" smilref="Title.smil#_13684" /><pagenum id="p784" page="normal" smilref="Title.smil#p784" /><p attribs="{'xml:space': 'preserve'}" id="_13685" smilref="Title.smil#_13685"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13686" smilref="Title.smil#_13686"> 771</p><p attribs="{'xml:space': 'preserve'}" id="_13687" smilref="Title.smil#_13687"> Starting point. To implement the mismatched character heuristic, we use an array right[] that gives, for each character in the alphabet, the index of its rightmost occurrence in the pattern (or -1 if the character is not in the pattern). This value tells us precisely how far to skip if that character appears in the text and causes a mismatch during the string search. To initialize the right[] array, we set all entries to -1 and then, for j from 0 to</p><p attribs="{'xml:space': 'preserve'}" id="_13688" smilref="Title.smil#_13688"> M-1, set right[pat.charAt(j)] to j, as shown</p><p attribs="{'xml:space': 'preserve'}" id="_13689" smilref="Title.smil#_13689"> in the example at right for our example pattern</p><p attribs="{'xml:space': 'preserve'}" id="_13690" smilref="Title.smil#_13690"> N E E D L E .</p><p attribs="{'xml:space': 'preserve'}" id="_13691" smilref="Title.smil#_13691"> right[c]</p><p attribs="{'xml:space': 'preserve'}" id="_13692" smilref="Title.smil#_13692"> c</p><p attribs="{'xml:space': 'preserve'}" id="_13693" smilref="Title.smil#_13693"> N E E D L E 0 1 2 3 4 5 A -1 -1 -1 -1 -1 -1 -1 -1 B -1 -1 -1 -1 -1 -1 -1 -1 C -1 -1 -1 -1 -1 -1 -1 -1 D -1 -1 -1 -1 3 3 3 3 E -1 -1 1 2 2 2 5 5 ... -1 L -1 -1 -1 -1 -1 4 4 4 M -1 -1 -1 -1 -1 -1 -1 -1 N -1 0 0 0 0 0 0 0 ... -1</p><p attribs="{'xml:space': 'preserve'}" id="_13694" smilref="Title.smil#_13694"> Boyer-Moore skip table computation</p><p attribs="{'xml:space': 'preserve'}" id="_13695" smilref="Title.smil#_13695"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13696" smilref="Title.smil#_13696"> i+j</p><p attribs="{'xml:space': 'preserve'}" id="_13697" smilref="Title.smil#_13697"> Substring search. With the right[] array pre- computed, the implementation in Algorithm 5.7 is straightforward. We have an index i moving from left to right through the text and an index j moving from right to left through the pattern. The inner loop tests whether the pattern aligns with the text at position i. If txt.charAt(i+j) is equal to pat.charAt(j) for all j from M-1 down to 0, then there is a match. Otherwise, there is a character mismatch, and we have one of the following three cases: </p><p attribs="{'xml:space': 'preserve'}" id="_13698" smilref="Title.smil#_13698"> increment i by j+1</p><p attribs="{'xml:space': 'preserve'}" id="_13699" smilref="Title.smil#_13699"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13700" smilref="Title.smil#_13700"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13701" smilref="Title.smil#_13701"> could do better with KMP-like table</p><p attribs="{'xml:space': 'preserve'}" id="_13702" smilref="Title.smil#_13702"> reset j to M-1</p><p attribs="{'xml:space': 'preserve'}" id="_13703" smilref="Title.smil#_13703"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13704" smilref="Title.smil#_13704"> . . . . . . T L E . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13705" smilref="Title.smil#_13705"> . . . . . . T L E . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13706" smilref="Title.smil#_13706"> Mismatched character heuristic (mismatch not in pattern)</p><p attribs="{'xml:space': 'preserve'}" id="_13707" smilref="Title.smil#_13707" /><pagenum id="p785" page="normal" smilref="Title.smil#p785" /><p attribs="{'xml:space': 'preserve'}" id="_13708" smilref="Title.smil#_13708"> 772</p><p attribs="{'xml:space': 'preserve'}" id="_13709" smilref="Title.smil#_13709"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13710" smilref="Title.smil#_13710"> ALGORITHM 5.7 Boyer-Moore substring search (mismatched character heuristic)</p><p attribs="{'xml:space': 'preserve'}" id="_13711" smilref="Title.smil#_13711"> public class BoyerMoore { private int[] right; private String pat;</p><p attribs="{'xml:space': 'preserve'}" id="_13712" smilref="Title.smil#_13712"> BoyerMoore(String pat) { // Compute skip table. this.pat = pat; int M = pat.length(); int R = 256; right = new int[R]; for (int c = 0; c &lt; R; c++) right[c] = -1; // -1 for chars not in pattern for (int j = 0; j &lt; M; j++) // rightmost position for right[pat.charAt(j)] = j; // chars in pattern }</p><p attribs="{'xml:space': 'preserve'}" id="_13713" smilref="Title.smil#_13713"> public int search(String txt) { // Search for pattern in txt. int N = txt.length(); int M = pat.length(); int skip; for (int i = 0; i &lt;= N-M; i += skip) { // Does the pattern match the text at position i ? skip = 0; for (int j = M-1; j &gt;= 0; j--) if (pat.charAt(j) != txt.charAt(i+j)) { skip = j - right[txt.charAt(i+j)]; if (skip &lt; 1) skip = 1; break; } if (skip == 0) return i; // found. } return N; // not found. }</p><p attribs="{'xml:space': 'preserve'}" id="_13714" smilref="Title.smil#_13714"> public static void main(String[] args) // See page 769. }</p><p attribs="{'xml:space': 'preserve'}" id="_13715" smilref="Title.smil#_13715"> The constructor in this substring search algorithm builds a table giving the rightmost occurrence in the pattern of each possible character. The search method scans from right to left in the pattern, skipping to align any character causing a mismatch with its rightmost occurrence in the pattern.</p><p attribs="{'xml:space': 'preserve'}" id="_13716" smilref="Title.smil#_13716" /><pagenum id="p786" page="normal" smilref="Title.smil#p786" /><p attribs="{'xml:space': 'preserve'}" id="_13717" smilref="Title.smil#_13717"> </p><p attribs="{'xml:space': 'preserve'}" id="_13718" smilref="Title.smil#_13718"> j - right[txt.charAt(i+j)]).</p><p attribs="{'xml:space': 'preserve'}" id="_13719" smilref="Title.smil#_13719"> The full Boyer-Moore algorithm takes into account precomputed mismatches of the pattern with itself (in a manner similar to the KMP algorithm) and provides a linear-time worst-case guarantee (whereas Algorithm 5.7 can take time proportional to NM in the worst case&#8212;see Exercise 5.3.19). We omit this computation because the mismatched character heuristic controls the performance in typical practical applications.</p><p attribs="{'xml:space': 'preserve'}" id="_13720" smilref="Title.smil#_13720"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13721" smilref="Title.smil#_13721"> 773</p><p attribs="{'xml:space': 'preserve'}" id="_13722" smilref="Title.smil#_13722"> basic idea</p><p attribs="{'xml:space': 'preserve'}" id="_13723" smilref="Title.smil#_13723"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13724" smilref="Title.smil#_13724"> i+j</p><p attribs="{'xml:space': 'preserve'}" id="_13725" smilref="Title.smil#_13725"> . . . . . . N L E . . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13726" smilref="Title.smil#_13726"> increment i by j - right['N']</p><p attribs="{'xml:space': 'preserve'}" id="_13727" smilref="Title.smil#_13727"> to line up text with N in pattern</p><p attribs="{'xml:space': 'preserve'}" id="_13728" smilref="Title.smil#_13728"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13729" smilref="Title.smil#_13729"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13730" smilref="Title.smil#_13730"> could do better with KMP-like table</p><p attribs="{'xml:space': 'preserve'}" id="_13731" smilref="Title.smil#_13731"> . . . . . . N L E . . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13732" smilref="Title.smil#_13732"> reset j to M-1</p><p attribs="{'xml:space': 'preserve'}" id="_13733" smilref="Title.smil#_13733"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13734" smilref="Title.smil#_13734"> heuristic is no help</p><p attribs="{'xml:space': 'preserve'}" id="_13735" smilref="Title.smil#_13735"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13736" smilref="Title.smil#_13736"> i+j</p><p attribs="{'xml:space': 'preserve'}" id="_13737" smilref="Title.smil#_13737"> . . . . . . E L E . . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13738" smilref="Title.smil#_13738"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13739" smilref="Title.smil#_13739"> lining up text with rightmost E would shift pattern left</p><p attribs="{'xml:space': 'preserve'}" id="_13740" smilref="Title.smil#_13740"> . . . . . . E L E . . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13741" smilref="Title.smil#_13741"> so increment i by 1</p><p attribs="{'xml:space': 'preserve'}" id="_13742" smilref="Title.smil#_13742"> i</p><p attribs="{'xml:space': 'preserve'}" id="_13743" smilref="Title.smil#_13743"> could do better with KMP-like table</p><p attribs="{'xml:space': 'preserve'}" id="_13744" smilref="Title.smil#_13744"> . . . . . . E L E . . . . . . N E E D L E</p><p attribs="{'xml:space': 'preserve'}" id="_13745" smilref="Title.smil#_13745"> reset j to M-1</p><p attribs="{'xml:space': 'preserve'}" id="_13746" smilref="Title.smil#_13746"> j</p><p attribs="{'xml:space': 'preserve'}" id="_13747" smilref="Title.smil#_13747"> Mismatched character heuristic (mismatch in pattern)</p><p attribs="{'xml:space': 'preserve'}" id="_13748" smilref="Title.smil#_13748"> Property O. On typical inputs, substring search with the Boyer-Moore mismatched character heuristic uses ~N&#11408;M character compares to search for a pattern of length M in a text of length N.</p><p attribs="{'xml:space': 'preserve'}" id="_13749" smilref="Title.smil#_13749"> Discussion: This result can be proved for various random string models, but such models tend to be unrealistic, so we shall skip the details. In many practical situations it is true that all but a few of the alphabet characters appear nowhere in the pattern, so nearly all compares lead to M characters being skipped, which gives the stated result.</p><p attribs="{'xml:space': 'preserve'}" id="_13750" smilref="Title.smil#_13750" /></level3><level3 id="_00107"><h3 id="ch5-s3-ss11" smilref="Title.smil#ch5-s3-ss11" xml:space="preserve">Rabin-Karp fingerprint algorithm</h3><pagenum id="p787" page="normal" smilref="Title.smil#p787" /><p attribs="{'xml:space': 'preserve'}" id="_13751" smilref="Title.smil#_13751"> 774</p><p attribs="{'xml:space': 'preserve'}" id="_13752" smilref="Title.smil#_13752"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13753" smilref="Title.smil#_13753"> Rabin-Karp fingerprint search The method developed by M. O. Rabin and R. A. Karp is a completely different approach to substring search that is based on hash- ing. We compute a hash function for the pattern and then look for a match by using the same hash function for each possible M-character substring of the text. If we find a text substring with the same hash value as the pattern, we can check for a match. This process is equivalent to storing the pattern in a hash table, then doing a search for each substring of the text, but we do not need to reserve the memory for the hash table because it would have just one entry. A straightforward implementation based on this description would be much slower than a brute-force search (since computing a hash function that involves every character is likely to be much more expensive than just comparing characters), but Rabin and Karp showed that it is easy to compute hash functions for M-character substrings in constant time (after some preprocessing), which leads to a linear-time substring search in practical situations.</p><p attribs="{'xml:space': 'preserve'}" id="_13754" smilref="Title.smil#_13754"> Basic plan. A string of length M corresponds to an M-digit base-R number. To use a hash table of size Q for keys of this type, we need a hash function to convert an M-digit base-R number to an int value between 0 and Q-1. Modular hashing (see Section 3.4) provides an answer: take the remainder when dividing the number by Q. In practice, we use a random prime Q, taking as large a value as possible while avoiding overflow (because we do not actually need to store a hash table). The method is simplest to understand for small Q and R = 10, shown in the example below. To find the pattern 2 6 5 3 5 in the text 3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 3 , we choose a table size Q (997 in the example), compute the hash value 26535 % 997 = 613, and then look for a match by computing hash values for each fi ve-digit substring in the text. In the example, we get the hash values 508, 201, 715, 971, 442, and 929 before finding the match 613.</p><p attribs="{'xml:space': 'preserve'}" id="_13755" smilref="Title.smil#_13755"> pat.charAt(j) j 0 1 2 3 4 2 6 5 3 5 % 997 = 613</p><p attribs="{'xml:space': 'preserve'}" id="_13756" smilref="Title.smil#_13756"> Computing</p><p attribs="{'xml:space': 'preserve'}" id="_13757" smilref="Title.smil#_13757"> the</p><p attribs="{'xml:space': 'preserve'}" id="_13758" smilref="Title.smil#_13758"> hash</p><p attribs="{'xml:space': 'preserve'}" id="_13759" smilref="Title.smil#_13759"> func-</p><p attribs="{'xml:space': 'preserve'}" id="_13760" smilref="Title.smil#_13760"> tion. With fi ve-digit values, we could just do all the necessary calculations with int values, but what do we do when M is 100 or 1,000? A simple application of Horner&#8217;s method, precisely like the method that we examined in Section 3.4 for strings and other types of keys with multiple values,</p><p attribs="{'xml:space': 'preserve'}" id="_13761" smilref="Title.smil#_13761"> txt.charAt(i) i 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 3 0 3 1 4 1 5 % 997 = 508 1 1 4 1 5 9 % 997 = 201 2 4 1 5 9 2 % 997 = 715 3 1 5 9 2 6 % 997 = 971 4 5 9 2 6 5 % 997 = 442 5 9 2 6 5 3 % 997 = 929 6 2 6 5 3 5 % 997 = 613</p><p attribs="{'xml:space': 'preserve'}" id="_13762" smilref="Title.smil#_13762"> return i = 6</p><p attribs="{'xml:space': 'preserve'}" id="_13763" smilref="Title.smil#_13763"> match</p><p attribs="{'xml:space': 'preserve'}" id="_13764" smilref="Title.smil#_13764"> Basis for Rabin-Karp substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13765" smilref="Title.smil#_13765" /><pagenum id="p788" page="normal" smilref="Title.smil#p788" /><p attribs="{'xml:space': 'preserve'}" id="_13766" smilref="Title.smil#_13766"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13767" smilref="Title.smil#_13767"> 775</p><p attribs="{'xml:space': 'preserve'}" id="_13768" smilref="Title.smil#_13768"> leads to the code shown at right, which computes the hash function for an M-digit base- R number represented as a char array in time proportional to M. (We pass M as an argument so that we can use the method for both the pattern and the text, as you will see.) For each digit in the number, we multiply by R, add the digit, and take the remainder when divided by Q. For example, computing the hash function for our pattern using this process is shown at the bottom of the page. The same method can work for computing the hash functions in the text, but the cost for the substring search would be a multiplication, addition, and remainder calculation for each text character, for a total of NM operations in the worst case, no improvement over the brute-force method.</p><p attribs="{'xml:space': 'preserve'}" id="_13769" smilref="Title.smil#_13769"> private long hash(String key, int M) { // Compute hash for key[0..M-1]. long h = 0; for (int j = 0; j &lt; M; j++) h = (R * h + key.charAt(j)) % Q; return h; }</p><p attribs="{'xml:space': 'preserve'}" id="_13770" smilref="Title.smil#_13770"> Horner &#8217;s method, applied to modular hashing</p><p attribs="{'xml:space': 'preserve'}" id="_13771" smilref="Title.smil#_13771"> Key idea. The Rabin-Karp method is based on efficiently computing the hash function for position i+1 in the text, given its value for position i. It follows directly from a simple mathematical formulation. Using the notation ti for txt.charAt(i), the number corresponding to the M-character substring of txt that starts at position i is</p><p attribs="{'xml:space': 'preserve'}" id="_13772" smilref="Title.smil#_13772"> xi = ti R M&#11002;1 &#11001; ti+1 R M&#11002;2 &#11001; . . . &#11001; ti+M&#11002;1R 0</p><p attribs="{'xml:space': 'preserve'}" id="_13773" smilref="Title.smil#_13773"> and we can assume that we know the value of h(xi) = xi mod Q . Shifting one position right in the text corresponds to replacing xi by</p><p attribs="{'xml:space': 'preserve'}" id="_13774" smilref="Title.smil#_13774"> xi+1 = (xi &#11002; ti R M&#11002;1) R &#11001; ti+M .</p><p attribs="{'xml:space': 'preserve'}" id="_13775" smilref="Title.smil#_13775"> We subtract off the leading digit, multiply by R, then add the trailing digit. Now, the crucial point is that we do not have to maintain the values of the numbers, just the values of their remainders when divided by Q. A fundamental property of the modulus operation is that if we take the remainder when divided by Q after each arithmetic operation, then we get the same answer as if we were to perform all of the arithmetic operations, then take the remainder when divided by Q. We took advantage of this property once before, when implementing modular hashing with Horner&#8217;s method (see page 460). The result is that we can effectively move right one position in the text in constant time, whether M is 5 or 100 or 1,000.</p><p attribs="{'xml:space': 'preserve'}" id="_13776" smilref="Title.smil#_13776"> pat.charAt(j) i 0 1 2 3 4 2 6 5 3 5 0 2 % 997 = 2 1 2 6 % 997 = (2*10 + 6) % 997 = 26 2 2 6 5 % 997 = (26*10 + 5) % 997 = 265 3 2 6 5 3 % 997 = (265*10 + 3) % 997 = 659 4 2 6 5 3 5 % 997 = (659*10 + 5) % 997 = 613</p><p attribs="{'xml:space': 'preserve'}" id="_13777" smilref="Title.smil#_13777"> Q</p><p attribs="{'xml:space': 'preserve'}" id="_13778" smilref="Title.smil#_13778"> R</p><p attribs="{'xml:space': 'preserve'}" id="_13779" smilref="Title.smil#_13779"> Computing the hash value for the pattern with Horner&#8217;s method</p><p attribs="{'xml:space': 'preserve'}" id="_13780" smilref="Title.smil#_13780" /><pagenum id="p789" page="normal" smilref="Title.smil#p789" /><p attribs="{'xml:space': 'preserve'}" id="_13781" smilref="Title.smil#_13781"> 776</p><p attribs="{'xml:space': 'preserve'}" id="_13782" smilref="Title.smil#_13782"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13783" smilref="Title.smil#_13783"> text</p><p attribs="{'xml:space': 'preserve'}" id="_13784" smilref="Title.smil#_13784"> i ... 2 3 4 5 6 7 ... 1 4 1 5 9 2 6 5 4 1 5 9 2 6 5</p><p attribs="{'xml:space': 'preserve'}" id="_13785" smilref="Title.smil#_13785"> current value new value</p><p attribs="{'xml:space': 'preserve'}" id="_13786" smilref="Title.smil#_13786"> Implementation. This discussion leads directly to the substring search implementation in Al- gorithm 5.8. The constructor computes a hash value patHash for the pattern; it also computes the value of RM&#11002;1mod Q in the variable RM. The hashSearch() method begins by computing the hash function for the first M characters of the text and comparing that value against the hash value for the pattern. If that is not a match, it proceeds through the text string, using the technique above to maintain the hash function for the M characters starting at position i for each i in a variable txtHash and comparing each new hash value to patHash. (An extra Q is added during the txtHash calculation to make sure that everything stays positive so that the remainder operation works as it should.)</p><p attribs="{'xml:space': 'preserve'}" id="_13787" smilref="Title.smil#_13787"> 4 1 5 9 2 - 4 0 0 0 0 1 5 9 2 * 1 0 1 5 9 2 0 + 6 1 5 9 2 6</p><p attribs="{'xml:space': 'preserve'}" id="_13788" smilref="Title.smil#_13788"> Key computation in Rabin-Karp substring search (move right one position in the text)</p><p attribs="{'xml:space': 'preserve'}" id="_13789" smilref="Title.smil#_13789"> current value</p><p attribs="{'xml:space': 'preserve'}" id="_13790" smilref="Title.smil#_13790"> subtract leading digit multiply by radix</p><p attribs="{'xml:space': 'preserve'}" id="_13791" smilref="Title.smil#_13791"> add new trailing digit new value</p><p attribs="{'xml:space': 'preserve'}" id="_13792" smilref="Title.smil#_13792"> A trick: Monte Carlo correctness. After finding a hash value for an M-character substring of txt that matches the pattern hash value, you might expect to see code to compare those characters with the pattern to ensure that we have a true match, not just a hash collision. We do not do that test because using it requires backup in the text string. Instead, we make the hash table &#8220;size&#8221; Q as large as we wish, since we are not actually building a hash table, just testing for a collision with one key, our pattern. We will use a long value greater than 1020, making the probability that a random key hashes to the</p><p attribs="{'xml:space': 'preserve'}" id="_13793" smilref="Title.smil#_13793"> Q</p><p attribs="{'xml:space': 'preserve'}" id="_13794" smilref="Title.smil#_13794"> i 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 3 0 3 % 997 = 3 1 3 1 % 997 = (3*10 + 1) % 997 = 31 2 3 1 4 % 997 = (31*10 + 4) % 997 = 314 3 3 1 4 1 % 997 = (314*10 + 1) % 997 = 150 4 3 1 4 1 5 % 997 = (150*10 + 5) % 997 = 508 5 1 4 1 5 9 % 997 = ((508 + 3*(997 - 30))*10 + 9) % 997 = 201 6 4 1 5 9 2 % 997 = ((201 + 1*(997 - 30))*10 + 2) % 997 = 715 7 1 5 9 2 6 % 997 = ((715 + 4*(997 - 30))*10 + 6) % 997 = 971 8 5 9 2 6 5 % 997 = ((971 + 1*(997 - 30))*10 + 5) % 997 = 442 9 9 2 6 5 3 % 997 = ((442 + 5*(997 - 30))*10 + 3) % 997 = 929 10 2 6 5 3 5 % 997 = ((929 + 9*(997 - 30))*10 + 5) % 997 = 613</p><p attribs="{'xml:space': 'preserve'}" id="_13795" smilref="Title.smil#_13795"> return i-M+1 = 6</p><p attribs="{'xml:space': 'preserve'}" id="_13796" smilref="Title.smil#_13796"> R M</p><p attribs="{'xml:space': 'preserve'}" id="_13797" smilref="Title.smil#_13797"> R</p><p attribs="{'xml:space': 'preserve'}" id="_13798" smilref="Title.smil#_13798"> match</p><p attribs="{'xml:space': 'preserve'}" id="_13799" smilref="Title.smil#_13799"> Rabin-Karp substring search example</p><p attribs="{'xml:space': 'preserve'}" id="_13800" smilref="Title.smil#_13800" /><pagenum id="p790" page="normal" smilref="Title.smil#p790" /><p attribs="{'xml:space': 'preserve'}" id="_13801" smilref="Title.smil#_13801"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13802" smilref="Title.smil#_13802"> 777</p><p attribs="{'xml:space': 'preserve'}" id="_13803" smilref="Title.smil#_13803"> ALGORITHM 5.8 Rabin-Karp fingerprint substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13804" smilref="Title.smil#_13804"> public class RabinKarp { private String pat; // pattern (only needed for Las Vegas) private long patHash; // pattern hash value private int M; // pattern length private long Q; // a large prime private int R = 256; // alphabet size private long RM; // R^(M-1) % Q</p><p attribs="{'xml:space': 'preserve'}" id="_13805" smilref="Title.smil#_13805"> public RabinKarp(String pat) { this.pat = pat; // save pattern (needed only for Las Vegas) M = pat.length(); Q = longRandomPrime(); RM = 1; for (int i = 1; i &lt;= M-1; i++) RM = (R * RM) % Q; patHash = hash(pat, M); }</p><p attribs="{'xml:space': 'preserve'}" id="_13806" smilref="Title.smil#_13806"> // Compute R^(M-1) % Q for use // in removing leading digit.</p><p attribs="{'xml:space': 'preserve'}" id="_13807" smilref="Title.smil#_13807"> // See Exercise 5.3.33.</p><p attribs="{'xml:space': 'preserve'}" id="_13808" smilref="Title.smil#_13808"> public boolean check(int i) // Monte Carlo (See text.) { return true; } // For Las Vegas, check pat vs txt(i..i-M+1).</p><p attribs="{'xml:space': 'preserve'}" id="_13809" smilref="Title.smil#_13809"> private long hash(String key, int M) // See text (page 775). private int search(String txt) { // Search for hash match in text. int N = txt.length(); long txtHash = hash(txt, M); if (patHash == txtHash &amp;&amp; check(0)) return 0; for (int i = M; i &lt; N; i++) { // Remove leading digit, add trailing digit, check for match. txtHash = (txtHash + Q - RM*txt.charAt(i-M) % Q) % Q; txtHash = (txtHash*R + txt.charAt(i)) % Q; if (patHash == txtHash) if (check(i - M + 1)) return i - M + 1; } return N; } }</p><p attribs="{'xml:space': 'preserve'}" id="_13810" smilref="Title.smil#_13810"> // no match</p><p attribs="{'xml:space': 'preserve'}" id="_13811" smilref="Title.smil#_13811"> // match</p><p attribs="{'xml:space': 'preserve'}" id="_13812" smilref="Title.smil#_13812"> // match</p><p attribs="{'xml:space': 'preserve'}" id="_13813" smilref="Title.smil#_13813"> This substring search algorithm is based on hashing. It computes a hash value for the pattern in the constructor, then searches through the text looking for a hash match.</p><p attribs="{'xml:space': 'preserve'}" id="_13814" smilref="Title.smil#_13814" /><pagenum id="p791" page="normal" smilref="Title.smil#p791" /><p attribs="{'xml:space': 'preserve'}" id="_13815" smilref="Title.smil#_13815"> 778</p><p attribs="{'xml:space': 'preserve'}" id="_13816" smilref="Title.smil#_13816"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13817" smilref="Title.smil#_13817"> same value as our pattern less than 10&#8211;20, an exceedingly small value. If that value is not small enough for you, you could run the algorithms again to get a probability of failure of less than 10&#8211;40. This algorithm is an early and famous example of a Monte Carlo algorithm that has a guaranteed completion time but fails to output a correct answer with a small probability. The alternative method of checking for a match could be slow (it might amount to the brute-force algorithm, with a very small probability) but is guaranteed correct. Such an algorithm is known as a Las Vegas algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_13818" smilref="Title.smil#_13818"> Property P. The Monte Carlo version of Rabin-Karp substring search is linear-time and extremely likely to be correct, and the Las Vegas version of Rabin-Karp substring search is correct and extremely likely to be linear-time.</p><p attribs="{'xml:space': 'preserve'}" id="_13819" smilref="Title.smil#_13819"> Discussion: The use of the very large value of Q, made possible by the fact that we need not maintain an actual hash table, makes it extremely unlikely that a collision will occur. Rabin and Karp showed that when Q is properly chosen, we get a hash collision for random strings with probability 1/Q, which implies that, for practical values of the variables, there are no hash matches when there are no substring matches and only one hash match if there is a substring match. Theoretically, a text position could lead to a hash collision and not a substring match, but in practice it can be relied upon to find a match.</p><p attribs="{'xml:space': 'preserve'}" id="_13820" smilref="Title.smil#_13820"> If your belief in probability theory (or in the random string model and the code we use to generate random numbers) is more half-hearted than resolute, you can add to check() the code to check that the text matches the pattern, which turns Algorithm 5.8 into the Las Vegas version of the algorithm (see Exercise 5.3.12). If you also add a check to see whether that code is ever executed, you might develop more faith in probability theory as time wears on.</p><p attribs="{'xml:space': 'preserve'}" id="_13821" smilref="Title.smil#_13821"> Rabin-Karp substring search is known as a fingerprint search because it uses a small amount of information to represent a (potentially very large) pattern. Then it looks for this fingerprint (the hash value) in the text. The algorithm is efficient because the fingerprints can be efficiently computed and compared.</p><p attribs="{'xml:space': 'preserve'}" id="_13822" smilref="Title.smil#_13822" /><pagenum id="p792" page="normal" smilref="Title.smil#p792" /><p attribs="{'xml:space': 'preserve'}" id="_13823" smilref="Title.smil#_13823"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13824" smilref="Title.smil#_13824"> 779</p><p attribs="{'xml:space': 'preserve'}" id="_13825" smilref="Title.smil#_13825"> Summary The table at the bottom of the page summarizes the algorithms that we have discussed for substring search. As is often the case when we have several algorithms for the same task, each of them has attractive features. Brute-force search is easy to implement and works well in typical cases ( Java&#8217;s indexOf() method in String uses brute-force search); Knuth-Morris-Pratt is guaranteed linear-time with no backup in the input; Boyer-Moore is sublinear (by a factor of M) in typical situations; and Rabin- Karp is linear. Each also has drawbacks: brute-force might require time proportional to MN; Knuth-Morris-Pratt and Boyer-Moore use extra space; and Rabin-Karp has a relatively long inner loop (several arithmetic operations, as opposed to character compares in the other methods). These characteristics are summarized in the table below.</p><p attribs="{'xml:space': 'preserve'}" id="_13826" smilref="Title.smil#_13826"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_13827" smilref="Title.smil#_13827"> version</p><p attribs="{'xml:space': 'preserve'}" id="_13828" smilref="Title.smil#_13828"> operation count guarantee typical</p><p attribs="{'xml:space': 'preserve'}" id="_13829" smilref="Title.smil#_13829"> backup in input?</p><p attribs="{'xml:space': 'preserve'}" id="_13830" smilref="Title.smil#_13830"> correct?</p><p attribs="{'xml:space': 'preserve'}" id="_13831" smilref="Title.smil#_13831"> extra space</p><p attribs="{'xml:space': 'preserve'}" id="_13832" smilref="Title.smil#_13832"> brute force</p><p attribs="{'xml:space': 'preserve'}" id="_13833" smilref="Title.smil#_13833"> &#8212;</p><p attribs="{'xml:space': 'preserve'}" id="_13834" smilref="Title.smil#_13834"> M N</p><p attribs="{'xml:space': 'preserve'}" id="_13835" smilref="Title.smil#_13835"> 1.1 N</p><p attribs="{'xml:space': 'preserve'}" id="_13836" smilref="Title.smil#_13836"> Knuth-Morris-Pratt</p><p attribs="{'xml:space': 'preserve'}" id="_13837" smilref="Title.smil#_13837"> Boyer-Moore</p><p attribs="{'xml:space': 'preserve'}" id="_13838" smilref="Title.smil#_13838"> Rabin-Karp&#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_13839" smilref="Title.smil#_13839"> full DFA (Algorithm 5.6 ) mismatch transitions only</p><p attribs="{'xml:space': 'preserve'}" id="_13840" smilref="Title.smil#_13840"> full algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_13841" smilref="Title.smil#_13841"> mismatched char heuristic only (Algorithm 5.7 ) Monte Carlo (Algorithm 5.8 )</p><p attribs="{'xml:space': 'preserve'}" id="_13842" smilref="Title.smil#_13842"> Las Vegas</p><p attribs="{'xml:space': 'preserve'}" id="_13843" smilref="Title.smil#_13843"> 2 N</p><p attribs="{'xml:space': 'preserve'}" id="_13844" smilref="Title.smil#_13844"> 3 N</p><p attribs="{'xml:space': 'preserve'}" id="_13845" smilref="Title.smil#_13845"> 3 N</p><p attribs="{'xml:space': 'preserve'}" id="_13846" smilref="Title.smil#_13846"> 1.1 N</p><p attribs="{'xml:space': 'preserve'}" id="_13847" smilref="Title.smil#_13847"> 1.1 N</p><p attribs="{'xml:space': 'preserve'}" id="_13848" smilref="Title.smil#_13848"> N / M</p><p attribs="{'xml:space': 'preserve'}" id="_13849" smilref="Title.smil#_13849"> M N</p><p attribs="{'xml:space': 'preserve'}" id="_13850" smilref="Title.smil#_13850"> N / M</p><p attribs="{'xml:space': 'preserve'}" id="_13851" smilref="Title.smil#_13851"> 7 N</p><p attribs="{'xml:space': 'preserve'}" id="_13852" smilref="Title.smil#_13852"> 7 N &#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_13853" smilref="Title.smil#_13853"> 7 N</p><p attribs="{'xml:space': 'preserve'}" id="_13854" smilref="Title.smil#_13854"> 7 N</p><p attribs="{'xml:space': 'preserve'}" id="_13855" smilref="Title.smil#_13855"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13856" smilref="Title.smil#_13856"> no</p><p attribs="{'xml:space': 'preserve'}" id="_13857" smilref="Title.smil#_13857"> no</p><p attribs="{'xml:space': 'preserve'}" id="_13858" smilref="Title.smil#_13858"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13859" smilref="Title.smil#_13859"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13860" smilref="Title.smil#_13860"> no</p><p attribs="{'xml:space': 'preserve'}" id="_13861" smilref="Title.smil#_13861"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13862" smilref="Title.smil#_13862"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13863" smilref="Title.smil#_13863"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13864" smilref="Title.smil#_13864"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13865" smilref="Title.smil#_13865"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13866" smilref="Title.smil#_13866"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13867" smilref="Title.smil#_13867"> yes &#8224;</p><p attribs="{'xml:space': 'preserve'}" id="_13868" smilref="Title.smil#_13868"> yes</p><p attribs="{'xml:space': 'preserve'}" id="_13869" smilref="Title.smil#_13869"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13870" smilref="Title.smil#_13870"> MR</p><p attribs="{'xml:space': 'preserve'}" id="_13871" smilref="Title.smil#_13871"> M</p><p attribs="{'xml:space': 'preserve'}" id="_13872" smilref="Title.smil#_13872"> R</p><p attribs="{'xml:space': 'preserve'}" id="_13873" smilref="Title.smil#_13873"> R</p><p attribs="{'xml:space': 'preserve'}" id="_13874" smilref="Title.smil#_13874"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13875" smilref="Title.smil#_13875"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_13876" smilref="Title.smil#_13876"> &#8224; probabilisitic guarantee, with uniform and independent hash function</p><p attribs="{'xml:space': 'preserve'}" id="_13877" smilref="Title.smil#_13877"> Cost summary for substring search implementations</p><p attribs="{'xml:space': 'preserve'}" id="_13878" smilref="Title.smil#_13878" /><pagenum id="p793" page="normal" smilref="Title.smil#p793" /><p attribs="{'xml:space': 'preserve'}" id="_13879" smilref="Title.smil#_13879"> 780</p><p attribs="{'xml:space': 'preserve'}" id="_13880" smilref="Title.smil#_13880"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13881" smilref="Title.smil#_13881"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_13882" smilref="Title.smil#_13882"> Q. This substring search problem seems like a bit of a toy problem. Do I really need to understand these complicated algorithms? A. Well, the factor of M speedup available with Boyer-Moore can be quite impressive in practice. Also, the ability to stream input (no backup) leads to many practical applications for KMP and Rabin-Karp. Beyond these direct practical applications, this topic provides an interesting introduction to the use of abstract machines and randomization in algorithm design. Q. Why not simplify things by converting each character to binary, treating all text as binary text? A. That idea is not quite effective because of false matches across character boundaries.</p><p attribs="{'xml:space': 'preserve'}" id="_13883" smilref="Title.smil#_13883" /><pagenum id="p794" page="normal" smilref="Title.smil#p794" /><p attribs="{'xml:space': 'preserve'}" id="_13884" smilref="Title.smil#_13884"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13885" smilref="Title.smil#_13885"> 781</p><p attribs="{'xml:space': 'preserve'}" id="_13886" smilref="Title.smil#_13886"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_13887" smilref="Title.smil#_13887"> 5.3.1 Develop a brute-force substring search implementation Brute, using the same</p><p attribs="{'xml:space': 'preserve'}" id="_13888" smilref="Title.smil#_13888"> API as Algorithm 5.6.</p><p attribs="{'xml:space': 'preserve'}" id="_13889" smilref="Title.smil#_13889"> 5.3.2 Give the dfa[][] array for the Knuth-Morris-Pratt algorithm for the pattern A A A A A A A A A, and draw the DFA, in the style of the figures in the text. 5.3.3 Give the dfa[][] array for the Knuth-Morris-Pratt algorithm for the pattern A B R A C A D A B R A, and draw the DFA, in the style of the figures in the text. 5.3.4 Write an efficient method that takes a string txt and an integer M as arguments and returns the position of the first occurrence of M consecutive blanks in the string, txt.length if there is no such occurrence. Estimate the number of character compares used by your method, on typical text and in the worst case. 5.3.5 Develop a brute-force substring search implementation BruteForceRL that processes the pattern from right to left (a simplified version of Algorithm 5.7). 5.3.6 Give the right[] array computed by the constructor in Algorithm 5.7 for the</p><p attribs="{'xml:space': 'preserve'}" id="_13890" smilref="Title.smil#_13890"> pattern A B R A C A D A B R A.</p><p attribs="{'xml:space': 'preserve'}" id="_13891" smilref="Title.smil#_13891"> 5.3.7 Add to our brute-force implementation of substring search a count() method to count occurrences and a searchAll() method to print all occurrences. 5.3.8 Add to KMP a count() method to count occurrences and a searchAll() method to print all occurrences. 5.3.9 Add to BoyerMoore a count() method to count occurrences and a searchAll() method to print all occurrences. 5.3.10 Add to RabinKarp a count() method to count occurrences and a searchAll() method to print all occurrences. 5.3.11 Construct a worst-case example for the Boyer-Moore implementation in Algo- rithm 5.7 (which demonstrates that it is not linear-time). 5.3.12 Add the code to check() in RabinKarp (Algorithm 5.8) that turns it into a Las Vegas algorithm (check that the pattern matches the text at the position given as argument). 5.3.13 In the Boyer-Moore implementation in Algorithm 5.7, show that you can set</p><p attribs="{'xml:space': 'preserve'}" id="_13892" smilref="Title.smil#_13892" /><pagenum id="p795" page="normal" smilref="Title.smil#p795" /><p attribs="{'xml:space': 'preserve'}" id="_13893" smilref="Title.smil#_13893"> 782</p><p attribs="{'xml:space': 'preserve'}" id="_13894" smilref="Title.smil#_13894"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13895" smilref="Title.smil#_13895"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_13896" smilref="Title.smil#_13896"> right[c] to the penultimate occurrence of c when c is the last character in the pattern. 5.3.14 Develop versions of the substring search implementations in this section that use char[] instead of String to represent the pattern and the text. 5.3.15 Design a brute-force substring search algorithm that scans the pattern from right to left. 5.3.16 Show the trace of the brute-force algorithm in the style of the figures in the text for the following pattern and text strings</p><p attribs="{'xml:space': 'preserve'}" id="_13897" smilref="Title.smil#_13897"> a. pattern: AAAAAAAB text: AAAAAAAAAAAAAAAAAAAAAAAAB b. pattern: ABABABAB text: ABABABABAABABABABAAAAAAAA</p><p attribs="{'xml:space': 'preserve'}" id="_13898" smilref="Title.smil#_13898"> 5.3.17 Draw the KMP DFA for the following pattern strings.</p><p attribs="{'xml:space': 'preserve'}" id="_13899" smilref="Title.smil#_13899"> a. AAAAAAB b. AACAAAB c. ABABABAB d. ABAABAAABAAAB e. ABAABCABAABCB</p><p attribs="{'xml:space': 'preserve'}" id="_13900" smilref="Title.smil#_13900"> 5.3.18 Suppose that the pattern and text are random strings over an alphabet of size R (which is at least 2). Show that the expected number of character compares for the brute-force method is (N &#11002; M + 1) (1 &#11002; R&#11002;M) / (1 &#11002; R&#11002;1) &#11349; 2(N &#11002; M + 1). 5.3.19 Construct an example where the Boyer-Moore algorithm (with only the mismatched character heuristic) performs poorly. 5.3.20 How would you modify the Rabin-Karp algorithm to determine whether any of a subset of k patterns (say, all of the same length) is in the text?</p><p attribs="{'xml:space': 'preserve'}" id="_13901" smilref="Title.smil#_13901"> Solution : Compute the hashes of the k patterns and store the hashes in a StringSET</p><p attribs="{'xml:space': 'preserve'}" id="_13902" smilref="Title.smil#_13902"> (see Exercise 5.2.6).</p><p attribs="{'xml:space': 'preserve'}" id="_13903" smilref="Title.smil#_13903"> 5.3.21 How would you modify the Rabin-Karp algorithm to search for a given pattern with the additional proviso that the middle character is a &#8220;wildcard&#8221; (any text character</p><p attribs="{'xml:space': 'preserve'}" id="_13904" smilref="Title.smil#_13904" /><pagenum id="p796" page="normal" smilref="Title.smil#p796" /><p attribs="{'xml:space': 'preserve'}" id="_13905" smilref="Title.smil#_13905"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13906" smilref="Title.smil#_13906"> 783</p><p attribs="{'xml:space': 'preserve'}" id="_13907" smilref="Title.smil#_13907"> at all can match it). 5.3.22 How would you modify the Rabin-Karp algorithm to search for an H-by-V pattern in an N-by-N text? 5.3.23 Write a program that reads characters one at a time and reports at each instant if the current string is a palindrome. Hint : Use the Rabin-Karp hashing idea.</p><p attribs="{'xml:space': 'preserve'}" id="_13908" smilref="Title.smil#_13908" /><pagenum id="p797" page="normal" smilref="Title.smil#p797" /><p attribs="{'xml:space': 'preserve'}" id="_13909" smilref="Title.smil#_13909"> 784</p><p attribs="{'xml:space': 'preserve'}" id="_13910" smilref="Title.smil#_13910"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13911" smilref="Title.smil#_13911"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_13912" smilref="Title.smil#_13912"> 5.3.24 Find all occurrences. Add a method findAll() to each of the four substring search algorithms given in the text that returns an Iterable&lt;Integer&gt; that allows clients to iterate through all offsets of the pattern in the text. 5.3.25 Streaming. Add a search() method to KMP that takes variable of type In as argument, and searches for the pattern in the specified input stream without using any extra instance variables. Then do the same for RabinKarp. 5.3.26 Cyclic rotation check. Write a program that, given two strings, determines whether one is a cyclic rotation of the other, such as example and ampleex. 5.3.27 Tandem repeat search. A tandem repeat of a base string b in a string s is a substring of s having at least two consecutive copies b (nonoverlapping). Develop and implement a linear-time algorithm that, given two strings b and s, returns the index of the beginning of the longest tandem repeat of b in s. For example, your program should</p><p attribs="{'xml:space': 'preserve'}" id="_13913" smilref="Title.smil#_13913"> return 3 when b is abcab and s is abcabcababcababcababcab.</p><p attribs="{'xml:space': 'preserve'}" id="_13914" smilref="Title.smil#_13914"> 5.3.28 Buffering in brute-force search. Add a search() method to your solution to Exercise 5.3.1 that takes an input stream (of type In) as argument and searches for the pattern in the given input stream. Note : You need to maintain a buffer that can keep at least the previous M characters in the input stream. Your challenge is to write efficient code to initialize, update, and clear the buffer for any input stream. 5.3.29 Buffering in Boyer-Moore. Add a search() method to Algorithm 5.7 that takes an input stream (of type In) as argument and searches for the pattern in the given input stream. 5.3.30 Two-dimensional search. Implement a version of the Rabin-Karp algorithm to search for patterns in two-dimensional text. Assume both pattern and text are rectangles of characters. 5.3.31 Random patterns. How many character compares are needed to do a substring search for a random pattern of length 100 in a given text?</p><p attribs="{'xml:space': 'preserve'}" id="_13915" smilref="Title.smil#_13915"> Answer: None. The method</p><p attribs="{'xml:space': 'preserve'}" id="_13916" smilref="Title.smil#_13916"> public boolean search(char[] txt) { return false; }</p><p attribs="{'xml:space': 'preserve'}" id="_13917" smilref="Title.smil#_13917" /><pagenum id="p798" page="normal" smilref="Title.smil#p798" /><p attribs="{'xml:space': 'preserve'}" id="_13918" smilref="Title.smil#_13918"> 5.3 </p><p attribs="{'xml:space': 'preserve'}" id="_13919" smilref="Title.smil#_13919"> 785</p><p attribs="{'xml:space': 'preserve'}" id="_13920" smilref="Title.smil#_13920"> is quite effective for this problem, since the chances of a random pattern of length 100 appearing in any text are so low that you may consider it to be 0. 5.3.32 Unique substrings. Solve Exercise 5.2.14 using the idea behind the Rabin- Karp method. 5.3.33 Random primes. Implement longRandomPrime() for RabinKarp (Algorithm 5.8). Hint : A random n-digit number is prime with probability proportional to 1/n. 5.3.34 Straight-line code. The Java Virtual Machine (and your computer&#8217;s assembly language) support a goto instruction so that the search can be &#8220;wired in&#8217;&#8217; to machine code, like the program at right (which is exactly equivalent to simulating the DFA for the pattern as in KMPdfa, but likely to be much more ef&#64257; cient). To avoid checking whether the end of the text has been reached each time i is incremented, we assume that the pattern itself is stored at the end of the text as a sentinel, as the last M characters of the text. The goto labels in this code correspond precisely to the dfa[] array. Write a static method that takes a pattern as input and produces as output a straight-line program like this that searches for the pattern. 5.3.35 Boyer-Moore in binary strings. The mismatched character heuristic does not help much for binary strings, because there are only two possibilities for characters that cause the mismatch (and these are both likely to be in the pattern). Develop a substring search class for binary strings that groups bits together to make &#8220;characters&#8217;&#8217; that can be used exactly as in Algorithm 5.7. Note : If you take b bits at a time, then you need a right[] array with 2b entries. The value of b should be chosen small enough so that this table is not too large, but large enough that most b-bit sections of the text are not likely to be in the pattern&#8212;there are M&#11002;b&#11001;1 different b-bit sections in the pattern (one starting at each bit position from 1 through M&#11002;b&#11001;1), so we want M&#11002;b&#11001;1 to be sig- ni&#64257; cantly less than 2b. For example, if you take 2b to be about lg (4M), then the right[] array will be more than three-quarters filled with -1 entries, but do not let b become less than M/2, since otherwise you could miss the pattern entirely, if it were split between two b-bit text sections.</p><p attribs="{'xml:space': 'preserve'}" id="_13921" smilref="Title.smil#_13921"> int i = -1; sm: i++; s0: if (txt[i]) != 'A' goto sm; s1: if (txt[i]) != 'A' goto s0; s2: if (txt[i]) != 'B' goto s0; s3: if (txt[i]) != 'A' goto s2; s4: if (txt[i]) != 'A' goto s0; s5: if (txt[i]) != 'A' goto s3; return i-8;</p><p attribs="{'xml:space': 'preserve'}" id="_13922" smilref="Title.smil#_13922"> Straight-line substring search for A A B A A A</p><p attribs="{'xml:space': 'preserve'}" id="_13923" smilref="Title.smil#_13923" /><pagenum id="p799" page="normal" smilref="Title.smil#p799" /><p attribs="{'xml:space': 'preserve'}" id="_13924" smilref="Title.smil#_13924"> 786</p><p attribs="{'xml:space': 'preserve'}" id="_13925" smilref="Title.smil#_13925"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13926" smilref="Title.smil#_13926"> EXPERIMENTS</p><p attribs="{'xml:space': 'preserve'}" id="_13927" smilref="Title.smil#_13927"> 5.3.36 Random text. Write a program that takes integers M and N as arguments, generates a random binary text string of length N, then counts the number of other occurrences of the last M bits elsewhere in the string. Note : Different methods may be appropriate for different values of M. 5.3.37 KMP for random text. Write a client that takes integers M, N, and T as input and runs the following experiment T times: Generate a random pattern of length M and a random text of length N, counting the number of character compares used by KMP to search for the pattern in the text. Instrument KMP to provide the number of compares, and print the average count for the T trials. 5.3.38 Boyer-Moore for random text. Answer the previous exercise for BoyerMoore. 5.3.39 Timings. Write a program that times the four methods for the task of searchng for the substring</p><p attribs="{'xml:space': 'preserve'}" id="_13928" smilref="Title.smil#_13928"> it is a far far better thing that i do than i have ever done</p><p attribs="{'xml:space': 'preserve'}" id="_13929" smilref="Title.smil#_13929"> in the text of Tale of Two Cities (tale.txt). Discuss the extent to which your results validate the hypthotheses about performance that are stated in the text.</p><p attribs="{'xml:space': 'preserve'}" id="_13930" smilref="Title.smil#_13930" /><pagenum id="p800" page="normal" smilref="Title.smil#p800" /><p attribs="{'xml:space': 'preserve'}" id="_13931" smilref="Title.smil#_13931"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_13932" smilref="Title.smil#_13932" /></level3><level3 id="_00108"><h3 id="ch5-s4-ss12" smilref="Title.smil#ch5-s4-ss12" xml:space="preserve">Describing patterns with REs</h3><pagenum id="p802" page="normal" smilref="Title.smil#p802" /><p attribs="{'xml:space': 'preserve'}" id="_13933" smilref="Title.smil#_13933"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_13934" smilref="Title.smil#_13934"> 789</p><p attribs="{'xml:space': 'preserve'}" id="_13935" smilref="Title.smil#_13935"> Describing patterns with regular expressions We focus on pattern descrip-</p><p attribs="{'xml:space': 'preserve'}" id="_13936" smilref="Title.smil#_13936"> tions made up of characters that serve as operands for three fundamental operations. In this context, we use the word language specifically to refer to a set of strings (pos- sibly in&#64257; nite) and the word pattern to refer to a language speci&#64257; cation. The rules that we consider are quite analogous to familiar rules for specifying arithmetic expressions.</p><p attribs="{'xml:space': 'preserve'}" id="_13937" smilref="Title.smil#_13937"> Concatenation. The first fundamental operation is the one used in the last section. When we write A B , we are specifying the language { A B } that has one two-character string, formed by concatenating A and B.</p><p attribs="{'xml:space': 'preserve'}" id="_13938" smilref="Title.smil#_13938"> Or. The second fundamental operation allows us to specify alternatives in the pattern. If we have an or between two alternatives, then both are in the language. We will use the vertical bar symbol | to denote this operation. For example, A | B specifies the language { A , B } and A | E | I | O | U specifies the language { A , E , I , O , U }. Concatenation has higher precedence than or, so A B | B C D specifies the language { A B , B C D } .</p><p attribs="{'xml:space': 'preserve'}" id="_13939" smilref="Title.smil#_13939"> Closure. The third fundamental operation allows parts of the pattern to be repeated arbitrarily. The closure of a pattern is the language of strings formed by concatenating the pattern with itself any number of times (including zero). We denote closure by placing a * after the pattern to be repeated. Closure has higher precedence than con- catenation, so A B * specifies the language consisting of strings with an A followed by 0 or more Bs, while A * B specifies the language consisting of strings with 0 or more As followed by a B. The empty string, which we denote by &#9280;, is found in every text string (and in A*).</p><p attribs="{'xml:space': 'preserve'}" id="_13940" smilref="Title.smil#_13940"> Parentheses. We use parentheses to override the default precedence rules. For exam- ple, C ( A C | B ) D specifies the language { C A C D , C B D }; ( A | C ) ( ( B | C ) D ) speci- fi es the language { A B D , C B D , A C D , C C D }; and ( A B ) * specifies the language of strings formed by concatenating any number of occurrences of A B , including no occurrences: { &#9280;, A B , A B A B , . . .}.</p><p attribs="{'xml:space': 'preserve'}" id="_13941" smilref="Title.smil#_13941"> ( A | B ) ( C | D )</p><p attribs="{'xml:space': 'preserve'}" id="_13942" smilref="Title.smil#_13942"> AC AD BC BD</p><p attribs="{'xml:space': 'preserve'}" id="_13943" smilref="Title.smil#_13943"> matches</p><p attribs="{'xml:space': 'preserve'}" id="_13944" smilref="Title.smil#_13944"> RE</p><p attribs="{'xml:space': 'preserve'}" id="_13945" smilref="Title.smil#_13945"> does not match</p><p attribs="{'xml:space': 'preserve'}" id="_13946" smilref="Title.smil#_13946"> every other string</p><p attribs="{'xml:space': 'preserve'}" id="_13947" smilref="Title.smil#_13947"> A(B|C)*D</p><p attribs="{'xml:space': 'preserve'}" id="_13948" smilref="Title.smil#_13948"> AD ABD ACD ABCCBD</p><p attribs="{'xml:space': 'preserve'}" id="_13949" smilref="Title.smil#_13949"> BCD ADD ABCBC</p><p attribs="{'xml:space': 'preserve'}" id="_13950" smilref="Title.smil#_13950"> A* | (A*BA*BA*)*</p><p attribs="{'xml:space': 'preserve'}" id="_13951" smilref="Title.smil#_13951"> These simple rules allow us to write down REs that, while complicated, clearly and completely describe languages (see the table at right for a few ex- amples). Often, a language can be simply described in some other way, but discovering such a description can be a challenge. For example, the RE in the bottom row of the table specifies the subset of ( A | B ) * with an even number of Bs.</p><p attribs="{'xml:space': 'preserve'}" id="_13952" smilref="Title.smil#_13952"> Examples of regular expressions</p><p attribs="{'xml:space': 'preserve'}" id="_13953" smilref="Title.smil#_13953"> AAA BBAABB BABAAA</p><p attribs="{'xml:space': 'preserve'}" id="_13954" smilref="Title.smil#_13954"> ABA BBB BABBAAA</p><p attribs="{'xml:space': 'preserve'}" id="_13955" smilref="Title.smil#_13955" /><pagenum id="p803" page="normal" smilref="Title.smil#p803" /><p attribs="{'xml:space': 'preserve'}" id="_13956" smilref="Title.smil#_13956"> 790</p><p attribs="{'xml:space': 'preserve'}" id="_13957" smilref="Title.smil#_13957"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13958" smilref="Title.smil#_13958"> Regular expressions are extremely simple formal objects, even simpler than the</p><p attribs="{'xml:space': 'preserve'}" id="_13959" smilref="Title.smil#_13959"> arithmetic expressions that you learned in grade school. Indeed, we will take advantage of their simplicity to develop compact and efficient algorithms for processing them. Our starting point will be the following formal defi nition:</p><p attribs="{'xml:space': 'preserve'}" id="_13960" smilref="Title.smil#_13960"> Definition. A regular expression (RE) is either </p><p attribs="{'xml:space': 'preserve'}" id="_13961" smilref="Title.smil#_13961"> This definition describes the syntax of regular expressions, telling us what constitutes a legal regular expression. The semantics that tells us the meaning of a given regular expression is the point of the informal descriptions that we have given in this section. For review, we summarize these by continuing the formal defi nition:</p><p attribs="{'xml:space': 'preserve'}" id="_13962" smilref="Title.smil#_13962"> Definition (continued). Each RE represents a set of strings, defined as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_13963" smilref="Title.smil#_13963"> There are many different ways to describe each language: we must try to specify succinct patterns just as we try to write compact programs and implement efficient algorithms.</p><p attribs="{'xml:space': 'preserve'}" id="_13964" smilref="Title.smil#_13964" /><pagenum id="p804" page="normal" smilref="Title.smil#p804" /><p attribs="{'xml:space': 'preserve'}" id="_13965" smilref="Title.smil#_13965"> Shortcuts Typical applications adopt various additions to these basic rules to enable us to develop succinct descriptions of languages of practical interest. From a theoretical standpoint, these are each simply a shortcut for a sequence of operations involving many operands; from a practical standpoint, they are a quite useful extention to the basic operations that enable us to develop compact patterns.</p><p attribs="{'xml:space': 'preserve'}" id="_13966" smilref="Title.smil#_13966"> Set-of-characters descriptors. It is often convenient</p><p attribs="{'xml:space': 'preserve'}" id="_13967" smilref="Title.smil#_13967"> to be able to use a single character or a short sequence to directly specify sets of characters. The dot character (.) is a wildcard that represents any single character. A sequence of characters within square brackets represents any one of those characters. The sequence may also be specified as a range of characters. If preceded by a ^, a sequence within square brackets represents any character but one of those characters. These notations are simply shortcuts for a sequence of or operations.</p><p attribs="{'xml:space': 'preserve'}" id="_13968" smilref="Title.smil#_13968"> Closure shortcuts. The closure operator specifies any number of copies of its operand. In practice, we want the flexibility to specify the number of copies, or a range on the number. In particular, we use the plus sign (+) to specify at least one copy, the question mark (?) to specify zero or one copy, and a count or a range within braces ({}) to specify a given number of copies. Again, these notations are shortcuts for a sequence of the basic concatenation, or, and closure operations.</p><p attribs="{'xml:space': 'preserve'}" id="_13969" smilref="Title.smil#_13969"> Escape sequences. Some characters, such as</p><p attribs="{'xml:space': 'preserve'}" id="_13970" smilref="Title.smil#_13970" /></level3><level3 id="_00109"><h3 id="ch5-s4-ss13" smilref="Title.smil#ch5-s4-ss13" xml:space="preserve">Applications</h3><pagenum id="p805" page="normal" smilref="Title.smil#p805" /><p attribs="{'xml:space': 'preserve'}" id="_13971" smilref="Title.smil#_13971"> 792</p><p attribs="{'xml:space': 'preserve'}" id="_13972" smilref="Title.smil#_13972"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_13973" smilref="Title.smil#_13973"> REs in applications REs have proven to be remarkably versatile in describing languages that are relevant in practical applications. Accordingly, REs are heavily used and have been heavily studied. To familiarize you with regular expressions while at the same time giving you some appreciation for their utility, we consider a number of practical applications before addressing the RE pattern-matching algorithm. REs also play an important role in theoretical computer science. Discussing this role to the extent it deserves is beyond the scope of this book, but we sometimes allude to relevant fundamental theoretical results.</p><p attribs="{'xml:space': 'preserve'}" id="_13974" smilref="Title.smil#_13974"> Substring search. Our general goal is to develop an algorithm that determines whether a given text string is in the set of strings described by a given regular expression. If a text is in the language described by a pattern, we say that the text matches the pattern. Pattern matching with REs vastly generalizes the substring search problem of Section 5.3. Precisely, to search for a substring pat in a text string txt is to check whether txt is in the language described by the pattern . * pat. * or not.</p><p attribs="{'xml:space': 'preserve'}" id="_13975" smilref="Title.smil#_13975"> Validity checking. You frequently encounter RE matching when you use the web. When you type in a date or an account number on a commercial website, the input- processing program has to check that your response is in the right format. One approach to performing such a check is to write code that checks all the cases: if you were to type in a dollar amount, the code might check that the first symbol is a $, that the $ is followed by a set of digits, and so forth. A better approach is to define an RE that describes the set of all legal inputs. Then, checking whether your input is legal is precisely the pattern-matching problem: is your input in the language described by the RE? Libraries of REs for common checks have sprung up on the web as this type of checking has come into widespread use. Typically, an RE is a much more precise and concise expression of the set of all valid strings than would be a program that checks all the cases.</p><p attribs="{'xml:space': 'preserve'}" id="_13976" smilref="Title.smil#_13976"> context</p><p attribs="{'xml:space': 'preserve'}" id="_13977" smilref="Title.smil#_13977"> regular expression</p><p attribs="{'xml:space': 'preserve'}" id="_13978" smilref="Title.smil#_13978"> matches</p><p attribs="{'xml:space': 'preserve'}" id="_13979" smilref="Title.smil#_13979"> substring search</p><p attribs="{'xml:space': 'preserve'}" id="_13980" smilref="Title.smil#_13980"> phone number</p><p attribs="{'xml:space': 'preserve'}" id="_13981" smilref="Title.smil#_13981"> Java identifier </p><p attribs="{'xml:space': 'preserve'}" id="_13982" smilref="Title.smil#_13982"> genome marker</p><p attribs="{'xml:space': 'preserve'}" id="_13983" smilref="Title.smil#_13983"> email address</p><p attribs="{'xml:space': 'preserve'}" id="_13984" smilref="Title.smil#_13984"> . * N E E D L E . *</p><p attribs="{'xml:space': 'preserve'}" id="_13985" smilref="Title.smil#_13985"> A H A Y S T A C K N E E D L E I N</p><p attribs="{'xml:space': 'preserve'}" id="_13986" smilref="Title.smil#_13986"> \([0-9]{3}\)\ [0-9]{3}-[0-9]{4}</p><p attribs="{'xml:space': 'preserve'}" id="_13987" smilref="Title.smil#_13987"> (800) 867-5309</p><p attribs="{'xml:space': 'preserve'}" id="_13988" smilref="Title.smil#_13988"> [$_A-Za-z][$_A-Za-z0-9]*</p><p attribs="{'xml:space': 'preserve'}" id="_13989" smilref="Title.smil#_13989"> Pattern_Matcher</p><p attribs="{'xml:space': 'preserve'}" id="_13990" smilref="Title.smil#_13990"> gcg(cgg|agg)*ctg</p><p attribs="{'xml:space': 'preserve'}" id="_13991" smilref="Title.smil#_13991"> gcgaggaggcggcggctg</p><p attribs="{'xml:space': 'preserve'}" id="_13992" smilref="Title.smil#_13992"> [a-z]+@([a-z]+\.)+(edu|com)</p><p attribs="{'xml:space': 'preserve'}" id="_13993" smilref="Title.smil#_13993"> rs@cs.princeton.edu</p><p attribs="{'xml:space': 'preserve'}" id="_13994" smilref="Title.smil#_13994"> Typical regular expressions in applications (simplif ied versions)</p><p attribs="{'xml:space': 'preserve'}" id="_13995" smilref="Title.smil#_13995" /><pagenum id="p806" page="normal" smilref="Title.smil#p806" /><p attribs="{'xml:space': 'preserve'}" id="_13996" smilref="Title.smil#_13996"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_13997" smilref="Title.smil#_13997"> 793</p><p attribs="{'xml:space': 'preserve'}" id="_13998" smilref="Title.smil#_13998"> Programmer&#8217;s toolbox. The origin of regular expression pattern matching is the Unix command grep, which prints all lines matching a given RE. This capability has proven invaluable for generations of programmers, and REs are built into many modern programming systems, from awk and emacs to Perl, Python, and JavaScript. For example, suppose that you have a directory with dozens of .java fi les, and you want to know which of them has code that uses StdIn. The command</p><p attribs="{'xml:space': 'preserve'}" id="_13999" smilref="Title.smil#_13999"> % grep StdIn *.java</p><p attribs="{'xml:space': 'preserve'}" id="_14000" smilref="Title.smil#_14000"> will immediately give the answer. It prints all lines that match .*StdIn.* for each fi le.</p><p attribs="{'xml:space': 'preserve'}" id="_14001" smilref="Title.smil#_14001"> Genomics. Biologists use REs to help address important scientific problems. For example, the human gene sequence has a region that can be described with the RE gcg(cgg)*ctg, where the number of repeats of the cgg pattern is highly variable among individuals, and a certain genetic disease that can cause mental retardation and other symptoms is known to be associated with a high number of repeats.</p><p attribs="{'xml:space': 'preserve'}" id="_14002" smilref="Title.smil#_14002"> Search. Web search engines support REs, though not always in their full glory. Typi- cally, if you want to specify alternatives with | or repetition with *, you can do so.</p><p attribs="{'xml:space': 'preserve'}" id="_14003" smilref="Title.smil#_14003"> Possibilities. A first introduction to theoretical computer science is to think about the set of languages that can be specified with an RE. For example, you might be surprised to know that you can implement the modulus operation with an RE: for example, ( 0 | 1 ( 0 1 * 0 ) * 1 ) * describes all strings of 0s and 1s that are the binary repre- sentatons of numbers that are multiples of three (!): 1 1 , 1 1 0 , 1 0 0 1 , and 1 1 0 0 are in the language, but 1 0 , 1 0 1 1 , and 1 0 0 0 0 are not.</p><p attribs="{'xml:space': 'preserve'}" id="_14004" smilref="Title.smil#_14004"> Limitations. Not all languages can be specified with REs. A thought-provoking example is that no RE can describe the set of all strings that specify legal REs. Simpler versions of this example are that we cannot use REs to check whether parentheses are balanced or to check whether a string has an equal number of As and Bs.</p><p attribs="{'xml:space': 'preserve'}" id="_14005" smilref="Title.smil#_14005"> These examples just scratch the surface. Suf&#64257; ce it to say that REs are a useful part of our computational infrastructure and have played an important role in our understanding of the nature of computation. As with KMP, the algorithm that we describe next is a byproduct of the search for that understanding.</p><p attribs="{'xml:space': 'preserve'}" id="_14006" smilref="Title.smil#_14006" /></level3><level3 id="_00110"><h3 id="ch5-s4-ss14" smilref="Title.smil#ch5-s4-ss14" xml:space="preserve">Nondeterministic finite-state automata</h3><pagenum id="p807" page="normal" smilref="Title.smil#p807" /><p attribs="{'xml:space': 'preserve'}" id="_14007" smilref="Title.smil#_14007"> 794</p><p attribs="{'xml:space': 'preserve'}" id="_14008" smilref="Title.smil#_14008"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14009" smilref="Title.smil#_14009"> Nondeterministic fi nite-state automata Recall that we can view the Knuth-</p><p attribs="{'xml:space': 'preserve'}" id="_14010" smilref="Title.smil#_14010"> Morris-Pratt algorithm as a fi nite-state machine constructed from the search pattern that scans the text. For regular expression pattern matching, we will generalize this idea. The fi nite-state automaton for KMP changes from state to state by looking at a character from the text string and then changing to another state, depending on the char- acter. The automaton reports a match if and only if it reaches the accept state. The algorithm itself is a simulation of the automaton. The characteristic of the machine that makes it easy to simulate is that it is deterministic: each state transition is completely determined by the next character in the text. To handle regular expressions, we consider a more powerful abstract machine. Be- cause of the or operation, the automaton cannot determine whether or not the pattern could occur at a given point by examining just one character; indeed, because of clo- sure, it cannot even determine how many characters might need to be examined before a mismatch is discovered. To overcome these problems, we will endow the automaton with the power of nondeterminism: when faced with more than one way to try to match the pattern, the machine can &#8220;guess&#8217;&#8217; the right one! This power might seem to you to be impossible to realize, but we will see that it is easy to write a program to build a nondeterministic fi nite-state automaton (NFA) and to efficiently simulate its operation. The overview of our RE pattern matching algorithm is the nearly the same as for KMP: </p><p attribs="{'xml:space': 'preserve'}" id="_14011" smilref="Title.smil#_14011"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14012" smilref="Title.smil#_14012"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14013" smilref="Title.smil#_14013"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14014" smilref="Title.smil#_14014"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14015" smilref="Title.smil#_14015"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14016" smilref="Title.smil#_14016"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14017" smilref="Title.smil#_14017"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14018" smilref="Title.smil#_14018"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14019" smilref="Title.smil#_14019"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14020" smilref="Title.smil#_14020"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14021" smilref="Title.smil#_14021"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14022" smilref="Title.smil#_14022"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14023" smilref="Title.smil#_14023"> start state</p><p attribs="{'xml:space': 'preserve'}" id="_14024" smilref="Title.smil#_14024"> accept state</p><p attribs="{'xml:space': 'preserve'}" id="_14025" smilref="Title.smil#_14025"> NFA corresponding to the pattern ( ( A * B | A C ) D )</p><p attribs="{'xml:space': 'preserve'}" id="_14026" smilref="Title.smil#_14026" /><pagenum id="p808" page="normal" smilref="Title.smil#p808" /><p attribs="{'xml:space': 'preserve'}" id="_14027" smilref="Title.smil#_14027"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14028" smilref="Title.smil#_14028"> 795</p><p attribs="{'xml:space': 'preserve'}" id="_14029" smilref="Title.smil#_14029"> </p><p attribs="{'xml:space': 'preserve'}" id="_14030" smilref="Title.smil#_14030"> A A A A B D 0 1 2 3 2 3 2 3 2 3 4 5 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14031" smilref="Title.smil#_14031"> match transition: scan to next input character and change state</p><p attribs="{'xml:space': 'preserve'}" id="_14032" smilref="Title.smil#_14032"> &#9280;-transition: change state with no match</p><p attribs="{'xml:space': 'preserve'}" id="_14033" smilref="Title.smil#_14033"> accept state reached and all text characters scanned: NFA recognizes text</p><p attribs="{'xml:space': 'preserve'}" id="_14034" smilref="Title.smil#_14034"> Finding a pattern with ( ( A * B | A C ) D ) NFA</p><p attribs="{'xml:space': 'preserve'}" id="_14035" smilref="Title.smil#_14035" /><pagenum id="p809" page="normal" smilref="Title.smil#p809" /><p attribs="{'xml:space': 'preserve'}" id="_14036" smilref="Title.smil#_14036"> 796</p><p attribs="{'xml:space': 'preserve'}" id="_14037" smilref="Title.smil#_14037"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14038" smilref="Title.smil#_14038"> A A A 0 1 2 3 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_14039" smilref="Title.smil#_14039"> wrong guess if input is A A A A B D</p><p attribs="{'xml:space': 'preserve'}" id="_14040" smilref="Title.smil#_14040"> A 0 1 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_14041" smilref="Title.smil#_14041"> A A A A C 0 1 2 3 2 3 2 3 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_14042" smilref="Title.smil#_14042"> Stalling sequences for ( ( A * B | A C ) D ) NFA</p><p attribs="{'xml:space': 'preserve'}" id="_14043" smilref="Title.smil#_14043"> no way out of state 7</p><p attribs="{'xml:space': 'preserve'}" id="_14044" smilref="Title.smil#_14044"> no way out of state 4</p><p attribs="{'xml:space': 'preserve'}" id="_14045" smilref="Title.smil#_14045"> no way out of state 4</p><p attribs="{'xml:space': 'preserve'}" id="_14046" smilref="Title.smil#_14046"> For example, suppose that our NFA for ( ( A * B | A C ) D ) is started (at state 0) with the text A A A A B D as input. The figure at the bottom of the previous page shows a sequence of state transitions ending in the accept state. This sequence demonstrates that the text is in the set of strings described by the RE&#8212;the text matches the pattern. With respect to the NFA, we say that the NFA recognizes that text. The examples shown at left illustrate that it is also possible to find transition sequences that cause the NFA to stall, even for input text such as A A A A B D that it should recognize. For example, if the NFA takes the transition to state 4 before scanning all the As, it is left with nowhere to go, since the only way out of state 4 is to match a B. These two examples demonstrate the nondeterministic nature of the automaton. After scanning an A and finding itself in state 3, the NFA has two choices: it could go on to state 4 or it could go back to state 2. The choices make the difference between getting to the accept state (as in the first example just discussed) or stalling (as in the second example just discussed). This NFA also has a choice to make at state 1 (whether to take an &#9280;-transition to state 2 or to state 6). These examples illustrate the key difference between NFAs and DFAs: since an NFA may have multiple edges leaving a given state, the transition from such a state is not deterministic&#8212;it might take one transition at one point in time and a different transition at a different point in time, without scanning past any text character. To make some sense of the operation of such an automaton, imagine that an NFA has the power to guess which transition (if any) will lead to the accept state for the given text string. In other words, we say that an NFA recognizes a text string if and only if there is some sequence of transitions that scans all the text characters and ends in the accept state when started at the beginning of the text in state 0. Conversely, an NFA does not recognize a text string if and only if there is no sequence of match transitions and &#9280;-transitions that can scan all the text characters and lead to the accept state for that string. As with DFAs, we have been tracing the operation of the NFA on a text string simply by listing the sequence of state changes, ending in the final state. Any such sequence is a proof that the machine recognizes the text string (there may be other proofs). But how do we find such a sequence for a given text string? And how do we prove that there is no such sequence for another given text string? The answers to these questions are easier than you might think: we systematically try all possibilities.</p><p attribs="{'xml:space': 'preserve'}" id="_14047" smilref="Title.smil#_14047" /></level3><level3 id="_00111"><h3 id="ch5-s4-ss15" smilref="Title.smil#ch5-s4-ss15" xml:space="preserve">Simulating an NFA</h3><pagenum id="p810" page="normal" smilref="Title.smil#p810" /><p attribs="{'xml:space': 'preserve'}" id="_14048" smilref="Title.smil#_14048"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14049" smilref="Title.smil#_14049"> 797</p><p attribs="{'xml:space': 'preserve'}" id="_14050" smilref="Title.smil#_14050"> Simulating an NFA The idea of an automaton that can guess the state transitions it needs to get to the accept state is like writing a program that can guess the right answer to a problem: it seems ridiculous. On refl ection, you will see that the task is conceptually not at all dif&#64257; cult: we make sure that we check all possible sequences of state transitions, so if there is one that gets to the accept state, we will find it.</p><p attribs="{'xml:space': 'preserve'}" id="_14051" smilref="Title.smil#_14051"> Representation. To begin, we need an NFA representation. The choice is clear: the RE itself gives the state names (the integers between 0 and M, where M is the number of characters in the RE). We keep the RE itself in an array re[] of char values that defines the match transitions (if re[i] is in the alphabet, then there is a match transition from i to i+1). The natural representation for the &#9280;-transitions is a digraph&#8212;they are directed edges (red edges in our diagrams) connecting vertices between 0 and M (one for each state). Accordingly, we represent all the &#9280;-transitions as a digraph G. We will consider the task of building the digraph associated with a given RE after we consider the simulation process. For our example, the digraph consists of the nine edges</p><p attribs="{'xml:space': 'preserve'}" id="_14052" smilref="Title.smil#_14052"> 0 &#8594; 1 1 &#8594; 2 1 &#8594; 6 2 &#8594; 3 3 &#8594; 2 3 &#8594; 4 5 &#8594; 8 8 &#8594; 9 10 &#8594; 11</p><p attribs="{'xml:space': 'preserve'}" id="_14053" smilref="Title.smil#_14053"> NFA simulation and reachability. To simulate an NFA, we keep track of the set of states that could possibly be encountered while the automaton is examining the current input character. The key computation is the familiar multiple-source reachability computation that we addressed in Algorithm 4.4 (page 571). To initialize this set, we find the set of states reachable via &#9280;-transitions from state 0. For each such state, we check whether a match transition for the first input character is possible. This check gives us the set of possible states for the NFA just after matching the first input character. To this set, we add all states that could be reached via &#9280;-transitions from one of the states in the set. Given the set of possible states for the NFA just after matching the first character in the input, the solution to the multiple-source reachability problem in the &#9280;-transition digraph gives the set of states that could lead to match transitions for the second character in the input. For example, the initial set of states for our example NFA is 0 1 2 3 4 6; if the first character is an A, the NFA could take a match transition to 3 or 7; then it could take &#9280;-transitions from 3 to 2 or 3 to 4, so the set of possible states that could lead to a match transition for the second character is 2 3 4 7. Iterating this process until all text characters are exhausted leads to one of two outcomes: </p><p attribs="{'xml:space': 'preserve'}" id="_14054" smilref="Title.smil#_14054" /><pagenum id="p811" page="normal" smilref="Title.smil#p811" /><p attribs="{'xml:space': 'preserve'}" id="_14055" smilref="Title.smil#_14055"> Simulation of ( ( A * B | A C ) D ) NFA for input A A B D</p><p attribs="{'xml:space': 'preserve'}" id="_14056" smilref="Title.smil#_14056"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14057" smilref="Title.smil#_14057"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14058" smilref="Title.smil#_14058"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14059" smilref="Title.smil#_14059"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14060" smilref="Title.smil#_14060"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14061" smilref="Title.smil#_14061"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14062" smilref="Title.smil#_14062"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14063" smilref="Title.smil#_14063"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14064" smilref="Title.smil#_14064"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14065" smilref="Title.smil#_14065"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14066" smilref="Title.smil#_14066"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14067" smilref="Title.smil#_14067"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14068" smilref="Title.smil#_14068"> 0 1 2 3 4 6 : set of states reachable via &#9280;-transitions from start</p><p attribs="{'xml:space': 'preserve'}" id="_14069" smilref="Title.smil#_14069"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14070" smilref="Title.smil#_14070"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14071" smilref="Title.smil#_14071"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14072" smilref="Title.smil#_14072"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14073" smilref="Title.smil#_14073"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14074" smilref="Title.smil#_14074"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14075" smilref="Title.smil#_14075"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14076" smilref="Title.smil#_14076"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14077" smilref="Title.smil#_14077"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14078" smilref="Title.smil#_14078"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14079" smilref="Title.smil#_14079"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14080" smilref="Title.smil#_14080"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14081" smilref="Title.smil#_14081"> 3 7 : set of states reachable after matching A</p><p attribs="{'xml:space': 'preserve'}" id="_14082" smilref="Title.smil#_14082"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14083" smilref="Title.smil#_14083"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14084" smilref="Title.smil#_14084"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14085" smilref="Title.smil#_14085"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14086" smilref="Title.smil#_14086"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14087" smilref="Title.smil#_14087"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14088" smilref="Title.smil#_14088"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14089" smilref="Title.smil#_14089"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14090" smilref="Title.smil#_14090"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14091" smilref="Title.smil#_14091"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14092" smilref="Title.smil#_14092"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14093" smilref="Title.smil#_14093"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14094" smilref="Title.smil#_14094"> 2 3 4 7 : set of states reachable via &#9280;-transitions after matching A</p><p attribs="{'xml:space': 'preserve'}" id="_14095" smilref="Title.smil#_14095"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14096" smilref="Title.smil#_14096"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14097" smilref="Title.smil#_14097"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14098" smilref="Title.smil#_14098"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14099" smilref="Title.smil#_14099"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14100" smilref="Title.smil#_14100"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14101" smilref="Title.smil#_14101"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14102" smilref="Title.smil#_14102"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14103" smilref="Title.smil#_14103"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14104" smilref="Title.smil#_14104"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14105" smilref="Title.smil#_14105"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14106" smilref="Title.smil#_14106"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14107" smilref="Title.smil#_14107"> 3 : set of states reachable after matching A A</p><p attribs="{'xml:space': 'preserve'}" id="_14108" smilref="Title.smil#_14108"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14109" smilref="Title.smil#_14109"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14110" smilref="Title.smil#_14110"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14111" smilref="Title.smil#_14111"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14112" smilref="Title.smil#_14112"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14113" smilref="Title.smil#_14113"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14114" smilref="Title.smil#_14114"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14115" smilref="Title.smil#_14115"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14116" smilref="Title.smil#_14116"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14117" smilref="Title.smil#_14117"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14118" smilref="Title.smil#_14118"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14119" smilref="Title.smil#_14119"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14120" smilref="Title.smil#_14120"> 2 3 4 : set of states reachable via &#9280;-transitions after matching A A</p><p attribs="{'xml:space': 'preserve'}" id="_14121" smilref="Title.smil#_14121"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14122" smilref="Title.smil#_14122"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14123" smilref="Title.smil#_14123"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14124" smilref="Title.smil#_14124"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14125" smilref="Title.smil#_14125"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14126" smilref="Title.smil#_14126"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14127" smilref="Title.smil#_14127"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14128" smilref="Title.smil#_14128"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14129" smilref="Title.smil#_14129"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14130" smilref="Title.smil#_14130"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14131" smilref="Title.smil#_14131"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14132" smilref="Title.smil#_14132"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14133" smilref="Title.smil#_14133"> 5 : set of states reachable after matching A A B</p><p attribs="{'xml:space': 'preserve'}" id="_14134" smilref="Title.smil#_14134"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14135" smilref="Title.smil#_14135"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14136" smilref="Title.smil#_14136"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14137" smilref="Title.smil#_14137"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14138" smilref="Title.smil#_14138"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14139" smilref="Title.smil#_14139"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14140" smilref="Title.smil#_14140"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14141" smilref="Title.smil#_14141"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14142" smilref="Title.smil#_14142"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14143" smilref="Title.smil#_14143"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14144" smilref="Title.smil#_14144"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14145" smilref="Title.smil#_14145"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14146" smilref="Title.smil#_14146"> 5 8 9 : set of states reachable via &#9280;-transitions after matching A A B</p><p attribs="{'xml:space': 'preserve'}" id="_14147" smilref="Title.smil#_14147"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14148" smilref="Title.smil#_14148"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14149" smilref="Title.smil#_14149"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14150" smilref="Title.smil#_14150"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14151" smilref="Title.smil#_14151"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14152" smilref="Title.smil#_14152"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14153" smilref="Title.smil#_14153"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14154" smilref="Title.smil#_14154"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14155" smilref="Title.smil#_14155"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14156" smilref="Title.smil#_14156"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14157" smilref="Title.smil#_14157"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14158" smilref="Title.smil#_14158"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14159" smilref="Title.smil#_14159"> 10 : set of states reachable after matching A A B D</p><p attribs="{'xml:space': 'preserve'}" id="_14160" smilref="Title.smil#_14160"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14161" smilref="Title.smil#_14161"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14162" smilref="Title.smil#_14162"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14163" smilref="Title.smil#_14163"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14164" smilref="Title.smil#_14164"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14165" smilref="Title.smil#_14165"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14166" smilref="Title.smil#_14166"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14167" smilref="Title.smil#_14167"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14168" smilref="Title.smil#_14168"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14169" smilref="Title.smil#_14169"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14170" smilref="Title.smil#_14170"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14171" smilref="Title.smil#_14171"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14172" smilref="Title.smil#_14172"> 10 11 : set of states reachable via &#9280;-transitions after matching A A B D</p><p attribs="{'xml:space': 'preserve'}" id="_14173" smilref="Title.smil#_14173"> accept !</p><p attribs="{'xml:space': 'preserve'}" id="_14174" smilref="Title.smil#_14174"> 798</p><p attribs="{'xml:space': 'preserve'}" id="_14175" smilref="Title.smil#_14175"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14176" smilref="Title.smil#_14176" /><pagenum id="p812" page="normal" smilref="Title.smil#p812" /><p attribs="{'xml:space': 'preserve'}" id="_14177" smilref="Title.smil#_14177"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14178" smilref="Title.smil#_14178"> 799</p><p attribs="{'xml:space': 'preserve'}" id="_14179" smilref="Title.smil#_14179"> data type and the DirectedDFS class just described for computing multiple-source reachability in a digraph, the NFA simulation code given below is a straightforward translation of the English-language description just given. You can check your understanding of the code by following the trace on the facing page, which illustrates the full simulation for our example.</p><p attribs="{'xml:space': 'preserve'}" id="_14180" smilref="Title.smil#_14180"> Proposition Q. Determining whether an N-character text string is recognized by the NFA corresponding to an M-character RE takes time proportional to NM in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_14181" smilref="Title.smil#_14181"> Proof : For each of the N text characters, we iterate through a set of states of size no more than M and run a DFS on the digraph of &#9280;-transitions. The construction that we will consider next establishes that the number of edges in that digraph is no more than 2M, so the worst-case time for each DFS is proportional to M.</p><p attribs="{'xml:space': 'preserve'}" id="_14182" smilref="Title.smil#_14182"> Take a moment to reflect on this remarkable result. This worst-case cost, the product of the text and pattern lengths, is the same as the worst-case cost of finding an exact substring match using the elementary algorithm that we started with at the beginning</p><p attribs="{'xml:space': 'preserve'}" id="_14183" smilref="Title.smil#_14183"> of Section 5.3.</p><p attribs="{'xml:space': 'preserve'}" id="_14184" smilref="Title.smil#_14184"> public boolean recognizes(String txt) { // Does the NFA recognize txt? Bag&lt;Integer&gt; pc = new Bag&lt;Integer&gt;(); DirectedDFS dfs = new DirectedDFS(G, 0); for (int v = 0; v &lt; G.V(); v++) if (dfs.marked(v)) pc.add(v);</p><p attribs="{'xml:space': 'preserve'}" id="_14185" smilref="Title.smil#_14185"> for (int i = 0; i &lt; txt.length(); i++) { // Compute possible NFA states for txt[i+1]. Bag&lt;Integer&gt; match = new Bag&lt;Integer&gt;(); for (int v : pc) if (v &lt; M) if (re[v] == txt.charAt(i) || re[v] == '.') match.add(v+1); pc = new Bag&lt;Integer&gt;(); dfs = new DirectedDFS(G, match); for (int v = 0; v &lt; G.V(); v++) if (dfs.marked(v)) pc.add(v);</p><p attribs="{'xml:space': 'preserve'}" id="_14186" smilref="Title.smil#_14186"> }</p><p attribs="{'xml:space': 'preserve'}" id="_14187" smilref="Title.smil#_14187"> for (int v : pc) if (v == M) return true; return false; }</p><p attribs="{'xml:space': 'preserve'}" id="_14188" smilref="Title.smil#_14188"> NFA simulation for pattern matching</p><p attribs="{'xml:space': 'preserve'}" id="_14189" smilref="Title.smil#_14189" /></level3><level3 id="_00112"><h3 id="ch5-s4-ss16" smilref="Title.smil#ch5-s4-ss16" xml:space="preserve">Building an NFA corresponding to an RE</h3><pagenum id="p813" page="normal" smilref="Title.smil#p813" /><p attribs="{'xml:space': 'preserve'}" id="_14190" smilref="Title.smil#_14190"> 800</p><p attribs="{'xml:space': 'preserve'}" id="_14191" smilref="Title.smil#_14191"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14192" smilref="Title.smil#_14192"> Building an NFA corresponding to an RE From the similarity between regu-</p><p attribs="{'xml:space': 'preserve'}" id="_14193" smilref="Title.smil#_14193"> lar expressions and familiar arithmetic expressions, you may not be surprised to find that translating an RE to an NFA is somewhat similar to the process of evaluating an arithmetic expression using Dijkstra&#8217;s two-stack algorithm, which we considered in Section 1.3. The process is a bit different because </p><p attribs="{'xml:space': 'preserve'}" id="_14194" smilref="Title.smil#_14194" /><pagenum id="p814" page="normal" smilref="Title.smil#p814" /><p attribs="{'xml:space': 'preserve'}" id="_14195" smilref="Title.smil#_14195"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14196" smilref="Title.smil#_14196"> 801</p><p attribs="{'xml:space': 'preserve'}" id="_14197" smilref="Title.smil#_14197"> These simple rules suffice to build NFAs corresponding to arbitrarily complicated REs. Algorithm 5.9 is an implementation whose constructor builds the &#9280;-transition digraph corresponding to a given RE, and a trace of the construction for our example appears on the following page. You can find other examples at the bottom of this page and in the exercises and are encouraged to enhance your understanding of the process by working your own examples. For brevity and for clarity, a few details (handling metacharacters, set-of-character descriptors, closure shortcuts, and multiway or op- erations) are left for exercises (see Exercises 5.4.16 through 5.4.21). Otherwise, the construction requires remarkably little code and represents one of the most ingenious algorithms that we have seen.</p><p attribs="{'xml:space': 'preserve'}" id="_14198" smilref="Title.smil#_14198"> single-character closure</p><p attribs="{'xml:space': 'preserve'}" id="_14199" smilref="Title.smil#_14199"> i i+1</p><p attribs="{'xml:space': 'preserve'}" id="_14200" smilref="Title.smil#_14200"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14201" smilref="Title.smil#_14201"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14202" smilref="Title.smil#_14202"> G.addEdge(i, i+1); G.addEdge(i+1, i);</p><p attribs="{'xml:space': 'preserve'}" id="_14203" smilref="Title.smil#_14203"> closure expression</p><p attribs="{'xml:space': 'preserve'}" id="_14204" smilref="Title.smil#_14204"> lp</p><p attribs="{'xml:space': 'preserve'}" id="_14205" smilref="Title.smil#_14205"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14206" smilref="Title.smil#_14206"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_14207" smilref="Title.smil#_14207"> i i+1</p><p attribs="{'xml:space': 'preserve'}" id="_14208" smilref="Title.smil#_14208"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14209" smilref="Title.smil#_14209"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14210" smilref="Title.smil#_14210"> G.addEdge(lp, i+1); G.addEdge(i+1, lp);</p><p attribs="{'xml:space': 'preserve'}" id="_14211" smilref="Title.smil#_14211"> or expression</p><p attribs="{'xml:space': 'preserve'}" id="_14212" smilref="Title.smil#_14212"> lp</p><p attribs="{'xml:space': 'preserve'}" id="_14213" smilref="Title.smil#_14213"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14214" smilref="Title.smil#_14214"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_14215" smilref="Title.smil#_14215"> or</p><p attribs="{'xml:space': 'preserve'}" id="_14216" smilref="Title.smil#_14216"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14217" smilref="Title.smil#_14217"> ...</p><p attribs="{'xml:space': 'preserve'}" id="_14218" smilref="Title.smil#_14218"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14219" smilref="Title.smil#_14219"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14220" smilref="Title.smil#_14220"> G.addEdge(lp, or+1); G.addEdge(or, i);</p><p attribs="{'xml:space': 'preserve'}" id="_14221" smilref="Title.smil#_14221"> NFA construction rules</p><p attribs="{'xml:space': 'preserve'}" id="_14222" smilref="Title.smil#_14222"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18</p><p attribs="{'xml:space': 'preserve'}" id="_14223" smilref="Title.smil#_14223"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14224" smilref="Title.smil#_14224"> .</p><p attribs="{'xml:space': 'preserve'}" id="_14225" smilref="Title.smil#_14225"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14226" smilref="Title.smil#_14226"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14227" smilref="Title.smil#_14227"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14228" smilref="Title.smil#_14228"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14229" smilref="Title.smil#_14229"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14230" smilref="Title.smil#_14230"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14231" smilref="Title.smil#_14231"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14232" smilref="Title.smil#_14232"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14233" smilref="Title.smil#_14233"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14234" smilref="Title.smil#_14234"> E</p><p attribs="{'xml:space': 'preserve'}" id="_14235" smilref="Title.smil#_14235"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14236" smilref="Title.smil#_14236"> F</p><p attribs="{'xml:space': 'preserve'}" id="_14237" smilref="Title.smil#_14237"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14238" smilref="Title.smil#_14238"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14239" smilref="Title.smil#_14239"> G</p><p attribs="{'xml:space': 'preserve'}" id="_14240" smilref="Title.smil#_14240"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14241" smilref="Title.smil#_14241"> NFA corresponding to the pattern ( . * A B ( ( C | D * E ) F ) * G )</p><p attribs="{'xml:space': 'preserve'}" id="_14242" smilref="Title.smil#_14242" /><pagenum id="p815" page="normal" smilref="Title.smil#p815" /><p attribs="{'xml:space': 'preserve'}" id="_14243" smilref="Title.smil#_14243"> 802</p><p attribs="{'xml:space': 'preserve'}" id="_14244" smilref="Title.smil#_14244"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14245" smilref="Title.smil#_14245"> ALGORITHM 5.9 Regular expression pattern matching (grep).</p><p attribs="{'xml:space': 'preserve'}" id="_14246" smilref="Title.smil#_14246"> public class NFA { private char[] re; // match transitions private Digraph G; // epsilon transitions private int M; // number of states</p><p attribs="{'xml:space': 'preserve'}" id="_14247" smilref="Title.smil#_14247"> public NFA(String regexp) { // Create the NFA for the given regular expression. Stack&lt;Integer&gt; ops = new Stack&lt;Integer&gt;(); re = regexp.toCharArray(); M = re.length; G = new Digraph(M+1);</p><p attribs="{'xml:space': 'preserve'}" id="_14248" smilref="Title.smil#_14248"> for (int i = 0; i &lt; M; i++) { int lp = i; if (re[i] == '(' || re[i] == '|') ops.push(i); else if (re[i] == ')') { int or = ops.pop(); if (re[or] == '|') { lp = ops.pop(); G.addEdge(lp, or+1); G.addEdge(or, i); } else lp = or; } if (i &lt; M-1 &amp;&amp; re[i+1] == '*') // lookahead { G.addEdge(lp, i+1); G.addEdge(i+1, lp); } if (re[i] == '(' || re[i] == '*' || re[i] == ')') G.addEdge(i, i+1); } } public boolean recognizes(String txt) // Does the NFA recognize txt? (See page 799.) }</p><p attribs="{'xml:space': 'preserve'}" id="_14249" smilref="Title.smil#_14249"> This constructor builds an NFA corresponding to a given RE by creating a digraph of &#9280;-transitions.</p><p attribs="{'xml:space': 'preserve'}" id="_14250" smilref="Title.smil#_14250" /><pagenum id="p816" page="normal" smilref="Title.smil#p816" /><p attribs="{'xml:space': 'preserve'}" id="_14251" smilref="Title.smil#_14251"> Building the NFA corresponding to ( ( A * B | A C ) D )</p><p attribs="{'xml:space': 'preserve'}" id="_14252" smilref="Title.smil#_14252"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14253" smilref="Title.smil#_14253"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14254" smilref="Title.smil#_14254"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14255" smilref="Title.smil#_14255"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14256" smilref="Title.smil#_14256"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14257" smilref="Title.smil#_14257"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14258" smilref="Title.smil#_14258"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14259" smilref="Title.smil#_14259"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14260" smilref="Title.smil#_14260"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14261" smilref="Title.smil#_14261"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14262" smilref="Title.smil#_14262"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14263" smilref="Title.smil#_14263"> 0 1 2 3 4 5 6 7 8 9 10 11</p><p attribs="{'xml:space': 'preserve'}" id="_14264" smilref="Title.smil#_14264"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14265" smilref="Title.smil#_14265"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14266" smilref="Title.smil#_14266"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14267" smilref="Title.smil#_14267"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14268" smilref="Title.smil#_14268"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14269" smilref="Title.smil#_14269"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14270" smilref="Title.smil#_14270"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14271" smilref="Title.smil#_14271"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14272" smilref="Title.smil#_14272"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14273" smilref="Title.smil#_14273"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14274" smilref="Title.smil#_14274"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14275" smilref="Title.smil#_14275"> 0 1 2 3 4 5 6 7 8 9 10</p><p attribs="{'xml:space': 'preserve'}" id="_14276" smilref="Title.smil#_14276"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14277" smilref="Title.smil#_14277"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14278" smilref="Title.smil#_14278"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14279" smilref="Title.smil#_14279"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14280" smilref="Title.smil#_14280"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14281" smilref="Title.smil#_14281"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14282" smilref="Title.smil#_14282"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14283" smilref="Title.smil#_14283"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14284" smilref="Title.smil#_14284"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14285" smilref="Title.smil#_14285"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14286" smilref="Title.smil#_14286"> 0 1 2 3 4 5 6 7 8 9</p><p attribs="{'xml:space': 'preserve'}" id="_14287" smilref="Title.smil#_14287"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14288" smilref="Title.smil#_14288"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14289" smilref="Title.smil#_14289"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14290" smilref="Title.smil#_14290"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14291" smilref="Title.smil#_14291"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14292" smilref="Title.smil#_14292"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14293" smilref="Title.smil#_14293"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14294" smilref="Title.smil#_14294"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14295" smilref="Title.smil#_14295"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14296" smilref="Title.smil#_14296"> 0 1 2 3 4 5 6 7 8</p><p attribs="{'xml:space': 'preserve'}" id="_14297" smilref="Title.smil#_14297"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14298" smilref="Title.smil#_14298"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14299" smilref="Title.smil#_14299"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14300" smilref="Title.smil#_14300"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14301" smilref="Title.smil#_14301"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14302" smilref="Title.smil#_14302"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14303" smilref="Title.smil#_14303"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14304" smilref="Title.smil#_14304"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14305" smilref="Title.smil#_14305"> 0 1 2 3 4 5 6 7</p><p attribs="{'xml:space': 'preserve'}" id="_14306" smilref="Title.smil#_14306"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14307" smilref="Title.smil#_14307"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14308" smilref="Title.smil#_14308"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14309" smilref="Title.smil#_14309"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14310" smilref="Title.smil#_14310"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14311" smilref="Title.smil#_14311"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14312" smilref="Title.smil#_14312"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14313" smilref="Title.smil#_14313"> 0 1 2 3 4 5 6</p><p attribs="{'xml:space': 'preserve'}" id="_14314" smilref="Title.smil#_14314"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14315" smilref="Title.smil#_14315"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14316" smilref="Title.smil#_14316"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14317" smilref="Title.smil#_14317"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14318" smilref="Title.smil#_14318"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14319" smilref="Title.smil#_14319"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14320" smilref="Title.smil#_14320"> 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_14321" smilref="Title.smil#_14321"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14322" smilref="Title.smil#_14322"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14323" smilref="Title.smil#_14323"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14324" smilref="Title.smil#_14324"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14325" smilref="Title.smil#_14325"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14326" smilref="Title.smil#_14326"> 0 1 2 3 4</p><p attribs="{'xml:space': 'preserve'}" id="_14327" smilref="Title.smil#_14327"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14328" smilref="Title.smil#_14328"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14329" smilref="Title.smil#_14329"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14330" smilref="Title.smil#_14330"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14331" smilref="Title.smil#_14331"> 0 1 2 3</p><p attribs="{'xml:space': 'preserve'}" id="_14332" smilref="Title.smil#_14332"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14333" smilref="Title.smil#_14333"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14334" smilref="Title.smil#_14334"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14335" smilref="Title.smil#_14335"> 0 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_14336" smilref="Title.smil#_14336"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14337" smilref="Title.smil#_14337"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14338" smilref="Title.smil#_14338"> 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_14339" smilref="Title.smil#_14339"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14340" smilref="Title.smil#_14340"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_14341" smilref="Title.smil#_14341"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_14342" smilref="Title.smil#_14342"> stack for indices of left parentheses and ors</p><p attribs="{'xml:space': 'preserve'}" id="_14343" smilref="Title.smil#_14343"> (ops)</p><p attribs="{'xml:space': 'preserve'}" id="_14344" smilref="Title.smil#_14344"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14345" smilref="Title.smil#_14345"> 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14346" smilref="Title.smil#_14346"> 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14347" smilref="Title.smil#_14347"> 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14348" smilref="Title.smil#_14348"> 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14349" smilref="Title.smil#_14349"> 5 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14350" smilref="Title.smil#_14350"> 5 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14351" smilref="Title.smil#_14351"> 5 1 0</p><p attribs="{'xml:space': 'preserve'}" id="_14352" smilref="Title.smil#_14352"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_14353" smilref="Title.smil#_14353"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_14354" smilref="Title.smil#_14354"> 803</p><p attribs="{'xml:space': 'preserve'}" id="_14355" smilref="Title.smil#_14355"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14356" smilref="Title.smil#_14356" /><pagenum id="p817" page="normal" smilref="Title.smil#p817" /><p attribs="{'xml:space': 'preserve'}" id="_14357" smilref="Title.smil#_14357"> 804</p><p attribs="{'xml:space': 'preserve'}" id="_14358" smilref="Title.smil#_14358"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14359" smilref="Title.smil#_14359"> Proposition R. Building the NFA corresponding to an M-character RE takes time and space proportional to M in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_14360" smilref="Title.smil#_14360"> Proof. For each of the M RE characters in the regular expression, we add at most three &#9280;-transitions and perhaps execute one or two stack operations.</p><p attribs="{'xml:space': 'preserve'}" id="_14361" smilref="Title.smil#_14361"> The classic GREP client for pattern matching, illustrated in the code at left, takes an RE as argument and prints the lines from standard input having some substring that is in the language described by the RE. This client was a feature in the early implementations of Unix and has been an indispensable tool for generations of programmers.</p><p attribs="{'xml:space': 'preserve'}" id="_14362" smilref="Title.smil#_14362"> public class GREP { public static void main(String[] args) { String regexp = "(.*" + args[0] + ".*)"; NFA nfa = new NFA(regexp); while (StdIn.hasNextLine()) { String txt = StdIn.hasNextLine(); if (nfa.recognizes(txt)) StdOut.println(txt); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_14363" smilref="Title.smil#_14363"> Classic Generalized Regular Expression Pattern-matching NFA client</p><p attribs="{'xml:space': 'preserve'}" id="_14364" smilref="Title.smil#_14364"> % more tinyL.txt AC AD AAA ABD ADD BCD ABCCBD BABAAA BABBAAA</p><p attribs="{'xml:space': 'preserve'}" id="_14365" smilref="Title.smil#_14365"> % java GREP "(A*B|AC)D" &lt; tinyL.txt ABD ABCCBD</p><p attribs="{'xml:space': 'preserve'}" id="_14366" smilref="Title.smil#_14366"> % java GREP StdIn &lt; GREP.java while (StdIn.hasNextLine()) String txt = StdIn.hasNextLine();</p><p attribs="{'xml:space': 'preserve'}" id="_14367" smilref="Title.smil#_14367" /><pagenum id="p818" page="normal" smilref="Title.smil#p818" /><p attribs="{'xml:space': 'preserve'}" id="_14368" smilref="Title.smil#_14368"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14369" smilref="Title.smil#_14369"> 805</p><p attribs="{'xml:space': 'preserve'}" id="_14370" smilref="Title.smil#_14370"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_14371" smilref="Title.smil#_14371"> Q. What is the difference between null and &#9280;? A. The former denotes an empty set; the latter denotes an empty string. You can have a set that contains one element, &#9280;, and is therefore not null.</p><p attribs="{'xml:space': 'preserve'}" id="_14372" smilref="Title.smil#_14372" /><pagenum id="p819" page="normal" smilref="Title.smil#p819" /><p attribs="{'xml:space': 'preserve'}" id="_14373" smilref="Title.smil#_14373"> 806</p><p attribs="{'xml:space': 'preserve'}" id="_14374" smilref="Title.smil#_14374"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14375" smilref="Title.smil#_14375"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_14376" smilref="Title.smil#_14376"> 5.4.1 Give regular expressions that describe all strings that contain </p><p attribs="{'xml:space': 'preserve'}" id="_14377" smilref="Title.smil#_14377"> b. A.*A | A c. .*ABBABBA.* d. .* A.*A.*A.*A.*</p><p attribs="{'xml:space': 'preserve'}" id="_14378" smilref="Title.smil#_14378"> 5.4.3 What is the maximum number of different strings that can be described by a regular expression with M or operators and no closure operators (parentheses and concatenation are allowed)? 5.4.4 Draw the NFA corresponding to the pattern ( ( ( A | B ) * | C D * | E F G ) * ) * . 5.4.5 Draw the digraph of &#9280;-transitions for the NFA from Exercise 5.4.4. 5.4.6 Give the sets of states reachable by your NFA from Exercise 5.4.4 after each character match and susbsequent &#9280;-transitions for the input A B B A C E F G E F G C A A B . 5.4.7 Modify the GREP client on page 804 to be a client GREPmatch that encloses the pattern in parentheses but does not add .* before and after the pattern, so that it prints out only those lines that are strings in the language described by the given RE. Give the result of typing each of the following commands:</p><p attribs="{'xml:space': 'preserve'}" id="_14379" smilref="Title.smil#_14379"> a. % java GREPmatch &#8220;(A|B)(C|D)&#8221; &lt; tinyL.txt b. % java GREPmatch &#8220;A(B|C)*D&#8221; &lt; tinyL.txt c. % java GREPmatch &#8220;(A*B|AC)D&#8221; &lt; tinyL.txt</p><p attribs="{'xml:space': 'preserve'}" id="_14380" smilref="Title.smil#_14380"> 5.4.8 Write a regular expression for each of the following sets of binary strings:</p><p attribs="{'xml:space': 'preserve'}" id="_14381" smilref="Title.smil#_14381"> a. Contains at least three consecutive 1s b. Contains the substring 110 c. Contains the substring 1101100 d. Does not contain the substring 110</p><p attribs="{'xml:space': 'preserve'}" id="_14382" smilref="Title.smil#_14382" /><pagenum id="p820" page="normal" smilref="Title.smil#p820" /><p attribs="{'xml:space': 'preserve'}" id="_14383" smilref="Title.smil#_14383"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14384" smilref="Title.smil#_14384"> 807</p><p attribs="{'xml:space': 'preserve'}" id="_14385" smilref="Title.smil#_14385"> 5.4.9 Write a regular expression for binary strings with at least two 0s but not consecutive 0s. 5.4.10 Write a regular expression for each of the following sets of binary strings:</p><p attribs="{'xml:space': 'preserve'}" id="_14386" smilref="Title.smil#_14386"> a. Has at least 3 characters, and the third character is 0 b. Number of 0s is a multiple of 3 c. Starts and ends with the same character d. Odd length e. Starts with 0 and has odd length, or starts with 1 and has even length f. Length is at least 1 and at most 3</p><p attribs="{'xml:space': 'preserve'}" id="_14387" smilref="Title.smil#_14387"> 5.4.11 For each of the following regular expressions, indicate how many bitstrings of length exactly 1,000 match:</p><p attribs="{'xml:space': 'preserve'}" id="_14388" smilref="Title.smil#_14388"> a. 0(0 | 1)*1 b. 0*101* c. (1 | 01)*</p><p attribs="{'xml:space': 'preserve'}" id="_14389" smilref="Title.smil#_14389"> 5.4.12 Write a Java regular expression for each of the following:</p><p attribs="{'xml:space': 'preserve'}" id="_14390" smilref="Title.smil#_14390"> a. Phone numbers, such as (609) 555-1234 b. Social Security numbers, such as 123-45-6789 c. Dates, such as December 31, 1999 d. IP addresses of the form a.b.c.d where each letter can represent one, two, or three digits, such as 196.26.155.241 e. License plates that start with four digits and end with two uppercase letters</p><p attribs="{'xml:space': 'preserve'}" id="_14391" smilref="Title.smil#_14391" /><pagenum id="p821" page="normal" smilref="Title.smil#p821" /><p attribs="{'xml:space': 'preserve'}" id="_14392" smilref="Title.smil#_14392"> 808</p><p attribs="{'xml:space': 'preserve'}" id="_14393" smilref="Title.smil#_14393"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14394" smilref="Title.smil#_14394"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_14395" smilref="Title.smil#_14395"> 5.4.13 Challenging REs. Construct an RE that describes each of the following sets of strings over the binary alphabet: a. All strings except 11 or 111 b. Strings with 1 in every odd-number bit position c. Strings with at least two 0s and at most one 1 d. Strings with no two consecutive 1s</p><p attribs="{'xml:space': 'preserve'}" id="_14396" smilref="Title.smil#_14396"> 5.4.14 Binary divisibility. Construct an RE that describes all binary strings that when interpreted as a binary number are a. Divisible by 2 b. Divisible by 3 c. Divisible by 123</p><p attribs="{'xml:space': 'preserve'}" id="_14397" smilref="Title.smil#_14397"> 5.4.15 One-level REs. Construct a Java RE that describes the set of strings that are legal REs over the binary alphabet, but with no occurrence of parentheses within pa- rentheses. For example, (0.*1)* or (1.*0)* is in this language, but (1(0 or 1)1)* is not. 5.4.16 Multiway or. Add multiway or to NFA. Your code should produce the machine drawn below for the pattern ( . * A B ( ( C | D | E ) F ) * G ) .</p><p attribs="{'xml:space': 'preserve'}" id="_14398" smilref="Title.smil#_14398"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</p><p attribs="{'xml:space': 'preserve'}" id="_14399" smilref="Title.smil#_14399"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14400" smilref="Title.smil#_14400"> .</p><p attribs="{'xml:space': 'preserve'}" id="_14401" smilref="Title.smil#_14401"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14402" smilref="Title.smil#_14402"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14403" smilref="Title.smil#_14403"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14404" smilref="Title.smil#_14404"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14405" smilref="Title.smil#_14405"> (</p><p attribs="{'xml:space': 'preserve'}" id="_14406" smilref="Title.smil#_14406"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14407" smilref="Title.smil#_14407"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14408" smilref="Title.smil#_14408"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14409" smilref="Title.smil#_14409"> |</p><p attribs="{'xml:space': 'preserve'}" id="_14410" smilref="Title.smil#_14410"> E</p><p attribs="{'xml:space': 'preserve'}" id="_14411" smilref="Title.smil#_14411"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14412" smilref="Title.smil#_14412"> F</p><p attribs="{'xml:space': 'preserve'}" id="_14413" smilref="Title.smil#_14413"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14414" smilref="Title.smil#_14414"> *</p><p attribs="{'xml:space': 'preserve'}" id="_14415" smilref="Title.smil#_14415"> G</p><p attribs="{'xml:space': 'preserve'}" id="_14416" smilref="Title.smil#_14416"> )</p><p attribs="{'xml:space': 'preserve'}" id="_14417" smilref="Title.smil#_14417"> NFA corresponding to the pattern ( . * A B ( ( C | D | E ) F ) * G )</p><p attribs="{'xml:space': 'preserve'}" id="_14418" smilref="Title.smil#_14418" /><pagenum id="p822" page="normal" smilref="Title.smil#p822" /><p attribs="{'xml:space': 'preserve'}" id="_14419" smilref="Title.smil#_14419"> 5.4 </p><p attribs="{'xml:space': 'preserve'}" id="_14420" smilref="Title.smil#_14420"> 809</p><p attribs="{'xml:space': 'preserve'}" id="_14421" smilref="Title.smil#_14421"> 5.4.17 Wildcard. Add to NFA the capability to handle wildcards. 5.4.18 One or more. Add to NFA the capability to handle the + closure operator. 5.4.19 Speci&#64257; ed set. Add to NFA the capability to handle speci&#64257; ed-set descriptors. 5.4.20 Range. Add to NFA the capability to handle range descriptors. 5.4.21 Complement. Add to NFA the capability to handle complement descriptors. 5.4.22 Proof. Develop a version of NFA that prints a proof that a given string is in the language recognized by the NFA (a sequence of state transitions that ends in the accept state).</p><p attribs="{'xml:space': 'preserve'}" id="_14422" smilref="Title.smil#_14422" /></level3><level3 id="_00113"><h3 id="ch5-s5-ss17" smilref="Title.smil#ch5-s5-ss17" xml:space="preserve">Rules of the game</h3><pagenum id="p824" page="normal" smilref="Title.smil#p824" /><p attribs="{'xml:space': 'preserve'}" id="_14423" smilref="Title.smil#_14423"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14424" smilref="Title.smil#_14424"> 811</p><p attribs="{'xml:space': 'preserve'}" id="_14425" smilref="Title.smil#_14425"> Rules of the game All of the types of data that we process with modern computer systems have something in common: they are ultimately represented in binary. We can consider each of them to be simply a sequence of bits (or bytes). For brevity, we use the term bitstream in this section to refer to a sequence of bits and bytestream when we are referring to the bits being considered as a sequence of fi xed-size bytes. A bitstream or a bytestream might be stored as a file on your computer, or it might be a message being transmitted on the internet.</p><p attribs="{'xml:space': 'preserve'}" id="_14426" smilref="Title.smil#_14426"> Basic model. Accordingly, our basic model for data compression is quite simple, having two primary components, each a black box that reads and writes bitstreams: </p><p attribs="{'xml:space': 'preserve'}" id="_14427" smilref="Title.smil#_14427"> Compress</p><p attribs="{'xml:space': 'preserve'}" id="_14428" smilref="Title.smil#_14428"> Expand</p><p attribs="{'xml:space': 'preserve'}" id="_14429" smilref="Title.smil#_14429"> bitstream B 0110110101...</p><p attribs="{'xml:space': 'preserve'}" id="_14430" smilref="Title.smil#_14430"> compressed version C(B) 1101011111...</p><p attribs="{'xml:space': 'preserve'}" id="_14431" smilref="Title.smil#_14431"> original bitstream B 0110110101...</p><p attribs="{'xml:space': 'preserve'}" id="_14432" smilref="Title.smil#_14432"> Basic model for data compression</p><p attribs="{'xml:space': 'preserve'}" id="_14433" smilref="Title.smil#_14433"> This model is known as lossless compression&#8212;we insist that no information be lost, in the specific sense that the result of compressing and expanding a bitstream must match the original, bit for bit. Lossless compression is required for many types of fi les, such as numerical data or executable code. For some types of files (such as images, videos, or music), it is reasonable to consider compression methods that are allowed to lose some information, so the decoder only produces an approximation of the original fi le. Lossy methods have to be evaluated in terms of a subjective quality standard in addition to the compression ratio.We do not address lossy compression in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_14434" smilref="Title.smil#_14434"> Reading and writing binary data A full description of how information is encoded on your computer is system-dependent and is beyond our scope, but with a few basic assumptions and two simple APIs, we can separate our implementations from these details. These APIs, BinaryStdIn and BinaryStdOut, are modeled on the StdIn and StdOut APIs that you have been using, but their purpose is to read and write bits, where StdIn and StdOut are oriented toward character streams encoded in Unicode. An int value on StdOut is a sequence of characters (its decimal representation); an int value on BinaryStdOut is a sequence of bits (its binary representation).</p><p attribs="{'xml:space': 'preserve'}" id="_14435" smilref="Title.smil#_14435" /></level3><level3 id="_00114"><h3 id="ch5-s5-ss18" smilref="Title.smil#ch5-s5-ss18" xml:space="preserve">Reading and writing binary data</h3><p attribs="{'xml:space': 'preserve'}" id="_14436" smilref="Title.smil#_14436" /><p attribs="{'xml:space': 'preserve'}" id="_14437" smilref="Title.smil#_14437"> 811</p><p attribs="{'xml:space': 'preserve'}" id="_14438" smilref="Title.smil#_14438"> Rules of the game All of the types of data that we process with modern computer systems have something in common: they are ultimately represented in binary. We can consider each of them to be simply a sequence of bits (or bytes). For brevity, we use the term bitstream in this section to refer to a sequence of bits and bytestream when we are referring to the bits being considered as a sequence of fi xed-size bytes. A bitstream or a bytestream might be stored as a file on your computer, or it might be a message being transmitted on the internet.</p><p attribs="{'xml:space': 'preserve'}" id="_14439" smilref="Title.smil#_14439"> Basic model. Accordingly, our basic model for data compression is quite simple, having two primary components, each a black box that reads and writes bitstreams: </p><p attribs="{'xml:space': 'preserve'}" id="_14440" smilref="Title.smil#_14440"> Compress</p><p attribs="{'xml:space': 'preserve'}" id="_14441" smilref="Title.smil#_14441"> Expand</p><p attribs="{'xml:space': 'preserve'}" id="_14442" smilref="Title.smil#_14442"> bitstream B 0110110101...</p><p attribs="{'xml:space': 'preserve'}" id="_14443" smilref="Title.smil#_14443"> compressed version C(B) 1101011111...</p><p attribs="{'xml:space': 'preserve'}" id="_14444" smilref="Title.smil#_14444"> original bitstream B 0110110101...</p><p attribs="{'xml:space': 'preserve'}" id="_14445" smilref="Title.smil#_14445"> Basic model for data compression</p><p attribs="{'xml:space': 'preserve'}" id="_14446" smilref="Title.smil#_14446"> This model is known as lossless compression&#8212;we insist that no information be lost, in the specific sense that the result of compressing and expanding a bitstream must match the original, bit for bit. Lossless compression is required for many types of fi les, such as numerical data or executable code. For some types of files (such as images, videos, or music), it is reasonable to consider compression methods that are allowed to lose some information, so the decoder only produces an approximation of the original fi le. Lossy methods have to be evaluated in terms of a subjective quality standard in addition to the compression ratio.We do not address lossy compression in this book.</p><p attribs="{'xml:space': 'preserve'}" id="_14447" smilref="Title.smil#_14447"> Reading and writing binary data A full description of how information is encoded on your computer is system-dependent and is beyond our scope, but with a few basic assumptions and two simple APIs, we can separate our implementations from these details. These APIs, BinaryStdIn and BinaryStdOut, are modeled on the StdIn and StdOut APIs that you have been using, but their purpose is to read and write bits, where StdIn and StdOut are oriented toward character streams encoded in Unicode. An int value on StdOut is a sequence of characters (its decimal representation); an int value on BinaryStdOut is a sequence of bits (its binary representation).</p><p attribs="{'xml:space': 'preserve'}" id="_14448" smilref="Title.smil#_14448" /><p attribs="{'xml:space': 'preserve'}" id="_14449" smilref="Title.smil#_14449"> 812</p><p attribs="{'xml:space': 'preserve'}" id="_14450" smilref="Title.smil#_14450"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14451" smilref="Title.smil#_14451"> Binary input and output. Most systems nowadays, including Java, base their I/O on 8-bit bytestreams, so we might decide to read and write bytestreams to match I/O formats with the internal representations of primitive types, encoding an 8-bit char with 1 byte, a 16-bit short with 2 bytes, a 32-bit int with 4 bytes, and so forth. Since bit- streams are the primary abstraction for data compression, we go a bit further to allow clients to read and write individual bits, intermixed with data of primitive types. The goal is to minimize the necessity for type conversion in client programs and also to take care of operating system conventions for representing data. We use the following API for reading a bitstream from standard input:</p><p attribs="{'xml:space': 'preserve'}" id="_14452" smilref="Title.smil#_14452"> public class BinaryStdIn</p><p attribs="{'xml:space': 'preserve'}" id="_14453" smilref="Title.smil#_14453"> boolean readBoolean()</p><p attribs="{'xml:space': 'preserve'}" id="_14454" smilref="Title.smil#_14454"> char readChar()</p><p attribs="{'xml:space': 'preserve'}" id="_14455" smilref="Title.smil#_14455"> char readChar(int r)</p><p attribs="{'xml:space': 'preserve'}" id="_14456" smilref="Title.smil#_14456"> read 1 bit of data and return as a boolean value read 8 bits of data and return as a char value read r (between 1 and 16) bits of data and return as a char value [similar methods for byte (8 bits); short (16 bits); int (32 bits); long and double (64 bits)] is the bitstream empty? close the bitstream</p><p attribs="{'xml:space': 'preserve'}" id="_14457" smilref="Title.smil#_14457"> boolean isEmpty()</p><p attribs="{'xml:space': 'preserve'}" id="_14458" smilref="Title.smil#_14458"> void close()</p><p attribs="{'xml:space': 'preserve'}" id="_14459" smilref="Title.smil#_14459"> API for static methods that read from a bitstream on standard input</p><p attribs="{'xml:space': 'preserve'}" id="_14460" smilref="Title.smil#_14460"> A key feature of the abstraction is that, in marked constrast to StdIn, the data on standard input is not necessarily aligned on byte boundaries. If the input stream is a single byte, a client could read it 1 bit at a time with eight calls to readBoolean(). The close() method is not essential, but, for clean termination, clients should call close() to indicate that no more bits are to be read. As with StdIn/StdOut, we use the following complementary API for writing bitstreams to standard output:</p><p attribs="{'xml:space': 'preserve'}" id="_14461" smilref="Title.smil#_14461"> public class BinaryStdOut</p><p attribs="{'xml:space': 'preserve'}" id="_14462" smilref="Title.smil#_14462"> void write(char c)</p><p attribs="{'xml:space': 'preserve'}" id="_14463" smilref="Title.smil#_14463"> void write(boolean b)</p><p attribs="{'xml:space': 'preserve'}" id="_14464" smilref="Title.smil#_14464"> write the specified  bit write the specified  8-bit char void write(char c, int r) write the r (between 1 and 16) least significant  bits of the specified  char [similar methods for byte (8 bits); short (16 bits); int (32 bits); long and double (64 bits)] close the bitstream</p><p attribs="{'xml:space': 'preserve'}" id="_14465" smilref="Title.smil#_14465"> void close()</p><p attribs="{'xml:space': 'preserve'}" id="_14466" smilref="Title.smil#_14466"> API for static methods that write to a bitstream on standard output</p><p attribs="{'xml:space': 'preserve'}" id="_14467" smilref="Title.smil#_14467" /><p attribs="{'xml:space': 'preserve'}" id="_14468" smilref="Title.smil#_14468"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14469" smilref="Title.smil#_14469"> 813</p><p attribs="{'xml:space': 'preserve'}" id="_14470" smilref="Title.smil#_14470"> For output, the close() method is essential: clients must call close() to ensure that all of the bits specified in prior write() calls make it to the bitstream and that the final byte is padded with 0s to byte-align the output for compatibility with the file system. As with the In and Out APIs associated with StdIn and StdOut, we also have available BinaryIn and BinaryOut that allows us to reference binary-encoded files directly.</p><p attribs="{'xml:space': 'preserve'}" id="_14471" smilref="Title.smil#_14471"> Example. As a simple example, suppose that you have a data type where a date is represented as three int values (month, day, year). Using StdOut to write those values in the format 12/31/1999 requires 10 characters, or 80 bits. If you write the values directly with BinaryStdOut, you would produce 96 bits (32 bits for each of the 3 int values); if you use a more economical representation that uses byte values for the month and day and a short value for the year, you would produce 32 bits. With BinaryStdOut you could also write a 4-bit fi eld, a 5-bit fi eld, and a 12-bit fi eld, for a total of 21 bits (24 bits, actually, because files must be an integral number of 8-bit bytes, so close() adds three 0 bits at the end). Important note: Such economy, in itself, is a crude form of data compression.</p><p attribs="{'xml:space': 'preserve'}" id="_14472" smilref="Title.smil#_14472"> Binary dumps. How can we examine the contents of a bitstream or a bytestream while debugging? This question faced early programmers when the only way to find a bug was to examine each of the bits in memory, and the term dump has been used since the early days of computing to describe a human-readable view of a bitstream. If you try to open</p><p attribs="{'xml:space': 'preserve'}" id="_14473" smilref="Title.smil#_14473"> a character stream (StdOut)</p><p attribs="{'xml:space': 'preserve'}" id="_14474" smilref="Title.smil#_14474"> StdOut.print(month + "/" + day + "/" + year);</p><p attribs="{'xml:space': 'preserve'}" id="_14475" smilref="Title.smil#_14475"> 0 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_14476" smilref="Title.smil#_14476"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_14477" smilref="Title.smil#_14477"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_14478" smilref="Title.smil#_14478"> /</p><p attribs="{'xml:space': 'preserve'}" id="_14479" smilref="Title.smil#_14479"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_14480" smilref="Title.smil#_14480"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_14481" smilref="Title.smil#_14481"> /</p><p attribs="{'xml:space': 'preserve'}" id="_14482" smilref="Title.smil#_14482"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_14483" smilref="Title.smil#_14483"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_14484" smilref="Title.smil#_14484"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_14485" smilref="Title.smil#_14485"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_14486" smilref="Title.smil#_14486"> 80 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14487" smilref="Title.smil#_14487"> three ints (BinaryStdOut)</p><p attribs="{'xml:space': 'preserve'}" id="_14488" smilref="Title.smil#_14488"> 8-bit ASCII representation of '9'</p><p attribs="{'xml:space': 'preserve'}" id="_14489" smilref="Title.smil#_14489"> BinaryStdOut.write(month); BinaryStdOut.write(day); BinaryStdOut.write(year);</p><p attribs="{'xml:space': 'preserve'}" id="_14490" smilref="Title.smil#_14490"> 32-bit integer representation of 31</p><p attribs="{'xml:space': 'preserve'}" id="_14491" smilref="Title.smil#_14491"> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_14492" smilref="Title.smil#_14492"> 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_14493" smilref="Title.smil#_14493"> 3 1</p><p attribs="{'xml:space': 'preserve'}" id="_14494" smilref="Title.smil#_14494"> 1 9 9 9</p><p attribs="{'xml:space': 'preserve'}" id="_14495" smilref="Title.smil#_14495"> 96 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14496" smilref="Title.smil#_14496"> two chars and a short (BinaryStdOut)</p><p attribs="{'xml:space': 'preserve'}" id="_14497" smilref="Title.smil#_14497"> a 4-bit field, a 5-bit field, and a 12-bit field (BinaryStdOut)</p><p attribs="{'xml:space': 'preserve'}" id="_14498" smilref="Title.smil#_14498"> BinaryStdOut.write((char) month); BinaryStdOut.write((char) day); BinaryStdOut.write((short) year);</p><p attribs="{'xml:space': 'preserve'}" id="_14499" smilref="Title.smil#_14499"> BinaryStdOut.write(month, 4); BinaryStdOut.write(day, 5); BinaryStdOut.write(year, 12);</p><p attribs="{'xml:space': 'preserve'}" id="_14500" smilref="Title.smil#_14500"> 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_14501" smilref="Title.smil#_14501"> 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_14502" smilref="Title.smil#_14502"> 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_14503" smilref="Title.smil#_14503"> 3 1</p><p attribs="{'xml:space': 'preserve'}" id="_14504" smilref="Title.smil#_14504"> 1 9 9 9</p><p attribs="{'xml:space': 'preserve'}" id="_14505" smilref="Title.smil#_14505"> 32 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14506" smilref="Title.smil#_14506"> 1 2</p><p attribs="{'xml:space': 'preserve'}" id="_14507" smilref="Title.smil#_14507"> 3 1</p><p attribs="{'xml:space': 'preserve'}" id="_14508" smilref="Title.smil#_14508"> 1 9 9 9</p><p attribs="{'xml:space': 'preserve'}" id="_14509" smilref="Title.smil#_14509"> 21 bits ( + 3 bits for byte alignment at close)</p><p attribs="{'xml:space': 'preserve'}" id="_14510" smilref="Title.smil#_14510"> Four ways to put a date onto standard output</p><p attribs="{'xml:space': 'preserve'}" id="_14511" smilref="Title.smil#_14511" /><p attribs="{'xml:space': 'preserve'}" id="_14512" smilref="Title.smil#_14512"> 814</p><p attribs="{'xml:space': 'preserve'}" id="_14513" smilref="Title.smil#_14513"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14514" smilref="Title.smil#_14514"> public class BinaryDump { public static void main(String[] args) { int width = Integer.parseInt(args[0]); int cnt; for (cnt = 0; !BinaryStdIn.isEmpty(); cnt++) { if (width == 0) continue; if (cnt != 0 &amp;&amp; cnt % width == 0) StdOut.println(); if (BinaryStdIn.readBoolean()) StdOut.print("1"); else StdOut.print("0"); } StdOut.println(); StdOut.println(cnt + " bits"); } }</p><p attribs="{'xml:space': 'preserve'}" id="_14515" smilref="Title.smil#_14515"> a file with an editor or view it in the manner in which you view text files (or just run a program that uses BinaryStdOut), you are likely to see gibberish, depending on the system you use. BinaryStdIn allows us to avoid such system dependencies by writing our own programs to convert bitstreams such that we can see them with our standard tools. For example, the program BinaryDump at left is a BinaryStdIn client that prints out the bits from standard in- put, encoded with the characters 0 and 1. This program is useful for debugging when working with small inputs. The similar client HexDump groups the data into 8-bit bytes and prints each as two hexadecimal digits that each represent 4 bits. The client PictureDump displays the bits in a Picture with 0 bits represented as white pixels and 1 bits represented as black pixels. This pictorial representation is often useful in identifying patterns in a bitstream. You can download BinaryDump, HexDump, and PictureDump from the booksite. Typically, we use piping and redirection at the command-line level when working with binary fi les: we can pipe the output of an encoder to BinaryDump, HexDump, or PictureDump, or redirect it to a fi le.</p><p attribs="{'xml:space': 'preserve'}" id="_14516" smilref="Title.smil#_14516"> Printing a bitstream on standard (character) output</p><p attribs="{'xml:space': 'preserve'}" id="_14517" smilref="Title.smil#_14517"> standard character stream</p><p attribs="{'xml:space': 'preserve'}" id="_14518" smilref="Title.smil#_14518"> % more abra.txt ABRACADABRA!</p><p attribs="{'xml:space': 'preserve'}" id="_14519" smilref="Title.smil#_14519"> bitstream represented as 0 and 1 characters</p><p attribs="{'xml:space': 'preserve'}" id="_14520" smilref="Title.smil#_14520"> % java BinaryDump 16 &lt; abra.txt 0100000101000010 0101001001000001 0100001101000001 0100010001000001 0100001001010010 0100000100100001 96 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14521" smilref="Title.smil#_14521"> bitstream represented with hex digits</p><p attribs="{'xml:space': 'preserve'}" id="_14522" smilref="Title.smil#_14522"> % java HexDump 4 &lt; abra.txt 41 42 52 41 43 41 44 41 42 52 41 21 96 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14523" smilref="Title.smil#_14523"> bitstream represented as pixels in a Picture</p><p attribs="{'xml:space': 'preserve'}" id="_14524" smilref="Title.smil#_14524"> % java PictureDump 16 6 &lt; abra.txt</p><p attribs="{'xml:space': 'preserve'}" id="_14525" smilref="Title.smil#_14525"> 16-by-6 pixel window, magnified</p><p attribs="{'xml:space': 'preserve'}" id="_14526" smilref="Title.smil#_14526"> 96 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14527" smilref="Title.smil#_14527"> Four ways to look at a bitstream</p><p attribs="{'xml:space': 'preserve'}" id="_14528" smilref="Title.smil#_14528" /><p attribs="{'xml:space': 'preserve'}" id="_14529" smilref="Title.smil#_14529"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14530" smilref="Title.smil#_14530"> 815</p><p attribs="{'xml:space': 'preserve'}" id="_14531" smilref="Title.smil#_14531"> 0 1 2 3 4 5 6 7 8 9 A B C D E F</p><p attribs="{'xml:space': 'preserve'}" id="_14532" smilref="Title.smil#_14532"> 0 NUL SOH STX ETX EOT ENQ ACK BEL BS HT LF VT FF CR SO SI 1 DLE DC1 DC2 DC3 DC4 NAK SYN ETB CAN EM SUB ESC FS GS RS US</p><p attribs="{'xml:space': 'preserve'}" id="_14533" smilref="Title.smil#_14533"> ASCII encoding. When you HexDump a bit- stream that contains ASCII-encoded charac- ters, the table at right is useful for reference. Given a two digit hex number, use the first hex digit as a row index and the second hex digit as a column index to find the character that it encodes. For example, 31 encodes the digit 1, 4A encodes the letter J, and so forth. This table is for 7-bit ASCII, so the first hex digit must be 7 or less. Hex numbers starting with 0 and 1 (and the numbers 20 and 7F) correspond to non-printing control charac- ters. Many of the control characters are left over from the days when physical devices such as typewriters were controlled by ASCII input; the table highlights a few that you might see in dumps. For example, SP is the space character, NUL is the null character, LF is line feed, and CR is carriage return.</p><p attribs="{'xml:space': 'preserve'}" id="_14534" smilref="Title.smil#_14534"> 2 SP ! " # $ % &amp; &#8216; ( ) * + , - . / 3 0 1 2 3 4 5 6 7 8 9 : ; &lt; = &gt; ? 4 @ A B C D E F G H I J K L M N O 5 P Q R S T U V W X Y Z [ \ ] ^ _ 6 ` a b c d e f g h i j k l m n o 7 p q r s t u v w x y z { | } ~ DEL</p><p attribs="{'xml:space': 'preserve'}" id="_14535" smilref="Title.smil#_14535"> Hexadecimal-to-ASCII conversion table</p><p attribs="{'xml:space': 'preserve'}" id="_14536" smilref="Title.smil#_14536"> In summary, working with data compression requires us to reorient our thinking about standard input and standard output to include binary encoding of data. BinaryStdIn and BinaryStdOut provide the methods that we need. They provide a way for you to make a clear distinction in your client programs between writing out information intended for file storage and data transmission (that will be read by programs) and printing information (that is likely to be read by humans).</p><p attribs="{'xml:space': 'preserve'}" id="_14537" smilref="Title.smil#_14537" /></level3><level3 id="_00115"><h3 id="ch5-s5-ss19" smilref="Title.smil#ch5-s5-ss19" xml:space="preserve">Limitations</h3><pagenum id="p829" page="normal" smilref="Title.smil#p829" /><p attribs="{'xml:space': 'preserve'}" id="_14538" smilref="Title.smil#_14538"> 816</p><p attribs="{'xml:space': 'preserve'}" id="_14539" smilref="Title.smil#_14539"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14540" smilref="Title.smil#_14540"> Limitations To appreciate data-compression algorithms, you need to understand fundamental limitations. Researchers have developed a thorough and important theoretical basis for this purpose, which we will consider briefly at the end of this section, but a few ideas will help us get started.</p><p attribs="{'xml:space': 'preserve'}" id="_14541" smilref="Title.smil#_14541"> Universal data compression. Armed with the algorithmic tools that have proven so useful for so many problems, you might think that our goal should be universal data compression: an algorithm that can make any bitstream smaller. Quite to the contrary, we have to adopt more modest goals because universal data compression is impossible.</p><p attribs="{'xml:space': 'preserve'}" id="_14542" smilref="Title.smil#_14542"> Proposition S. No algorithm can compress every bitstream.</p><p attribs="{'xml:space': 'preserve'}" id="_14543" smilref="Title.smil#_14543"> Proof : We consider two proofs that each provide some insight. The first is by contradiction: Suppose that you have an algorithm that does compress every bitstream. Then you could use that algorithm to compress its output to get a still shorter bitstream, and continue until you have a bistream of length 0! The conclusion that your algorithm compresses every bitstream to 0 bits is absurd, and so is the assumption that it can compress every bitstream. The second proof is a counting argument. Suppose that you have an algorithm that claims lossless compression for every 1,000-bit stream. That is, every such stream must map to a different shorter one. But there are only 1 + 2 + 4 + ... + 2998 + 2999 = 21000&#11002;1 bit- streams with fewer than 1,000 bits and 21000 bitstreams with 1,000 bits, so your algorithm cannot compress all of them. This argument becomes more persuasive if we consider stronger claims. Say your goal is to achieve better than a 50 percent compression ratio. You have to know that you will be successful for only about 1 out of 2500 of the 1,000-bit bitstreams!</p><p attribs="{'xml:space': 'preserve'}" id="_14544" smilref="Title.smil#_14544"> Put another way, you have at most a 1 in 2500 chance of being able to compress by half a random 1,000-bit stream with any data-compres- sion algorithm. When you run across a new lossless compression al- gorithm, it is a sure bet that it will not achieve significant compression for a random bitstream. The insight that we cannot hope to compress random streams is a start to understanding data compression. We regularly process strings of millions or billions of bits but will never process even the tiniest fraction of all possible such strings, so we need</p><p attribs="{'xml:space': 'preserve'}" id="_14545" smilref="Title.smil#_14545"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14546" smilref="Title.smil#_14546"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14547" smilref="Title.smil#_14547"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14548" smilref="Title.smil#_14548"> . . .</p><p attribs="{'xml:space': 'preserve'}" id="_14549" smilref="Title.smil#_14549"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14550" smilref="Title.smil#_14550"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14551" smilref="Title.smil#_14551"> U</p><p attribs="{'xml:space': 'preserve'}" id="_14552" smilref="Title.smil#_14552"> &#9280;</p><p attribs="{'xml:space': 'preserve'}" id="_14553" smilref="Title.smil#_14553"> Universal data compression?</p><p attribs="{'xml:space': 'preserve'}" id="_14554" smilref="Title.smil#_14554" /><pagenum id="p830" page="normal" smilref="Title.smil#p830" /><p attribs="{'xml:space': 'preserve'}" id="_14555" smilref="Title.smil#_14555"> % java RandomBits | java PictureDump 2000 500</p><p attribs="{'xml:space': 'preserve'}" id="_14556" smilref="Title.smil#_14556"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14557" smilref="Title.smil#_14557"> 817</p><p attribs="{'xml:space': 'preserve'}" id="_14558" smilref="Title.smil#_14558"> 1000000 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14559" smilref="Title.smil#_14559"> A difficult file to compress: 1 million (pseudo-) random bits</p><p attribs="{'xml:space': 'preserve'}" id="_14560" smilref="Title.smil#_14560"> not be discouraged by this theoretical result. Indeed, the bitstrings that we regularly process are typically highly structured, a fact that we can exploit for compression.</p><p attribs="{'xml:space': 'preserve'}" id="_14561" smilref="Title.smil#_14561"> Undecidability. Consider the million-bit string pictured at the top of this page. This string appears to be random, so you are not likely to find a lossless compression algorithm that will compress it. But there is a way to represent that string with just a few thousand bits, because it was produced by the program below. (This program is an example of a pseudo-random number generator, like Java&#8217;s Math.random() method.) A compression algorithm that compresses by writing the program in ASCII and expands by reading the program and then running it achieves a .3 percent compression ratio, which is difficult to beat (and we can drive the ratio arbitrarily low by writing more bits). To compress such a file is to discover the program that produced it. This example is not so far-fetched as it first appears: when you compress a video or an old book that was digitized with a scanner or any of countless other types of files from the web, you are discovering something about the program that produced the fi le. The realization that much of the data that we process is produced by a program leads to deep issues in the theory of computation and also gives insight into the challenges of data compres- sion. For example, it is possible to prove that optimal data compression (&#64257; nd the shortest program to produce a given string) is an undecidable problem: not only can we not have an algorithm that compresses every bit- stream, but also we cannot have a strategy for developing the best algorithm!</p><p attribs="{'xml:space': 'preserve'}" id="_14562" smilref="Title.smil#_14562"> public class RandomBits { public static void main(String[] args) { int x = 11111; for (int i = 0; i &lt; 1000000; i++) { x = x * 314159 + 218281; BinaryStdOut.write(x &gt; 0); } BinaryStdOut.close(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_14563" smilref="Title.smil#_14563"> A &#8220;compressed&#8221; million-bit stream</p><p attribs="{'xml:space': 'preserve'}" id="_14564" smilref="Title.smil#_14564" /><pagenum id="p831" page="normal" smilref="Title.smil#p831" /><p attribs="{'xml:space': 'preserve'}" id="_14565" smilref="Title.smil#_14565"> 818</p><p attribs="{'xml:space': 'preserve'}" id="_14566" smilref="Title.smil#_14566"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14567" smilref="Title.smil#_14567"> </p><p attribs="{'xml:space': 'preserve'}" id="_14568" smilref="Title.smil#_14568"> </p><p attribs="{'xml:space': 'preserve'}" id="_14569" smilref="Title.smil#_14569"> </p><p attribs="{'xml:space': 'preserve'}" id="_14570" smilref="Title.smil#_14570"> </p><p attribs="{'xml:space': 'preserve'}" id="_14571" smilref="Title.smil#_14571"> The practical impact of these limitations is that lossless compression methods must be oriented toward taking advantage of known structure in the bitstreams to be com- pressed. The four methods that we consider exploit, in turn, the following structural characteristics: Small alphabets Long sequences of identical bits/characters Frequently used characters Long reused bit/character sequences If you know that a given bitstream exhibits one or more of these characteristics, you can compress it with one of the methods that you are about to learn; if not, trying them each is probably still worth the effort, since the underlying structure of your data may not be obvious, and these methods are widely applicable. As you will see, each method has parameters and variations that may need to be tuned for best compression of a particular bitstream. The first and last recourse is to learn something about the structure of your data yourself and exploit that knowledge to compress it, perhaps using one of the techniques we are about to consider.</p><p attribs="{'xml:space': 'preserve'}" id="_14572" smilref="Title.smil#_14572" /><pagenum id="p832" page="normal" smilref="Title.smil#p832" /><p attribs="{'xml:space': 'preserve'}" id="_14573" smilref="Title.smil#_14573"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14574" smilref="Title.smil#_14574"> 819</p><p attribs="{'xml:space': 'preserve'}" id="_14575" smilref="Title.smil#_14575"> Warmup: genomics As preparation for more complicated data-compression al- gorithms, we now consider an elementary (but very important) data-compression task. All of our implementations will use the same conventions that we will now introduce in the context of this example.</p><p attribs="{'xml:space': 'preserve'}" id="_14576" smilref="Title.smil#_14576"> Genomic data. As a first example of data compression, consider this string:</p><p attribs="{'xml:space': 'preserve'}" id="_14577" smilref="Title.smil#_14577"> A T A G A T G C A T A G C G C A T A G C T A G A T G T G C T A G C A T</p><p attribs="{'xml:space': 'preserve'}" id="_14578" smilref="Title.smil#_14578"> Using standard ASCII encoding (1 byte, or 8 bits per character), this string is a bitstream of length 8&#11003;35 = 280. Strings of this sort are extremely important in modern biology, because biologists use the letters A, C, T, and G to represent the four nucleotides in the DNA of living organisms. A genome is a sequence of nucleotides. Scientists know that understanding the properties of genomes is a key to understanding the processes that manifest themselves in living organisms, including life, death, and disease. Genomes for many living things are known, and scientists are writing programs to study the structure of these sequences.</p><p attribs="{'xml:space': 'preserve'}" id="_14579" smilref="Title.smil#_14579"> 2-bit code compression. One simple prop-</p><p attribs="{'xml:space': 'preserve'}" id="_14580" smilref="Title.smil#_14580"> public static void compress() { Alphabet DNA = new Alphabet("ACTG"); String s = BinaryStdIn.readString(); int N = s.length(); BinaryStdOut.write(N); for (int i = 0; i &lt; N; i++) { // Write two-bit code for char. int d = DNA.toIndex(s.charAt(i)); BinaryStdOut.write(d, DNA.lgR()); } BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14581" smilref="Title.smil#_14581"> erty of genomes is that they contain only four different characters, so each can be encoded with just 2 bits per character, as in the compress() method shown at right. Even though we know the input stream to be character-encoded, we use BinaryStdIn to read the input, to emphasize adherence to the standard data-compression model (bitstream to bitstream). We include the number of encoded characters in the compressed fi le, to ensure proper decoding if the last bit does not fall at the end of a byte. Since it converts each 8-bit character to a 2-bit code and just adds 32 bits for the length, this program approaches a 25 percent compression ratio as the number of characters increases.</p><p attribs="{'xml:space': 'preserve'}" id="_14582" smilref="Title.smil#_14582"> Compression method for genomic data</p><p attribs="{'xml:space': 'preserve'}" id="_14583" smilref="Title.smil#_14583"> 2-bit code expansion. The expand() method at the top of the next page expands a bitstream produced by this compress() method. As with compression, this method reads a bitstream and writes a bitstream, in accordance with the basic data-compression model. The bitstream that we produce as output is the original input.</p><p attribs="{'xml:space': 'preserve'}" id="_14584" smilref="Title.smil#_14584" /><pagenum id="p833" page="normal" smilref="Title.smil#p833" /><p attribs="{'xml:space': 'preserve'}" id="_14585" smilref="Title.smil#_14585"> 820</p><p attribs="{'xml:space': 'preserve'}" id="_14586" smilref="Title.smil#_14586"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14587" smilref="Title.smil#_14587"> public static void expand() { Alphabet DNA = new Alphabet("ACTG"); int w = DNA.lgR(); int N = BinaryStdIn.readInt(); for (int i = 0; i &lt; N; i++) { // Read 2 bits; write char. char c = BinaryStdIn.readChar(w); BinaryStdOut.write(DNA.toChar(c)); } BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14588" smilref="Title.smil#_14588"> Expansion method for genomic data</p><p attribs="{'xml:space': 'preserve'}" id="_14589" smilref="Title.smil#_14589"> The same approach works for other fi xed- size alphabets, but we leave this generalization for an (easy) exercise (see Exercise</p><p attribs="{'xml:space': 'preserve'}" id="_14590" smilref="Title.smil#_14590"> 5.5.25).</p><p attribs="{'xml:space': 'preserve'}" id="_14591" smilref="Title.smil#_14591"> These methods do not quite adhere to the standard data-compression model, because the compressed bitstream does not contain all the information needed to decode it. The fact that the alphabet is one of the letters A, C, T, or G is agreed upon by the two meth- ods. Such a convention is reasonable in an application such as genomics, where the same code is widely reused. Other situations might require including the alphabet in the encoded message (see Exercise 5.5.25). The norm in data compression is to include such costs when comparing methods. In the early days of genomics, learning a genomic sequence was a long and arduous task, so sequences were relatively short and scientists used standard ASCII encoding to store and exchange them. The experimental process has been vastly streamlined, to the point where known genomes are numerous and lengthy (the human genome is over 1010 bits), and the 75 percent savings achieved by these simple methods is very signi&#64257; - cant. Is there room for further compression? That is a very interesting question to con- template, because it is a scientific question: the ability to compress implies the existence of some structure in the data, and a prime focus of modern genomics is to discover structure in genomic data. Standard data-compression methods like the ones we will consider are ineffective with (2-bit-encoded) genomic data, as with random data. We package compress() and expand() as static methods in the same class, along with a simple driver, as shown at right. To test your understanding of the rules of the game and the basic tools that we use for data com- pression, make sure that you understand the various commands on the facing page that</p><p attribs="{'xml:space': 'preserve'}" id="_14592" smilref="Title.smil#_14592"> public class Genome { public static void compress() // See text.</p><p attribs="{'xml:space': 'preserve'}" id="_14593" smilref="Title.smil#_14593"> public static void expand() // See text.</p><p attribs="{'xml:space': 'preserve'}" id="_14594" smilref="Title.smil#_14594"> public static void main(String[] args) { if (args[0].equals("-")) compress(); if (args[0].equals("+")) expand(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_14595" smilref="Title.smil#_14595"> invoke Genome.compress() and</p><p attribs="{'xml:space': 'preserve'}" id="_14596" smilref="Title.smil#_14596"> Genome.expand() on our sample data (and their consequences).</p><p attribs="{'xml:space': 'preserve'}" id="_14597" smilref="Title.smil#_14597"> Packaging convention for data-compression methods</p><p attribs="{'xml:space': 'preserve'}" id="_14598" smilref="Title.smil#_14598" /><pagenum id="p834" page="normal" smilref="Title.smil#p834" /><p attribs="{'xml:space': 'preserve'}" id="_14599" smilref="Title.smil#_14599"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14600" smilref="Title.smil#_14600"> 821</p><p attribs="{'xml:space': 'preserve'}" id="_14601" smilref="Title.smil#_14601"> tiny test case (264 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14602" smilref="Title.smil#_14602"> % more genomeTiny.txt ATAGATGCATAGCGCATAGCTAGATGTGCTAGC</p><p attribs="{'xml:space': 'preserve'}" id="_14603" smilref="Title.smil#_14603"> java BinaryDump 64 &lt; genomeTiny.txt 0100000101010100010000010100011101000001010101000100011101000011 0100000101010100010000010100011101000011010001110100001101000001 0101010001000001010001110100001101010100010000010100011101000001 0101010001000111010101000100011101000011010101000100000101000111 01000011 264 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14604" smilref="Title.smil#_14604"> % java Genome - &lt; genomeTiny.txt ??</p><p attribs="{'xml:space': 'preserve'}" id="_14605" smilref="Title.smil#_14605"> cannot see bitstream on standard output</p><p attribs="{'xml:space': 'preserve'}" id="_14606" smilref="Title.smil#_14606"> % java Genome - &lt; genomeTiny.txt | java BinaryDump 64 0000000000000000000000000010000100100011001011010010001101110100 1000110110001100101110110110001101000000 104 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14607" smilref="Title.smil#_14607"> % java Genome - &lt; genomeTiny.txt | java HexDump 8 00 00 00 21 23 2d 23 74 8d 8c bb 63 40 104 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14608" smilref="Title.smil#_14608"> % java Genome - &lt; genomeTiny.txt &gt; genomeTiny.2bit % java Genome + &lt; genomeTiny.2bit ATAGATGCATAGCGCATAGCTAGATGTGCTAGC</p><p attribs="{'xml:space': 'preserve'}" id="_14609" smilref="Title.smil#_14609"> % java Genome - &lt; genomeTiny.txt | java Genome + ATAGATGCATAGCGCATAGCTAGATGTGCTAGC</p><p attribs="{'xml:space': 'preserve'}" id="_14610" smilref="Title.smil#_14610"> compress-expand cycle produces original input</p><p attribs="{'xml:space': 'preserve'}" id="_14611" smilref="Title.smil#_14611"> an actual virus (50000 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14612" smilref="Title.smil#_14612"> % java PictureDump 512 100 &lt; genomeVirus.txt</p><p attribs="{'xml:space': 'preserve'}" id="_14613" smilref="Title.smil#_14613"> 50000 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14614" smilref="Title.smil#_14614"> % java Genome - &lt; genomeVirus.txt | java PictureDump 512 25</p><p attribs="{'xml:space': 'preserve'}" id="_14615" smilref="Title.smil#_14615"> 12536 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14616" smilref="Title.smil#_14616"> Compressing and expanding genomic sequences with 2-bit encoding</p><p attribs="{'xml:space': 'preserve'}" id="_14617" smilref="Title.smil#_14617" /></level3><level3 id="_00116"><h3 id="ch5-s5-ss20" smilref="Title.smil#ch5-s5-ss20" xml:space="preserve">Run-length coding</h3><pagenum id="p835" page="normal" smilref="Title.smil#p835" /><p attribs="{'xml:space': 'preserve'}" id="_14618" smilref="Title.smil#_14618"> 822</p><p attribs="{'xml:space': 'preserve'}" id="_14619" smilref="Title.smil#_14619"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14620" smilref="Title.smil#_14620"> Run-length encoding The simplest type of redundancy in a bitstream is long runs of repeated bits. Next, we consider a classic method known as run-length encoding for taking advantage of this redundancy to compress data. For example, consider the following 40-bit string:</p><p attribs="{'xml:space': 'preserve'}" id="_14621" smilref="Title.smil#_14621"> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_14622" smilref="Title.smil#_14622"> This string consists of 15 0s, then 7 1s, then 7 0s, then 11 1s, so we can encode the bit- string with the numbers 15, 7, 7, and 11. All bitstrings are composed of alternating runs of 0s and 1s; we just encode the length of the runs. In our example, if we use 4 bits to encode the numbers and start with a run of 0s, we get the 16-bit string</p><p attribs="{'xml:space': 'preserve'}" id="_14623" smilref="Title.smil#_14623"> 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_14624" smilref="Title.smil#_14624"> (15 = 1111, then 7 = 0111, then 7 = 0111, then 11 = 1011) for a compression ratio of 16/40 = 40 percent. In order to turn this description into an effective data compression method, we have to consider the following issues: </p><p attribs="{'xml:space': 'preserve'}" id="_14625" smilref="Title.smil#_14625"> Bitmaps. As an example of the effectiveness of run-length encoding, we consider bit- maps, which are widely use to represent pictures and scanned documents. For brevity and simplicity, we consider binary-valued bitmaps organized as bitstreams formed by taking the pixels in row-major order. To view the contents of a bitmap, we use PictureDump. Writing a program to convert an image from one of the many common lossless image formats that have been defined for &#8220;screen shots&#8221; or scanned documents into a bitmap is a simple matter (see Exercise 5.5.X). Our example to demonstrate the effectiveness of run-length encoding comes from screen shots of this book: a letter q (at various resolutions). We focus on a binary dump of a 32-by-48-pixel screen</p><p attribs="{'xml:space': 'preserve'}" id="_14626" smilref="Title.smil#_14626" /><pagenum id="p836" page="normal" smilref="Title.smil#p836" /><p attribs="{'xml:space': 'preserve'}" id="_14627" smilref="Title.smil#_14627"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14628" smilref="Title.smil#_14628"> 823</p><p attribs="{'xml:space': 'preserve'}" id="_14629" smilref="Title.smil#_14629"> % java BinaryDump 32 &lt; q32x48.bin</p><p attribs="{'xml:space': 'preserve'}" id="_14630" smilref="Title.smil#_14630"> 7 1s</p><p attribs="{'xml:space': 'preserve'}" id="_14631" smilref="Title.smil#_14631"> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</p><p attribs="{'xml:space': 'preserve'}" id="_14632" smilref="Title.smil#_14632"> 1536 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14633" smilref="Title.smil#_14633"> 32 32 15 7 10 12 15 5 10 4 4 9 5 8 4 9 6 5 7 3 12 5 5 6 4 12 5 5 5 4 13 5 5 4 4 14 5 5 4 4 14 5 5 3 4 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 5 15 5 5 2 6 14 5 5 2 6 14 5 5 3 6 13 5 5 3 6 13 5 5 4 6 12 5 5 4 7 11 5 5 5 7 10 5 5 6 8 7 6 5 7 20 5 9 11 2 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 22 5 5 21 7 4 18 12 2 17 14 1 32 32</p><p attribs="{'xml:space': 'preserve'}" id="_14634" smilref="Title.smil#_14634"> shot, shown at right along with run lengths for each row. Since each row starts and ends with a 0, there is an odd number of run lengths on each row ; since the end of one row is followed by the beginning of the next, the corresponding run length in the bitstream is the sum of the last run length in each row and the first run length in the next (with extra additions corresponding to rows that are all 0).</p><p attribs="{'xml:space': 'preserve'}" id="_14635" smilref="Title.smil#_14635"> Implementation. The</p><p attribs="{'xml:space': 'preserve'}" id="_14636" smilref="Title.smil#_14636"> informal description just given leads immediately to the compress() and expand() implementations on the next page. As usual, the expand() implementation is the simpler of the two: read a run length, print that many copies of the current bit, complement the current bit, and continue until the input is exhausted. The compress() method is not much more dif&#64257; cult, consisting of the following steps while there are bits in the input stream: </p><p attribs="{'xml:space': 'preserve'}" id="_14637" smilref="Title.smil#_14637"> 17 0s</p><p attribs="{'xml:space': 'preserve'}" id="_14638" smilref="Title.smil#_14638"> A typical bitmap, with run lengths for each row</p><p attribs="{'xml:space': 'preserve'}" id="_14639" smilref="Title.smil#_14639"> Increasing resolution in bitmaps. The primary reason that run-length encoding is widely used for bitmaps is that its effectiveness increases dramatically as resolution in- creases. It is easy to see why this is true. Suppose that we double the resolution for our example. Then the following facts are evident: </p><p attribs="{'xml:space': 'preserve'}" id="_14640" smilref="Title.smil#_14640" /><pagenum id="p837" page="normal" smilref="Title.smil#p837" /><p attribs="{'xml:space': 'preserve'}" id="_14641" smilref="Title.smil#_14641"> 824</p><p attribs="{'xml:space': 'preserve'}" id="_14642" smilref="Title.smil#_14642"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14643" smilref="Title.smil#_14643"> public static void expand() { boolean b = false; while (!BinaryStdIn.isEmpty()) { char cnt = BinaryStdIn.readChar(); for (int i = 0; i &lt; cnt; i++) BinaryStdOut.write(b); b = !b; } BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14644" smilref="Title.smil#_14644"> public static void compress() { char cnt = 0; boolean b, old = false; while (!BinaryStdIn.isEmpty()) { b = BinaryStdIn.readBoolean(); if (b != old) { BinaryStdOut.write(cnt); cnt = 0; old = !old; } else { if (cnt == 255) { BinaryStdOut.write(cnt); cnt = 0; BinaryStdOut.write(cnt); } } cnt++; } BinaryStdOut.write(cnt); BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14645" smilref="Title.smil#_14645"> Expand and compress methods for run-length encoding</p><p attribs="{'xml:space': 'preserve'}" id="_14646" smilref="Title.smil#_14646"> Without run-length encoding, space requirements increase by a factor of 4 when the resolution is doubled; with run-length encod- ing, space requirements for the compressed bitstream just double when the resolution is doubled. That is, space grows and the compression ratio drops linearly with resolution. For example, our (low-resolution) letter q yields just a 74 percent compression ratio; if we increase the resolution to 64 by 96, the ratio drops to 37 percent. This change is graphically evident in the PictureDump outputs shown in the figure on the facing page. The higher-resolution letter takes four times the space of the lower resolution letter (double in both dimensions), but the compressed version takes just twice the space (double in one dimension). If we further increase the resolution to 128-by-192 (closer to what is needed for print), the ratio drops to 18 percent (see</p><p attribs="{'xml:space': 'preserve'}" id="_14647" smilref="Title.smil#_14647"> Exercise 5.5.5).</p><p attribs="{'xml:space': 'preserve'}" id="_14648" smilref="Title.smil#_14648"> Run-length encoding is very effective</p><p attribs="{'xml:space': 'preserve'}" id="_14649" smilref="Title.smil#_14649"> in many situations, but there are plenty of cases where the bitstream we wish to compress (for example, typical English-language text) may have no long runs at all. Next, we consider two methods that are effective for a broad variety of fi les. They are widely used, and you likely have used one or both of these methods when downloading from the web.</p><p attribs="{'xml:space': 'preserve'}" id="_14650" smilref="Title.smil#_14650" /><pagenum id="p838" page="normal" smilref="Title.smil#p838" /><p attribs="{'xml:space': 'preserve'}" id="_14651" smilref="Title.smil#_14651"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14652" smilref="Title.smil#_14652"> 825</p><p attribs="{'xml:space': 'preserve'}" id="_14653" smilref="Title.smil#_14653"> tiny test case (40 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14654" smilref="Title.smil#_14654"> % java BinaryDump 40 &lt; 4runs.bin 0000000000000001111111000000011111111111 40 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14655" smilref="Title.smil#_14655"> % java RunLength - &lt; 4runs.bin | java HexDump 0f 07 07 0b 32 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14656" smilref="Title.smil#_14656"> compression ratio 32/40 = 80%</p><p attribs="{'xml:space': 'preserve'}" id="_14657" smilref="Title.smil#_14657"> % java RunLength - &lt; 4runs.bin | java RunLength + | java BinaryDump 40 0000000000000001111111000000011111111111 40 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14658" smilref="Title.smil#_14658"> compress-expand produces original input</p><p attribs="{'xml:space': 'preserve'}" id="_14659" smilref="Title.smil#_14659"> ASCII text (96 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14660" smilref="Title.smil#_14660"> % java RunLength - &lt; abra.txt | java HexDump 24 01 01 05 01 01 01 04 01 02 01 01 01 02 01 02 01 05 01 01 01 04 02 01 01 05 01 01 01 03 01 03 01 05 01 01 01 04 01 02 01 01 01 02 01 02 01 05 01 02 01 04 01 416 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14661" smilref="Title.smil#_14661"> compression ratio 416/ = 433% &#8212; do not use run-length encoding for ASCII !</p><p attribs="{'xml:space': 'preserve'}" id="_14662" smilref="Title.smil#_14662"> a bitmap (1536 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14663" smilref="Title.smil#_14663"> % java PictureDump 32 48 &lt; q32x48.bin</p><p attribs="{'xml:space': 'preserve'}" id="_14664" smilref="Title.smil#_14664"> % java RunLength - &lt; q32x48.bin &gt; q32x48.bin.rle % java HexDump 16 &lt; q32x48.bin.rle 4f 07 16 0f 0f 04 04 09 0d 04 09 06 0c 03 0c 05 0b 04 0c 05 0a 04 0d 05 09 04 0e 05 09 04 0e 05 08 04 0f 05 08 04 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 05 0f 05 07 06 0e 05 07 06 0e 05 08 06 0d 05 08 06 0d 05 09 06 0c 05 09 07 0b 05 0a 07 0a 05 0b 08 07 06 0c 14 0e 0b 02 05 11 05 05 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1b 05 1a 07 16 0c 13 0e 41 1144 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14665" smilref="Title.smil#_14665"> compression ratio 1144/1536 = 74%</p><p attribs="{'xml:space': 'preserve'}" id="_14666" smilref="Title.smil#_14666"> a higher-resolution bitmap (6144 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_14667" smilref="Title.smil#_14667"> % java BinaryDump 0 &lt; q64x96.bin 6144 bits % java RunLength - &lt; q64x96.bin | java BinaryDump 0 2296 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14668" smilref="Title.smil#_14668"> compression ratio 2296/6144 = 37%</p><p attribs="{'xml:space': 'preserve'}" id="_14669" smilref="Title.smil#_14669"> 1536 bits % java PictureDump 32 36 &lt; q32x48.rle.bin</p><p attribs="{'xml:space': 'preserve'}" id="_14670" smilref="Title.smil#_14670"> 1144 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14671" smilref="Title.smil#_14671"> % java PictureDump 64 96 &lt; q64x96.bin</p><p attribs="{'xml:space': 'preserve'}" id="_14672" smilref="Title.smil#_14672"> 6144 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14673" smilref="Title.smil#_14673"> % java PictureDump 64 36 &lt; q64x96.rle.bin</p><p attribs="{'xml:space': 'preserve'}" id="_14674" smilref="Title.smil#_14674"> Compressing and expanding bitstreams with run-length encoding</p><p attribs="{'xml:space': 'preserve'}" id="_14675" smilref="Title.smil#_14675"> 2296 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14676" smilref="Title.smil#_14676" /></level3><level3 id="_00117"><h3 id="ch5-s5-ss21" smilref="Title.smil#ch5-s5-ss21" xml:space="preserve">Huffman compression</h3><pagenum id="p839" page="normal" smilref="Title.smil#p839" /><p attribs="{'xml:space': 'preserve'}" id="_14677" smilref="Title.smil#_14677"> 826</p><p attribs="{'xml:space': 'preserve'}" id="_14678" smilref="Title.smil#_14678"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14679" smilref="Title.smil#_14679"> Huffman compression We now examine a data-compression technique that can save a substantial amount of space in natural language files (and many other kinds of fi les). The idea is to abandon the way in which text files are usually stored: instead of using the usual 7 or 8 bits for each character, we use fewer bits for characters that appear often than for those that appear rarely. To introduce the basic ideas, we start with a small example. Suppose we wish to encode the string A B R A C A D A B R A ! Encoding it in 7-bit ASCII gives this bitstring:</p><p attribs="{'xml:space': 'preserve'}" id="_14680" smilref="Title.smil#_14680"> 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 - 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 .</p><p attribs="{'xml:space': 'preserve'}" id="_14681" smilref="Title.smil#_14681"> To decode this bitstring, we simply read off 7 bits at a time and convert according to the ASCII coding table on page 815. In this standard code the D, which appears only once, requires the same number of bits as the A, which appears five times. Huffman compression is based on the idea that we can save bits by encoding frequently used characters with fewer bits than rarely used characters, thereby lowering the total number of bits used.</p><p attribs="{'xml:space': 'preserve'}" id="_14682" smilref="Title.smil#_14682"> Variable-length pre&#64257; x-free codes. A code associates each character with a bitstring: a symbol table with characters as keys and bitstrings as values. As a start, we might try to assign the shortest bitstrings to the most commonly used letters, encoding A with 0, B with 1, R with 00, C with 01, D with 10, and ! with 11, so A B R A C A D A B R A ! would be encoded as 0 1 00 0 01 0 10 0 1 00 0 11. This representation uses only 17 bits compared to the 77 for 7-bit ASCII, but it is not really a code because it depends on the blanks to delimit the characters. Without the blanks, the bitstring would be</p><p attribs="{'xml:space': 'preserve'}" id="_14683" smilref="Title.smil#_14683"> 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1</p><p attribs="{'xml:space': 'preserve'}" id="_14684" smilref="Title.smil#_14684"> and could be decoded as C R R D D C R C B or as several other strings. Still, the count of 17 bits plus 10 delimiters is rather more compact than the standard code, primarily because no bits are used to encode letters not appearing in the message. The next step is to take advantage of the fact that delimiters are not needed if no character code is the prefix of another. A code with this property is known as a pre&#64257; x-free code. The code just given is not pre&#64257; x-free because 0, the code for A, is a prefix of 00, the code for R. For example, if we encode A with 0, B with 1111, C with 110, D with 100, R with 1110, and ! with 101, there is only one way to decode the 30-bit string</p><p attribs="{'xml:space': 'preserve'}" id="_14685" smilref="Title.smil#_14685"> 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_14686" smilref="Title.smil#_14686"> A B R A C A D A B R A ! All pre&#64257; x-free codes are uniquely decodable (without needing any delimiters) in this way, so pre&#64257; x-free codes are widely used in practice. Note that fi xed- length codes such as 7-bit ASCII are pre&#64257; x-free.</p><p attribs="{'xml:space': 'preserve'}" id="_14687" smilref="Title.smil#_14687" /><pagenum id="p840" page="normal" smilref="Title.smil#p840" /><p attribs="{'xml:space': 'preserve'}" id="_14688" smilref="Title.smil#_14688"> Trie representation for pre&#64257; x-free codes. One conve-</p><p attribs="{'xml:space': 'preserve'}" id="_14689" smilref="Title.smil#_14689"> codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_14690" smilref="Title.smil#_14690"> trie representation</p><p attribs="{'xml:space': 'preserve'}" id="_14691" smilref="Title.smil#_14691"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14692" smilref="Title.smil#_14692"> 827</p><p attribs="{'xml:space': 'preserve'}" id="_14693" smilref="Title.smil#_14693"> nient way to represent a pre&#64257; x-free code is with a trie (see Section 5.2). In fact, any trie with M null links defines a pre&#64257; x-free code for M characters: we replace the null links by links to leaves (nodes with two null links), each containing a character to be encoded, and define the code for each character with the bitstring defined by the path from the root to the character, in the standard manner for tries where we associate 0 with moving left and 1 with moving right. For example, the figure at right shows two pre&#64257; x- free codes for the characters in A B R A C A D A B R A ! . On top is the variable-length code just considered; below is a code that produces the string</p><p attribs="{'xml:space': 'preserve'}" id="_14694" smilref="Title.smil#_14694"> 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 1</p><p attribs="{'xml:space': 'preserve'}" id="_14695" smilref="Title.smil#_14695"> key</p><p attribs="{'xml:space': 'preserve'}" id="_14696" smilref="Title.smil#_14696"> ! A B C D R</p><p attribs="{'xml:space': 'preserve'}" id="_14697" smilref="Title.smil#_14697"> value</p><p attribs="{'xml:space': 'preserve'}" id="_14698" smilref="Title.smil#_14698"> 101 0 1111 110 100 1110</p><p attribs="{'xml:space': 'preserve'}" id="_14699" smilref="Title.smil#_14699"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14700" smilref="Title.smil#_14700"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14701" smilref="Title.smil#_14701"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14702" smilref="Title.smil#_14702"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14703" smilref="Title.smil#_14703"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14704" smilref="Title.smil#_14704"> leaves</p><p attribs="{'xml:space': 'preserve'}" id="_14705" smilref="Title.smil#_14705"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14706" smilref="Title.smil#_14706"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14707" smilref="Title.smil#_14707"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14708" smilref="Title.smil#_14708"> !</p><p attribs="{'xml:space': 'preserve'}" id="_14709" smilref="Title.smil#_14709"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14710" smilref="Title.smil#_14710"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14711" smilref="Title.smil#_14711"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14712" smilref="Title.smil#_14712"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14713" smilref="Title.smil#_14713"> R</p><p attribs="{'xml:space': 'preserve'}" id="_14714" smilref="Title.smil#_14714"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14715" smilref="Title.smil#_14715"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14716" smilref="Title.smil#_14716"> compressed bitstring</p><p attribs="{'xml:space': 'preserve'}" id="_14717" smilref="Title.smil#_14717"> 011111110011001000111111100101 A B RA CA DA B RA !</p><p attribs="{'xml:space': 'preserve'}" id="_14718" smilref="Title.smil#_14718"> 30 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14719" smilref="Title.smil#_14719"> codeword table key value</p><p attribs="{'xml:space': 'preserve'}" id="_14720" smilref="Title.smil#_14720"> ! A B C D R</p><p attribs="{'xml:space': 'preserve'}" id="_14721" smilref="Title.smil#_14721"> 101 11 00 010 100 011</p><p attribs="{'xml:space': 'preserve'}" id="_14722" smilref="Title.smil#_14722"> trie representation</p><p attribs="{'xml:space': 'preserve'}" id="_14723" smilref="Title.smil#_14723"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14724" smilref="Title.smil#_14724"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14725" smilref="Title.smil#_14725"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14726" smilref="Title.smil#_14726"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14727" smilref="Title.smil#_14727"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14728" smilref="Title.smil#_14728"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14729" smilref="Title.smil#_14729"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14730" smilref="Title.smil#_14730"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14731" smilref="Title.smil#_14731"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14732" smilref="Title.smil#_14732"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14733" smilref="Title.smil#_14733"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14734" smilref="Title.smil#_14734"> !</p><p attribs="{'xml:space': 'preserve'}" id="_14735" smilref="Title.smil#_14735"> 29 bits</p><p attribs="{'xml:space': 'preserve'}" id="_14736" smilref="Title.smil#_14736"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14737" smilref="Title.smil#_14737"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14738" smilref="Title.smil#_14738"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14739" smilref="Title.smil#_14739"> R</p><p attribs="{'xml:space': 'preserve'}" id="_14740" smilref="Title.smil#_14740"> which is 29 bits, 1 bit shorter. Is there a trie that leads to even more compression? How do we find the trie that leads to the best pre&#64257; x-free code? It turns out that there is an elegant answer to these questions in the form of an algorithm that computes a trie which leads to a bitstream of minimal length for any given string. To make a fair comparison with other codes, we also need to count the bits in the code itself, since the string cannot be decoded without it, and, as you will see, the code depends on the string. The general method for finding the optimal pre&#64257; x-free code was discovered by D. Huffman (while a student!) in 1952 and is called Huffman encoding.</p><p attribs="{'xml:space': 'preserve'}" id="_14741" smilref="Title.smil#_14741"> 11000111101011100110001111101 A B R A C A D A B R A !</p><p attribs="{'xml:space': 'preserve'}" id="_14742" smilref="Title.smil#_14742"> Two prefix-free codes</p><p attribs="{'xml:space': 'preserve'}" id="_14743" smilref="Title.smil#_14743"> compressed bitstring</p><p attribs="{'xml:space': 'preserve'}" id="_14744" smilref="Title.smil#_14744"> Overview. Using a pre&#64257; x-free code for data compression involves five major steps. We view the bitstream to be encoded as a bytestream and use a pre&#64257; x-free code for the characters as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_14745" smilref="Title.smil#_14745" /><pagenum id="p841" page="normal" smilref="Title.smil#p841" /><p attribs="{'xml:space': 'preserve'}" id="_14746" smilref="Title.smil#_14746"> 828</p><p attribs="{'xml:space': 'preserve'}" id="_14747" smilref="Title.smil#_14747"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14748" smilref="Title.smil#_14748"> private static class Node implements Comparable&lt;Node&gt; { // Huffman trie node private char ch; // unused for internal nodes private int freq; // unused for expand private final Node left, right;</p><p attribs="{'xml:space': 'preserve'}" id="_14749" smilref="Title.smil#_14749"> Node(char ch, int freq, Node left, Node right) { this.ch = ch; this.freq = freq; this.left = left; this.right = right; }</p><p attribs="{'xml:space': 'preserve'}" id="_14750" smilref="Title.smil#_14750"> public boolean isLeaf() { return left == null &amp;&amp; right == null; }</p><p attribs="{'xml:space': 'preserve'}" id="_14751" smilref="Title.smil#_14751"> public int compareTo(Node that) { return this.freq - that.freq; }</p><p attribs="{'xml:space': 'preserve'}" id="_14752" smilref="Title.smil#_14752"> }</p><p attribs="{'xml:space': 'preserve'}" id="_14753" smilref="Title.smil#_14753"> Trie node representation</p><p attribs="{'xml:space': 'preserve'}" id="_14754" smilref="Title.smil#_14754"> Trie nodes. We begin with the Node class at left. It is similar to the nested classes that we have used before to construct binary trees and tries: each Node has left and right references to Nodes, which define the trie structure. Each Node also has an instance variable freq that is used in construction, and an instance variable ch, which is used in leaves to represent characters to be encoded.</p><p attribs="{'xml:space': 'preserve'}" id="_14755" smilref="Title.smil#_14755"> Expansion</p><p attribs="{'xml:space': 'preserve'}" id="_14756" smilref="Title.smil#_14756"> for pre&#64257; x-free</p><p attribs="{'xml:space': 'preserve'}" id="_14757" smilref="Title.smil#_14757"> public static void expand() { Node root = readTrie(); int N = BinaryStdIn.readInt(); for (int i = 0; i &lt; N; i++) { // Expand ith codeword. Node x = root; while (!x.isLeaf()) if (BinaryStdIn.readBoolean()) x = x.right; else x = x.left; BinaryStdOut.write(x.ch); } BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14758" smilref="Title.smil#_14758"> codes. Expanding a bitstream that was encoded with a pre&#64257; x- free code is simple, given the trie that defines the code. The expand() method at left is an implementation of this process. After reading the trie from standard input using the readTrie() method to be described later, we use it to expand the rest of the bitstream as follows: Starting at the root, proceed down the trie as directed by the bitstream (read in input bit, move left if it is 0, and move right if it is 1). When you encounter a leaf, output the character at that node and restart at the root. If you study the operation of this method on the small prefix code example on the next page, you will understand and appreciate this process: For example, to decode the bitstring 0 1 1 1 1 1 0 0 1 0 1 1 . . . we start at the root, move left because the first bit is 0, output A; go back to the root, move right three times, then output B; go back to the root, move right twice, then left, then output R; and so forth. The simplicity of expansion is one reason for the popularity of pre&#64257; x-free codes in general and Huffman compression in particular.</p><p attribs="{'xml:space': 'preserve'}" id="_14759" smilref="Title.smil#_14759"> Pref ix-free code expansion (decoding)</p><p attribs="{'xml:space': 'preserve'}" id="_14760" smilref="Title.smil#_14760" /><pagenum id="p842" page="normal" smilref="Title.smil#p842" /><p attribs="{'xml:space': 'preserve'}" id="_14761" smilref="Title.smil#_14761"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14762" smilref="Title.smil#_14762"> 829</p><p attribs="{'xml:space': 'preserve'}" id="_14763" smilref="Title.smil#_14763"> private static String[] buildCode(Node root) { // Make a lookup table from trie. String[] st = new String[R]; buildCode(st, root, ""); return st; }</p><p attribs="{'xml:space': 'preserve'}" id="_14764" smilref="Title.smil#_14764"> private static void buildCode(String[] st, Node x, String s) { // Make a lookup table from trie (recursive). if (x.isLeaf()) { st[x.ch] = s; return; } buildCode(st, x.left, s + '0'); buildCode(st, x.right, s + '1'); }</p><p attribs="{'xml:space': 'preserve'}" id="_14765" smilref="Title.smil#_14765"> Building an encoding table from a (pref ix-free) code trie</p><p attribs="{'xml:space': 'preserve'}" id="_14766" smilref="Title.smil#_14766"> Compression for pre&#64257; x-free codes. For compression, we use</p><p attribs="{'xml:space': 'preserve'}" id="_14767" smilref="Title.smil#_14767"> Codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_14768" smilref="Title.smil#_14768"> Trie representation</p><p attribs="{'xml:space': 'preserve'}" id="_14769" smilref="Title.smil#_14769"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14770" smilref="Title.smil#_14770"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14771" smilref="Title.smil#_14771"> A</p><p attribs="{'xml:space': 'preserve'}" id="_14772" smilref="Title.smil#_14772"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14773" smilref="Title.smil#_14773"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14774" smilref="Title.smil#_14774"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14775" smilref="Title.smil#_14775"> R</p><p attribs="{'xml:space': 'preserve'}" id="_14776" smilref="Title.smil#_14776"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14777" smilref="Title.smil#_14777"> B</p><p attribs="{'xml:space': 'preserve'}" id="_14778" smilref="Title.smil#_14778"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14779" smilref="Title.smil#_14779"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14780" smilref="Title.smil#_14780"> D</p><p attribs="{'xml:space': 'preserve'}" id="_14781" smilref="Title.smil#_14781"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14782" smilref="Title.smil#_14782"> C</p><p attribs="{'xml:space': 'preserve'}" id="_14783" smilref="Title.smil#_14783"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_14784" smilref="Title.smil#_14784"> !</p><p attribs="{'xml:space': 'preserve'}" id="_14785" smilref="Title.smil#_14785"> key</p><p attribs="{'xml:space': 'preserve'}" id="_14786" smilref="Title.smil#_14786"> value</p><p attribs="{'xml:space': 'preserve'}" id="_14787" smilref="Title.smil#_14787"> ! A B C D R</p><p attribs="{'xml:space': 'preserve'}" id="_14788" smilref="Title.smil#_14788"> A Huffman code</p><p attribs="{'xml:space': 'preserve'}" id="_14789" smilref="Title.smil#_14789"> 1010 0 111 1011 100 110</p><p attribs="{'xml:space': 'preserve'}" id="_14790" smilref="Title.smil#_14790"> the trie that defines the code to build the code table, as shown in the buildCode() method at the top of this page. This method is compact and elegant, but a bit tricky, so it deserves careful study. For any trie, it produces a table giving the bit- string associated with each character in the trie (represented as a String of 0s and 1s). The coding table is a symbol table that associates a String with each character: we use a charac- ter-indexed array st[] instead of a general symbol table for ef&#64257; ciency, because the number of characters is not large. To create it, buildCode() recursively walks the tree, maintaining a binary string that corresponds to the path from the root to each node (0 for left links and 1 for right links), and setting the codeword corresponding to each character when the character is found in a leaf. Once the coding table is built, compression is a simple matter: just look up the code for each character in the input. To use the encoding at right to compress A B R A C A D A B R A ! we write 0 (the codeword associated with A), then 111 (the codeword associated with B), then 110 (the codeword associated with R), and so forth. The code snippet at right accomplishes this task: we look up the String associated with each character in the input, convert it to 0/1 values in a char array, and write the corresponding bitstring to the output.</p><p attribs="{'xml:space': 'preserve'}" id="_14791" smilref="Title.smil#_14791"> for (int i = 0; i &lt; input.length; i++) { String code = st[input[i]]; for (int j = 0; j &lt; code.length(); j++) if (code.charAt(j) == '1') BinaryStdOut.write(true); else BinaryStdOut.write(false); }</p><p attribs="{'xml:space': 'preserve'}" id="_14792" smilref="Title.smil#_14792"> Compression with an encoding table</p><p attribs="{'xml:space': 'preserve'}" id="_14793" smilref="Title.smil#_14793" /><pagenum id="p843" page="normal" smilref="Title.smil#p843" /><p attribs="{'xml:space': 'preserve'}" id="_14794" smilref="Title.smil#_14794"> 830</p><p attribs="{'xml:space': 'preserve'}" id="_14795" smilref="Title.smil#_14795"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_14796" smilref="Title.smil#_14796"> Trie construction. For reference as we describe the process, the figure on the facing page illustrates the process of constructing a Huffman trie for the input</p><p attribs="{'xml:space': 'preserve'}" id="_14797" smilref="Title.smil#_14797"> it was the best of times it was the worst of times</p><p attribs="{'xml:space': 'preserve'}" id="_14798" smilref="Title.smil#_14798"> We keep the characters to be encoded in leaves and maintain the freq instance variable in each node that represents the frequency of occurrence of all characters in the subtree rooted at that node. The first step is to create a forest of 1-node trees (leaves), one for each character in the input stream, each assigned a freq value equal to its frequency of occurrence in the input. In the example, the input has 8 ts, 5 es, 11 spaces, and so forth. (Important note: To obtain these frequencies, we need to read the whole input stream&#8212; Huffman encoding is a two-pass algorithm because we will need to read the input stream a second time to compress it.) Next, we build the coding trie from the bottom up according to the frequencies. When building the trie, we view it as a binary trie with frequencies stored in the nodes; after it has been built, we view it as a trie for coding, as just described. The process works as follows: we find the two nodes with the smallest frequencies and then create a new node with those two nodes as children (and with frequency value set to the sum of the values of the children). This operation reduces the number of tries in the forest by one. Then we iterate the process: find the two nodes with smallest frequency in that forest and a create a new node created in the same way. Implementing the process is straightforward with a priority queue, as shown in the buildTrie() method on page 830. (For clarity, the tries in the figure are kept in sorted order.) Continuing, we build up larger and larger tries and at the same time reduce the number of tries in the forest by one at each step (remove two, add one). Ultimately, all the</p><p attribs="{'xml:space': 'preserve'}" id="_14799" smilref="Title.smil#_14799"> private static Node buildTrie(int[] freq) { // Initialize priority queue with singleton trees. MinPQ&lt;Node&gt; pq = new MinPQ&lt;Node&gt;(); for (char c = 0; c &lt; R; c++) if (freq[c] &gt; 0) pq.insert(new Node(c, freq[c], null, null));</p><p attribs="{'xml:space': 'preserve'}" id="_14800" smilref="Title.smil#_14800"> while (pq.size() &gt; 1) { // Merge two smallest trees. Node x = pq.delMin(); Node y = pq.delMin(); Node parent = new Node('(cid:0)', x.freq + y.freq, x, y); pq.insert(parent); } return pq.delMin(); }</p><p attribs="{'xml:space': 'preserve'}" id="_14801" smilref="Title.smil#_14801"> Building a Huf fman encoding trie</p><p attribs="{'xml:space': 'preserve'}" id="_14802" smilref="Title.smil#_14802" /><pagenum id="p844" page="normal" smilref="Title.smil#p844" /><p attribs="{'xml:space': 'preserve'}" id="_14803" smilref="Title.smil#_14803"> 831</p><p attribs="{'xml:space': 'preserve'}" id="_14804" smilref="Title.smil#_14804"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_14805" smilref="Title.smil#_14805"> e</p><p attribs="{'xml:space': 'preserve'}" id="_14806" smilref="Title.smil#_14806"> w</p><p attribs="{'xml:space': 'preserve'}" id="_14807" smilref="Title.smil#_14807"> o</p><p attribs="{'xml:space': 'preserve'}" id="_14808" smilref="Title.smil#_14808"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_14809" smilref="Title.smil#_14809"> s</p><p attribs="{'xml:space': 'preserve'}" id="_14810" smilref="Title.smil#_14810"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_14811" smilref="Title.smil#_14811"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14812" smilref="Title.smil#_14812"> b</p><p attribs="{'xml:space': 'preserve'}" id="_14813" smilref="Title.smil#_14813"> f</p><p attribs="{'xml:space': 'preserve'}" id="_14814" smilref="Title.smil#_14814"> h</p><p attribs="{'xml:space': 'preserve'}" id="_14815" smilref="Title.smil#_14815"> m</p><p attribs="{'xml:space': 'preserve'}" id="_14816" smilref="Title.smil#_14816"> a</p><p attribs="{'xml:space': 'preserve'}" id="_14817" smilref="Title.smil#_14817"> t</p><p attribs="{'xml:space': 'preserve'}" id="_14818" smilref="Title.smil#_14818"> r</p><p attribs="{'xml:space': 'preserve'}" id="_14819" smilref="Title.smil#_14819"> Constructing a Huffman encoding trie</p><p attribs="{'xml:space': 'preserve'}" id="_14820" smilref="Title.smil#_14820"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_14821" smilref="Title.smil#_14821"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14822" smilref="Title.smil#_14822"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14823" smilref="Title.smil#_14823"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_14824" smilref="Title.smil#_14824"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14825" smilref="Title.smil#_14825"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14826" smilref="Title.smil#_14826"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14827" smilref="Title.smil#_14827"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14828" smilref="Title.smil#_14828"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14829" smilref="Title.smil#_14829"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14830" smilref="Title.smil#_14830"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14831" smilref="Title.smil#_14831"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14832" smilref="Title.smil#_14832"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14833" smilref="Title.smil#_14833"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14834" smilref="Title.smil#_14834"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14835" smilref="Title.smil#_14835"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14836" smilref="Title.smil#_14836"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14837" smilref="Title.smil#_14837"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14838" smilref="Title.smil#_14838"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14839" smilref="Title.smil#_14839"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14840" smilref="Title.smil#_14840"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14841" smilref="Title.smil#_14841"> 1313</p><p attribs="{'xml:space': 'preserve'}" id="_14842" smilref="Title.smil#_14842"> 1616</p><p attribs="{'xml:space': 'preserve'}" id="_14843" smilref="Title.smil#_14843"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14844" smilref="Title.smil#_14844"> 2222</p><p attribs="{'xml:space': 'preserve'}" id="_14845" smilref="Title.smil#_14845"> 2929</p><p attribs="{'xml:space': 'preserve'}" id="_14846" smilref="Title.smil#_14846"> 5151</p><p attribs="{'xml:space': 'preserve'}" id="_14847" smilref="Title.smil#_14847"> e</p><p attribs="{'xml:space': 'preserve'}" id="_14848" smilref="Title.smil#_14848"> w</p><p attribs="{'xml:space': 'preserve'}" id="_14849" smilref="Title.smil#_14849"> o</p><p attribs="{'xml:space': 'preserve'}" id="_14850" smilref="Title.smil#_14850"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_14851" smilref="Title.smil#_14851"> s</p><p attribs="{'xml:space': 'preserve'}" id="_14852" smilref="Title.smil#_14852"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_14853" smilref="Title.smil#_14853"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14854" smilref="Title.smil#_14854"> b</p><p attribs="{'xml:space': 'preserve'}" id="_14855" smilref="Title.smil#_14855"> f</p><p attribs="{'xml:space': 'preserve'}" id="_14856" smilref="Title.smil#_14856"> h</p><p attribs="{'xml:space': 'preserve'}" id="_14857" smilref="Title.smil#_14857"> m</p><p attribs="{'xml:space': 'preserve'}" id="_14858" smilref="Title.smil#_14858"> a</p><p attribs="{'xml:space': 'preserve'}" id="_14859" smilref="Title.smil#_14859"> t</p><p attribs="{'xml:space': 'preserve'}" id="_14860" smilref="Title.smil#_14860"> r</p><p attribs="{'xml:space': 'preserve'}" id="_14861" smilref="Title.smil#_14861"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_14862" smilref="Title.smil#_14862"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14863" smilref="Title.smil#_14863"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14864" smilref="Title.smil#_14864"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_14865" smilref="Title.smil#_14865"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14866" smilref="Title.smil#_14866"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14867" smilref="Title.smil#_14867"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14868" smilref="Title.smil#_14868"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14869" smilref="Title.smil#_14869"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14870" smilref="Title.smil#_14870"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14871" smilref="Title.smil#_14871"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14872" smilref="Title.smil#_14872"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14873" smilref="Title.smil#_14873"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14874" smilref="Title.smil#_14874"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14875" smilref="Title.smil#_14875"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14876" smilref="Title.smil#_14876"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14877" smilref="Title.smil#_14877"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14878" smilref="Title.smil#_14878"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14879" smilref="Title.smil#_14879"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14880" smilref="Title.smil#_14880"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14881" smilref="Title.smil#_14881"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14882" smilref="Title.smil#_14882"> 1313</p><p attribs="{'xml:space': 'preserve'}" id="_14883" smilref="Title.smil#_14883"> 1616</p><p attribs="{'xml:space': 'preserve'}" id="_14884" smilref="Title.smil#_14884"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14885" smilref="Title.smil#_14885"> 2222</p><p attribs="{'xml:space': 'preserve'}" id="_14886" smilref="Title.smil#_14886"> 2929</p><p attribs="{'xml:space': 'preserve'}" id="_14887" smilref="Title.smil#_14887"> e</p><p attribs="{'xml:space': 'preserve'}" id="_14888" smilref="Title.smil#_14888"> w</p><p attribs="{'xml:space': 'preserve'}" id="_14889" smilref="Title.smil#_14889"> o</p><p attribs="{'xml:space': 'preserve'}" id="_14890" smilref="Title.smil#_14890"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_14891" smilref="Title.smil#_14891"> s</p><p attribs="{'xml:space': 'preserve'}" id="_14892" smilref="Title.smil#_14892"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_14893" smilref="Title.smil#_14893"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14894" smilref="Title.smil#_14894"> b</p><p attribs="{'xml:space': 'preserve'}" id="_14895" smilref="Title.smil#_14895"> f</p><p attribs="{'xml:space': 'preserve'}" id="_14896" smilref="Title.smil#_14896"> h</p><p attribs="{'xml:space': 'preserve'}" id="_14897" smilref="Title.smil#_14897"> m</p><p attribs="{'xml:space': 'preserve'}" id="_14898" smilref="Title.smil#_14898"> a</p><p attribs="{'xml:space': 'preserve'}" id="_14899" smilref="Title.smil#_14899"> t</p><p attribs="{'xml:space': 'preserve'}" id="_14900" smilref="Title.smil#_14900"> r</p><p attribs="{'xml:space': 'preserve'}" id="_14901" smilref="Title.smil#_14901"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_14902" smilref="Title.smil#_14902"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14903" smilref="Title.smil#_14903"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14904" smilref="Title.smil#_14904"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_14905" smilref="Title.smil#_14905"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14906" smilref="Title.smil#_14906"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14907" smilref="Title.smil#_14907"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14908" smilref="Title.smil#_14908"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14909" smilref="Title.smil#_14909"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14910" smilref="Title.smil#_14910"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14911" smilref="Title.smil#_14911"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14912" smilref="Title.smil#_14912"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14913" smilref="Title.smil#_14913"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14914" smilref="Title.smil#_14914"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14915" smilref="Title.smil#_14915"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14916" smilref="Title.smil#_14916"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14917" smilref="Title.smil#_14917"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14918" smilref="Title.smil#_14918"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14919" smilref="Title.smil#_14919"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14920" smilref="Title.smil#_14920"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14921" smilref="Title.smil#_14921"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14922" smilref="Title.smil#_14922"> 1313</p><p attribs="{'xml:space': 'preserve'}" id="_14923" smilref="Title.smil#_14923"> 1616</p><p attribs="{'xml:space': 'preserve'}" id="_14924" smilref="Title.smil#_14924"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14925" smilref="Title.smil#_14925"> 2222</p><p attribs="{'xml:space': 'preserve'}" id="_14926" smilref="Title.smil#_14926"> e</p><p attribs="{'xml:space': 'preserve'}" id="_14927" smilref="Title.smil#_14927"> w</p><p attribs="{'xml:space': 'preserve'}" id="_14928" smilref="Title.smil#_14928"> o</p><p attribs="{'xml:space': 'preserve'}" id="_14929" smilref="Title.smil#_14929"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_14930" smilref="Title.smil#_14930"> s</p><p attribs="{'xml:space': 'preserve'}" id="_14931" smilref="Title.smil#_14931"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_14932" smilref="Title.smil#_14932"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14933" smilref="Title.smil#_14933"> b</p><p attribs="{'xml:space': 'preserve'}" id="_14934" smilref="Title.smil#_14934"> f</p><p attribs="{'xml:space': 'preserve'}" id="_14935" smilref="Title.smil#_14935"> h</p><p attribs="{'xml:space': 'preserve'}" id="_14936" smilref="Title.smil#_14936"> m</p><p attribs="{'xml:space': 'preserve'}" id="_14937" smilref="Title.smil#_14937"> a</p><p attribs="{'xml:space': 'preserve'}" id="_14938" smilref="Title.smil#_14938"> t</p><p attribs="{'xml:space': 'preserve'}" id="_14939" smilref="Title.smil#_14939"> r</p><p attribs="{'xml:space': 'preserve'}" id="_14940" smilref="Title.smil#_14940"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_14941" smilref="Title.smil#_14941"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14942" smilref="Title.smil#_14942"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14943" smilref="Title.smil#_14943"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_14944" smilref="Title.smil#_14944"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14945" smilref="Title.smil#_14945"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14946" smilref="Title.smil#_14946"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14947" smilref="Title.smil#_14947"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14948" smilref="Title.smil#_14948"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14949" smilref="Title.smil#_14949"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14950" smilref="Title.smil#_14950"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14951" smilref="Title.smil#_14951"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14952" smilref="Title.smil#_14952"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14953" smilref="Title.smil#_14953"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14954" smilref="Title.smil#_14954"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14955" smilref="Title.smil#_14955"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14956" smilref="Title.smil#_14956"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14957" smilref="Title.smil#_14957"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14958" smilref="Title.smil#_14958"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14959" smilref="Title.smil#_14959"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14960" smilref="Title.smil#_14960"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14961" smilref="Title.smil#_14961"> 1313</p><p attribs="{'xml:space': 'preserve'}" id="_14962" smilref="Title.smil#_14962"> 1616</p><p attribs="{'xml:space': 'preserve'}" id="_14963" smilref="Title.smil#_14963"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14964" smilref="Title.smil#_14964"> e</p><p attribs="{'xml:space': 'preserve'}" id="_14965" smilref="Title.smil#_14965"> w</p><p attribs="{'xml:space': 'preserve'}" id="_14966" smilref="Title.smil#_14966"> o</p><p attribs="{'xml:space': 'preserve'}" id="_14967" smilref="Title.smil#_14967"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_14968" smilref="Title.smil#_14968"> s</p><p attribs="{'xml:space': 'preserve'}" id="_14969" smilref="Title.smil#_14969"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_14970" smilref="Title.smil#_14970"> i</p><p attribs="{'xml:space': 'preserve'}" id="_14971" smilref="Title.smil#_14971"> b</p><p attribs="{'xml:space': 'preserve'}" id="_14972" smilref="Title.smil#_14972"> f</p><p attribs="{'xml:space': 'preserve'}" id="_14973" smilref="Title.smil#_14973"> h</p><p attribs="{'xml:space': 'preserve'}" id="_14974" smilref="Title.smil#_14974"> m</p><p attribs="{'xml:space': 'preserve'}" id="_14975" smilref="Title.smil#_14975"> a</p><p attribs="{'xml:space': 'preserve'}" id="_14976" smilref="Title.smil#_14976"> t</p><p attribs="{'xml:space': 'preserve'}" id="_14977" smilref="Title.smil#_14977"> r</p><p attribs="{'xml:space': 'preserve'}" id="_14978" smilref="Title.smil#_14978"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_14979" smilref="Title.smil#_14979"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14980" smilref="Title.smil#_14980"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_14981" smilref="Title.smil#_14981"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_14982" smilref="Title.smil#_14982"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14983" smilref="Title.smil#_14983"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_14984" smilref="Title.smil#_14984"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14985" smilref="Title.smil#_14985"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14986" smilref="Title.smil#_14986"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14987" smilref="Title.smil#_14987"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14988" smilref="Title.smil#_14988"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_14989" smilref="Title.smil#_14989"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_14990" smilref="Title.smil#_14990"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14991" smilref="Title.smil#_14991"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14992" smilref="Title.smil#_14992"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14993" smilref="Title.smil#_14993"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14994" smilref="Title.smil#_14994"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14995" smilref="Title.smil#_14995"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_14996" smilref="Title.smil#_14996"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14997" smilref="Title.smil#_14997"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_14998" smilref="Title.smil#_14998"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_14999" smilref="Title.smil#_14999"> 1313</p><p attribs="{'xml:space': 'preserve'}" id="_15000" smilref="Title.smil#_15000"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15001" smilref="Title.smil#_15001"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15002" smilref="Title.smil#_15002"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15003" smilref="Title.smil#_15003"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15004" smilref="Title.smil#_15004"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15005" smilref="Title.smil#_15005"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15006" smilref="Title.smil#_15006"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15007" smilref="Title.smil#_15007"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15008" smilref="Title.smil#_15008"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15009" smilref="Title.smil#_15009"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15010" smilref="Title.smil#_15010"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15011" smilref="Title.smil#_15011"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15012" smilref="Title.smil#_15012"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15013" smilref="Title.smil#_15013"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15014" smilref="Title.smil#_15014"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_15015" smilref="Title.smil#_15015"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15016" smilref="Title.smil#_15016"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15017" smilref="Title.smil#_15017"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15018" smilref="Title.smil#_15018"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15019" smilref="Title.smil#_15019"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15020" smilref="Title.smil#_15020"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15021" smilref="Title.smil#_15021"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15022" smilref="Title.smil#_15022"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15023" smilref="Title.smil#_15023"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15024" smilref="Title.smil#_15024"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15025" smilref="Title.smil#_15025"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15026" smilref="Title.smil#_15026"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15027" smilref="Title.smil#_15027"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15028" smilref="Title.smil#_15028"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15029" smilref="Title.smil#_15029"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15030" smilref="Title.smil#_15030"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15031" smilref="Title.smil#_15031"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15032" smilref="Title.smil#_15032"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15033" smilref="Title.smil#_15033"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15034" smilref="Title.smil#_15034"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15035" smilref="Title.smil#_15035"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_15036" smilref="Title.smil#_15036"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15037" smilref="Title.smil#_15037"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15038" smilref="Title.smil#_15038"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15039" smilref="Title.smil#_15039"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15040" smilref="Title.smil#_15040"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15041" smilref="Title.smil#_15041"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15042" smilref="Title.smil#_15042"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15043" smilref="Title.smil#_15043"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15044" smilref="Title.smil#_15044"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15045" smilref="Title.smil#_15045"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15046" smilref="Title.smil#_15046"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15047" smilref="Title.smil#_15047"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15048" smilref="Title.smil#_15048"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15049" smilref="Title.smil#_15049"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15050" smilref="Title.smil#_15050"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15051" smilref="Title.smil#_15051"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15052" smilref="Title.smil#_15052"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15053" smilref="Title.smil#_15053"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15054" smilref="Title.smil#_15054"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15055" smilref="Title.smil#_15055"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15056" smilref="Title.smil#_15056"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15057" smilref="Title.smil#_15057"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15058" smilref="Title.smil#_15058"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15059" smilref="Title.smil#_15059"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15060" smilref="Title.smil#_15060"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15061" smilref="Title.smil#_15061"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15062" smilref="Title.smil#_15062"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15063" smilref="Title.smil#_15063"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15064" smilref="Title.smil#_15064"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15065" smilref="Title.smil#_15065"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15066" smilref="Title.smil#_15066"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15067" smilref="Title.smil#_15067"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15068" smilref="Title.smil#_15068"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15069" smilref="Title.smil#_15069"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15070" smilref="Title.smil#_15070"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15071" smilref="Title.smil#_15071"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15072" smilref="Title.smil#_15072"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15073" smilref="Title.smil#_15073"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15074" smilref="Title.smil#_15074"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15075" smilref="Title.smil#_15075"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15076" smilref="Title.smil#_15076"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15077" smilref="Title.smil#_15077"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15078" smilref="Title.smil#_15078"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15079" smilref="Title.smil#_15079"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15080" smilref="Title.smil#_15080"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15081" smilref="Title.smil#_15081"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15082" smilref="Title.smil#_15082"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15083" smilref="Title.smil#_15083"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15084" smilref="Title.smil#_15084"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15085" smilref="Title.smil#_15085"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15086" smilref="Title.smil#_15086"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15087" smilref="Title.smil#_15087"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15088" smilref="Title.smil#_15088"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15089" smilref="Title.smil#_15089"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15090" smilref="Title.smil#_15090"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15091" smilref="Title.smil#_15091"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15092" smilref="Title.smil#_15092"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15093" smilref="Title.smil#_15093"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15094" smilref="Title.smil#_15094"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15095" smilref="Title.smil#_15095"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15096" smilref="Title.smil#_15096"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15097" smilref="Title.smil#_15097"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15098" smilref="Title.smil#_15098"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15099" smilref="Title.smil#_15099"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15100" smilref="Title.smil#_15100"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15101" smilref="Title.smil#_15101"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15102" smilref="Title.smil#_15102"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15103" smilref="Title.smil#_15103"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15104" smilref="Title.smil#_15104"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15105" smilref="Title.smil#_15105"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15106" smilref="Title.smil#_15106"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15107" smilref="Title.smil#_15107"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15108" smilref="Title.smil#_15108"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15109" smilref="Title.smil#_15109"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15110" smilref="Title.smil#_15110"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15111" smilref="Title.smil#_15111"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15112" smilref="Title.smil#_15112"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15113" smilref="Title.smil#_15113"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15114" smilref="Title.smil#_15114"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15115" smilref="Title.smil#_15115"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15116" smilref="Title.smil#_15116"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15117" smilref="Title.smil#_15117"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15118" smilref="Title.smil#_15118"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15119" smilref="Title.smil#_15119"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15120" smilref="Title.smil#_15120"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15121" smilref="Title.smil#_15121"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15122" smilref="Title.smil#_15122"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15123" smilref="Title.smil#_15123"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15124" smilref="Title.smil#_15124"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15125" smilref="Title.smil#_15125"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15126" smilref="Title.smil#_15126"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15127" smilref="Title.smil#_15127"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15128" smilref="Title.smil#_15128"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15129" smilref="Title.smil#_15129"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15130" smilref="Title.smil#_15130"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15131" smilref="Title.smil#_15131"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15132" smilref="Title.smil#_15132"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15133" smilref="Title.smil#_15133"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15134" smilref="Title.smil#_15134"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15135" smilref="Title.smil#_15135"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15136" smilref="Title.smil#_15136"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15137" smilref="Title.smil#_15137"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15138" smilref="Title.smil#_15138"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15139" smilref="Title.smil#_15139"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15140" smilref="Title.smil#_15140"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15141" smilref="Title.smil#_15141"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15142" smilref="Title.smil#_15142"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15143" smilref="Title.smil#_15143"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15144" smilref="Title.smil#_15144"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15145" smilref="Title.smil#_15145"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15146" smilref="Title.smil#_15146"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15147" smilref="Title.smil#_15147"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15148" smilref="Title.smil#_15148"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15149" smilref="Title.smil#_15149"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15150" smilref="Title.smil#_15150"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15151" smilref="Title.smil#_15151"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15152" smilref="Title.smil#_15152"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15153" smilref="Title.smil#_15153"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15154" smilref="Title.smil#_15154"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15155" smilref="Title.smil#_15155"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15156" smilref="Title.smil#_15156"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15157" smilref="Title.smil#_15157"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15158" smilref="Title.smil#_15158"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15159" smilref="Title.smil#_15159"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15160" smilref="Title.smil#_15160"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15161" smilref="Title.smil#_15161"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15162" smilref="Title.smil#_15162"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15163" smilref="Title.smil#_15163"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15164" smilref="Title.smil#_15164"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15165" smilref="Title.smil#_15165"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15166" smilref="Title.smil#_15166"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15167" smilref="Title.smil#_15167"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15168" smilref="Title.smil#_15168"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15169" smilref="Title.smil#_15169"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15170" smilref="Title.smil#_15170"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15171" smilref="Title.smil#_15171"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15172" smilref="Title.smil#_15172"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15173" smilref="Title.smil#_15173"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15174" smilref="Title.smil#_15174"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15175" smilref="Title.smil#_15175"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15176" smilref="Title.smil#_15176"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15177" smilref="Title.smil#_15177"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15178" smilref="Title.smil#_15178"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15179" smilref="Title.smil#_15179"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15180" smilref="Title.smil#_15180"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15181" smilref="Title.smil#_15181"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15182" smilref="Title.smil#_15182"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15183" smilref="Title.smil#_15183"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15184" smilref="Title.smil#_15184"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15185" smilref="Title.smil#_15185"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15186" smilref="Title.smil#_15186"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15187" smilref="Title.smil#_15187"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15188" smilref="Title.smil#_15188"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15189" smilref="Title.smil#_15189"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15190" smilref="Title.smil#_15190"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15191" smilref="Title.smil#_15191"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15192" smilref="Title.smil#_15192"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15193" smilref="Title.smil#_15193"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15194" smilref="Title.smil#_15194"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15195" smilref="Title.smil#_15195"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15196" smilref="Title.smil#_15196"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15197" smilref="Title.smil#_15197"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15198" smilref="Title.smil#_15198"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15199" smilref="Title.smil#_15199"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15200" smilref="Title.smil#_15200"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15201" smilref="Title.smil#_15201"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15202" smilref="Title.smil#_15202"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15203" smilref="Title.smil#_15203"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15204" smilref="Title.smil#_15204"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15205" smilref="Title.smil#_15205"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15206" smilref="Title.smil#_15206"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15207" smilref="Title.smil#_15207"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15208" smilref="Title.smil#_15208"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15209" smilref="Title.smil#_15209"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15210" smilref="Title.smil#_15210"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15211" smilref="Title.smil#_15211"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15212" smilref="Title.smil#_15212"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15213" smilref="Title.smil#_15213"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15214" smilref="Title.smil#_15214"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15215" smilref="Title.smil#_15215"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15216" smilref="Title.smil#_15216"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15217" smilref="Title.smil#_15217"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15218" smilref="Title.smil#_15218"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15219" smilref="Title.smil#_15219"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15220" smilref="Title.smil#_15220"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15221" smilref="Title.smil#_15221"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15222" smilref="Title.smil#_15222"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15223" smilref="Title.smil#_15223"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15224" smilref="Title.smil#_15224"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15225" smilref="Title.smil#_15225"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15226" smilref="Title.smil#_15226"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15227" smilref="Title.smil#_15227"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15228" smilref="Title.smil#_15228"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15229" smilref="Title.smil#_15229"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15230" smilref="Title.smil#_15230"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15231" smilref="Title.smil#_15231"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15232" smilref="Title.smil#_15232"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15233" smilref="Title.smil#_15233"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15234" smilref="Title.smil#_15234"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15235" smilref="Title.smil#_15235"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15236" smilref="Title.smil#_15236"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15237" smilref="Title.smil#_15237"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15238" smilref="Title.smil#_15238"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15239" smilref="Title.smil#_15239"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15240" smilref="Title.smil#_15240"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15241" smilref="Title.smil#_15241"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15242" smilref="Title.smil#_15242"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15243" smilref="Title.smil#_15243"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15244" smilref="Title.smil#_15244"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15245" smilref="Title.smil#_15245"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15246" smilref="Title.smil#_15246"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15247" smilref="Title.smil#_15247"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15248" smilref="Title.smil#_15248"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15249" smilref="Title.smil#_15249"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15250" smilref="Title.smil#_15250"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15251" smilref="Title.smil#_15251"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15252" smilref="Title.smil#_15252"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15253" smilref="Title.smil#_15253"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15254" smilref="Title.smil#_15254"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15255" smilref="Title.smil#_15255"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15256" smilref="Title.smil#_15256"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15257" smilref="Title.smil#_15257"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15258" smilref="Title.smil#_15258"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_15259" smilref="Title.smil#_15259"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15260" smilref="Title.smil#_15260"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15261" smilref="Title.smil#_15261"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15262" smilref="Title.smil#_15262"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15263" smilref="Title.smil#_15263"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15264" smilref="Title.smil#_15264"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15265" smilref="Title.smil#_15265"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15266" smilref="Title.smil#_15266"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15267" smilref="Title.smil#_15267"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15268" smilref="Title.smil#_15268"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15269" smilref="Title.smil#_15269"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15270" smilref="Title.smil#_15270"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15271" smilref="Title.smil#_15271"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15272" smilref="Title.smil#_15272"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15273" smilref="Title.smil#_15273"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15274" smilref="Title.smil#_15274"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15275" smilref="Title.smil#_15275"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15276" smilref="Title.smil#_15276"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15277" smilref="Title.smil#_15277"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15278" smilref="Title.smil#_15278"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15279" smilref="Title.smil#_15279"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15280" smilref="Title.smil#_15280"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15281" smilref="Title.smil#_15281"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15282" smilref="Title.smil#_15282"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15283" smilref="Title.smil#_15283"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15284" smilref="Title.smil#_15284"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15285" smilref="Title.smil#_15285"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15286" smilref="Title.smil#_15286"> two tries with smallest weights</p><p attribs="{'xml:space': 'preserve'}" id="_15287" smilref="Title.smil#_15287"> new parent for those two tries</p><p attribs="{'xml:space': 'preserve'}" id="_15288" smilref="Title.smil#_15288"> to top of right column</p><p attribs="{'xml:space': 'preserve'}" id="_15289" smilref="Title.smil#_15289"> from bottom of left column</p><p attribs="{'xml:space': 'preserve'}" id="_15290" smilref="Title.smil#_15290"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15291" smilref="Title.smil#_15291" /><pagenum id="p845" page="normal" smilref="Title.smil#p845" /><p attribs="{'xml:space': 'preserve'}" id="_15292" smilref="Title.smil#_15292"> 832</p><p attribs="{'xml:space': 'preserve'}" id="_15293" smilref="Title.smil#_15293"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15294" smilref="Title.smil#_15294"> trie representation</p><p attribs="{'xml:space': 'preserve'}" id="_15295" smilref="Title.smil#_15295"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15296" smilref="Title.smil#_15296"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15297" smilref="Title.smil#_15297"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15298" smilref="Title.smil#_15298"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15299" smilref="Title.smil#_15299"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_15300" smilref="Title.smil#_15300"> SP</p><p attribs="{'xml:space': 'preserve'}" id="_15301" smilref="Title.smil#_15301"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15302" smilref="Title.smil#_15302"> e</p><p attribs="{'xml:space': 'preserve'}" id="_15303" smilref="Title.smil#_15303"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15304" smilref="Title.smil#_15304"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15305" smilref="Title.smil#_15305"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15306" smilref="Title.smil#_15306"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15307" smilref="Title.smil#_15307"> w</p><p attribs="{'xml:space': 'preserve'}" id="_15308" smilref="Title.smil#_15308"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15309" smilref="Title.smil#_15309"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15310" smilref="Title.smil#_15310"> o</p><p attribs="{'xml:space': 'preserve'}" id="_15311" smilref="Title.smil#_15311"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15312" smilref="Title.smil#_15312"> 3 occurrences of w in input</p><p attribs="{'xml:space': 'preserve'}" id="_15313" smilref="Title.smil#_15313"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15314" smilref="Title.smil#_15314"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15315" smilref="Title.smil#_15315"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15316" smilref="Title.smil#_15316"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15317" smilref="Title.smil#_15317"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15318" smilref="Title.smil#_15318"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_15319" smilref="Title.smil#_15319"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15320" smilref="Title.smil#_15320"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15321" smilref="Title.smil#_15321"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15322" smilref="Title.smil#_15322"> r</p><p attribs="{'xml:space': 'preserve'}" id="_15323" smilref="Title.smil#_15323"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15324" smilref="Title.smil#_15324"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15325" smilref="Title.smil#_15325"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15326" smilref="Title.smil#_15326"> i</p><p attribs="{'xml:space': 'preserve'}" id="_15327" smilref="Title.smil#_15327"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15328" smilref="Title.smil#_15328"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15329" smilref="Title.smil#_15329"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15330" smilref="Title.smil#_15330"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15331" smilref="Title.smil#_15331"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15332" smilref="Title.smil#_15332"> b</p><p attribs="{'xml:space': 'preserve'}" id="_15333" smilref="Title.smil#_15333"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15334" smilref="Title.smil#_15334"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15335" smilref="Title.smil#_15335"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15336" smilref="Title.smil#_15336"> t</p><p attribs="{'xml:space': 'preserve'}" id="_15337" smilref="Title.smil#_15337"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15338" smilref="Title.smil#_15338"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15339" smilref="Title.smil#_15339"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15340" smilref="Title.smil#_15340"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15341" smilref="Title.smil#_15341"> f</p><p attribs="{'xml:space': 'preserve'}" id="_15342" smilref="Title.smil#_15342"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15343" smilref="Title.smil#_15343"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15344" smilref="Title.smil#_15344"> h</p><p attribs="{'xml:space': 'preserve'}" id="_15345" smilref="Title.smil#_15345"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15346" smilref="Title.smil#_15346"> m</p><p attribs="{'xml:space': 'preserve'}" id="_15347" smilref="Title.smil#_15347"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15348" smilref="Title.smil#_15348"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15349" smilref="Title.smil#_15349"> a</p><p attribs="{'xml:space': 'preserve'}" id="_15350" smilref="Title.smil#_15350"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15351" smilref="Title.smil#_15351"> labels on path from root are 11010 so 11010 is code for m</p><p attribs="{'xml:space': 'preserve'}" id="_15352" smilref="Title.smil#_15352"> codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_15353" smilref="Title.smil#_15353"> key LF SP</p><p attribs="{'xml:space': 'preserve'}" id="_15354" smilref="Title.smil#_15354"> a b e f h i m o r s t w</p><p attribs="{'xml:space': 'preserve'}" id="_15355" smilref="Title.smil#_15355"> value</p><p attribs="{'xml:space': 'preserve'}" id="_15356" smilref="Title.smil#_15356"> 101010 01 11011 101011 000 11000 11001 1011 11010 0011 10100 100 111 0010</p><p attribs="{'xml:space': 'preserve'}" id="_15357" smilref="Title.smil#_15357"> Huffman code for the character stream &#8220;it was the best of times it was the worst of times LF&#8221;</p><p attribs="{'xml:space': 'preserve'}" id="_15358" smilref="Title.smil#_15358"> nodes are combined together into a single trie. The leaves in this trie have the characters to be encoded and their frequencies in the input; each non-leaf node is the sum of the frequencies of its two children. Nodes with low frequencies end up far down in the trie, and nodes with high frequencies end up near the root of the trie. The frequency in the root equals the number of characters in the input. Since it is a binary trie with characters only in its leaves, it defines a pre&#64257; x-free code for the characters. Using the codeword table created by buildCode() for this example (shown at right in the diagram at the top of this page), we get the output bitstring</p><p attribs="{'xml:space': 'preserve'}" id="_15359" smilref="Title.smil#_15359"> 1 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 - 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 - 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 - 0 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 .</p><p attribs="{'xml:space': 'preserve'}" id="_15360" smilref="Title.smil#_15360"> which is 176 bits, a savings of 57 percent over the 408 bits needed to encode the 51 characters in standard 8-bit ASCII (not counting the cost of including the code, which we will soon consider). Moreover, since it is a Huffman code, no other pre&#64257; x-free code can encode the input with fewer bits.</p><p attribs="{'xml:space': 'preserve'}" id="_15361" smilref="Title.smil#_15361"> Optimality. We have observed that high-frequency characters are nearer the root of the tree than lower-frequency characters and are therefore encoded with fewer bits, so this is a good code, but why is it an optimal pre&#64257; x-free code? To answer this question, we begin by defining the weighted external path length of a tree to be the sum of the weight (associated frequency count) times depth (see page 226) of all of the leaves.</p><p attribs="{'xml:space': 'preserve'}" id="_15362" smilref="Title.smil#_15362" /><pagenum id="p846" page="normal" smilref="Title.smil#p846" /><p attribs="{'xml:space': 'preserve'}" id="_15363" smilref="Title.smil#_15363"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15364" smilref="Title.smil#_15364"> 833</p><p attribs="{'xml:space': 'preserve'}" id="_15365" smilref="Title.smil#_15365"> Proposition T. For any pre&#64257; x-free code, the length of the encoded bitstring is equal to the weighted external path length of the corresponding trie.</p><p attribs="{'xml:space': 'preserve'}" id="_15366" smilref="Title.smil#_15366"> Proof : The depth of each leaf is the number of bits used to encode the character in the leaf. Thus, the weighted external path length is the length of encoded bitstring : it is equivalent to the sum over all letters of the number of occurrences times the number of bits per occurrence.</p><p attribs="{'xml:space': 'preserve'}" id="_15367" smilref="Title.smil#_15367"> For our example, there is one leaf at distance 2 (SP, with frequency 11), three leaves at distance 3 (e, s, and t, with total frequency 19), three leaves at distance 4 (w, o, and i, with total frequency 10), five leaves at distance 5 (r, f, h, m, and a, with total frequency 9) and two leaves at distance 6 (LF and b, with total frequency 2), so the sum total is 2&#183;11 &#11001; 3&#183;19 &#11001; 4&#183;10 &#11001; 5&#183;9 &#11001; 6&#183;2 &#11005;176, the length of the output bitstring, as expected.</p><p attribs="{'xml:space': 'preserve'}" id="_15368" smilref="Title.smil#_15368"> Proposition U. Given a set of r symbols and frequencies, the Huffman algorithm builds an optimal pre&#64257; x-free code.</p><p attribs="{'xml:space': 'preserve'}" id="_15369" smilref="Title.smil#_15369"> Proof : By induction on r. Assume that the Huffman code is optimal for any set of fewer than r symbols. Let TH be the code computed by Huffman for the set of symbols and associated frequencies (s1, r1), . . . , (sr , fr) and denote the length of the code (weighted external path length of the trie) by W(TH). Suppose that (si , fi) and (sj, fj) are the first two symbols chosen. The algorithm then computes the code TH* for the set of n&#11002;1 symbols with (si , fi) and (si , fj) replaced by (s*, fi + fj) where s* is a new symbol in a leaf at some depth d. Note that W(TH) = W(TH*) &#11002; d( fi + fj) + (d + 1)( fi + fj ) = W(TH*) + (fi + fj ) Now consider an optimal trie T for (s1, r1), . . . , (sr , fr), of height h. Note that that (si , fi) and (sj , fj) must be at depth h (else we could make a trie with lower external path length by swapping them with nodes at depth h). Also, assume (si , fi) and (sj, fj) are siblings by swapping (sj, fj) with (si , fi)&#8217;s sibling. Now consider the tree T* obtained by replacing their parent with (s*, fi + fj ). Note that (by the same argument as above) W(T ) = W(T*) + (fi + fj). By the inductive hypothesis TH* is optimal: W(TH*) &#11349; W(T*). Therefore, W(TH) = W(TH*) + ( fi + fj ) &#11349; W(T*) + ( fi + fj ) = W(T ) Since T is optimal, equality must hold, and TH is optimal.</p><p attribs="{'xml:space': 'preserve'}" id="_15370" smilref="Title.smil#_15370" /><pagenum id="p847" page="normal" smilref="Title.smil#p847" /><p attribs="{'xml:space': 'preserve'}" id="_15371" smilref="Title.smil#_15371"> 834</p><p attribs="{'xml:space': 'preserve'}" id="_15372" smilref="Title.smil#_15372"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15373" smilref="Title.smil#_15373"> Whenever a node is to be picked, it can be the case that there are several nodes with the same weight. Huffman&#8217;s method does not specify how such ties are to be broken. It also does not specify the left/right positions of the children. Different choices lead to different Huffman codes, but all such codes will encode the message with the optimal number of bits among pre&#64257; x-free codes.</p><p attribs="{'xml:space': 'preserve'}" id="_15374" smilref="Title.smil#_15374"> preorder traversal</p><p attribs="{'xml:space': 'preserve'}" id="_15375" smilref="Title.smil#_15375"> A</p><p attribs="{'xml:space': 'preserve'}" id="_15376" smilref="Title.smil#_15376"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15377" smilref="Title.smil#_15377"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15378" smilref="Title.smil#_15378"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15379" smilref="Title.smil#_15379"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15380" smilref="Title.smil#_15380"> leaves</p><p attribs="{'xml:space': 'preserve'}" id="_15381" smilref="Title.smil#_15381"> A</p><p attribs="{'xml:space': 'preserve'}" id="_15382" smilref="Title.smil#_15382"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15383" smilref="Title.smil#_15383"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_15384" smilref="Title.smil#_15384"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_15385" smilref="Title.smil#_15385"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15386" smilref="Title.smil#_15386"> 01010000010010100010001000010101010000110101010010101000010</p><p attribs="{'xml:space': 'preserve'}" id="_15387" smilref="Title.smil#_15387"> D</p><p attribs="{'xml:space': 'preserve'}" id="_15388" smilref="Title.smil#_15388"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15389" smilref="Title.smil#_15389"> R</p><p attribs="{'xml:space': 'preserve'}" id="_15390" smilref="Title.smil#_15390"> B</p><p attribs="{'xml:space': 'preserve'}" id="_15391" smilref="Title.smil#_15391"> Writing and reading the trie. As we</p><p attribs="{'xml:space': 'preserve'}" id="_15392" smilref="Title.smil#_15392"> Using preorder traversal to encode a trie as a bitstream</p><p attribs="{'xml:space': 'preserve'}" id="_15393" smilref="Title.smil#_15393"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_15394" smilref="Title.smil#_15394"> R</p><p attribs="{'xml:space': 'preserve'}" id="_15395" smilref="Title.smil#_15395"> B</p><p attribs="{'xml:space': 'preserve'}" id="_15396" smilref="Title.smil#_15396"> D</p><p attribs="{'xml:space': 'preserve'}" id="_15397" smilref="Title.smil#_15397"> C</p><p attribs="{'xml:space': 'preserve'}" id="_15398" smilref="Title.smil#_15398"> C</p><p attribs="{'xml:space': 'preserve'}" id="_15399" smilref="Title.smil#_15399"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15400" smilref="Title.smil#_15400"> LF</p><p attribs="{'xml:space': 'preserve'}" id="_15401" smilref="Title.smil#_15401"> internal nodes</p><p attribs="{'xml:space': 'preserve'}" id="_15402" smilref="Title.smil#_15402"> have emphasized, the savings figure quoted above is not entirely accurate, because the compressed bitstream cannot be encoded without the trie, so we must account for the cost of including the trie in the compressed output, along with the bitstring. For long inputs, this cost is relatively small, but in order for us to have a full data-compression scheme, we must write the trie onto a bitstream when compressing and read it back when expanding. How can we encode a trie as a bitstream, and then expand it? Remarkably, both tasks can be achieved with simple recursive procedures, based on a preorder traversal of the trie. The procedure writeTrie() below traverses a trie in preorder: when it visits an internal node, it writes a single 0 bit; when it visits a leaf, it writes a 1 bit, followed by the 8-bit ASCII code of the character in the leaf. The bitstring encoding of the Huffman trie for our A B R A C A D A B R A ! example is shown above. The first bit is 0, corresponding to the root; since the leaf containing A is encountered next, the next bit is 1, followed by 0100001, the 8-bit ASCII code for A; the next two bits are 0 because two internal nodes are encountered next, and so forth. The corresponding method readTrie() on page 835 reconstructs the trie from the bitstring: it reads a single bit to learn which type of node comes next: if a leaf (the bit is 1) it reads the next character and creates a leaf; if an internal node (the bit is 0) it creates an internal node and</p><p attribs="{'xml:space': 'preserve'}" id="_15403" smilref="Title.smil#_15403"> private static void writeTrie(Node x) { // Write bitstring-encoded trie. if (x.isLeaf()) { BinaryStdOut.write(true); BinaryStdOut.write(x.ch); return; } BinaryStdOut.write(false); writeTrie(x.left); writeTrie(x.right); }</p><p attribs="{'xml:space': 'preserve'}" id="_15404" smilref="Title.smil#_15404"> Writing a trie as a bitstring</p><p attribs="{'xml:space': 'preserve'}" id="_15405" smilref="Title.smil#_15405" /><pagenum id="p848" page="normal" smilref="Title.smil#p848" /><p attribs="{'xml:space': 'preserve'}" id="_15406" smilref="Title.smil#_15406"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15407" smilref="Title.smil#_15407"> 835</p><p attribs="{'xml:space': 'preserve'}" id="_15408" smilref="Title.smil#_15408"> private static Node readTrie() { if (BinaryStdIn.readBoolean()) return new Node(BinaryStdIn.readChar(), 0, null, null); return new Node('(cid:0)', 0, readTrie(), readTrie()); }</p><p attribs="{'xml:space': 'preserve'}" id="_15409" smilref="Title.smil#_15409"> Reconstructing a trie from the preorder bitstring representation</p><p attribs="{'xml:space': 'preserve'}" id="_15410" smilref="Title.smil#_15410"> then (recursively) builds its left and right subtrees. Be sure that you understand these methods: their simplicity is somewhat deceiving.</p><p attribs="{'xml:space': 'preserve'}" id="_15411" smilref="Title.smil#_15411"> Huffman compression implementation. Along with the methods buildCode(),</p><p attribs="{'xml:space': 'preserve'}" id="_15412" smilref="Title.smil#_15412"> buildTrie(), readTrie() and writeTrie() that we have just considered (and the expand() method that we considered fi rst), Algorithm 5.10 is a complete implementation of Huffman compression. To expand the overview that we considered several pages earlier, we view the bitstream to be encoded as a stream of 8-bit char values and compress it as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_15413" smilref="Title.smil#_15413" /><pagenum id="p849" page="normal" smilref="Title.smil#p849" /><p attribs="{'xml:space': 'preserve'}" id="_15414" smilref="Title.smil#_15414"> 836</p><p attribs="{'xml:space': 'preserve'}" id="_15415" smilref="Title.smil#_15415"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15416" smilref="Title.smil#_15416"> ALGORITHM 5.10 Huffman compression</p><p attribs="{'xml:space': 'preserve'}" id="_15417" smilref="Title.smil#_15417"> public class Huffman { private static int R = 256; // ASCII alphabet // See page 828 for inner Node class. // See text for helper methods and expand().</p><p attribs="{'xml:space': 'preserve'}" id="_15418" smilref="Title.smil#_15418"> public static void compress() { // Read input. String s = BinaryStdIn.readString(); char[] input = s.toCharArray();</p><p attribs="{'xml:space': 'preserve'}" id="_15419" smilref="Title.smil#_15419"> // Tabulate frequency counts. int[] freq = new int[R]; for (int i = 0; i &lt; input.length; i++) freq[input[i]]++;</p><p attribs="{'xml:space': 'preserve'}" id="_15420" smilref="Title.smil#_15420"> // Build Huffman code trie. Node root = buildTrie(freq);</p><p attribs="{'xml:space': 'preserve'}" id="_15421" smilref="Title.smil#_15421"> // Build code table (recursive). String[] st = new String[R]; buildCode(st, root, "");</p><p attribs="{'xml:space': 'preserve'}" id="_15422" smilref="Title.smil#_15422"> // Print trie for decoder (recursive). writeTrie(root);</p><p attribs="{'xml:space': 'preserve'}" id="_15423" smilref="Title.smil#_15423"> // Print number of chars. BinaryStdOut.write(input.length);</p><p attribs="{'xml:space': 'preserve'}" id="_15424" smilref="Title.smil#_15424"> // Use Huffman code to encode input. for (int i = 0; i &lt; input.length; i++) { String code = st[input[i]]; for (int j = 0; j &lt; code.length(); j++) if (code.charAt(j) == '1') BinaryStdOut.write(true); else BinaryStdOut.write(false); } BinaryStdOut.close(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_15425" smilref="Title.smil#_15425"> This implementation of Huffman encoding builds an explicit coding trie, using various helper methods that are presented and explained in the last several pages of text.</p><p attribs="{'xml:space': 'preserve'}" id="_15426" smilref="Title.smil#_15426" /><pagenum id="p850" page="normal" smilref="Title.smil#p850" /><p attribs="{'xml:space': 'preserve'}" id="_15427" smilref="Title.smil#_15427"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15428" smilref="Title.smil#_15428"> 837</p><p attribs="{'xml:space': 'preserve'}" id="_15429" smilref="Title.smil#_15429"> test case (96 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15430" smilref="Title.smil#_15430"> % more abra.txt ABRACADABRA!</p><p attribs="{'xml:space': 'preserve'}" id="_15431" smilref="Title.smil#_15431"> % java Huffman - &lt; abra.txt | java BinaryDump 60 010100000100101000100010000101010100001101010100101010000100 000000000000000000000000000110001111100101101000111110010100 120 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15432" smilref="Title.smil#_15432"> compression ratio 120/96 = 125% due to 59 bits for trie and 32 bits for count</p><p attribs="{'xml:space': 'preserve'}" id="_15433" smilref="Title.smil#_15433"> example from text (408 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15434" smilref="Title.smil#_15434"> % more tinytinyTale.txt it was the best of times it was the worst of times</p><p attribs="{'xml:space': 'preserve'}" id="_15435" smilref="Title.smil#_15435"> % java Huffman - &lt; tinytinyTale.txt | java BinaryDump 64 0001011001010101110111101101111100100000001011100110010111001001 0000101010110001010110100100010110011010110100001011011011011000 0110111010000000000000000000000000000110011101111101001011011100 0111111001000011010110001001110100111100001111101111010000100011 0111110100101101110001111110010000100100011101001001110100111100 00111110111101000010010101000000 352 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15436" smilref="Title.smil#_15436"> compression ratio 352/408 = 86% even with 137 bits for trie and 32 bits for count</p><p attribs="{'xml:space': 'preserve'}" id="_15437" smilref="Title.smil#_15437"> % java Huffman - &lt; tinytinyTale.txt | java Huffman + it was the best of times it was the worst of times</p><p attribs="{'xml:space': 'preserve'}" id="_15438" smilref="Title.smil#_15438"> first chapter of Tale of Two Cities</p><p attribs="{'xml:space': 'preserve'}" id="_15439" smilref="Title.smil#_15439"> % java PictureDump 512 90 &lt; medTale.txt</p><p attribs="{'xml:space': 'preserve'}" id="_15440" smilref="Title.smil#_15440"> 45056 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15441" smilref="Title.smil#_15441"> % java Huffman - &lt; medTale.txt | java PictureDump 512 47</p><p attribs="{'xml:space': 'preserve'}" id="_15442" smilref="Title.smil#_15442"> 23912 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15443" smilref="Title.smil#_15443"> compression ratio 23912/45056 = 53%</p><p attribs="{'xml:space': 'preserve'}" id="_15444" smilref="Title.smil#_15444"> entire text of Tale of Two Cities</p><p attribs="{'xml:space': 'preserve'}" id="_15445" smilref="Title.smil#_15445"> % java BinaryDump 0 &lt; tale.txt 5812552 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15446" smilref="Title.smil#_15446"> % java Huffman - &lt; tale.txt &gt; tale.txt.huf % java BinaryDump 0 &lt; tale.txt.huf 3043928 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15447" smilref="Title.smil#_15447"> compression ratio 3043928/5812552 = 52%</p><p attribs="{'xml:space': 'preserve'}" id="_15448" smilref="Title.smil#_15448"> Compressing and expanding bytestreams with Huffman encoding</p><p attribs="{'xml:space': 'preserve'}" id="_15449" smilref="Title.smil#_15449" /><pagenum id="p851" page="normal" smilref="Title.smil#p851" /><p attribs="{'xml:space': 'preserve'}" id="_15450" smilref="Title.smil#_15450"> 838</p><p attribs="{'xml:space': 'preserve'}" id="_15451" smilref="Title.smil#_15451"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15452" smilref="Title.smil#_15452"> One reason for the popularity of Huffman compression is that it is effective for various types of fi les, not just natural language text. We have been careful to code the method so that it can work properly for any 8-bit value in each 8-bit character. In other words, we can apply it to any bytestream whatsoever. Several examples, for file types that we have considered earlier in this section, are shown in the figure at the bottom of this page. These examples show that Huffman compression is competitive with both fi xed-length encoding and run-length encoding, even though those methods are designed to perform well for certain types of fi les. Understanding the reason Huff- man encoding performs well in these domains is instructive. In the case of genomic data, Huffman compression essentially discovers a 2-bit code, as the four letters appear with approximately equal frequency so that the Huffman trie is balanced, with each character assigned a 2-bit code. In the case of run-length encoding, 0 0 0 0 0 0 0 0 and 1 1 1 1 1 1 1 1 are likely to be the most frequently occurring characters, so they are likely to be encoded with 2 or 3 bits, leading to substantial compression.</p><p attribs="{'xml:space': 'preserve'}" id="_15453" smilref="Title.smil#_15453"> virus (50000 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15454" smilref="Title.smil#_15454"> % java Genome - &lt; genomeVirus.txt | java PictureDump 512 25</p><p attribs="{'xml:space': 'preserve'}" id="_15455" smilref="Title.smil#_15455"> 12536 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15456" smilref="Title.smil#_15456"> % java Huffman - &lt; genomeVirus.txt | java PictureDump 512 25</p><p attribs="{'xml:space': 'preserve'}" id="_15457" smilref="Title.smil#_15457"> 12576 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15458" smilref="Title.smil#_15458"> Huffman compression needs just 40 more bits than custom 2-bit code</p><p attribs="{'xml:space': 'preserve'}" id="_15459" smilref="Title.smil#_15459"> bitmap (1536 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15460" smilref="Title.smil#_15460"> % java RunLength - &lt; q32x48.bin | java BinaryDump 0 1144 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15461" smilref="Title.smil#_15461"> % java Huffman - &lt; q32x48.bin | java BinaryDump 0 816 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15462" smilref="Title.smil#_15462"> Huffman compression uses 29% fewer bits than customized method</p><p attribs="{'xml:space': 'preserve'}" id="_15463" smilref="Title.smil#_15463"> higher-resolution bitmap (6144 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15464" smilref="Title.smil#_15464"> % java RunLength - &lt; q64x96.bin | java BinaryDump 0 2296 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15465" smilref="Title.smil#_15465"> % java Huffman - &lt; q64x96.bin | java BinaryDump 0 2032 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15466" smilref="Title.smil#_15466"> gap narrows to 11% for higher resolution</p><p attribs="{'xml:space': 'preserve'}" id="_15467" smilref="Title.smil#_15467"> Compressing and expanding genomic data and bitmaps with Huffman encoding</p><p attribs="{'xml:space': 'preserve'}" id="_15468" smilref="Title.smil#_15468" /></level3><level3 id="_00118"><h3 id="ch5-s5-ss22" smilref="Title.smil#ch5-s5-ss22" xml:space="preserve">LZW compression</h3><pagenum id="p852" page="normal" smilref="Title.smil#p852" /><p attribs="{'xml:space': 'preserve'}" id="_15469" smilref="Title.smil#_15469"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15470" smilref="Title.smil#_15470"> 839</p><p attribs="{'xml:space': 'preserve'}" id="_15471" smilref="Title.smil#_15471"> A remarkable alternative to Huffman compression that was developed in the late 1970s and the early 1980s by A. Lempel, J. Ziv, and T. Welch has emerged as one of the most widely used compression methods because it is easy to implement and works well for a variety of file types. The basic plan complements the basic plan for Huffman coding. Rather than maintain a table of variable-length codewords for fi xed-length patterns in the input, we maintain a table of fi xed-length codewords for variable-length patterns in the input. A surprising added feature of the method is that, by contrast with Huffman encoding, we do not have to encode the table.</p><p attribs="{'xml:space': 'preserve'}" id="_15472" smilref="Title.smil#_15472"> LZW compression. To fix ideas, we will consider a compression example where we read the input as a stream of 7-bit ASCII characters and write the output as a stream of 8-bit bytes. (In practice, we typically use larger values for these parameters&#8212;our implementations use 8-bit inputs and 12-bit outputs.) We refer to input bytes as char- acters, sequences of input bytes as strings, and output bytes as codewords, even though these terms have slightly different meanings in other contexts. The LZW compression algorithm is based on maintaining a symbol table that associates string keys with (&#64257; xed-length) codeword values. We initialize the symbol table with the 128 possible single-character string keys and associate them with 8-bit codewords obtained by prepending 0 to the 7-bit value defining each character. For economy and clarity, we use hexadecimal to refer to codeword values, so 41 is the codeword for ASCII A, 52 for R, and so forth. We reserve the codeword 80 to signify end of fi le. We will assign the rest of the codeword values (81 through FF) to various substrings of the input that we encoun- ter, by starting at 81 and incrementing the value for each new key added. To compress, we perform the following steps as long as there are unscanned input characters: </p><p attribs="{'xml:space': 'preserve'}" id="_15473" smilref="Title.smil#_15473" /><pagenum id="p853" page="normal" smilref="Title.smil#p853" /><p attribs="{'xml:space': 'preserve'}" id="_15474" smilref="Title.smil#_15474"> 840</p><p attribs="{'xml:space': 'preserve'}" id="_15475" smilref="Title.smil#_15475"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15476" smilref="Title.smil#_15476"> LZW compression example. The figure below gives details of the operation of LZW compression for the example input A B R A C A D A B R A B R A B R A. For the first seven characters, the longest prefix match is just one character, so we output the codeword associated with the character and associate the codewords from 81 through 87 to two- character strings. Then we find prefix matches with AB (so we output 81 and add ABR to the table), RA (so we output 83 and add RAB to the table), BR (so we output 82 and add BRA to the table), and ABR (so we output 88 and add ABRA to the table), leaving the last A (so we output its codeword, 41).</p><p attribs="{'xml:space': 'preserve'}" id="_15477" smilref="Title.smil#_15477"> input</p><p attribs="{'xml:space': 'preserve'}" id="_15478" smilref="Title.smil#_15478"> matches</p><p attribs="{'xml:space': 'preserve'}" id="_15479" smilref="Title.smil#_15479"> output</p><p attribs="{'xml:space': 'preserve'}" id="_15480" smilref="Title.smil#_15480"> A B R A C A D A B R A B R A B R A A B R A C A D A B R A B R A B R A 41 42 52 41 43 41 44 81 83 82 88 41 80</p><p attribs="{'xml:space': 'preserve'}" id="_15481" smilref="Title.smil#_15481"> EOF</p><p attribs="{'xml:space': 'preserve'}" id="_15482" smilref="Title.smil#_15482"> A B 81</p><p attribs="{'xml:space': 'preserve'}" id="_15483" smilref="Title.smil#_15483"> A B B R 82</p><p attribs="{'xml:space': 'preserve'}" id="_15484" smilref="Title.smil#_15484"> input substring</p><p attribs="{'xml:space': 'preserve'}" id="_15485" smilref="Title.smil#_15485"> A B B R R A 83</p><p attribs="{'xml:space': 'preserve'}" id="_15486" smilref="Title.smil#_15486"> A B B R R A A C 84</p><p attribs="{'xml:space': 'preserve'}" id="_15487" smilref="Title.smil#_15487"> LZW codeword</p><p attribs="{'xml:space': 'preserve'}" id="_15488" smilref="Title.smil#_15488"> A B B R R A A C C A 85</p><p attribs="{'xml:space': 'preserve'}" id="_15489" smilref="Title.smil#_15489"> A B B R R A A C C A A D 86</p><p attribs="{'xml:space': 'preserve'}" id="_15490" smilref="Title.smil#_15490"> lookahead character</p><p attribs="{'xml:space': 'preserve'}" id="_15491" smilref="Title.smil#_15491"> A B B R R A A C C A A D D A 87</p><p attribs="{'xml:space': 'preserve'}" id="_15492" smilref="Title.smil#_15492"> A B B R R A A C C A A D D A A BR 88</p><p attribs="{'xml:space': 'preserve'}" id="_15493" smilref="Title.smil#_15493"> A B B R R A A C C A A D D A A B R R AB 89</p><p attribs="{'xml:space': 'preserve'}" id="_15494" smilref="Title.smil#_15494"> A B B R R A A C C A A D D A A B R R A B B RA 8A</p><p attribs="{'xml:space': 'preserve'}" id="_15495" smilref="Title.smil#_15495"> LZW compression for A B R A C A D A B R A B R A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15496" smilref="Title.smil#_15496"> A B B R R A A C C A A D D A A B R R A B B R A A B RA 8B</p><p attribs="{'xml:space': 'preserve'}" id="_15497" smilref="Title.smil#_15497"> codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_15498" smilref="Title.smil#_15498"> key</p><p attribs="{'xml:space': 'preserve'}" id="_15499" smilref="Title.smil#_15499"> value</p><p attribs="{'xml:space': 'preserve'}" id="_15500" smilref="Title.smil#_15500"> A B B R R A A C C A A D D A A B R R A B B R A A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15501" smilref="Title.smil#_15501"> 81 82 83 84 85 86 87 88 89 8A 8B</p><p attribs="{'xml:space': 'preserve'}" id="_15502" smilref="Title.smil#_15502"> The input is 17 ASCII characters of 7 bits each for a total of 119 bits; the output is 12 codewords of 8 bits each for a total of 96 bits&#8212;a compression ratio of 82 percent even for this tiny example.</p><p attribs="{'xml:space': 'preserve'}" id="_15503" smilref="Title.smil#_15503"> LZW trie representation. LZW compression involves two symbol-table operations: </p><p attribs="{'xml:space': 'preserve'}" id="_15504" smilref="Title.smil#_15504"> Trie representation of LZW code table</p><p attribs="{'xml:space': 'preserve'}" id="_15505" smilref="Title.smil#_15505"> 81</p><p attribs="{'xml:space': 'preserve'}" id="_15506" smilref="Title.smil#_15506"> CC</p><p attribs="{'xml:space': 'preserve'}" id="_15507" smilref="Title.smil#_15507"> 43</p><p attribs="{'xml:space': 'preserve'}" id="_15508" smilref="Title.smil#_15508"> BB</p><p attribs="{'xml:space': 'preserve'}" id="_15509" smilref="Title.smil#_15509"> 42</p><p attribs="{'xml:space': 'preserve'}" id="_15510" smilref="Title.smil#_15510"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15511" smilref="Title.smil#_15511"> 87</p><p attribs="{'xml:space': 'preserve'}" id="_15512" smilref="Title.smil#_15512"> RR</p><p attribs="{'xml:space': 'preserve'}" id="_15513" smilref="Title.smil#_15513"> 82</p><p attribs="{'xml:space': 'preserve'}" id="_15514" smilref="Title.smil#_15514"> DD</p><p attribs="{'xml:space': 'preserve'}" id="_15515" smilref="Title.smil#_15515"> 86</p><p attribs="{'xml:space': 'preserve'}" id="_15516" smilref="Title.smil#_15516"> DD</p><p attribs="{'xml:space': 'preserve'}" id="_15517" smilref="Title.smil#_15517"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_15518" smilref="Title.smil#_15518"> CC</p><p attribs="{'xml:space': 'preserve'}" id="_15519" smilref="Title.smil#_15519"> 84</p><p attribs="{'xml:space': 'preserve'}" id="_15520" smilref="Title.smil#_15520"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15521" smilref="Title.smil#_15521"> 8B</p><p attribs="{'xml:space': 'preserve'}" id="_15522" smilref="Title.smil#_15522"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15523" smilref="Title.smil#_15523"> 85</p><p attribs="{'xml:space': 'preserve'}" id="_15524" smilref="Title.smil#_15524"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15525" smilref="Title.smil#_15525"> 41</p><p attribs="{'xml:space': 'preserve'}" id="_15526" smilref="Title.smil#_15526"> RR</p><p attribs="{'xml:space': 'preserve'}" id="_15527" smilref="Title.smil#_15527"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15528" smilref="Title.smil#_15528"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15529" smilref="Title.smil#_15529"> 8A</p><p attribs="{'xml:space': 'preserve'}" id="_15530" smilref="Title.smil#_15530"> BB</p><p attribs="{'xml:space': 'preserve'}" id="_15531" smilref="Title.smil#_15531"> RR</p><p attribs="{'xml:space': 'preserve'}" id="_15532" smilref="Title.smil#_15532"> AA</p><p attribs="{'xml:space': 'preserve'}" id="_15533" smilref="Title.smil#_15533"> BB</p><p attribs="{'xml:space': 'preserve'}" id="_15534" smilref="Title.smil#_15534"> 52</p><p attribs="{'xml:space': 'preserve'}" id="_15535" smilref="Title.smil#_15535"> 83</p><p attribs="{'xml:space': 'preserve'}" id="_15536" smilref="Title.smil#_15536"> 89</p><p attribs="{'xml:space': 'preserve'}" id="_15537" smilref="Title.smil#_15537" /><pagenum id="p854" page="normal" smilref="Title.smil#p854" /><p attribs="{'xml:space': 'preserve'}" id="_15538" smilref="Title.smil#_15538"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15539" smilref="Title.smil#_15539"> 841</p><p attribs="{'xml:space': 'preserve'}" id="_15540" smilref="Title.smil#_15540"> space ef&#64257; ciency, as described in Section 5.2. The contrast with the use of tries in Huff- man encoding is worth noting: for Huffman encoding, tries are useful because no prefix of a codeword is also a codeword; for LZW tries are useful because every prefix of an input-substring key is also a key.</p><p attribs="{'xml:space': 'preserve'}" id="_15541" smilref="Title.smil#_15541"> LZW expansion. The input for LZW expansion in our example is a sequence of 8-bit codewords; the output is a string of 7-bit ASCII characters. To implement expansion, we maintain a symbol table that associates strings of characters with codeword values (the inverse of the table used for compression). We fill the table entries from 00 to 7F with one-character strings, one for each ASCII character, set the first unassigned codeword value to 81 (reserving 80 for end of fi le), set the current string val to the one- character string consisting of the first character, and perform the following steps until reading codeword 80 (end of fi le): </p><p attribs="{'xml:space': 'preserve'}" id="_15542" smilref="Title.smil#_15542"> input output</p><p attribs="{'xml:space': 'preserve'}" id="_15543" smilref="Title.smil#_15543"> 41 42 52 41 43 41 44 81 83 82 88 41 80 A B R A C A D A B R A B R A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15544" smilref="Title.smil#_15544"> 81</p><p attribs="{'xml:space': 'preserve'}" id="_15545" smilref="Title.smil#_15545"> A B</p><p attribs="{'xml:space': 'preserve'}" id="_15546" smilref="Title.smil#_15546"> A B B R</p><p attribs="{'xml:space': 'preserve'}" id="_15547" smilref="Title.smil#_15547"> 82</p><p attribs="{'xml:space': 'preserve'}" id="_15548" smilref="Title.smil#_15548"> A B B R R A</p><p attribs="{'xml:space': 'preserve'}" id="_15549" smilref="Title.smil#_15549"> 83</p><p attribs="{'xml:space': 'preserve'}" id="_15550" smilref="Title.smil#_15550"> A B B R R A A C</p><p attribs="{'xml:space': 'preserve'}" id="_15551" smilref="Title.smil#_15551"> 84</p><p attribs="{'xml:space': 'preserve'}" id="_15552" smilref="Title.smil#_15552"> inverse codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_15553" smilref="Title.smil#_15553"> key value</p><p attribs="{'xml:space': 'preserve'}" id="_15554" smilref="Title.smil#_15554"> A B B R R A A C C A</p><p attribs="{'xml:space': 'preserve'}" id="_15555" smilref="Title.smil#_15555"> 85</p><p attribs="{'xml:space': 'preserve'}" id="_15556" smilref="Title.smil#_15556"> A B B R R A A C C A A D</p><p attribs="{'xml:space': 'preserve'}" id="_15557" smilref="Title.smil#_15557"> 86</p><p attribs="{'xml:space': 'preserve'}" id="_15558" smilref="Title.smil#_15558"> A B B R R A A C C A A D D A</p><p attribs="{'xml:space': 'preserve'}" id="_15559" smilref="Title.smil#_15559"> 87</p><p attribs="{'xml:space': 'preserve'}" id="_15560" smilref="Title.smil#_15560"> LZW codeword</p><p attribs="{'xml:space': 'preserve'}" id="_15561" smilref="Title.smil#_15561"> A B B R R A A C C A A D D A A B R</p><p attribs="{'xml:space': 'preserve'}" id="_15562" smilref="Title.smil#_15562"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_15563" smilref="Title.smil#_15563"> input substring</p><p attribs="{'xml:space': 'preserve'}" id="_15564" smilref="Title.smil#_15564"> A B B R R A A C C A A D D A A B R R A B</p><p attribs="{'xml:space': 'preserve'}" id="_15565" smilref="Title.smil#_15565"> 89</p><p attribs="{'xml:space': 'preserve'}" id="_15566" smilref="Title.smil#_15566"> A B B R R A A C C A A D D A A B R R A B B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15567" smilref="Title.smil#_15567"> 8A</p><p attribs="{'xml:space': 'preserve'}" id="_15568" smilref="Title.smil#_15568"> A B B R R A A C C A A D D A A B R R A B B R A A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15569" smilref="Title.smil#_15569"> 8B</p><p attribs="{'xml:space': 'preserve'}" id="_15570" smilref="Title.smil#_15570"> 81 82 83 84 85 86 87 88 89 8A 8B</p><p attribs="{'xml:space': 'preserve'}" id="_15571" smilref="Title.smil#_15571"> A B B R R A A C C A A D D A A B R R A B B R A A B R A</p><p attribs="{'xml:space': 'preserve'}" id="_15572" smilref="Title.smil#_15572"> LZW expansion for 41 42 52 41 43 41 44 81 83 82 88 41 80</p><p attribs="{'xml:space': 'preserve'}" id="_15573" smilref="Title.smil#_15573" /><pagenum id="p855" page="normal" smilref="Title.smil#p855" /><p attribs="{'xml:space': 'preserve'}" id="_15574" smilref="Title.smil#_15574"> 842</p><p attribs="{'xml:space': 'preserve'}" id="_15575" smilref="Title.smil#_15575"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15576" smilref="Title.smil#_15576"> ALGORITHM 5.11 LZW compression</p><p attribs="{'xml:space': 'preserve'}" id="_15577" smilref="Title.smil#_15577"> public class LZW { private static final int R = 256; // number of input chars private static final int L = 4096; // number of codewords = 2^12 private static final int W = 12; // codeword width</p><p attribs="{'xml:space': 'preserve'}" id="_15578" smilref="Title.smil#_15578"> public static void compress() { String input = BinaryStdIn.readString(); TST&lt;Integer&gt; st = new TST&lt;Integer&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_15579" smilref="Title.smil#_15579"> for (int i = 0; i &lt; R; i++) st.put("" + (char) i, i); int code = R+1; // R is codeword for EOF.</p><p attribs="{'xml:space': 'preserve'}" id="_15580" smilref="Title.smil#_15580"> while (input.length() &gt; 0) { String s = st. longestPrefixOf(input); // Find max prefix match. BinaryStdOut.write(st.get(s), W); // Print s's encoding. int t = s.length(); if (t &lt; input.length() &amp;&amp; code &lt; L) // Add s to symbol table. st.put(input.substring(0, t + 1), code++); input = input.substring(t); // Scan past s in input. }</p><p attribs="{'xml:space': 'preserve'}" id="_15581" smilref="Title.smil#_15581"> BinaryStdOut.write(R, W); // Write EOF. BinaryStdOut.close(); }</p><p attribs="{'xml:space': 'preserve'}" id="_15582" smilref="Title.smil#_15582"> public static void expand() // See page 844. }</p><p attribs="{'xml:space': 'preserve'}" id="_15583" smilref="Title.smil#_15583"> This implementation of Lempel-Ziv-Welch data compression uses 8-bit input bytes and 12-bit codewords and is appropriate for arbitrary large fi les. Its codewords for the small example are similar to those discussed in the text: the single-character codewords have a leading 0; the others start at 100.</p><p attribs="{'xml:space': 'preserve'}" id="_15584" smilref="Title.smil#_15584"> % more abraLZW.txt ABRACADABRABRABRA</p><p attribs="{'xml:space': 'preserve'}" id="_15585" smilref="Title.smil#_15585"> % java LZW - &lt; abraLZW.txt | java HexDump 20 04 10 42 05 20 41 04 30 41 04 41 01 10 31 02 1080  41 10 00 160 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15586" smilref="Title.smil#_15586" /><pagenum id="p856" page="normal" smilref="Title.smil#p856" /><p attribs="{'xml:space': 'preserve'}" id="_15587" smilref="Title.smil#_15587"> the end of the process, we have written the original input, as expected, and also built the same code table as for compression, but with the key-value roles inverted. Note that we can use a simple array-of-strings representation for the table, indexed by codeword.</p><p attribs="{'xml:space': 'preserve'}" id="_15588" smilref="Title.smil#_15588"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15589" smilref="Title.smil#_15589"> 843</p><p attribs="{'xml:space': 'preserve'}" id="_15590" smilref="Title.smil#_15590"> Tricky situation. There is a subtle bug in the process just described, one that is often discovered by students (and experienced programmers!) only after developing an implementation based on the description above. The problem, illustrated in the example at right, is that it is possible for the lookahead process to get one character ahead of itself. In the example, the input string</p><p attribs="{'xml:space': 'preserve'}" id="_15591" smilref="Title.smil#_15591"> compression A B A B A B A A B A B A B A 41 42 81 83 80</p><p attribs="{'xml:space': 'preserve'}" id="_15592" smilref="Title.smil#_15592"> codeword table</p><p attribs="{'xml:space': 'preserve'}" id="_15593" smilref="Title.smil#_15593"> matches</p><p attribs="{'xml:space': 'preserve'}" id="_15594" smilref="Title.smil#_15594"> output</p><p attribs="{'xml:space': 'preserve'}" id="_15595" smilref="Title.smil#_15595"> input</p><p attribs="{'xml:space': 'preserve'}" id="_15596" smilref="Title.smil#_15596"> A B A B A B A</p><p attribs="{'xml:space': 'preserve'}" id="_15597" smilref="Title.smil#_15597"> is compressed to five output codewords</p><p attribs="{'xml:space': 'preserve'}" id="_15598" smilref="Title.smil#_15598"> 41 42 81 83 80</p><p attribs="{'xml:space': 'preserve'}" id="_15599" smilref="Title.smil#_15599"> A B 81</p><p attribs="{'xml:space': 'preserve'}" id="_15600" smilref="Title.smil#_15600"> A B B A 82</p><p attribs="{'xml:space': 'preserve'}" id="_15601" smilref="Title.smil#_15601"> A B B A A B A 83</p><p attribs="{'xml:space': 'preserve'}" id="_15602" smilref="Title.smil#_15602"> key</p><p attribs="{'xml:space': 'preserve'}" id="_15603" smilref="Title.smil#_15603"> A B B A A B A</p><p attribs="{'xml:space': 'preserve'}" id="_15604" smilref="Title.smil#_15604"> value</p><p attribs="{'xml:space': 'preserve'}" id="_15605" smilref="Title.smil#_15605"> 81 82 83</p><p attribs="{'xml:space': 'preserve'}" id="_15606" smilref="Title.smil#_15606"> expansion 41 42 81 83 80 A B A B ?</p><p attribs="{'xml:space': 'preserve'}" id="_15607" smilref="Title.smil#_15607"> input output</p><p attribs="{'xml:space': 'preserve'}" id="_15608" smilref="Title.smil#_15608"> must be A B A (see below)</p><p attribs="{'xml:space': 'preserve'}" id="_15609" smilref="Title.smil#_15609"> 82</p><p attribs="{'xml:space': 'preserve'}" id="_15610" smilref="Title.smil#_15610"> 83</p><p attribs="{'xml:space': 'preserve'}" id="_15611" smilref="Title.smil#_15611"> need lookahead character to complete entry</p><p attribs="{'xml:space': 'preserve'}" id="_15612" smilref="Title.smil#_15612"> 81</p><p attribs="{'xml:space': 'preserve'}" id="_15613" smilref="Title.smil#_15613"> A B</p><p attribs="{'xml:space': 'preserve'}" id="_15614" smilref="Title.smil#_15614"> A B B A</p><p attribs="{'xml:space': 'preserve'}" id="_15615" smilref="Title.smil#_15615"> A B B A A B ?</p><p attribs="{'xml:space': 'preserve'}" id="_15616" smilref="Title.smil#_15616"> as shown in the top part of the fi gure. To expand, we read the codeword 41, output A, read the codeword 42 to get the lookahead character, add AB as table entry 81, output the B associated with 42, read the codeword 81 to get the lookahead char- acter, add BA as table entry 82, and output the AB associated with 81. So far, so good. But when we read the codeword 83 to get the lookahead character, we are stuck, because the reason that we are reading that codeword is to complete table entry 83! Fortunately, it is easy to test for that condition (it happens precisely when the codeword is the same as the table entry to be completed) and to correct it (the lookahead character must be the first character in that table entry, since that will be the next character to be output). In this example, this logic tells us that the lookahead character must be A (the first character in ABA). Thus, both the next output string and table entry 83 should be ABA.</p><p attribs="{'xml:space': 'preserve'}" id="_15617" smilref="Title.smil#_15617"> LZW expansion: tricky situation</p><p attribs="{'xml:space': 'preserve'}" id="_15618" smilref="Title.smil#_15618"> next character in output&#8212;the lookahead character!</p><p attribs="{'xml:space': 'preserve'}" id="_15619" smilref="Title.smil#_15619"> Implementation. With these descriptions, implementing LZW encoding is straight- forward, given in Algorithm 5.11 on the facing page (the implementation of expand() is on the next page). These implementations take 8-bit bytes as input (so we can compress any fi le, not just strings) and produce 12-bit codewords as output (so that we can get better compression by having a much larger dictionary). These values are specified in the (&#64257; nal) instance variables R, L, and W in the code. We use a TST (see section 5.2) for the code table in compress() (taking advantage of the ability of trie data structures to support efficient implementations of longestPrefixOf()) and an array of strings</p><p attribs="{'xml:space': 'preserve'}" id="_15620" smilref="Title.smil#_15620" /><pagenum id="p857" page="normal" smilref="Title.smil#p857" /><p attribs="{'xml:space': 'preserve'}" id="_15621" smilref="Title.smil#_15621"> 844</p><p attribs="{'xml:space': 'preserve'}" id="_15622" smilref="Title.smil#_15622"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15623" smilref="Title.smil#_15623"> ALGORITHM 5.11 (continued) LZW expansion</p><p attribs="{'xml:space': 'preserve'}" id="_15624" smilref="Title.smil#_15624"> public static void expand() { String[] st = new String[L];</p><p attribs="{'xml:space': 'preserve'}" id="_15625" smilref="Title.smil#_15625"> int i; // next available codeword value</p><p attribs="{'xml:space': 'preserve'}" id="_15626" smilref="Title.smil#_15626"> for (i = 0; i &lt; R; i++) // Initialize table for chars. st[i] = "" + (char) i; st[i++] = " "; // (unused) lookahead for EOF</p><p attribs="{'xml:space': 'preserve'}" id="_15627" smilref="Title.smil#_15627"> int codeword = BinaryStdIn.readInt(W); String val = st[codeword]; while (true) { BinaryStdOut.write(val); // Write current substring. codeword = BinaryStdIn.readInt(W); if (codeword == R) break; String s = st[codeword]; // Get next codeword. if (i == codeword) // If lookahead is invalid, s = val + val.charAt(0); // make codeword from last one. if (i &lt; L) st[i++] = val + s.charAt(0); // Add new entry to code table. val = s; // Update current codeword. }</p><p attribs="{'xml:space': 'preserve'}" id="_15628" smilref="Title.smil#_15628"> BinaryStdOut.close();</p><p attribs="{'xml:space': 'preserve'}" id="_15629" smilref="Title.smil#_15629"> }</p><p attribs="{'xml:space': 'preserve'}" id="_15630" smilref="Title.smil#_15630"> This implementation of expansion for the Lempel-Ziv-Welch algorithm is a bit more complicated than compression because of the need to extract the lookahead character from the next codeword and because of a tricky situation where lookahead is invalid (see text).</p><p attribs="{'xml:space': 'preserve'}" id="_15631" smilref="Title.smil#_15631"> % java LZW - &lt; abraLZW.txt | java LZW + ABRACADABRABRABRA</p><p attribs="{'xml:space': 'preserve'}" id="_15632" smilref="Title.smil#_15632"> % more ababLZW.txt ABABABA</p><p attribs="{'xml:space': 'preserve'}" id="_15633" smilref="Title.smil#_15633"> % java LZW - &lt; ababLZW.txt | java LZW + ABABABA</p><p attribs="{'xml:space': 'preserve'}" id="_15634" smilref="Title.smil#_15634" /><pagenum id="p858" page="normal" smilref="Title.smil#p858" /><p attribs="{'xml:space': 'preserve'}" id="_15635" smilref="Title.smil#_15635"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15636" smilref="Title.smil#_15636"> 845</p><p attribs="{'xml:space': 'preserve'}" id="_15637" smilref="Title.smil#_15637"> for the inverse code table in expand(). With these choices, the code for compress() and expand() is little more than a line-by-line translation of the descriptions in the text. These methods are very effective as they stand. For certain fi les, they can be further improved by emptying the codeword table and starting over each time all the codeword values are used. These improvements, along with experiments to evaluate their effec- tiveness, are addressed in the exercises at the end of this section.</p><p attribs="{'xml:space': 'preserve'}" id="_15638" smilref="Title.smil#_15638"> As usual, it is worth your while to study carefully the examples given with the programs and at the bottom of this page of LZW compression in action. Over the several decades since its invention, it has proven to be a versatile and effective data-compres- sion method.</p><p attribs="{'xml:space': 'preserve'}" id="_15639" smilref="Title.smil#_15639"> virus (50000 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15640" smilref="Title.smil#_15640"> % java Genome - &lt; genomeVirus.txt | java PictureDump 512 25</p><p attribs="{'xml:space': 'preserve'}" id="_15641" smilref="Title.smil#_15641"> 12536 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15642" smilref="Title.smil#_15642"> % java LZW - &lt; genomeVirus.txt | java PictureDump 512 36</p><p attribs="{'xml:space': 'preserve'}" id="_15643" smilref="Title.smil#_15643"> 18232 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15644" smilref="Title.smil#_15644"> not as good as 2-bit code because repetitive data is rare</p><p attribs="{'xml:space': 'preserve'}" id="_15645" smilref="Title.smil#_15645"> bitmap (6144 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15646" smilref="Title.smil#_15646"> % java RunLength - &lt; q64x96.bin | java BinaryDump 0 2296 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15647" smilref="Title.smil#_15647"> % java LZW - &lt; q64x96.bin | java BinaryDump 0 2824 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15648" smilref="Title.smil#_15648"> not as good as run-length code because file size is too small</p><p attribs="{'xml:space': 'preserve'}" id="_15649" smilref="Title.smil#_15649"> entire text of Tale of Two Cities (5812552 bits)</p><p attribs="{'xml:space': 'preserve'}" id="_15650" smilref="Title.smil#_15650"> % java BinaryDump 0 &lt; tale.txt 5812552 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15651" smilref="Title.smil#_15651"> % java Huffman - &lt; tale.txt | java BinaryDump 0 3043928 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15652" smilref="Title.smil#_15652"> % java LZW - &lt; tale.txt | java BinaryDump 0 2667952 bits</p><p attribs="{'xml:space': 'preserve'}" id="_15653" smilref="Title.smil#_15653"> compression ratio 2667952/5812552 = 46% (best yet)</p><p attribs="{'xml:space': 'preserve'}" id="_15654" smilref="Title.smil#_15654"> Compressing and expanding various files with LZW 12-bit encoding</p><p attribs="{'xml:space': 'preserve'}" id="_15655" smilref="Title.smil#_15655" /><pagenum id="p859" page="normal" smilref="Title.smil#p859" /><p attribs="{'xml:space': 'preserve'}" id="_15656" smilref="Title.smil#_15656"> 846</p><p attribs="{'xml:space': 'preserve'}" id="_15657" smilref="Title.smil#_15657"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15658" smilref="Title.smil#_15658"> Q&amp;A</p><p attribs="{'xml:space': 'preserve'}" id="_15659" smilref="Title.smil#_15659"> Q. Why BinaryStdIn and BinaryStdOut?</p><p attribs="{'xml:space': 'preserve'}" id="_15660" smilref="Title.smil#_15660"> A. It&#8217;s a tradeoff between efficiency and convenience. StdIn can handle 8 bits at a time; BinaryStdIn has to handle each bit. Most applications are bytestream-oriented; data compression is a special case. Q. Why close() ? A. This requirement stems from the fact that standard output is actually a bytestream, so BinaryStdOut needs to know when to write the last byte. Q. Can we mix StdIn and BinaryStdIn ? A. That is not a good idea. Because of system and implementation dependencies, there is no guarantee of what might happen. Our implementations will raise an exception. On the other hand, there is no problem with mixing StdOut and BinaryStdOut (we do it in our code). Q. Why is the Node class static in Huffman? A. Our data-compression algorithms are organized as collections of static methods, not data-type implementations. Q. Can I at least guarantee that my compression algorithm will not increase the length of a bitstream? A. You can just copy it from input to output, but you still need to signify not to use a standard compression scheme. Commercial implementations sometimes make this guarantee, but it is quite weak and far from universal compression. Indeed, typical compression algorithms do not even make it past the second step of our first proof of Proposition S: few algorithms will further compress a bitstring produced by that same algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_15661" smilref="Title.smil#_15661" /><pagenum id="p860" page="normal" smilref="Title.smil#p860" /><p attribs="{'xml:space': 'preserve'}" id="_15662" smilref="Title.smil#_15662"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15663" smilref="Title.smil#_15663"> 847</p><p attribs="{'xml:space': 'preserve'}" id="_15664" smilref="Title.smil#_15664"> EXERCISES</p><p attribs="{'xml:space': 'preserve'}" id="_15665" smilref="Title.smil#_15665"> 5.5.1 Consider the four variable-length codes shown in the table at right. Which of the codes are pre&#64257; x-free? Uniquely decodable? For those that are uniquely decod- able, give the encoding of 1 0 0 0 0 0 0 0 0 0 0 0 0 . 5.5.2 Given a example of a uniquely decodable code that is not pre&#64257; x-free.</p><p attribs="{'xml:space': 'preserve'}" id="_15666" smilref="Title.smil#_15666"> Answer : Any suf&#64257; x-free code is uniquely decodable.</p><p attribs="{'xml:space': 'preserve'}" id="_15667" smilref="Title.smil#_15667"> symbol</p><p attribs="{'xml:space': 'preserve'}" id="_15668" smilref="Title.smil#_15668"> code 1</p><p attribs="{'xml:space': 'preserve'}" id="_15669" smilref="Title.smil#_15669"> code 2</p><p attribs="{'xml:space': 'preserve'}" id="_15670" smilref="Title.smil#_15670"> code 3</p><p attribs="{'xml:space': 'preserve'}" id="_15671" smilref="Title.smil#_15671"> code 4</p><p attribs="{'xml:space': 'preserve'}" id="_15672" smilref="Title.smil#_15672"> A</p><p attribs="{'xml:space': 'preserve'}" id="_15673" smilref="Title.smil#_15673"> B</p><p attribs="{'xml:space': 'preserve'}" id="_15674" smilref="Title.smil#_15674"> C</p><p attribs="{'xml:space': 'preserve'}" id="_15675" smilref="Title.smil#_15675"> D</p><p attribs="{'xml:space': 'preserve'}" id="_15676" smilref="Title.smil#_15676"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_15677" smilref="Title.smil#_15677"> 100</p><p attribs="{'xml:space': 'preserve'}" id="_15678" smilref="Title.smil#_15678"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_15679" smilref="Title.smil#_15679"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15680" smilref="Title.smil#_15680"> 0</p><p attribs="{'xml:space': 'preserve'}" id="_15681" smilref="Title.smil#_15681"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_15682" smilref="Title.smil#_15682"> 00</p><p attribs="{'xml:space': 'preserve'}" id="_15683" smilref="Title.smil#_15683"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_15684" smilref="Title.smil#_15684"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_15685" smilref="Title.smil#_15685"> 01</p><p attribs="{'xml:space': 'preserve'}" id="_15686" smilref="Title.smil#_15686"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_15687" smilref="Title.smil#_15687"> 01</p><p attribs="{'xml:space': 'preserve'}" id="_15688" smilref="Title.smil#_15688"> 001</p><p attribs="{'xml:space': 'preserve'}" id="_15689" smilref="Title.smil#_15689"> 001</p><p attribs="{'xml:space': 'preserve'}" id="_15690" smilref="Title.smil#_15690"> 0001</p><p attribs="{'xml:space': 'preserve'}" id="_15691" smilref="Title.smil#_15691"> 000</p><p attribs="{'xml:space': 'preserve'}" id="_15692" smilref="Title.smil#_15692"> 5.5.3 Give an example of a uniquely decodable code that is not prefix free or suffix free.</p><p attribs="{'xml:space': 'preserve'}" id="_15693" smilref="Title.smil#_15693"> Answer : {0011, 011, 11, 1110} or {01, 10, 011, 110}</p><p attribs="{'xml:space': 'preserve'}" id="_15694" smilref="Title.smil#_15694"> 5.5.4 Are { 01, 1001, 1011, 111, 1110 } and { 01, 1001, 1011, 111, 1110 } unique-</p><p attribs="{'xml:space': 'preserve'}" id="_15695" smilref="Title.smil#_15695"> ly decodable? If not, find a string with two encodings. 5.5.5 Use RunLength on the file q128x192.bin from the booksite. How many bits are there in the compressed fi le? 5.5.6 How many bits are needed to encode N copies of the symbol a (as a function of N)? N copies of the sequence abc? 5.5.7 Give the result of encoding the strings a, aa, aaa, aaaa, ... (strings consisting of N a&#8217;s) with run-length, Huffman, and LZW encoding. What is the compression ratio as a function of N? 5.5.8 Give the result of encoding the strings ab, abab, ababab, abababab, ... (strings consisting of N repetitions of ab) with run-length, Huffman, and LZW encoding. What is the compression ratio as a function of N? 5.5.9 Estimate the compression ratio achieved by run-length, Huffman, and LZW encoding for a random ASCII string of length N (all characters equally likely at each posi- tion, independently). 5.5.10 In the style of the figure in the text, show the Huffman coding tree construction process when you use Huffman for the string "it was the age of foolishness&#8221;. How many bits does the compressed bitstream require?</p><p attribs="{'xml:space': 'preserve'}" id="_15696" smilref="Title.smil#_15696" /><pagenum id="p861" page="normal" smilref="Title.smil#p861" /><p attribs="{'xml:space': 'preserve'}" id="_15697" smilref="Title.smil#_15697"> 848</p><p attribs="{'xml:space': 'preserve'}" id="_15698" smilref="Title.smil#_15698"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15699" smilref="Title.smil#_15699"> EXERCISES (continued)</p><p attribs="{'xml:space': 'preserve'}" id="_15700" smilref="Title.smil#_15700"> 5.5.11 What is the Huffman code for a string whose characters are all from a two- character alphabet? Give an example showing the maximum number of bits that could be used in a Huffman code for an N-character string whose characters are all from a two-character alphabet. 5.5.12 Suppose that all of the symbol probabilities are negative powers of 2. Describe the Huffman code. 5.5.13 Suppose that all of the symbol frequencies are equal. Describe the Huffman code. 5.5.14 Suppose that the frequencies of the occurrence of all the characters to be encoded are different. Is the Huffman encoding tree unique? 5.5.15 Huffman coding could be extended in a straightforward way to encode in 2-bit characters (using 4-way trees). What would be the main advantage and the main disadvantage of doing so? 5.5.16 What is the LZW encoding of the following inputs?</p><p attribs="{'xml:space': 'preserve'}" id="_15701" smilref="Title.smil#_15701"> a. T O B E O R N O T T O B E b. Y A B B A D A B B A D A B B A D O O c. A A A A A A A A A A A A A A A A A A A A A</p><p attribs="{'xml:space': 'preserve'}" id="_15702" smilref="Title.smil#_15702"> 5.5.17 Characterize the tricky situation in LZW coding.</p><p attribs="{'xml:space': 'preserve'}" id="_15703" smilref="Title.smil#_15703"> Solution : Whenever it encounters cScSc, where c is a symbol and S is a string, cS is in the dictionary already but cSc is not.</p><p attribs="{'xml:space': 'preserve'}" id="_15704" smilref="Title.smil#_15704"> 5.5.18 Let Fk be the k th Fibonacci number. Consider N symbols, where the k th symbol has frequency Fk. Note that F1 + F1 + ... + FN = FN+2 &#11002; 1. Describe the Huffman code. Hint : The longest codeword has length N &#11002; 1. 5.5.19 Show that there are at least 2N&#11002;1 different Huffman codes corresponding to a given set of N symbols. 5.5.20 Give a Huffman code where the frequency of 0s in the output is much, much higher than the frequency of 1s.</p><p attribs="{'xml:space': 'preserve'}" id="_15705" smilref="Title.smil#_15705"> Answer : If the character A occurs 1 million times and the character B occurs once, the codeword for A will be 0 and the codeword for B will be 1.</p><p attribs="{'xml:space': 'preserve'}" id="_15706" smilref="Title.smil#_15706" /><pagenum id="p862" page="normal" smilref="Title.smil#p862" /><p attribs="{'xml:space': 'preserve'}" id="_15707" smilref="Title.smil#_15707"> 5.5 </p><p attribs="{'xml:space': 'preserve'}" id="_15708" smilref="Title.smil#_15708"> 849</p><p attribs="{'xml:space': 'preserve'}" id="_15709" smilref="Title.smil#_15709"> 5.5.21 Prove that the two longest codewords in a Huffman code have the same length. 5.5.22 Prove the following fact about Huffman codes: If the frequency of symbol i is strictly larger than the frequency of symbol j, then the length of the codeword for symbol i is less than or equal to the length of the codeword for symbol j. 5.5.23 What would be the result of breaking up a Huffman-encoded string into fi ve-bit characters and Huffman-encoding that string? 5.5.24 In the style of the figures in the text, show the encoding trie and the compression and expansion processes when LZW is used for the string</p><p attribs="{'xml:space': 'preserve'}" id="_15710" smilref="Title.smil#_15710"> it was the best of times it was the worst of times</p><p attribs="{'xml:space': 'preserve'}" id="_15711" smilref="Title.smil#_15711" /><pagenum id="p863" page="normal" smilref="Title.smil#p863" /><p attribs="{'xml:space': 'preserve'}" id="_15712" smilref="Title.smil#_15712"> 850</p><p attribs="{'xml:space': 'preserve'}" id="_15713" smilref="Title.smil#_15713"> CHAPTER 5 </p><p attribs="{'xml:space': 'preserve'}" id="_15714" smilref="Title.smil#_15714"> CREATIVE PROBLEMS</p><p attribs="{'xml:space': 'preserve'}" id="_15715" smilref="Title.smil#_15715"> 5.5.25 Fixed length width code. Implement a class RLE that uses fi xed-length encod- ing, to compress ASCII bytestreams using relatively few different characters, including the code as part of the encoded bitstream. Add code to compress() to make a string alpha with all the distinct characters in the message and use it to make an Alphabet for use in compress(), prepend alpha (8-bit encoding plus its length) to the compressed bitstream, then add code to expand() to read the alphabet before expansion. 5.5.26 Rebuilding the LZW dictionary. Modify LZW to empty the dictionary and start over when it is full. This approach is recommended in some applications because it better adapts to changes in the general character of the input. 5.5.27 Long repeats. Estimate the compression ratio achieved by run-length, Huff- man, and LZW encoding for a string of length 2N formed by concatenating two copies of a random ASCII string of length N (see Exercise 5.5.9), under any assumptions that you think are reasonable.</p><p attribs="{'xml:space': 'preserve'}" id="_15716" smilref="Title.smil#_15716" /><pagenum id="p864" page="normal" smilref="Title.smil#p864" /><p attribs="{'xml:space': 'preserve'}" id="_15717" smilref="Title.smil#_15717"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_15718" smilref="Title.smil#_15718" /></level3></level1><level1 id="ch6"><section epub:type="chapter" id="section_00005"><header id="header_00005"><pagenum epub:type="pagebreak" id="p865" page="normal" smilref="Title.smil#p865" /><h1 id="ch6-start" smilref="Title.smil#ch6-start" xml:space="preserve">6 Context</h1></header></section><pagenum id="p865" page="normal" smilref="Title.smil#p865" /><p attribs="{'xml:space': 'preserve'}" id="_15719" smilref="Title.smil#_15719"> S I X</p><p attribs="{'xml:space': 'preserve'}" id="_15720" smilref="Title.smil#_15720"> Context</p><p attribs="{'xml:space': 'preserve'}" id="_15721" smilref="Title.smil#_15721" /><pagenum id="p866" page="normal" smilref="Title.smil#p866" /><p attribs="{'xml:space': 'preserve'}" id="_15722" smilref="Title.smil#_15722"> Computing devices are ubiquitous in the modern world. In the last several decades, we have evolved from a world where computing devices were virtually unknown to a world where billions of people use them regularly. Moreover, to- day&#8217;s cellphones are orders of magnitude more powerful than the supercomputers that were available only to the privileged few as little as 30 years ago. But many of the underlying algorithms that enable these devices to work effectively are the same ones that we have studied in this book. Why? Survival of the fi ttest. Scalable (linear and linearithmic) algorithms have played a central role in the process and validate the idea that efficient algorithms are important. Researchers of the 1960s and 1970s built the basic infrastructure that we now enjoy with such algorithms. They knew that scalable algorithms are the key to the future; the developments of the past several decades have validated that vision. Now that the infrastructure is built, people are beginning to use it, for all sorts of purposes. As B. Chazelle has famously observed, the 20th century was the century of the equation, but the 21st century is the century of the algorithm. Our treatment of fundamental algorithms in this book is only a starting point. The day is soon coming (if it is not already here) when one could build a college major around the study of algorithms. In commerical applications, scientific computing, en- gineering, operations research (OR), and countless other areas of inquiry too diverse to even mention, efficient algorithms make the difference between being able to solve problems in the modern world and not being able to address them at all. Our emphasis throughout this book has been to study important and useful algorithms. In this chapter, we reinforce this orientation by considering examples that illustrate the role of the algorithms that we have studied (and our approach to the study of algorithms) in</p><p attribs="{'xml:space': 'preserve'}" id="_15723" smilref="Title.smil#_15723"> 853</p><p attribs="{'xml:space': 'preserve'}" id="_15724" smilref="Title.smil#_15724" /><pagenum id="p867" page="normal" smilref="Title.smil#p867" /><p attribs="{'xml:space': 'preserve'}" id="_15725" smilref="Title.smil#_15725"> 854</p><p attribs="{'xml:space': 'preserve'}" id="_15726" smilref="Title.smil#_15726"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15727" smilref="Title.smil#_15727"> several advanced contexts. To indicate the scope of the impact of the algorithms, we begin with a very brief description of several important areas of application. To indicate the depth, we later consider specific representative examples in detail and introduce the theory of algorithms. In both cases, this brief treatment at the end of a long book can only be indicative, not inclusive. For every area of application that we mention, there are dozens of others, equally broad in scope; for every point that we describe within an application, there are scores of others, equally important; and for every detailed example we consider, there are hundreds if not thousands of others, equally impactful.</p><p attribs="{'xml:space': 'preserve'}" id="_15728" smilref="Title.smil#_15728"> Commercial applications. The emergence of the internet has underscored the central role of algorithms in commercial applications. All of the applications that you use regularly benefit from the classic algorithms that we have studied: </p><p attribs="{'xml:space': 'preserve'}" id="_15729" smilref="Title.smil#_15729"> Scienti&#64257; c computing. Since von Neumann developed mergesort in 1950, algorithms have played a central role in scientific computing. Today&#8217;s scientists are awash in experimental data and are using both mathematical and computational models to understand the natural world for: </p><p attribs="{'xml:space': 'preserve'}" id="_15730" smilref="Title.smil#_15730"> Engineering. Almost by defi nition, modern engineering is based on technology. Mod- ern technology is computer-based, so algorithms play a central role for </p><p attribs="{'xml:space': 'preserve'}" id="_15731" smilref="Title.smil#_15731" /><pagenum id="p868" page="normal" smilref="Title.smil#p868" /><p attribs="{'xml:space': 'preserve'}" id="_15732" smilref="Title.smil#_15732"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15733" smilref="Title.smil#_15733"> 855</p><p attribs="{'xml:space': 'preserve'}" id="_15734" smilref="Title.smil#_15734"> </p><p attribs="{'xml:space': 'preserve'}" id="_15735" smilref="Title.smil#_15735"> Operations research. Researchers and practitioners in OR develop and apply mathematical models for problem solving, including </p><p attribs="{'xml:space': 'preserve'}" id="_15736" smilref="Title.smil#_15736"> Algorithms play an imporTant role in numerous subfields of computer science with applications in all of these areas, including, but certainly not limited to </p><p attribs="{'xml:space': 'preserve'}" id="_15737" smilref="Title.smil#_15737" /><level3 id="_00119"><h3 id="ch6-s1-ss1" smilref="Title.smil#ch6-s1-ss1" xml:space="preserve">Hard-disc model</h3><p attribs="{'xml:space': 'preserve'}" id="_15738" smilref="Title.smil#_15738"> 856</p><p attribs="{'xml:space': 'preserve'}" id="_15739" smilref="Title.smil#_15739"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15740" smilref="Title.smil#_15740"> Event-driven simulation Our first example is a fundamental scientific applica- tion: simulate the motion of a system of moving particles that behave according to the laws of elastic collision. Scientists use such systems to understand and predict properties of physical systems. This paradigm embraces the motion of molecules in a gas, the dynamics of chemical reactions, atomic diffusion, sphere packing, the stability of the rings around planets, the phase transitions of certain elements, one-dimensional self- gravitating systems, front propagation, and many other situations. Applications range from molecular dynamics, where the objects are tiny subatomic particles, to astrophys- ics, where the objects are huge celestial bodies. Addressing this problem requires a bit of high-school physics, a bit of software engi- neering, and a bit of algorithmics. We leave most of the physics for the exercises at the end of this section so that we can concentrate on the topic at hand: using a fundamental algorithmic tool (heap-based priority queues) to address an application, enabling calculations that would not otherwise be possible.</p><p attribs="{'xml:space': 'preserve'}" id="_15741" smilref="Title.smil#_15741"> Hard-disc model. We begin with an idealized model of the motion of atoms or molecules in a container that has the following salient features: </p><p attribs="{'xml:space': 'preserve'}" id="_15742" smilref="Title.smil#_15742"> advance time to t + dt</p><p attribs="{'xml:space': 'preserve'}" id="_15743" smilref="Title.smil#_15743"> advance time to t + 2dt</p><p attribs="{'xml:space': 'preserve'}" id="_15744" smilref="Title.smil#_15744"> roll back time to moment of collision</p><p attribs="{'xml:space': 'preserve'}" id="_15745" smilref="Title.smil#_15745"> Time-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15746" smilref="Title.smil#_15746"> Time-driven simulation. Our primary goal is simply to maintain the model: that is, we want to be able to keep track of the positions and velocities of all the particles as time passes. The basic calculation that we have to do is the following: given the positions and velocities for a specific time t, update them to reflect the situation at</p><p attribs="{'xml:space': 'preserve'}" id="_15747" smilref="Title.smil#_15747" /></level3><level3 id="_00120"><h3 id="ch6-s1-ss2" smilref="Title.smil#ch6-s1-ss2" xml:space="preserve">Collision prediction</h3><pagenum id="p870" page="normal" smilref="Title.smil#p870" /><p attribs="{'xml:space': 'preserve'}" id="_15748" smilref="Title.smil#_15748"> Event-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15749" smilref="Title.smil#_15749"> 857</p><p attribs="{'xml:space': 'preserve'}" id="_15750" smilref="Title.smil#_15750"> dt too small: excessive computation</p><p attribs="{'xml:space': 'preserve'}" id="_15751" smilref="Title.smil#_15751"> dt too large: may miss collisions</p><p attribs="{'xml:space': 'preserve'}" id="_15752" smilref="Title.smil#_15752"> a future time t+dt for a specific amount of time dt. Now, if the particles are sufficiently far from one another and from the walls that no collision will occur before t+dt, then the calculation is easy : since particles travel in a straight-line trajectory, we use each particle&#8217;s velocity to update its position. The challenge is to take the collisions into account. One approach, known as time-driven simulation, is based on using a fixed value of dt. To do each update, we need to check all pairs of particles, determine whether or not any two occupy the same position, and then back up to the moment of the first such collision. At that point, we are able to properly update the velocities of the two particles to reflect the collision (using calculations that we will discuss later). This approach is computationally intensive when simulating a large number of particles: if dt is measured in seconds (fractions of a second, usually), it takes time proportional to N 2/dt to simulate an N-particle system for 1 second. This cost is prohibitive (even worse than usual for quadratic algorithms)&#8212;in the applications of interest, N is very large and dt is very small. The challenge is that if we make dt too small, the computational cost is high, and if we make dt too large, we may miss collisions.</p><p attribs="{'xml:space': 'preserve'}" id="_15753" smilref="Title.smil#_15753"> Event-driven simulation. We pursue an alternative approach that focuses only on those times at which collisions occur. In particular, we are always interested in the next collision (because the simple update of all of the particle positions using their velocities is valid until that time). Therefore, we maintain a priority queue of events, where an event is a potential collision sometime in the future, either between two particles or between a particle and a wall. The priority associated with each event is its time, so when we remove the minimum from the priority queue, we get the next potential collision.</p><p attribs="{'xml:space': 'preserve'}" id="_15754" smilref="Title.smil#_15754"> Collision prediction. How do we identify potential collisions? The particle velocities provide precisely the information that we need. For example, suppose that we have, at time t, a particle of radius s at position (rx , ry ) moving with velocity (vx , vy ) in the unit box. Consider the vertical wall at x = 1 with y between 0 and 1. Our interest is in the horizontal component of the motion, so we can concentrate on the x-component of the position rx and the x-component of the velocity vx. If vx is negative, the particle is not on a collision course with the wall, but if vx is positive, there is a potential collision with the wall. Dividing the horizontal distance to the wall (1 &#11002; s &#11002; rx ) by the magnitude of the horizontal component of the velocity (vx ) we find that the particle will hit the wall after dt = (1 &#11002; s &#11002; rx )/vx time units, when the particle will be at ( 1 &#11002; s, ry &#11001; vy dt), unless it hits some other particle or a horizontal wall before that time. Accordingly, we</p><p attribs="{'xml:space': 'preserve'}" id="_15755" smilref="Title.smil#_15755"> Fundamental challenge for time-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15756" smilref="Title.smil#_15756" /></level3><level3 id="_00121"><h3 id="ch6-s1-ss3" smilref="Title.smil#ch6-s1-ss3" xml:space="preserve">Collision resolution</h3><pagenum id="p871" page="normal" smilref="Title.smil#p871" /><p attribs="{'xml:space': 'preserve'}" id="_15757" smilref="Title.smil#_15757"> 858</p><p attribs="{'xml:space': 'preserve'}" id="_15758" smilref="Title.smil#_15758"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15759" smilref="Title.smil#_15759"> prediction (at time t) dt &#11013; time to hit wall = distance/velocity</p><p attribs="{'xml:space': 'preserve'}" id="_15760" smilref="Title.smil#_15760"> = (1 &#8722; s &#8722; rx )/vx</p><p attribs="{'xml:space': 'preserve'}" id="_15761" smilref="Title.smil#_15761"> resolution (at time t + dt) velocity after collision = ( &#8722; vx , vy) position after collision = ( 1 &#8722; s , ry + vydt)</p><p attribs="{'xml:space': 'preserve'}" id="_15762" smilref="Title.smil#_15762"> s</p><p attribs="{'xml:space': 'preserve'}" id="_15763" smilref="Title.smil#_15763"> (rx , ry )</p><p attribs="{'xml:space': 'preserve'}" id="_15764" smilref="Title.smil#_15764"> vy</p><p attribs="{'xml:space': 'preserve'}" id="_15765" smilref="Title.smil#_15765"> vx</p><p attribs="{'xml:space': 'preserve'}" id="_15766" smilref="Title.smil#_15766"> 1 &#8722; s &#8722; rx</p><p attribs="{'xml:space': 'preserve'}" id="_15767" smilref="Title.smil#_15767"> wall at x = 1</p><p attribs="{'xml:space': 'preserve'}" id="_15768" smilref="Title.smil#_15768"> Predicting and resolving a particle-wall collision</p><p attribs="{'xml:space': 'preserve'}" id="_15769" smilref="Title.smil#_15769"> put an entry on the priority queue with priority t &#11001; dt (and appropriate information describing the particle-wall collision event). The collision-prediction calculations for other walls are similar (see Exercise 6.1). The calculation for two particles colliding is also similar, but more complicated. Note that it is often the case that the calculation leads to a prediction that the collision will not happen (if the particle is moving away from the wall, or if two particles are moving away from one another)&#8212;we do not need to put anything on the priority queue in such cases. To handle another typical situation where the predicted collision might be too far in the future to be of interest, we include a parameter limit that specifies the time period of interest, so we can also ignore any events that are predicted to happen at a time later than limit.</p><p attribs="{'xml:space': 'preserve'}" id="_15770" smilref="Title.smil#_15770"> Collision resolution. When a collision does occur, we need to resolve it by applying the physical formulas that specify the behavior of a particle after an elastic collision with a reflecting boundary or with another particle. In our example where the particle hits the vertical wall, if the collision does occur, the velocity of the particle will change from (vx , vy ) to (&#8211; vx , vy ) at that time. The collision-resolution calculations for other walls are similar, as are the calculations for two particles colliding, but these are more complicated (see Exercise 6.1).</p><p attribs="{'xml:space': 'preserve'}" id="_15771" smilref="Title.smil#_15771"> prediction (at time t) particles hit unless one passes intersection point before the other arrives</p><p attribs="{'xml:space': 'preserve'}" id="_15772" smilref="Title.smil#_15772"> resolution (at time t + dt) velocities of both particles change after collision</p><p attribs="{'xml:space': 'preserve'}" id="_15773" smilref="Title.smil#_15773"> Predicting and resolving a particle-particle collision</p><p attribs="{'xml:space': 'preserve'}" id="_15774" smilref="Title.smil#_15774" /><pagenum id="p872" page="normal" smilref="Title.smil#p872" /><p attribs="{'xml:space': 'preserve'}" id="_15775" smilref="Title.smil#_15775"> Event-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15776" smilref="Title.smil#_15776"> 859</p><p attribs="{'xml:space': 'preserve'}" id="_15777" smilref="Title.smil#_15777"> particle moving towards a wall</p><p attribs="{'xml:space': 'preserve'}" id="_15778" smilref="Title.smil#_15778"> Invalidated events. Many of the collisions that we predict do not actually happen because some other collision intervenes. To handle this situ- ation, we maintain an instance variable for each particle that counts the number of collisions in which it has been involved. When we remove an event from the priority queue for processing, we check whether the counts corresponding to its particle(s) have changed since the event was creat- ed. This approach to handling invalidated collisions is the so-called lazy approach: when a particle is involved in a colli- sion, we leave the now-invalid events associated with it on the priority queue and essentially ignore them when they come off. An alternative approach, the so-called eager approach, is to remove from the priority queue all events involving any colliding particle before calculating all of the new potential collisions for that particle. This approach requires a more sophisticated priority queue (that implements the remove operation).</p><p attribs="{'xml:space': 'preserve'}" id="_15779" smilref="Title.smil#_15779"> particle moving away from a wall</p><p attribs="{'xml:space': 'preserve'}" id="_15780" smilref="Title.smil#_15780"> particles moving away from each other</p><p attribs="{'xml:space': 'preserve'}" id="_15781" smilref="Title.smil#_15781"> particles moving on a collision course</p><p attribs="{'xml:space': 'preserve'}" id="_15782" smilref="Title.smil#_15782"> Predictable events</p><p attribs="{'xml:space': 'preserve'}" id="_15783" smilref="Title.smil#_15783"> one particle reaching potential collision point before the other</p><p attribs="{'xml:space': 'preserve'}" id="_15784" smilref="Title.smil#_15784"> collision too far into the future</p><p attribs="{'xml:space': 'preserve'}" id="_15785" smilref="Title.smil#_15785"> Predictable non-events</p><p attribs="{'xml:space': 'preserve'}" id="_15786" smilref="Title.smil#_15786"> This discussion sets the stage for a full event-driven simulation of particles in motion, interacting according to the physical laws of elastic collisions. The software architecture is to encapsulate the implementation in three classes: a Particle data type that encapsulates calculations that involve particles, an Event data type for predicted events, and a CollisionSystem client that does the simulation. The centerpiece of the simulation is a MinPQ that contains events, ordered by time. Next, we consider implementations of Particle,</p><p attribs="{'xml:space': 'preserve'}" id="_15787" smilref="Title.smil#_15787"> two particles on a collision course</p><p attribs="{'xml:space': 'preserve'}" id="_15788" smilref="Title.smil#_15788"> Event, and CollisionSystem.</p><p attribs="{'xml:space': 'preserve'}" id="_15789" smilref="Title.smil#_15789"> third particle interferes: no collision</p><p attribs="{'xml:space': 'preserve'}" id="_15790" smilref="Title.smil#_15790"> An invalidated event</p><p attribs="{'xml:space': 'preserve'}" id="_15791" smilref="Title.smil#_15791" /><pagenum id="p873" page="normal" smilref="Title.smil#p873" /><p attribs="{'xml:space': 'preserve'}" id="_15792" smilref="Title.smil#_15792"> 860</p><p attribs="{'xml:space': 'preserve'}" id="_15793" smilref="Title.smil#_15793"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15794" smilref="Title.smil#_15794"> Particles. Exercise 6.1 outlines the implementation of a data type particles, based on a direct application of Newton&#8217;s laws of motion. A simulation client needs to be able to move particles, draw them, and perform a number of calculations related to collisions, as detailed in the following API:</p><p attribs="{'xml:space': 'preserve'}" id="_15795" smilref="Title.smil#_15795"> public class Particle</p><p attribs="{'xml:space': 'preserve'}" id="_15796" smilref="Title.smil#_15796"> Particle()</p><p attribs="{'xml:space': 'preserve'}" id="_15797" smilref="Title.smil#_15797"> void draw()</p><p attribs="{'xml:space': 'preserve'}" id="_15798" smilref="Title.smil#_15798"> void move(double dt)</p><p attribs="{'xml:space': 'preserve'}" id="_15799" smilref="Title.smil#_15799"> int count()</p><p attribs="{'xml:space': 'preserve'}" id="_15800" smilref="Title.smil#_15800"> Particle( double rx, double ry, double vx, double vy, double s, double mass)</p><p attribs="{'xml:space': 'preserve'}" id="_15801" smilref="Title.smil#_15801"> create a new random particle in unit square create a particle with the given position, velocity, radius, and mass draw the particle change position to refl ect passage of time dt number of collisions involving this particle time until this particle hits particle b double timeToHitHorizontalWall() time until this particle hits a horizontal wall time until this particle hits a vertical wall change particle velocities to refl ect collision void bounceOffHorizontalWall() change velocity to refl ect hitting horizontal wall change velocity to refl ect hitting vertical wall</p><p attribs="{'xml:space': 'preserve'}" id="_15802" smilref="Title.smil#_15802"> double timeToHitVericaltWall()</p><p attribs="{'xml:space': 'preserve'}" id="_15803" smilref="Title.smil#_15803"> double timeToHit(Particle b)</p><p attribs="{'xml:space': 'preserve'}" id="_15804" smilref="Title.smil#_15804"> void bounceOff(Particle b)</p><p attribs="{'xml:space': 'preserve'}" id="_15805" smilref="Title.smil#_15805"> void bounceOffVerticalWall()</p><p attribs="{'xml:space': 'preserve'}" id="_15806" smilref="Title.smil#_15806"> API for moving-particle objects</p><p attribs="{'xml:space': 'preserve'}" id="_15807" smilref="Title.smil#_15807"> The three timeToHit*() methods all return Double.POSITIVE_INFINITY for the (rather common) case when there is no collision course. These methods allow us to predict all future collisions that are associated with a given particle, putting an event on a priority queue corresponding to each one that happens before a given time limit. We use the bounce() method each time that we process an event that corresponds to two particles colliding to change the velocities (of both particles) to reflect the collision, and the bounceOff*() methods for events corresponding to collisions between a particle and a wall.</p><p attribs="{'xml:space': 'preserve'}" id="_15808" smilref="Title.smil#_15808" /><pagenum id="p874" page="normal" smilref="Title.smil#p874" /><p attribs="{'xml:space': 'preserve'}" id="_15809" smilref="Title.smil#_15809"> Event-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15810" smilref="Title.smil#_15810"> 861</p><p attribs="{'xml:space': 'preserve'}" id="_15811" smilref="Title.smil#_15811"> Events. We encapsulate in a private class the description of the objects to be placed on the priority queue (events). The instance variable time holds the time when the event is predicted to happen, and the instance variables a and b hold the particles associated with the event. We have three different types of events: a particle may hit a vertical wall, a horizontal wall, or another particle. To develop a smooth dynamic display of the particles in motion, we add a fourth event type, a redraw event that is a command to draw all the particles at their current positions. A slight twist in the implementation of Event is that we use the fact that particle values may be null to encode these four different types of events, as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_15812" smilref="Title.smil#_15812"> private static class Event implements Comparable&lt;Event&gt; { private final double time; private final Particle a, b; private final int countA, countB;</p><p attribs="{'xml:space': 'preserve'}" id="_15813" smilref="Title.smil#_15813"> public Event(double t, Particle a, Particle b) { // Create a new event to occur at time t involving a and b. this.time = t; this.a = a; this.b = b; if (a != null) countA = a.count(); else countA = -1; if (b != null) countB = b.count(); else countB = -1; }</p><p attribs="{'xml:space': 'preserve'}" id="_15814" smilref="Title.smil#_15814"> public int compareTo(Event that) { if (this.time &lt; that.time) return -1; else if (this.time &gt; that.time) return +1; else return 0; }</p><p attribs="{'xml:space': 'preserve'}" id="_15815" smilref="Title.smil#_15815"> public boolean isValid() { if (a != null &amp;&amp; a.count() != countA) return false; if (b != null &amp;&amp; b.count() != countB) return false; return true; } }</p><p attribs="{'xml:space': 'preserve'}" id="_15816" smilref="Title.smil#_15816"> Event class for particle simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15817" smilref="Title.smil#_15817" /><pagenum id="p875" page="normal" smilref="Title.smil#p875" /><p attribs="{'xml:space': 'preserve'}" id="_15818" smilref="Title.smil#_15818"> 862</p><p attribs="{'xml:space': 'preserve'}" id="_15819" smilref="Title.smil#_15819"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15820" smilref="Title.smil#_15820"> A second twist in the implementation of Event is that we maintain the instance variables countA and countB to record the number of collisions involving each of the particles at the time the event is created. If these counts are unchanged when the event is removed from the priority queue, we can go ahead and simulate the occurrence of the event, but if one of the counts changes between the time an event goes on the priority queue and the time it leaves, we know that the event has been invalidated and can ignore it. The method isValid() allows client code to test this condition.</p><p attribs="{'xml:space': 'preserve'}" id="_15821" smilref="Title.smil#_15821"> Simulation code. With the computational details encapsulated in Particle and Event, the simulation itself requires remarkably little code, as you can see in the implementation in the class CollisionSystem (see page 863 and page 864). Most of the calculations are encapsulated in the predictCollisions() method shown on this page. This method calculates all potential future collisions involving particle a (either with another particle or with a wall) and puts an event corresponding to each onto the priority queue. The heart of the simulation is the simulate() method shown on page 864. We initialize by calling</p><p attribs="{'xml:space': 'preserve'}" id="_15822" smilref="Title.smil#_15822"> private void predictCollisions(Particle a, double limit) { if (a == null) return; for (int i = 0; i &lt; particles.length; i++) { // Put collision with particles[i] on pq. double dt = a.timeToHit(particles[i]); if (t + dt &lt;= limit) pq.insert(new Event(t + dt, a, particles[i])); } double dtX = a.timeToHitVerticalWall(); if (t + dtX &lt;= limit) pq.insert(new Event(t + dtX, a, null)); double dtY = a.timeToHitHorizontalWall(); if (t + dtY &lt;= limit) pq.insert(new Event(t + dtY, null, a)); }</p><p attribs="{'xml:space': 'preserve'}" id="_15823" smilref="Title.smil#_15823"> Predicting collisions with other particles</p><p attribs="{'xml:space': 'preserve'}" id="_15824" smilref="Title.smil#_15824"> p r e d i c t C o l l i s i o n s ( )</p><p attribs="{'xml:space': 'preserve'}" id="_15825" smilref="Title.smil#_15825"> for each particle to fill the priority queue with the potential collisions involving all particle-wall and all particle-particle pairs. Then we enter the main event-driven simulation loop, which works as follows: </p><p attribs="{'xml:space': 'preserve'}" id="_15826" smilref="Title.smil#_15826" /><pagenum id="p876" page="normal" smilref="Title.smil#p876" /><p attribs="{'xml:space': 'preserve'}" id="_15827" smilref="Title.smil#_15827"> Event-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15828" smilref="Title.smil#_15828"> 863</p><p attribs="{'xml:space': 'preserve'}" id="_15829" smilref="Title.smil#_15829"> Event-driven simulation of colliding particles (scaffolding)</p><p attribs="{'xml:space': 'preserve'}" id="_15830" smilref="Title.smil#_15830"> public class CollisionSystem { private class Event implements Comparable&lt;Event&gt; { /* See text. */ }</p><p attribs="{'xml:space': 'preserve'}" id="_15831" smilref="Title.smil#_15831"> private MinPQ&lt;Event&gt; pq; private double t = 0.0; private Particle[] particles;</p><p attribs="{'xml:space': 'preserve'}" id="_15832" smilref="Title.smil#_15832"> // the priority queue // simulation clock time // the array of particles</p><p attribs="{'xml:space': 'preserve'}" id="_15833" smilref="Title.smil#_15833"> public CollisionSystem(Particle[] particles) { this.particles = particles; }</p><p attribs="{'xml:space': 'preserve'}" id="_15834" smilref="Title.smil#_15834"> private void predictCollisions(Particle a, double limit) { /* See text. */ }</p><p attribs="{'xml:space': 'preserve'}" id="_15835" smilref="Title.smil#_15835"> public void redraw(double limit, double Hz) { // Redraw event: redraw all particles. StdDraw.clear(); for(int i = 0; i &lt; particles.length; i++) particles[i].draw(); StdDraw.show(20); if (t &lt; limit) pq.insert(new Event(t + 1.0 / Hz, null, null)); }</p><p attribs="{'xml:space': 'preserve'}" id="_15836" smilref="Title.smil#_15836"> public void simulate(double limit, double Hz) { /* See next page. */ }</p><p attribs="{'xml:space': 'preserve'}" id="_15837" smilref="Title.smil#_15837"> public static void main(String[] args) { StdDraw.show(0); int N = Integer.parseInt(args[0]); Particle[] particles = new Particle[N]; for (int i = 0; i &lt; N; i++) particles[i] = new Particle(); CollisionSystem system = new CollisionSystem(particles); system.simulate(10000, 0.5); } }</p><p attribs="{'xml:space': 'preserve'}" id="_15838" smilref="Title.smil#_15838"> This class is a priority-queue client that simulates the motion of a system of particles over time. The main() test client takes a command-line argument N, creates N random particles, creates a CollisionSystem consisting of the particles, and calls simulate() to do the simulation. The instance variables are a priority queue for the simulation, the time, and the particles.</p><p attribs="{'xml:space': 'preserve'}" id="_15839" smilref="Title.smil#_15839" /><pagenum id="p877" page="normal" smilref="Title.smil#p877" /><p attribs="{'xml:space': 'preserve'}" id="_15840" smilref="Title.smil#_15840"> 864</p><p attribs="{'xml:space': 'preserve'}" id="_15841" smilref="Title.smil#_15841"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15842" smilref="Title.smil#_15842"> Event-driven simulation of colliding particles (primary loop)</p><p attribs="{'xml:space': 'preserve'}" id="_15843" smilref="Title.smil#_15843"> public void simulate(double limit, double Hz) { pq = new MinPQ&lt;Event&gt;(); for (int i = 0; i &lt; particles.length; i++) predictCollisions(particles[i], limit); pq.insert(new Event(0, null, null)); // Add redraw event.</p><p attribs="{'xml:space': 'preserve'}" id="_15844" smilref="Title.smil#_15844"> while (!pq.isEmpty()) { // Process one event to drive simulation. Event event = pq.delMin(); if (!event.isValid()) continue; for (int i = 0; i &lt; particles.length; i++) particles[i].move(event.time - t); // Update particle positions t = event.time; // and time. Particle a = event.a, b = event.b; if (a != null &amp;&amp; b != null) a.bounceOff(b); else if (a != null &amp;&amp; b == null) a.bounceOffHorizontalWall(); else if (a == null &amp;&amp; b != null) b.bounceOffVerticalWall(); else if (a == null &amp;&amp; b == null) redraw(limit, Hz); predictCollisions(a, limit); predictCollisions(b, limit); } }</p><p attribs="{'xml:space': 'preserve'}" id="_15845" smilref="Title.smil#_15845"> This method represents the main event-driven simulation. First, the priority queue is initialized with events representing all predicted future collisions involving each particle. Then the main loop takes an event from the queue, updates time and particle positions, and adds new events to reflect changes.</p><p attribs="{'xml:space': 'preserve'}" id="_15846" smilref="Title.smil#_15846"> % java CollisonSystem 5</p><p attribs="{'xml:space': 'preserve'}" id="_15847" smilref="Title.smil#_15847"> a co l l i s ion</p><p attribs="{'xml:space': 'preserve'}" id="_15848" smilref="Title.smil#_15848" /><pagenum id="p878" page="normal" smilref="Title.smil#p878" /><p attribs="{'xml:space': 'preserve'}" id="_15849" smilref="Title.smil#_15849"> Event-driven simulation</p><p attribs="{'xml:space': 'preserve'}" id="_15850" smilref="Title.smil#_15850"> 865</p><p attribs="{'xml:space': 'preserve'}" id="_15851" smilref="Title.smil#_15851"> of interest is the amount of pressure exerted by the particles against the walls. One way to calculate the pressure is to keep track of the number and magnitude of wall collisions (an easy computation based on particle mass and velocity) so that we can easily compute the total . Temperature involves a similar calculation.</p><p attribs="{'xml:space': 'preserve'}" id="_15852" smilref="Title.smil#_15852"> Performance. As described at the outset, our interest in event-driven simulation is to avoid the computationally intensive inner loop intrinsic in time-driven simulation.</p><p attribs="{'xml:space': 'preserve'}" id="_15853" smilref="Title.smil#_15853"> Proposition A. An event-driven simulation of N colliding particles requires at most N 2 priority queue operations for initialization, and at most N priority queue operations per collision (with one extra priority queue operation for each invalid collision).</p><p attribs="{'xml:space': 'preserve'}" id="_15854" smilref="Title.smil#_15854"> Proof Immediate from the code.</p><p attribs="{'xml:space': 'preserve'}" id="_15855" smilref="Title.smil#_15855"> Using our standard guaranteed-logarithmic-time-per operation priority-queue implementation from Section 2.4, the time needed per collision is linearithmic. Simulations with large numbers of particles are therefore quite feasible.</p><p attribs="{'xml:space': 'preserve'}" id="_15856" smilref="Title.smil#_15856"> Event-driven simulation applies to countless other domains that involve physical modeling of moving objects, from molecular modeling to astrophysics to robotics. Such applications may involve extending the model to add other kinds of bodies, to operate in three dimensions, to include other forces, and in many other ways. Each extension involves its own computational challenges. This event-driven approach results in a more robust, accurate, and efficient simulation than many other alternatives that we might consider, and the efficiency of the heap-based priority queue enables calculations that might not otherwise be possible. Simulation plays a vital role in helping researchers to understand properties of the natural world in all fields of science and engineering. Applications ranging from manufacturing processes to biological systems to financial systems to complex engineered structures are too numerous to even list here. For a great many of these applications, the extra efficiency afforded by the heap-based priority queue data type or an efficient sorting algorithm can make a substantial difference in the quality and extent that are possible in the simulation.</p><p attribs="{'xml:space': 'preserve'}" id="_15857" smilref="Title.smil#_15857" /></level3><level3 id="_00122"><h3 id="ch6-s2-ss4" smilref="Title.smil#ch6-s2-ss4" xml:space="preserve">Cost model</h3><p attribs="{'xml:space': 'preserve'}" id="_15858" smilref="Title.smil#_15858"> 866</p><p attribs="{'xml:space': 'preserve'}" id="_15859" smilref="Title.smil#_15859"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15860" smilref="Title.smil#_15860"> B-trees</p><p attribs="{'xml:space': 'preserve'}" id="_15861" smilref="Title.smil#_15861"> In Chapter 3, we saw that algorithms that are appropriate for accessing items from huge collections of data are of immense practical importance. Searching is a fundamental operation on huge data sets, and such searching consumes a significant fraction of the resources used in many computing environments. With the advent of the web, we have the ability to access a vast amount of information that might be relevant to a task&#8212;our challenge is to be able to search through it ef&#64257; ciently. In this section, we describe a further extension of the balanced-tree algorithms from Section 3.3 that can support external search in symbol tables that are kept on a disk or on the web and are thus potentially far larger than those we have been considering (which have to fit in addressable memory). Modern software systems are blurring the distinction between local files and web pages, which may be stored on a remote computer, so the amount of data that we might wish to search is virtually unlimited. Remarkably, the methods that we shall study can support search and insert operations on symbol tables containing trillions of items or more using only four or five references to small blocks of data.</p><p attribs="{'xml:space': 'preserve'}" id="_15862" smilref="Title.smil#_15862"> B-tree cost model. When study-</p><p attribs="{'xml:space': 'preserve'}" id="_15863" smilref="Title.smil#_15863"> Cost model. Data storage mechanisms vary widely and continue to evolve, so we use a simple model to capture the essentials. We use the term page to refer to a contiguous block of data and the term probe to refer to the first access to a page. We assume that accessing a page involves reading its contents into local memory, so that subsequent accesses are relatively inexpensive. A page could be a file on your local computer or a web page on a distant computer or part of a file on a server, or whatever. Our goal is to develop search implementations that use a small number of probes to find any given key. We avoid making specific assumptions about the page size and about the ratio of the time required for a probe (which presumably requires communicating with a distant device) to the time required, subsequently, to access items within the block (which presumably happens in a local processor). In typical situations, these values are likely to be on the order of 100 or 1,000 or 10,000; we do not need to be more precise because the algorithms are not highly sensitive to differences in the values in the ranges of interest. B-trees. The approach is to extend the 2-3 tree data structure described in Section 3.3, with a crucial difference: rather than store the data in the tree, we build a tree with copies of the keys, each key copy associated with a link. This approach enables us to more easily separate the index from the table itself, much like the index in a book. As with 2-3 trees, we enforce upper and lower bounds on the number of key-link pairs</p><p attribs="{'xml:space': 'preserve'}" id="_15864" smilref="Title.smil#_15864"> ing algorithms for external searching, we count page accesses (the number of times a page is ac- cessed, for read or write).</p><p attribs="{'xml:space': 'preserve'}" id="_15865" smilref="Title.smil#_15865" /><p attribs="{'xml:space': 'preserve'}" id="_15866" smilref="Title.smil#_15866"> B-trees</p><p attribs="{'xml:space': 'preserve'}" id="_15867" smilref="Title.smil#_15867"> 867</p><p attribs="{'xml:space': 'preserve'}" id="_15868" smilref="Title.smil#_15868"> that can be in each node: we choose a parameter M (an even number, by convention) and build multiway trees where every node must have at most M &#11002; 1 key-link pairs (we assume that M is sufficiently small that an M-way node will fit on a page) and at least M/2 key-link pairs (to provide the branching that we need to keep search paths short), except possibly the root, which can have fewer than M/2 key-link pairs but must have at least 2. Such trees were named B-trees by Bayer and McCreight, who, in 1970, were the first researchers to consider the use of multiway balanced trees for external search- ing. Some people reserve the term B-tree to describe the exact data structure built by the algorithm suggested by Bayer and McCreight; we use it as a generic term for data structures based on multiway balanced search trees with a fixed page size. We specify the value of M by using the terminology &#8220;B-tree of order M.&#8221; In a B-tree of order 4, each node has at most 3 and at least 2 key-link pairs; in a B-tree of order 6, each node has at most 5 and at least 3 link pairs (except possibly the root, which could have 2 key-link pairs), and so forth. The reason for the exception at the root for larger M will become clear when we consider the construction algorithm in detail.</p><p attribs="{'xml:space': 'preserve'}" id="_15869" smilref="Title.smil#_15869"> Conventions. To illustrate the basic mechanisms, we consider an (ordered) SET implementation (with keys and no values). Extending to provide an ordered ST to associate keys with values is an instructive exercise (see Exercise 6.16). Our goal is to support add() and contains() for a set of keys that could be huge. We use ordered keys because we are generalizing search trees, which are based on ordered keys. Extending our implementation to support other ordered operations is also an instructive exercise. In external searching applications, it is common to keep the index separate from the data. For B-trees, we do so by using two different kinds of nodes: </p><p attribs="{'xml:space': 'preserve'}" id="_15870" smilref="Title.smil#_15870"> sentinel key</p><p attribs="{'xml:space': 'preserve'}" id="_15871" smilref="Title.smil#_15871"> * D H</p><p attribs="{'xml:space': 'preserve'}" id="_15872" smilref="Title.smil#_15872"> external 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_15873" smilref="Title.smil#_15873"> * K</p><p attribs="{'xml:space': 'preserve'}" id="_15874" smilref="Title.smil#_15874"> 2-node</p><p attribs="{'xml:space': 'preserve'}" id="_15875" smilref="Title.smil#_15875"> internal 3-node</p><p attribs="{'xml:space': 'preserve'}" id="_15876" smilref="Title.smil#_15876"> each red key is a copy of min key in subtree</p><p attribs="{'xml:space': 'preserve'}" id="_15877" smilref="Title.smil#_15877"> K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15878" smilref="Title.smil#_15878"> external 5-node (full)</p><p attribs="{'xml:space': 'preserve'}" id="_15879" smilref="Title.smil#_15879"> external 4-node</p><p attribs="{'xml:space': 'preserve'}" id="_15880" smilref="Title.smil#_15880"> * B C</p><p attribs="{'xml:space': 'preserve'}" id="_15881" smilref="Title.smil#_15881"> D E F</p><p attribs="{'xml:space': 'preserve'}" id="_15882" smilref="Title.smil#_15882"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15883" smilref="Title.smil#_15883"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15884" smilref="Title.smil#_15884"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15885" smilref="Title.smil#_15885"> U W X Y</p><p attribs="{'xml:space': 'preserve'}" id="_15886" smilref="Title.smil#_15886"> client keys (black) are in external nodes</p><p attribs="{'xml:space': 'preserve'}" id="_15887" smilref="Title.smil#_15887"> all nodes except the root are 3-, 4- or 5-nodes</p><p attribs="{'xml:space': 'preserve'}" id="_15888" smilref="Title.smil#_15888"> Anatomy of a B-tree set (M = 6)</p><p attribs="{'xml:space': 'preserve'}" id="_15889" smilref="Title.smil#_15889" /></level3><level3 id="_00123"><h3 id="ch6-s2-ss5" smilref="Title.smil#ch6-s2-ss5" xml:space="preserve">Search and insert</h3><pagenum id="p881" page="normal" smilref="Title.smil#p881" /><p attribs="{'xml:space': 'preserve'}" id="_15890" smilref="Title.smil#_15890"> 868</p><p attribs="{'xml:space': 'preserve'}" id="_15891" smilref="Title.smil#_15891"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15892" smilref="Title.smil#_15892"> any. It is convenient to use a special key, known as a sentinel, that is defined to be less than all other keys, and to start with a root node containing that key, associated with the tree containing all the keys. The symbol table does not contain duplicate keys, but we use copies of keys (in internal nodes) to guide the search. (In our examples, we use single-letter keys and the character * as the sentinel that is less than all other keys.) These conventions simplify the code somewhat and thus represent a convenient (and widely used) alternative to mixing all the data with links in the internal nodes, as we have done for other search trees.</p><p attribs="{'xml:space': 'preserve'}" id="_15893" smilref="Title.smil#_15893"> Search and insert. Search in a B-tree is based on recursively searching in the unique subtree that could contain the search key. Every search ends in an external node that contains the key if and only if it is in the set. We might also terminate a search hit when encountering a copy of the search key in an internal node, but we always search to an external node because doing so simplifies extending the code to an ordered symbol- table implementation (also, this event rarely happens when M is large). To be speci&#64257; c, consider searching in a B-tree of order 6: it consists of 3-nodes with 3 key-link pairs, 4-nodes with 4 key-link pairs, and 5-nodes with 5 key-link pairs, with possibly a 2-node at the root. To search, we start at the root and move from one node to the next by fi nd- ing the proper interval for the search key in the current node and then exiting through the corresponding link to get to the next node. Eventually, the search process leads us to a page containing keys at the bottom of the tree. We terminate the search with a search hit if the search key is in that page; we terminate with a search miss if it is not. As with 2-3 trees, we can use recursive code to insert a new key at the bottom of the tree. If there is no room for the key, we allow the node at the bottom to temporarily overflow (be- come a 6-node) and then split 6-nodes on the way up the tree, after the recursive call. If the root is an 6-node, we split it into a 2-node connected to two 3-nodes; elsewhere in the tree, we replace any k-node attached to a 6-node by a (k+1)-node attached to two 3-nodes. Replacing 3 by M/2 and 6 by M in this description converts it into a description of search and insert for B-trees of order M and leads to the following defi nition:</p><p attribs="{'xml:space': 'preserve'}" id="_15894" smilref="Title.smil#_15894"> Definition. A B-tree of order M (where M is an even positive integer) is a tree that either is an external k-node (with k keys and associated information) or comprises internal k-nodes (each with k keys and k links to B-trees representing each of the k intervals delimited by the keys), having the following structural properties: every path from the root to an external node must be the same length ( perfect balance); and k must be between 2 and M &#11002; 1 at the root and between M/2 and M &#11002; 1 at every other node.</p><p attribs="{'xml:space': 'preserve'}" id="_15895" smilref="Title.smil#_15895" /><pagenum id="p882" page="normal" smilref="Title.smil#p882" /><p attribs="{'xml:space': 'preserve'}" id="_15896" smilref="Title.smil#_15896"> B-trees</p><p attribs="{'xml:space': 'preserve'}" id="_15897" smilref="Title.smil#_15897"> 869</p><p attribs="{'xml:space': 'preserve'}" id="_15898" smilref="Title.smil#_15898"> searching for E</p><p attribs="{'xml:space': 'preserve'}" id="_15899" smilref="Title.smil#_15899"> * K</p><p attribs="{'xml:space': 'preserve'}" id="_15900" smilref="Title.smil#_15900"> follow this link because E is between * and K</p><p attribs="{'xml:space': 'preserve'}" id="_15901" smilref="Title.smil#_15901"> * D H</p><p attribs="{'xml:space': 'preserve'}" id="_15902" smilref="Title.smil#_15902"> follow this link because E is between D and H</p><p attribs="{'xml:space': 'preserve'}" id="_15903" smilref="Title.smil#_15903"> K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15904" smilref="Title.smil#_15904"> * B C</p><p attribs="{'xml:space': 'preserve'}" id="_15905" smilref="Title.smil#_15905"> D E F</p><p attribs="{'xml:space': 'preserve'}" id="_15906" smilref="Title.smil#_15906"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15907" smilref="Title.smil#_15907"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15908" smilref="Title.smil#_15908"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15909" smilref="Title.smil#_15909"> U W X</p><p attribs="{'xml:space': 'preserve'}" id="_15910" smilref="Title.smil#_15910"> search for E in this external node</p><p attribs="{'xml:space': 'preserve'}" id="_15911" smilref="Title.smil#_15911"> Searching in a B-tree set (M = 6)</p><p attribs="{'xml:space': 'preserve'}" id="_15912" smilref="Title.smil#_15912"> inserting A</p><p attribs="{'xml:space': 'preserve'}" id="_15913" smilref="Title.smil#_15913"> * H K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15914" smilref="Title.smil#_15914"> * B C E F</p><p attribs="{'xml:space': 'preserve'}" id="_15915" smilref="Title.smil#_15915"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15916" smilref="Title.smil#_15916"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15917" smilref="Title.smil#_15917"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15918" smilref="Title.smil#_15918"> U W X</p><p attribs="{'xml:space': 'preserve'}" id="_15919" smilref="Title.smil#_15919"> * H K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15920" smilref="Title.smil#_15920"> * A B C E F</p><p attribs="{'xml:space': 'preserve'}" id="_15921" smilref="Title.smil#_15921"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15922" smilref="Title.smil#_15922"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15923" smilref="Title.smil#_15923"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15924" smilref="Title.smil#_15924"> U W X</p><p attribs="{'xml:space': 'preserve'}" id="_15925" smilref="Title.smil#_15925"> new key (A) causes overflow and split</p><p attribs="{'xml:space': 'preserve'}" id="_15926" smilref="Title.smil#_15926"> * C H K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15927" smilref="Title.smil#_15927"> new key (C) causes overflow and split</p><p attribs="{'xml:space': 'preserve'}" id="_15928" smilref="Title.smil#_15928"> * A B</p><p attribs="{'xml:space': 'preserve'}" id="_15929" smilref="Title.smil#_15929"> C E F</p><p attribs="{'xml:space': 'preserve'}" id="_15930" smilref="Title.smil#_15930"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15931" smilref="Title.smil#_15931"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15932" smilref="Title.smil#_15932"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15933" smilref="Title.smil#_15933"> U W X</p><p attribs="{'xml:space': 'preserve'}" id="_15934" smilref="Title.smil#_15934"> * K</p><p attribs="{'xml:space': 'preserve'}" id="_15935" smilref="Title.smil#_15935"> * C H</p><p attribs="{'xml:space': 'preserve'}" id="_15936" smilref="Title.smil#_15936"> root split causes a new root to be created</p><p attribs="{'xml:space': 'preserve'}" id="_15937" smilref="Title.smil#_15937"> K Q U</p><p attribs="{'xml:space': 'preserve'}" id="_15938" smilref="Title.smil#_15938"> * A B</p><p attribs="{'xml:space': 'preserve'}" id="_15939" smilref="Title.smil#_15939"> C E F</p><p attribs="{'xml:space': 'preserve'}" id="_15940" smilref="Title.smil#_15940"> H I J</p><p attribs="{'xml:space': 'preserve'}" id="_15941" smilref="Title.smil#_15941"> K M N O P</p><p attribs="{'xml:space': 'preserve'}" id="_15942" smilref="Title.smil#_15942"> Q R T</p><p attribs="{'xml:space': 'preserve'}" id="_15943" smilref="Title.smil#_15943"> U W X</p><p attribs="{'xml:space': 'preserve'}" id="_15944" smilref="Title.smil#_15944"> Inserting a new key into a B-tree set</p><p attribs="{'xml:space': 'preserve'}" id="_15945" smilref="Title.smil#_15945" /><pagenum id="p883" page="normal" smilref="Title.smil#p883" /><p attribs="{'xml:space': 'preserve'}" id="_15946" smilref="Title.smil#_15946"> 870</p><p attribs="{'xml:space': 'preserve'}" id="_15947" smilref="Title.smil#_15947"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15948" smilref="Title.smil#_15948"> Representation. As just discussed, we have a great deal of freedom in choosing concrete representations for nodes in B-trees. We encapsulate these choices in a Page API that associates keys with links to Page objects and supports the operations that we need to test for overfull pages, split them, and distinguish between internal and external pages. You can think of a Page as a symbol table, kept externally (in a file on your computer or on the web). The terms open and close in the API refer to the process of bringing an external page into internal memory and writing its contents back out (if necessary). The add() method for internal pages is a symbol-table operation that associates the given page with the minimum key in the tree rooted at that page. The put() and contains() methods for external pages are like their corresponding SET opera- tions. The workhorse of any implementation is the split() method, which splits a full page by moving the M/2 key-value pairs of rank greater than M/2 to a new Page and returns a reference to that page. Exercise 6.15 discusses an implementation of Page using BinarySearchST, which implements B-trees in memory, like our other search implementations. On some systems, this might suffice as an external searching implementation because a virtual-memory system might take care of disk references. More typical practical implementations might involve hardware-speci&#64257; c code that reads and</p><p attribs="{'xml:space': 'preserve'}" id="_15949" smilref="Title.smil#_15949"> public class Page&lt;Key&gt;</p><p attribs="{'xml:space': 'preserve'}" id="_15950" smilref="Title.smil#_15950"> Page(boolean bottom)</p><p attribs="{'xml:space': 'preserve'}" id="_15951" smilref="Title.smil#_15951"> void close()</p><p attribs="{'xml:space': 'preserve'}" id="_15952" smilref="Title.smil#_15952"> void add(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_15953" smilref="Title.smil#_15953"> void add(Page p)</p><p attribs="{'xml:space': 'preserve'}" id="_15954" smilref="Title.smil#_15954"> boolean isExternal()</p><p attribs="{'xml:space': 'preserve'}" id="_15955" smilref="Title.smil#_15955"> boolean contains(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_15956" smilref="Title.smil#_15956"> Page next(Key key)</p><p attribs="{'xml:space': 'preserve'}" id="_15957" smilref="Title.smil#_15957"> boolean isFull()</p><p attribs="{'xml:space': 'preserve'}" id="_15958" smilref="Title.smil#_15958"> Page split()</p><p attribs="{'xml:space': 'preserve'}" id="_15959" smilref="Title.smil#_15959"> Iterable&lt;Key&gt; keys()</p><p attribs="{'xml:space': 'preserve'}" id="_15960" smilref="Title.smil#_15960"> create and open a page close a page add key into the (external) page open p and add an entry into this (internal) page that associates the smallest key in p with p is this page external? is key in the page? the subtree that could contain the key has the page overfl owed? move the highest-ranking half of the keys in the page to a new page iterator for the keys on the page</p><p attribs="{'xml:space': 'preserve'}" id="_15961" smilref="Title.smil#_15961"> API for a B-tree page</p><p attribs="{'xml:space': 'preserve'}" id="_15962" smilref="Title.smil#_15962" /><pagenum id="p884" page="normal" smilref="Title.smil#p884" /><p attribs="{'xml:space': 'preserve'}" id="_15963" smilref="Title.smil#_15963"> B-trees</p><p attribs="{'xml:space': 'preserve'}" id="_15964" smilref="Title.smil#_15964"> 871</p><p attribs="{'xml:space': 'preserve'}" id="_15965" smilref="Title.smil#_15965"> writes pages. Exercise 6.19 encourages you to think about implementing Page using web pages. We ignore such details here in the text to emphasize the utility of the B-tree concept in a broad variety of settings. With these preparations, the code for BTreeSET on page 872 is remarkably simple. For contains(), we use a recursive method that takes a Page as argument and handles three cases: </p><p attribs="{'xml:space': 'preserve'}" id="_15966" smilref="Title.smil#_15966"> Performance. The most important property of B-trees is that for reasonable values of the parameter M the search cost is constant, for all practical purposes:</p><p attribs="{'xml:space': 'preserve'}" id="_15967" smilref="Title.smil#_15967"> Proposition B. A search or an insertion in a B-tree of order M with N items requires between logM N and logM/2 N probes&#8212;a constant number, for practical purposes. Proof This property follows from the observation that all the nodes in the interior of the tree (nodes that are not the root and are not external) have between M/2 and M &#11002; 1 links, since they are formed from a split of a full node with M keys and can only grow in size (when a child is split). In the best case, these nodes form a complete tree of branching factor M &#11002; 1, which leads immediately to the stated bound. In the worst case, we have a root with two entries each of which refers to a complete tree of degree M/2. Taking the logarithm to the base M results in a very small number&#8212;for example, when M is 1,000, the height of the tree is less than 4 for N less than 62.5 billion.</p><p attribs="{'xml:space': 'preserve'}" id="_15968" smilref="Title.smil#_15968"> In typical situations, we can reduce the cost by one probe by keeping the root in internal memory. For searching on disk or on the web, we might take this step explicitly before embarking on any application involving a huge number of searches; in a virtual memory with caching, the root node will be the one most likely to be in fast memory, because it is the most frequently accessed node.</p><p attribs="{'xml:space': 'preserve'}" id="_15969" smilref="Title.smil#_15969"> Space. The space usage of B-trees is also of interest in practical applications. By con- struction, the pages are at least half full, so, in the worst case, B-trees use about double the space that is absolutely necessary for keys, plus extra space for links. For random keys, A. Yao proved in 1979 (using mathematical analysis that is beyond the scope of</p><p attribs="{'xml:space': 'preserve'}" id="_15970" smilref="Title.smil#_15970" /><pagenum id="p885" page="normal" smilref="Title.smil#p885" /><p attribs="{'xml:space': 'preserve'}" id="_15971" smilref="Title.smil#_15971"> 872</p><p attribs="{'xml:space': 'preserve'}" id="_15972" smilref="Title.smil#_15972"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15973" smilref="Title.smil#_15973"> ALGORITHM 6.12 B-tree set implementation</p><p attribs="{'xml:space': 'preserve'}" id="_15974" smilref="Title.smil#_15974"> public class BTreeSET&lt;Key extends Comparable&lt;Key&gt;&gt; { private Page root = new Page(true);</p><p attribs="{'xml:space': 'preserve'}" id="_15975" smilref="Title.smil#_15975"> public BTreeSET(Key sentinel) { add(sentinel); }</p><p attribs="{'xml:space': 'preserve'}" id="_15976" smilref="Title.smil#_15976"> public boolean contains(Key key) { return contains(root, key); }</p><p attribs="{'xml:space': 'preserve'}" id="_15977" smilref="Title.smil#_15977"> private boolean contains(Page h, Key key) { if (h.isExternal()) return h.contains(key); return contains(h.next(key), key); }</p><p attribs="{'xml:space': 'preserve'}" id="_15978" smilref="Title.smil#_15978"> public void add(Key key) { add(root, key); if (root.isFull()) { Page lefthalf = root; Page righthalf = root.split(); root = new Page(false); root.add(lefthalf); root.add(righthalf); } }</p><p attribs="{'xml:space': 'preserve'}" id="_15979" smilref="Title.smil#_15979"> public void add(Page h, Key key) { if (h.isExternal()) { h.add(key); return; }</p><p attribs="{'xml:space': 'preserve'}" id="_15980" smilref="Title.smil#_15980"> Page next = h.next(key); add(next, key); if (next.isFull()) h.add(next.split()); next.close(); } }</p><p attribs="{'xml:space': 'preserve'}" id="_15981" smilref="Title.smil#_15981"> This B-tree implementation implements multiway balanced search trees as described in the text, using a Page data type that supports search by associating keys with subtrees that could contain the key and supports insertion by including a test for overflow and a page split method.</p><p attribs="{'xml:space': 'preserve'}" id="_15982" smilref="Title.smil#_15982" /><pagenum id="p886" page="normal" smilref="Title.smil#p886" /><p attribs="{'xml:space': 'preserve'}" id="_15983" smilref="Title.smil#_15983"> B-trees</p><p attribs="{'xml:space': 'preserve'}" id="_15984" smilref="Title.smil#_15984"> 873</p><p attribs="{'xml:space': 'preserve'}" id="_15985" smilref="Title.smil#_15985"> each line shows the result of inserting one key in some page</p><p attribs="{'xml:space': 'preserve'}" id="_15986" smilref="Title.smil#_15986"> white: unoccupied portion of page</p><p attribs="{'xml:space': 'preserve'}" id="_15987" smilref="Title.smil#_15987"> black: occupied portion of page</p><p attribs="{'xml:space': 'preserve'}" id="_15988" smilref="Title.smil#_15988"> full page, about to split</p><p attribs="{'xml:space': 'preserve'}" id="_15989" smilref="Title.smil#_15989"> full page splits into two half -full pages then a new key is added to one of them</p><p attribs="{'xml:space': 'preserve'}" id="_15990" smilref="Title.smil#_15990"> Building a large B-tree</p><p attribs="{'xml:space': 'preserve'}" id="_15991" smilref="Title.smil#_15991" /><pagenum id="p887" page="normal" smilref="Title.smil#p887" /><p attribs="{'xml:space': 'preserve'}" id="_15992" smilref="Title.smil#_15992"> 874</p><p attribs="{'xml:space': 'preserve'}" id="_15993" smilref="Title.smil#_15993"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_15994" smilref="Title.smil#_15994"> this book) that the average number of keys in a node is about M ln 2, so about 44 percent of the space is unused. As with many other search algorithms, this random model reasonably predicts results for key distributions that we observe in practice.</p><p attribs="{'xml:space': 'preserve'}" id="_15995" smilref="Title.smil#_15995"> The implications of Proposition B are profound and worth contemplating. Would</p><p attribs="{'xml:space': 'preserve'}" id="_15996" smilref="Title.smil#_15996"> you have guessed that you can develop a search implementation that can guarantee a cost of four or five probes for search and insert in files as large as you can reasonably contemplate needing to process? B-trees are widely used because they allow us to achieve this ideal. In practice, the primary challenge to developing an implementation is ensuring that space is available for the B-tree nodes, but even that challenge becomes easier to address as available storage space increases on typical devices. Many variations on the basic B-tree abstraction suggest themselves immediately. One class of variations saves time by packing as many page references as possible in internal nodes, thereby increasing the branching factor and flattening the tree. Another class of variations improves storage efficiency by combining nodes with siblings before splitting. The precise choice of variant and algorithm parameter can be engineered to suit particular devices and applications. Although we are limited to getting a small constant factor improvement, such an improvement can be of significant importance for applications where the table is huge and/or huge numbers of transactions are involved, precisely the applications for which B-trees are so effective.</p><p attribs="{'xml:space': 'preserve'}" id="_15997" smilref="Title.smil#_15997" /></level3><level3 id="_00124"><h3 id="ch6-s3-ss6" smilref="Title.smil#ch6-s3-ss6" xml:space="preserve">Longest repeated substring</h3><p attribs="{'xml:space': 'preserve'}" id="_15998" smilref="Title.smil#_15998"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_15999" smilref="Title.smil#_15999"> 875</p><p attribs="{'xml:space': 'preserve'}" id="_16000" smilref="Title.smil#_16000"> Suf&#64257; x arrays Ef&#64257; cient algorithms for string processing play a critical role in commercial applications and in scientific computing. From the countless strings that define web pages that are searched by billions of users to the extensive genomic databases that scientists are studying to unlock the secret of life, computing applications of the 21st century are increasingly string-based. As usual, some classic algorithms are effective, but remarkable new algorithms are being developed. Next, we describe a data structure and an API that support some of these algorithms. We begin by describing a typical (and a classic) string-processing problem.</p><p attribs="{'xml:space': 'preserve'}" id="_16001" smilref="Title.smil#_16001"> Longest repeated substring. What is the longest substring that appears at least twice in a given string? For example, the longest repeated substring in the string "to be or not to be" is the string "to be". Think briefly about how you might solve it. Could you find the longest repeated substring in a string that has millions of char- acters? This problem is simple to state and has many important applications, including data compression, cryptography, and computer-assisted music analysis. For example, a standard technique used in the development of large software systems is refactoring code. Programmers often put together new programs by cutting and pasting code from old programs. In a large program built over a long period of time, replacing duplicate code by function calls to a single copy of the code can make the program much easier to understand and maintain. This improvement can be accomplished by finding long repeated substrings in the program. Another application is found in computational biology. Are substantial identical fragments to be found within a given genome? Again, the basic computational problem underlying this question is to find the longest repeated substring in a string. Scientists are typically interested in more detailed questions (indeed, the nature of the repeated substrings is precisely what scientists seek to under- stand), but such questions are certainly no easier to answer than the basic question of finding the longest repeated substring.</p><p attribs="{'xml:space': 'preserve'}" id="_16002" smilref="Title.smil#_16002"> Brute-force solution. As a warmup, consider the following simple task: given two strings, find their longest common prefix (the longest substring that is a prefix of both strings). For example, the longest common prefix of acctgttaac and accgttaa is acc. The code at right is a useful starting point for addressing more complicated tasks: it takes time proportional to the length of the match. Now, how do we find the longest repeated substring in a given string? With lcp(), the following</p><p attribs="{'xml:space': 'preserve'}" id="_16003" smilref="Title.smil#_16003"> private static int lcp(String s, String t) { int N = Math.min(s.length(), t.length()); for (int i = 0; i &lt; N; i++) if (s.charAt(i) != t.charAt(i)) return i; return N; }</p><p attribs="{'xml:space': 'preserve'}" id="_16004" smilref="Title.smil#_16004"> Longest common pref ix of two strings</p><p attribs="{'xml:space': 'preserve'}" id="_16005" smilref="Title.smil#_16005" /></level3><level3 id="_00125"><h3 id="ch6-s3-ss7" smilref="Title.smil#ch6-s3-ss7" xml:space="preserve">Suffix sorting</h3><pagenum id="p889" page="normal" smilref="Title.smil#p889" /><p attribs="{'xml:space': 'preserve'}" id="_16006" smilref="Title.smil#_16006"> 876</p><p attribs="{'xml:space': 'preserve'}" id="_16007" smilref="Title.smil#_16007"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16008" smilref="Title.smil#_16008"> brute-force solution immediately suggests itself: we compare the substring starting at each string position i with the substring starting at each other starting position j, keeping track of the longest match found. This code is not useful for long strings, because its running time is at least quadratic in the length of the string: the number of different pairs i and j is N (N&#11002;1)&#11408; 2, so the number of calls on lcp() for this approach would be ~N 2/2. Using this solution for a genomic sequence with millions of characters would require trillions of lcp() calls, which is infeasible.</p><p attribs="{'xml:space': 'preserve'}" id="_16009" smilref="Title.smil#_16009"> input string</p><p attribs="{'xml:space': 'preserve'}" id="_16010" smilref="Title.smil#_16010"> suffixes</p><p attribs="{'xml:space': 'preserve'}" id="_16011" smilref="Title.smil#_16011"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13</p><p attribs="{'xml:space': 'preserve'}" id="_16012" smilref="Title.smil#_16012"> 14</p><p attribs="{'xml:space': 'preserve'}" id="_16013" smilref="Title.smil#_16013"> a a c a a g t t t a c a a g c</p><p attribs="{'xml:space': 'preserve'}" id="_16014" smilref="Title.smil#_16014"> Suf&#64257; x sort solution. The following clever approach, which takes advantage of sorting in an unexpected way, is an effective way to find the longest repeated substring, even in a huge string: we use Java&#8217;s substring() method to make an array of strings that consists of the suffixes of s (the substrings starting at each position and going to the end), and then we sort this array. The key to the algorithm is that every substring appears somewhere as a prefix of one of the suffixes in the array. After sorting, the longest repeated substrings will appear in adjacent positions in the array. Thus, we can make a single pass through the sorted array, keeping track of the longest matching prefixes between adjacent strings. This approach is significantly more efficient than the brute-force method, but before implementing and analyzing it, we consider another application of suffix sorting.</p><p attribs="{'xml:space': 'preserve'}" id="_16015" smilref="Title.smil#_16015"> a a c a a g t t t a c a a g c a c a a g t t t a c a a g c c a a g t t t a c a a g c a a g t t t a c a a g c a g t t t a c a a g c g t t t a c a a g c t t t a c a a g c t t a c a a g c t a c a a g c a c a a g c c a a g c a a g c a g c g c c</p><p attribs="{'xml:space': 'preserve'}" id="_16016" smilref="Title.smil#_16016"> sorted suffixes</p><p attribs="{'xml:space': 'preserve'}" id="_16017" smilref="Title.smil#_16017"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14</p><p attribs="{'xml:space': 'preserve'}" id="_16018" smilref="Title.smil#_16018"> 0 11 3 9 1 12 4 14 10 2 13 5 8 7 6</p><p attribs="{'xml:space': 'preserve'}" id="_16019" smilref="Title.smil#_16019"> a a c a a g t t t a c a a g c a a g c a a g t t t a c a a g c a c a a gc a c a a gt t t a c a a g c a g c a g t t t a c a a g c c c a a g c c a a g t t t a c a a g c g c g t t t a c a a g c t a c a a g c t t a c a a g c t t t a c a a g c</p><p attribs="{'xml:space': 'preserve'}" id="_16020" smilref="Title.smil#_16020"> longest repeated substring</p><p attribs="{'xml:space': 'preserve'}" id="_16021" smilref="Title.smil#_16021"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_16022" smilref="Title.smil#_16022"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_16023" smilref="Title.smil#_16023"> a a c a a gt t ta c a a gc</p><p attribs="{'xml:space': 'preserve'}" id="_16024" smilref="Title.smil#_16024"> Computing the LRS by sorting suffixes</p><p attribs="{'xml:space': 'preserve'}" id="_16025" smilref="Title.smil#_16025" /><pagenum id="p890" page="normal" smilref="Title.smil#p890" /><p attribs="{'xml:space': 'preserve'}" id="_16026" smilref="Title.smil#_16026"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16027" smilref="Title.smil#_16027"> 877</p><p attribs="{'xml:space': 'preserve'}" id="_16028" smilref="Title.smil#_16028"> key</p><p attribs="{'xml:space': 'preserve'}" id="_16029" smilref="Title.smil#_16029"> value</p><p attribs="{'xml:space': 'preserve'}" id="_16030" smilref="Title.smil#_16030"> symbol-table search with string keys: find the pages containing the key</p><p attribs="{'xml:space': 'preserve'}" id="_16031" smilref="Title.smil#_16031"> Indexing a string. When you are trying to find a particular substring within a large text&#8212;for example, while working in a text editor or within a page you are viewing with a browser&#8212;you are doing a substring search, the problem we considered in Section 5.3. For that problem, we assume the text to be relatively large and focus on preprocessing the substring, with the goal of being able to efficiently find that substring in any given text. When you type search keys into your web browser, you are doing a search with string keys, the subject of Section 5.2. Your search engine must precompute an index, since it cannot afford to scan all the pages in the web for your keys. As we discussed in Section 3.5 (see FileIndex on page 501), this would ideally be an inverted index associating each possible search string with all web pages that contain it&#8212;a symbol table where each entry is a string key and each value is a set of pointers (each pointer giving the information necessary to locate an occurrence of the key on the web&#8212;perhaps a URL that names a web page and an integer offset within that page). In practice, such a symbol table would be far too big, so your search engine uses various sophisticated algorithms to reduce its size. One approach is to rank web pages by importance (perhaps using an algorithm like the PageR- ank algorithm that we discussed on page 502) and work only with highly- ranked pages, not all pages. Another approach to cutting down on the size of a symbol table to support search with string keys is to associate URLs with words (substrings delimited by whitespace) as keys in the precomputed index. Then, when you search for a word, the search engine can use the index to find the (important) pages containing your search keys (words) and then use substring search within each page to find them. But with this approach, if the text were to contain "everything" and you were to search for "thing", you would not find it. For some applications, it is worthwhile to build an index to help find any substring within a given text. Doing so might be justified for a linguistic study of an important piece of literature, for a genomic sequence that might be an object of study for many scientists, or just for a widely accessed web page. Again, ideally, the index</p><p attribs="{'xml:space': 'preserve'}" id="_16032" smilref="Title.smil#_16032"> Idealized view of a typical web search</p><p attribs="{'xml:space': 'preserve'}" id="_16033" smilref="Title.smil#_16033"> ... it was the best deal I could get ...</p><p attribs="{'xml:space': 'preserve'}" id="_16034" smilref="Title.smil#_16034"> it was the best</p><p attribs="{'xml:space': 'preserve'}" id="_16035" smilref="Title.smil#_16035"> ... it was the best kiss I&#8217;ve ever had ...</p><p attribs="{'xml:space': 'preserve'}" id="_16036" smilref="Title.smil#_16036"> ... it was the best of times, it was the worst of times ...</p><p attribs="{'xml:space': 'preserve'}" id="_16037" smilref="Title.smil#_16037"> substring search: find the key in the page</p><p attribs="{'xml:space': 'preserve'}" id="_16038" smilref="Title.smil#_16038" /><pagenum id="p891" page="normal" smilref="Title.smil#p891" /><p attribs="{'xml:space': 'preserve'}" id="_16039" smilref="Title.smil#_16039"> 878</p><p attribs="{'xml:space': 'preserve'}" id="_16040" smilref="Title.smil#_16040"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16041" smilref="Title.smil#_16041"> would associate all possible substrings of the text string with each position where it occurs in the text string, as depicted at right. The basic problem with this ideal is that the number of possible substrings is too large to have a symbol-table entry for each of them (an N- character text has N (N+1)&#11408; 2 substrings). The table for the example at right would need</p><p attribs="{'xml:space': 'preserve'}" id="_16042" smilref="Title.smil#_16042"> entries for b, be, bes, best, best o, best of, e, es, est, est o, est of, s, st, st o, st of,</p><p attribs="{'xml:space': 'preserve'}" id="_16043" smilref="Title.smil#_16043"> key</p><p attribs="{'xml:space': 'preserve'}" id="_16044" smilref="Title.smil#_16044"> value</p><p attribs="{'xml:space': 'preserve'}" id="_16045" smilref="Title.smil#_16045"> best of times</p><p attribs="{'xml:space': 'preserve'}" id="_16046" smilref="Title.smil#_16046"> it was</p><p attribs="{'xml:space': 'preserve'}" id="_16047" smilref="Title.smil#_16047"> ... it was the best of times, it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief ...</p><p attribs="{'xml:space': 'preserve'}" id="_16048" smilref="Title.smil#_16048"> Idealized view of a text-string index</p><p attribs="{'xml:space': 'preserve'}" id="_16049" smilref="Title.smil#_16049"> t, t o, t of, o, of, and many, many other substrings. Again, we can use a suffix sort to address this problem in a manner analogous to our first symbol-table implementation using binary search, in Section 3.1. We consider each of the N suffixes to be keys, create a sorted array of our keys (the suf&#64257; xes), and use binary search to search in that array, comparing the search key with each suf&#64257; x.</p><p attribs="{'xml:space': 'preserve'}" id="_16050" smilref="Title.smil#_16050"> suffixes</p><p attribs="{'xml:space': 'preserve'}" id="_16051" smilref="Title.smil#_16051"> sorted suffix array</p><p attribs="{'xml:space': 'preserve'}" id="_16052" smilref="Title.smil#_16052"> i index(i) lcp(i)</p><p attribs="{'xml:space': 'preserve'}" id="_16053" smilref="Title.smil#_16053"> 0 1 0 0 b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16054" smilref="Title.smil#_16054"> 1 2 4 1 i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16055" smilref="Title.smil#_16055"> 2 1 5 1 o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16056" smilref="Title.smil#_16056"> 3 3 1 1 t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16057" smilref="Title.smil#_16057"> 4 6 4 t h e b e s t o f t i m e s i t w a s t h e 5 1 8 2 t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16058" smilref="Title.smil#_16058"> 6 2 7 1 w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16059" smilref="Title.smil#_16059"> 7 2 8 w a s t h e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16060" smilref="Title.smil#_16060"> 8 2 9 0 a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16061" smilref="Title.smil#_16061"> 9 4 6 a s t h e b e s t o f t i m e s i t w a s t h e 1 0 1 1 0 b e s t o f t i m e s i t w a s t h e index(9) 1 2 9 1 e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16062" smilref="Title.smil#_16062"> 1 1 3 4 0 e</p><p attribs="{'xml:space': 'preserve'}" id="_16063" smilref="Title.smil#_16063"> select(9)</p><p attribs="{'xml:space': 'preserve'}" id="_16064" smilref="Title.smil#_16064"> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34</p><p attribs="{'xml:space': 'preserve'}" id="_16065" smilref="Title.smil#_16065"> i t w a s t h e b e s t o f t i m e s i t w a s t h e t w a s t h e b e s t o f t i m e s i t w a s t h e w a s t h e b e s t o f t i m e s i t w a s t h e w a s t h e b e s t o f t i m e s i t w a s t h e a s t h e b e s t o f t i m e s i t w a s t h e s t h e b e s t o f t i m e s i t w a s t h e t h e b e s t o f t i m e s i t w a s t h e t h e b e s t o f t i m e s i t w a s t h e h e b e s t o f t i m e s i t w a s t h e e b e s t o f t i m e s i t w a s t h e b e s t o f t i m e s i t w a s t h e b e s t o f t i m e s i t w a s t h e e s t o f t i m e s i t w a s t h e s t o f t i m e s i t w a s t h e t o f t i m e s i t w a s t h e o f t i m e s i t w a s t h e o f t i m e s i t w a s t h e f t i m e s i t w a s t h e t i m e s i t w a s t h e t i m e s i t w a s t h e i m e s i t w a s t h e m e s i t w a s t h e e s i t w a s t h e s i t w a s t h e i t w a s t h e i t w a s t h e t w a s t h e w a s t h e w a s t h e a s t h e s t h e t h e t h e h e e</p><p attribs="{'xml:space': 'preserve'}" id="_16066" smilref="Title.smil#_16066"> rank("th")</p><p attribs="{'xml:space': 'preserve'}" id="_16067" smilref="Title.smil#_16067"> 1 3 2 2 1 e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16068" smilref="Title.smil#_16068"> 1 4 1 2 2 e s t o f t i m e s i t w a s t h e 1 5 1 7 0 f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16069" smilref="Title.smil#_16069"> 1 6 3 3 0 h e</p><p attribs="{'xml:space': 'preserve'}" id="_16070" smilref="Title.smil#_16070"> 1 7 8 2 h e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16071" smilref="Title.smil#_16071"> 1 8 2 0 0 i m e s i t w a s t h e 1 9 2 5 1 i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16072" smilref="Title.smil#_16072"> 2 0 0 1 0 i t w a s t h e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16073" smilref="Title.smil#_16073"> 2 1 2 1 0 m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16074" smilref="Title.smil#_16074"> 2 3 2 3 0 s i t w a s t h e 2 4 3 0 2 s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16075" smilref="Title.smil#_16075"> 2 2 1 6 0 o f t i m e s i t w a s t h e lcp(20) 2 5 5 5 s t h e b e s t o f t i m e s i t w a s t h e 2 6 1 3 1 s t o f t i m e s i t w a s t h e 2 7 1 4 0 t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16076" smilref="Title.smil#_16076"> 2 8 2 6 2 t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16077" smilref="Title.smil#_16077"> 2 9 1 9 t w a s t h e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16078" smilref="Title.smil#_16078"> 3 0 3 2 1 t he</p><p attribs="{'xml:space': 'preserve'}" id="_16079" smilref="Title.smil#_16079"> 3 1 7 3 t he b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16080" smilref="Title.smil#_16080"> 3 2 1 9 1 t i m e s i t w a s t h e 3 3 2 8 0 w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16081" smilref="Title.smil#_16081"> 3 4 3 7 w a s t h e b e s t o f t i m e s i t w a s t h e</p><p attribs="{'xml:space': 'preserve'}" id="_16082" smilref="Title.smil#_16082"> Binary search in a suffix array</p><p attribs="{'xml:space': 'preserve'}" id="_16083" smilref="Title.smil#_16083"> in t e r va l s con ta in ing "th" found by rank() du r ing b ina r y s ea rch</p><p attribs="{'xml:space': 'preserve'}" id="_16084" smilref="Title.smil#_16084" /><pagenum id="p892" page="normal" smilref="Title.smil#p892" /><p attribs="{'xml:space': 'preserve'}" id="_16085" smilref="Title.smil#_16085"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16086" smilref="Title.smil#_16086"> 879</p><p attribs="{'xml:space': 'preserve'}" id="_16087" smilref="Title.smil#_16087"> API and client code. To support client code to solve these two problems, we articulate the API shown below. It includes a constructor; a length() method; methods select() and index(), which give the string and index of the suffix of a given rank in the sorted list of suf&#64257; xes; a method lcp() that gives the length of the longest common prefix of each suffix and the one preceding it in the sorted list; and a method rank() that gives the number of suffixes less than the given key (just as we have been using since we first examined binary search in Chapter 1). We use the term suffix array to describe the abstraction of a sorted list of suffix strings, without necessarily committing to use an array of strings as the underlying data structure.</p><p attribs="{'xml:space': 'preserve'}" id="_16088" smilref="Title.smil#_16088"> public class SuffixArray</p><p attribs="{'xml:space': 'preserve'}" id="_16089" smilref="Title.smil#_16089"> SuffixArray(String text) build suffix  array for text int length()</p><p attribs="{'xml:space': 'preserve'}" id="_16090" smilref="Title.smil#_16090"> String select(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_16091" smilref="Title.smil#_16091"> int index(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_16092" smilref="Title.smil#_16092"> int lcp(int i)</p><p attribs="{'xml:space': 'preserve'}" id="_16093" smilref="Title.smil#_16093"> int rank(String key)</p><p attribs="{'xml:space': 'preserve'}" id="_16094" smilref="Title.smil#_16094"> length of text ith in the suffix  array (i between 0 and N-1) index of select(i) (i between 0 and N-1) length of longest common prefix  of select(i) and select(i-1) (i between 1 and N-1) number of suffixes  less than key</p><p attribs="{'xml:space': 'preserve'}" id="_16095" smilref="Title.smil#_16095"> Suf f ix array API</p><p attribs="{'xml:space': 'preserve'}" id="_16096" smilref="Title.smil#_16096"> In the example on the facing page, select(9) is "as the best of times...", index(9)</p><p attribs="{'xml:space': 'preserve'}" id="_16097" smilref="Title.smil#_16097"> is 4, lcp(20) is 10 because "it was the best of times..." and "it was the" have</p><p attribs="{'xml:space': 'preserve'}" id="_16098" smilref="Title.smil#_16098"> the common prefix "it was the" which is of length 10, and rank("th") is 30. Note also that the select(rank(key)) is the first possible suffix in the sorted suffix list that has key as prefix and that all other occurrences of key in the text immediately follow (see the figure on the opposite page). With this API, the client code on the next two pages is immediate. LRS (page 880) finds the longest repeated substring in the text on standard input by building a suffix array and then scanning through the sorted suffixes to find the maximum lcp() value. KWIC (page 881) builds a suffix array for the text named as command-line argument, takes queries from standard input, and prints all occurrences of each query in the text (including a specified number of characters before and after to give context). The name KWIC stands for keyword-in-context search, a term dating at least to the 1960s. The simplicity and efficiency of this client code for these typical string-processing applications is remarkable, and testimony to the importance of careful API design (and the power of a simple but ingenious idea).</p><p attribs="{'xml:space': 'preserve'}" id="_16099" smilref="Title.smil#_16099" /><pagenum id="p893" page="normal" smilref="Title.smil#p893" /><p attribs="{'xml:space': 'preserve'}" id="_16100" smilref="Title.smil#_16100"> 880</p><p attribs="{'xml:space': 'preserve'}" id="_16101" smilref="Title.smil#_16101"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16102" smilref="Title.smil#_16102"> public class LRS { public static void main(String[] args) { String text = StdIn.readAll(); int N = text.length(); SuffixArray sa = new SuffixArray(text); String lrs = ""; for (int i = 1; i &lt; N; i++) { int length = sa.lcp(i); if (length &gt; lrs.length()) lrs = sa.select(i).substring(0, length); } StdOut.println(lrs); } }</p><p attribs="{'xml:space': 'preserve'}" id="_16103" smilref="Title.smil#_16103"> Longest repeated substring client</p><p attribs="{'xml:space': 'preserve'}" id="_16104" smilref="Title.smil#_16104"> % more tinyTale.txt it was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness it was the epoch of belief it was the epoch of incredulity it was the season of light it was the season of darkness it was the spring of hope it was the winter of despair</p><p attribs="{'xml:space': 'preserve'}" id="_16105" smilref="Title.smil#_16105"> % java LRS &lt; tinyTale.txt st of times it was the</p><p attribs="{'xml:space': 'preserve'}" id="_16106" smilref="Title.smil#_16106" /><pagenum id="p894" page="normal" smilref="Title.smil#p894" /><p attribs="{'xml:space': 'preserve'}" id="_16107" smilref="Title.smil#_16107"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16108" smilref="Title.smil#_16108"> 881</p><p attribs="{'xml:space': 'preserve'}" id="_16109" smilref="Title.smil#_16109"> public class KWIC { public static void main(String[] args) { In in = new In(args[0]); int context = Integer.parseInt(args[1]);</p><p attribs="{'xml:space': 'preserve'}" id="_16110" smilref="Title.smil#_16110"> String text = in.readAll().replaceAll("\\s+", " ");; int N = text.length(); SuffixArray sa = new SuffixArray(text);</p><p attribs="{'xml:space': 'preserve'}" id="_16111" smilref="Title.smil#_16111"> while (StdIn.hasNextLine()) { String q = StdIn.readLine(); for (int i = sa.rank(q); i &lt; N &amp;&amp; sa.select(i).startsWith(q); i++) { int from = Math.max(0, sa.index(i) - context); int to = Math.min(N-1, from + q.length() + 2*context); StdOut.println(text.substring(from, to)); } StdOut.println(); } } }</p><p attribs="{'xml:space': 'preserve'}" id="_16112" smilref="Title.smil#_16112"> Keyword-in-contex t indexing client</p><p attribs="{'xml:space': 'preserve'}" id="_16113" smilref="Title.smil#_16113"> % java KWIC tale.txt 15 search o st giless to search for contraband her unavailing search for your fathe le and gone in search of her husband t provinces in search of impoverishe dispersing in search of other carri n that bed and search the straw hold</p><p attribs="{'xml:space': 'preserve'}" id="_16114" smilref="Title.smil#_16114"> better thing t is a far far better thing that i do than some sense of better things else forgotte was capable of better things mr carton ent</p><p attribs="{'xml:space': 'preserve'}" id="_16115" smilref="Title.smil#_16115" /><pagenum id="p895" page="normal" smilref="Title.smil#p895" /><p attribs="{'xml:space': 'preserve'}" id="_16116" smilref="Title.smil#_16116"> 882</p><p attribs="{'xml:space': 'preserve'}" id="_16117" smilref="Title.smil#_16117"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16118" smilref="Title.smil#_16118"> Implementation. The code on the facing page is a straightforward implementation of the SuffixArray API. Its instance variables are an array of strings and (for economy in code) a variable N that holds the length of the array (the length of the string and its number of suf&#64257; xes). The constructor builds the suffix array and sorts it, so select(i) just returns suffixes[i]. The implementation of index() is also a one-liner, but it is a bit tricky, based on the observation that the length of the suffix string uniquely determines its starting point. The suffix of length N starts at position 0, the suffix of length N-1 starts at position 1, the suu&#64257; x of length N-2 starts at position 2, and so forth, so index(i) just returns N - suffixes[i].length(). The implementation of lcp() is immedi- ate, given the static method lcp() on page 875, and rank() is virtually the same as our implementation of binary search for symbol tables, on page 381. Again, the simplicity and elegance of this implementation should not mask the fact that it is a sophisticated algorithm that enables solution of important problems like the longest repeated substring problem that would otherwise seem to be infeasible.</p><p attribs="{'xml:space': 'preserve'}" id="_16119" smilref="Title.smil#_16119"> Performance. The efficiency of suffix sorting depends on the fact that Java substring extraction uses a constant amount of space&#8212;each substring is composed of standard object overhead, a pointer into the original, and a length. Thus, the size of the index is linear in the size of the string. This point is a bit counterintuitive because the total number of characters in the suffixes is ~N 2/2, a quadratic function of the size of the string. Moreover, that quadratic factor gives one pause when considering the cost of sorting the suffix array. It is very important to bear in mind that this approach is effective for long strings because of the Java representation for strings: when we exchange two strings, we are exchanging only references, not the whole string. Now, the cost of comparing two strings may be proportional to the length of the strings in the case when their common prefix is very long, but most comparisons in typical applications involve only a few characters. If so, the running time of the suffix sort is linearithmic. For ex- ample, in many applications, it is reasonable to use a random string model:</p><p attribs="{'xml:space': 'preserve'}" id="_16120" smilref="Title.smil#_16120"> Proposition C. Using 3-way string quicksort, we can build a suffix array from a random string of length N with space proportional to N and ~ 2N ln N character compares, on the average.</p><p attribs="{'xml:space': 'preserve'}" id="_16121" smilref="Title.smil#_16121"> Discussion: The space bound is immediate, but the time bound is follows from a a detailed and difficult research result by P. Jacquet and W. Szpankowski, which implies that the cost of sorting the suffixes is asymptotically the same as the cost of sorting N random strings (see Proposition E on page 723).</p><p attribs="{'xml:space': 'preserve'}" id="_16122" smilref="Title.smil#_16122" /><pagenum id="p896" page="normal" smilref="Title.smil#p896" /><p attribs="{'xml:space': 'preserve'}" id="_16123" smilref="Title.smil#_16123"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16124" smilref="Title.smil#_16124"> 883</p><p attribs="{'xml:space': 'preserve'}" id="_16125" smilref="Title.smil#_16125"> ALGORITHM 6.13 Suffix array (elementary implementation)</p><p attribs="{'xml:space': 'preserve'}" id="_16126" smilref="Title.smil#_16126"> import java.util.Arrays;</p><p attribs="{'xml:space': 'preserve'}" id="_16127" smilref="Title.smil#_16127"> public class SuffixArray { private final String[] suffixes; // suffix array private final int N; // length of string (and array)</p><p attribs="{'xml:space': 'preserve'}" id="_16128" smilref="Title.smil#_16128"> public SuffixArray(String s) { N = s.length(); suffixes = new String[N]; for (int i = 0; i &lt; N; i++) suffixes[i] = s.substring(i); Arrays.sort(suffixes); }</p><p attribs="{'xml:space': 'preserve'}" id="_16129" smilref="Title.smil#_16129"> public int length() { return N; } public String select(int i) { return suffixes[i]; } public int index(int i) { return N - suffixes[i].length(); }</p><p attribs="{'xml:space': 'preserve'}" id="_16130" smilref="Title.smil#_16130"> private static int lcp(String s, String t) // See page page 875.</p><p attribs="{'xml:space': 'preserve'}" id="_16131" smilref="Title.smil#_16131"> public int lcp(int i) { return lcp(suffixes[i], suffixes[i-1]); }</p><p attribs="{'xml:space': 'preserve'}" id="_16132" smilref="Title.smil#_16132"> public int rank(String key) { // binary search int lo = 0, hi = N - 1; while (lo &lt;= hi) { int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(suffixes[mid]); if (cmp &lt; 0) hi = mid - 1; else if (cmp &gt; 0) lo = mid + 1; else return mid; } return lo; }</p><p attribs="{'xml:space': 'preserve'}" id="_16133" smilref="Title.smil#_16133"> }</p><p attribs="{'xml:space': 'preserve'}" id="_16134" smilref="Title.smil#_16134"> This implementation of our SuffixArray API depends for its efficiency on the fact that substrings are constant-size references and substring extraction takes constant time (see text).</p><p attribs="{'xml:space': 'preserve'}" id="_16135" smilref="Title.smil#_16135" /><pagenum id="p897" page="normal" smilref="Title.smil#p897" /><p attribs="{'xml:space': 'preserve'}" id="_16136" smilref="Title.smil#_16136"> 884</p><p attribs="{'xml:space': 'preserve'}" id="_16137" smilref="Title.smil#_16137"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16138" smilref="Title.smil#_16138"> input string</p><p attribs="{'xml:space': 'preserve'}" id="_16139" smilref="Title.smil#_16139"> a a c a a g t t t a c a a g c</p><p attribs="{'xml:space': 'preserve'}" id="_16140" smilref="Title.smil#_16140"> Improved implementations. Our elementary implementation of SuffixArray has poor worst-case performance. For example, if all the characters are equal, the sort examines every character in each substring and thus takes quadratic time. For strings of the type we have been using as examples, such as genomic sequences or natural-language text, this is not likely to be problematic, but the algorithm can be slow for texts with long runs of identical characters. Another way of looking at the problem is to observe that the cost of fi nd- ing the longest repeated substring is quadratic in the length of the substring because all of the prefixes of the repeat need to be checked (see the diagram at right). This is not a problem for a text such as A Tale of Two Cities, where the longest repeat</p><p attribs="{'xml:space': 'preserve'}" id="_16141" smilref="Title.smil#_16141"> a c a a g c a a g a a g a g g</p><p attribs="{'xml:space': 'preserve'}" id="_16142" smilref="Title.smil#_16142"> all appear at least twice as a prefix of a suffix string</p><p attribs="{'xml:space': 'preserve'}" id="_16143" smilref="Title.smil#_16143"> suffixes of longest repeat (M = 5)</p><p attribs="{'xml:space': 'preserve'}" id="_16144" smilref="Title.smil#_16144"> sorted suffixes of input</p><p attribs="{'xml:space': 'preserve'}" id="_16145" smilref="Title.smil#_16145"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_16146" smilref="Title.smil#_16146"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_16147" smilref="Title.smil#_16147"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_16148" smilref="Title.smil#_16148"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_16149" smilref="Title.smil#_16149"> a a c a a g t t t a c a a g c a a g c a a g t t t a c a a g c a c a a g c a c a a g t t t a c a a g c a g c a g t t t a c a a g c c c a a g c c a a g t t t a c a a g c g c g t t t a c a a g c t a c a a g c t t a c a a g c t t t a c a a g c</p><p attribs="{'xml:space': 'preserve'}" id="_16150" smilref="Title.smil#_16150"> "s dropped because it would have been a bad thing for me in a worldly point of view i"</p><p attribs="{'xml:space': 'preserve'}" id="_16151" smilref="Title.smil#_16151"> 1</p><p attribs="{'xml:space': 'preserve'}" id="_16152" smilref="Title.smil#_16152"> comparison cost is at least 1 + 2 + . . . + M ~ M 2 /2</p><p attribs="{'xml:space': 'preserve'}" id="_16153" smilref="Title.smil#_16153"> LRS cost is quadratic in repeat length</p><p attribs="{'xml:space': 'preserve'}" id="_16154" smilref="Title.smil#_16154"> has just 84 characters, but it is a serious problem for genomic data, where long repeated substrings are not unusual. How can this quadratic behavior for repeat searching be avoided? Re- markably, research by P. Weiner in 1973 showed that it is possible to solve the longest repeated substring problem in guaranteed linear time. Weiner&#8217;s algorithm was based on building a suffix tree data structure (essentially a trie for suf&#64257; xes). With multiple pointers per character, suffix trees consume too much space for many practical problems, which led to the development of suffix arrays. In the 1990s, U. Manber and E. Myers presented a linearithmic algorithm for building suffix arrays directly and a method that does preprocessing at the same time as the suffix sort to support constant-time lcp(). Several linear-time suffix sorting algorithms have been developed since. With a bit more work, the Manber-Myers implementation can also support a two-argument lcp() that finds the longest common prefix of two given suffixes that are not necessarily adjacent in guaranteed constant time, again a remarkable improvement over the straightforard implementation. These results are quite surpris- ing, as they achieve efficiencies quite beyond what you might have expected.</p><p attribs="{'xml:space': 'preserve'}" id="_16155" smilref="Title.smil#_16155" /><pagenum id="p898" page="normal" smilref="Title.smil#p898" /><p attribs="{'xml:space': 'preserve'}" id="_16156" smilref="Title.smil#_16156"> Suf f ix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16157" smilref="Title.smil#_16157"> 885</p><p attribs="{'xml:space': 'preserve'}" id="_16158" smilref="Title.smil#_16158"> Proposition D. With suffix arrays, we can solve both the suffix sorting and longest repeated substring problems in linear time.</p><p attribs="{'xml:space': 'preserve'}" id="_16159" smilref="Title.smil#_16159"> Proof : The remarkable algorithms for these tasks are just beyond our scope, but you can find on the booksite code that implements the SuffixArray constructor in linear time and lcp() queries in constant time.</p><p attribs="{'xml:space': 'preserve'}" id="_16160" smilref="Title.smil#_16160"> A SuffixArray implementation based on these ideas supports efficient solutions of numerous string-processing problems, with simple client code, as in our LRS and KWIC examples.</p><p attribs="{'xml:space': 'preserve'}" id="_16161" smilref="Title.smil#_16161"> Suffix arrays are the culmination of decades of research that began with the development of tries for KWIC indices in the 1960s. The algorithms that we have discussed were worked out by many researchers over several decades in the context of solving practical problems ranging from putting the Oxford English Dictionary online to the development of the first web search engines to sequencing the human genome. This story certainly helps put the importance of algorithm design and analysis in context.</p><p attribs="{'xml:space': 'preserve'}" id="_16162" smilref="Title.smil#_16162" /><pagenum id="p900" page="normal" smilref="Title.smil#p900" /><p attribs="{'xml:space': 'preserve'}" id="_16163" smilref="Title.smil#_16163"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16164" smilref="Title.smil#_16164"> 887</p><p attribs="{'xml:space': 'preserve'}" id="_16165" smilref="Title.smil#_16165"> Local equilibrium in a flow network</p><p attribs="{'xml:space': 'preserve'}" id="_16166" smilref="Title.smil#_16166"> in f low equal  s out  f low a t e v e r y v e r tex ( ex c e p t th e s ou rc e and th e s ink )</p><p attribs="{'xml:space': 'preserve'}" id="_16167" smilref="Title.smil#_16167"> simply fill all pipes to full capacity. Otherwise, not all pipes are full, but oil flows through the network, controlled by switch settings at the junctions, satisfying a local equilibrium condition at the junctions: the amount of oil flowing into each junction is equal to the amount of oil flowing out. For ex- ample, consider the network in the diagram on the opposite page. Operators might start the flow by opening the switches along the path 0-&gt;1-&gt;3-&gt;5, which can handle 2 units of fl ow, then open switches along the path 0-&gt;2-&gt;4-&gt;5 to get another unit of flow in the network. Since 0-&gt;1, 2-&gt;4, and 3-&gt;5 are full, there is no direct way to get more flow from 0 to 5, but if we change the switch at 1 to redirect enough flow to fill 1-&gt;4, we open up enough capacity in 3-&gt;5 to allow us to add a unit of flow on 0-&gt;2-&gt;3-&gt;5. Even for this simple network, finding switch settings that increase the flow is not an easy task; for a complicated network, we are clearly interested in the following question: What switch settings will maximize the amount of oil flowing from source to sink? We can model this situation directly with an edge-weighted digraph that has a single source and a single sink. The edges in the network correspond to the oil pipes, the vertices correspond to the junctions with switches that control how much oil goes into each outgoing edge, and the weights on the edges correspond to the capacity of the pipes. We assume that the edges are directed, specifying that oil can flow in only one direction in each pipe. Each pipe has a certain amount of fl ow, which is less than or equal to its capacity, and every vertex satisfies the equilibrium condition that the flow in is equal to the flow out. This fl ow-network abstraction is a useful problem-solving model that applies directly to a variety of applications and indirectly to still more. We sometimes appeal to the idea of oil flowing through pipes for intuitive support of basic ideas,</p><p attribs="{'xml:space': 'preserve'}" id="_16168" smilref="Title.smil#_16168"> drawing with capacities</p><p attribs="{'xml:space': 'preserve'}" id="_16169" smilref="Title.smil#_16169"> drawing with flow</p><p attribs="{'xml:space': 'preserve'}" id="_16170" smilref="Title.smil#_16170"> flow representation</p><p attribs="{'xml:space': 'preserve'}" id="_16171" smilref="Title.smil#_16171"> standard drawing s ou rc e</p><p attribs="{'xml:space': 'preserve'}" id="_16172" smilref="Title.smil#_16172"> tinyFN.txt</p><p attribs="{'xml:space': 'preserve'}" id="_16173" smilref="Title.smil#_16173"> V</p><p attribs="{'xml:space': 'preserve'}" id="_16174" smilref="Title.smil#_16174"> E</p><p attribs="{'xml:space': 'preserve'}" id="_16175" smilref="Title.smil#_16175"> 6 8 0 1 2.0 0 2 3.0 1 3 3.0 1 4 1.0 2 3 1.0 2 4 1.0 3 5 2.0 4 5 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16176" smilref="Title.smil#_16176"> capacities</p><p attribs="{'xml:space': 'preserve'}" id="_16177" smilref="Title.smil#_16177"> s ink</p><p attribs="{'xml:space': 'preserve'}" id="_16178" smilref="Title.smil#_16178"> Anatomy of a network-flow problem</p><p attribs="{'xml:space': 'preserve'}" id="_16179" smilref="Title.smil#_16179"> 0 1 2.0 2.0 0 2 3.0 1.0 1 3 3.0 2.0 1 4 1.0 0.0 2 3 1.0 0.0 2 4 1.0 1.0 3 5 2.0 2.0 4 5 3.0 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16180" smilref="Title.smil#_16180"> flow value associated with each edge</p><p attribs="{'xml:space': 'preserve'}" id="_16181" smilref="Title.smil#_16181" /><pagenum id="p901" page="normal" smilref="Title.smil#p901" /><p attribs="{'xml:space': 'preserve'}" id="_16182" smilref="Title.smil#_16182"> 888</p><p attribs="{'xml:space': 'preserve'}" id="_16183" smilref="Title.smil#_16183"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16184" smilref="Title.smil#_16184"> but our discussion applies equally well to goods moving through distribution channels and to numerous other situations. As with our use of distance in shortest-paths algorithms, we are free to abandon any physical intuition when convenient because all the defi nitions, properties, and algorithms that we consider are based entirely on an abstract model that does not necessarily obey physical laws. Indeed, a prime reason for our interest in the network-&#64258; ow model is that it allows us to solve numerous other problems through reduction, as we see in the next section.</p><p attribs="{'xml:space': 'preserve'}" id="_16185" smilref="Title.smil#_16185"> De&#64257; nitions. Because of this broad applicability, it is worthwhile to consider precise statements of the terms and concepts that we have just informally introduced:</p><p attribs="{'xml:space': 'preserve'}" id="_16186" smilref="Title.smil#_16186"> Definition. A flow network is an edge-weighted digraph with positive edge weights (which we refer to as capacities). An st-&#64258; ow network has two identified vertices, a source s and a sink t.</p><p attribs="{'xml:space': 'preserve'}" id="_16187" smilref="Title.smil#_16187"> We sometimes refer to edges as having infinite capacity or, equivalently, as being un- capacitated. That might mean that we do not compare flow against capacity for such edges, or we might use a sentinel value that is guaranteed to be larger than any flow value. We refer to the total flow into a vertex (the sum of the flows on its incoming edges) as the vertex&#8217;s infl ow, the total flow out of a vertex (the sum of the flows on its outgoing edges) as the vertex&#8217;s out&#64258; ow, and the difference between the two (in&#64258; ow minus out&#64258; ow) as the vertex&#8217;s net&#64258; ow. To simplify the discussion, we also assume that there are no edges leaving t or entering s.</p><p attribs="{'xml:space': 'preserve'}" id="_16188" smilref="Title.smil#_16188"> Definition. An st- flow in an st-&#64258; ow network is a set of nonnegative values associated with each edge, which we refer to as edge fl ows. We say that aflow is feasible if it satisfies the condition that no edge&#8217;s flow is greater than that edge&#8217;s capacity and the local equilibrium condition that the every vertex&#8217;s net&#64258; ow is zero (except s and t).</p><p attribs="{'xml:space': 'preserve'}" id="_16189" smilref="Title.smil#_16189"> We refer to the sink&#8217;s inflow as the st-&#64258; ow value. We will see in Proposition C that the value is also equal to the source&#8217;s out&#64258; ow. With these defi nitions, the formal statement of our basic problem is straightforward:</p><p attribs="{'xml:space': 'preserve'}" id="_16190" smilref="Title.smil#_16190"> Maximum st-&#64258; ow. Given an st-&#64258; ow network, find an st-&#64258; ow such that no other flow from s to t has a larger value.</p><p attribs="{'xml:space': 'preserve'}" id="_16191" smilref="Title.smil#_16191"> For brevity, we refer to such aflow as a max&#64258; ow and the problem of finding one in a network as the max&#64258; ow problem. In some applications, we might be content to know</p><p attribs="{'xml:space': 'preserve'}" id="_16192" smilref="Title.smil#_16192" /><pagenum id="p902" page="normal" smilref="Title.smil#p902" /><p attribs="{'xml:space': 'preserve'}" id="_16193" smilref="Title.smil#_16193"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16194" smilref="Title.smil#_16194"> 889</p><p attribs="{'xml:space': 'preserve'}" id="_16195" smilref="Title.smil#_16195"> just the max&#64258; ow value, but we generally want to know aflow (edge flow values) that achieves that value. APIs. The FlowEdge and FlowNetwork APIs shown on page 890 are straightforward extensions of APIs from CHAPTER 3. We will consider on page 896 an implementation of FlowEdge that is based on adding an instance variable containing the flow to our WeightedEdge class from page 610. Flows have a direction, but we do not base FlowEdge on WeightedDirectedEdge because we work with a more general abstraction known as the residual network that is described below, and we need each edge to appear in the adjacency lists of both its vertices to implement the residual network. The residual network allows us to both add and subtract flow and to test whether an edge is full to capacity (no more flow can be added) or empty (no flow can be subtracted). This abstraction is implemented via the methods residualCapacity() and addResidualFlow() that we will consider later. The implementation of FlowNetwork is virtually identical to our EdgeWeightedGraph implementation on page 611, so we omit it. To simplify the file for- mat, we adopt the convention that the source is 0 and the sink is V&#11002;1. These APIs leave a straightforward goal for max&#64258; ow algorithms: build a network, then assign values to the flow instance variables in the client&#8217;s edges that maximize flow through the net- work. Shown at right are client methods for certifying whether aflow is feasible. Typically, we might do such a check as the final action of a max&#64258; ow algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_16196" smilref="Title.smil#_16196"> private boolean localEq(FlowNetwork G, int v) { // Check local equilibrium at vertex v. double EPSILON = 1E-11; double netflow = 0.0; for (FlowEdge e : G.adj(v)) if (v == e.from()) netflow -= e.flow(); else netflow += e.flow();</p><p attribs="{'xml:space': 'preserve'}" id="_16197" smilref="Title.smil#_16197"> return Math.abs(netflow) &lt; EPSILON; }</p><p attribs="{'xml:space': 'preserve'}" id="_16198" smilref="Title.smil#_16198"> private boolean isFeasible(FlowNetwork G) { // Check that flow on each edge is nonnegative // and not greater than capacity. for (int v = 0; v &lt; G.V(); v++) for (FlowEdge e : G.adj(v)) if (e.flow() &lt; 0 || e.flow() &gt; e.cap()) return false;</p><p attribs="{'xml:space': 'preserve'}" id="_16199" smilref="Title.smil#_16199"> // Check local equilibrium at each vertex. for (int v = 0; v &lt; G.V(); v++) if (v !=s &amp;&amp; v != t &amp;&amp; !localEq(v)) return false;</p><p attribs="{'xml:space': 'preserve'}" id="_16200" smilref="Title.smil#_16200"> return true; }</p><p attribs="{'xml:space': 'preserve'}" id="_16201" smilref="Title.smil#_16201"> Checking that a f low is feasible in a f low network</p><p attribs="{'xml:space': 'preserve'}" id="_16202" smilref="Title.smil#_16202" /><pagenum id="p903" page="normal" smilref="Title.smil#p903" /><p attribs="{'xml:space': 'preserve'}" id="_16203" smilref="Title.smil#_16203"> 890</p><p attribs="{'xml:space': 'preserve'}" id="_16204" smilref="Title.smil#_16204"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16205" smilref="Title.smil#_16205"> public class FlowEdge</p><p attribs="{'xml:space': 'preserve'}" id="_16206" smilref="Title.smil#_16206"> FlowEdge(int v, int w, double cap) int from() int to() int other(int v) double capacity() double flow() double residualCapacityTo(int v) void addFlowTo(int v, double delta) add delta fl ow toward v String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_16207" smilref="Title.smil#_16207"> vertex this edge points from vertex this edge points to other endpoint capacity of this edge fl ow in this edge residual capacity toward v</p><p attribs="{'xml:space': 'preserve'}" id="_16208" smilref="Title.smil#_16208"> string representation</p><p attribs="{'xml:space': 'preserve'}" id="_16209" smilref="Title.smil#_16209"> API for edges in a f low network</p><p attribs="{'xml:space': 'preserve'}" id="_16210" smilref="Title.smil#_16210"> public class FlowNetwork</p><p attribs="{'xml:space': 'preserve'}" id="_16211" smilref="Title.smil#_16211"> FlowNetwork(int V) FlowNetwork(In in) int V() int E() void addEdge(FlowEdge e) Iterable&lt;FlowEdge&gt; adj(int v)</p><p attribs="{'xml:space': 'preserve'}" id="_16212" smilref="Title.smil#_16212"> Iterable&lt;FlowEdge&gt; edges()</p><p attribs="{'xml:space': 'preserve'}" id="_16213" smilref="Title.smil#_16213"> String toString()</p><p attribs="{'xml:space': 'preserve'}" id="_16214" smilref="Title.smil#_16214"> Flow network API</p><p attribs="{'xml:space': 'preserve'}" id="_16215" smilref="Title.smil#_16215"> empty V-vertex fl ow network construct from input stream number of vertices number of edges add e to this fl ow network edges pointing from v all edges in this fl ow network string representation</p><p attribs="{'xml:space': 'preserve'}" id="_16216" smilref="Title.smil#_16216"> tinyFN.txt</p><p attribs="{'xml:space': 'preserve'}" id="_16217" smilref="Title.smil#_16217"> V</p><p attribs="{'xml:space': 'preserve'}" id="_16218" smilref="Title.smil#_16218"> E</p><p attribs="{'xml:space': 'preserve'}" id="_16219" smilref="Title.smil#_16219"> 6 8 0 1 2.0 0 2 3.0 1 3 3.0 1 4 1.0 2 3 1.0 2 4 1.0 3 5 2.0 4 5 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16220" smilref="Title.smil#_16220"> adj[] 0 1 2 3 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_16221" smilref="Title.smil#_16221"> 0 2</p><p attribs="{'xml:space': 'preserve'}" id="_16222" smilref="Title.smil#_16222"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16223" smilref="Title.smil#_16223"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16224" smilref="Title.smil#_16224"> 0 1 2.0 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16225" smilref="Title.smil#_16225"> references to the same FlowEdge object</p><p attribs="{'xml:space': 'preserve'}" id="_16226" smilref="Title.smil#_16226"> 1 4</p><p attribs="{'xml:space': 'preserve'}" id="_16227" smilref="Title.smil#_16227"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16228" smilref="Title.smil#_16228"> 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_16229" smilref="Title.smil#_16229"> 1 3 3.0 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16230" smilref="Title.smil#_16230"> 0 1 2.0 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16231" smilref="Title.smil#_16231"> 2 4</p><p attribs="{'xml:space': 'preserve'}" id="_16232" smilref="Title.smil#_16232"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16233" smilref="Title.smil#_16233"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16234" smilref="Title.smil#_16234"> 2 3 1.0 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_16235" smilref="Title.smil#_16235"> 0 2 3.0 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16236" smilref="Title.smil#_16236"> 3 5</p><p attribs="{'xml:space': 'preserve'}" id="_16237" smilref="Title.smil#_16237"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16238" smilref="Title.smil#_16238"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16239" smilref="Title.smil#_16239"> 2 3 1.0 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_16240" smilref="Title.smil#_16240"> 1 3 3.0 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16241" smilref="Title.smil#_16241"> 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_16242" smilref="Title.smil#_16242"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16243" smilref="Title.smil#_16243"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16244" smilref="Title.smil#_16244"> 2 4 1.0 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16245" smilref="Title.smil#_16245"> 1 4 1.0 0.0</p><p attribs="{'xml:space': 'preserve'}" id="_16246" smilref="Title.smil#_16246"> 4 5</p><p attribs="{'xml:space': 'preserve'}" id="_16247" smilref="Title.smil#_16247"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16248" smilref="Title.smil#_16248"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16249" smilref="Title.smil#_16249"> 3 5 2.0 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16250" smilref="Title.smil#_16250"> Flow network representation</p><p attribs="{'xml:space': 'preserve'}" id="_16251" smilref="Title.smil#_16251"> Bag objects</p><p attribs="{'xml:space': 'preserve'}" id="_16252" smilref="Title.smil#_16252" /></level3><level3 id="_00126"><h3 id="ch6-s4-ss8" smilref="Title.smil#ch6-s4-ss8" xml:space="preserve">Ford-Fulkerson algorithm</h3><pagenum id="p904" page="normal" smilref="Title.smil#p904" /><p attribs="{'xml:space': 'preserve'}" id="_16253" smilref="Title.smil#_16253"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16254" smilref="Title.smil#_16254"> 891</p><p attribs="{'xml:space': 'preserve'}" id="_16255" smilref="Title.smil#_16255"> Ford-Fulkerson algorithm. An effective approach to solving max- flow problems was developed by L. R. Ford and D. R. Fulkerson in 1962. It is a generic method for increasing flows incrementally along paths from source to sink that serves as the basis for a family of algo- rithms. It is known as the Ford-Fulkerson algorithm in the classical lit- erature; the more descriptive term augmenting-path algorithm is also widely used. Consider any directed path from source to sink through an st-&#64258; ow network. Let x be the minimum of the unused capacities of the edges on the path. We can increase the network&#8217;s flow value by at least x by increasing the flow in all edges on the path by that amount. Iterating this action, we get a first attempt at computing flow in a network: find another path, increase the flow along that path, and continue until all paths from source to sink have at least one full edge (so that we can no longer increase flow in this way). This algorithm will compute the max&#64258; ow in some cases but will fall short in other cases. Our introductory example on page 886 is such an example. To improve the algorithm such that it always finds a max&#64258; ow, we consider a more general way to increase the fl ow, along a path from source to sink through the network&#8217;s underlying undirected graph. The edges on any such path are either forward edges, which go with the flow (when we traverse the path from source to sink, we traverse the edge from its source vertex to its destination vertex), or backward edges, which go against the flow (when we traverse the path from source to sink, we traverse the edge from its destination vertex to its source vertex). Now, for any path from source to sink with no full forward edges and no empty backward edges, we can increase the amount of flow in the network by increasing flow in forward edges and decreasing flow in backward edges. The amount by which the flow can be increased is limited by the minimum of the unused capacities in the forward edges and the flows in the backward edges. Such a path is called an augmenting path. An example is shown at right. In the new fl ow, at least one of the forward edges along the path becomes full or at least one of the backward edges along the path becomes empty. The process just sketched is the basis for the classical Ford-Fulkerson max&#64258; ow algorithm (augmenting-path method). We summarize it as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_16256" smilref="Title.smil#_16256"> no path from 0 to 5 without a full edge</p><p attribs="{'xml:space': 'preserve'}" id="_16257" smilref="Title.smil#_16257"> add 1 unit of flow</p><p attribs="{'xml:space': 'preserve'}" id="_16258" smilref="Title.smil#_16258"> along 0-&gt;2-&gt;3</p><p attribs="{'xml:space': 'preserve'}" id="_16259" smilref="Title.smil#_16259"> out  o f equ l ib r ium</p><p attribs="{'xml:space': 'preserve'}" id="_16260" smilref="Title.smil#_16260"> subtract 1 unit of flow from 1-&gt;3 (traverse 3-&gt;1)</p><p attribs="{'xml:space': 'preserve'}" id="_16261" smilref="Title.smil#_16261"> out  o f equ l ib r ium</p><p attribs="{'xml:space': 'preserve'}" id="_16262" smilref="Title.smil#_16262"> add 1 unit of flow</p><p attribs="{'xml:space': 'preserve'}" id="_16263" smilref="Title.smil#_16263"> along 1-&gt;4-&gt;5</p><p attribs="{'xml:space': 'preserve'}" id="_16264" smilref="Title.smil#_16264"> An augmenting path (0-&gt;2-&gt;3-&gt;1-&gt;4-&gt;5)</p><p attribs="{'xml:space': 'preserve'}" id="_16265" smilref="Title.smil#_16265" /><pagenum id="p905" page="normal" smilref="Title.smil#p905" /><p attribs="{'xml:space': 'preserve'}" id="_16266" smilref="Title.smil#_16266"> 892</p><p attribs="{'xml:space': 'preserve'}" id="_16267" smilref="Title.smil#_16267"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16268" smilref="Title.smil#_16268"> Ford-Fulkerson maxflow algorithm. Start with zero flow everywhere. Increase the flow along any augmenting path from source to sink (with no full forward edges or empty backward edges), continuing until there are no such paths in the network.</p><p attribs="{'xml:space': 'preserve'}" id="_16269" smilref="Title.smil#_16269"> Remarkably (under certain technical conditions about numeric properties of the fl ow), this method always finds a max&#64258; ow, no matter how we choose the paths. Like the greedy MST algorithm discussed in Section 4.3 and the generic shortest-paths method discussed in Section 4.4, it is a generic algorithm that is useful because it establishes the correctness of a whole family of more specific algorithms. We are free to use any method whatever to choose the path. Several algorithms that compute sequences of augmenting paths have been developed, all of which lead to a max&#64258; ow. The algorithms differ in the number of augmenting paths they compute and the costs of finding each path, but they all implement the Ford-Fulkerson algorithm and find a max&#64258; ow.</p><p attribs="{'xml:space': 'preserve'}" id="_16270" smilref="Title.smil#_16270"> Max&#64258; ow-mincut theorem. To show that any flow computed by any implementation of the Ford-Fulkerson algorithm is indeed a max&#64258; ow, we prove a key fact known as the max&#64258; ow-mincut theorem. Understanding this theorem is a crucial step in understanding network-&#64258; ow algorithms. As suggested by its name, the theorem is based on a direct relationship between flows and cuts in networks, so we begin by defining terms that relate to cuts. Recall from Section 4.3 that a cut in a graph is a partition of the vertices into two disjoint sets, and a crossing edge is an edge that connects a vertex in one set to a vertex in the other set. For flow networks, we refine these definitions as follows:</p><p attribs="{'xml:space': 'preserve'}" id="_16271" smilref="Title.smil#_16271"> Definition. An st-cut is a cut that places vertex s in one of its sets and vertex t in the other.</p><p attribs="{'xml:space': 'preserve'}" id="_16272" smilref="Title.smil#_16272"> Each crossing edge corresponding to an st-cut is either an st-edge that goes from a vertex in the set containing s to a vertex in the set containing t, or a ts-edge that goes in the other direction. We sometimes refer to the set of crossing st-edges as a cut set. The capacity of an st-cut in aflow network is the sum of the capacities of that cut&#8217;s st-edges, and the flow across an st-cut is the difference between the sum of the flows in that cut&#8217;s st-edges and the sum of the flows in that cut&#8217;s ts-edges. Removing all the st-edges (the cut set) in an st-cut of a network leaves no path from s to t, but adding any one of them back could create such a path. Cuts are the appropriate abstraction for many applica- tions. For our oil-&#64258; ow model, a cut provides a way to completely stop the flow of oil</p><p attribs="{'xml:space': 'preserve'}" id="_16273" smilref="Title.smil#_16273" /><pagenum id="p906" page="normal" smilref="Title.smil#p906" /><p attribs="{'xml:space': 'preserve'}" id="_16274" smilref="Title.smil#_16274"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16275" smilref="Title.smil#_16275"> 893</p><p attribs="{'xml:space': 'preserve'}" id="_16276" smilref="Title.smil#_16276"> from the source to the sink. If we view the capacity of the cut as the cost of doing so, to stop the flow in the most economical manner is to solve the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_16277" smilref="Title.smil#_16277"> Minimum st-cut. Given an st-network, find an st-cut such that the capacity of no other cut is smaller. For brevity, we refer to such a cut as a mincut and to the problem of finding one in a network as the mincut problem.</p><p attribs="{'xml:space': 'preserve'}" id="_16278" smilref="Title.smil#_16278"> The statement of the mincut problem includes no mention of fl ows, and these defi ni- tions might seem to digress from our discussion of the augmenting-path algorithm. On the surface, computing a mincut (a set of edges) seems easier than computing a max&#64258; ow (an assignment of weights to all the edges). On the contrary, the max&#64258; ow and mincut problems are intimately related. The augmenting-path method itself provides a proof. That proof rests on the following basic relationship between flows and cuts, which immediately gives a proof that local equilibrium in an st-&#64258; ow implies global equilibrium as well (the first corollary) and an upper bound on the value of any st-&#64258; ow (the second corollary):</p><p attribs="{'xml:space': 'preserve'}" id="_16279" smilref="Title.smil#_16279"> Proposition E. For any st-&#64258; ow, the flow across each st-cut is equal to the value of the fl ow. Proof : Let Cs be the vertex set containing s and Ct the vertex set containing t. This fact follows immediately by induction on the size of Ct. The property is true by defi - nition when Ct is t and when a vertex is moved from Cs to Ct , local equilibrium at that vertex implies that the stated property is preserved. Any st-cut can be created by moving vertices in this way.</p><p attribs="{'xml:space': 'preserve'}" id="_16280" smilref="Title.smil#_16280"> Cs</p><p attribs="{'xml:space': 'preserve'}" id="_16281" smilref="Title.smil#_16281"> Ct</p><p attribs="{'xml:space': 'preserve'}" id="_16282" smilref="Title.smil#_16282"> s</p><p attribs="{'xml:space': 'preserve'}" id="_16283" smilref="Title.smil#_16283"> t</p><p attribs="{'xml:space': 'preserve'}" id="_16284" smilref="Title.smil#_16284"> difference between inflow and outflow is flow across cut</p><p attribs="{'xml:space': 'preserve'}" id="_16285" smilref="Title.smil#_16285"> inflow to t is value of the flow</p><p attribs="{'xml:space': 'preserve'}" id="_16286" smilref="Title.smil#_16286"> Corollary. The outflow from s is equal to the inflow to t (the value of the st-&#64258; ow). Proof : Let Cs be {s }.</p><p attribs="{'xml:space': 'preserve'}" id="_16287" smilref="Title.smil#_16287"> Corollary. No st-&#64258; ow&#8217;s value can exceed the capacity of any st-cut.</p><p attribs="{'xml:space': 'preserve'}" id="_16288" smilref="Title.smil#_16288" /><pagenum id="p907" page="normal" smilref="Title.smil#p907" /><p attribs="{'xml:space': 'preserve'}" id="_16289" smilref="Title.smil#_16289"> 894</p><p attribs="{'xml:space': 'preserve'}" id="_16290" smilref="Title.smil#_16290"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16291" smilref="Title.smil#_16291"> Proposition F. ( Maxflow-mincut theorem) Let f be an st-&#64258; ow. The following three</p><p attribs="{'xml:space': 'preserve'}" id="_16292" smilref="Title.smil#_16292"> conditions are equivalent: i. There exists an st-cut whose capacity equals the value of the flow f. ii. f is a max&#64258; ow. iii. There is no augmenting path with respect to f. Proof : Condition i. implies condition ii. by the corollary to Proposition E. Con- dition ii. implies condition iii. because the existence of an augmenting path implies the existence of aflow with a larger flow value, contradicting the maximality of f. It remains to prove that condition iii. implies condition i. Let Cs be the set of all vertices that can be reached from s with an undirected path that does not contain a full forward or empty backward edge, and let Ct be the remaining vertices. Then, t must be in Ct , so (Cs , Ct) is an st-cut, whose cut set consists entirely of full forward or empty backward edges. The flow across this cut is equal to the cut&#8217;s capacity (since forward edges are full and the backward edges are empty) and also to the value of the flow (by Proposition E).</p><p attribs="{'xml:space': 'preserve'}" id="_16293" smilref="Title.smil#_16293"> Corollary. ( Integrality property) When capacities are integers, there exists an inte- ger-valued max&#64258; ow, and the Ford-Fulkerson algorithm finds it.</p><p attribs="{'xml:space': 'preserve'}" id="_16294" smilref="Title.smil#_16294"> Proof : Each augmenting path increases the flow by a positive integer (the minimum of the unused capacities in the forward edges and the flows in the backward edges, all of which are always positive integers).</p><p attribs="{'xml:space': 'preserve'}" id="_16295" smilref="Title.smil#_16295"> It is possible to design a max&#64258; ow with noninteger fl ows, even when capacities are all integers, but we do not need to consider such fl ows. From a theoretical standpoint, this observation is important: allowing capacities and flows that are real numbers, as we have done and as is common in practice, can lead to unpleasant anomalous situations. For example, it is known that the Ford-Fulkerson algorithm could, in principle, lead to an infinite sequence of augmenting paths that does not even converge to the max&#64258; ow value. The version of the algorithm that we consider is known to always converge, even when capacities and flows are real-valued. No matter what method we choose to find an augmenting path and no matter what paths we fi nd, we always end up with aflow that does not admit an augmenting path, which therefore must be a max&#64258; ow.</p><p attribs="{'xml:space': 'preserve'}" id="_16296" smilref="Title.smil#_16296" /><pagenum id="p908" page="normal" smilref="Title.smil#p908" /><p attribs="{'xml:space': 'preserve'}" id="_16297" smilref="Title.smil#_16297"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16298" smilref="Title.smil#_16298"> 895</p><p attribs="{'xml:space': 'preserve'}" id="_16299" smilref="Title.smil#_16299"> Residual network. The generic Ford-Fulkerson algorithm does not specify any particular method for finding an augmenting path. How can we find a path with no full forward edges and no empty backward edges? To this end, we begin with the following defi nition:</p><p attribs="{'xml:space': 'preserve'}" id="_16300" smilref="Title.smil#_16300"> Definition. Given a st-&#64258; ow network and an st-&#64258; ow, the residual network for the flow has the same vertices as the original and one or two edges in the residual network for each edge in the original, defined as follows: For each edge e from v to w in the original, let fe be its flow and ce its capacity. If fe is positive, include an edge w-&gt;v in the residual with capacity fe ; and if fe is less than ce, include an edge v-&gt;w in the residual with capacity ce &#11002; fe .</p><p attribs="{'xml:space': 'preserve'}" id="_16301" smilref="Title.smil#_16301"> If an edge e from v to w is empty (fe is equal to 0), there is a single corresponding edge v-&gt;w with capacity ce in the residual; if it is full (fe is equal to ce), there is a single corresponding edge w-&gt;v with capacity fe in the residual; and if it is neither empty nor full, both v-&gt;w and w-&gt;v are in the residual with their respective capacities. An example is shown at the bottom of this page. At fi rst, the residual network representation is a bit confusing because the edges corresponding to flow go in the opposite direction of the flow itself. The forward edges represent the remaining capacity (the amount of flow we can add if traversing that edge); the backward edges represent the flow (the amount of flow we can remove if traversing that edge). The code on page 896 gives the methods in the FlowEdge class that we need to implement the residual network abstraction. With these implementations, our algorithms work with the residual network, but they are actually examining capacities and changing flow (through edge references) in the client&#8217;s edg- es. The methods from() and other() allow us to process edges in either orientation:</p><p attribs="{'xml:space': 'preserve'}" id="_16302" smilref="Title.smil#_16302"> drawing with flow</p><p attribs="{'xml:space': 'preserve'}" id="_16303" smilref="Title.smil#_16303"> flow representation</p><p attribs="{'xml:space': 'preserve'}" id="_16304" smilref="Title.smil#_16304"> residual network</p><p attribs="{'xml:space': 'preserve'}" id="_16305" smilref="Title.smil#_16305"> 0 1 2.0 2.0 0 2 3.0 1.0 1 3 3.0 2.0 1 4 1.0 0.0 2 3 1.0 0.0 2 4 1.0 1.0 3 5 2.0 2.0 4 5 3.0 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16306" smilref="Title.smil#_16306"> capacity</p><p attribs="{'xml:space': 'preserve'}" id="_16307" smilref="Title.smil#_16307"> flow</p><p attribs="{'xml:space': 'preserve'}" id="_16308" smilref="Title.smil#_16308"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16309" smilref="Title.smil#_16309"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16310" smilref="Title.smil#_16310"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16311" smilref="Title.smil#_16311"> backward edge (flow)</p><p attribs="{'xml:space': 'preserve'}" id="_16312" smilref="Title.smil#_16312"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16313" smilref="Title.smil#_16313"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16314" smilref="Title.smil#_16314"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16315" smilref="Title.smil#_16315"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16316" smilref="Title.smil#_16316"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16317" smilref="Title.smil#_16317"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16318" smilref="Title.smil#_16318"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16319" smilref="Title.smil#_16319"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16320" smilref="Title.smil#_16320"> forward edge (remaining capacity)</p><p attribs="{'xml:space': 'preserve'}" id="_16321" smilref="Title.smil#_16321"> Anatomy of a network-flow problem (revisited)</p><p attribs="{'xml:space': 'preserve'}" id="_16322" smilref="Title.smil#_16322" /><pagenum id="p909" page="normal" smilref="Title.smil#p909" /><p attribs="{'xml:space': 'preserve'}" id="_16323" smilref="Title.smil#_16323"> 896</p><p attribs="{'xml:space': 'preserve'}" id="_16324" smilref="Title.smil#_16324"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16325" smilref="Title.smil#_16325"> Flow edge data type (residual network)</p><p attribs="{'xml:space': 'preserve'}" id="_16326" smilref="Title.smil#_16326"> public class FlowEdge { private final int v; // edge source private final int w; // edge target private final double capacity; // capacity private double flow; // flow</p><p attribs="{'xml:space': 'preserve'}" id="_16327" smilref="Title.smil#_16327"> public FlowEdge(int v, int w, double capacity) { this.v = v; this.w = w; this.capacity = capacity; this.flow = 0.0; }</p><p attribs="{'xml:space': 'preserve'}" id="_16328" smilref="Title.smil#_16328"> public int from() { return v; } public int to() { return w; } public double capacity() { return capacity; } public double flow() { return flow; }</p><p attribs="{'xml:space': 'preserve'}" id="_16329" smilref="Title.smil#_16329"> public int other(int vertex) // same as for Edge</p><p attribs="{'xml:space': 'preserve'}" id="_16330" smilref="Title.smil#_16330"> public double residualCapacityTo(int vertex) { if (vertex == v) return flow; else if (vertex == w) return cap - flow; else throw new RuntimeException("Inconsistent edge");</p><p attribs="{'xml:space': 'preserve'}" id="_16331" smilref="Title.smil#_16331"> }</p><p attribs="{'xml:space': 'preserve'}" id="_16332" smilref="Title.smil#_16332"> public void addResidualFlowTo(int vertex, double delta) { if (vertex == v) flow -= delta; else if (vertex == w) flow += delta; else throw new RuntimeException("Inconsistent edge");</p><p attribs="{'xml:space': 'preserve'}" id="_16333" smilref="Title.smil#_16333"> }</p><p attribs="{'xml:space': 'preserve'}" id="_16334" smilref="Title.smil#_16334"> public String toString() { return String.format("%d-&gt;%d %.2f %.2f", v, w, capacity, flow); } }</p><p attribs="{'xml:space': 'preserve'}" id="_16335" smilref="Title.smil#_16335"> This FlowEdge implementation adds to the weighted DirectedEdge implementation of Section 4.4 (see page 642) a flow instance variable and two methods to implement the residual flow network.</p><p attribs="{'xml:space': 'preserve'}" id="_16336" smilref="Title.smil#_16336" /><pagenum id="p910" page="normal" smilref="Title.smil#p910" /><p attribs="{'xml:space': 'preserve'}" id="_16337" smilref="Title.smil#_16337"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16338" smilref="Title.smil#_16338"> 897</p><p attribs="{'xml:space': 'preserve'}" id="_16339" smilref="Title.smil#_16339"> e.other(v) returns the endpoint of e that is not v. The methods residualCapTo() and addResidualFlowTo() implement the residual network. Residual networks allow us to use graph search to find an augmenting path, since any path from source to sink in the residual network corresponds directly to an augmenting path in the original network. Increasing the flow along the path implies making changes in the residual network: for example, at least one edge on the path becomes full or empty, so at least one edge in the residual network changes direction or disappears (but our use of an abstract residual network means that we just check for positive capacity and do not need to actually insert and delete edges).</p><p attribs="{'xml:space': 'preserve'}" id="_16340" smilref="Title.smil#_16340"> Algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16341" smilref="Title.smil#_16341"> private boolean hasAugmentingPath(FlowNetwork G, int s, int t) { marked = new boolean[G.V()]; // Is path to this vertex known? edgeTo = new FlowEdge[G.V()]; // last edge on path Queue&lt;Integer&gt; q = new Queue&lt;Integer&gt;();</p><p attribs="{'xml:space': 'preserve'}" id="_16342" smilref="Title.smil#_16342"> Shortest-augmenting-path method. Perhaps the simplest Ford-Fulkerson implementation is to use a shortest augmenting path (as measured by the number of edges on the path, not flow or capacity). This method was suggested by J. Edmonds and R. Karp in 1972. In this case, the search for an augmenting path amounts to breadth-&#64257; rst search (BFS) in the residual network, precisely as described in Section 4.1, as you can see by comparing the hasAugmentingPath() implementation below to our breadth-&#64257; rst search implemention in Algorithm 4.2 on page 540 (the residual graph is a digraph, and this is fundamentally a digraph processing algorithm, as mentioned on page 685). This method forms the basis for the full imp l e m e n t a t i o n in 6.14 on the next page, a remarkably concise imp l em en t a t ion based on the tools we have devel- oped. For brevity, we refer to this method as the shortest-augment- ing-path max&#64258; ow algorithm. A trace for our example is shown in detail on page 899.</p><p attribs="{'xml:space': 'preserve'}" id="_16343" smilref="Title.smil#_16343"> marked[s] = true; // Mark the source q.enqueue(s); // and put it on the queue. while (!q.isEmpty()) { int v = q.dequeue(); for (FlowEdge e : G.adj(v)) { int w = e.other(v); if (e.residualCapacityTo(w) &gt; 0 &amp;&amp; !marked[w]) { // For every edge to an unmarked vertex (in residual) edgeTo[w] = e; // Save the last edge on a path. marked[w] = true; // Mark w because a path is known q.enqueue(w); // and add it to the queue. } } } return marked[t]; }</p><p attribs="{'xml:space': 'preserve'}" id="_16344" smilref="Title.smil#_16344"> Finding an augmenting path in the residual network via breadth-f irst search</p><p attribs="{'xml:space': 'preserve'}" id="_16345" smilref="Title.smil#_16345" /><pagenum id="p911" page="normal" smilref="Title.smil#p911" /><p attribs="{'xml:space': 'preserve'}" id="_16346" smilref="Title.smil#_16346"> 898</p><p attribs="{'xml:space': 'preserve'}" id="_16347" smilref="Title.smil#_16347"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16348" smilref="Title.smil#_16348"> ALGORITHM 6.14 Ford-Fulkerson shortest-augmenting path maxflow algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16349" smilref="Title.smil#_16349"> public class FordFulkerson { private boolean[] marked; // Is s-&gt;v path in residual graph? private FlowEdge[] edgeTo; // last edge on shortest s-&gt;v path private double value; // current value of maxflow</p><p attribs="{'xml:space': 'preserve'}" id="_16350" smilref="Title.smil#_16350"> public FordFulkerson(FlowNetwork G, int s, int t) { // Find maxflow in flow network G from s to t.</p><p attribs="{'xml:space': 'preserve'}" id="_16351" smilref="Title.smil#_16351"> while (hasAugmentingPath(G, s, t)) { // While there exists an augmenting path, use it.</p><p attribs="{'xml:space': 'preserve'}" id="_16352" smilref="Title.smil#_16352"> // Compute bottleneck capacity. double bottle = Double.POSITIVE_INFINITY; for (int v = t; v != s; v = edgeTo[v].other(v)) bottle = Math.min(bottle, edgeTo[v].residualCapacityTo(v));</p><p attribs="{'xml:space': 'preserve'}" id="_16353" smilref="Title.smil#_16353"> // Augment flow. for (int v = t; v != s; v = edgeTo[v].other(v)) edgeTo[v].addResidualFlowTo(v, bottle);</p><p attribs="{'xml:space': 'preserve'}" id="_16354" smilref="Title.smil#_16354"> value += bottle; } }</p><p attribs="{'xml:space': 'preserve'}" id="_16355" smilref="Title.smil#_16355"> public double value() { return value; } public boolean inCut(int v) { return marked[v]; }</p><p attribs="{'xml:space': 'preserve'}" id="_16356" smilref="Title.smil#_16356"> public static void main(String[] args) { FlowNetwork G = new FlowNetwork(new In(args[0])); int s = 0, t = G.V() - 1; FordFulkerson maxflow = new FordFulkerson(G, s, t);</p><p attribs="{'xml:space': 'preserve'}" id="_16357" smilref="Title.smil#_16357"> StdOut.println("Max flow from " + s + " to " + t); for (int v = 0; v &lt; G.V(); v++) for (FlowEdge e : G.adj(v)) if ((v == e.from()) &amp;&amp; e.flow() &gt; 0) StdOut.println(" " + e); StdOut.println("Max flow value = " + maxflow.value());</p><p attribs="{'xml:space': 'preserve'}" id="_16358" smilref="Title.smil#_16358"> } }</p><p attribs="{'xml:space': 'preserve'}" id="_16359" smilref="Title.smil#_16359"> This implementation of the Ford-Fulkerson algorithm finds the shortest augmenting path in the residual network, finds the bottneck capacity in that path, and augments the flow along that path, continuing until no path from source to sink exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16360" smilref="Title.smil#_16360" /><pagenum id="p912" page="normal" smilref="Title.smil#p912" /><p attribs="{'xml:space': 'preserve'}" id="_16361" smilref="Title.smil#_16361"> initial empty network</p><p attribs="{'xml:space': 'preserve'}" id="_16362" smilref="Title.smil#_16362"> residual network</p><p attribs="{'xml:space': 'preserve'}" id="_16363" smilref="Title.smil#_16363"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16364" smilref="Title.smil#_16364"> 899</p><p attribs="{'xml:space': 'preserve'}" id="_16365" smilref="Title.smil#_16365"> add 2 units of flow</p><p attribs="{'xml:space': 'preserve'}" id="_16366" smilref="Title.smil#_16366"> along 0-&gt;1-&gt;3-&gt;5</p><p attribs="{'xml:space': 'preserve'}" id="_16367" smilref="Title.smil#_16367"> add 1 unit of flow</p><p attribs="{'xml:space': 'preserve'}" id="_16368" smilref="Title.smil#_16368"> along 0-&gt;2-&gt;4-&gt;5</p><p attribs="{'xml:space': 'preserve'}" id="_16369" smilref="Title.smil#_16369"> add 1 unit of flow</p><p attribs="{'xml:space': 'preserve'}" id="_16370" smilref="Title.smil#_16370"> along 0-&gt;2-&gt;3-&gt;1-&gt;4-&gt;5</p><p attribs="{'xml:space': 'preserve'}" id="_16371" smilref="Title.smil#_16371"> st-cut</p><p attribs="{'xml:space': 'preserve'}" id="_16372" smilref="Title.smil#_16372"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16373" smilref="Title.smil#_16373"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16374" smilref="Title.smil#_16374"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16375" smilref="Title.smil#_16375"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16376" smilref="Title.smil#_16376"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16377" smilref="Title.smil#_16377"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16378" smilref="Title.smil#_16378"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16379" smilref="Title.smil#_16379"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16380" smilref="Title.smil#_16380"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16381" smilref="Title.smil#_16381"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16382" smilref="Title.smil#_16382"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16383" smilref="Title.smil#_16383"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16384" smilref="Title.smil#_16384"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16385" smilref="Title.smil#_16385"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16386" smilref="Title.smil#_16386"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16387" smilref="Title.smil#_16387"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16388" smilref="Title.smil#_16388"> 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16389" smilref="Title.smil#_16389"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16390" smilref="Title.smil#_16390"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16391" smilref="Title.smil#_16391"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16392" smilref="Title.smil#_16392"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16393" smilref="Title.smil#_16393"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16394" smilref="Title.smil#_16394"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16395" smilref="Title.smil#_16395"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16396" smilref="Title.smil#_16396"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16397" smilref="Title.smil#_16397"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16398" smilref="Title.smil#_16398"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16399" smilref="Title.smil#_16399"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16400" smilref="Title.smil#_16400"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16401" smilref="Title.smil#_16401"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16402" smilref="Title.smil#_16402"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16403" smilref="Title.smil#_16403"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16404" smilref="Title.smil#_16404"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16405" smilref="Title.smil#_16405"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16406" smilref="Title.smil#_16406"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16407" smilref="Title.smil#_16407"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16408" smilref="Title.smil#_16408"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16409" smilref="Title.smil#_16409"> 2.0</p><p attribs="{'xml:space': 'preserve'}" id="_16410" smilref="Title.smil#_16410"> 1.0</p><p attribs="{'xml:space': 'preserve'}" id="_16411" smilref="Title.smil#_16411"> Trace of augmenting-path Ford-Fulkerson algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16412" smilref="Title.smil#_16412"> % java FordFulkerson tinyFN.txt Max flow from 0 to 5 0-&gt;2 3.0 2.0 0-&gt;1 2.0 2.0 1-&gt;4 1.0 1.0 1-&gt;3 3.0 1.0 2-&gt;3 1.0 1.0 2-&gt;4 1.0 1.0 3-&gt;5 2.0 2.0 4-&gt;5 3.0 2.0 Max flow value = 4.0</p><p attribs="{'xml:space': 'preserve'}" id="_16413" smilref="Title.smil#_16413" /><pagenum id="p913" page="normal" smilref="Title.smil#p913" /><p attribs="{'xml:space': 'preserve'}" id="_16414" smilref="Title.smil#_16414"> 900</p><p attribs="{'xml:space': 'preserve'}" id="_16415" smilref="Title.smil#_16415"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16416" smilref="Title.smil#_16416"> Shortest augmenting paths in a larger flow network</p><p attribs="{'xml:space': 'preserve'}" id="_16417" smilref="Title.smil#_16417"> Performance. A larger example is shown in the figure above. As is evident from the fi gure, the lengths of the augmenting paths form a nondecreasing sequence. This fact is a first key to analyzing the performance of the algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_16418" smilref="Title.smil#_16418"> Proposition G. The number of augmenting paths needed in the shortest-augment- ing-path implementation of the Ford-Fulkerson max&#64258; ow algorithm for aflow network with V vertices and E edges is at most EV /2.</p><p attribs="{'xml:space': 'preserve'}" id="_16419" smilref="Title.smil#_16419"> Proof sketch: Every augmenting path has a critical edge&#8212;an edge that is deleted from the residual network because it corresponds either to a forward edge that becomes filled to capacity or a backward edge that is emptied. Each time an edge is a critical edge, the length of the augmenting path through it must increase by 2 (see Exercise 6.39). Since an augmenting path is of length at most V each edge can be on at most V/2 augmenting paths, and the total number of augmenting paths is at most EV/2.</p><p attribs="{'xml:space': 'preserve'}" id="_16420" smilref="Title.smil#_16420" /><pagenum id="p914" page="normal" smilref="Title.smil#p914" /><p attribs="{'xml:space': 'preserve'}" id="_16421" smilref="Title.smil#_16421"> Network-flow algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16422" smilref="Title.smil#_16422"> 901</p><p attribs="{'xml:space': 'preserve'}" id="_16423" smilref="Title.smil#_16423"> Corollary. The shortest-augmenting-path implementation of the Ford-Fulkerson max&#64258; ow algorithm takes time proportional to VE 2 in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_16424" smilref="Title.smil#_16424"> Proof : Breadth-&#64257; rst search examines at most E edges.</p><p attribs="{'xml:space': 'preserve'}" id="_16425" smilref="Title.smil#_16425"> The upper bound of Proposition G is very conservative. For example, the graph shown in the figure at the top of page 900 has 11 vertices and 20 vertices, so the bound says that the algorithm uses no more than 110 augmenting paths. In fact, it uses 14.</p><p attribs="{'xml:space': 'preserve'}" id="_16426" smilref="Title.smil#_16426"> Other implementations. Another Ford-Fulkerson implementation, suggested by Ed- monds and Karp, is the following: Augment along the path that increases the flow by the largest amount. For brevity, we refer to this method as the maximum-capacity- augmenting-path max&#64258; ow algorithm. We can implement this (and other approaches) by using a priority queue and slightly modifying our implementation of Dijkstra&#8217;s shortest-paths algorithm, choosing edges from the priority queue to give the maximum amount of flow that can be pushed through a forward edge or diverted from a backward edge. Or, we might look for a longest augmenting path, or make a random choice. A complete analysis establishing which method is best is a complex task, because their running times depend on </p><p attribs="{'xml:space': 'preserve'}" id="_16427" smilref="Title.smil#_16427" /></level3><level3 id="_00127"><h3 id="ch6-s4-ss9" smilref="Title.smil#ch6-s4-ss9" xml:space="preserve">Minimum cut</h3><pagenum id="p915" page="normal" smilref="Title.smil#p915" /><p attribs="{'xml:space': 'preserve'}" id="_16428" smilref="Title.smil#_16428"> 902</p><p attribs="{'xml:space': 'preserve'}" id="_16429" smilref="Title.smil#_16429"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16430" smilref="Title.smil#_16430"> Computing a minimum st-cut. Remarkably, the Ford-Fulkerson algorithm computes not only a maximum st-&#64258; ow but also a minimum st-cut. The augmenting path algorithm terminates when there are no more augmenting paths with respect to the flow f. Upon termination, let Cs be the set of all vertices that can be reached from s with an undirected path that does not contain a full forward or empty backward edge, and let Ct be the remaining vertices. Then, as in the proof of Proposition F, (Cs , Ct) is a minimum st-cut. Algorithm 6.14 provides an inCut() method that identifies the vertices on the s-side of the mincut. It accomplishes this by using the information left over in</p><p attribs="{'xml:space': 'preserve'}" id="_16431" smilref="Title.smil#_16431"> marked[] from the last call to hasAugmentingPath().</p><p attribs="{'xml:space': 'preserve'}" id="_16432" smilref="Title.smil#_16432"> The practical application of max&#64258; ow algorithms remains both an art and a science. The art lies in picking the strategy that is most effective for a given practical situation; the science lies in understanding the essential nature of the problem. Are there new data structures and algorithms that can solve the max&#64258; ow problem in linear time, or can we prove that none exist?</p><p attribs="{'xml:space': 'preserve'}" id="_16433" smilref="Title.smil#_16433"> algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16434" smilref="Title.smil#_16434"> worst-case order of growth of running time for V vertices and E edges with integral capacities (max C)</p><p attribs="{'xml:space': 'preserve'}" id="_16435" smilref="Title.smil#_16435"> Ford-Fulkerson shortest augmenting path Ford-Fulkerson maximum-capacity augmenting path prefl ow-push</p><p attribs="{'xml:space': 'preserve'}" id="_16436" smilref="Title.smil#_16436"> possible ?</p><p attribs="{'xml:space': 'preserve'}" id="_16437" smilref="Title.smil#_16437"> VE 2</p><p attribs="{'xml:space': 'preserve'}" id="_16438" smilref="Title.smil#_16438"> E 2 log C</p><p attribs="{'xml:space': 'preserve'}" id="_16439" smilref="Title.smil#_16439"> E V log (E / V 2) V + E ?</p><p attribs="{'xml:space': 'preserve'}" id="_16440" smilref="Title.smil#_16440"> Performance characteristics of max f low algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16441" smilref="Title.smil#_16441" /></level3><level3 id="_00128"><h3 id="ch6-s5-ss10" smilref="Title.smil#ch6-s5-ss10" xml:space="preserve">Sorting</h3><p attribs="{'xml:space': 'preserve'}" id="_16442" smilref="Title.smil#_16442"> Reduction</p><p attribs="{'xml:space': 'preserve'}" id="_16443" smilref="Title.smil#_16443"> 903</p><p attribs="{'xml:space': 'preserve'}" id="_16444" smilref="Title.smil#_16444"> Reduction Throughout this book, we have focused on articulating specific prob- lems, then developing algorithms and data structures to solve them. In several cases (many of which are listed below), we have found it convenient to solve a problem by formulating it as an instance of another problem that we have already solved. Formal- izing this notion is a worthwhile starting point for studying relationships among the diverse problems and algorithms that we have studied.</p><p attribs="{'xml:space': 'preserve'}" id="_16445" smilref="Title.smil#_16445"> Definition. We say that a problem A reduces to another problem B if we can use an algorithm that solves B to develop an algorithm that solves A.</p><p attribs="{'xml:space': 'preserve'}" id="_16446" smilref="Title.smil#_16446"> This concept is certainly a familiar one in software development: when you use a library method to solve a problem, you are reducing your problem to the one solved by the library method. In this book, we have informally referred to problems that we can reduce to a given problem as applications. Sorting reductions. We first encountered reduction in Chapter 2, to express the idea that an efficient sorting algorithm is useful for efficiently solving many other problems, that may not seem to be at all related to sorting. For example, we considered the following problems, among many others:</p><p attribs="{'xml:space': 'preserve'}" id="_16447" smilref="Title.smil#_16447"> Finding the median. Given a set of numbers, find the median value.</p><p attribs="{'xml:space': 'preserve'}" id="_16448" smilref="Title.smil#_16448"> Distinct values. Determine the number of distinct values in a set of numbers.</p><p attribs="{'xml:space': 'preserve'}" id="_16449" smilref="Title.smil#_16449"> Scheduling to minimize average completion time. Given a set of jobs of speci-</p><p attribs="{'xml:space': 'preserve'}" id="_16450" smilref="Title.smil#_16450"> fied duration to be completed, how can we schedule the jobs on a single processor so as to minimize their average completion time?</p><p attribs="{'xml:space': 'preserve'}" id="_16451" smilref="Title.smil#_16451"> Proposition H. The following problems reduce to sorting: </p><p attribs="{'xml:space': 'preserve'}" id="_16452" smilref="Title.smil#_16452"> Proof : See page 345 and Exercise 2.5.12.</p><p attribs="{'xml:space': 'preserve'}" id="_16453" smilref="Title.smil#_16453"> Now, we have to pay attention to cost when doing a reduction. For example, we can find the median of a set of numbers in linear time, but using the reduction to sorting will</p><p attribs="{'xml:space': 'preserve'}" id="_16454" smilref="Title.smil#_16454" /></level3><level3 id="_00129"><h3 id="ch6-s5-ss11" smilref="Title.smil#ch6-s5-ss11" xml:space="preserve">Shortest path</h3><pagenum id="p917" page="normal" smilref="Title.smil#p917" /><p attribs="{'xml:space': 'preserve'}" id="_16455" smilref="Title.smil#_16455"> 904</p><p attribs="{'xml:space': 'preserve'}" id="_16456" smilref="Title.smil#_16456"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16457" smilref="Title.smil#_16457"> end up costing linearithmic time. Even so, such extra cost might be acceptable, since we can use an exisiting sort implementation. Sorting is valuable for three reasons: </p><p attribs="{'xml:space': 'preserve'}" id="_16458" smilref="Title.smil#_16458"> Single-source shortest paths in undirected graphs. Given an edge-weighted un-</p><p attribs="{'xml:space': 'preserve'}" id="_16459" smilref="Title.smil#_16459"> directed graph with nonnegative weights and a source vertex s, support queries of the form Is there a path from s to a given target vertex v? If so, find a shortest such path (one whose total weight is minimal).</p><p attribs="{'xml:space': 'preserve'}" id="_16460" smilref="Title.smil#_16460"> Parallel precedence-constrained scheduling. Given a set of jobs of specified du-</p><p attribs="{'xml:space': 'preserve'}" id="_16461" smilref="Title.smil#_16461"> ration to be completed, with precedence constraints that specify that certain jobs have to be completed before certain other jobs are begun, how can we schedule the jobs on identical processors (as many as needed) such that they are all completed in the minimum amount of time while still respecting the constraints?</p><p attribs="{'xml:space': 'preserve'}" id="_16462" smilref="Title.smil#_16462"> Arbitrage. Find an arbitrage opportunity in a given table of currency-conversion rates.</p><p attribs="{'xml:space': 'preserve'}" id="_16463" smilref="Title.smil#_16463"> Again, the latter two problems do not seem to be directly related to shortest-paths problems, but we saw that shortest paths is an effective way to address them. These ex- amples, while important, are merely indicative. A large number of important problems, too many to survey here, are known to reduce to shortest paths&#8212;it is an effective and important problem-solving model.</p><p attribs="{'xml:space': 'preserve'}" id="_16464" smilref="Title.smil#_16464" /></level3><level3 id="_00130"><h3 id="ch6-s5-ss12" smilref="Title.smil#ch6-s5-ss12" xml:space="preserve">Maximum flow</h3><pagenum id="p918" page="normal" smilref="Title.smil#p918" /><p attribs="{'xml:space': 'preserve'}" id="_16465" smilref="Title.smil#_16465"> Reduction</p><p attribs="{'xml:space': 'preserve'}" id="_16466" smilref="Title.smil#_16466"> 905</p><p attribs="{'xml:space': 'preserve'}" id="_16467" smilref="Title.smil#_16467"> Proposition I. The following problems reduce to shortest paths in weighted digraphs: </p><p attribs="{'xml:space': 'preserve'}" id="_16468" smilref="Title.smil#_16468"> Proof examples: See page 654, page 665, and page 680.</p><p attribs="{'xml:space': 'preserve'}" id="_16469" smilref="Title.smil#_16469"> Max&#64258; ow reductions. Max&#64258; ow algorithms are also important in a broad context. We can remove various restrictions on the flow network and solve related flow problems; we can solve other network- and graph-processing problems; and we can solve problems that are not network problems at all. For example, consider the following problems.</p><p attribs="{'xml:space': 'preserve'}" id="_16470" smilref="Title.smil#_16470"> Job placement. A college&#8217;s job-placement office arranges interviews for a set of students with a set of companies; these interviews result in a set of job offers. As- suming that an interview followed by a job offer represents mutual interest in the student taking a job at the company, it is in everyone&#8217;s best interests to maximize the number of job placements. Is it possible to match every student with a job? What is the maximum number of jobs that can be fi lled?</p><p attribs="{'xml:space': 'preserve'}" id="_16471" smilref="Title.smil#_16471"> Product distribution. A company that manufactures a single product has fac- tories, where the product is produced; distribution centers, where the product is stored temporarily ; and retail outlets, where the product is sold. The company must distribute the product from factories through distribution centers to retail outlets on a regular basis, using distribution channels that have varying capacities. Is it possible to get the product from the warehouses to the retail outlets such that supply meets demand everywhere?</p><p attribs="{'xml:space': 'preserve'}" id="_16472" smilref="Title.smil#_16472"> Network reliability. A simplified model considers a computer network as consisting of a set of trunk lines that connect computers through switches such that there is the possibility of a switched path through trunk lines connecting any two given computers. What is the minimum number of trunk lines that can be cut to disconnect some pair of computers?</p><p attribs="{'xml:space': 'preserve'}" id="_16473" smilref="Title.smil#_16473"> Again, these problems seem to be unrelated to one another and to flow networks, but they all reduce to max&#64258; ow.</p><p attribs="{'xml:space': 'preserve'}" id="_16474" smilref="Title.smil#_16474" /></level3><level3 id="_00131"><h3 id="ch6-s5-ss13" smilref="Title.smil#ch6-s5-ss13" xml:space="preserve">Bipartite matching</h3><pagenum id="p919" page="normal" smilref="Title.smil#p919" /><p attribs="{'xml:space': 'preserve'}" id="_16475" smilref="Title.smil#_16475"> 906</p><p attribs="{'xml:space': 'preserve'}" id="_16476" smilref="Title.smil#_16476"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16477" smilref="Title.smil#_16477"> Proposition J. The following problems reduce to the max&#64258; ow problem: </p><p attribs="{'xml:space': 'preserve'}" id="_16478" smilref="Title.smil#_16478"> Proof example: We prove the first (which is known as the maximum bipartite matching problem) and leave the others for exercises. Given a job-placement prob- lem, construct an instance of the max&#64258; ow problem by directing all edges from students to companies, adding a source vertex with edges directed to all the students and adding a sink vertex with edges directed from all the companies. Assign each edge capacity 1. Now, any integral solution to the max&#64258; ow problem for this network provides a solution to the corresponding bipartite matching problem (see the corollary to Proposition F). The matching corresponds exactly to those edges between vertices in the two sets that are filled to capacity by the max&#64258; ow algorithm. First, the network flow always gives a legal matching: since each vertex has an edge of capacity 1 either coming in (from the sink) or going out (to the source), at most 1 unit of flow can go through each vertex, implying in turn that each vertex will be included at most once in the matching. Second, no matching can have more edges, since any such matching would lead directly to a better flow than that produced by the max&#64258; ow algorithm.</p><p attribs="{'xml:space': 'preserve'}" id="_16479" smilref="Title.smil#_16479"> bipartite matching problem 1</p><p attribs="{'xml:space': 'preserve'}" id="_16480" smilref="Title.smil#_16480"> 7</p><p attribs="{'xml:space': 'preserve'}" id="_16481" smilref="Title.smil#_16481"> Alice Adobe Amazon Facebook Bob Adobe Amazon Yahoo Carol Facebook Google IBM Dave Adobe Amazon Eliza Google IBM Yahoo Frank IBM Yahoo</p><p attribs="{'xml:space': 'preserve'}" id="_16482" smilref="Title.smil#_16482"> 2</p><p attribs="{'xml:space': 'preserve'}" id="_16483" smilref="Title.smil#_16483"> 3</p><p attribs="{'xml:space': 'preserve'}" id="_16484" smilref="Title.smil#_16484"> 4</p><p attribs="{'xml:space': 'preserve'}" id="_16485" smilref="Title.smil#_16485"> 5</p><p attribs="{'xml:space': 'preserve'}" id="_16486" smilref="Title.smil#_16486"> 6</p><p attribs="{'xml:space': 'preserve'}" id="_16487" smilref="Title.smil#_16487"> Adobe Alice Bob Dave Amazon Alice Bob Dave Facebook Alice Carol Google Carol Eliza IBM Carol Eliza Frank Yahoo Bob Eliza Frank</p><p attribs="{'xml:space': 'preserve'}" id="_16488" smilref="Title.smil#_16488"> 8</p><p attribs="{'xml:space': 'preserve'}" id="_16489" smilref="Title.smil#_16489"> 9</p><p attribs="{'xml:space': 'preserve'}" id="_16490" smilref="Title.smil#_16490"> 10</p><p attribs="{'xml:space': 'preserve'}" id="_16491" smilref="Title.smil#_16491"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_16492" smilref="Title.smil#_16492"> 12</p><p attribs="{'xml:space': 'preserve'}" id="_16493" smilref="Title.smil#_16493"> matching (solution)</p><p attribs="{'xml:space': 'preserve'}" id="_16494" smilref="Title.smil#_16494"> Alice Bob Carol Dave Eliza Frank</p><p attribs="{'xml:space': 'preserve'}" id="_16495" smilref="Title.smil#_16495"> Amazon Yahoo Facebook Adobe Google IBM</p><p attribs="{'xml:space': 'preserve'}" id="_16496" smilref="Title.smil#_16496"> network-flow formulation</p><p attribs="{'xml:space': 'preserve'}" id="_16497" smilref="Title.smil#_16497"> maximum flow</p><p attribs="{'xml:space': 'preserve'}" id="_16498" smilref="Title.smil#_16498"> ss</p><p attribs="{'xml:space': 'preserve'}" id="_16499" smilref="Title.smil#_16499"> ss ss</p><p attribs="{'xml:space': 'preserve'}" id="_16500" smilref="Title.smil#_16500"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_16501" smilref="Title.smil#_16501"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_16502" smilref="Title.smil#_16502"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_16503" smilref="Title.smil#_16503"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_16504" smilref="Title.smil#_16504"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_16505" smilref="Title.smil#_16505"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_16506" smilref="Title.smil#_16506"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_16507" smilref="Title.smil#_16507"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_16508" smilref="Title.smil#_16508"> 99</p><p attribs="{'xml:space': 'preserve'}" id="_16509" smilref="Title.smil#_16509"> 1010</p><p attribs="{'xml:space': 'preserve'}" id="_16510" smilref="Title.smil#_16510"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_16511" smilref="Title.smil#_16511"> 1212</p><p attribs="{'xml:space': 'preserve'}" id="_16512" smilref="Title.smil#_16512"> 11</p><p attribs="{'xml:space': 'preserve'}" id="_16513" smilref="Title.smil#_16513"> 77</p><p attribs="{'xml:space': 'preserve'}" id="_16514" smilref="Title.smil#_16514"> 22</p><p attribs="{'xml:space': 'preserve'}" id="_16515" smilref="Title.smil#_16515"> 88</p><p attribs="{'xml:space': 'preserve'}" id="_16516" smilref="Title.smil#_16516"> 33</p><p attribs="{'xml:space': 'preserve'}" id="_16517" smilref="Title.smil#_16517"> 44</p><p attribs="{'xml:space': 'preserve'}" id="_16518" smilref="Title.smil#_16518"> 55</p><p attribs="{'xml:space': 'preserve'}" id="_16519" smilref="Title.smil#_16519"> 66</p><p attribs="{'xml:space': 'preserve'}" id="_16520" smilref="Title.smil#_16520"> 99</p><p attribs="{'xml:space': 'preserve'}" id="_16521" smilref="Title.smil#_16521"> 1010</p><p attribs="{'xml:space': 'preserve'}" id="_16522" smilref="Title.smil#_16522"> 1111</p><p attribs="{'xml:space': 'preserve'}" id="_16523" smilref="Title.smil#_16523"> 1212</p><p attribs="{'xml:space': 'preserve'}" id="_16524" smilref="Title.smil#_16524"> tt</p><p attribs="{'xml:space': 'preserve'}" id="_16525" smilref="Title.smil#_16525"> ttttttttttttttt tt</p><p attribs="{'xml:space': 'preserve'}" id="_16526" smilref="Title.smil#_16526"> Example of reducing maximum bipartite matching to network flow</p><p attribs="{'xml:space': 'preserve'}" id="_16527" smilref="Title.smil#_16527" /></level3><level3 id="_00132"><h3 id="ch6-s5-ss14" smilref="Title.smil#ch6-s5-ss14" xml:space="preserve">Linear programming</h3><pagenum id="p920" page="normal" smilref="Title.smil#p920" /><p attribs="{'xml:space': 'preserve'}" id="_16528" smilref="Title.smil#_16528"> For example, as illustrated in the figure at right, an augmenting-path max- flow algorithm might use the paths s-&gt;1-&gt;7-&gt;t, s-&gt;2-&gt;8-&gt;t, s-&gt;3-&gt;9-&gt;t,</p><p attribs="{'xml:space': 'preserve'}" id="_16529" smilref="Title.smil#_16529"> s-&gt;5-&gt;10-&gt;t, s-&gt;6-&gt;11-&gt;t, and s-&gt;4-&gt;7-&gt;1-&gt;8-&gt;2-&gt;12-&gt;t to compute</p><p attribs="{'xml:space': 'preserve'}" id="_16530" smilref="Title.smil#_16530"> the matching 1-8, 2-12, 3-9, 4-7, 5-10, and 6-11. Thus, there is a way to match all the students to jobs in our example. Each augmenting path fills one edge from the source and one edge into the sink. Note that these edges are never used as back edges, so there are at most V augmenting paths. and a total running time proportional to VE.</p><p attribs="{'xml:space': 'preserve'}" id="_16531" smilref="Title.smil#_16531"> Shortest paths and maxflow are important problem-solving models</p><p attribs="{'xml:space': 'preserve'}" id="_16532" smilref="Title.smil#_16532"> because they have the same properties that we articulated for sorting: </p><p attribs="{'xml:space': 'preserve'}" id="_16533" smilref="Title.smil#_16533"> Linear programming. One of the cornerstones of operations research is linear programming (LP). It refers to the idea of reducing a given problem to the following mathematical formulation:</p><p attribs="{'xml:space': 'preserve'}" id="_16534" smilref="Title.smil#_16534"> Linear programming. Given a set of M linear inequalities and linear equations involving N variables, and a linear objective function of the N variables, find an assignment of values to the variables that maximizes the objective function, or report that no feasible assignment exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16535" smilref="Title.smil#_16535"> Linear programming is an extremely important prob- lem-solving model because </p><p attribs="{'xml:space': 'preserve'}" id="_16536" smilref="Title.smil#_16536"> Maximize f + h subject to the constraints 0 &#11349; a &#11349; 2 0 &#11349; b &#11349; 3 0 &#11349; c &#11349; 3 0 &#11349; d &#11349; 1 0 &#11349; e &#11349; 1 0 &#11349; f &#11349; 1 0 &#11349; g &#11349; 2 0 &#11349; h &#11349; 3 a = c + d b = e + f c + e = g d + f = h</p><p attribs="{'xml:space': 'preserve'}" id="_16537" smilref="Title.smil#_16537"> LP example</p><p attribs="{'xml:space': 'preserve'}" id="_16538" smilref="Title.smil#_16538"> Reduction</p><p attribs="{'xml:space': 'preserve'}" id="_16539" smilref="Title.smil#_16539"> 907</p><p attribs="{'xml:space': 'preserve'}" id="_16540" smilref="Title.smil#_16540"> pa th w i th ba ck edge s</p><p attribs="{'xml:space': 'preserve'}" id="_16541" smilref="Title.smil#_16541"> Augmenting paths for bipartite matching</p><p attribs="{'xml:space': 'preserve'}" id="_16542" smilref="Title.smil#_16542" /><pagenum id="p921" page="normal" smilref="Title.smil#p921" /><p attribs="{'xml:space': 'preserve'}" id="_16543" smilref="Title.smil#_16543"> 908</p><p attribs="{'xml:space': 'preserve'}" id="_16544" smilref="Title.smil#_16544"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16545" smilref="Title.smil#_16545"> Proposition K. The following problems reduce to linear programming </p><p attribs="{'xml:space': 'preserve'}" id="_16546" smilref="Title.smil#_16546"> maxflow problem V</p><p attribs="{'xml:space': 'preserve'}" id="_16547" smilref="Title.smil#_16547"> E</p><p attribs="{'xml:space': 'preserve'}" id="_16548" smilref="Title.smil#_16548"> 6 8 0 1 2.0 0 2 3.0 1 3 3.0 1 4 1.0 2 3 1.0 2 4 1.0 3 5 2.0 4 5 3.0</p><p attribs="{'xml:space': 'preserve'}" id="_16549" smilref="Title.smil#_16549"> capacities</p><p attribs="{'xml:space': 'preserve'}" id="_16550" smilref="Title.smil#_16550"> maxflow solution</p><p attribs="{'xml:space': 'preserve'}" id="_16551" smilref="Title.smil#_16551"> Max flow from 0 to 5 0-&gt;2 3.0 2.0 0-&gt;1 2.0 2.0 1-&gt;4 1.0 1.0 1-&gt;3 3.0 1.0 2-&gt;3 1.0 1.0 2-&gt;4 1.0 1.0 3-&gt;5 2.0 2.0 4-&gt;5 3.0 2.0 Max flow value: 4.0</p><p attribs="{'xml:space': 'preserve'}" id="_16552" smilref="Title.smil#_16552"> LP formulation Maximize x 35 + x 45 subject to the constraints</p><p attribs="{'xml:space': 'preserve'}" id="_16553" smilref="Title.smil#_16553"> LP solution</p><p attribs="{'xml:space': 'preserve'}" id="_16554" smilref="Title.smil#_16554"> x 01 = 2 x 02 = 2 x 13 = 1 x 14 = 1 x 23 = 1 x 24 = 1 x 35 = 2 x 45 = 2</p><p attribs="{'xml:space': 'preserve'}" id="_16555" smilref="Title.smil#_16555"> 0 &#11349; x 01 &#11349; 2 0 &#11349; x 02 &#11349; 3 0 &#11349; x 13 &#11349; 3 0 &#11349; x 14 &#11349; 1 0 &#11349; x 23 &#11349; 1 0 &#11349; x 24 &#11349; 1 0 &#11349; x 35 &#11349; 2 0 &#11349; x 45 &#11349; 3 x 01 = x 13 + x 14 x 02 = x 23 + x 24 x 13 + x 23 = x 35 x 14 + x 24 = x 45</p><p attribs="{'xml:space': 'preserve'}" id="_16556" smilref="Title.smil#_16556"> Example of reducing network flow to linear programming</p><p attribs="{'xml:space': 'preserve'}" id="_16557" smilref="Title.smil#_16557" /><pagenum id="p922" page="normal" smilref="Title.smil#p922" /><p attribs="{'xml:space': 'preserve'}" id="_16558" smilref="Title.smil#_16558"> Reduction</p><p attribs="{'xml:space': 'preserve'}" id="_16559" smilref="Title.smil#_16559"> 909</p><p attribs="{'xml:space': 'preserve'}" id="_16560" smilref="Title.smil#_16560"> The &#8220;many, many other problems&#8221; in the statement of Proposition K refers to three ideas. First, it is very easy to extend a model and to add constraints. Second, reduction is transitive, so all the problems that reduce to shortest paths and maximum flow also reduce to linear programming. Third, and more generally, optimization problems of all sorts can be directly formulated as linear programming problems. Indeed, the term linear programming means &#8220;formulate an optimization problem as a linear programming problem.&#8221; This use predates the use of the word programming for computers. Equally important as the idea that a great many problems reduce to linear programming is the fact that efficient algorithms have been known for linear programming for many de- cades. The most famous, developed by G. Dantzig in the 1940s, is known as the simplex algorithm. Simplex is not difficult to understand (see the bare-bones implementation on the booksite). More recently, the ellipsoid algorithm presented by L. G. Khachian in 1979 led to the development of interior point methods in the 1980s that have proven to be an effective complement to the simplex algorithm for the huge linear programming problems that people are solving in modern applications. Nowadays, linear programming solvers are robust, extensively tested, ef&#64257; cient, and critical to the basic operation of modern corporations. Uses in scientific contexts and even in applications programming are also greatly expanding. If you can model your problem as a linear programming problem, you are likely to be able to solve it.</p><p attribs="{'xml:space': 'preserve'}" id="_16561" smilref="Title.smil#_16561"> In a very real sense, linear programming is the parent of problem-solving</p><p attribs="{'xml:space': 'preserve'}" id="_16562" smilref="Title.smil#_16562"> models, since so many problems reduce to it. Naturally, this idea leads to the question of whether there is an even more powerful problem-solving model than linear pro- gramming. What sorts of problems do not reduce to linear programming? Here is an example of such a problem:</p><p attribs="{'xml:space': 'preserve'}" id="_16563" smilref="Title.smil#_16563"> Load balancing. Given a set of jobs of specified duration to be completed, how can we schedule the jobs on two identical processors so as to minimize the completion time of all the jobs?</p><p attribs="{'xml:space': 'preserve'}" id="_16564" smilref="Title.smil#_16564"> Can we articulate a more general problem-solving model and solve instances of problems within that model ef&#64257; ciently? This line of thinking leads to the idea of intractabil- ity, our last topic.</p><p attribs="{'xml:space': 'preserve'}" id="_16565" smilref="Title.smil#_16565" /><pagenum id="p924" page="normal" smilref="Title.smil#p924" /><p attribs="{'xml:space': 'preserve'}" id="_16566" smilref="Title.smil#_16566"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16567" smilref="Title.smil#_16567"> 911</p><p attribs="{'xml:space': 'preserve'}" id="_16568" smilref="Title.smil#_16568"> Again, this is a statement about the natural world, buttressed by the idea that all known computing devices can be simulated by a Turing machine, with at most a polynomial factor increase in cost. In recent years, the idea of quantum computing has given some researchers reason to doubt the extended Church-Turing thesis. Most agree that, from a practical point of view, it is probably safe for some time, but many researchers are hard at work on trying to falsify the thesis.</p><p attribs="{'xml:space': 'preserve'}" id="_16569" smilref="Title.smil#_16569"> Exponential running time. The purpose of the theory of intractability is to separate problems that can be solved in polynomial time from problems that (probably) require exponential time to solve in the worst case. It is useful to think of an exponential-time algorithm as one that, for some input of size N, takes time proportional to 2N (at least). The substance of the argument does not change if we replace 2 by any number &#9251; &gt; 1. We generally take as granted that an exponential-time algorithm cannot be guaranteed to solve a problem of size 100 (say) in a reasonable amount of time, because no one can wait for an algorithm to take 2100 steps, regardless of the speed of the computer. Exponential growth dwarfs technological changes: a supercomputer may be a trillion times faster than an abacus, but neither can come close to solving a problem that requires 2100 steps. Sometimes the line between &#8220;easy&#8221; and &#8220;hard&#8221; problems is a fine one. For ex- ample, we studied an algorithm in Section 4.1 that can solve the following problem:</p><p attribs="{'xml:space': 'preserve'}" id="_16570" smilref="Title.smil#_16570"> public class LongestPath { private boolean[] marked; private int max;</p><p attribs="{'xml:space': 'preserve'}" id="_16571" smilref="Title.smil#_16571"> Shortest-path length. What</p><p attribs="{'xml:space': 'preserve'}" id="_16572" smilref="Title.smil#_16572"> is the length of the shortest path from a given vertex s to a given vertex t in a given graph?</p><p attribs="{'xml:space': 'preserve'}" id="_16573" smilref="Title.smil#_16573"> But we did not study algorithms for the following problem, which seems to be virtually the same:</p><p attribs="{'xml:space': 'preserve'}" id="_16574" smilref="Title.smil#_16574"> Longest-path</p><p attribs="{'xml:space': 'preserve'}" id="_16575" smilref="Title.smil#_16575"> length. What</p><p attribs="{'xml:space': 'preserve'}" id="_16576" smilref="Title.smil#_16576"> is the length of the longest simple path from a given vertex s to a given vertex t in a given graph?</p><p attribs="{'xml:space': 'preserve'}" id="_16577" smilref="Title.smil#_16577"> public LongestPath(Graph G, int s, int t) { marked = new boolean[G.V()]; dfs(G, s, t, 0); }</p><p attribs="{'xml:space': 'preserve'}" id="_16578" smilref="Title.smil#_16578"> private void dfs(Graph G, int v, int t, int i) { if (v == t &amp;&amp; i &gt; max) max = i; if (v == t) return; marked[v] = true; for (int w : G.adj(v)) if (!marked[w]) dfs(G, w, t, i+1); marked[v] = false; }</p><p attribs="{'xml:space': 'preserve'}" id="_16579" smilref="Title.smil#_16579"> public int maxLength() { return max; }</p><p attribs="{'xml:space': 'preserve'}" id="_16580" smilref="Title.smil#_16580"> }</p><p attribs="{'xml:space': 'preserve'}" id="_16581" smilref="Title.smil#_16581"> Finding the length of the longest path in a graph</p><p attribs="{'xml:space': 'preserve'}" id="_16582" smilref="Title.smil#_16582" /></level3><level3 id="_00133"><h3 id="ch6-s6-ss15" smilref="Title.smil#ch6-s6-ss15" xml:space="preserve">Longest-paths problem</h3><pagenum id="p925" page="normal" smilref="Title.smil#p925" /><p attribs="{'xml:space': 'preserve'}" id="_16583" smilref="Title.smil#_16583"> 912</p><p attribs="{'xml:space': 'preserve'}" id="_16584" smilref="Title.smil#_16584"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16585" smilref="Title.smil#_16585"> The crux of the matter is this: as far as we know, these problems are nearly at opposite ends of the spectrum with respect to dif&#64257; culty. Breadth-&#64257; rst search yields a solution for the first problem in linear time, but all known algorithms for the second problem take exponential time in the worst case. The code at the bottom of the previous page shows a variant of depth-&#64257; rst search that accomplishes the task. It is quite similar to depth-&#64257; rst search, but it examines all simple paths from s to t in the digraph to find the longest one.</p><p attribs="{'xml:space': 'preserve'}" id="_16586" smilref="Title.smil#_16586"> Search problems. The great disparity between problems that can be solved with &#8220;ef- fi cient&#8221; algorithms of the type we have been studying in this book and problems where we need to look for a solution among a potentially huge number of possibilities makes it possible to study the interface between them with a simple formal model. The first step is to characterize the type of problem that we study :</p><p attribs="{'xml:space': 'preserve'}" id="_16587" smilref="Title.smil#_16587"> Definition. A search problem is a problem having solutions with the property that the time needed to certify that any solution is correct is bounded by a polynomial in the size of the input. We say that an algorithm solves a search problem if, given any input, it either produces a solution or reports that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16588" smilref="Title.smil#_16588"> Four particular problems that are of interest in our discussion of intractability are shown at the top of the facing page. These problems are known as satisfiability prob- lems. Now, all that is required to establish that a problem is a search problem is to show that any solution is sufficiently well-characterized that you can efficiently certify that it is correct. Solving a search problem is like searching for a &#8220;needle in a haystack&#8221; with the sole proviso that you can recognize the needle when you see it. For example, if you are given an assignment of values to variables in each of the satisfiability problems at the top of page 913, you easily can certify that each equality or inequality is satis&#64257; ed, but searching for such an assignment is a totally different task. The name NP is commonly used to describe search problems&#8212;we will describe the reason for the name on page 914:</p><p attribs="{'xml:space': 'preserve'}" id="_16589" smilref="Title.smil#_16589"> Definition. NP is the set of all search problems.</p><p attribs="{'xml:space': 'preserve'}" id="_16590" smilref="Title.smil#_16590"> NP is nothing more than a precise characterization of all the problems that scientists, engineers, and applications programmers aspire to solve with programs that are guaranteed to finish in a feasible amount of time.</p><p attribs="{'xml:space': 'preserve'}" id="_16591" smilref="Title.smil#_16591" /><pagenum id="p926" page="normal" smilref="Title.smil#p926" /><p attribs="{'xml:space': 'preserve'}" id="_16592" smilref="Title.smil#_16592"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16593" smilref="Title.smil#_16593"> 913</p><p attribs="{'xml:space': 'preserve'}" id="_16594" smilref="Title.smil#_16594"> Linear equation satis&#64257; ability. Given a set of M linear equations involving N variables, find an assignment of values to the variables that satisfies all of the equations, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16595" smilref="Title.smil#_16595"> Linear inequality satisfiability (search formulation of linear program-</p><p attribs="{'xml:space': 'preserve'}" id="_16596" smilref="Title.smil#_16596"> ming). Given a set of M linear inequalities involving N variables, find an assignment of values to the variables that satisfies all of the inequalities, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16597" smilref="Title.smil#_16597"> 0-1 integer linear inequality satisfiability (search formulation of 0-1 integer</p><p attribs="{'xml:space': 'preserve'}" id="_16598" smilref="Title.smil#_16598"> linear programming). Given a set of M linear inequalities involving N integer variables, find an assignment of the values 0 or 1 to the variables that satisfies all of the inequalities, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16599" smilref="Title.smil#_16599"> Boolean satis&#64257; ability. Given a set of M equations involving and and or operations on N boolean variables, find an assignment of values to the variables that satisfies all of the equations, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16600" smilref="Title.smil#_16600"> Selected search problems</p><p attribs="{'xml:space': 'preserve'}" id="_16601" smilref="Title.smil#_16601"> Other types of problems. The concept of search problems is one of many ways to characterize the set of problems that form the basis of the study of intractability. Other possibilities are decision problems (does a solution exist?) and optimization problems (what is the best solution)? For example, the longest-paths length problem on page 911 is an optimization problem, not a search problem (given a solution, we have no way to verify that it is a longest-path length). A search version of this problem is to find a simple path connecting all the vertices (this problem is known as the Hamiltonian path problem). A decision version of the problem is to ask whether there exists a simple path connecting all the vertices. Arbitrage, boolean satis&#64257; ability, and Hamiltonian path are search problems; to ask whether a solution exists to any of these problems is a decision problem; and shortest/longest paths, max&#64258; ow, and linear programming are all optimization problems. While not technically equivalent, search, decision, and optimization problems typically reduce to one another (see Exercise 6.58 and 6.59) and the main conclusions we draw apply to all three types of problems.</p><p attribs="{'xml:space': 'preserve'}" id="_16602" smilref="Title.smil#_16602" /><pagenum id="p927" page="normal" smilref="Title.smil#p927" /><p attribs="{'xml:space': 'preserve'}" id="_16603" smilref="Title.smil#_16603"> 914</p><p attribs="{'xml:space': 'preserve'}" id="_16604" smilref="Title.smil#_16604"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16605" smilref="Title.smil#_16605"> Easy search problems. The definition of NP says nothing about the difficulty of finding the solution, just certifying that it is a solution. The second of the two sets of problems that form the basis of the study of intractability, which is known as P, is concerned with the difficulty of finding the solution. In this model, the efficiency of an algorithm is a function of the number of bits used to encode the input.</p><p attribs="{'xml:space': 'preserve'}" id="_16606" smilref="Title.smil#_16606"> Definition. P is the set of all search problems that can be solved in polynomial time.</p><p attribs="{'xml:space': 'preserve'}" id="_16607" smilref="Title.smil#_16607"> Implicit in the definition is the idea that the polynomial time bound is a worst-case bound. For a problem to be in P, there must exist an algorithm that can guarantee to solve it in polynomial time. Note that the polynomial is not specified at all. Linear, lin- earithmic, quadratic, and cubic are all polynomial time bounds, so this definition certainly covers the standard algorithms we have studied so far. The time taken by an algorithm depends on the computer used, but the extended Church-Turing thesis renders that point moot&#8212;it says that a polynomial-time solution on any computing device implies the existence of a polynomial-time solution on any other computing device. Sorting belongs to P because (for example) insertion sort runs in time proportional to N 2 (the existence of linearithmic sorting algorithms is not relevant in this context), as does shortest paths, linear equation satis&#64257; ability, and many others. Having an efficient algorithm to solve a problem is a proof that the problem is in P. In other words, P is nothing more than a precise characterization of all the problems that scientists, engi- neers, and applications programmers do solve with programs that are guaranteed to finish in a feasible amount of time.</p><p attribs="{'xml:space': 'preserve'}" id="_16608" smilref="Title.smil#_16608"> Nondeterminism. The N in NP stands for nondeterminism. It represents the idea that one way (in theory) to extend the power of a computer is to endow it with the power of nondeterminism: to assert that when an algorithm is faced with a choice of several options, it has the power to &#8220;guess&#8221; the right one. For the purposes of our discus- sion, we can think of an algorithm for a nondeterministic machine as &#8220;guessing&#8221; the solution to a problem, then certifying that the solution is valid. In a Turing machine, nondeterminism is as simple as defining two different successor states for a given state and a given input and characterizing solutions as all legal paths to the desired result. Nondeterminism may be a mathematical fi ction, but it is a useful idea. For example, in Section 5.4, we used nondeterminism as a tool for algorithm design&#8212;our regular expression pattern-matching algorithm is based on efficiently simulating a nondeterministic machine.</p><p attribs="{'xml:space': 'preserve'}" id="_16609" smilref="Title.smil#_16609" /><pagenum id="p928" page="normal" smilref="Title.smil#p928" /><p attribs="{'xml:space': 'preserve'}" id="_16610" smilref="Title.smil#_16610"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16611" smilref="Title.smil#_16611"> 915</p><p attribs="{'xml:space': 'preserve'}" id="_16612" smilref="Title.smil#_16612"> problem</p><p attribs="{'xml:space': 'preserve'}" id="_16613" smilref="Title.smil#_16613"> input</p><p attribs="{'xml:space': 'preserve'}" id="_16614" smilref="Title.smil#_16614"> description</p><p attribs="{'xml:space': 'preserve'}" id="_16615" smilref="Title.smil#_16615"> poly-time algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16616" smilref="Title.smil#_16616"> instance</p><p attribs="{'xml:space': 'preserve'}" id="_16617" smilref="Title.smil#_16617"> solution</p><p attribs="{'xml:space': 'preserve'}" id="_16618" smilref="Title.smil#_16618"> Hamiltonian path</p><p attribs="{'xml:space': 'preserve'}" id="_16619" smilref="Title.smil#_16619"> graph G</p><p attribs="{'xml:space': 'preserve'}" id="_16620" smilref="Title.smil#_16620"> find a simple path that visits every vertex</p><p attribs="{'xml:space': 'preserve'}" id="_16621" smilref="Title.smil#_16621"> factoring</p><p attribs="{'xml:space': 'preserve'}" id="_16622" smilref="Title.smil#_16622"> integer x</p><p attribs="{'xml:space': 'preserve'}" id="_16623" smilref="Title.smil#_16623"> find a nontrivial factor of x</p><p attribs="{'xml:space': 'preserve'}" id="_16624" smilref="Title.smil#_16624"> 0-1 linear inequality satisfiability </p><p attribs="{'xml:space': 'preserve'}" id="_16625" smilref="Title.smil#_16625"> all problems in P</p><p attribs="{'xml:space': 'preserve'}" id="_16626" smilref="Title.smil#_16626"> M 0-1 variables N inequalities</p><p attribs="{'xml:space': 'preserve'}" id="_16627" smilref="Title.smil#_16627"> assign values to the variables that satisfy the inequalities</p><p attribs="{'xml:space': 'preserve'}" id="_16628" smilref="Title.smil#_16628"> see table below</p><p attribs="{'xml:space': 'preserve'}" id="_16629" smilref="Title.smil#_16629"> Examples of problems in NP</p><p attribs="{'xml:space': 'preserve'}" id="_16630" smilref="Title.smil#_16630"> ?</p><p attribs="{'xml:space': 'preserve'}" id="_16631" smilref="Title.smil#_16631"> ?</p><p attribs="{'xml:space': 'preserve'}" id="_16632" smilref="Title.smil#_16632"> ?</p><p attribs="{'xml:space': 'preserve'}" id="_16633" smilref="Title.smil#_16633"> 0-2-1-3</p><p attribs="{'xml:space': 'preserve'}" id="_16634" smilref="Title.smil#_16634"> 97605257271</p><p attribs="{'xml:space': 'preserve'}" id="_16635" smilref="Title.smil#_16635"> 8784561</p><p attribs="{'xml:space': 'preserve'}" id="_16636" smilref="Title.smil#_16636"> x &#11002; y &#11349; 1 2x &#11002; z &#11349; 2 x + y &#11350; 2 z &#11350; 0</p><p attribs="{'xml:space': 'preserve'}" id="_16637" smilref="Title.smil#_16637"> x = 1 y = 1 z = 0</p><p attribs="{'xml:space': 'preserve'}" id="_16638" smilref="Title.smil#_16638"> problem</p><p attribs="{'xml:space': 'preserve'}" id="_16639" smilref="Title.smil#_16639"> input</p><p attribs="{'xml:space': 'preserve'}" id="_16640" smilref="Title.smil#_16640"> description</p><p attribs="{'xml:space': 'preserve'}" id="_16641" smilref="Title.smil#_16641"> shortest st-path</p><p attribs="{'xml:space': 'preserve'}" id="_16642" smilref="Title.smil#_16642"> graph G vertices s, t</p><p attribs="{'xml:space': 'preserve'}" id="_16643" smilref="Title.smil#_16643"> find the shortest path from s to t</p><p attribs="{'xml:space': 'preserve'}" id="_16644" smilref="Title.smil#_16644"> sorting</p><p attribs="{'xml:space': 'preserve'}" id="_16645" smilref="Title.smil#_16645"> array a</p><p attribs="{'xml:space': 'preserve'}" id="_16646" smilref="Title.smil#_16646"> linear equation satisfiability </p><p attribs="{'xml:space': 'preserve'}" id="_16647" smilref="Title.smil#_16647"> M variables N equations</p><p attribs="{'xml:space': 'preserve'}" id="_16648" smilref="Title.smil#_16648"> find a permutation that puts a in ascending order</p><p attribs="{'xml:space': 'preserve'}" id="_16649" smilref="Title.smil#_16649"> assign values to the variables that satisfy the equations</p><p attribs="{'xml:space': 'preserve'}" id="_16650" smilref="Title.smil#_16650"> poly-time algorithm</p><p attribs="{'xml:space': 'preserve'}" id="_16651" smilref="Title.smil#_16651"> s</p><p attribs="{'xml:space': 'preserve'}" id="_16652" smilref="Title.smil#_16652"> BFS</p><p attribs="{'xml:space': 'preserve'}" id="_16653" smilref="Title.smil#_16653"> instance</p><p attribs="{'xml:space': 'preserve'}" id="_16654" smilref="Title.smil#_16654"> solution</p><p attribs="{'xml:space': 'preserve'}" id="_16655" smilref="Title.smil#_16655"> 0-3</p><p attribs="{'xml:space': 'preserve'}" id="_16656" smilref="Title.smil#_16656"> t</p><p attribs="{'xml:space': 'preserve'}" id="_16657" smilref="Title.smil#_16657"> mergesort 2.8 8.5 4.1 1.3</p><p attribs="{'xml:space': 'preserve'}" id="_16658" smilref="Title.smil#_16658"> 3 0 2 1</p><p attribs="{'xml:space': 'preserve'}" id="_16659" smilref="Title.smil#_16659"> Gaussian elimination</p><p attribs="{'xml:space': 'preserve'}" id="_16660" smilref="Title.smil#_16660"> x + y = 1.5 2x &#11002; y = 0</p><p attribs="{'xml:space': 'preserve'}" id="_16661" smilref="Title.smil#_16661"> linear inequality satisfiability </p><p attribs="{'xml:space': 'preserve'}" id="_16662" smilref="Title.smil#_16662"> M variables N inequalities</p><p attribs="{'xml:space': 'preserve'}" id="_16663" smilref="Title.smil#_16663"> assign values to the variables that satisfy the inequalities</p><p attribs="{'xml:space': 'preserve'}" id="_16664" smilref="Title.smil#_16664"> ellipsoid</p><p attribs="{'xml:space': 'preserve'}" id="_16665" smilref="Title.smil#_16665"> x &#11002; y &#11349; 1.5 2x &#11002; z &#11349; 0 x + y &#11350; 3.5 z &#11350; 4.0</p><p attribs="{'xml:space': 'preserve'}" id="_16666" smilref="Title.smil#_16666"> Examples of problems in P</p><p attribs="{'xml:space': 'preserve'}" id="_16667" smilref="Title.smil#_16667"> x = 0.5 y = 1</p><p attribs="{'xml:space': 'preserve'}" id="_16668" smilref="Title.smil#_16668"> x = 2.0 y = 1.5 z = 4.0</p><p attribs="{'xml:space': 'preserve'}" id="_16669" smilref="Title.smil#_16669" /><pagenum id="p929" page="normal" smilref="Title.smil#p929" /><p attribs="{'xml:space': 'preserve'}" id="_16670" smilref="Title.smil#_16670"> 916</p><p attribs="{'xml:space': 'preserve'}" id="_16671" smilref="Title.smil#_16671"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16672" smilref="Title.smil#_16672"> The main question. Nondeterminism is such a powerful notion that it seems almost absurd to consider it seriously. Why bother considering an imaginary tool that makes difficult problems seem trivial? The answer is that, powerful as nondeterminism may seem, no one has been able to prove that it helps for any particular problem! Put another way, no one has been able to find a single problem that can be proven to be in NP but not in P (or even prove that one exists), leaving the following question open: Does P = NP ? This question was first posed in a famous letter from K. G&#246;del to J. von Neumann in 1950 and has completely stumped mathematicians and computer scientists ever since. Other ways of posing the question shed light on its fundamental nature: </p><p attribs="{'xml:space': 'preserve'}" id="_16673" smilref="Title.smil#_16673"> Poly-time reductions. Recall from page 903 that we show that a problem A reduces to another problem B by demonstrating that we can solve any instance of A in three steps: </p><p attribs="{'xml:space': 'preserve'}" id="_16674" smilref="Title.smil#_16674" /></level3><level3 id="_00134"><h3 id="ch6-s6-ss16" smilref="Title.smil#ch6-s6-ss16" xml:space="preserve">NP-completeness</h3><pagenum id="p930" page="normal" smilref="Title.smil#p930" /><p attribs="{'xml:space': 'preserve'}" id="_16675" smilref="Title.smil#_16675"> Proposition L. Boolean satisfiability poly-time reduces to 0-1 integer linear inequality satis&#64257; ability.</p><p attribs="{'xml:space': 'preserve'}" id="_16676" smilref="Title.smil#_16676"> Proof : Given an instance of boolean satis&#64257; ability, define a set of inequalities with one 0-1 variable corresponding to each boolean variable and one 0-1 variable corresponding to each clause, as illustrated in the example at right. With this construction, we can tranform a solution to the integer 0-1 linear inequality satisfiability problem to a solution to the boolean sat- is&#64257; ability problem by assigning each boolean variable to be true if the corresponding integer variable is 1 and false if it is 0.</p><p attribs="{'xml:space': 'preserve'}" id="_16677" smilref="Title.smil#_16677"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16678" smilref="Title.smil#_16678"> 917</p><p attribs="{'xml:space': 'preserve'}" id="_16679" smilref="Title.smil#_16679"> boolean satisfiability problem</p><p attribs="{'xml:space': 'preserve'}" id="_16680" smilref="Title.smil#_16680"> (x'1 or x2 or x3) and (x1 or x'2 or x3) and (x'1 or x'2 or x'3) and (x'1 or x'2 or x3)</p><p attribs="{'xml:space': 'preserve'}" id="_16681" smilref="Title.smil#_16681"> 0-1 integer linear inequality satisfiability formulation c1is 1 if and only if first clause is satisfiable</p><p attribs="{'xml:space': 'preserve'}" id="_16682" smilref="Title.smil#_16682"> c1 &#11350; x2 c1 &#11350; x3</p><p attribs="{'xml:space': 'preserve'}" id="_16683" smilref="Title.smil#_16683"> c1 &#11350; 1 &#5009; x1</p><p attribs="{'xml:space': 'preserve'}" id="_16684" smilref="Title.smil#_16684"> c1 &#11349; (1 &#5009; x1) + x2 + x3</p><p attribs="{'xml:space': 'preserve'}" id="_16685" smilref="Title.smil#_16685"> c2 &#11350; x1</p><p attribs="{'xml:space': 'preserve'}" id="_16686" smilref="Title.smil#_16686"> c2</p><p attribs="{'xml:space': 'preserve'}" id="_16687" smilref="Title.smil#_16687"> &#11349; x1 + (1 &#5009; x2) + x3</p><p attribs="{'xml:space': 'preserve'}" id="_16688" smilref="Title.smil#_16688"> c2 &#11350; 1 &#5009; x2</p><p attribs="{'xml:space': 'preserve'}" id="_16689" smilref="Title.smil#_16689"> c2 &#11350; x3</p><p attribs="{'xml:space': 'preserve'}" id="_16690" smilref="Title.smil#_16690"> Corollary. If satisfiability is hard to solve, then so is integer linear programming.</p><p attribs="{'xml:space': 'preserve'}" id="_16691" smilref="Title.smil#_16691"> c3 &#11350; 1 &#5009; x1 c3 &#11350; 1 &#5009; x2 c3 &#11350; 1 &#5009; x3</p><p attribs="{'xml:space': 'preserve'}" id="_16692" smilref="Title.smil#_16692"> c3 &#11349; (1 &#5009; x1) + 1 &#5009; x2 + (1 &#5009; x3 )</p><p attribs="{'xml:space': 'preserve'}" id="_16693" smilref="Title.smil#_16693"> c4 &#11350; 1 &#5009; x1 c4 &#11350; 1 &#5009; x2</p><p attribs="{'xml:space': 'preserve'}" id="_16694" smilref="Title.smil#_16694"> c4 &#11349; (1 &#5009; x1) + (1 &#5009; x2) + x3</p><p attribs="{'xml:space': 'preserve'}" id="_16695" smilref="Title.smil#_16695"> c4 &#11350; x3</p><p attribs="{'xml:space': 'preserve'}" id="_16696" smilref="Title.smil#_16696"> This statement is a meaningful statement about the relative difficulty of solving these two problems even in the absence of a precise definition of hard to solve. In the present context, by &#8220;hard to solve,&#8221; we mean &#8220;not in P.&#8221; We generally use the word intractable to refer to problems that are not in P. Starting with the seminal work of R. Karp in 1972, researchers have shown literally tens of thousands of problems from a wide variety of applications areas to be related by reduction relationships of this sort. More- over, these relationships imply much more than just relationships between the individual problems, a concept that we now address. NP-completeness. Many, many problems are known to belong to NP but probably do not belong to P. That is, we can easily certify that any given solution is valid, but, despite considerable effort, no one has been able to develop an efficient algorithm to find a so- lution. Remarkably, all of these many, many problems have an additional property that provides convincing evidence that P &#11005; NP :</p><p attribs="{'xml:space': 'preserve'}" id="_16697" smilref="Title.smil#_16697"> s &#11349; c1 s &#11349; c2 s &#11349; c3 s &#11349; c4 s &#11350; c1 + c2 + c3 + c4 &#5009; 3</p><p attribs="{'xml:space': 'preserve'}" id="_16698" smilref="Title.smil#_16698"> s is 1 if and only if c&#8217;s are all 1</p><p attribs="{'xml:space': 'preserve'}" id="_16699" smilref="Title.smil#_16699"> Example of reducing boolean satisfiability to 0-1 integer linear inequality satisfiability</p><p attribs="{'xml:space': 'preserve'}" id="_16700" smilref="Title.smil#_16700" /><pagenum id="p931" page="normal" smilref="Title.smil#p931" /><p attribs="{'xml:space': 'preserve'}" id="_16701" smilref="Title.smil#_16701"> 918</p><p attribs="{'xml:space': 'preserve'}" id="_16702" smilref="Title.smil#_16702"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16703" smilref="Title.smil#_16703"> Definition. A search problem A is said to be NP-complete if all problems in NP poly- time reduce to A.</p><p attribs="{'xml:space': 'preserve'}" id="_16704" smilref="Title.smil#_16704"> This definition enables us to upgrade our definition of &#8220;hard to solve&#8221; to mean &#8220;intrac- table unless P = NP.&#8221; If any NP-complete problem can be solved in polynomial time on a deterministic machine, then so can all problems in NP (i.e., P = NP). That is, the collective failure of all researchers to find efficient algorithms for all of these problems might be viewed as a collective failure to prove that P = NP. NP-complete problems, meaning that we do not expect to find guaranteed polynomial-time algorithms. Most practical search problems are known to be either in P or NP-complete. Cook-Levin theorem. Reduction uses the NP-completeness of one problem to imply the NP-completeness of another. But reduction cannot be used in one case: how was the first problem proven to be NP-complete? This was done independently by S. Cook and L. Levin in the early 1970s.</p><p attribs="{'xml:space': 'preserve'}" id="_16705" smilref="Title.smil#_16705"> Proposition M. ( Cook-Levin theorem) Boolean satisfiability is NP-complete.</p><p attribs="{'xml:space': 'preserve'}" id="_16706" smilref="Title.smil#_16706"> Extremely brief proof sketch: The goal is to show that if there is a polynomial time algorithm for boolean satis&#64257; ability, then all problems in NP can be solved in polynomial time. Now, a nondeterministic Turing machine can solve any problem in NP, so the first step in the proof is to describe each feature of the machine in terms of logical formulas such as appear in the boolean satisfiability problem. This construction establishes a correspondence between every problem in NP (which can be expressed as a program on the nondeterministic Turing machine) and some instance of satisfiability (the translation of that program into a logical formula). Now, the solution to the satisfiability problem essentially corresponds to a simulation of the machine running the given program on the given input, so it produces a solution to an instance of the given problem. Further details of this proof are well beyond the scope of this book. Fortunately, only one such proof is really necessary : it is much easier to use reduction to prove NP-completeness.</p><p attribs="{'xml:space': 'preserve'}" id="_16707" smilref="Title.smil#_16707"> The Cook-Levin theorem, in conjunction with the thousands and thousands of poly- time reductions from NP-complete problems that have followed it, leaves us with two possible universes: either P = NP and no intractable search problems exist (all search problems can be solved in polynomial time); or P &#8800; NP, there do exist intractable search problems (some search problems cannot be solved in polynomial time). NP-complete</p><p attribs="{'xml:space': 'preserve'}" id="_16708" smilref="Title.smil#_16708" /><pagenum id="p932" page="normal" smilref="Title.smil#p932" /><p attribs="{'xml:space': 'preserve'}" id="_16709" smilref="Title.smil#_16709"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16710" smilref="Title.smil#_16710"> 919</p><p attribs="{'xml:space': 'preserve'}" id="_16711" smilref="Title.smil#_16711"> P = NP</p><p attribs="{'xml:space': 'preserve'}" id="_16712" smilref="Title.smil#_16712"> P = NP</p><p attribs="{'xml:space': 'preserve'}" id="_16713" smilref="Title.smil#_16713"> P &#8800; NP</p><p attribs="{'xml:space': 'preserve'}" id="_16714" smilref="Title.smil#_16714"> NP</p><p attribs="{'xml:space': 'preserve'}" id="_16715" smilref="Title.smil#_16715"> P</p><p attribs="{'xml:space': 'preserve'}" id="_16716" smilref="Title.smil#_16716"> NPC</p><p attribs="{'xml:space': 'preserve'}" id="_16717" smilref="Title.smil#_16717"> Two possible universes</p><p attribs="{'xml:space': 'preserve'}" id="_16718" smilref="Title.smil#_16718"> problems arise frequently in important natural practical ap- plications, so there has been strong motivation to find good algorithms to solve them. The fact that no good algorithm has been found for any of these problems is surely strong evidence that P &#8800; NP, and most researchers certainly believe this to be the case. On the other hand, the fact that no one has been able to prove that any of these problems do not belong to P could be construed to comprise a similar body of circumstantial evidence on the other side. Whether or not P = NP, the practical fact is that the best known algorithm for any of the NP-com- plete problems takes exponential time in the worst case.</p><p attribs="{'xml:space': 'preserve'}" id="_16719" smilref="Title.smil#_16719"> Classifying problems. To prove that a search problem is in P, we need to exhibit a polynomial-time algorithm for solving it, perhaps by reducing it to a problem known to be in P. To prove that a problem in NP is NP-complete, we need to show that some known NP-complete problem is poly-time reducible to it: that is, that a polynomial- time algorithm for the new problem could be used to solve the NP-complete problem, and then could, in turn, be used to solve all problems in NP. Thousands and thousands of problems have been shown to be NP-complete in this way, as we did for integer linear programming in Proposition L. The list on page 920, which includes several of the problems addressed by Karp, is representative, but contains only a tiny fraction of the known NP-complete problems. Classifying problems as being easy to solve (in P) or hard to solve (NP-complete) can be: </p><p attribs="{'xml:space': 'preserve'}" id="_16720" smilref="Title.smil#_16720" /><pagenum id="p933" page="normal" smilref="Title.smil#p933" /><p attribs="{'xml:space': 'preserve'}" id="_16721" smilref="Title.smil#_16721"> 920</p><p attribs="{'xml:space': 'preserve'}" id="_16722" smilref="Title.smil#_16722"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16723" smilref="Title.smil#_16723"> Boolean satis&#64257; ability. Given a set of M equations involving N boolean variables, find an assignment of values to the variables that satisfies all of the equations, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16724" smilref="Title.smil#_16724"> Integer linear programming. Given a set of M linear inequalities involving N integer variables, find an assignment of values to the variables that satisfies all of the inequalities, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16725" smilref="Title.smil#_16725"> Load balancing. Given a set of jobs of specified duration to be completed and a time bound T, how can we schedule the jobs on two identical processors so as to complete them all by time T?</p><p attribs="{'xml:space': 'preserve'}" id="_16726" smilref="Title.smil#_16726"> Vertex cover. Given a graph and a integer C, find a set of C vertices such that each edge of the graph is incident to at least one vertex of the set.</p><p attribs="{'xml:space': 'preserve'}" id="_16727" smilref="Title.smil#_16727"> Hamiltonian path. Given a graph, find a simple path that visits each vertex exactly once, or report that none exists.</p><p attribs="{'xml:space': 'preserve'}" id="_16728" smilref="Title.smil#_16728"> Protein folding. Given energy level M, find a folded three-dimensional conformation of a protein having potential energy less than M.</p><p attribs="{'xml:space': 'preserve'}" id="_16729" smilref="Title.smil#_16729"> Ising model. Given an Ising model on a lattice of dimension three and an energy threshhold E, is there a subgraph with free energy less than E ?</p><p attribs="{'xml:space': 'preserve'}" id="_16730" smilref="Title.smil#_16730"> Risk portfolio of a given return. Given an investment portfolio with a given total cost, a given return, risk values assigned to each investment, and a threshold M, find a way to allocate the investments such that the risk is less than M.</p><p attribs="{'xml:space': 'preserve'}" id="_16731" smilref="Title.smil#_16731"> Some famous NP-complete problems</p><p attribs="{'xml:space': 'preserve'}" id="_16732" smilref="Title.smil#_16732" /><pagenum id="p934" page="normal" smilref="Title.smil#p934" /><p attribs="{'xml:space': 'preserve'}" id="_16733" smilref="Title.smil#_16733"> Intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16734" smilref="Title.smil#_16734"> 921</p><p attribs="{'xml:space': 'preserve'}" id="_16735" smilref="Title.smil#_16735"> Coping with NP-completeness. Some sort of solution to this vast panoply of problems must be found in practice, so there is intense interest in finding ways to address them. It is impossible to do justice to this vast field of study in one paragraph, but we can briefly describe various approaches that have been tried. One approach is to change the problem and find an &#8220;approximation&#8221; algorithm that finds not the best solution but a solution guaranteed to be close to the best. For example, it is easy to find a solution to the Euclidean traveling salesperson problem that is within a factor of 2 of the optimal. Unfortunately, this approach is often not sufficient to ward off NP-completeness, when seeking improved approximations. Another approach is to develop an algorithm that solves efficiently virtually all of the instances that do arise in practice, even though there exist worst-case inputs for which finding a solution is infeasible. The most famous example of this approach are the integer linear programming solvers, which have been workhorses for many decades in solving huge optimizaiton problems in countless industrial applications. Even though they could require exponential time, the inputs that arise in practice evidently are not worst-case inputs. A third approach is to work with &#8220;ef&#64257; cient&#8221; exponential algorithms, using a technique known as backtracking to avoid having to check all possible solutions. Finally, there is quite a large gap between polynomial and exponential time that is not addressed by the theory. What about an algorithm that runs in time proportional to N log N or 2&#20906; N ?</p><p attribs="{'xml:space': 'preserve'}" id="_16736" smilref="Title.smil#_16736"> All the applications areas we have studied in this book are touched by NP-com- pleteness: NP-complete problems arise in elementary programming, in sorting and searching, in graph processing, in string processing, in scientific computing, in systems programming, in operations research, and in any conceivable area where computing plays a role. The most important practical contribution of the theory of NP-complete- ness is that it provides a mechanism to discover whether a new problem from any of these diverse areas is &#8220;easy&#8221; or &#8220;hard.&#8221; If one can find an efficient algorithm to solve a new problem, then there is no dif&#64257; culty. If not, a proof that the problem is NP-complete tells us that developing an efficient algorithm would be a stunning achievement (and suggests that a different approach should perhaps be tried). The scores of efficient algorithms that we have examined in this book are testimony that we have learned a great deal about efficient computational methods since Euclid, but the theory of NP- completeness shows that, indeed, we still have a great deal to learn.</p><p attribs="{'xml:space': 'preserve'}" id="_16737" smilref="Title.smil#_16737" /><pagenum id="p935" page="normal" smilref="Title.smil#p935" /><p attribs="{'xml:space': 'preserve'}" id="_16738" smilref="Title.smil#_16738"> 922</p><p attribs="{'xml:space': 'preserve'}" id="_16739" smilref="Title.smil#_16739"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16740" smilref="Title.smil#_16740"> EXERCISES on collision simulation</p><p attribs="{'xml:space': 'preserve'}" id="_16741" smilref="Title.smil#_16741"> 6.1 Complete the implementation predictCollisions() and Particle as described in the text. There are three equations governing the elastic collision between a pair of hard discs: (a) conservation of linear momentum, (b) conservation of kinetic energy, and (c) upon collision, the normal force acts perpendicular to the surface at the collision point (assuming no friction or spin). See the booksite for more details. 6.2 Develop a version of CollisionSystem, Particle, and Event that handles multi- particle collisions. Such collisions are important when simulating the break in a game of billiards. (This is a difficult exercise!) 6.3 Develop a version of CollisionSystem, Particle, and Event that works in three dimensions. 6.4 Explore the idea of improving the performance of simulate() in CollisionSystem by dividing the region into rectangular cells and adding a new event type so that you only need to predict collisions with particles in one of nine adjacent cells in any time quantum. This approach reduces the number of predictions to calculate at the cost of monitoring the movement of particles from cell to cell. 6.5 Introduce the concept of entropy to CollisionSystem and use it to confirm classical results. 6.6 Brownian motion. In 1827, the botanist Robert Brown observed the motion of wildflower pollen grains immersed in water using a microscope. He observed that the pollen grains were in a random motion, following what would become known as Brownian motion. This phenomenon was discussed, but no convincing explanation was provided until Einstein provided a mathematical one in 1905. Einstein&#8217;s explana- tion: the motion of the pollen grain particles was caused by millions of tiny molecules colliding with the larger particles. Run a simulation that illustrates this phenomenon. 6.7 Temperature. Add a method temperature() to Particle that returns the product of its mass and the square of the magitude of its velocity divided by dkB where d =2 is the dimension and kB =1.3806503 &#215; 10&#11002;23 is Boltzmann&#8217;s constant. The temperature of the system is the average value of these quantities. Then add a method temperature() to CollisionSystem and write a driver that plots the temperature periodically, to check that it is constant.</p><p attribs="{'xml:space': 'preserve'}" id="_16742" smilref="Title.smil#_16742" /><pagenum id="p936" page="normal" smilref="Title.smil#p936" /><p attribs="{'xml:space': 'preserve'}" id="_16743" smilref="Title.smil#_16743"> 923</p><p attribs="{'xml:space': 'preserve'}" id="_16744" smilref="Title.smil#_16744"> 6.8 Maxwell-Boltzmann. The distribution of velocity of particles in the hard disc model obeys the Maxwell-Boltzmann distribution (assuming that the system has thermalized and particles are sufficiently heavy that we can discount quantum-mechanical effects), which is known as the Rayleigh distribution in two dimensions. The distribution shape depends on temperature. Write a driver that computes a histogram of the particle velocities and test it for various temperatures. 6.9 Arbitrary shape. Molecules travel very quickly (faster than a speeding jet) but diffuse slowly because they collide with other molecules, thereby changing their direction. Extend the model to have a boundary shape where two vessels are connected by a pipe containing two different types of particles. Run a simulation and measure the fraction of particles of each type in each vessel as a function of time. 6.10 Rewind. After running a simulation, negate all velocities and then run the system backward. It should return to its original state! Measure roundoff error by measuring the difference between the final and original states of the system. 6.11 Pressure. Add a method pressure() to Particle that measures pressure by accumulating the number and magnitude of collisions against walls. The pressure of the system is the sucm of these quantities. Then add a method pressure() to CollisionSystem and write a client that validates the equation pv = nRT. 6.12 Index priority queue implementation. Develop a version of CollisionSystem that uses an index priority queue to guarantee that the size of the priority queue is at most linear in the number of particles (instead of quadratic or worse). 6.13 Priority queue performance. Instrument the priority queue and test Pressure at various temperatures to identify the computational bottleneck. If warranted, try switching to a different priority-queue implementation for better performance at high temperatures.</p><p attribs="{'xml:space': 'preserve'}" id="_16745" smilref="Title.smil#_16745" /><pagenum id="p937" page="normal" smilref="Title.smil#p937" /><p attribs="{'xml:space': 'preserve'}" id="_16746" smilref="Title.smil#_16746"> 924</p><p attribs="{'xml:space': 'preserve'}" id="_16747" smilref="Title.smil#_16747"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16748" smilref="Title.smil#_16748"> EXERCISES on B-Trees</p><p attribs="{'xml:space': 'preserve'}" id="_16749" smilref="Title.smil#_16749"> 6.14 Suppose that, in a three-level tree, we can afford to keep a links in internal mem- ory, between b and 2b links in pages representing internal nodes, and between c and 2c items in pages representing external nodes. What is the maximum number of items that we can hold in such a tree, as a function of a, b, and c? 6.15 Develop an implementation of Page that represents each B-tree node as a</p><p attribs="{'xml:space': 'preserve'}" id="_16750" smilref="Title.smil#_16750"> BinarySearchST object.</p><p attribs="{'xml:space': 'preserve'}" id="_16751" smilref="Title.smil#_16751"> 6.16 Extend BTreeSET to develop a BTreeST implementation that associates keys with values and supports our full ordered symbol table API that includes min(), max(),</p><p attribs="{'xml:space': 'preserve'}" id="_16752" smilref="Title.smil#_16752"> floor(), ceiling(), deleteMin(), deleteMax(), select(), rank(), and the two-</p><p attribs="{'xml:space': 'preserve'}" id="_16753" smilref="Title.smil#_16753"> argument versions of size() and get(). 6.17 Write a program that uses StdDraw to visualize B-trees as they grow, as in the text. 6.18 Estimate the average number of probes per search in a B-tree for S random searches, in a typical cache system, where the T most-recently-accessed pages are kept in memory (and therefore add 0 to the probe count). Assume that S is much larger than T. 6.19 Web search. Develop an implementation of Page that represents B-tree nodes as text files on web pages, for the purposes of indexing (building a concordance for) the web. Use a file of search terms. Take web pages to be indexed from standard input. To keep control, take a command-line parameter m, and set an upper limit of 10m internal nodes (check with your system administrator before running for large m). Use an m- digit number to name your internal nodes. For example, when m is 4, your nodes names might be BTreeNode0000, BTreeNode0001, BTreeNode0002, and so forth. Keep pairs of strings on pages. Add a close() operation to the API, to sort and write. To test your implementation, ook for yourself and your friends on your university&#8217;s website. 6.20 B* trees. Consider the sibling split (or B*-tree) heuristic for B-trees: When it comes time to split a node because it contains M entries, we combine the node with its sibling. If the sibling has k entries with k &lt; M&#11002;1, we reallocate the items giving the sibling and the full node each about (M+k)/2 entries. Otherwise, we create a new node and give each of the three nodes about 2M/3 entries. Also, we allow the root to grow to hold about 4M/3 items, splitting it and creating a new root node with two entries when it reaches that bound. State bounds on the number of probes used for a search or an insertion in a B*-tree of order M with N items. Compare your bounds with the</p><p attribs="{'xml:space': 'preserve'}" id="_16754" smilref="Title.smil#_16754" /><pagenum id="p938" page="normal" smilref="Title.smil#p938" /><p attribs="{'xml:space': 'preserve'}" id="_16755" smilref="Title.smil#_16755"> 925</p><p attribs="{'xml:space': 'preserve'}" id="_16756" smilref="Title.smil#_16756"> corresponding bounds for B-trees (see Proposition B). Develop an insert implementation for B*-trees. 6.21 Write a program to compute the average number of external pages for a B-tree of order M built from N random insertions into an initially empty tree. Run your program for reasonable values of M and N. 6.22 If your system supports virtual memory, design and conduct experiments to compare the performance of B-trees with that of binary search, for random searches in a huge symbol table. 6.23 For your internal-memory implementation of Page in EXERCISE 6.15, run experiments to determine the value of M that leads to the fastest search times for a B-tree implementation supporting random search operations in a huge symbol table. Restrict your attention to values of M that are multiples of 100. 6.24 Run experiments to compare search times for internal B-trees (using the value of M determined in the previous exercise), linear probing hashing, and red-black trees for random search operations in a huge symbol table.</p><p attribs="{'xml:space': 'preserve'}" id="_16757" smilref="Title.smil#_16757" /><pagenum id="p939" page="normal" smilref="Title.smil#p939" /><p attribs="{'xml:space': 'preserve'}" id="_16758" smilref="Title.smil#_16758"> 926</p><p attribs="{'xml:space': 'preserve'}" id="_16759" smilref="Title.smil#_16759"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16760" smilref="Title.smil#_16760"> EXERCISES on suffix arrays</p><p attribs="{'xml:space': 'preserve'}" id="_16761" smilref="Title.smil#_16761"> 6.25 Give, in the style of the figure on page 882, the suf&#64257; xes, sorted suf&#64257; xes, index() and lcp() tables for the following strings:</p><p attribs="{'xml:space': 'preserve'}" id="_16762" smilref="Title.smil#_16762"> a. abacadaba b. mississippi c. abcdefghij d. aaaaaaaaaa</p><p attribs="{'xml:space': 'preserve'}" id="_16763" smilref="Title.smil#_16763"> 6.26 Identify the problem with the following code fragment to compute all the suffixes for suffix sort:</p><p attribs="{'xml:space': 'preserve'}" id="_16764" smilref="Title.smil#_16764"> suffix = ""; for (int i = s.length() - 1; i &gt;= 0; i--) { suffix = s.charAt(i) + suffix; suffixes[i] = suffix; }</p><p attribs="{'xml:space': 'preserve'}" id="_16765" smilref="Title.smil#_16765"> Answer : It uses quadratic time and quadratic space.</p><p attribs="{'xml:space': 'preserve'}" id="_16766" smilref="Title.smil#_16766"> 6.27 Some applications require a sort of cyclic rotations of a text, which all contain all the characters of the text. For i from 0 to N &#11002; 1, the i th cyclic rotation of a text of length N is the last N &#11002; i characters followed by the first i characters. Identify the problem with the following code fragment to compute all the cyclic rotations:</p><p attribs="{'xml:space': 'preserve'}" id="_16767" smilref="Title.smil#_16767"> int N = s.length(); for (int i = 0; i &lt; N; i++) rotation[i] = s.substring(i, N) + s.substring(0, i);</p><p attribs="{'xml:space': 'preserve'}" id="_16768" smilref="Title.smil#_16768"> Answer : It uses quadratic time and quadratic space.</p><p attribs="{'xml:space': 'preserve'}" id="_16769" smilref="Title.smil#_16769"> 6.28 Design a linear-time algorithm to compute all the cyclic rotations of a text string.</p><p attribs="{'xml:space': 'preserve'}" id="_16770" smilref="Title.smil#_16770"> Answer :</p><p attribs="{'xml:space': 'preserve'}" id="_16771" smilref="Title.smil#_16771"> String t = s + s; int N = s.length(); for (int i = 0; i &lt; N; i++) rotation[i] = r.substring(i, i + N);</p><p attribs="{'xml:space': 'preserve'}" id="_16772" smilref="Title.smil#_16772" /><pagenum id="p940" page="normal" smilref="Title.smil#p940" /><p attribs="{'xml:space': 'preserve'}" id="_16773" smilref="Title.smil#_16773"> 927</p><p attribs="{'xml:space': 'preserve'}" id="_16774" smilref="Title.smil#_16774"> 6.29 Under the assumptions described in Section 1.4. give the memory usage of a SuffixArray object with a string of length N . 6.30 Longest common substring. Write a SuffixArray client LCS that take two fi le- names as command-line arguments, reads the two text fi les, and finds the longest substring that appears in both in linear time. (In 1970, D. Knuth conjectured that this task was impossible.) Hint : Create a suffix array for s#t where s and t are the two text strings and # is a character that does not appear in either. 6.31 Burrows-Wheeler transform. The Burrows-Wheeler transform (BWT) is a transformation that is used in data compression algorithms, including bzip2 and in high- throughput sequencing in genomics. Write a SuffixArray client that computes the BWT in linear time, as follows: Given a string of length N (terminated by a special end- of-&#64257; le character $ that is smaller than any other character), consider the N-by-N matrix in which each row contains a different cyclic rotation of the original text string. Sort the rows lexicographically. The Burrows-Wheeler transform is the rightmost column in the sorted matrix. For example, the BWT of mississippi$ is ipssm$pissii. The Burrows-Wheeler inverse transform (BWI) inverts the BWT. For example, the BWI of ipssm$pissii is mississippi$. Also write a client that, given the BWT of a text string, computes the BWI in linear time. 6.32 Circular string linearization. Write a SuffixArray client that, given a string, finds the cyclic rotation that is the smallest lexicographically in linear time. This problem arises in chemical databases for circular molecules, where each molecule is represented as a circular string, and a canonical representation (smallest cyclic rotation) is used to support search with any rotation as key. (See Exercise 6.27 and Exercise 6.28.) 6.33 Longest k-repeated substring. Write a SuffixArray client that, given a string and an integer k, find the longest substring that is repeated k or more times. 6.34 Long repeated substrings. Write a SuffixArray client that, given a string and an integer L, finds all repeated substrings of length L or more. 6.35 k-gram frequency counts. Develop and implement an ADT for preprocessing a string to support efficiently answering queries of the form How many times does a given k-gram appear ? Each query should take time proportional to k log N in the worst case, where N is the length of the string.</p><p attribs="{'xml:space': 'preserve'}" id="_16775" smilref="Title.smil#_16775" /><pagenum id="p941" page="normal" smilref="Title.smil#p941" /><p attribs="{'xml:space': 'preserve'}" id="_16776" smilref="Title.smil#_16776"> 928</p><p attribs="{'xml:space': 'preserve'}" id="_16777" smilref="Title.smil#_16777"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16778" smilref="Title.smil#_16778"> EXERCISES on max flow</p><p attribs="{'xml:space': 'preserve'}" id="_16779" smilref="Title.smil#_16779"> 6.36 If capacities are positive integers less than M, what is the maximum possible flow value for any st-network with V vertices and E edges? Give two answers, depending on whether or not parallel edges are allowed. 6.37 Give an algorithm to solve the max&#64258; ow problem for the case that the network forms a tree if the sink is removed. 6.38 True or false. If true provide a short proof, if false give a counterexample:</p><p attribs="{'xml:space': 'preserve'}" id="_16780" smilref="Title.smil#_16780"> a. In any max fl ow, there is no directed cycle on which every edge carries positive flow b. There exists a max flow for which there is no directed cycle on which every edge carries positive flow c. If all edge capacities are distinct, the max flow is unique d. If all edge capacities are increased by an additive constant, the min cut remains unchanged e. If all edge capacities are multiplied by a positive integer, the min cut remains unchanged 6.39 Complete the proof of Proposition G: Show that each time an edge is a critical edge, the length of the augmenting path through it must increase by 2. 6.40 Find a large network online that you can use as a vehicle for testing flow algorithms on realistic data. Possibilities include transportation networks (road, rail, or air), communications networks (telephone or computer connections), or distribution networks. If capacities are not available, devise a reasonable model to add them. Write a program that uses the interface to implement flow networks from your data. If war- ranted, develop additional private methods to clean up the data. 6.41 Write a random-network generator for sparse networks with integer capacities between 0 and 220. Use a separate class for capacities and develop two implementa- tions: one that generates uniformly distributed capacities and another that generates capacities according to a Gaussian distribution. Implement client programs that generate random networks for both weight distributions with a well-chosen set of values of V and E so that you can use them to run empirical tests on graphs drawn from various distributions of edge weights.</p><p attribs="{'xml:space': 'preserve'}" id="_16781" smilref="Title.smil#_16781" /><pagenum id="p942" page="normal" smilref="Title.smil#p942" /><p attribs="{'xml:space': 'preserve'}" id="_16782" smilref="Title.smil#_16782"> 929</p><p attribs="{'xml:space': 'preserve'}" id="_16783" smilref="Title.smil#_16783"> 6.42 Write a program that generates V random points in the plane, then builds aflow network with edges (in both directions) connecting all pairs of points within a given distance d of each other, setting each edge&#8217;s capacity using one of the random models described in the previous exercise. 6.43 Basic reductions. Develop FordFulkerson clients for finding a max&#64258; ow in each of the following types of flow networks:</p><p attribs="{'xml:space': 'preserve'}" id="_16784" smilref="Title.smil#_16784"> </p><p attribs="{'xml:space': 'preserve'}" id="_16785" smilref="Title.smil#_16785"> 6.44 Product distribution. Suppose that aflow represents products to be transferred by trucks between cities, with the flow on edge u-v representing the amount to be taken from city u to city v in a given day. Write a client that prints out daily orders for truck- ers, telling them how much and where to pick up and how much and where to drop off. Assume that there are no limits on the supply of truckers and that nothing leaves a given distribution point until everything has arrived. 6.45 Job placement. Develop a FordFulkerson client that solves the job-placement problem, using the reduction in Proposition J. Use a symbol table to convert symbolic names into integers for use in the flow network. 6.46 Construct a family of bipartite matching problems where the average length of the augmenting paths used by any augmenting-path algorithm to solve the corresponding max&#64258; ow problem is proportional to E. 6.47 st-connectivity. Develop a FordFulkerson client that, given an undirected graph G and vertices s and t, finds the minimum number of edges in G whose removal will disconnect t from s. 6.48 Disjoint paths. Develop a FordFulkerson client that, given an undirected graph G and vertices s and t, finds the maximum number of edge-disjoint paths from s to t.</p><p attribs="{'xml:space': 'preserve'}" id="_16786" smilref="Title.smil#_16786" /><pagenum id="p943" page="normal" smilref="Title.smil#p943" /><p attribs="{'xml:space': 'preserve'}" id="_16787" smilref="Title.smil#_16787"> 930</p><p attribs="{'xml:space': 'preserve'}" id="_16788" smilref="Title.smil#_16788"> CONTEXT</p><p attribs="{'xml:space': 'preserve'}" id="_16789" smilref="Title.smil#_16789"> EXERCISES on reductions and intractability</p><p attribs="{'xml:space': 'preserve'}" id="_16790" smilref="Title.smil#_16790"> 6.49 Find a nontrivial factor of 37703491. 6.50 Prove that the shortest-paths problem reduces to linear programming. 6.51 Could there be an algorithm that solves an NP-complete problem in an average time of N log N, if P &#8800; NP? Explain your answer. 6.52 Suppose that someone discovers an algorithm that is guranteed to solve the boolean satisfiability problem in time proportional to 1.1N Does this imply that we can solve other NP-complete problems in time proportional to 1.1N? 6.53 What would be the significance of a program that could solve the integer linear programming problem in time proportional to 1.1N ? 6.54 Give a poly-time reduction from vertex cover to 0-1 integer linear inequality satis&#64257; ability. 6.55 Prove that the problem of finding a Hamiltonian path in a directed graph is NP- complete, using the NP-completeness of the Hamiltonian-path problem for undirected graphs. 6.56 Suppose that two problems are known to be NP-complete. Does this imply that there is a poly-time reduction from one to the other? 6.57 Suppose that X is NP-complete, X poly-time reduces to Y, and Y poly-time reduces to X. Is Y necessarily NP-complete?</p><p attribs="{'xml:space': 'preserve'}" id="_16791" smilref="Title.smil#_16791"> Answer : No, since Y may not be in NP. 6.58 Suppose that we have an algorithm to solve the decision version of boolean satis&#64257; - ability, which indicates that there exists an assignment of truth values to the variables that satisfies the boolean expression. Show how to find the assignment. 6.59 Suppose that we have an algorithm to solve the decision version of the vertex cover problem, which indicates that there exists a vertex cover of a given size. Show how to solve the optimization version of finding the vertex cover of minimum cardinality. 6.60 Explain why the optimization version of the vertex cover problem is not necessarily a search problem.</p><p attribs="{'xml:space': 'preserve'}" id="_16792" smilref="Title.smil#_16792" /><pagenum id="p944" page="normal" smilref="Title.smil#p944" /><p attribs="{'xml:space': 'preserve'}" id="_16793" smilref="Title.smil#_16793"> 931</p><p attribs="{'xml:space': 'preserve'}" id="_16794" smilref="Title.smil#_16794"> Answer : There does not appear to be an efficient way to certify that a purported solution is the best possible (even though we could use binary search on the search version of the problem to find the best solution).</p><p attribs="{'xml:space': 'preserve'}" id="_16795" smilref="Title.smil#_16795"> 6.61 Suppose that X and Y are two search problems an that X poly-time reduces to Y. Which of the following can we infer?</p><p attribs="{'xml:space': 'preserve'}" id="_16796" smilref="Title.smil#_16796"> a. If Y is NP-complete then so is X.</p><p attribs="{'xml:space': 'preserve'}" id="_16797" smilref="Title.smil#_16797"> b. If X is NP-complete then so is Y.</p><p attribs="{'xml:space': 'preserve'}" id="_16798" smilref="Title.smil#_16798"> c. If X is in P, then Y is in P.</p><p attribs="{'xml:space': 'preserve'}" id="_16799" smilref="Title.smil#_16799"> d. If Y is in P, then X is in P. 6.62 Suppose that P &#8800; NP. Which of the following can we infer?</p><p attribs="{'xml:space': 'preserve'}" id="_16800" smilref="Title.smil#_16800"> e. If X is NP-complete, then X cannot be solved in polynomial time. f. If X is in NP, then X cannot be solved in polynomial time. g. If X is in NP but not NP-complete, then X can be solved in polynomial time. h. If X is in P, then X is not NP-complete.</p><p attribs="{'xml:space': 'preserve'}" id="_16801" smilref="Title.smil#_16801" /></level3></level1><level1 id="ch7"><section epub:type="chapter" id="section_00006"><header id="header_00006"><pagenum epub:type="pagebreak" id="p945" page="normal" smilref="Title.smil#p945" /><h1 id="ch7-start" smilref="Title.smil#ch7-start" xml:space="preserve">Index</h1></header></section><pagenum id="p945" page="normal" smilref="Title.smil#p945" /><p attribs="{'xml:space': 'preserve'}" id="_16802" smilref="Title.smil#_16802"> Index</p><p attribs="{'xml:space': 'preserve'}" id="_16803" smilref="Title.smil#_16803" /><pagenum id="p947" page="normal" smilref="Title.smil#p947" /><p attribs="{'xml:space': 'preserve'}" id="_16804" smilref="Title.smil#_16804"> 934</p><p attribs="{'xml:space': 'preserve'}" id="_16805" smilref="Title.smil#_16805"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16806" smilref="Title.smil#_16806"> cost model 182 divide-and-conquer 272 doubling ratio 192&#8211;193 doubling test 176&#8211;177 input models 197 log-log plot 176 mathematical models 178 memory usage 200&#8211;204 multiple parameters 196 observations 173&#8211;175 order-of-growth 179 order-of-growth classi&#64257; cations 186&#8211;188 order-of-growth hypothesis 180 problem size 173 randomized algorithm 198 scientific method 172 tilde approximation 178 worst-case guarantee 197 Antisymmetric relation 247 APIs</p><p attribs="{'xml:space': 'preserve'}" id="_16807" smilref="Title.smil#_16807"> Accumulator 93 Alphabet 698</p><p attribs="{'xml:space': 'preserve'}" id="_16808" smilref="Title.smil#_16808"> Bag 121</p><p attribs="{'xml:space': 'preserve'}" id="_16809" smilref="Title.smil#_16809"> BinaryStdIn 812 BinaryStdOut 812 Buffer 170</p><p attribs="{'xml:space': 'preserve'}" id="_16810" smilref="Title.smil#_16810"> CC 543</p><p attribs="{'xml:space': 'preserve'}" id="_16811" smilref="Title.smil#_16811"> Counter 65 Date 79 Degrees 596 Deque 167 Digraph 568 DirectedCycle 576</p><p attribs="{'xml:space': 'preserve'}" id="_16812" smilref="Title.smil#_16812"> DirectedDFS 570 DirectedEdge 641</p><p attribs="{'xml:space': 'preserve'}" id="_16813" smilref="Title.smil#_16813"> Draw 83</p><p attribs="{'xml:space': 'preserve'}" id="_16814" smilref="Title.smil#_16814"> Edge 608</p><p attribs="{'xml:space': 'preserve'}" id="_16815" smilref="Title.smil#_16815"> EdgeWeightedDigraph 641 EdgeWeightedGraph 608 FixedCapacityStack 135</p><p attribs="{'xml:space': 'preserve'}" id="_16816" smilref="Title.smil#_16816"> FixedCapacityStackOf- Strings 133 FlowEdge 890 FlowNetwork 890 GeneralizedQueue 169 Graph 522 GraphProperties 559</p><p attribs="{'xml:space': 'preserve'}" id="_16817" smilref="Title.smil#_16817"> In 41, 83</p><p attribs="{'xml:space': 'preserve'}" id="_16818" smilref="Title.smil#_16818"> IndexMaxPQ 320 IndexMinPQ 320 Interval1D 77 Interval2D 77 java.lang.Double 34 java.lang.Integer 34 java.lang.Math 28 java.lang.String 80 java.util.Arrays 29</p><p attribs="{'xml:space': 'preserve'}" id="_16819" smilref="Title.smil#_16819"> KMP 769 List 511</p><p attribs="{'xml:space': 'preserve'}" id="_16820" smilref="Title.smil#_16820"> MathSET 509 Matrix 60 MaxPQ 309 MinPQ 309</p><p attribs="{'xml:space': 'preserve'}" id="_16821" smilref="Title.smil#_16821"> MST 613 Out 41, 83 Page 870</p><p attribs="{'xml:space': 'preserve'}" id="_16822" smilref="Title.smil#_16822"> Particle 860 Paths 535 Point2D 77 Queue 121 RandomBag 167 RandomQueue 168 Rational 117</p><p attribs="{'xml:space': 'preserve'}" id="_16823" smilref="Title.smil#_16823"> SCC 586</p><p attribs="{'xml:space': 'preserve'}" id="_16824" smilref="Title.smil#_16824"> Search 528</p><p attribs="{'xml:space': 'preserve'}" id="_16825" smilref="Title.smil#_16825"> SET 489 SP 644, 677 ST 363, 366, 860, 870, 879</p><p attribs="{'xml:space': 'preserve'}" id="_16826" smilref="Title.smil#_16826"> Stack 121 StaticSETofInts 99 StdDraw 43 StdIn 39 StdOut 37</p><p attribs="{'xml:space': 'preserve'}" id="_16827" smilref="Title.smil#_16827"> StdRandom 30 StdStats 30 Stopwatch 175 StringSET 754 StringST 730 SuffixArray 879 SymbolDigraph 581 SymbolGraph 548 Topological 578 Transaction 79 TransitiveClosure 592</p><p attribs="{'xml:space': 'preserve'}" id="_16828" smilref="Title.smil#_16828"> UF 219</p><p attribs="{'xml:space': 'preserve'}" id="_16829" smilref="Title.smil#_16829"> VisualAccumulator 95</p><p attribs="{'xml:space': 'preserve'}" id="_16830" smilref="Title.smil#_16830"> Application programming inter- face. See also APIs client 28 contract 33 data type definition 65 implementation 28 library of static methods 28 Arbitrage detection 679&#8211;681 Arithmetic expression evaluation 128&#8211;131 Array 18&#8211;21 2-dimensional 19 aliasing 19 as object 72 bounds checking 19 memory usage of 202 of objects 72 ragged 19 Array resizing. See Resizing array</p><p attribs="{'xml:space': 'preserve'}" id="_16831" smilref="Title.smil#_16831"> Arrays.sort() 29, 306</p><p attribs="{'xml:space': 'preserve'}" id="_16832" smilref="Title.smil#_16832"> Articulation point 562 ASCII encoding 696, 815 Assertion 107 assert statement 107 Assignment statement 14 Associative array 363 Augmenting path 891 Autoboxing 122, 214 AVL tree 452</p><p attribs="{'xml:space': 'preserve'}" id="_16833" smilref="Title.smil#_16833" /><p attribs="{'xml:space': 'preserve'}" id="_16834" smilref="Title.smil#_16834"> 936</p><p attribs="{'xml:space': 'preserve'}" id="_16835" smilref="Title.smil#_16835"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16836" smilref="Title.smil#_16836"> Center of a graph 559 Certi&#64257; cation binary heap 330 binary search 392 binary search tree 419 minimum spanning tree 634 NP complexity class 912 red-black BST 452 search problem 912 shortest paths 651 sorting 246, 265 char primitive data type 12, 696 Chazelle, B. 629, 853 Chebyshev&#8217;s inequality 303 Church-Turing thesis 910 Circular linked list 165 Circular queue 169 Circular rotation 114 Classpath 66 Client 28 Closest pair 210 Collections 120 bag 124&#8211;125 catenable 171 deque 167 generalized queue 169 priority queue 308&#8211;334 pushdown stack 127 queue 126 random bag 167 random queue 168 ring buffer 169 stack 127 steque 167 symbol table 360&#8211;513 trie 730&#8211;757. Collision resolution 458 Command-line argument 36 Command-line interface command-line argument 36 compile a Java program 10 piping 40</p><p attribs="{'xml:space': 'preserve'}" id="_16837" smilref="Title.smil#_16837"> redirection 40 run a Java program 10 standard input 39 standard output 37&#8211;38 terminal window 36 Comma-separated-value 493 Comparable interface compareTo() method 246&#8211;247 Date 247 natural order 337 sorting 244, 246&#8211;247</p><p attribs="{'xml:space': 'preserve'}" id="_16838" smilref="Title.smil#_16838"> String 353</p><p attribs="{'xml:space': 'preserve'}" id="_16839" smilref="Title.smil#_16839"> symbol table 368&#8211;369</p><p attribs="{'xml:space': 'preserve'}" id="_16840" smilref="Title.smil#_16840"> Transaction 266</p><p attribs="{'xml:space': 'preserve'}" id="_16841" smilref="Title.smil#_16841"> Comparator interface 338&#8211;340 compare() method 338&#8211;339 priority queue 340</p><p attribs="{'xml:space': 'preserve'}" id="_16842" smilref="Title.smil#_16842"> Transaction 339 compare() method.</p><p attribs="{'xml:space': 'preserve'}" id="_16843" smilref="Title.smil#_16843"> See Comparator interface</p><p attribs="{'xml:space': 'preserve'}" id="_16844" smilref="Title.smil#_16844"> compareTo() method.</p><p attribs="{'xml:space': 'preserve'}" id="_16845" smilref="Title.smil#_16845"> See Comparable interface Compile a program 10 Compiler 492, 498 Complete binary tree 314 Complete graph 681 Compression. See Data compression Computability 910 Computational complexity Cook-Levin theorem 918 intractability 910&#8211;921 NP-complete 917&#8211;918 NP 912 P 914 P= NP question 916 poly-time reduction 916&#8211;917 sorting 279&#8211;282 Computational geometry 76 Concatenation of strings 34 Concordance 510 Concrete type 122, 134</p><p attribs="{'xml:space': 'preserve'}" id="_16846" smilref="Title.smil#_16846"> Conditional statement 15 Connected components computing 543&#8211;546 defined 519 union-&#64257; nd 217 Connected graph 519 Connectivity articulation point 562 biconnectivity 562 bridge 562 components 543&#8211;546 dynamic 216 edge-connected graph 562 strong connectivity 584&#8211;591 undirected graph 530 union-&#64257; nd 216&#8211;241 Constant running time 186 Constructor 65, 84&#8211;85 continue statement 15 Contract 33 Cook-Levin theorem 918 Cook, S. 759, 918 Cost model 182. array accesses 182, 220, 369 binary search 184 B-tree 866 compares 369 equality tests 369 searching 369 sorting 246 symbol table 369 3-sum 182 union-&#64257; nd 220 Coupon collector problem 215 Covariant arrays 158 CPM. See Critical-path method C language 104 C++ language 104 Critical edge 633, 690, 900 Critical path 663 Critical-path method 663, 664 Crossing edge 606</p><p attribs="{'xml:space': 'preserve'}" id="_16847" smilref="Title.smil#_16847" /><p attribs="{'xml:space': 'preserve'}" id="_16848" smilref="Title.smil#_16848"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16849" smilref="Title.smil#_16849"> 945</p><p attribs="{'xml:space': 'preserve'}" id="_16850" smilref="Title.smil#_16850"> ordered symbol table 378 sorting 357 Parallel edge 518, 566, 612, 640 Parallel job scheduling 663&#8211;667 Parallel precedence-constrained scheduling 663, 904 Parameterized type. See Generics Parent-link representation breadth-&#64257; rst search tree 539 depth-&#64257; rst search tree 535 minimum spanning tree 620 shortest-paths tree 640 union-&#64257; nd 225 Parsing an arithmetic expression 128 a regular expression 800&#8211;804 Particle data type 860 Partitioning algorithm 290 2-way 288 3-way (Bentley-McIlroy) 306 3-way (Dijkstra) 298 median-of-3 296, 305 median-of-5 305 selection 346&#8211;347 Partitioning item 290 Pass by reference 71 Pass by value 24, 71 Path. See Longest paths; See also Shortest paths augmenting 891 Hamiltonian 913, 920 in a digraph 567 in a graph 519 length of 519, 567 simple 519, 567 Path compression 231 Pattern matching. See Regular expression Perfect hash function 480 Performance. See Propositions Permutation Kendall-tau distance 356</p><p attribs="{'xml:space': 'preserve'}" id="_16851" smilref="Title.smil#_16851"> random 168 ranking 345 sorting 354 Phone book 492 Picture data type 814 Piping 40 Point data type 77 Pointer 111. See also Reference safe 112 Pointer sort 338 Poisson approximation 466 Poisson distribution 466 Polar angle 356 Polar coordinate 77 Polar sort 356 Poly-time reduction 916 Pop operation 127 Post&#64257; x notation 162 Postorder traversal of a digraph 578 reverse 578 Power law 178 Pratt, V. R. 759 Precedence-constrainted scheduling 574&#8211;575 Precedence order arithmetic expressions 13 regular expressions 789 Pre&#64257; x-free code 826&#8211;827 compression 829 expansion 828 Huffman 833 optimal 833 reading and writing 834&#8211;835 trie representation 827 Preorder traversal of a digraph 578 of a trie 834 Prime number 23, 774, 785 Primitive data type 11&#8211;12 memory usage of 200 reason for 51</p><p attribs="{'xml:space': 'preserve'}" id="_16852" smilref="Title.smil#_16852"> wrapper type 102 Primitive type versus reference type 110 Prim, R. 628 Prim&#8217;s algorithm 350, 616&#8211;623 eager 620&#8211;623 lazy 616&#8211;619 Priority queue 308&#8211;335 binary heap 313&#8211;322 change priority 321 delete 321 Dijkstra&#8217;s algorithm 652 Fibonacci heap 628 Huffman compression 830 index priority queue 320&#8211;321 linked-list 312 multiway heap 319 ordered array 312 Prim's algorithm 616 reductions 345 remove the minimum 321 soft heap 629 stability 356 unordered array 310 private access modifier 84 Probabilistic algorithm. See Ran- domized algorithm Probe 471 Problem size 173 Programs</p><p attribs="{'xml:space': 'preserve'}" id="_16853" smilref="Title.smil#_16853"> Accumulator 93 AcyclicLP 661</p><p attribs="{'xml:space': 'preserve'}" id="_16854" smilref="Title.smil#_16854"> AcyclicSP 660</p><p attribs="{'xml:space': 'preserve'}" id="_16855" smilref="Title.smil#_16855"> Arbitrage 680 Average 39</p><p attribs="{'xml:space': 'preserve'}" id="_16856" smilref="Title.smil#_16856"> Bag 155</p><p attribs="{'xml:space': 'preserve'}" id="_16857" smilref="Title.smil#_16857"> BellmanFordSP 674 BinaryDump 814 BinarySearch 47 BinarySearchST 379, 381, 382 BlackFilter 491 BoyerMoore 772</p><p attribs="{'xml:space': 'preserve'}" id="_16858" smilref="Title.smil#_16858" /><p attribs="{'xml:space': 'preserve'}" id="_16859" smilref="Title.smil#_16859"> 946</p><p attribs="{'xml:space': 'preserve'}" id="_16860" smilref="Title.smil#_16860"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16861" smilref="Title.smil#_16861"> BreadthFirstPaths 540</p><p attribs="{'xml:space': 'preserve'}" id="_16862" smilref="Title.smil#_16862"> BST 398, 399, 407, 409, 411</p><p attribs="{'xml:space': 'preserve'}" id="_16863" smilref="Title.smil#_16863"> BTreeSET 872</p><p attribs="{'xml:space': 'preserve'}" id="_16864" smilref="Title.smil#_16864"> Cat 82 CC 544</p><p attribs="{'xml:space': 'preserve'}" id="_16865" smilref="Title.smil#_16865"> CollisionSystem 863&#8211;864 Count 699 Counter 89</p><p attribs="{'xml:space': 'preserve'}" id="_16866" smilref="Title.smil#_16866"> CPM 665</p><p attribs="{'xml:space': 'preserve'}" id="_16867" smilref="Title.smil#_16867"> Cycle 547</p><p attribs="{'xml:space': 'preserve'}" id="_16868" smilref="Title.smil#_16868"> Date 91, 103, 247</p><p attribs="{'xml:space': 'preserve'}" id="_16869" smilref="Title.smil#_16869"> DeDup 490 DegreesOfSeparation 555 DepthFirstOrder 580 DepthFirstPaths 536 DepthFirstSearch 531 Digraph 569 DijkstraAllPairsSP 656 DijkstraSP 655 DirectedCycle 577 DirectedDFS 571 DirectedEdge 642 DoublingTest 177</p><p attribs="{'xml:space': 'preserve'}" id="_16870" smilref="Title.smil#_16870"> Edge 610</p><p attribs="{'xml:space': 'preserve'}" id="_16871" smilref="Title.smil#_16871"> EdgeWeightedDigraph 643 EdgeWeightedGraph 611 Evaluate 129 Event 861 Example 245 FileIndex 501 FixedCapacityStack 135 FixedCapacityStackOf- Strings 133 Flips 70 FlipsMax 71 FlowEdge 896 FordFulkerson 898 FrequencyCounter 372</p><p attribs="{'xml:space': 'preserve'}" id="_16872" smilref="Title.smil#_16872"> Genome 819&#8211;820</p><p attribs="{'xml:space': 'preserve'}" id="_16873" smilref="Title.smil#_16873"> Graph 526</p><p attribs="{'xml:space': 'preserve'}" id="_16874" smilref="Title.smil#_16874"> GREP 804 Heap 324</p><p attribs="{'xml:space': 'preserve'}" id="_16875" smilref="Title.smil#_16875"> HexDump 814 Huffman 836 Insertion 251</p><p attribs="{'xml:space': 'preserve'}" id="_16876" smilref="Title.smil#_16876"> KMP 768</p><p attribs="{'xml:space': 'preserve'}" id="_16877" smilref="Title.smil#_16877"> KosarajuSCC 587 KruskalMST 627</p><p attribs="{'xml:space': 'preserve'}" id="_16878" smilref="Title.smil#_16878"> KWIC 881</p><p attribs="{'xml:space': 'preserve'}" id="_16879" smilref="Title.smil#_16879"> LazyPrimMST 619 LinearProbingHashST 470 LookupCSV 495 LookupIndex 499</p><p attribs="{'xml:space': 'preserve'}" id="_16880" smilref="Title.smil#_16880"> LRS 880 LSD 707 LZW 842, 844</p><p attribs="{'xml:space': 'preserve'}" id="_16881" smilref="Title.smil#_16881"> MaxPQ 318</p><p attribs="{'xml:space': 'preserve'}" id="_16882" smilref="Title.smil#_16882"> Merge 271, 273</p><p attribs="{'xml:space': 'preserve'}" id="_16883" smilref="Title.smil#_16883"> MergeBU 278</p><p attribs="{'xml:space': 'preserve'}" id="_16884" smilref="Title.smil#_16884"> MSD 712</p><p attribs="{'xml:space': 'preserve'}" id="_16885" smilref="Title.smil#_16885"> Multiway 322</p><p attribs="{'xml:space': 'preserve'}" id="_16886" smilref="Title.smil#_16886"> NFA 799, 802</p><p attribs="{'xml:space': 'preserve'}" id="_16887" smilref="Title.smil#_16887"> PictureDump 814 PrimMST 622 Queue 151</p><p attribs="{'xml:space': 'preserve'}" id="_16888" smilref="Title.smil#_16888"> Quick 289, 291</p><p attribs="{'xml:space': 'preserve'}" id="_16889" smilref="Title.smil#_16889"> Quick3string 720 Quick3way 299 RabinKarp 777 RedBlackBST 439 ResizingArrayQueue 140 ResizingArrayStack 141 Reverse 127</p><p attribs="{'xml:space': 'preserve'}" id="_16890" smilref="Title.smil#_16890"> RLE 824</p><p attribs="{'xml:space': 'preserve'}" id="_16891" smilref="Title.smil#_16891"> Rolls 72 Selection 249 SeparateChainingHashST 465 SequentialSearchST 375</p><p attribs="{'xml:space': 'preserve'}" id="_16892" smilref="Title.smil#_16892"> SET 489</p><p attribs="{'xml:space': 'preserve'}" id="_16893" smilref="Title.smil#_16893"> Shell 259 SortCompare 256 SparseVector 503 Stack 149 StaticSETofInts 99</p><p attribs="{'xml:space': 'preserve'}" id="_16894" smilref="Title.smil#_16894"> Stats 125 Stopwatch 175 SuffixArray 883 SymbolGraph 552 ThreeSum 173 ThreeSumFast 190</p><p attribs="{'xml:space': 'preserve'}" id="_16895" smilref="Title.smil#_16895"> TopM 311</p><p attribs="{'xml:space': 'preserve'}" id="_16896" smilref="Title.smil#_16896"> Topological 581 Transaction 340 TransitiveClosure 593</p><p attribs="{'xml:space': 'preserve'}" id="_16897" smilref="Title.smil#_16897"> TrieST 737&#8211;741 TST 747</p><p attribs="{'xml:space': 'preserve'}" id="_16898" smilref="Title.smil#_16898"> TwoColor 547 TwoSumFast 189</p><p attribs="{'xml:space': 'preserve'}" id="_16899" smilref="Title.smil#_16899"> UF 221</p><p attribs="{'xml:space': 'preserve'}" id="_16900" smilref="Title.smil#_16900"> VisualAccumulator 95 WeightedQuickUnionUF 228 WhiteFilter 491 Whitelist 99</p><p attribs="{'xml:space': 'preserve'}" id="_16901" smilref="Title.smil#_16901"> Properties 180 3-sum 180 Boyer-Moore algorithm 773 insertion sort 255 quicksort 343 Rabin-Karp algorithm 778 red-black BST 445 selection sort 255 separate-chaining 467 shellsort 262 versus proposition 183 Propositions 182 2-3 search tree 429 3-sum 182 3-way quicksort 301 3-way string quicksort 723 arbitrage 681 B-tree 871 Bellman-Ford 671, 673 binary heap 319 binary search 383 BST 403&#8211;404, 412 breadth-&#64257; rst search 541</p><p attribs="{'xml:space': 'preserve'}" id="_16902" smilref="Title.smil#_16902" /><pagenum id="p962" page="normal" smilref="Title.smil#p962" /><p attribs="{'xml:space': 'preserve'}" id="_16903" smilref="Title.smil#_16903"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16904" smilref="Title.smil#_16904"> 949</p><p attribs="{'xml:space': 'preserve'}" id="_16905" smilref="Title.smil#_16905"> Scienti&#64257; c method 172 Scope of a variable 14, 87 Search hit 376 Searching 360&#8211;513. See also Symbol table Search miss 376 Search problem 912 Sedgewick, R. 298 Selection 345 binary search tree 406 ordered symbol table 367 quickselect 346&#8211;347 suffix array 879 Selection client 249 Selection sort 248&#8211;249 Self-loop 518, 566, 612, 640 Separate-chaining 464&#8211;468 Sequential allocation 156 Sequential search 374&#8211;377 Set data type 489&#8211;491 Shannon entropy 300&#8211;301 Shellsort 258&#8211;262 Shortest ancestral path 598 Shortest augmenting path 897 Shortest path 638 Shortest paths problem 638&#8211;693 all-pairs 656 arbitrage detection 679&#8211;681 Bellman-Ford 668&#8211;678 bitonic 689 bottleneck 690 certification 651 critical edge 690 Dijkstra&#8217;s algorithm 652&#8211;657 edge relaxation 646&#8211;647 edge-weighted DAG 658&#8211;667 generic algorithm 651 ineligible edge 646 in Euclidean graphs 656 monotonic 689 negative cycle 669 Negative cycle detection 670</p><p attribs="{'xml:space': 'preserve'}" id="_16906" smilref="Title.smil#_16906"> negative weights 668&#8211;681 optimality conditions 650 parent-link 640 reduction 904&#8211;905 shortest-paths tree 640 single-source 639, 654 source-sink 656 undirected graph 654 vertex relaxation 648 Shortest-processing-time-&#64257; rst rule 349, 355 short primitive data type 13 Shuf&#64258; ing a linked list 286 an array 32 quicksort 292 Side effect 22, 108 Signature instance method 86 static method 22 Simple digraph 567 Simple graph 518 Simplex algorithm 909 Single-source problems connectivity 556 directed paths 573 longest paths in DAG 661 paths 534 reachability 570 shortest directed paths 573 shortest paths in undirected graphs 654, 904 shortest paths 538, 639 Social network 517 Soft heap 629 Software cache 391, 451, 462 Sollin, M. 628 Sorting 242&#8211;359. See also String sorting 3-way quicksort 298&#8211;301 binary search tree 412 certification 246, 265</p><p attribs="{'xml:space': 'preserve'}" id="_16907" smilref="Title.smil#_16907"> Comparable 246&#8211;247</p><p attribs="{'xml:space': 'preserve'}" id="_16908" smilref="Title.smil#_16908"> compare-based 279 complexity of 279&#8211;282 cost model 246 entropy-optimal 296&#8211;301 extra memory 246 heapsort 323&#8211;327 indirect 286 in-place 246 insertion sort 250&#8211;252 inversion 252 lower bound 279&#8211;282, 306 mergesort 270&#8211;288 partially-sorted array 252 pointer 338 primitive types 343 quicksort 288&#8211;307 reduction 903&#8211;904 reductions 344&#8211;347 selection sort 248&#8211;250 shellsort 258&#8211;262 stability 341 suffix array 875&#8211;885 system sort 343 Source-sink shortest paths 656 Spanning forest 520 Spanning tree 520, 604 Sparse graph 520 Sparse matrix 510 Sparse vector 502&#8211;505 Speci&#64257; cation problem 97 SPT. See Shortest paths tree; See also Shortest-process- ing-time-&#64257; rst rule st-cut 892 st-&#64258; ow 888 st-&#64258; ow network 888 Stability 341, 355 insertion sort 341 key-indexed counting 705 LSD string sort 706 mergesort 341</p><p attribs="{'xml:space': 'preserve'}" id="_16909" smilref="Title.smil#_16909" /><pagenum id="p963" page="normal" smilref="Title.smil#p963" /><p attribs="{'xml:space': 'preserve'}" id="_16910" smilref="Title.smil#_16910"> 950</p><p attribs="{'xml:space': 'preserve'}" id="_16911" smilref="Title.smil#_16911"> INDEX</p><p attribs="{'xml:space': 'preserve'}" id="_16912" smilref="Title.smil#_16912"> priority queue 356 Stack data type 127 analysis of 198, 199 array implementation 132 fi xed-capacity 132&#8211;133 generic 134 iteration 138&#8211;140 linked-list 147&#8211;149 resizing array 136 Standard deviation 30 Standard drawing 36, 42&#8211;45 Standard input 36, 39 Standard libraries 30 Draw 82&#8211;83 In 41, 82&#8211;83 Out 41, 82&#8211;83</p><p attribs="{'xml:space': 'preserve'}" id="_16913" smilref="Title.smil#_16913"> StdDraw 43 StdIn 39 StdOut 37 StdRandom 30 StdStats 30 Stopwatch 174&#8211;175</p><p attribs="{'xml:space': 'preserve'}" id="_16914" smilref="Title.smil#_16914"> Standard output 36, 37&#8211;38 Static method 22&#8211;25 argument 22 defining a 22 invoking a 22 overloaded 24 pass by value 24 recursive 25 return statement 24 return value 22 side effect 22, 24 signature 22 Static variable 113 Statistics chi-square 483 median 345 minimum and maximum 30 order 345 sample mean 30, 125 sample standard deviation 30</p><p attribs="{'xml:space': 'preserve'}" id="_16915" smilref="Title.smil#_16915"> sample variance 30, 125 StdDraw library 43 StdIn library 39 StdOut library 37 StdRandom library 30 StdStats library 30 Steque data type 167, 212 Stirling's approximation 185 Stopwatch data type 174&#8211;175 String data type 34, 80&#8211;81 API 80 characters 696 charAt() method 696 concatenation 34, 697 conversion 102 immutability 696 indexing 696 indexOf() method 779 length 696 length() method 696 literal 34 memory usage of 202 + operator 80, 697 substring extraction 696 substring() method 696 String processing 80&#8211;81, 694&#8211;851 data compression 810&#8211;851 regular expression 788 sorting 702&#8211;729 substring search 758&#8211;785 suffix array 875&#8211;885 tries 730&#8211;757 String search. See Substring search; See also Trie String sorting 702&#8211;729 3-way quicksort 719&#8211;723 key-indexed counting 703 LSD string sort 706&#8211;709 MSD string sort 710&#8211;718 Strong component 584 Strong connectivity 584&#8211;591</p><p attribs="{'xml:space': 'preserve'}" id="_16916" smilref="Title.smil#_16916"> Strongly connected component. See Strong component Strongly connected relation 584 Strongly typed language 14 Subclass 101 Subgraph 519 Sublinear running time 716, 779 Substring extraction memory usage of 202&#8211;204 substring() method 696 Substring search 758&#8211;785 Boyer-Moore 770&#8211;773 brute-force 760&#8211;761 indexOf() method 779 Knuth-Morris-Pratt 762&#8211;769 Rabin-Karp 774&#8211;778 Subtyping 100 Suf&#64257; x array 875&#8211;885 Suf&#64257; x array data type 879 Suf&#64257; x-free code 847 Superclass 101 Symbol digraph 581 Symbol graph 548&#8211;555 Symbol table 360&#8211;513 2-3 search tree 424&#8211;431 API 363, 366 associative array 363 balanced search tree 424&#8211;457 binary search 378&#8211;384 binary search tree 396&#8211;423 B-tree 866&#8211;874 cost model 369 defined 362 duplicate key policy 363 floor and ceiling 367 hash table 458&#8211;485 insertion 362 key equality 365 lazy deletion 364 linear-probing 469&#8211;474 minimum and maximum 367 null value 364</p><p attribs="{'xml:space': 'preserve'}" id="_16917" smilref="Title.smil#_16917" /><p attribs="{'xml:space': 'preserve'}" id="_16918" smilref="Title.smil#_16918"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_16919" smilref="Title.smil#_16919" /></level1><level1 id="ch8"><section epub:type="chapter" id="section_00007"><header id="header_00007"><pagenum epub:type="pagebreak" id="p967" page="normal" smilref="Title.smil#p967" /><h1 id="ch8-start" smilref="Title.smil#ch8-start" xml:space="preserve">Algorithms</h1></header></section><pagenum id="p967" page="normal" smilref="Title.smil#p967" /><p attribs="{'xml:space': 'preserve'}" id="_16920" smilref="Title.smil#_16920"> A L G O R I T H M S</p><p attribs="{'xml:space': 'preserve'}" id="_16921" smilref="Title.smil#_16921"> Fundamentals</p><p attribs="{'xml:space': 'preserve'}" id="_16922" smilref="Title.smil#_16922"> Graphs</p><p attribs="{'xml:space': 'preserve'}" id="_16923" smilref="Title.smil#_16923"> 1.1 Pushdown stack (resizing array)</p><p attribs="{'xml:space': 'preserve'}" id="_16924" smilref="Title.smil#_16924"> 4.1 Depth-&#64257; rst search</p><p attribs="{'xml:space': 'preserve'}" id="_16925" smilref="Title.smil#_16925"> 1.2 Pushdown stack (linked-list)</p><p attribs="{'xml:space': 'preserve'}" id="_16926" smilref="Title.smil#_16926"> 4.2 Breadth-&#64257; rst search</p><p attribs="{'xml:space': 'preserve'}" id="_16927" smilref="Title.smil#_16927"> 1.3 FIFO queue</p><p attribs="{'xml:space': 'preserve'}" id="_16928" smilref="Title.smil#_16928"> 1.4 Bag</p><p attribs="{'xml:space': 'preserve'}" id="_16929" smilref="Title.smil#_16929"> 1.5 Union-&#64257; nd</p><p attribs="{'xml:space': 'preserve'}" id="_16930" smilref="Title.smil#_16930"> Sorting</p><p attribs="{'xml:space': 'preserve'}" id="_16931" smilref="Title.smil#_16931"> 2.1 Selection sort</p><p attribs="{'xml:space': 'preserve'}" id="_16932" smilref="Title.smil#_16932"> 2.2 Insertion sort</p><p attribs="{'xml:space': 'preserve'}" id="_16933" smilref="Title.smil#_16933"> 2.3 Shellsort</p><p attribs="{'xml:space': 'preserve'}" id="_16934" smilref="Title.smil#_16934"> 2.4 Top-down mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_16935" smilref="Title.smil#_16935"> Bottom-up mergesort</p><p attribs="{'xml:space': 'preserve'}" id="_16936" smilref="Title.smil#_16936"> 2.5 Quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_16937" smilref="Title.smil#_16937"> Quicksort with 3-way partitioning</p><p attribs="{'xml:space': 'preserve'}" id="_16938" smilref="Title.smil#_16938"> 2.6 Heap priority queue</p><p attribs="{'xml:space': 'preserve'}" id="_16939" smilref="Title.smil#_16939"> 2.7 Heapsort</p><p attribs="{'xml:space': 'preserve'}" id="_16940" smilref="Title.smil#_16940"> Symbol Tables</p><p attribs="{'xml:space': 'preserve'}" id="_16941" smilref="Title.smil#_16941"> 3.1 Sequential search</p><p attribs="{'xml:space': 'preserve'}" id="_16942" smilref="Title.smil#_16942"> 3.2 Binary search</p><p attribs="{'xml:space': 'preserve'}" id="_16943" smilref="Title.smil#_16943"> 3.3 Binary tree search</p><p attribs="{'xml:space': 'preserve'}" id="_16944" smilref="Title.smil#_16944"> 3.4 Red-black BST search</p><p attribs="{'xml:space': 'preserve'}" id="_16945" smilref="Title.smil#_16945"> 4.3 Connected components</p><p attribs="{'xml:space': 'preserve'}" id="_16946" smilref="Title.smil#_16946"> 4.4 Reachability</p><p attribs="{'xml:space': 'preserve'}" id="_16947" smilref="Title.smil#_16947"> 4.5 Topological sort</p><p attribs="{'xml:space': 'preserve'}" id="_16948" smilref="Title.smil#_16948"> 4.6 Strong components (Kosaraju-Sharir)</p><p attribs="{'xml:space': 'preserve'}" id="_16949" smilref="Title.smil#_16949"> 4.7 Minimum spanning tree (Prim)</p><p attribs="{'xml:space': 'preserve'}" id="_16950" smilref="Title.smil#_16950"> 4.8 Minimum spanning tree (Kruskal)</p><p attribs="{'xml:space': 'preserve'}" id="_16951" smilref="Title.smil#_16951"> 4.9 Shortest paths (Dijkstra)</p><p attribs="{'xml:space': 'preserve'}" id="_16952" smilref="Title.smil#_16952"> 4.10 Shortest paths in DAGs</p><p attribs="{'xml:space': 'preserve'}" id="_16953" smilref="Title.smil#_16953"> 4.11 Shortest paths (Bellman-Ford)</p><p attribs="{'xml:space': 'preserve'}" id="_16954" smilref="Title.smil#_16954"> Strings</p><p attribs="{'xml:space': 'preserve'}" id="_16955" smilref="Title.smil#_16955"> 5.1 LSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_16956" smilref="Title.smil#_16956"> 5.2 MSD string sort</p><p attribs="{'xml:space': 'preserve'}" id="_16957" smilref="Title.smil#_16957"> 5.3 Three-way string quicksort</p><p attribs="{'xml:space': 'preserve'}" id="_16958" smilref="Title.smil#_16958"> 5.4 Trie symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_16959" smilref="Title.smil#_16959"> 5.5 TST symbol table</p><p attribs="{'xml:space': 'preserve'}" id="_16960" smilref="Title.smil#_16960"> 5.6 Substring search (Knuth-Morris-Pratt)</p><p attribs="{'xml:space': 'preserve'}" id="_16961" smilref="Title.smil#_16961"> 5.7 Substring search (Boyer-Moore)</p><p attribs="{'xml:space': 'preserve'}" id="_16962" smilref="Title.smil#_16962"> 5.8 Substring search (Rabin-Karp)</p><p attribs="{'xml:space': 'preserve'}" id="_16963" smilref="Title.smil#_16963"> 5.9 Regular expression pattern matching</p><p attribs="{'xml:space': 'preserve'}" id="_16964" smilref="Title.smil#_16964"> 3.5 Hashing with separate chaining</p><p attribs="{'xml:space': 'preserve'}" id="_16965" smilref="Title.smil#_16965"> 5.10 Huffman compression/expansion</p><p attribs="{'xml:space': 'preserve'}" id="_16966" smilref="Title.smil#_16966"> 3.6 Hashing with linear probing</p><p attribs="{'xml:space': 'preserve'}" id="_16967" smilref="Title.smil#_16967"> 5.11 LZW compression/expansion</p><p attribs="{'xml:space': 'preserve'}" id="_16968" smilref="Title.smil#_16968"> 954</p><p attribs="{'xml:space': 'preserve'}" id="_16969" smilref="Title.smil#_16969" /></level1><level1 id="ch9"><section epub:type="chapter" id="section_00008"><header id="header_00008"><pagenum epub:type="pagebreak" id="p968" page="normal" smilref="Title.smil#p968" /><h1 id="ch9-start" smilref="Title.smil#ch9-start" xml:space="preserve">Clients</h1></header></section><pagenum id="p968" page="normal" smilref="Title.smil#p968" /><p attribs="{'xml:space': 'preserve'}" id="_16970" smilref="Title.smil#_16970"> C L I E N T S</p><p attribs="{'xml:space': 'preserve'}" id="_16971" smilref="Title.smil#_16971"> Fundamentals</p><p attribs="{'xml:space': 'preserve'}" id="_16972" smilref="Title.smil#_16972"> Whitelisting</p><p attribs="{'xml:space': 'preserve'}" id="_16973" smilref="Title.smil#_16973"> Expression evaluation</p><p attribs="{'xml:space': 'preserve'}" id="_16974" smilref="Title.smil#_16974"> Connectivity</p><p attribs="{'xml:space': 'preserve'}" id="_16975" smilref="Title.smil#_16975"> Strings</p><p attribs="{'xml:space': 'preserve'}" id="_16976" smilref="Title.smil#_16976"> Regular expression pattern matching</p><p attribs="{'xml:space': 'preserve'}" id="_16977" smilref="Title.smil#_16977"> Huffman compression</p><p attribs="{'xml:space': 'preserve'}" id="_16978" smilref="Title.smil#_16978"> Lempel-Ziv-Welch compression</p><p attribs="{'xml:space': 'preserve'}" id="_16979" smilref="Title.smil#_16979"> Sorting</p><p attribs="{'xml:space': 'preserve'}" id="_16980" smilref="Title.smil#_16980"> Context</p><p attribs="{'xml:space': 'preserve'}" id="_16981" smilref="Title.smil#_16981"> Comparing two algorithms</p><p attribs="{'xml:space': 'preserve'}" id="_16982" smilref="Title.smil#_16982"> Colliding particle simulation</p><p attribs="{'xml:space': 'preserve'}" id="_16983" smilref="Title.smil#_16983"> Top M</p><p attribs="{'xml:space': 'preserve'}" id="_16984" smilref="Title.smil#_16984"> Multiway merge</p><p attribs="{'xml:space': 'preserve'}" id="_16985" smilref="Title.smil#_16985"> Symbol Tables</p><p attribs="{'xml:space': 'preserve'}" id="_16986" smilref="Title.smil#_16986"> Dedup</p><p attribs="{'xml:space': 'preserve'}" id="_16987" smilref="Title.smil#_16987"> Frequency counter</p><p attribs="{'xml:space': 'preserve'}" id="_16988" smilref="Title.smil#_16988"> Dictionary lookup</p><p attribs="{'xml:space': 'preserve'}" id="_16989" smilref="Title.smil#_16989"> Index lookup</p><p attribs="{'xml:space': 'preserve'}" id="_16990" smilref="Title.smil#_16990"> File indexing</p><p attribs="{'xml:space': 'preserve'}" id="_16991" smilref="Title.smil#_16991"> Sparse vector with dot product</p><p attribs="{'xml:space': 'preserve'}" id="_16992" smilref="Title.smil#_16992"> Graphs</p><p attribs="{'xml:space': 'preserve'}" id="_16993" smilref="Title.smil#_16993"> Symbol graph data type</p><p attribs="{'xml:space': 'preserve'}" id="_16994" smilref="Title.smil#_16994"> Degrees of separation</p><p attribs="{'xml:space': 'preserve'}" id="_16995" smilref="Title.smil#_16995"> Critical-path method</p><p attribs="{'xml:space': 'preserve'}" id="_16996" smilref="Title.smil#_16996"> Arbitrage</p><p attribs="{'xml:space': 'preserve'}" id="_16997" smilref="Title.smil#_16997"> B-tree set</p><p attribs="{'xml:space': 'preserve'}" id="_16998" smilref="Title.smil#_16998"> Suf&#64257; x array (elementary)</p><p attribs="{'xml:space': 'preserve'}" id="_16999" smilref="Title.smil#_16999"> Longest repeated substring</p><p attribs="{'xml:space': 'preserve'}" id="_17000" smilref="Title.smil#_17000"> Keyword in context</p><p attribs="{'xml:space': 'preserve'}" id="_17001" smilref="Title.smil#_17001"> Max&#64258; ow (Ford-Fulkerson)</p><p attribs="{'xml:space': 'preserve'}" id="_17002" smilref="Title.smil#_17002"> 955</p><p attribs="{'xml:space': 'preserve'}" id="_17003" smilref="Title.smil#_17003" /><pagenum id="p969" page="normal" smilref="Title.smil#p969" /><p attribs="{'xml:space': 'preserve'}" id="_17004" smilref="Title.smil#_17004"> This page intentionally left blank</p><p attribs="{'xml:space': 'preserve'}" id="_17005" smilref="Title.smil#_17005" /><pagenum id="p970" page="normal" smilref="Title.smil#p970" /><p attribs="{'xml:space': 'preserve'}" id="_17006" smilref="Title.smil#_17006"> Introduct ion to Programming in Java: An Interdisc iplinar y Approach</p><p attribs="{'xml:space': 'preserve'}" id="_17007" smilref="Title.smil#_17007"> Robert Sedgewick/Kevin Wayne</p><p attribs="{'xml:space': 'preserve'}" id="_17008" smilref="Title.smil#_17008"> &#169;2008 (cid:116) 736 pp (cid:116) ISBN: 0-321-49805-4</p><p attribs="{'xml:space': 'preserve'}" id="_17009" smilref="Title.smil#_17009"> Introduction to Programming in Java takes an interdisciplinary approach to teaching programming with the Java programming language. Features</p><p attribs="{'xml:space': 'preserve'}" id="_17010" smilref="Title.smil#_17010"> (cid:53)(cid:73)(cid:74)(cid:84)(cid:3)(cid:67)(cid:80)(cid:80)(cid:76)(cid:3)(cid:85)(cid:73)(cid:80)(cid:83)(cid:80)(cid:86)(cid:72)(cid:73)(cid:77)(cid:90)(cid:3)(cid:68)(cid:80)(cid:87)(cid:70)(cid:83)(cid:84)(cid:3)(cid:85)(cid:73)(cid:70)(cid:3)(cid:109)(cid:3)(cid:70)(cid:77)(cid:69)(cid:3)(cid:66)(cid:79)(cid:69)(cid:3)(cid:74)(cid:84)(cid:3)(cid:74)(cid:69)(cid:70)(cid:66)(cid:77)(cid:3) for introductory programming courses. It can also be used for courses that integrate programming with mathematics, science, or engineering. Students learn basic computer science concepts in the context of interesting applications in science, engineering, and commercial computing, leveraging familiar science and math while preparing students (cid:85)(cid:80)(cid:3)(cid:86)(cid:84)(cid:70)(cid:3)(cid:68)(cid:80)(cid:78)</p><p attribs="{'xml:space': 'preserve'}" id="_17011" smilref="Title.smil#_17011"> Instructors, contact your Pearson representative to receive an exam copy, or email PearsonEd.CS@Pearson.com.</p><p attribs="{'xml:space': 'preserve'}" id="_17012" smilref="Title.smil#_17012" /><pagenum id="p971" page="normal" smilref="Title.smil#p971" /><p attribs="{'xml:space': 'preserve'}" id="_17013" smilref="Title.smil#_17013"> THIS PRODUCT</p><p attribs="{'xml:space': 'preserve'}" id="_17014" smilref="Title.smil#_17014"> informit.com / register</p><p attribs="{'xml:space': 'preserve'}" id="_17015" smilref="Title.smil#_17015"> Register the Addison-Wesley, Exam Cram, Prentice Hall, Que, and Sams products you own to unlock great bene&#64257; ts.</p><p attribs="{'xml:space': 'preserve'}" id="_17016" smilref="Title.smil#_17016"> To begin the registration process, simply go to inform it .com / reg ister to sign in or create an account. You will then be prompted to enter the 10 or 13 -digit ISBN that appears on the back cover of your product.</p><p attribs="{'xml:space': 'preserve'}" id="_17017" smilref="Title.smil#_17017"> Registering your products can unlock the following benefits : &#8226; Access to supplemental content, including bonus chapters, source code, or project fi les. &#8226; A coupon to be used on your next  purchase.</p><p attribs="{'xml:space': 'preserve'}" id="_17018" smilref="Title.smil#_17018"> Registration benefits vary by product. Bene&#64257; ts will be listed on your Account page under Registered Products.</p><p attribs="{'xml:space': 'preserve'}" id="_17019" smilref="Title.smil#_17019"> About InformIT &#8212; THE TRUSTED TECHNOLOGY LEARN ING SOURCE INFORMIT IS HOME TO THE LEADING TECHNOLOGY PUBLISHING IMPRINTS</p><p attribs="{'xml:space': 'preserve'}" id="_17020" smilref="Title.smil#_17020"> Addison -Wesley Professional, Cisco Press, Exam Cram, IBM Press, Prentice Hall Professional, Que, and Sams. Here you will gain access to quality and trusted content and resources from the authors, creators, innovators, and leaders of technology. Whether you&#8217;re looking for a book on a new technology, a helpful ar ticle, timely newslet ters, or access to the Safari Books Online digital library, InformIT has a solution for you.</p><p attribs="{'xml:space': 'preserve'}" id="_17021" smilref="Title.smil#_17021"> inform IT.com</p><p attribs="{'xml:space': 'preserve'}" id="_17022" smilref="Title.smil#_17022"> THE TRUSTED TECHNOLOGY LEARN ING SOURCE</p><p attribs="{'xml:space': 'preserve'}" id="_17023" smilref="Title.smil#_17023"> Addison -Wesley | Cisco Press | Exam Cram IBM P ress | Que | P rent ice Ha l l | Sams</p><p attribs="{'xml:space': 'preserve'}" id="_17024" smilref="Title.smil#_17024"> SAFAR I BOOKS ONL INE</p><p attribs="{'xml:space': 'preserve'}" id="_17025" smilref="Title.smil#_17025" /><pagenum id="p972" page="normal" smilref="Title.smil#p972" /><p attribs="{'xml:space': 'preserve'}" id="_17026" smilref="Title.smil#_17026"> inform IT.com THE TRUSTED TECHNOLOGY LE ARN ING SOURCE</p><p attribs="{'xml:space': 'preserve'}" id="_17027" smilref="Title.smil#_17027"> In fo rm IT is a b rand o f Pea rson and the on l ine p resence fo r the wo r ld &#8217;s lead ing technology  pub l ishe rs . I t &#8217;s you r sou rce fo r re l iab le and qua l i f ied content and know ledge, p rov id ing access to the top b rands , au tho rs , and con t r ibu to rs f rom the tech commun i t y.</p><p attribs="{'xml:space': 'preserve'}" id="_17028" smilref="Title.smil#_17028"> LearnIT at Inform IT</p><p attribs="{'xml:space': 'preserve'}" id="_17029" smilref="Title.smil#_17029"> Look ing fo r a book , eBook , o r t ra in ing v ideo on a new technology  ? Seek ing t ime ly and re levant  in fo rma t ion and tu to r ia ls? Look ing fo r expe r t op in ions , adv ice, and t ips? In fo rm IT has the so lu t ion .</p><p attribs="{'xml:space': 'preserve'}" id="_17030" smilref="Title.smil#_17030"> &#8226;</p><p attribs="{'xml:space': 'preserve'}" id="_17031" smilref="Title.smil#_17031"> Lea rn about  new re leases and spec ia l p romo t ions by subscr ib ing to a w ide va r ie t y o f news le t te rs . V is i t in fo rm i t .com / news le t te rs.</p><p attribs="{'xml:space': 'preserve'}" id="_17032" smilref="Title.smil#_17032"> &#8226; Access FREE podcas ts f rom expe r ts a t in fo rm i t .com / podcas ts.</p><p attribs="{'xml:space': 'preserve'}" id="_17033" smilref="Title.smil#_17033"> &#8226; Read the la test  au tho r a r t ic les and samp le chapters  a t in fo rm i t .com / a r t ic les.</p><p attribs="{'xml:space': 'preserve'}" id="_17034" smilref="Title.smil#_17034"> &#8226;</p><p attribs="{'xml:space': 'preserve'}" id="_17035" smilref="Title.smil#_17035"> Access thousands o f books and v ideos in the Sa fa r i Books On l ine d ig i ta l l ib ra r y a t sa fa r i . in fo rm i t .com.</p><p attribs="{'xml:space': 'preserve'}" id="_17036" smilref="Title.smil#_17036"> &#8226; Ge t t ips f rom expe r t b logs a t in fo rm i t .com / b logs.</p><p attribs="{'xml:space': 'preserve'}" id="_17037" smilref="Title.smil#_17037"> V is i t in fo rm i t .com / lea rn to d iscove r a l l the ways you can access the ho t test  technology  content .</p><p attribs="{'xml:space': 'preserve'}" id="_17038" smilref="Title.smil#_17038"> Are You Par t of the IT Crowd?</p><p attribs="{'xml:space': 'preserve'}" id="_17039" smilref="Title.smil#_17039"> Connec t w i th Pea rson au tho rs and ed i to rs v ia RSS feeds , Facebook , Tw i t te r, YouTube, and mo re ! V is i t in fo rm i t .com / soc ia lconnec t .</p><p attribs="{'xml:space': 'preserve'}" id="_17040" smilref="Title.smil#_17040"> informIT.com TH E TRUST ED T ECHNO LOGY LE ARN ING SOURCE</p><p attribs="{'xml:space': 'preserve'}" id="_17041" smilref="Title.smil#_17041" /><pagenum id="p973" page="normal" smilref="Title.smil#p973" /><p attribs="{'xml:space': 'preserve'}" id="_17042" smilref="Title.smil#_17042"> Try Safari Books Online FREE</p><p attribs="{'xml:space': 'preserve'}" id="_17043" smilref="Title.smil#_17043"> Ge t on line access to 5 ,000 + Books and V ideos</p><p attribs="{'xml:space': 'preserve'}" id="_17044" smilref="Title.smil#_17044"> FREE TRIAL&#8212;GET STARTED TODAY! www.informit.com/safaritrial</p><p attribs="{'xml:space': 'preserve'}" id="_17045" smilref="Title.smil#_17045"> Find trusted answers, fast</p><p attribs="{'xml:space': 'preserve'}" id="_17046" smilref="Title.smil#_17046"> Only Safar i lets you search across thousands of best-selling books from the top technology publishers, including Addison-Wesley Professional , Cisco Press, O&#8217;Reilly, Prentice Hall , Que, and Sams.</p><p attribs="{'xml:space': 'preserve'}" id="_17047" smilref="Title.smil#_17047"> Master the latest tools and techniques</p><p attribs="{'xml:space': 'preserve'}" id="_17048" smilref="Title.smil#_17048"> In addition to gaining access to an incredible inventor y of technical books, Safar i&#8217;s ex tensive collection  of v ideo tutor ials lets you learn from the leading v ideo training exper ts.</p><p attribs="{'xml:space': 'preserve'}" id="_17049" smilref="Title.smil#_17049"> WAIT, THERE&#8217;S MORE!</p><p attribs="{'xml:space': 'preserve'}" id="_17050" smilref="Title.smil#_17050"> Keep your competitive edge</p><p attribs="{'xml:space': 'preserve'}" id="_17051" smilref="Title.smil#_17051"> W ith Rough Cuts, get access to the developing manuscript  and be among the first to learn the newest technologies.</p><p attribs="{'xml:space': 'preserve'}" id="_17052" smilref="Title.smil#_17052"> Stay current with emerging technologies</p><p attribs="{'xml:space': 'preserve'}" id="_17053" smilref="Title.smil#_17053"> Shor t Cuts and Quick Reference Sheets are shor t, concise, focused content created to get you up-to-speed quickly on new and cutting-edge technologies.</p><p attribs="{'xml:space': 'preserve'}" id="_17054" smilref="Title.smil#_17054" /></level1></bodymatter></book></dtbook>