<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/css" href="daisy.css" media="screen" ?><?xml-stylesheet type="text/xsl" href="daisyTransform.xsl" media="screen" ?><!DOCTYPE dtbook SYSTEM "dtbook-2005-3.dtd"><dtbook xmlns="http://www.daisy.org/z3986/2005/dtbook/" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="index: http://www.index.com/" xml:lang="eng" lang="en" version="2005-3">
  <head>
    <meta name="dtb:uid" content="urn:isbn:9781118889497" />
    <meta name="dc:Identifier" content="urn:isbn:9781118889497" />
    <meta name="dc:Title" content="Machine Learning" />
    <meta name="dc:Creator" content="Jason Bell" />
    <meta name="dc:Description" content="Dig deep into the data with a hands-on guide to machine learningMachine Learning: Hands-On for Developers and Technical Professionals provides hands-on instruction and fully-coded working examples for the most common machine learning techniques used by developers and technical professionals. The book contains a breakdown of each ML variant, explaining how it works and how it is used within certain industries, allowing readers to incorporate the presented techniques into their own work as they follow along. A core tenant of machine learning is a strong focus on data preparation, and a full exploration of the various types of learning algorithms illustrates how the proper tools can help any developer extract information and insights from existing data. The book includes a full complement of Instructor's Materials to facilitate use in the classroom, making this resource useful for students and as a professional reference.At its core, machine learning is a mathematical, algorithm-based technology that forms the basis of historical data mining and modern big data science. Scientific analysis of big data requires a working knowledge of machine learning, which forms predictions based on known properties learned from training data. Machine Learning is an accessible, comprehensive guide for the non-mathematician, providing clear guidance that allows readers to:Learn the languages of machine learning including Hadoop, Mahout, and WekaUnderstand decision trees, Bayesian networks, and artificial neural networksImplement Association Rule, Real Time, and Batch learningDevelop a strategic plan for safe, effective, and efficient machine learningBy learning to construct a system that can learn from data, readers can increase their utility across industries. Machine learning sits at the core of deep dive data analysis and visualization, which is increasingly in demand as companies discover the goldmine hiding in their existing data. For the tech professional involved in data science, Machine Learning: Hands-On for Developers and Technical Professionals provides the skills and techniques required to dig deeper." />
    <meta name="dc:Publisher" content="Bookshare" />
    <meta name="dc:Format" content="ANSI/NISO Z39.86-2005" />
    <meta name="dc:Language" content="en" />
  </head>
  <book epub:type="frontmatter" id="book_73158409374">
    <frontmatter id="frontmatter_000001">
      <doctitle id="doctitle_000001">Machine Learning</doctitle>
      <docauthor id="docauthor_000001">Jason Bell</docauthor>
      <level1 id="bookshare_note">
  <h1 id="bks_notice_001" smilref="Machine_Learning00001.smil#bks_notice_001">NOTICE</h1>
  <p id="COPYRIGHT_LEGALESE_0">This accessible media has been made available to people with bona fide disabilities that affect reading.  This
      notice tells you about restrictions on the use of this accessible media, which could be a book, a periodical, or other content.</p>
  <level2 id="COPYRIGHT_LEGALESE_1">
    <h2 id="COPYRIGHT_LEGALESE_2">Copyright Notice</h2>
    <p id="COPYRIGHT_LEGALESE_3"><strong id="COPYRIGHT_LEGALESE_4">Title:</strong> <span class="text" id="COPYRIGHT_LEGALESE_5">Machine Learning</span></p>
    <p id="COPYRIGHT_LEGALESE_6"><strong id="COPYRIGHT_LEGALESE_7">Author:</strong> <span class="text" id="COPYRIGHT_LEGALESE_8">Jason Bell</span></p>
    <p id="COPYRIGHT_LEGALESE_9"><strong id="COPYRIGHT_LEGALESE_10">Copyright</strong> <span class="text" id="COPYRIGHT_LEGALESE_11">1991 by Wiley</span></p>
    <p id="COPYRIGHT_LEGALESE_12">This notice is not part of the copyrighted work, which begins below after the phrase "Begin Content".</p>
    <p id="COPYRIGHT_LEGALESE_13">Bookshare distributes this accessible media under restrictions set forth either in copyright law or in an
        agreement with the copyright owner.  If you are not a person with a print disability, or an agency serving
        people with print disabilities, you should not use this accessible media and should destroy this content.  You
        are not allowed to redistribute content derived from this accessible media to anybody else, with one exception:
        we allow hardcopy Braille books prepared from Accessible Media to be provided to other blind people.</p>
    <p id="COPYRIGHT_LEGALESE_14">Access to accessible media through Bookshare is a valuable right and privilege.  Protect this access for the
        print disabled community by complying with these restrictions!</p>
    <p id="COPYRIGHT_LEGALESE_15">You, your parents, or your school (or agency) signed a Bookshare agreement.  For the full text of the current
        version of the Member Agreements, please visit www.bookshare.org/Agreements.  This information in this accessible
        media file does not in any way change the terms of your Agreement with Bookshare.</p>
  </level2>
  <level2 id="COPYRIGHT_LEGALESE_16">
    <h2 id="COPYRIGHT_LEGALESE_17">Limitation of Liability; Indemnity by User</h2>
    <p id="COPYRIGHT_LEGALESE_18">Most authors and publishers do not have control over the content available through Bookshare.  By downloading and
        using this material, you agree that neither Bookshare nor the authors or original publishers of the materials
        shall be financially responsible for any loss or damage to you or any third parties caused by the failure or
        malfunction of the Bookshare Web Site (www.bookshare.org) or because of any inaccuracy or lack of completeness
        of any content that you download from the Web Site.</p>
    <p id="COPYRIGHT_LEGALESE_19">BOOKSHARE, AND THE AUTHORS, PUBLISHERS AND COPYRIGHT OWNERS OF THE MATERIALS, SHALL NOT IN ANY CASE BE LIABLE FOR
        DIRECT, INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES, WHETHER BASED ON CONTRACT, TORT OR ANY OTHER
        LEGAL THEORY, IN CONNECTION WITH OR ARISING OUT OF THE FURNISHING OF CONTENT, THE FUNCTIONING OF THE WEB SITE,
        OR ANY OTHER ASPECT OF YOUR USE OF THE WEB SITE AND THE CONTENTS PROVIDED HEREUNDER.</p>
    <p id="COPYRIGHT_LEGALESE_20">You agree to indemnify and hold Bookshare and Benetech, the Web Site provider, harmless from any liability,
        loss, cost, damage or expense, including reasonable attorney's fees, that result from any claim made by any
        author, publisher or copyright owner that you, or any one acquiring copies of copyrighted materials downloaded
        from the Web Site through you, is not print disabled or otherwise entitled to download and use the digital
        materials from the Bookshare Web Site.  This indemnity includes any claims arising out of any breach of your
        obligations under your Member Agreement, whether by reason of misuse, negligence or otherwise.</p>
  </level2>
  <level2 id="COPYRIGHT_LEGALESE_21">
    <h2 id="COPYRIGHT_LEGALESE_22">Permitted Use; Limited Waiver of Privacy Principles and Laws</h2>
    <p id="COPYRIGHT_LEGALESE_23">You are permitted under this restricted license to use this digital copy for your own personal use.  However,
        any further reproduction, distribution, or any commercial usage requires the express, prior consent of the
        copyright holder.</p>
    <p id="COPYRIGHT_LEGALESE_24">This material contains digital watermarks and fingerprints designed to identify this material as a Bookshare
        digital material that was specifically downloaded by you.  It is generally illegal to delete or modify these
        watermarks and fingerprints, as well as being in violation of the terms of your Member Agreement.  Your
        Member Agreement expressly authorizes us to include these security devices, solely for this use, as an express
        exception to current and future privacy laws relating to protection of personal information data.  Should any
        future privacy law or regulation preclude the use of this personal data for purposes of tracking the downloading
        and use of these materials and enforcing the limitations of relevant copyright law or the Member Agreement,
        your right to use these materials will terminate on the effective date of any such law or regulation.</p>
    <p id="COPYRIGHT_LEGALESE_25">This material was downloaded by Peter Saathoff-Harshfield and is digitally fingerprinted in the manner described above.</p>
  </level2>
  <level2 id="COPYRIGHT_LEGALESE_26">
    <h2 id="COPYRIGHT_LEGALESE_27">Book Quality</h2>
    <p id="COPYRIGHT_LEGALESE_28">Bookshare is interested in improving book quality over time, if you can help us by providing any book quality
        feedback, we'll work hard to make those changes and republish the books.</p>
    <list type="ul" id="COPYRIGHT_LEGALESE_29">
      <li id="COPYRIGHT_LEGALESE_30"><a href="http://www.bookshare.org/bookQualityFeedback?titleInstanceId=988248" external="true" id="COPYRIGHT_LEGALESE_31">Report book quality issue</a></li>
      <li id="COPYRIGHT_LEGALESE_32"><a href="http://www.bookshare.org/bookQualityFeedback" external="true" id="COPYRIGHT_LEGALESE_33">See all reported book quality issues</a></li>
    </list>
  </level2>
  <p id="COPYRIGHT_LEGALESE_34">BEGIN CONTENT</p>
</level1>
      <level1 id="cover">
        <section epub:type="cover" id="section_000001">
          <figure id="cover-coverstart">
            <p class="center" xml:space="preserve" id="p_000001"><img src="images/cover_fmt.jpg" alt="Cover Page" id="img_000001" /></p>
          </figure>
        </section>
      </level1>
      <level1 id="toc">
        <level2 class="toc" id="toc-toc">
          <h2 xml:space="preserve" id="h2_000001" smilref="Machine_Learning00001.smil#h2_000001">Table of Contents</h2>
          <list type="ol" id="list_000001">
            <li class="contentsH1" id="li_000001">
              <a href="#c01-c1" external="false" id="a_000001" smilref="Machine_Learning00001.smil#a_000001">Chapter 1: What Is Machine Learning?</a>
              <list type="ol" id="list_000002">
                <li class="contentsH2" id="li_000002">
                  <a href="#c01-c01_level1_1" external="false" id="a_000002" smilref="Machine_Learning00001.smil#a_000002">History of Machine Learning</a>
                </li>
                <li class="contentsH2" id="li_000003">
                  <a href="#c01-c01_level1_2" external="false" id="a_000003" smilref="Machine_Learning00001.smil#a_000003">Algorithm Types for Machine Learning</a>
                </li>
                <li class="contentsH2" id="li_000004">
                  <a href="#c01-c01_level1_3" external="false" id="a_000004" smilref="Machine_Learning00001.smil#a_000004">The Human Touch</a>
                </li>
                <li class="contentsH2" id="li_000005">
                  <a href="#c01-c01_level1_4" external="false" id="a_000005" smilref="Machine_Learning00001.smil#a_000005">Uses for Machine Learning</a>
                </li>
                <li class="contentsH2" id="li_000006">
                  <a href="#c01-c01_level1_5" external="false" id="a_000006" smilref="Machine_Learning00001.smil#a_000006">Languages for Machine Learning</a>
                </li>
                <li class="contentsH2" id="li_000007">
                  <a href="#c01-c01_level1_6" external="false" id="a_000007" smilref="Machine_Learning00001.smil#a_000007">Software Used in This Book</a>
                </li>
                <li class="contentsH2" id="li_000008">
                  <a href="#c01-c01_level1_7" external="false" id="a_000008" smilref="Machine_Learning00001.smil#a_000008">Data Repositories</a>
                </li>
                <li class="contentsH2" id="li_000009">
                  <a href="#c01-c01_level1_8" external="false" id="a_000009" smilref="Machine_Learning00001.smil#a_000009">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000010">
              <a href="#c02-c2" external="false" id="a_000010" smilref="Machine_Learning00001.smil#a_000010">Chapter 2: Planning for Machine Learning</a>
              <list type="ol" id="list_000003">
                <li class="contentsH2" id="li_000011">
                  <a href="#c02-c02_level1_1" external="false" id="a_000011" smilref="Machine_Learning00001.smil#a_000011">The Machine Learning Cycle</a>
                </li>
                <li class="contentsH2" id="li_000012">
                  <a href="#c02-c02_level1_2" external="false" id="a_000012" smilref="Machine_Learning00001.smil#a_000012">It All Starts with a Question</a>
                </li>
                <li class="contentsH2" id="li_000013">
                  <a href="#c02-c02_level1_3" external="false" id="a_000013" smilref="Machine_Learning00001.smil#a_000013">I Don't Have Data!</a>
                </li>
                <li class="contentsH2" id="li_000014">
                  <a href="#c02-c02_level1_4" external="false" id="a_000014" smilref="Machine_Learning00001.smil#a_000014">One Solution Fits All?</a>
                </li>
                <li class="contentsH2" id="li_000015">
                  <a href="#c02-c02_level1_5" external="false" id="a_000015" smilref="Machine_Learning00001.smil#a_000015">Defining the Process</a>
                </li>
                <li class="contentsH2" id="li_000016">
                  <a href="#c02-c02_level1_6" external="false" id="a_000016" smilref="Machine_Learning00001.smil#a_000016">Building a Data Team</a>
                </li>
                <li class="contentsH2" id="li_000017">
                  <a href="#c02-c02_level1_7" external="false" id="a_000017" smilref="Machine_Learning00001.smil#a_000017">Data Processing</a>
                </li>
                <li class="contentsH2" id="li_000018">
                  <a href="#c02-c02_level1_8" external="false" id="a_000018" smilref="Machine_Learning00001.smil#a_000018">Data Storage</a>
                </li>
                <li class="contentsH2" id="li_000019">
                  <a href="#c02-c02_level1_9" external="false" id="a_000019" smilref="Machine_Learning00001.smil#a_000019">Data Privacy</a>
                </li>
                <li class="contentsH2" id="li_000020">
                  <a href="#c02-c02_level1_10" external="false" id="a_000020" smilref="Machine_Learning00001.smil#a_000020">Data Quality and Cleaning</a>
                </li>
                <li class="contentsH2" id="li_000021">
                  <a href="#c02-c02_level1_11" external="false" id="a_000021" smilref="Machine_Learning00001.smil#a_000021">Thinking about Input Data</a>
                </li>
                <li class="contentsH2" id="li_000022">
                  <a href="#c02-c02_level1_12" external="false" id="a_000022" smilref="Machine_Learning00001.smil#a_000022">Thinking about Output Data</a>
                </li>
                <li class="contentsH2" id="li_000023">
                  <a href="#c02-c02_level1_13" external="false" id="a_000023" smilref="Machine_Learning00001.smil#a_000023">Don't Be Afraid to Experiment</a>
                </li>
                <li class="contentsH2" id="li_000024">
                  <a href="#c02-c02_level1_14" external="false" id="a_000024" smilref="Machine_Learning00001.smil#a_000024">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000025">
              <a href="#c03-c3" external="false" id="a_000025" smilref="Machine_Learning00001.smil#a_000025">Chapter 3: Working with Decision Trees</a>
              <list type="ol" id="list_000004">
                <li class="contentsH2" id="li_000026">
                  <a href="#c03-c03_level1_1" external="false" id="a_000026" smilref="Machine_Learning00001.smil#a_000026">The Basics of Decision Trees</a>
                </li>
                <li class="contentsH2" id="li_000027">
                  <a href="#c03-c03_level1_2" external="false" id="a_000027" smilref="Machine_Learning00001.smil#a_000027">Decision Trees in Weka</a>
                </li>
                <li class="contentsH2" id="li_000028">
                  <a href="#c03-c03_level1_3" external="false" id="a_000028" smilref="Machine_Learning00001.smil#a_000028">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000029">
              <a href="#c04-c4" external="false" id="a_000029" smilref="Machine_Learning00001.smil#a_000029">Chapter 4: Bayesian Networks</a>
              <list type="ol" id="list_000005">
                <li class="contentsH2" id="li_000030">
                  <a href="#c04-c04_level1_1" external="false" id="a_000030" smilref="Machine_Learning00001.smil#a_000030">Pilots to Paperclips</a>
                </li>
                <li class="contentsH2" id="li_000031">
                  <a href="#c04-c04_level1_2" external="false" id="a_000031" smilref="Machine_Learning00001.smil#a_000031">A Little Graph Theory</a>
                </li>
                <li class="contentsH2" id="li_000032">
                  <a href="#c04-c04_level1_3" external="false" id="a_000032" smilref="Machine_Learning00001.smil#a_000032">A Little Probability Theory</a>
                </li>
                <li class="contentsH2" id="li_000033">
                  <a href="#c04-c04_level1_4" external="false" id="a_000033" smilref="Machine_Learning00001.smil#a_000033">Bayes' Theorem</a>
                </li>
                <li class="contentsH2" id="li_000034">
                  <a href="#c04-c04_level1_5" external="false" id="a_000034" smilref="Machine_Learning00001.smil#a_000034">How Bayesian Networks Work</a>
                </li>
                <li class="contentsH2" id="li_000035">
                  <a href="#c04-c04_level1_6" external="false" id="a_000035" smilref="Machine_Learning00001.smil#a_000035">Node Counts</a>
                </li>
                <li class="contentsH2" id="li_000036">
                  <a href="#c04-c04_level1_7" external="false" id="a_000036" smilref="Machine_Learning00001.smil#a_000036">Using Domain Experts</a>
                </li>
                <li class="contentsH2" id="li_000037">
                  <a href="#c04-c04_level1_8" external="false" id="a_000037" smilref="Machine_Learning00001.smil#a_000037">A Bayesian Network Walkthrough</a>
                </li>
                <li class="contentsH2" id="li_000038">
                  <a href="#c04-c04_level1_9" external="false" id="a_000038" smilref="Machine_Learning00001.smil#a_000038">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000039">
              <a href="#c05-c5" external="false" id="a_000039" smilref="Machine_Learning00001.smil#a_000039">Chapter 5: Artificial Neural Networks</a>
              <list type="ol" id="list_000006">
                <li class="contentsH2" id="li_000040">
                  <a href="#c05-c05_level1_1" external="false" id="a_000040" smilref="Machine_Learning00001.smil#a_000040">What Is a Neural Network?</a>
                </li>
                <li class="contentsH2" id="li_000041">
                  <a href="#c05-c05_level1_2" external="false" id="a_000041" smilref="Machine_Learning00001.smil#a_000041">Artificial Neural Network Uses</a>
                </li>
                <li class="contentsH2" id="li_000042">
                  <a href="#c05-c05_level1_3" external="false" id="a_000042" smilref="Machine_Learning00001.smil#a_000042">Breaking Down the Artificial Neural Network</a>
                </li>
                <li class="contentsH2" id="li_000043">
                  <a href="#c05-c05_level1_4" external="false" id="a_000043" smilref="Machine_Learning00001.smil#a_000043">Data Preparation for Artificial Neural Networks</a>
                </li>
                <li class="contentsH2" id="li_000044">
                  <a href="#c05-c05_level1_5" external="false" id="a_000044" smilref="Machine_Learning00001.smil#a_000044">Artificial Neural Networks with Weka</a>
                </li>
                <li class="contentsH2" id="li_000045">
                  <a href="#c05-c05_level1_6" external="false" id="a_000045" smilref="Machine_Learning00001.smil#a_000045">Implementing a Neural Network in Java</a>
                </li>
                <li class="contentsH2" id="li_000046">
                  <a href="#c05-c05_level1_7" external="false" id="a_000046" smilref="Machine_Learning00001.smil#a_000046">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000047">
              <a href="#c06-c6" external="false" id="a_000047" smilref="Machine_Learning00001.smil#a_000047">Chapter 6: Association Rules Learning</a>
              <list type="ol" id="list_000007">
                <li class="contentsH2" id="li_000048">
                  <a href="#c06-c06_level1_1" external="false" id="a_000048" smilref="Machine_Learning00001.smil#a_000048">Where Is Association Rules Learning Used?</a>
                </li>
                <li class="contentsH2" id="li_000049">
                  <a href="#c06-c06_level1_2" external="false" id="a_000049" smilref="Machine_Learning00001.smil#a_000049">How Association Rules Learning Works</a>
                </li>
                <li class="contentsH2" id="li_000050">
                  <a href="#c06-c06_level1_3" external="false" id="a_000050" smilref="Machine_Learning00001.smil#a_000050">Algorithms</a>
                </li>
                <li class="contentsH2" id="li_000051">
                  <a href="#c06-c06_level1_4" external="false" id="a_000051" smilref="Machine_Learning00001.smil#a_000051">Mining the Baskets—A Walkthrough</a>
                </li>
                <li class="contentsH2" id="li_000052">
                  <a href="#c06-c06_level1_5" external="false" id="a_000052" smilref="Machine_Learning00001.smil#a_000052">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000053">
              <a href="#c07-c7" external="false" id="a_000053" smilref="Machine_Learning00001.smil#a_000053">Chapter 7: Support Vector Machines</a>
              <list type="ol" id="list_000008">
                <li class="contentsH2" id="li_000054">
                  <a href="#c07-c07_level1_1" external="false" id="a_000054" smilref="Machine_Learning00001.smil#a_000054">What Is a Support Vector Machine?</a>
                </li>
                <li class="contentsH2" id="li_000055">
                  <a href="#c07-c07_level1_2" external="false" id="a_000055" smilref="Machine_Learning00001.smil#a_000055">Where Are Support Vector Machines Used?</a>
                </li>
                <li class="contentsH2" id="li_000056">
                  <a href="#c07-c07_level1_3" external="false" id="a_000056" smilref="Machine_Learning00001.smil#a_000056">The Basic Classification Principles</a>
                </li>
                <li class="contentsH2" id="li_000057">
                  <a href="#c07-c07_level1_4" external="false" id="a_000057" smilref="Machine_Learning00001.smil#a_000057">How Support Vector Machines Approach Classification</a>
                </li>
                <li class="contentsH2" id="li_000058">
                  <a href="#c07-c07_level1_5" external="false" id="a_000058" smilref="Machine_Learning00001.smil#a_000058">Using Support Vector Machines in Weka</a>
                </li>
                <li class="contentsH2" id="li_000059">
                  <a href="#c07-c07_level1_6" external="false" id="a_000059" smilref="Machine_Learning00001.smil#a_000059">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000060">
              <a href="#c08-c8" external="false" id="a_000060" smilref="Machine_Learning00001.smil#a_000060">Chapter 8: Clustering</a>
              <list type="ol" id="list_000009">
                <li class="contentsH2" id="li_000061">
                  <a href="#c08-c08_level1_1" external="false" id="a_000061" smilref="Machine_Learning00001.smil#a_000061">What Is Clustering?</a>
                </li>
                <li class="contentsH2" id="li_000062">
                  <a href="#c08-c08_level1_2" external="false" id="a_000062" smilref="Machine_Learning00001.smil#a_000062">Where Is Clustering Used?</a>
                </li>
                <li class="contentsH2" id="li_000063">
                  <a href="#c08-c08_level1_3" external="false" id="a_000063" smilref="Machine_Learning00001.smil#a_000063">Clustering Models</a>
                </li>
                <li class="contentsH2" id="li_000064">
                  <a href="#c08-c08_level1_4" external="false" id="a_000064" smilref="Machine_Learning00001.smil#a_000064">K-Means Clustering with Weka</a>
                </li>
                <li class="contentsH2" id="li_000065">
                  <a href="#c08-c08_level1_5" external="false" id="a_000065" smilref="Machine_Learning00001.smil#a_000065">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000066">
              <a href="#c09-c9" external="false" id="a_000066" smilref="Machine_Learning00001.smil#a_000066">Chapter 9: Machine Learning in Real Time with Spring XD</a>
              <list type="ol" id="list_000010">
                <li class="contentsH2" id="li_000067">
                  <a href="#c09-c09_level1_1" external="false" id="a_000067" smilref="Machine_Learning00001.smil#a_000067">Capturing the Firehose of Data</a>
                </li>
                <li class="contentsH2" id="li_000068">
                  <a href="#c09-c09_level1_2" external="false" id="a_000068" smilref="Machine_Learning00001.smil#a_000068">Using Spring XD</a>
                </li>
                <li class="contentsH2" id="li_000069">
                  <a href="#c09-c09_level1_3" external="false" id="a_000069" smilref="Machine_Learning00001.smil#a_000069">Learning from Twitter Data</a>
                </li>
                <li class="contentsH2" id="li_000070">
                  <a href="#c09-c09_level1_4" external="false" id="a_000070" smilref="Machine_Learning00001.smil#a_000070">Configuring Spring XD</a>
                </li>
                <li class="contentsH2" id="li_000071">
                  <a href="#c09-c09_level1_5" external="false" id="a_000071" smilref="Machine_Learning00001.smil#a_000071">Spring XD and Twitter</a>
                </li>
                <li class="contentsH2" id="li_000072">
                  <a href="#c09-c09_level1_6" external="false" id="a_000072" smilref="Machine_Learning00001.smil#a_000072">Introducing Processors</a>
                </li>
                <li class="contentsH2" id="li_000073">
                  <a href="#c09-c09_level1_7" external="false" id="a_000073" smilref="Machine_Learning00001.smil#a_000073">Real-Time Sentiment Analysis</a>
                </li>
                <li class="contentsH2" id="li_000074">
                  <a href="#c09-c09_level1_8" external="false" id="a_000074" smilref="Machine_Learning00001.smil#a_000074">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000075">
              <a href="#c10-c10" external="false" id="a_000075" smilref="Machine_Learning00001.smil#a_000075">Chapter 10: Machine Learning as a Batch Process</a>
              <list type="ol" id="list_000011">
                <li class="contentsH2" id="li_000076">
                  <a href="#c10-c010_level1_1" external="false" id="a_000076" smilref="Machine_Learning00001.smil#a_000076">Is It Big Data?</a>
                </li>
                <li class="contentsH2" id="li_000077">
                  <a href="#c10-c010_level1_2" external="false" id="a_000077" smilref="Machine_Learning00001.smil#a_000077">Considerations for Batch Processing Data</a>
                </li>
                <li class="contentsH2" id="li_000078">
                  <a href="#c10-c010_level1_3" external="false" id="a_000078" smilref="Machine_Learning00001.smil#a_000078">Practical Examples of Batch Processes</a>
                </li>
                <li class="contentsH2" id="li_000079">
                  <a href="#c10-c010_level1_4" external="false" id="a_000079" smilref="Machine_Learning00001.smil#a_000079">Using the Hadoop Framework</a>
                </li>
                <li class="contentsH2" id="li_000080">
                  <a href="#c10-c010_level1_5" external="false" id="a_000080" smilref="Machine_Learning00001.smil#a_000080">How MapReduce Works</a>
                </li>
                <li class="contentsH2" id="li_000081">
                  <a href="#c10-c010_level1_6" external="false" id="a_000081" smilref="Machine_Learning00001.smil#a_000081">Mining the Hashtags</a>
                </li>
                <li class="contentsH2" id="li_000082">
                  <a href="#c10-c010_level1_7" external="false" id="a_000082" smilref="Machine_Learning00001.smil#a_000082">Mining Sales Data</a>
                </li>
                <li class="contentsH2" id="li_000083">
                  <a href="#c10-c010_level1_8" external="false" id="a_000083" smilref="Machine_Learning00001.smil#a_000083">Scheduling Batch Jobs</a>
                </li>
                <li class="contentsH2" id="li_000084">
                  <a href="#c10-c010_level1_9" external="false" id="a_000084" smilref="Machine_Learning00001.smil#a_000084">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000085">
              <a href="#c11-c11" external="false" id="a_000085" smilref="Machine_Learning00001.smil#a_000085">Chapter 11: Apache Spark</a>
              <list type="ol" id="list_000012">
                <li class="contentsH2" id="li_000086">
                  <a href="#c11-c011_level1_1" external="false" id="a_000086" smilref="Machine_Learning00001.smil#a_000086">Spark: A Hadoop Replacement?</a>
                </li>
                <li class="contentsH2" id="li_000087">
                  <a href="#c11-c011_level1_2" external="false" id="a_000087" smilref="Machine_Learning00001.smil#a_000087">Java, Scala, or Python?</a>
                </li>
                <li class="contentsH2" id="li_000088">
                  <a href="#c11-c011_level1_3" external="false" id="a_000088" smilref="Machine_Learning00001.smil#a_000088">Scala Crash Course</a>
                </li>
                <li class="contentsH2" id="li_000089">
                  <a href="#c11-c011_level1_4" external="false" id="a_000089" smilref="Machine_Learning00001.smil#a_000089">Downloading and Installing Spark</a>
                </li>
                <li class="contentsH2" id="li_000090">
                  <a href="#c11-c011_level1_5" external="false" id="a_000090" smilref="Machine_Learning00001.smil#a_000090">A Quick Intro to Spark</a>
                </li>
                <li class="contentsH2" id="li_000091">
                  <a href="#c11-c011_level1_6" external="false" id="a_000091" smilref="Machine_Learning00001.smil#a_000091">Comparing Hadoop MapReduce to Spark</a>
                </li>
                <li class="contentsH2" id="li_000092"> 
                  <a href="#c11-c011_level1_7" external="false" id="a_000092" smilref="Machine_Learning00001.smil#a_000092">Writing Standalone Programs with Spark</a>
                </li> 
                <li class="contentsH2" id="li_000093"> 
                  <a href="#c11-c011_level1_8" external="false" id="a_000093" smilref="Machine_Learning00001.smil#a_000093">Spark SQL</a>
                </li>  
                <li class="contentsH2" id="li_000094">   
                  <a href="#c11-c011_level1_9" external="false" id="a_000094" smilref="Machine_Learning00001.smil#a_000094">Spark Streaming</a>
                </li>  
                <li class="contentsH2" id="li_000095">   
                  <a href="#c11-c011_level1_10" external="false" id="a_000095" smilref="Machine_Learning00001.smil#a_000095">MLib: The Machine Learning Library</a>
                </li>   
                <li class="contentsH2" id="li_000096">
                  <a href="#c11-c011_level1_11" external="false" id="a_000096" smilref="Machine_Learning00001.smil#a_000096">Summary</a>
                </li> 
              </list> 
            </li> 
            <li class="contentsH1" id="li_000097">   
              <a href="#c12-c12" external="false" id="a_000097" smilref="Machine_Learning00001.smil#a_000097">Chapter 12: Machine Learning with R</a>
              <list type="ol" id="list_000013"> 
                <li class="contentsH2" id="li_000098">   
                  <a href="#c12-c012_level1_1" external="false" id="a_000098" smilref="Machine_Learning00001.smil#a_000098">Installing R</a>
                </li>  
                <li class="contentsH2" id="li_000099">   
                  <a href="#c12-c012_level1_2" external="false" id="a_000099" smilref="Machine_Learning00001.smil#a_000099">Your First Run</a>
                </li>
                <li class="contentsH2" id="li_000100">  
                  <a href="#c12-c012_level1_3" external="false" id="a_000100" smilref="Machine_Learning00001.smil#a_000100">Installing R-Studio</a>
                </li> 
                <li class="contentsH2" id="li_000101">   
                  <a href="#c12-c012_level1_4" external="false" id="a_000101" smilref="Machine_Learning00001.smil#a_000101">The R Basics</a>
                </li>   
                <li class="contentsH2" id="li_000102">   
                  <a href="#c12-c012_level1_5" external="false" id="a_000102" smilref="Machine_Learning00001.smil#a_000102">Simple Statistics</a>
                </li>   
                <li class="contentsH2" id="li_000103">  
                  <a href="#c12-c012_level1_6" external="false" id="a_000103" smilref="Machine_Learning00001.smil#a_000103">Simple Linear Regression</a>
                </li>  
                <li class="contentsH2" id="li_000104">
                  <a href="#c12-c012_level1_7" external="false" id="a_000104" smilref="Machine_Learning00001.smil#a_000104">Basic Sentiment Analysis</a>
                </li>    
                <li class="contentsH2" id="li_000105"> 
                  <a href="#c12-c012_level1_8" external="false" id="a_000105" smilref="Machine_Learning00001.smil#a_000105">Apriori Association Rules</a>
                </li>   
                <li class="contentsH2" id="li_000106">    
                  <a href="#c12-c012_level1_9" external="false" id="a_000106" smilref="Machine_Learning00001.smil#a_000106">Accessing R from Java</a>
                </li>  
                <li class="contentsH2" id="li_000107">  
                  <a href="#c12-c012_level1_10" external="false" id="a_000107" smilref="Machine_Learning00001.smil#a_000107">R and Hadoop</a>
                </li>    
                <li class="contentsH2" id="li_000108">   
                  <a href="#c12-c012_level1_11" external="false" id="a_000108" smilref="Machine_Learning00001.smil#a_000108">Summary</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000109">
              <a href="#bappxA" external="false" id="a_000109" smilref="Machine_Learning00001.smil#a_000109">Appendix A: SpringXD Quick Start</a>
              <list type="ol" id="list_000014">
                <li class="contentsH2" id="li_000110">
                  <a href="#bappxA-c0A_level1_1" external="false" id="a_000110" smilref="Machine_Learning00001.smil#a_000110">Installing Manually</a>
                </li>
                <li class="contentsH2" id="li_000111">
                  <a href="#bappxA-c0A_level1_2" external="false" id="a_000111" smilref="Machine_Learning00001.smil#a_000111">Starting SpringXD</a>
                </li>
                <li class="contentsH2" id="li_000112">
                  <a href="#bappxA-c0A_level1_3" external="false" id="a_000112" smilref="Machine_Learning00001.smil#a_000112">Creating a Stream</a>
                </li>
                <li class="contentsH2" id="li_000113">
                  <a href="#bappxA-c0A_level1_4" external="false" id="a_000113" smilref="Machine_Learning00001.smil#a_000113">Adding a Twitter Application Key</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000114">
              <a href="#bappxB" external="false" id="a_000114" smilref="Machine_Learning00001.smil#a_000114">Appendix B: Hadoop 1.x Quick Start</a>
              <list type="ol" id="list_000015">
                <li class="contentsH2" id="li_000115">
                  <a href="#bappxB-c0B_level1_1" external="false" id="a_000115" smilref="Machine_Learning00001.smil#a_000115">Downloading and Installing Hadoop</a>
                </li>
                <li class="contentsH2" id="li_000116">
                  <a href="#bappxB-c0B_level1_2" external="false" id="a_000116" smilref="Machine_Learning00001.smil#a_000116">Formatting the HDFS Filesystem</a>
                </li>
                <li class="contentsH2" id="li_000117">
                  <a href="#bappxB-c0B_level1_3" external="false" id="a_000117" smilref="Machine_Learning00001.smil#a_000117">Starting and Stopping Hadoop</a>
                </li>
                <li class="contentsH2" id="li_000118">
                  <a href="#bappxB-c0B_level1_4" external="false" id="a_000118" smilref="Machine_Learning00001.smil#a_000118">Process List of a Basic Job</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000119">
              <a href="#bappxC" external="false" id="a_000119" smilref="Machine_Learning00001.smil#a_000119">Appendix C: Useful Unix Commands</a>
              <list type="ol" id="list_000016">
                <li class="contentsH2" id="li_000120">
                  <a href="#bappxC-c0C_level1_1" external="false" id="a_000120" smilref="Machine_Learning00001.smil#a_000120">Using Sample Data</a>
                </li>
                <li class="contentsH2" id="li_000121">
                  <a href="#bappxC-c0C_level1_2" external="false" id="a_000121" smilref="Machine_Learning00001.smil#a_000121">Showing the Contents: cat, more, and less</a>
                </li>
                <li class="contentsH2" id="li_000122">
                  <a href="#bappxC-c0C_level1_3" external="false" id="a_000122" smilref="Machine_Learning00001.smil#a_000122">Filtering Content: grep</a>
                </li>
                <li class="contentsH2" id="li_000123">
                  <a href="#bappxC-c0C_level1_4" external="false" id="a_000123" smilref="Machine_Learning00001.smil#a_000123">Sorting Data: sort</a>
                </li>
                <li class="contentsH2" id="li_000124">
                  <a href="#bappxC-c0C_level1_5" external="false" id="a_000124" smilref="Machine_Learning00001.smil#a_000124">Finding Unique Occurrences: uniq</a>
                </li>
                <li class="contentsH2" id="li_000125">
                  <a href="#bappxC-c0C_level1_6" external="false" id="a_000125" smilref="Machine_Learning00001.smil#a_000125">Showing the Top of a File: head</a>
                </li>
                <li class="contentsH2" id="li_000126">
                  <a href="#bappxC-c0C_level1_7" external="false" id="a_000126" smilref="Machine_Learning00001.smil#a_000126">Counting Words: wc</a>
                </li>
                <li class="contentsH2" id="li_000127">
                  <a href="#bappxC-c0C_level1_8" external="false" id="a_000127" smilref="Machine_Learning00001.smil#a_000127">Locating Anything: find</a>
                </li>
                <li class="contentsH2" id="li_000128">
                  <a href="#bappxC-c0C_level1_9" external="false" id="a_000128" smilref="Machine_Learning00001.smil#a_000128">Combining Commands and Redirecting Output</a>
                </li>
                <li class="contentsH2" id="li_000129">
                  <a href="#bappxC-c0C_level1_10" external="false" id="a_000129" smilref="Machine_Learning00001.smil#a_000129">Picking a Text Editor</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000130">
              <a href="#bappxD" external="false" id="a_000130" smilref="Machine_Learning00001.smil#a_000130">Appendix D: Further Reading</a>
              <list type="ol" id="list_000017">
                <li class="contentsH2" id="li_000131">
                  <a href="#bappxD-c0D_level1_1" external="false" id="a_000131" smilref="Machine_Learning00001.smil#a_000131">Machine Learning</a>
                </li>
                <li class="contentsH2" id="li_000132">
                  <a href="#bappxD-c0D_level1_2" external="false" id="a_000132" smilref="Machine_Learning00001.smil#a_000132">Statistics</a>
                </li>
                <li class="contentsH2" id="li_000133">
                  <a href="#bappxD-c0D_level1_3" external="false" id="a_000133" smilref="Machine_Learning00001.smil#a_000133">Big Data and Data Science</a>
                </li>
                <li class="contentsH2" id="li_000134">
                  <a href="#bappxD-c0D_level1_4" external="false" id="a_000134" smilref="Machine_Learning00001.smil#a_000134">Hadoop</a>
                </li>
                <li class="contentsH2" id="li_000135">
                  <a href="#bappxD-c0D_level1_5" external="false" id="a_000135" smilref="Machine_Learning00001.smil#a_000135">Visualization</a>
                </li>
                <li class="contentsH2" id="li_000136">
                  <a href="#bappxD-c0D_level1_6" external="false" id="a_000136" smilref="Machine_Learning00001.smil#a_000136">Making Decisions</a>
                </li>
                <li class="contentsH2" id="li_000137">
                  <a href="#bappxD-c0D_level1_7" external="false" id="a_000137" smilref="Machine_Learning00001.smil#a_000137">Datasets</a>
                </li>
                <li class="contentsH2" id="li_000138">
                  <a href="#bappxD-c0D_level1_8" external="false" id="a_000138" smilref="Machine_Learning00001.smil#a_000138">Blogs</a>
                </li>
                <li class="contentsH2" id="li_000139">
                  <a href="#bappxD-c0D_level1_9" external="false" id="a_000139" smilref="Machine_Learning00001.smil#a_000139">Useful Websites</a>
                </li>
                <li class="contentsH2" id="li_000140">
                  <a href="#bappxD-c0D_level1_10" external="false" id="a_000140" smilref="Machine_Learning00001.smil#a_000140">The Tools of the Trade</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000141">
              <a href="#f05-f5" external="false" id="a_000141" smilref="Machine_Learning00001.smil#a_000141">Introduction</a>
              <list type="ol" id="list_000018">
                <li class="contentsH1" id="li_000142">
                  <a href="#f05-c0x_level1_1" external="false" id="a_000142" smilref="Machine_Learning00001.smil#a_000142">Aims of This Book</a>
                </li>
                <li class="contentsH1" id="li_000143">
                  <a href="#f05-c0x_level1_2" external="false" id="a_000143" smilref="Machine_Learning00001.smil#a_000143">“Hands-On” Means Hands-On</a>
                </li>
                <li class="contentsH1" id="li_000144">
                  <a href="#f05-c0x_level1_3" external="false" id="a_000144" smilref="Machine_Learning00001.smil#a_000144">“What About the Math?”</a>
                </li>
                <li class="contentsH1" id="li_000145">
                  <a href="#f05-c0x_level1_4" external="false" id="a_000145" smilref="Machine_Learning00001.smil#a_000145">What Will You Have Learned by the End?</a>
                </li>
                <li class="contentsH1" id="li_000146">
                  <a href="#f05-c0x_level1_5" external="false" id="a_000146" smilref="Machine_Learning00001.smil#a_000146">Balancing Theory and Hands-On Learning</a>
                </li>
                <li class="contentsH1" id="li_000147">
                  <a href="#f05-c0x_level1_6" external="false" id="a_000147" smilref="Machine_Learning00001.smil#a_000147">Outline of the Chapters</a>
                </li>
                <li class="contentsH1" id="li_000148">
                  <a href="#f05-c0x_level1_7" external="false" id="a_000148" smilref="Machine_Learning00001.smil#a_000148">Source Code for This Book</a>
                </li>
                <li class="contentsH1" id="li_000149">
                  <a href="#f05-c0x_level1_8" external="false" id="a_000149" smilref="Machine_Learning00001.smil#a_000149">Using Git</a>
                </li>
              </list>
            </li>
            <li class="contentsH1" id="li_000150">
              <a href="#u9781118889497eula" external="false" id="a_000150" smilref="Machine_Learning00001.smil#a_000150">End User License Agreement</a>
            </li>
          </list>
        </level2>
        <level2 class="guideList" id="toc-guide">
          <h2 xml:space="preserve" id="h2_000002" smilref="Machine_Learning00001.smil#h2_000002">Guide</h2>
          <list type="ol" id="list_000019">
            <li id="li_000151">
              <a epub:type="cover" href="#cover" external="false" id="a_000151" smilref="Machine_Learning00001.smil#a_000151">Cover</a>
            </li>
            <li id="li_000152">
              <a epub:type="toc" href="#toc-toc" external="false" id="a_000152" smilref="Machine_Learning00001.smil#a_000152">Table of Contents</a>
            </li>
            <li id="li_000153">
              <a epub:type="introduction" href="#f05" external="false" id="a_000153" smilref="Machine_Learning00001.smil#a_000153">Introduction</a>
            </li>
            <li id="li_000154">
              <a epub:type="chapter" href="#c01" external="false" id="a_000154" smilref="Machine_Learning00001.smil#a_000154">Begin Reading</a>
            </li>
          </list>
        </level2>
        <level2 id="level2_000001">
          <h2 xml:space="preserve" id="h2_000003" smilref="Machine_Learning00001.smil#h2_000003">List of Illustrations</h2>
          <list type="ol" id="list_000020">
            <li class="contentsH1" id="li_000155">
              <a href="#c02-c02-fig-0001" external="false" id="a_000155" smilref="Machine_Learning00001.smil#a_000155">Figure 2-1</a>
            </li>
            <li class="contentsH1" id="li_000156">
              <a href="#c03-c03-fig-0001" external="false" id="a_000156" smilref="Machine_Learning00001.smil#a_000156">Figure 3-1</a>
            </li>
            <li class="contentsH1" id="li_000157">
              <a href="#c03-c03-fig-0002" external="false" id="a_000157" smilref="Machine_Learning00001.smil#a_000157">Figure 3-2</a>
            </li>
            <li class="contentsH1" id="li_000158">
              <a href="#c03-c03-fig-0003" external="false" id="a_000158" smilref="Machine_Learning00001.smil#a_000158">Figure 3-3</a>
            </li>
            <li class="contentsH1" id="li_000159">
              <a href="#c03-c03-fig-0004" external="false" id="a_000159" smilref="Machine_Learning00001.smil#a_000159">Figure 3-4</a>
            </li>
            <li class="contentsH1" id="li_000160">
              <a href="#c03-c03-fig-0005" external="false" id="a_000160" smilref="Machine_Learning00001.smil#a_000160">Figure 3-5</a>
            </li>
            <li class="contentsH1" id="li_000161">
              <a href="#c03-c03-fig-0006" external="false" id="a_000161" smilref="Machine_Learning00001.smil#a_000161">Figure 3-6</a>
            </li>
            <li class="contentsH1" id="li_000162">
              <a href="#c03-c03-fig-0007" external="false" id="a_000162" smilref="Machine_Learning00001.smil#a_000162">Figure 3-7</a>
            </li>
            <li class="contentsH1" id="li_000163">
              <a href="#c03-c03-fig-0008" external="false" id="a_000163" smilref="Machine_Learning00001.smil#a_000163">Figure 3-8</a>
            </li>
            <li class="contentsH1" id="li_000164">
              <a href="#c04-c04-fig-0001" external="false" id="a_000164" smilref="Machine_Learning00001.smil#a_000164">Figure 4-1</a>
            </li>
            <li class="contentsH1" id="li_000165">
              <a href="#c04-c04-fig-0002" external="false" id="a_000165" smilref="Machine_Learning00001.smil#a_000165">Figure 4-2</a>
            </li>
            <li class="contentsH1" id="li_000166">
              <a href="#c04-c04-fig-0003" external="false" id="a_000166" smilref="Machine_Learning00001.smil#a_000166">Figure 4-3</a>
            </li>
            <li class="contentsH1" id="li_000167">
              <a href="#c04-c04-fig-0004" external="false" id="a_000167" smilref="Machine_Learning00001.smil#a_000167">Figure 4-4</a>
            </li>
            <li class="contentsH1" id="li_000168">
              <a href="#c04-c04-fig-0005" external="false" id="a_000168" smilref="Machine_Learning00001.smil#a_000168">Figure 4-5</a>
            </li>
            <li class="contentsH1" id="li_000169">
              <a href="#c04-c04-fig-0006" external="false" id="a_000169" smilref="Machine_Learning00001.smil#a_000169">Figure 4-6</a>
            </li>
            <li class="contentsH1" id="li_000170">
              <a href="#c04-c04-fig-0007" external="false" id="a_000170" smilref="Machine_Learning00001.smil#a_000170">Figure 4-7</a>
            </li>
            <li class="contentsH1" id="li_000171">
              <a href="#c04-c04-fig-0008" external="false" id="a_000171" smilref="Machine_Learning00001.smil#a_000171">Figure 4-8</a>
            </li>
            <li class="contentsH1" id="li_000172">
              <a href="#c04-c04-fig-0009" external="false" id="a_000172" smilref="Machine_Learning00001.smil#a_000172">Figure 4-9</a>
            </li>
            <li class="contentsH1" id="li_000173">
              <a href="#c05-c05-fig-0001" external="false" id="a_000173" smilref="Machine_Learning00001.smil#a_000173">Figure 5-1</a>
            </li>
            <li class="contentsH1" id="li_000174">
              <a href="#c05-c05-fig-0002" external="false" id="a_000174" smilref="Machine_Learning00001.smil#a_000174">Figure 5-2</a>
            </li>
            <li class="contentsH1" id="li_000175">
              <a href="#c05-c05-fig-0003" external="false" id="a_000175" smilref="Machine_Learning00001.smil#a_000175">Figure 5-3</a>
            </li>
            <li class="contentsH1" id="li_000176">
              <a href="#c05-c05-fig-0004" external="false" id="a_000176" smilref="Machine_Learning00001.smil#a_000176">Figure 5-4</a>
            </li>
            <li class="contentsH1" id="li_000177">
              <a href="#c05-c05-fig-0005" external="false" id="a_000177" smilref="Machine_Learning00001.smil#a_000177">Figure 5-5</a>
            </li>
            <li class="contentsH1" id="li_000178">
              <a href="#c05-c05-fig-0006" external="false" id="a_000178" smilref="Machine_Learning00001.smil#a_000178">Figure 5-6</a>
            </li>
            <li class="contentsH1" id="li_000179">
              <a href="#c05-c05-fig-0007" external="false" id="a_000179" smilref="Machine_Learning00001.smil#a_000179">Figure 5-7</a>
            </li>
            <li class="contentsH1" id="li_000180">
              <a href="#c05-c05-fig-0008" external="false" id="a_000180" smilref="Machine_Learning00001.smil#a_000180">Figure 5-8</a>
            </li>
            <li class="contentsH1" id="li_000181">
              <a href="#c05-c05-fig-0009" external="false" id="a_000181" smilref="Machine_Learning00001.smil#a_000181">Figure 5-9</a>
            </li>
            <li class="contentsH1" id="li_000182">
              <a href="#c05-c05-fig-0010" external="false" id="a_000182" smilref="Machine_Learning00001.smil#a_000182">Figure 5-10</a>
            </li>
            <li class="contentsH1" id="li_000183">
              <a href="#c05-c05-fig-0011" external="false" id="a_000183" smilref="Machine_Learning00001.smil#a_000183">Figure 5-11</a>
            </li>
            <li class="contentsH1" id="li_000184">
              <a href="#c05-c05-fig-0012" external="false" id="a_000184" smilref="Machine_Learning00001.smil#a_000184">Figure 5-12</a>
            </li>
            <li class="contentsH1" id="li_000185">
              <a href="#c05-c05-fig-0013" external="false" id="a_000185" smilref="Machine_Learning00001.smil#a_000185">Figure 5-13</a>
            </li>
            <li class="contentsH1" id="li_000186">
              <a href="#c05-c05-fig-0014" external="false" id="a_000186" smilref="Machine_Learning00001.smil#a_000186">Figure 5-14</a>
            </li>
            <li class="contentsH1" id="li_000187">
              <a href="#c05-c05-fig-0015" external="false" id="a_000187" smilref="Machine_Learning00001.smil#a_000187">Figure 5-15</a>
            </li>
            <li class="contentsH1" id="li_000188">
              <a href="#c06-c06-fig-0001" external="false" id="a_000188" smilref="Machine_Learning00001.smil#a_000188">Figure 6-1</a>
            </li>
            <li class="contentsH1" id="li_000189">
              <a href="#c06-c06-fig-0002" external="false" id="a_000189" smilref="Machine_Learning00001.smil#a_000189">Figure 6-2</a>
            </li>
            <li class="contentsH1" id="li_000190">
              <a href="#c07-c07-fig-0001" external="false" id="a_000190" smilref="Machine_Learning00001.smil#a_000190">Figure 7-1</a>
            </li>
            <li class="contentsH1" id="li_000191">
              <a href="#c07-c07-fig-0002" external="false" id="a_000191" smilref="Machine_Learning00001.smil#a_000191">Figure 7-2</a>
            </li>
            <li class="contentsH1" id="li_000192">
              <a href="#c07-c07-fig-0003" external="false" id="a_000192" smilref="Machine_Learning00001.smil#a_000192">Figure 7-3</a>
            </li>
            <li class="contentsH1" id="li_000193">
              <a href="#c07-c07-fig-0004" external="false" id="a_000193" smilref="Machine_Learning00001.smil#a_000193">Figure 7-4</a>
            </li>
            <li class="contentsH1" id="li_000194">
              <a href="#c07-c07-fig-0005" external="false" id="a_000194" smilref="Machine_Learning00001.smil#a_000194">Figure 7-5</a>
            </li>
            <li class="contentsH1" id="li_000195">
              <a href="#c07-c07-fig-0006" external="false" id="a_000195" smilref="Machine_Learning00001.smil#a_000195">Figure 7-6</a>
            </li>
            <li class="contentsH1" id="li_000196">
              <a href="#c07-c07-fig-0007" external="false" id="a_000196" smilref="Machine_Learning00001.smil#a_000196">Figure 7-7</a>
            </li>
            <li class="contentsH1" id="li_000197">
              <a href="#c07-c07-fig-0008" external="false" id="a_000197" smilref="Machine_Learning00001.smil#a_000197">Figure 7-8</a>
            </li>
            <li class="contentsH1" id="li_000198">
              <a href="#c07-c07-fig-0009" external="false" id="a_000198" smilref="Machine_Learning00001.smil#a_000198">Figure 7-9</a>
            </li>
            <li class="contentsH1" id="li_000199">
              <a href="#c07-c07-fig-0010" external="false" id="a_000199" smilref="Machine_Learning00001.smil#a_000199">Figure 7-10</a>
            </li>
            <li class="contentsH1" id="li_000200">
              <a href="#c07-c07-fig-0011" external="false" id="a_000200" smilref="Machine_Learning00001.smil#a_000200">Figure 7-11</a>
            </li>
            <li class="contentsH1" id="li_000201">
              <a href="#c07-c07-fig-0012" external="false" id="a_000201" smilref="Machine_Learning00001.smil#a_000201">Figure 7-12</a>
            </li>
            <li class="contentsH1" id="li_000202">
              <a href="#c07-c07-fig-0013" external="false" id="a_000202" smilref="Machine_Learning00001.smil#a_000202">Figure 7-13</a>
            </li>
            <li class="contentsH1" id="li_000203">
              <a href="#c07-c07-fig-0014" external="false" id="a_000203" smilref="Machine_Learning00001.smil#a_000203">Figure 7-14</a>
            </li>
            <li class="contentsH1" id="li_000204">
              <a href="#c07-c07-fig-0015" external="false" id="a_000204" smilref="Machine_Learning00001.smil#a_000204">Figure 7-15</a>
            </li>
            <li class="contentsH1" id="li_000205">
              <a href="#c08-c08-fig-0001" external="false" id="a_000205" smilref="Machine_Learning00001.smil#a_000205">Figure 8-1</a>
            </li>
            <li class="contentsH1" id="li_000206">
              <a href="#c08-c08-fig-0002" external="false" id="a_000206" smilref="Machine_Learning00001.smil#a_000206">Figure 8-2</a>
            </li>
            <li class="contentsH1" id="li_000207">
              <a href="#c08-c08-fig-0003" external="false" id="a_000207" smilref="Machine_Learning00001.smil#a_000207">Figure 8-3</a>
            </li>
            <li class="contentsH1" id="li_000208">
              <a href="#c08-c08-fig-0004" external="false" id="a_000208" smilref="Machine_Learning00001.smil#a_000208">Figure 8-4</a>
            </li>
            <li class="contentsH1" id="li_000209">
              <a href="#c08-c08-fig-0005" external="false" id="a_000209" smilref="Machine_Learning00001.smil#a_000209">Figure 8-5</a>
            </li>
            <li class="contentsH1" id="li_000210">
              <a href="#c08-c08-fig-0006" external="false" id="a_000210" smilref="Machine_Learning00001.smil#a_000210">Figure 8-6</a>
            </li>
            <li class="contentsH1" id="li_000211">
              <a href="#c08-c08-fig-0007" external="false" id="a_000211" smilref="Machine_Learning00001.smil#a_000211">Figure 8-7</a>
            </li>
            <li class="contentsH1" id="li_000212">
              <a href="#c08-c08-fig-0008" external="false" id="a_000212" smilref="Machine_Learning00001.smil#a_000212">Figure 8-8</a>
            </li>
            <li class="contentsH1" id="li_000213">
              <a href="#c08-c08-fig-0009" external="false" id="a_000213" smilref="Machine_Learning00001.smil#a_000213">Figure 8-9</a>
            </li>
            <li class="contentsH1" id="li_000214">
              <a href="#c08-c08-fig-0010" external="false" id="a_000214" smilref="Machine_Learning00001.smil#a_000214">Figure 8-10</a>
            </li>
            <li class="contentsH1" id="li_000215">
              <a href="#c08-c08-fig-0011" external="false" id="a_000215" smilref="Machine_Learning00001.smil#a_000215">Figure 8-11</a>
            </li>
            <li class="contentsH1" id="li_000216">
              <a href="#c08-c08-fig-0012" external="false" id="a_000216" smilref="Machine_Learning00001.smil#a_000216">Figure 8-12</a>
            </li>
            <li class="contentsH1" id="li_000217">
              <a href="#c09-c09-fig-0001" external="false" id="a_000217" smilref="Machine_Learning00001.smil#a_000217">Figure 9-1</a>
            </li>
            <li class="contentsH1" id="li_000218">
              <a href="#c09-c09-fig-0002" external="false" id="a_000218" smilref="Machine_Learning00001.smil#a_000218">Figure 9-2</a>
            </li>
            <li class="contentsH1" id="li_000219">
              <a href="#c09-c09-fig-0003" external="false" id="a_000219" smilref="Machine_Learning00001.smil#a_000219">Figure 9-3</a>
            </li>
            <li class="contentsH1" id="li_000220">
              <a href="#c09-c09-fig-0004" external="false" id="a_000220" smilref="Machine_Learning00001.smil#a_000220">Figure 9-4</a>
            </li>
            <li class="contentsH1" id="li_000221">
              <a href="#c09-c09-fig-0005" external="false" id="a_000221" smilref="Machine_Learning00001.smil#a_000221">Figure 9-5</a>
            </li>
            <li class="contentsH1" id="li_000222">
              <a href="#c09-c09-fig-0006" external="false" id="a_000222" smilref="Machine_Learning00001.smil#a_000222">Figure 9-6</a>
            </li>
            <li class="contentsH1" id="li_000223">
              <a href="#c09-c09-fig-0007" external="false" id="a_000223" smilref="Machine_Learning00001.smil#a_000223">Figure 9-7</a>
            </li>
            <li class="contentsH1" id="li_000224">
              <a href="#c09-c09-fig-0008" external="false" id="a_000224" smilref="Machine_Learning00001.smil#a_000224">Figure 9-8</a>
            </li>
            <li class="contentsH1" id="li_000225">
              <a href="#c09-c09-fig-0009" external="false" id="a_000225" smilref="Machine_Learning00001.smil#a_000225">Figure 9-9</a>
            </li>
            <li class="contentsH1" id="li_000226">
              <a href="#c09-c09-fig-0010" external="false" id="a_000226" smilref="Machine_Learning00001.smil#a_000226">Figure 9-10</a>
            </li>
            <li class="contentsH1" id="li_000227">
              <a href="#c09-c09-fig-0011" external="false" id="a_000227" smilref="Machine_Learning00001.smil#a_000227">Figure 9-11</a>
            </li>
            <li class="contentsH1" id="li_000228">
              <a href="#c09-c09-fig-0012" external="false" id="a_000228" smilref="Machine_Learning00001.smil#a_000228">Figure 9-12</a>
            </li>
            <li class="contentsH1" id="li_000229">
              <a href="#c09-c09-fig-0013" external="false" id="a_000229" smilref="Machine_Learning00001.smil#a_000229">Figure 9-13</a>
            </li>
            <li class="contentsH1" id="li_000230">
              <a href="#c09-c09-fig-0014" external="false" id="a_000230" smilref="Machine_Learning00001.smil#a_000230">Figure 9-14</a>
            </li>
            <li class="contentsH1" id="li_000231">
              <a href="#c10-c10-fig-0001" external="false" id="a_000231" smilref="Machine_Learning00001.smil#a_000231">Figure 10-1</a>
            </li>
            <li class="contentsH1" id="li_000232">
              <a href="#c10-c10-fig-0002" external="false" id="a_000232" smilref="Machine_Learning00001.smil#a_000232">Figure 10-2</a>
            </li>
            <li class="contentsH1" id="li_000233">
              <a href="#c10-c10-fig-0003" external="false" id="a_000233" smilref="Machine_Learning00001.smil#a_000233">Figure 10-3</a>
            </li>
            <li class="contentsH1" id="li_000234">
              <a href="#c10-c10-fig-0004" external="false" id="a_000234" smilref="Machine_Learning00001.smil#a_000234">Figure 10-4</a>
            </li>
            <li class="contentsH1" id="li_000235">
              <a href="#c11-c11-fig-0001" external="false" id="a_000235" smilref="Machine_Learning00001.smil#a_000235">Figure 11-1</a>
            </li>
            <li class="contentsH1" id="li_000236">
              <a href="#c12-c12-fig-0001" external="false" id="a_000236" smilref="Machine_Learning00001.smil#a_000236">Figure 12-1</a>
            </li>
            <li class="contentsH1" id="li_000237">
              <a href="#c12-c12-fig-0002" external="false" id="a_000237" smilref="Machine_Learning00001.smil#a_000237">Figure 12-2</a>
            </li>
            <li class="contentsH1" id="li_000238">
              <a href="#c12-c12-fig-0003" external="false" id="a_000238" smilref="Machine_Learning00001.smil#a_000238">Figure 12-3</a>
            </li>
            <li class="contentsH1" id="li_000239">
              <a href="#c12-c12-fig-0004" external="false" id="a_000239" smilref="Machine_Learning00001.smil#a_000239">Figure 12-4</a>
            </li>
            <li class="contentsH1" id="li_000240">
              <a href="#c12-c12-fig-0005" external="false" id="a_000240" smilref="Machine_Learning00001.smil#a_000240">Figure 12-5</a>
            </li>
            <li class="contentsH1" id="li_000241">
              <a href="#c12-c12-fig-0006" external="false" id="a_000241" smilref="Machine_Learning00001.smil#a_000241">Figure 12-6</a>
            </li>
            <li class="contentsH1" id="li_000242">
              <a href="#c12-c12-fig-0007" external="false" id="a_000242" smilref="Machine_Learning00001.smil#a_000242">Figure 12-7</a>
            </li>
            <li class="contentsH1" id="li_000243">
              <a href="#c12-c12-fig-0008" external="false" id="a_000243" smilref="Machine_Learning00001.smil#a_000243">Figure 12-8</a>
            </li>
            <li class="contentsH1" id="li_000244">
              <a href="#c12-c12-fig-0009" external="false" id="a_000244" smilref="Machine_Learning00001.smil#a_000244">Figure 12-9</a>
            </li>
            <li class="contentsH1" id="li_000245">
              <a href="#c12-c12-fig-0010" external="false" id="a_000245" smilref="Machine_Learning00001.smil#a_000245">Figure 12-10</a>
            </li>
            <li class="contentsH1" id="li_000246">
              <a href="#c12-c12-fig-0011" external="false" id="a_000246" smilref="Machine_Learning00001.smil#a_000246">Figure 12-11</a>
            </li>
            <li class="contentsH1" id="li_000247">
              <a href="#c12-c12-fig-0012" external="false" id="a_000247" smilref="Machine_Learning00001.smil#a_000247">Figure 12-12</a>
            </li>
            <li class="contentsH1" id="li_000248">
              <a href="#c12-c12-fig-0013" external="false" id="a_000248" smilref="Machine_Learning00001.smil#a_000248">Figure 12-13</a>
            </li>
            <li class="contentsH1" id="li_000249">
              <a href="#bappxC-bappxC-fig-0001" external="false" id="a_000249" smilref="Machine_Learning00001.smil#a_000249">Figure C-1</a>
            </li>
            <li class="contentsH1" id="li_000250">
              <a href="#bappxC-bappxC-fig-0002" external="false" id="a_000250" smilref="Machine_Learning00001.smil#a_000250">Figure C-2</a>
            </li>
            <li class="contentsH1" id="li_000251">
              <a href="#bappxC-bappxC-fig-0003" external="false" id="a_000251" smilref="Machine_Learning00001.smil#a_000251">Figure C-3</a>
            </li>
          </list>
        </level2>
        <level2 id="level2_000002">
          <h2 xml:space="preserve" id="h2_000004" smilref="Machine_Learning00001.smil#h2_000004">List of Tables</h2>
          <list type="ol" id="list_000021">
            <li class="contentsH1" id="li_000252">
              <a href="#c02-c02-tbl-0001" external="false" id="a_000252" smilref="Machine_Learning00001.smil#a_000252">Table 2-1</a>
            </li>
            <li class="contentsH1" id="li_000253">
              <a href="#c03-c03-tbl-0001" external="false" id="a_000253" smilref="Machine_Learning00001.smil#a_000253">Table 3-1</a>
            </li>
            <li class="contentsH1" id="li_000254">
              <a href="#c05-c05-tbl-0001" external="false" id="a_000254" smilref="Machine_Learning00001.smil#a_000254">Table 5-1</a>
            </li>
            <li class="contentsH1" id="li_000255">
              <a href="#c05-c05-tbl-0002" external="false" id="a_000255" smilref="Machine_Learning00001.smil#a_000255">Table 5-2</a>
            </li>
            <li class="contentsH1" id="li_000256">
              <a href="#c09-c09-tbl-0001" external="false" id="a_000256" smilref="Machine_Learning00001.smil#a_000256">Table 9-1</a>
            </li>
            <li class="contentsH1" id="li_000257">
              <a href="#c09-c09-tbl-0002" external="false" id="a_000257" smilref="Machine_Learning00001.smil#a_000257">Table 9-2</a>
            </li>
            <li class="contentsH1" id="li_000258">
              <a href="#c09-c09-tbl-0003" external="false" id="a_000258" smilref="Machine_Learning00001.smil#a_000258">Table 9-3</a>
            </li>
            <li class="contentsH1" id="li_000259">
              <a href="#c09-c09-tbl-0004" external="false" id="a_000259" smilref="Machine_Learning00001.smil#a_000259">Table 9-4</a>
            </li>
            <li class="contentsH1" id="li_000260">
              <a href="#c10-c10-tbl-0001" external="false" id="a_000260" smilref="Machine_Learning00001.smil#a_000260">Table 10-1</a>
            </li>
            <li class="contentsH1" id="li_000261">
              <a href="#c10-c10-tbl-0002" external="false" id="a_000261" smilref="Machine_Learning00001.smil#a_000261">Table 10-2</a>
            </li>
            <li class="contentsH1" id="li_000262">
              <a href="#bappxC-bappxC-tbl-0001" external="false" id="a_000262" smilref="Machine_Learning00001.smil#a_000262">Table C-1</a>
            </li>
          </list>
        </level2>
      </level1>
    </frontmatter>
    <bodymatter id="bodymatter_000001">
      <level1 id="c01">
        <section epub:type="chapter" id="section_000002">
          <header id="header_000001">
            <h1 id="c01-c1" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c1">Chapter 1 What Is Machine Learning?</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p1" page="normal" smilref="Machine_Learning00001.smil#p1">1</pagenum>
          <p xml:space="preserve" id="p_000002" smilref="Machine_Learning00001.smil#p_000002">Let's start at the beginning, looking at what machine learning actually is, its history, and where it is used in industry. This chapter also describes some of the software used throughout the book so you can have everything installed and be ready to get working on the practical things.</p>
          <level2 id="level2_000003">
            <h2 id="c01-c01_level1_1" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_1">History of Machine Learning</h2>
            <p xml:space="preserve" id="p_000003" smilref="Machine_Learning00001.smil#p_000003">So, what is the definition of machine learning? Over the last six decades, several pioneers of the industry have worked to steer us in the right direction.</p>
            <level3 id="level3_000001">
              <h3 xml:space="preserve" id="h3_000001" smilref="Machine_Learning00001.smil#h3_000001">Alan Turing</h3>
              <p xml:space="preserve" id="p_000004"><span class="text" id="span_000001" smilref="Machine_Learning00001.smil#span_000001">In his 1950 paper, “Computing Machinery and Intelligence,” Alan Turing asked, “Can machines think?” (See </span><code xml:space="preserve" id="code_000001"><a href="http://www.csee.umbc.edu/courses/471/papers/turing.pdf" external="true" id="a_000263" smilref="Machine_Learning00001.smil#a_000263">www.csee.umbc.edu/courses/471/papers/turing.pdf</a></code><span class="text" id="span_000002" smilref="Machine_Learning00001.smil#span_000002"> for the full paper.) The paper describes the “Imitation Game,” which involves three participants—a human acting as a judge, another human, and a computer that is attempting to convince the judge that it is human. The judge would type into a terminal program to “talk” to the other two participants. Both the human and the computer would respond, and the judge would decide which response came from the computer. If the judge couldn't consistently tell the difference between the human and computer responses then the computer won the game.</span></p>
              <pagenum epub:type="pagebreak" id="p2" page="normal" smilref="Machine_Learning00001.smil#p2">2</pagenum>
              <p id="c01-c01-para-0004" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0004">The test continues today in the form of the Loebner Prize, an annual competition in artificial intelligence. The aim is simple enough: Convince the judges that they are chatting to a human instead of a computer chat bot program.</p>
            </level3>
            <level3 id="level3_000002">
              <h3 xml:space="preserve" id="h3_000002" smilref="Machine_Learning00001.smil#h3_000002">Arthur Samuel</h3>
              <p xml:space="preserve" id="p_000005" smilref="Machine_Learning00001.smil#p_000005">In 1959, Arthur Samuel defined machine learning as, “[A] Field of study that gives computers the ability to learn without being explicitly programmed.” Samuel is credited with creating one of the self-learning computer programs with his work at IBM. He focused on games as a way of getting the computer to learn things.</p>
              <p id="c01-c01-para-0006" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0006">The game of choice for Samuel was checkers because it is a simple game but requires strategy from which the program could learn. With the use of alpha-beta evaluation pruning (eliminating nodes that do not need evaluating) and minimax (minimizing the loss for the worst case) strategies, the program would discount moves and thus improve costly memory performance of the program.</p>
              <p id="c01-c01-para-0007" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0007">Samuel is widely known for his work in artificial intelligence, but he was also noted for being one of the first programmers to use hash tables, and he certainly made a big impact at IBM.</p>
            </level3>
            <level3 id="level3_000003">
              <h3 xml:space="preserve" id="h3_000003" smilref="Machine_Learning00001.smil#h3_000003">Tom M. Mitchell</h3>
              <p xml:space="preserve" id="p_000006"><span class="text" id="span_000003" smilref="Machine_Learning00001.smil#span_000003">Tom M. Mitchell is the Chair of Machine Learning at Carnegie Mellon University. As author of the book </span><em id="em_000001" smilref="Machine_Learning00001.smil#em_000001">Machine Learning</em><span class="text" id="span_000004" smilref="Machine_Learning00001.smil#span_000004"> (McGraw-Hill, 1997), his definition of machine learning is often quoted:</span></p>
              <blockquote id="blockquote_000001">
                <p xml:space="preserve" id="p_000007" smilref="Machine_Learning00001.smil#p_000007">A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with the experience E.</p>
              </blockquote>
              <p id="c01-c01-para-0010" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0010">The important thing here is that you now have a set of objects to define machine learning:</p>
              <list type="ul" id="list_000022">
                <li id="li_000263" smilref="Machine_Learning00001.smil#li_000263">Task (T), either one or more</li>
                <li id="li_000264" smilref="Machine_Learning00001.smil#li_000264">Experience (E)</li>
                <li id="li_000265" smilref="Machine_Learning00001.smil#li_000265">Performance (P)</li>
              </list>
              <p id="c01-c01-para-0011" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0011">So, with a computer running a set of tasks, the experience should be leading to performance increases.</p>
            </level3>
            <level3 id="level3_000004">
              <h3 xml:space="preserve" id="h3_000004" smilref="Machine_Learning00001.smil#h3_000004">Summary Definition</h3>
              <p xml:space="preserve" id="p_000008"><em id="em_000002" smilref="Machine_Learning00001.smil#em_000002">Machine learning</em><span class="text" id="span_000005" smilref="Machine_Learning00001.smil#span_000005"> is a branch of artificial intelligence. Using computing, we design systems that can learn from data in a manner of being trained. The systems might learn and improve with experience, and with time, refine a model that can be used to predict outcomes of questions based on the previous learning.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000004">
            <h2 id="c01-c01_level1_2" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_2">Algorithm Types for Machine Learning</h2>
            <pagenum epub:type="pagebreak" id="p3" page="normal" smilref="Machine_Learning00001.smil#p3">3</pagenum>
            <p xml:space="preserve" id="p_000009" smilref="Machine_Learning00001.smil#p_000009">There are a number of different algorithms that you can employ in machine learning. The required output is what decides which to use. As you work through the chapters, you'll see the different algorithm types being put to work. Machine learning algorithms characteristically fall into one of two learning types: supervised or unsupervised learning.</p>
            <level3 id="level3_000005">
              <h3 xml:space="preserve" id="h3_000005" smilref="Machine_Learning00001.smil#h3_000005">Supervised Learning</h3>
              <p xml:space="preserve" id="p_000010"><em id="em_000003" smilref="Machine_Learning00001.smil#em_000003">Supervised learning</em><span class="text" id="span_000006" smilref="Machine_Learning00001.smil#span_000006"> refers to working with a set of labeled training data. For every example in the training data you have an input object and an output object. An example would be classifying Twitter data. (Twitter data is used a lot in the later chapters of the book.) Assume you have the following data from Twitter; these would be your input data objects:</span></p>
              <p xml:space="preserve" id="p_000011"><code class="preserve-whitespace" xml:space="preserve" id="code_000002" smilref="Machine_Learning00001.smil#code_000002">Really loving the new St Vincent album!
#fashion I'm selling my Louboutins! Who's interested? #louboutins
I've got my Hadoop cluster working on a load of data. #data</code></p>
              <p id="c01-c01-para-0015" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0015">In order for your supervised learning classifier to know the outcome result of each tweet, you have to manually enter the answers; for clarity, I've added the resulting output object at the start of each line.</p>
              <p xml:space="preserve" id="p_000012"><code class="preserve-whitespace" xml:space="preserve" id="code_000003" smilref="Machine_Learning00001.smil#code_000003">music    Really loving the new St Vincent album!
clothing    #fashion I'm selling my Louboutins! Who's interested? #louboutins
bigdata    I've got my Hadoop cluster working on a load of data. #data</code></p>
              <p id="c01-c01-para-0016" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0016">Obviously, for the classifier to make any sense of the data, when run properly, you have to work manually on a lot more input data. What you have, though, is a training set that can be used for later classification of data.</p>
              <p id="c01-c01-para-0017" xml:space="preserve"><span class="text" id="span_000007" smilref="Machine_Learning00001.smil#span_000007">There are issues with supervised learning that must be taken into account. The </span><em id="em_000004" smilref="Machine_Learning00001.smil#em_000004">bias-variance dilemma</em><span class="text" id="span_000008" smilref="Machine_Learning00001.smil#span_000008"> is one of them: how the machine learning model performs accurately using different training sets. High bias models contain restricted learning sets, whereas high variance models learn with complexity against noisy training data. There's a trade-off between the two models. The key is where to settle with the trade-off and when to apply which type of model.</span></p>
            </level3>
            <level3 id="level3_000006">
              <h3 xml:space="preserve" id="h3_000006" smilref="Machine_Learning00001.smil#h3_000006">Unsupervised Learning</h3>
              <p xml:space="preserve" id="p_000013" smilref="Machine_Learning00001.smil#p_000013">On the opposite end of this spectrum is unsupervised learning, where you let the algorithm find a hidden pattern in a load of data. With unsupervised learning there is no right or wrong answer; it's just a case of running the machine learning algorithm and seeing what patterns and outcomes occur.</p>
              <pagenum epub:type="pagebreak" id="p4" page="normal" smilref="Machine_Learning00001.smil#p4">4</pagenum>
              <p id="c01-c01-para-0019" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0019">Unsupervised learning might be more a case of data mining than of actual learning. If you're looking at clustering data, then there's a good chance you're going to spend a lot of time with unsupervised learning in comparison to something like artificial neural networks, which are trained prior to being used.</p>
            </level3>
          </level2>
          <level2 id="level2_000005">
            <h2 id="c01-c01_level1_3" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_3">The Human Touch</h2>
            <p xml:space="preserve" id="p_000014" smilref="Machine_Learning00001.smil#p_000014">Outcomes will change, data will change, and requirements will change. Machine learning cannot be seen as a write-it-once solution to problems. Also, it requires human hands and intuition to write these algorithms. Remember that Arthur Samuel's checkers program basically improved on what the human had already taught it. The computer needed a human to get it started, and then it built on that basic knowledge. It's important that you remember that.</p>
            <p id="c01-c01-para-0021" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0021">Throughout this book I talk about the importance of knowing what question you are trying to answer. The question is the cornerstone of any data project, and it starts with having open discussions and planning. (Read more about this in Chapter 2, “Planning for Machine Learning.”)</p>
            <p id="c01-c01-para-0022" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0022">It's only in rare circumstances that you can throw data at a machine learning routine and have it start to provide insight immediately.</p>
          </level2>
          <level2 id="level2_000006">
            <h2 id="c01-c01_level1_4" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_4">Uses for Machine Learning</h2>
            <p xml:space="preserve" id="p_000015" smilref="Machine_Learning00001.smil#p_000015">So, what can you do with machine learning? Quite a lot, really. This section breaks things down and describes how machine learning is being used at the moment.</p>
            <level3 id="level3_000007">
              <h3 xml:space="preserve" id="h3_000007" smilref="Machine_Learning00001.smil#h3_000007">Software</h3>
              <p xml:space="preserve" id="p_000016" smilref="Machine_Learning00001.smil#p_000016">Machine learning is widely used in software to enable an improved experience with the user. With some packages, the software is learning about the user's behavior after its first use. After the software has been in use for a period of time it begins to predict what the user wants to do.</p>
              <level4 id="level4_000001">
                <h4 xml:space="preserve" id="h4_000001" smilref="Machine_Learning00001.smil#h4_000001">Spam Detection</h4>
                <p xml:space="preserve" id="p_000017" smilref="Machine_Learning00001.smil#p_000017">For all the junk mail that gets caught, there's a good chance a Bayesian classification filter is doing the work to catch it. Since the early days of SpamAssassin to Google's work in Google Mail, there's been some form of learning to figure out whether a message is good or bad.</p>
                <p id="c01-c01-para-0026" xml:space="preserve"><span class="text" id="span_000009" smilref="Machine_Learning00001.smil#span_000009">Spam detection is one of the classic uses of machine learning, and over time the algorithms have gotten better and better. Think about the e-mail program </span><pagenum epub:type="pagebreak" id="p5" page="normal" smilref="Machine_Learning00001.smil#p5">5</pagenum><span class="text" id="span_000010" smilref="Machine_Learning00001.smil#span_000010">that you use. When it sees a message it thinks is junk, it asks you to confirm whether it is junk or isn't. If you decide that the message is spam, the system learns from that message and from the experience. Future messages will, hopefully, be treated correctly from then on.</span></p>
              </level4>
              <level4 id="level4_000002">
                <h4 xml:space="preserve" id="h4_000002" smilref="Machine_Learning00001.smil#h4_000002">Voice Recognition</h4>
                <p xml:space="preserve" id="p_000018" smilref="Machine_Learning00001.smil#p_000018">Apple's Siri service that is on many iOS devices is another example of software machine learning. You ask Siri a question, and it works out what you want to do. The result might be sending a tweet or a text message, or it could be setting a calendar appointment. If Siri can't work out what you're asking of it, it performs a Google search on the phrase you said.</p>
                <p id="c01-c01-para-0028" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0028">Siri is an impressive service that uses a device and cloud-based statistical model to analyze your phrase and the order of the words in it to come up with a resulting action for the device to perform.</p>
              </level4>
            </level3>
            <level3 id="level3_000008">
              <h3 xml:space="preserve" id="h3_000008" smilref="Machine_Learning00001.smil#h3_000008">Stock Trading</h3>
              <p xml:space="preserve" id="p_000019" smilref="Machine_Learning00001.smil#p_000019">There are lots of platforms that aim to help users make better stock trades. These platforms have to do a large amount of analysis and computation to make recommendations. From a machine learning perspective, decisions are being made for you on whether to buy or sell a stock at the current price. It takes into account the historical opening and closing prices and the buy and sell volumes of that stock.</p>
              <p id="c01-c01-para-0030" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0030">With four pieces of information (the low and high prices plus the daily opening and closing prices) a machine learning algorithm can learn trends for the stock. Apply this with all stocks in your portfolio, and you have a system to aid you in the decision whether to buy or sell.</p>
              <p id="c01-c01-para-0031" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0031">Bitcoins are a good example of algorithmic trading at work; the virtual coins are bought and sold based on the price the market is willing to pay and the price at which existing coin owners are willing to sell.</p>
              <p id="c01-c01-para-0032" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0032">The media is interested in the high-speed variety of algorithmic trading. The ability to perform many thousands of trades each second based on algorithmic prediction is a very compelling story. A huge amount of money is poured into these systems and how close they can get the machinery to the main stock trading exchanges. Milliseconds of network latency can cost the trading house millions in trades if they aren't placed in time.</p>
              <p id="c01-c01-para-0033" xml:space="preserve"><span class="text" id="span_000011" smilref="Machine_Learning00001.smil#span_000011">About 70 percent of trades are performed by machine and not by humans on the trading floor. This is all very well when things are going fine, but when a problem occurs it can be minutes before the fault is noticed, by which time many trades have happened. The flash crash in May 2010, when the Dow Jones </span><pagenum epub:type="pagebreak" id="p6" page="normal" smilref="Machine_Learning00001.smil#p6">6</pagenum><span class="text" id="span_000012" smilref="Machine_Learning00001.smil#span_000012">industrial average dove 600 points, is a good example of when this problem occurred.</span></p>
            </level3>
            <level3 id="level3_000009">
              <h3 xml:space="preserve" id="h3_000009" smilref="Machine_Learning00001.smil#h3_000009">Robotics</h3>
              <p xml:space="preserve" id="p_000020" smilref="Machine_Learning00001.smil#p_000020">Using machine learning, robots can acquire skills or learn to adapt to the environment in which they are working. Robots can acquire skills such as object placement, grasping objects, and locomotion skills through either automated learning or learning via human intervention.</p>
              <p id="c01-c01-para-0035" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0035">With the increasing amount of sensors within robotics, other algorithms could be employed outside of the robot for further analysis.</p>
            </level3>
            <level3 id="level3_000010">
              <h3 xml:space="preserve" id="h3_000010" smilref="Machine_Learning00001.smil#h3_000010">Medicine and Healthcare</h3>
              <p xml:space="preserve" id="p_000021" smilref="Machine_Learning00001.smil#p_000021">The race is on for machine learning to be used in healthcare analytics. A number of startups are looking at the advantages of using machine learning with Big Data to provide healthcare professionals with better-informed data to enable them to make better decisions.</p>
              <p id="c01-c01-para-0037" xml:space="preserve"><span class="text" id="span_000013" smilref="Machine_Learning00001.smil#span_000013">IBM's famed Watson supercomputer, once used to win the television quiz program </span><em id="em_000005" smilref="Machine_Learning00001.smil#em_000005">Jeopardy</em><span class="text" id="span_000014" smilref="Machine_Learning00001.smil#span_000014"> against two human contestants, is being used to help doctors. Using Watson as a service on the cloud, doctors can access learning on millions of pages of medical research and hundreds of thousands of pieces of information on medical evidence.</span></p>
              <p id="c01-c01-para-0038" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0038">With the number of consumers using smartphones and the related devices for collating a range of health information—such as weight, heart rate, pulse, pedometers, blood pressure, and even blood glucose levels—it's now possible to track and trace user health regularly and see patterns in dates and times. Machine learning systems can recommend healthier alternatives to the user via the device.</p>
              <p id="c01-c01-para-0039" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0039">Although it's easy enough to analyze data, protecting the privacy of user health data is another story. Obviously, some users are more concerned about how their data is used, especially in the case of it being sold to third-party companies. The increased volume of analytics in healthcare and medicine is new, but the privacy debate will be the deciding factor about how the algorithms will ultimately be used.</p>
            </level3>
            <level3 id="level3_000011">
              <h3 xml:space="preserve" id="h3_000011" smilref="Machine_Learning00001.smil#h3_000011">Advertising</h3>
              <p xml:space="preserve" id="p_000022"><span class="text" id="span_000015" smilref="Machine_Learning00001.smil#span_000015">For as long as products have been manufactured and services have been offered, companies have been trying to influence people to buy their products. Since 1995, the Internet has given marketers the chance to advertise directly to our screens without needing television or large print campaigns. Remember the </span><pagenum epub:type="pagebreak" id="p7" page="normal" smilref="Machine_Learning00001.smil#p7">7</pagenum><span class="text" id="span_000016" smilref="Machine_Learning00001.smil#span_000016">thought of cookies being on our computers with the potential to track us? The race to disable cookies from browsers and control who saw our habits was big news at the time.</span></p>
              <p id="c01-c01-para-0041" xml:space="preserve"><em id="em_000006" smilref="Machine_Learning00001.smil#em_000006">Log file analysis</em><span class="text" id="span_000017" smilref="Machine_Learning00001.smil#span_000017"> is another tactic that advertisers use to see the things that interest us. They are able to cluster results and segment user groups according to who may be interested in specific types of products. Couple that with mobile location awareness and you have highly targeted advertisements sent directly to you.</span></p>
              <p id="c01-c01-para-0042" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0042">There was a time when this type of advertising was considered a huge invasion of privacy, but we've gradually gotten use to the idea, and some people are even happy to “check in” at a location and announce their arrival. If you're thinking your friends are the only ones watching, think again. In fact, plenty of companies are learning from your activity. With some learning and analysis, advertisers can do a very good job of figuring out where you'll be on a given day and attempt to push offers your way.</p>
            </level3>
            <level3 id="level3_000012">
              <h3 xml:space="preserve" id="h3_000012" smilref="Machine_Learning00001.smil#h3_000012">Retail and E-Commerce</h3>
              <p xml:space="preserve" id="p_000023" smilref="Machine_Learning00001.smil#p_000023">Machine learning is heavily used in retail, both in e-commerce and bricks-and-mortar retail. At a high level, the obvious use case is the loyalty card. Retailers that issue loyalty cards often struggle to make sense of the data that's coming back to them. Because I worked with one company that analyzes this data, I know the pain that supermarkets go through to get insight.</p>
              <p id="c01-c01-para-0044" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0044">UK supermarket giant Tesco is the leader when it comes to customer loyalty programs. The Tesco Clubcard is used heavily by customers and gives Tesco a great view of customer purchasing decisions. Data is collected from the point of sale (POS) and fed back to a data warehouse. In the early days of the Clubcard, the data couldn't be mined fast enough; there was just too much. As processing methods improved over the years, Tesco and marketing company Dunn Humby have developed a good strategy for understanding customer behavior and shopping habits and encouraging customers to try products similar to their usual choices.</p>
              <p id="c01-c01-para-0045" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0045">An American equivalent is Target, which runs a similar sort of program that tracks every customer engagement with the brand, including mailings, website visits, and even in-store visits. From the data warehouse, Target can fine-tune how to get the right communication method to the right customers in order for them to react to the brand. Target learned that not every customer wants an e-mail or an SMS message; some still prefer receiving mail via the postal service.</p>
              <p id="c01-c01-para-0046" xml:space="preserve"><span class="text" id="span_000018" smilref="Machine_Learning00001.smil#span_000018">The uses for machine learning in retail are obvious: Mining baskets and segmenting users are key processes for communicating the right message to the customer. On the other hand, it can be too accurate and cause headaches. Target's “baby club” story, which was widely cited in the press as a huge privacy </span><pagenum epub:type="pagebreak" id="p8" page="normal" smilref="Machine_Learning00001.smil#p8">8</pagenum><span class="text" id="span_000019" smilref="Machine_Learning00001.smil#span_000019">danger in Big Data, showed us that machine learning can easily determine that we're creatures of habit, and when those habits change they will get noticed.</span></p>
              <sidebar render="required" id="sidebar_000001">
                <div class="top hr" id="div_000001" />
                <level2 class="feature1" id="level2_000007">
                  <h2 xml:space="preserve" id="h2_000005" smilref="Machine_Learning00001.smil#h2_000005">Target's Privacy Issue</h2>
                  <p xml:space="preserve" id="p_000024" smilref="Machine_Learning00001.smil#p_000024">Target's statistician, Andrew Pole, analyzed basket data to see whether he could determine when a customer was pregnant. A select number of products started to show up in the analysis, and Target developed a pregnancy prediction score. Coupons were sent to customers who were predicted to be pregnant according to the newly mined score. That was all very well until the father of a teenage girl contacted his local store to complain about the baby coupons that were being sent to his daughter. It turned out that Target predicted the girl's pregnancy before she had told her father that she was pregnant.</p>
                </level2>
              </sidebar>
              <p id="c01-c01-para-0048" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0048">For all the positive uses of machine learning, there are some urban myths, too. For example, you might have heard the “beer and diapers” story associated with Walmart and other large retailers. The idea is that the sales of beer and diapers both increase on Fridays, suggesting that mothers were going out and dads would stock up on beer for themelves and diapers for the little ones they were looking after. It turned out to be a myth, but this still doesn't stop marketing companies from wheeling out the story (and believing it's true) to organizations who want to learn from their data.</p>
              <p id="c01-c01-para-0049" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0049">Another myth is that the heavy metal band Iron Maiden would mine bit-torrent data to figure out which countries were illegally downloading their songs and then fly to those locations to play concerts. That story got the marketers and media very excited about Big Data and machine learning, but sadly it's untrue. That's not to say that these things can't happen someday; they just haven't happened yet.</p>
            </level3>
            <level3 id="level3_000013">
              <h3 xml:space="preserve" id="h3_000013" smilref="Machine_Learning00001.smil#h3_000013">Gaming Analytics</h3>
              <p xml:space="preserve" id="p_000025" smilref="Machine_Learning00001.smil#p_000025">We've already established that checkers is a good candidate for machine learning. Do you remember those old chess computer games with the real plastic pieces? The human player made a move and then the computer made a move. Well, that's a case of machine learning planning algorithms in action. Fast-forward a few decades (the chess computer still feels like yesterday to me) to today when the console market is pumping out analytics data every time you play your favorite game.</p>
              <p id="c01-c01-para-0051" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0051">Microsoft has spent time studying the data from Halo 3 to see how players perform on certain levels and also to figure out when players are using cheats. Fixes have been created based on the analysis of data coming back from the consoles.</p>
              <pagenum epub:type="pagebreak" id="p9" page="normal" smilref="Machine_Learning00001.smil#p9">9</pagenum>
              <p id="c01-c01-para-0052" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0052">Microsoft also worked on Drivatar, which is incorporated into the driving game Forza Motorsport. When you first play the game, it knows nothing about your driving style. Over a period of practice laps the system learns your style, consistency, exit speeds on corners, and your positioning on the track. The sampling happens over three laps, which is enough time to see how your profile behaves. As time progresses the system continues to learn from your driving patterns. After you've let the game learn your driving style the game opens up new levels and lets you compete with other drivers and even your friends.</p>
              <p id="c01-c01-para-0053" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0053">If you have children, you might have seen the likes of Nintendogs (or cats), a game in which a person is tasked with looking after an on-screen pet. (Think Tamagotchi, but on a larger scale.) Algorithms can work out when the pet needs to play, how to react to the owner, and how hungry the pet is.</p>
              <p id="c01-c01-para-0054" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0054">It's still the early days of game companies putting machine learning into infrastructure to make the games better. With more and more games appearing on small devices, such as those with the iOS and Android platforms, the real learning is in how to make players come back and play more and more. Analysis can be performed about the “stickiness” of the game—do players return to play again or do they drop off over a period of time in favor of something else? Ultimately there's a trade-off between the level of machine learning and gaming performance, especially in smaller devices. Higher levels of machine learning require more memory within the device. Sometimes you have to factor in the limit of what you can learn from within the game.</p>
            </level3>
            <level3 id="level3_000014">
              <h3 xml:space="preserve" id="h3_000014" smilref="Machine_Learning00001.smil#h3_000014">The Internet of Things</h3>
              <p xml:space="preserve" id="p_000026" smilref="Machine_Learning00001.smil#p_000026">Connected devices that can collate all manner of data are sprouting up all over the place. Device-to-device communication is hardly new, but it hadn't really hit the public minds until fairly recently. With the low cost of manufacture and distribution, now devices are being used in the home just as much as they are in industry.</p>
              <p id="c01-c01-para-0056" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0056">Uses include home automation, shopping, and smart meters for measuring energy consumption. These things are in their infancy, and there's still a lot of concern on the security aspects of these devices. In the same way mobile device location is a concern, companies can pinpoint devices by their unique IDs and eventually associate them to a user.</p>
              <p id="c01-c01-para-0057" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0057">On the plus side, the data is so rich that there's plenty of opportunity to put machine learning in the heart of the data and learn from the devices' output. This may be as simple as monitoring a house to sense ambient temperature—for example, is it too hot or too cold?</p>
              <p id="c01-c01-para-0058" xml:space="preserve"><span class="text" id="span_000020" smilref="Machine_Learning00001.smil#span_000020">It's very early days for the Internet of things, but there's a lot of groundwork happening that is leading to some interesting outcomes. With the likes of Arduino and Raspberry Pi computers, it's relatively cheap to get started measuring the </span><pagenum epub:type="pagebreak" id="p10" page="normal" smilref="Machine_Learning00001.smil#p10">10</pagenum><span class="text" id="span_000021" smilref="Machine_Learning00001.smil#span_000021">likes of motion, temperature, and sound and then extracting the data for analysis, either after it's been collated or in real time.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000008">
            <h2 id="c01-c01_level1_5" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_5">Languages for Machine Learning</h2>
            <p xml:space="preserve" id="p_000027" smilref="Machine_Learning00001.smil#p_000027">This book uses the Java programming language for the working examples. The reasons are simple: It's a widely used language, and the libraries are well supported. Java isn't the only language to be used for machine learning—far from it. If you're working for an existing organization, you may be restricted to the languages used within it.</p>
            <p id="c01-c01-para-0060" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0060">With most languages, there is a lot of crossover in functionality. With the languages that access the Java Virtual Machine (JVM) there's a good chance that you'll be accessing Java-based libraries. There's no such thing as one language being “better” than another. It's a case of picking the right tool for the job. The following sections describe some of the other languages that you can use for machine learning.</p>
            <level3 id="level3_000015">
              <h3 xml:space="preserve" id="h3_000015" smilref="Machine_Learning00001.smil#h3_000015">Python</h3>
              <p xml:space="preserve" id="p_000028" smilref="Machine_Learning00001.smil#p_000028">The Python language has increased in usage, because it's easy to learn and easy to read. It also has some good machine learning libraries, such as scikit-learn, PyML, and pybrain. Jython was developed as a Python interpreter for the JVM, which may be worth investigating.</p>
            </level3>
            <level3 id="level3_000016">
              <h3 xml:space="preserve" id="h3_000016" smilref="Machine_Learning00001.smil#h3_000016">R</h3>
              <p xml:space="preserve" id="p_000029" smilref="Machine_Learning00001.smil#p_000029">R is an open source statistical programming language. The syntax is not the easiest to learn, but I do encourage you to have a look at it. It also has a large number of machine learning packages and visualization tools. The RJava project allows Java programmers to access R functions from Java code. For a basic introduction to R, have a look at Chapter 12.</p>
            </level3>
            <level3 id="level3_000017">
              <h3 xml:space="preserve" id="h3_000017" smilref="Machine_Learning00001.smil#h3_000017">Matlab</h3>
              <p xml:space="preserve" id="p_000030" smilref="Machine_Learning00001.smil#p_000030">The Matlab language is used widely within academia for technical computing and algorithm creation. Like R, it also has a facility for plotting visualizations and graphs.</p>
            </level3>
            <level3 id="level3_000018">
              <h3 xml:space="preserve" id="h3_000018" smilref="Machine_Learning00001.smil#h3_000018">Scala</h3>
              <p xml:space="preserve" id="p_000031"><span class="text" id="span_000022" smilref="Machine_Learning00001.smil#span_000022">A new breed of languages is emerging that takes advantage of Java's runtime environment, which potentially increases performance, based on the threading </span><pagenum epub:type="pagebreak" id="p11" page="normal" smilref="Machine_Learning00001.smil#p11">11</pagenum><span class="text" id="span_000023" smilref="Machine_Learning00001.smil#span_000023">architecture of the platform. Scala (which is an acronym for </span><em id="em_000007" smilref="Machine_Learning00001.smil#em_000007">Sca</em><span class="text" id="span_000024" smilref="Machine_Learning00001.smil#span_000024">lable </span><em id="em_000008" smilref="Machine_Learning00001.smil#em_000008">La</em><span class="text" id="span_000025" smilref="Machine_Learning00001.smil#span_000025">nguage) is one of these, and it is being widely used by a number of startups.</span></p>
              <p id="c01-c01-para-0065" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0065">There are machine learning libraries, such as ScalaNLP, but Scala can access Java jar files, and it can also implement the likes of Classifier4J and Mahout, which are covered in this book. It's also core to the Apache Spark project, which is covered in Chapter 11.</p>
            </level3>
            <level3 id="level3_000019">
              <h3 xml:space="preserve" id="h3_000019" smilref="Machine_Learning00001.smil#h3_000019">Clojure</h3>
              <p xml:space="preserve" id="p_000032" smilref="Machine_Learning00001.smil#p_000032">Another JVM-based language, Clojure, is based on the Lisp programming language. It's designed for concurrency, which makes it a great candidate for machine learning applications on large sets of data.</p>
            </level3>
            <level3 id="level3_000020">
              <h3 xml:space="preserve" id="h3_000020" smilref="Machine_Learning00001.smil#h3_000020">Ruby</h3>
              <p xml:space="preserve" id="p_000033" smilref="Machine_Learning00001.smil#p_000033">Many people know about the Ruby language by association with the Ruby On Rails web development framework, but it's also used as a standalone language. The best way to integrate machine learning frameworks is to look at JRuby, which is a JVM-based alternative that enables you to access the Java machine learning libraries.</p>
            </level3>
          </level2>
          <level2 id="level2_000009">
            <h2 id="c01-c01_level1_6" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_6">Software Used in This Book</h2>
            <p xml:space="preserve" id="p_000034" smilref="Machine_Learning00001.smil#p_000034">The hands-on elements in the book use a number of programs and packages to get the algorithms and machine learning working.</p>
            <p id="c01-c01-para-0069" xml:space="preserve"><span class="text" id="span_000026" smilref="Machine_Learning00001.smil#span_000026">To keep things easy, I strongly advise that you create a directory on your system to install all these packages. I'm going to call mine </span><code xml:space="preserve" id="code_000004" smilref="Machine_Learning00001.smil#code_000004">mlbook</code><span class="text" id="span_000027" smilref="Machine_Learning00001.smil#span_000027">:</span></p>
            <p xml:space="preserve" id="p_000035"><code class="preserve-whitespace" xml:space="preserve" id="code_000005" smilref="Machine_Learning00001.smil#code_000005">$mkdir ˜/mlbook
$cd ˜/mlbook</code></p>
            <level3 id="level3_000021">
              <h3 xml:space="preserve" id="h3_000021" smilref="Machine_Learning00001.smil#h3_000021">Checking the Java Version</h3>
              <p xml:space="preserve" id="p_000036" smilref="Machine_Learning00001.smil#p_000036">As the programs used in the book rely on Java, you need to quickly check the version of Java that you're using. The programs require Java 1.6 or later. To check your version, open a terminal window and run the following:</p>
              <p xml:space="preserve" id="p_000037"><code class="preserve-whitespace" xml:space="preserve" id="code_000006" smilref="Machine_Learning00001.smil#code_000006">$ java -version
java version "1.7.0_40"
Java(TM) SE Runtime Environment (build 1.7.0_40-b43)
Java HotSpot(TM) 64-Bit Server VM (build 24.0-b56, mixed mode)</code></p>
              <p id="c01-c01-para-0071" xml:space="preserve"><span class="text" id="span_000028" smilref="Machine_Learning00001.smil#span_000028">If you are running a version older than 1.6, then you need to upgrade your Java version. You can download the current version from </span><code xml:space="preserve" id="code_000007"><a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" external="true" id="a_000264" smilref="Machine_Learning00001.smil#a_000264">www.oracle.com/technetwork/java/javase/downloads/index.html</a></code><span class="text" id="span_000029" smilref="Machine_Learning00001.smil#span_000029">.</span></p>
            </level3>
            <level3 id="level3_000022">
              <h3 xml:space="preserve" id="h3_000022" smilref="Machine_Learning00001.smil#h3_000022">Weka Toolkit</h3>
              <pagenum epub:type="pagebreak" id="p12" page="normal" smilref="Machine_Learning00001.smil#p12">12</pagenum>
              <p xml:space="preserve" id="p_000038" smilref="Machine_Learning00001.smil#p_000038">Weka (Waikato Environment for Knowledge Acquisition) is a machine learning and data mining toolkit written in Java by the University of Waikato in New Zealand. It provides a suite of tools for learning and visualization via the supplied workbench program or the command line. Weka also enables you to retrieve data from existing data sources that have a JDBC driver. With Weka you can do the following:</p>
              <list type="ul" id="list_000023">
                <li id="li_000266" smilref="Machine_Learning00001.smil#li_000266">Preprocessing data</li>
                <li id="li_000267" smilref="Machine_Learning00001.smil#li_000267">Clustering</li>
                <li id="li_000268" smilref="Machine_Learning00001.smil#li_000268">Classification</li>
                <li id="li_000269" smilref="Machine_Learning00001.smil#li_000269">Regression</li>
                <li id="li_000270" smilref="Machine_Learning00001.smil#li_000270">Association rules</li>
              </list>
              <p id="c01-c01-para-0073" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0073">The Weka toolkit is widely used and now supports the Big Data aspects by interfacing with Hadoop for clustered data mining.</p>
              <pagenum epub:type="pagebreak" id="p13" page="normal" smilref="Machine_Learning00001.smil#p13">13</pagenum>
              <p id="c01-c01-para-0074" xml:space="preserve"><span class="text" id="span_000030" smilref="Machine_Learning00001.smil#span_000030">You can download Weka from the University of Waikato website at </span><code xml:space="preserve" id="code_000008"><a href="http://www.cs.waikato.ac.nz/ml/weka/downloading.html" external="true" id="a_000265" smilref="Machine_Learning00001.smil#a_000265">www.cs.waikato.ac.nz/ml/weka/downloading.html</a></code><span class="text" id="span_000031" smilref="Machine_Learning00001.smil#span_000031">. There are versions of Weka available for Linux, Mac OSX, and Windows. To install Weka on Linux, you just need to unzip the supplied file to a directory. On Mac OSX and Windows, an installer program is supplied that will unzip all the required files for you.</span></p>
            </level3>
            <level3 id="level3_000023">
              <h3 xml:space="preserve" id="h3_000023" smilref="Machine_Learning00001.smil#h3_000023">Mahout</h3>
              <p xml:space="preserve" id="p_000039"><span class="text" id="span_000032" smilref="Machine_Learning00001.smil#span_000032">The Mahout machine learning libraries are an open source project that are part of the Apache project. The key feature of Mahout is its </span><em id="em_000009" smilref="Machine_Learning00001.smil#em_000009">scalability</em><span class="text" id="span_000033" smilref="Machine_Learning00001.smil#span_000033">; it works either on a single node or a cluster of machines. It has tight integration with the Hadoop Map/Reduce paradigm to enable large-scale processing.</span></p>
              <p id="c01-c01-para-0076" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0076">Mahout supports a number of algorithms including</p>
              <list type="ul" id="list_000024">
                <li id="li_000271" smilref="Machine_Learning00001.smil#li_000271">Naive Bayes Classifier</li>
                <li id="li_000272" smilref="Machine_Learning00001.smil#li_000272">K Means Clustering</li>
                <li id="li_000273" smilref="Machine_Learning00001.smil#li_000273">Recommendation Engines</li>
                <li id="li_000274" smilref="Machine_Learning00001.smil#li_000274">Random Forest Decision Trees</li>
                <li id="li_000275" smilref="Machine_Learning00001.smil#li_000275">Logistic Regression Classifier</li>
              </list>
              <p id="c01-c01-para-0077" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0077">There's no workbench in Mahout like there is in the Weka toolkit, but the emphasis is on integrating machine learning library code within your projects. There are a wealth of examples and ready-to-run programs that can be used with your existing data.</p>
              <p id="c01-c01-para-0078" xml:space="preserve"><span class="text" id="span_000034" smilref="Machine_Learning00001.smil#span_000034">You can download Mahout from </span><code xml:space="preserve" id="code_000009"><a href="http://www.apache.org/dyn/closer.cgi/mahout/" external="true" id="a_000266" smilref="Machine_Learning00001.smil#a_000266">www.apache.org/dyn/closer.cgi/mahout/</a></code><span class="text" id="span_000035" smilref="Machine_Learning00001.smil#span_000035">. As Mahout is platform independent, there's one download that covers all the operating systems. To install the download, all you have to do is unzip Mahout into a directory and update your path to find the executable files.</span></p>
            </level3>
            <level3 id="level3_000024">
              <h3 xml:space="preserve" id="h3_000024" smilref="Machine_Learning00001.smil#h3_000024">SpringXD</h3>
              <p xml:space="preserve" id="p_000040" smilref="Machine_Learning00001.smil#p_000040">Whereas Weka and Mahout concentrate on algorithms and producing the knowledge you need, you must also think about acquiring and processing data.</p>
              <p id="c01-c01-para-0080" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0080">Spring XD is a “data ingestion engine” that reads in, processes, and stores raw data. It's highly customizable with the ability to create processing units. It also integrates with all the other tools mentioned in this chapter.</p>
              <p id="c01-c01-para-0081" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0081">Spring XD is relatively new, but it's certainly useful. It not only relates to Internet-based data, it can also ingest network and system messages across a cluster of machines.</p>
              <p id="c01-c01-para-0082" xml:space="preserve"><span class="text" id="span_000036" smilref="Machine_Learning00001.smil#span_000036">You can download the Spring XD distribution from </span><code xml:space="preserve" id="code_000010"><a href="http://projects.spring.io/spring-xd/" external="true" id="a_000267" smilref="Machine_Learning00001.smil#a_000267">http://projects.spring.io/spring-xd/</a></code><span class="text" id="span_000037" smilref="Machine_Learning00001.smil#span_000037">. The link for the zip file is in the Quick Start section.</span></p>
              <p id="c01-c01-para-0083" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0083">After the zip file has downloaded you need to unzip the distribution into a directory. For a detailed walkthrough of using Spring XD, read Chapter 9, “Machine Learning in Real Time with Spring XD.”</p>
            </level3>
            <level3 id="level3_000025">
              <h3 xml:space="preserve" id="h3_000025" smilref="Machine_Learning00001.smil#h3_000025">Hadoop</h3>
              <p xml:space="preserve" id="p_000041" smilref="Machine_Learning00001.smil#p_000041">Unless you've been living on some secluded island without power and an Internet connection, you will have heard about the savior of Big Data: Hadoop. Hadoop is very good for processing Big Data, but it's not a required tool. In this book, it comes into play in Chapter 10, “Machine Learning as a Batch Process.”</p>
              <p id="c01-c01-para-0085" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0085">Hadoop is a framework for processing data in parallel. It does this using the MapReduce pattern, where work is divided into blocks and is distributed across a cluster of machines. You can use Hadoop on a single machine with success; that's what this book covers.</p>
              <p id="c01-c01-para-0086" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0086">There are two versions of Hadoop. This book uses version 1.2.1.</p>
              <p id="c01-c01-para-0087" xml:space="preserve"><span class="text" id="span_000038" smilref="Machine_Learning00001.smil#span_000038">The Apache Foundation runs a series of mirror download servers and refers you to the ones relevant to your location. The main download page is at </span><code xml:space="preserve" id="code_000011"><a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" external="true" id="a_000268" smilref="Machine_Learning00001.smil#a_000268">www.apache.org/dyn/closer.cgi/hadoop/common/</a></code><span class="text" id="span_000039" smilref="Machine_Learning00001.smil#span_000039">.</span></p>
              <p id="c01-c01-para-0088" xml:space="preserve"><span class="text" id="span_000040" smilref="Machine_Learning00001.smil#span_000040">After you have picked your mirror site, navigate your way to hadoop-1.2.1 releases and download </span><code xml:space="preserve" id="code_000012" smilref="Machine_Learning00001.smil#code_000012">hadoop-1.2.1-bin.tar.gz</code><span class="text" id="span_000041" smilref="Machine_Learning00001.smil#span_000041">. Unzip and untar the distribution to a directory.</span></p>
              <p id="c01-c01-para-0089" xml:space="preserve"><span class="text" id="span_000042" smilref="Machine_Learning00001.smil#span_000042">If you are running a Red Hat or Debian server, you can download the respective </span><code xml:space="preserve" id="code_000013" smilref="Machine_Learning00001.smil#code_000013">.rpm</code><span class="text" id="span_000043" smilref="Machine_Learning00001.smil#span_000043"> or </span><code xml:space="preserve" id="code_000014" smilref="Machine_Learning00001.smil#code_000014">.deb</code><span class="text" id="span_000044" smilref="Machine_Learning00001.smil#span_000044"> files and install them via the package installer for your operating system. If preferred, Debian and Ubuntu users can install Hadoop with the </span><code xml:space="preserve" id="code_000015" smilref="Machine_Learning00001.smil#code_000015">apt-get</code><span class="text" id="span_000045" smilref="Machine_Learning00001.smil#span_000045"> or </span><code xml:space="preserve" id="code_000016" smilref="Machine_Learning00001.smil#code_000016">yum</code><span class="text" id="span_000046" smilref="Machine_Learning00001.smil#span_000046"> command.</span></p>
            </level3>
            <level3 id="level3_000026">
              <h3 xml:space="preserve" id="h3_000026" smilref="Machine_Learning00001.smil#h3_000026">Using an IDE</h3>
              <pagenum epub:type="pagebreak" id="p14" page="normal" smilref="Machine_Learning00001.smil#p14">14</pagenum>
              <p xml:space="preserve" id="p_000042" smilref="Machine_Learning00001.smil#p_000042">Some discussions seem to spark furious debate in certain circles—for example, favorite actor/actress, best football team, and best integrated development environment (IDE).</p>
              <p id="c01-c01-para-0091" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0091">I'm an Eclipse user. I'm also an IDEA user, and I have NetBeans as well. Basically, I use all three. There's no hard rule that IDE you should use, as they all do the same thing very well. The examples in this book use Eclipse (Juno release).</p>
            </level3>
          </level2>
          <level2 id="level2_000010">
            <h2 id="c01-c01_level1_7" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_7">Data Repositories</h2>
            <p xml:space="preserve" id="p_000043" smilref="Machine_Learning00001.smil#p_000043">One question that comes up again and again in my classes is “Where can I get data?” There are a few answers to this question, but the best answer depends on what you are trying to learn.</p>
            <p id="c01-c01-para-0093" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0093">Data comes in all shapes and sizes, which is something discussed further in the next chapter. I strongly suggest that you take some time to hunt around the Internet for different data sets and look through them. You'll get a feel for how these things are put together. Sometimes you'll find comma separated variable (CSV) data, or you might find JSON or XML data.</p>
            <p id="c01-c01-para-0094" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0094">Remember, some of the best learning comes from playing with the data. Having a question in mind that you are trying to answer with the data is a good start (and something you will see me refer to a number of times in this book), but learning comes from experimentation and improvement on results. So, I'm all for playing around with the data first and seeing what works. I hail from a very pragmatic background when it comes to development and learning. Although the majority of publications about machine learning have come from people with academic backgrounds—and I fully endorse and support them—we shouldn't discourage learning by doing.</p>
            <p id="c01-c01-para-0095" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0095">The following sections describe some places where you can get plenty of data with which to play.</p>
            <level3 id="level3_000027">
              <h3 xml:space="preserve" id="h3_000027" smilref="Machine_Learning00001.smil#h3_000027">UC Irvine Machine Learning Repository</h3>
              <p xml:space="preserve" id="p_000044"><span class="text" id="span_000047" smilref="Machine_Learning00001.smil#span_000047">This machine learning repository consists of more than 270 data sets. Included in these sets are notes on the variable name, instances, and tasks the data would be associated with. You can find this repository at </span><code xml:space="preserve" id="code_000017"><a href="http://archive.ics.uci.edu/ml/datasets" external="true" id="a_000269" smilref="Machine_Learning00001.smil#a_000269">http://archive.ics.uci.edu/ml/datasets</a></code><span class="text" id="span_000048" smilref="Machine_Learning00001.smil#span_000048">.</span></p>
            </level3>
            <level3 id="level3_000028">
              <h3 xml:space="preserve" id="h3_000028" smilref="Machine_Learning00001.smil#h3_000028">Infochimps</h3>
              <p xml:space="preserve" id="p_000045"><span class="text" id="span_000049" smilref="Machine_Learning00001.smil#span_000049">The data marketplace at Infochimps has been around for a few years. Although the company has expanded to cloud-based offerings, the data is still available to download at </span><code xml:space="preserve" id="code_000018"><a href="http://www.infochimps.com/datasets" external="true" id="a_000270" smilref="Machine_Learning00001.smil#a_000270">www.infochimps.com/datasets</a></code><span class="text" id="span_000050" smilref="Machine_Learning00001.smil#span_000050">.</span></p>
            </level3>
            <level3 id="level3_000029">
              <h3 xml:space="preserve" id="h3_000029" smilref="Machine_Learning00001.smil#h3_000029">Kaggle</h3>
              <pagenum epub:type="pagebreak" id="p15" page="normal" smilref="Machine_Learning00001.smil#p15">15</pagenum>
              <p xml:space="preserve" id="p_000046"><span class="text" id="span_000051" smilref="Machine_Learning00001.smil#span_000051">The competitions that Kaggle run have gained a lot of interest over the last couple of years. The 101 section on the site offers some data sets with which to experiment. You can find them at </span><code xml:space="preserve" id="code_000019"><a href="http://www.kaggle.com/competitions" external="true" id="a_000271" smilref="Machine_Learning00001.smil#a_000271">www.kaggle.com/competitions</a></code><span class="text" id="span_000052" smilref="Machine_Learning00001.smil#span_000052">.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000011">
            <h2 id="c01-c01_level1_8" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01_level1_8">Summary</h2>
            <p xml:space="preserve" id="p_000047" smilref="Machine_Learning00001.smil#p_000047">This chapter looked at what machine learning is, how it can be applied to different areas of business, and what tools you need to follow along with the remainder of the book.</p>
            <p id="c01-c01-para-0100" xml:space="preserve" smilref="Machine_Learning00001.smil#c01-c01-para-0100">Chapter 2 introduces you to planning for machine learning. It covers data science teams, cleaning, and different methods of processing data.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c02">
        <section epub:type="chapter" id="section_000003">
          <header id="header_000002">
            <h1 id="c02-c2" xml:space="preserve" smilref="Machine_Learning00001.smil#c02-c2">Chapter 2 Planning for Machine Learning</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p17" page="normal" smilref="Machine_Learning00001.smil#p17">17</pagenum>
          <p xml:space="preserve" id="p_000048" smilref="Machine_Learning00001.smil#p_000048">This chapter looks at planning your machine learning projects, storage types, processing options and data input. The chapter also covers data quality and methods to validate and clean data before you do any analysis.</p>
          <level2 id="level2_000012">
            <h2 id="c02-c02_level1_1" xml:space="preserve" smilref="Machine_Learning00001.smil#c02-c02_level1_1">The Machine Learning Cycle</h2>
            <p xml:space="preserve" id="p_000049"><span class="text" id="span_000053" smilref="Machine_Learning00001.smil#span_000053">A machine learning project is basically a cycle of actions that need to be performed. (See </span><a id="c02-c02-fig-anc-0001" href="#c02-c02-fig-0001" external="false" smilref="Machine_Learning00001.smil#c02-c02-fig-anc-0001">Figure 2-1</a><span class="text" id="span_000054" smilref="Machine_Learning00001.smil#span_000054">.)</span></p>
            <figure id="figure_000001">
              <img class="center" src="images/c02f001.jpg" alt="image" id="img_000002" />
              <figcaption id="figcaption_000001">
                <p xml:space="preserve" id="p_000050"><span class="figureLabel" id="span_000055"><a id="c02-c02-fig-0001" href="#c02-c02-fig-anc-0001" external="false"><strong id="strong_000001" smilref="Machine_Learning00001.smil#strong_000001">Figure 2-1</strong></a></span><span class="text" id="span_000056" smilref="Machine_Learning00002.smil#span_000056"> The machine learning process</span></p>
              </figcaption>
            </figure>
            <pagenum epub:type="pagebreak" id="p18" page="normal" smilref="Machine_Learning00002.smil#p18">18</pagenum>
            <p id="c02-c02-para-0003" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0003">You can acquire data from many sources; it might be data that's held by your organization or open data from the Internet. There might be one dataset, or there could be ten or more.</p>
            <p id="c02-c02-para-0004" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0004">You must come to accept that data will need to be cleaned and checked for quality before any processing can take place. These processes occur during the prepare phase.</p>
            <p id="c02-c02-para-0005" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0005">The processing phase is where the work gets done. The machine learning routines that you have created perform this phase.</p>
            <p id="c02-c02-para-0006" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0006">Finally, the results are presented. Reporting can happen in a variety of ways, such as reinvesting the data back into a data store or reporting the results as a spreadsheet or report.</p>
          </level2>
          <level2 id="level2_000013">
            <h2 id="c02-c02_level1_2" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_2">It All Starts with a Question</h2>
            <p xml:space="preserve" id="p_000051" smilref="Machine_Learning00002.smil#p_000051">There seems to be a misconception that machine learning, like Big Data, is a case of throwing enough data at the problem that the answers magically appear. As much as I'd like to say this happens all the time, it doesn't. Machine learning projects start with a question or a hunch that needs investigating. I've encountered this quite a few times in speaking to people about their companies' data ambitions and what they are looking to achieve with the likes of machine learning and Hadoop.</p>
            <p id="c02-c02-para-0008" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0008">Using a whiteboard, sticky notes, or even a sheet of paper, start asking questions like the following:</p>
            <list type="ul" id="list_000025">
              <li id="li_000276" smilref="Machine_Learning00002.smil#li_000276">Is there a correlation between our sales and the weather?</li>
              <li id="li_000277" smilref="Machine_Learning00002.smil#li_000277">Do sales on Saturday and Sunday generate the majority of revenue to the business compared to the other five days of the week?</li>
              <li id="li_000278" smilref="Machine_Learning00002.smil#li_000278">Can we plan what fashions to stock in the next three months by looking at Twitter data for popular hashtags?</li>
              <li id="li_000279" smilref="Machine_Learning00002.smil#li_000279">Can we tell when our customers become pregnant?</li>
            </list>
            <p id="c02-c02-para-0009" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0009">All these examples are reasonable questions, and they also provide the basis for proper discussion. Stakeholders will usually come up with the questions, and then the data project team (which might be one person—you!) can spin into action.</p>
            <p id="c02-c02-para-0010" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0010">Without knowing the question, it's difficult to know where to start. Anyone who thinks the answers just pop out of thin air needs a polite, but firm, explanation of what has to happen for the answers to be discovered.</p>
          </level2>
          <level2 id="level2_000014">
            <h2 id="c02-c02_level1_3" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_3">I Don't Have Data!</h2>
            <pagenum epub:type="pagebreak" id="p19" page="normal" smilref="Machine_Learning00002.smil#p19">19</pagenum>
            <p xml:space="preserve" id="p_000052" smilref="Machine_Learning00002.smil#p_000052">This sounds like a silly statement when you have a book on machine learning in your hands, but sometimes people just don't have the data.</p>
            <p id="c02-c02-para-0012" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0012">In an ideal world, we expect companies to have well-groomed customer relationship management (CRM) systems and neat repositories of data that could be retrieved on a whim and copied nicely into a Hadoop filesystem, so countless MapReduce jobs could run (read more about Hadoop and MapReduce in Chapter 10, “Machine Learning as a Batch Process”).</p>
            <p id="c02-c02-para-0013" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0013">Data comes from a variety of sources. Plenty of open data initiatives are available, so you have a good chance of being able to find some data to work with.</p>
            <level3 id="level3_000030">
              <h3 xml:space="preserve" id="h3_000030" smilref="Machine_Learning00002.smil#h3_000030">Starting Local</h3>
              <p xml:space="preserve" id="p_000053" smilref="Machine_Learning00002.smil#p_000053">Perhaps you could make a difference in your local community; see what data they have open with which you can experiment. New York City has a whole portal of open data with more than 1,100 datasets for citizens to download and learn from. Hackathons and competitions to encourage people to get involved and give back to the community. The results of the hackathons make a difference, because insights about how the local community is run are fed back to the event organizers. If you can't find the dataset you want then you are also encouraged to request it.</p>
            </level3>
            <level3 id="level3_000031">
              <h3 xml:space="preserve" id="h3_000031" smilref="Machine_Learning00002.smil#h3_000031">Competitions</h3>
              <p xml:space="preserve" id="p_000054" smilref="Machine_Learning00002.smil#p_000054">If you fancy a real challenge, then think about entering competitions. One of the most famous was the Netflix Prize, which was a competition to improve the recommendation algorithm for the Netflix film service.</p>
              <p id="c02-c02-para-0016" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0016">Teams who were competing downloaded sample sets of user data and worked on an algorithm to improve the predictions of movies that customers would like. The winning team was the one that improved the results by 10 percent. In 2009, the $1 million prize was awarded to “BellKor's Pragmatic Chaos.” This triggered a new wave of competitions, letting the data out into the open so collaborative teams could improve things.</p>
              <p id="c02-c02-para-0017" xml:space="preserve"><span class="text" id="span_000057" smilref="Machine_Learning00002.smil#span_000057">In 2010, Anthony Goldbloom founded </span><code xml:space="preserve" id="code_000020"><a href="http://Kaggle.com" external="true" id="a_000272" smilref="Machine_Learning00002.smil#a_000272">Kaggle.com</a></code><span class="text" id="span_000058" smilref="Machine_Learning00002.smil#span_000058">, which is a platform for predictive modeling and analytics competitions. Each competition posted has sample datasets and a brief of the desired outcome. Either teams or individuals can enter, and the most effective algorithms, very similar to the Netflix Prize, decided the winner.</span></p>
              <pagenum epub:type="pagebreak" id="p20" page="normal" smilref="Machine_Learning00002.smil#p20">20</pagenum>
              <p id="c02-c02-para-0018" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0018">Is competition effective? It seems to be. Kaggle has more than 100,000 data scientists registered from across the world. Organizations such as Facebook, NASA, GE, Wikipedia, and AllState have used the service to improve their products and even head-hunt top talent.</p>
            </level3>
          </level2>
          <level2 id="level2_000015">
            <h2 id="c02-c02_level1_4" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_4">One Solution Fits All?</h2>
            <p xml:space="preserve" id="p_000055" smilref="Machine_Learning00002.smil#p_000055">Machine learning is built up from a varying set of tools, languages, and techniques. It's fair to say that there is no one solution that fits most projects. As you will find in this chapter and throughout the book, I'll refer to various tools to get certain aspects of the job done. For example, there might be data in a relational database that needs extracting to a file before you can process.</p>
            <p id="c02-c02-para-0020" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0020">Over the last few years, I've seen managers and developers with faces of complete joy and happiness when a data project is assigned. It's new, it's hip and, dare I say it, funky to be working on data projects. Then after the scale of the project comes into focus, I've seen the color drain from their faces. Usually this happens after the managers and developers see how many different elements are required to get things working for the project to succeed. And, like any major project, the specification from the stakeholders will change things along the way.</p>
          </level2>
          <level2 id="level2_000016">
            <h2 id="c02-c02_level1_5" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_5">Defining the Process</h2>
            <p xml:space="preserve" id="p_000056" smilref="Machine_Learning00002.smil#p_000056">Making anything comes down to process, whether that's baking a cake, brewing a cup of coffee, or planning a machine learning project. Processes can be refined as time goes on, but if you've never developed one before, then you can use the following process as a template.</p>
            <level3 id="level3_000032">
              <h3 xml:space="preserve" id="h3_000032" smilref="Machine_Learning00002.smil#h3_000032">Planning</h3>
              <p xml:space="preserve" id="p_000057" smilref="Machine_Learning00002.smil#p_000057">During the late 1980s, I wrote many assignments and papers on the upcoming trend of the paperless office and how computers would one day transform the way day-to-day operations would be performed. Even without the Internet, it was easy to see that computers were changing how things were being done.</p>
              <p id="c02-c02-para-0023" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0023">Skip ahead to the present day and you'll see that my desk is littered with paper, notebooks, sticky notes, and other scraps of information. The paperless office didn't quite make the changes I was expecting, and you need no more evidence than the state of my desk. I would show you a photograph, but it might prove embarrassing.</p>
              <pagenum epub:type="pagebreak" id="p21" page="normal" smilref="Machine_Learning00002.smil#p21">21</pagenum>
              <p id="c02-c02-para-0024" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0024">What I have found is that all projects start on paper. For me, it doesn't work to jump in and code; I find that method haphazard and error prone. I need to plan first. I use A5 Moleskin notebooks for notes and A4 and A3 artist drawing pads for large diagrams. They're on my desk, in my bag, and in my jacket pocket.</p>
              <p id="c02-c02-para-0025" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0025">Whiteboards are good, too. Whiteboards hold lots of ideas and diagrams, but I find they can get out of control and messy after a while. There was once an office wall in Santa Clara that I covered in sticky notes. (I did take them down once I was finished. The team thought I was mad.)</p>
              <p id="c02-c02-para-0026" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0026">Planning might take into account where the data is coming from, if it needs to be cleaned, what learning methods to use and what the output is going to look like. The main point is that these things can be changed at any time—the earlier in the process they change, the better. So it's worth taking the time to sit around a table with stakeholders and the team and figure out what you are trying achieve.</p>
            </level3>
            <level3 id="level3_000033">
              <h3 xml:space="preserve" id="h3_000033" smilref="Machine_Learning00002.smil#h3_000033">Developing</h3>
              <p xml:space="preserve" id="p_000058" smilref="Machine_Learning00002.smil#p_000058">This process might involve algorithm development or code development. The more iterations you perform on the code the better it will be. Agile development processes work best; in agile development, you only work on what needs to be done without trying to future-proof the software as you go along. It's worth using some form of code repository site like Github or BitBucket to keep all your work private; it also means you can roll back to earlier versions if you're not happy with the way things are going.</p>
            </level3>
            <level3 id="level3_000034">
              <h3 xml:space="preserve" id="h3_000034" smilref="Machine_Learning00002.smil#h3_000034">Testing</h3>
              <p xml:space="preserve" id="p_000059"><span class="text" id="span_000059" smilref="Machine_Learning00002.smil#span_000059">In this case, </span><em id="em_000010" smilref="Machine_Learning00002.smil#em_000010">testing</em><span class="text" id="span_000060" smilref="Machine_Learning00002.smil#span_000060"> means testing with data. You might use a random sample of the data or the full set. The important thing is to remind yourself that you're testing the process, so it's okay for things to not go as planned. If you push things straight to production, then you won't really know what's going to happen. With testing you can get an idea of the pain points. You might find data-loading issues, data-processing issues, or answers that just don't make sense. When you test, you have time to change things.</span></p>
            </level3>
            <level3 id="level3_000035">
              <h3 xml:space="preserve" id="h3_000035" smilref="Machine_Learning00002.smil#h3_000035">Reporting</h3>
              <p xml:space="preserve" id="p_000060"><span class="text" id="span_000061" smilref="Machine_Learning00002.smil#span_000061">Sit down with the stakeholders and discuss the test results. Do the results make sense? The developers and mathematicians might want to amend algorithms or the code. Stakeholders might have a new question to ask (this happens a lot), or perhaps you want to introduce some new data to get another angle on the answers. </span><pagenum epub:type="pagebreak" id="p22" page="normal" smilref="Machine_Learning00002.smil#p22">22</pagenum><span class="text" id="span_000062" smilref="Machine_Learning00002.smil#span_000062">Regardless of the situation, make sure the original people from the planning phase are back around the table again.</span></p>
            </level3>
            <level3 id="level3_000036">
              <h3 xml:space="preserve" id="h3_000036" smilref="Machine_Learning00002.smil#h3_000036">Refining</h3>
              <p xml:space="preserve" id="p_000061" smilref="Machine_Learning00002.smil#p_000061">When everyone is happy with the way the process is going it's time to refine code and, if possible, the algorithms. With huge volumes of data, squeeze every ounce of performance you can from your code and the quicker the overall processing time will be. Think of a bobsled run; a slower start converts to a much slower finish.</p>
            </level3>
            <level3 id="level3_000037">
              <h3 xml:space="preserve" id="h3_000037" smilref="Machine_Learning00002.smil#h3_000037">Production</h3>
              <p xml:space="preserve" id="p_000062" smilref="Machine_Learning00002.smil#p_000062">When all is tested, reviewed, and refined by the team, moving to production shouldn't be a big job. Be sure to give consideration to when this project will be run—is it an hourly/daily/weekly/monthly job? Will the data change wildly between the project going in to production and the next run?</p>
              <p id="c02-c02-para-0032" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0032">Make sure the team reviews the first few production runs to ensure the results are as expected, and then look at the project as a whole and see if it's meeting the criteria of the stakeholders. Things might need to be refined. As you probably already know, software is rarely finished.</p>
            </level3>
          </level2>
          <level2 id="level2_000017">
            <h2 id="c02-c02_level1_6" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_6">Building a Data Team</h2>
            <p xml:space="preserve" id="p_000063"><span class="text" id="span_000063" smilref="Machine_Learning00002.smil#span_000063">A </span><em id="em_000011" smilref="Machine_Learning00002.smil#em_000011">data scientist</em><span class="text" id="span_000064" smilref="Machine_Learning00002.smil#span_000064"> is someone who can bring the facets of data processing, analytics, statistics, programming, and visualization to a project. With so many skill sets in action, even for the smallest of projects, it's a lot to ask for one person to have all the necessary skills. In fact, I'd go as far to say that such a person might not exist—or is at least extremely rare. A data science team might touch on some, or all, of the following areas of expertise.</span></p>
            <level3 id="level3_000038">
              <h3 xml:space="preserve" id="h3_000038" smilref="Machine_Learning00002.smil#h3_000038">Mathematics and Statistics</h3>
              <p xml:space="preserve" id="p_000064" smilref="Machine_Learning00002.smil#p_000064">Someone on the team needs to have a good head for mathematics—someone who isn't going to flinch when the words “linear regression” are mentioned in the interview. I'm not saying there's a minimum level of statistics you should know before embarking on any project, but knowledge of descriptive statistics (the mean, the mode, and the median), distributions, and outliers will give you a good grounding to start.</p>
              <p id="c02-c02-para-0035" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0035">The debate will rage on about the level of mathematics needed in any machine learning project, but my opinion is that every project comes with its own set of complications. If new information needs to be learned, then there are plenty of sources out there from which you can learn.</p>
              <pagenum epub:type="pagebreak" id="p23" page="normal" smilref="Machine_Learning00002.smil#p23">23</pagenum>
              <p id="c02-c02-para-0036" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0036">If you have access to talented mathematicians, then your data team is a blessed group indeed.</p>
            </level3>
            <level3 id="level3_000039">
              <h3 xml:space="preserve" id="h3_000039" smilref="Machine_Learning00002.smil#h3_000039">Programming</h3>
              <p xml:space="preserve" id="p_000065" smilref="Machine_Learning00002.smil#p_000065">Good programming talent is hard to come by, but I'm assuming that if you have this book in your hand then there's a good chance you're a programmer already. Taking algorithms and being able to transfer that to workable code can take time and planning. It's also worth knowing some of the Big Data tools, such as the Hadoop framework and Spring XD. (Read Chapters 9 and 10 for a comprehensive walkthrough on both technologies.)</p>
            </level3>
            <level3 id="level3_000040">
              <h3 xml:space="preserve" id="h3_000040" smilref="Machine_Learning00002.smil#h3_000040">Graphic Design</h3>
              <p xml:space="preserve" id="p_000066" smilref="Machine_Learning00002.smil#p_000066">Visualizing data is important; it tells the story of your findings to the stakeholders or end users. Although much emphasis has been placed on the web for presentation with technologies such as D3 and Processing, don't forget the likes of BIRT, Jasper Reports, and Crystal Reports.</p>
              <p id="c02-c02-para-0039" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0039">This book doesn't touch on visualization, but Appendix D, “Further Reading,” includes some titles that will point you in the right direction.</p>
            </level3>
            <level3 id="level3_000041">
              <h3 xml:space="preserve" id="h3_000041" smilref="Machine_Learning00002.smil#h3_000041">Domain Knowledge</h3>
              <p xml:space="preserve" id="p_000067" smilref="Machine_Learning00002.smil#p_000067">If, for example, you are working with medical data, then it would be beneficial to have someone who knows the medical field well. The same goes for retail; there's not much point trawling through rows of transactions if no one knows how to interpret how customers behave. Domain experts are the vital heroes in guiding the team through a project. There are some decisions that the domain expert will instinctively know.</p>
              <p id="c02-c02-para-0041" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0041">Think of a border crossing with passport control. There might be many permutations of rules that are given depending on nationality, immigration rules, and so on. A domain expert would have this knowledge in place and make your life as the developer much easier and would help to get a solution up and running more quickly.</p>
              <p id="c02-c02-para-0042" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0042">There's a notion that we don't need domain experts. I'm of the mind that we do, even if you only sit down and have coffee with someone who knows the domain. Always take a notebook and keep notes.</p>
            </level3>
          </level2>
          <level2 id="level2_000018">
            <h2 id="c02-c02_level1_7" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_7">Data Processing</h2>
            <p xml:space="preserve" id="p_000068"><span class="text" id="span_000065" smilref="Machine_Learning00002.smil#span_000065">After you have a team in place and a rough idea of how all of this is going to get put together, it's time to turn your attention to what is going to do all the work for you. You must give thought to the frequency of the data process jobs </span><pagenum epub:type="pagebreak" id="p24" page="normal" smilref="Machine_Learning00002.smil#p24">24</pagenum><span class="text" id="span_000066" smilref="Machine_Learning00002.smil#span_000066">that will take place. If it will occur only once in a while, then it might be false economy investing in hardware over the long term. It makes more sense to start with what you have in hand and then add as you go along and as you notice growth in processing times and frequency.</span></p>
            <level3 id="level3_000042">
              <h3 xml:space="preserve" id="h3_000042" smilref="Machine_Learning00002.smil#h3_000042">Using Your Computer</h3>
              <p xml:space="preserve" id="p_000069" smilref="Machine_Learning00002.smil#p_000069">Yes, you can use your own machine, either a desktop or a laptop. I do my development on an Apple MacBook Pro. I run the likes of Hadoop on this machine as it's pretty fast, and I'm not using terabytes of data. There's nothing to stop you from using your own machine; it's available and it saves financial outlay to get more machines. Obviously, there can be limitations. Processing a heavy job might mean you have to turn your attention to less processor-intensive things, but never rule out the option of using your own machine.</p>
              <p id="c02-c02-para-0045" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0045">Operating systems like Linux and Mac OSX tend to be preferred over Windows, especially for Big Data–based operations. The best choice comes down to what you know best and what suits the project best in order to get the job done efficiently. I don't believe there's only one right way to do things.</p>
            </level3>
            <level3 id="level3_000043">
              <h3 xml:space="preserve" id="h3_000043" smilref="Machine_Learning00002.smil#h3_000043">A Cluster of Machines</h3>
              <p xml:space="preserve" id="p_000070" smilref="Machine_Learning00002.smil#p_000070">Eventually you'll come across a scenario that requires you to use a cluster of machines to do the work. Frameworks like Hadoop are designed for use over clusters of machines, which make it possible for the distribution of work to be done in parallel. Ideally the machines should be on the same network to reduce network traffic latency.</p>
              <p id="c02-c02-para-0047" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0047">At this point in time, it's also worthwhile to add a good system administrator to the data science team. Any performance that can be improved over the cluster will bring marked performance against the whole project.</p>
            </level3>
            <level3 id="level3_000044">
              <h3 xml:space="preserve" id="h3_000044" smilref="Machine_Learning00002.smil#h3_000044">Cloud-Based Services</h3>
              <p xml:space="preserve" id="p_000071" smilref="Machine_Learning00002.smil#p_000071">If the thought of maintaining and paying for your own hardware does not appeal, then consider using some form of cloud-based service. Vendors such as Amazon, Rackspace, and others provide scalable servers where you can increase, or decrease, the number of machines and amount of power that you require. The advantage of these services is that they are “turn on/turn off” technology, enabling you to use only what you need.</p>
              <p id="c02-c02-para-0049" xml:space="preserve"><span class="text" id="span_000067" smilref="Machine_Learning00002.smil#span_000067">Keep a close eye on the cost of cloud-based services, as they can sometimes prove more expensive than just using a standard hosting option over longer time periods. Some companies provide dedicated Big Data services if you require the likes of Hadoop to do your processing. With cloud-based services, it's always </span><pagenum epub:type="pagebreak" id="p25" page="normal" smilref="Machine_Learning00002.smil#p25">25</pagenum><span class="text" id="span_000068" smilref="Machine_Learning00002.smil#span_000068">important to turn the instance off, otherwise you'll be charged for the usage while the instance is active.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000019">
            <h2 id="c02-c02_level1_8" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_8">Data Storage</h2>
            <p xml:space="preserve" id="p_000072" smilref="Machine_Learning00002.smil#p_000072">There are some decisions to make on how the data is going to be stored. This might be on a physical disc or deployed on a cloud-based solution.</p>
            <level3 id="level3_000045">
              <h3 xml:space="preserve" id="h3_000045" smilref="Machine_Learning00002.smil#h3_000045">Physical Discs</h3>
              <p xml:space="preserve" id="p_000073" smilref="Machine_Learning00002.smil#p_000073">The most common form of storage is the one that you will more than likely have in your computer to start off with. The hard disc is adequate for testing and small jobs. You will notice a difference in performance between physical discs and solid state drives (SSD); the latter provides much faster performance. External drives are cheap, too, and provide a good storage solution for when data volumes increase.</p>
            </level3>
            <level3 id="level3_000046">
              <h3 xml:space="preserve" id="h3_000046" smilref="Machine_Learning00002.smil#h3_000046">Cloud-Based Storage</h3>
              <p xml:space="preserve" id="p_000074" smilref="Machine_Learning00002.smil#p_000074">Plenty of cloud-based storage facilities are available to store your data as required. If you are looking at cloud-based processing, then you'll more than likely be purchasing some form of cloud-based storage to go with it. For example, if you use Amazon's Elastic Map Reduce (EMR) system, then you would be using it alongside the S3 storage solution.</p>
              <p id="c02-c02-para-0053" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0053">Like cloud processing, storage based on the cloud will cost you on a monthly or annual basis. You also have to think about the bandwidth implications of moving large volumes of data from your office location to the cloud system, which is another cost to keep in mind.</p>
            </level3>
          </level2>
          <level2 id="level2_000020">
            <h2 id="c02-c02_level1_9" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_9">Data Privacy</h2>
            <p xml:space="preserve" id="p_000075" smilref="Machine_Learning00002.smil#p_000075">Data is power and with it comes an awful lot of responsibility. The privacy issue will always rage on in the hearts and minds of the users and the general public. Everyone has an opinion on the matter, and often people err on the side of caution.</p>
            <level3 id="level3_000047">
              <h3 xml:space="preserve" id="h3_000047" smilref="Machine_Learning00002.smil#h3_000047">Cultural Norms</h3>
              <p xml:space="preserve" id="p_000076"><span class="text" id="span_000069" smilref="Machine_Learning00002.smil#span_000069">Cultural expectations are difficult to measure. As the World Wide Web has progressed since the mid-1990s, there has been a privacy battle about everything </span><pagenum epub:type="pagebreak" id="p26" page="normal" smilref="Machine_Learning00002.smil#p26">26</pagenum><span class="text" id="span_000070" smilref="Machine_Learning00002.smil#span_000070">from how cookies were stored on your computer to how a multitude of companies are tracking locations, social interactions, ratings, and purchasing decisions through your mobile devices.</span></p>
              <p id="c02-c02-para-0056" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0056">If you're collecting data via a website or mobile application, then there's an expectation that you will be giving something in return for user information. When you collect that information, it's only right to tell the user what you intend to do with the data.</p>
              <p id="c02-c02-para-0057" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0057">Supermarket loyalty card schemes are a simple data-collecting exercise. For every basket that goes through the checkout, there's the potential that the customer has a loyalty card. In associating that customer with that basket of products you can start to apply machine learning. Over time you will be able to see the shopping habits of that customer—her average spend, the day of the week she shops—and the customer expects some form of discount promotion for telling you all this information.</p>
              <p id="c02-c02-para-0058" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0058">So, how do you keep cultural norms onside? By giving customers a very clear opt-in or opt-out strategy.</p>
            </level3>
            <level3 id="level3_000048">
              <h3 xml:space="preserve" id="h3_000048" smilref="Machine_Learning00002.smil#h3_000048">Generational Expectations</h3>
              <p xml:space="preserve" id="p_000077" smilref="Machine_Learning00002.smil#p_000077">During sessions of my iPhone development class, I open up with a discussion about personal data. I can watch the room divide instantly, and I can easily see the deciding factor: age.</p>
              <p id="c02-c02-para-0060" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0060">Some people are more than happy to share with their friends, and the rest of the world, their location, what they are doing, and with whom. These people post pictures of their activities and tag them so they could be easily searched, rated, and commented on. They use Facebook, Instagram, Foursquare, Twitter, and other apps as a normal, everyday part of their lives.</p>
              <p id="c02-c02-para-0061" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0061">The other group of people, who were older, were not comfortable with the concept of handing over personal information. Some of them thought that no one in their right minds would be interested in such information. Most couldn't see the point.</p>
              <p id="c02-c02-para-0062" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0062">Although the generation gap might be closing and there is a steady relaxation of what people are willing to put on the Internet, developers have a responsibility to the suppliers of the information. You have to consider whether the results you generate will cause a concern to them or enhance their lives.</p>
            </level3>
            <level3 id="level3_000049">
              <h3 xml:space="preserve" id="h3_000049" smilref="Machine_Learning00002.smil#h3_000049">The Anonymity of User Data</h3>
              <p xml:space="preserve" id="p_000078"><span class="text" id="span_000071" smilref="Machine_Learning00002.smil#span_000071">You can learn from data, but users get touchy when their names are attached to it. Creating hashes of important data is a starting point, but it's certainly not the end game. </span><pagenum epub:type="pagebreak" id="p27" page="normal" smilref="Machine_Learning00002.smil#p27">27</pagenum><span class="text" id="span_000072" smilref="Machine_Learning00002.smil#span_000072">Consider my name as an MD5 hash. Using the Linux </span><code xml:space="preserve" id="code_000021" smilref="Machine_Learning00002.smil#code_000021">md5sum</code><span class="text" id="span_000073" smilref="Machine_Learning00002.smil#span_000073"> command I can find it out very easily, as shown here:</span></p>
              <p xml:space="preserve" id="p_000079"><code class="preserve-whitespace" xml:space="preserve" id="code_000022" smilref="Machine_Learning00002.smil#code_000022">$ printf '%s' "Jason Bell" | md5sum
a7b19ed2ca59f8e94121b54f9f26333c  -</code></p>
              <p id="c02-c02-para-0064" xml:space="preserve"><span class="text" id="span_000074" smilref="Machine_Learning00002.smil#span_000074">Now, I have a hash value, which is a good start, but it's still not really protecting my identity. You now know it and what it would possibly relate to if it were used as a user key in a machine learning process. It wouldn't take much time for a decent programmer with a list of first and last names to generate all the </span><code xml:space="preserve" id="code_000023" smilref="Machine_Learning00002.smil#code_000023">md5</code><span class="text" id="span_000075" smilref="Machine_Learning00002.smil#span_000075"> values for all the combinations.</span></p>
              <p id="c02-c02-para-0065" xml:space="preserve"><span class="text" id="span_000076" smilref="Machine_Learning00002.smil#span_000076">Using a salt value is a better solution. A </span><em id="em_000012" smilref="Machine_Learning00002.smil#em_000012">salt value</em><span class="text" id="span_000077" smilref="Machine_Learning00002.smil#span_000077"> is random data that's used with the piece of data to make it more secure and harder to crack.</span></p>
              <p id="c02-c02-para-0066" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0066">Let's assume the salt value is the number of nanoseconds from the 1st January 1970. You take that and the string you're looking to hash:</p>
              <p xml:space="preserve" id="p_000080"><code class="preserve-whitespace" xml:space="preserve" id="code_000024" smilref="Machine_Learning00002.smil#code_000024">$ printf '%s' "Jason Bell $(date +%sN)" | md5sum
40e46b48a873c30c80469dbbefaa5e16  -</code></p>
              <p id="c02-c02-para-0067" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0067">There are different ways of handling the input string. You might want to remove spaces but the concept remains the same. The security of these hashes has to be maintained by you, so when the time comes to interpret the answers, you'll know which customers are doing the actions you are seeking. Hashes aren't just restricted to usernames or customer names; they can be applied to any data. Anything that you consider private information (known as personally identifiable information or PII)—something that you don't want any third party to see—must be hashed.</p>
            </level3>
            <level3 id="level3_000050">
              <h3 xml:space="preserve" id="h3_000050" smilref="Machine_Learning00002.smil#h3_000050">Don't Cross “The Creepy Line”</h3>
              <p xml:space="preserve" id="p_000081"><span class="text" id="span_000078" smilref="Machine_Learning00002.smil#span_000078">Be careful not to make the customer freak out by crossing the line in the sand that I call “the creepy line.” It's the point where the horrified customer would shriek, “How did they know that?” For an example of a company and what they know about you visit the settings pages of your Google account (</span><a href="https://www.google.com/settings/dashboard" external="true" id="a_000273" smilref="Machine_Learning00002.smil#a_000273">https://www.google.com/settings/dashboard</a><span class="text" id="span_000079" smilref="Machine_Learning00002.smil#span_000079">) and have a look your web search history or your location history.</span></p>
              <p id="c02-c02-para-0069" xml:space="preserve"><span class="text" id="span_000080" smilref="Machine_Learning00002.smil#span_000080">One near-legendary example in data science, Big Data, and machine learning circles is the story of Target and pregnant mothers, which was widely cited on the Internet because of Charles Duhigg's book </span><em id="em_000013" smilref="Machine_Learning00002.smil#em_000013">The Power of Habit</em><span class="text" id="span_000081" smilref="Machine_Learning00002.smil#span_000081"> (Random House, 2011). What readers of the Internet forgot to realize was that Target had been using the same practice for years; the concept was originally run in 2002 as an exercise to see if there was a correlation between two things.</span></p>
              <pagenum epub:type="pagebreak" id="p28" page="normal" smilref="Machine_Learning00002.smil#p28">28</pagenum>
              <p id="c02-c02-para-0070" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0070">Good mathematics and item matching isolated a number of items that mothers-to-be started to buy. Target has enough data to predict what trimester of the pregnancy the mother is in. With an opt-in to the baby club this might have all passed without problem. But when an angry father rolls up to the store to enquire why his teenage daughter is receiving baby promotions and coupons, well, that's a different matter.</p>
              <p id="c02-c02-para-0071" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0071">What does this example highlight? Well, apart from freaking out the customer, it causes undue pressure on the in-store staff. Everyone in the organization needs to be aware of the work that's going on. Also, the data team needs to be acutely aware of the social effect of their learning.</p>
              <p id="c02-c02-para-0072" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0072">The UK supermarket chain Tesco started the Clubcard loyalty scheme in 1995; it holds more data than some governments on customer purchasing behavior, social classes, and income bracket. The store's data processing power is controlled by a marketing company, Dunn Humby, which runs the Clubcard and analyzes the data. What is the upside for the customer? Four times a year Clubcard members receive coupons for money off and incentives to buy items they normally purchase. The offers resemble the customers' typical shopping patterns, but other items are thrown in so it doesn't look like they've been stalked.</p>
              <p id="c02-c02-para-0073" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0073">Mining the baskets is hardly a new idea (you'll be reading about other techniques in later chapters), but when the supermarket becomes large and the volumes of data are huge, the insight that can be gained becomes an enormous commercial advantage. The cost of this advantage is appearing to know the intimate shopping details of the customer even when they've not overtly given permission for you to send offers.</p>
            </level3>
          </level2>
          <level2 id="level2_000021">
            <h2 id="c02-c02_level1_10" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_10">Data Quality and Cleaning</h2>
            <p xml:space="preserve" id="p_000082" smilref="Machine_Learning00002.smil#p_000082">In an ideal world, you'd receive data and put it straight into the system for processing. Then your favorite actor or actress would hand you your favorite drink and pat you on the back for a job well done.</p>
            <p id="c02-c02-para-0075" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0075">In the real world, data is messy, usually unclean, and error prone. The following sections offer some basic checks you should do, and I've included some sample data so you can see clearly what to look for.</p>
            <p id="c02-c02-para-0076" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0076">The example data is a simple address book with a first name, last name, e-mail address, and age.</p>
            <level3 id="level3_000051">
              <h3 xml:space="preserve" id="h3_000051" smilref="Machine_Learning00002.smil#h3_000051">Presence Checks</h3>
              <p xml:space="preserve" id="p_000083" smilref="Machine_Learning00002.smil#p_000083">First things first, check that data has been entered at all. Within web-based businesses, registration usually involves at least an e-mail address, first name, and last name. It's amazing how many times users will try to avoid putting in their names.</p>
              <pagenum epub:type="pagebreak" id="p29" page="normal" smilref="Machine_Learning00002.smil#p29">29</pagenum>
              <p id="c02-c02-para-0078" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0078">The presence check is simple enough. If the field length is empty or null, and that piece of data is important in the analysis, then you can't use records from which the data is missing.</p>
              <figure id="figure_000002">
                <table border="1" id="table_000001">
                  <tr id="tr_000001">
                    <td class="left" rowspan="1" colspan="1" id="td_000001" />
                    <td class="left" rowspan="1" colspan="1" id="td_000002" smilref="Machine_Learning00002.smil#td_000002">Firstname</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000003" smilref="Machine_Learning00002.smil#td_000003">Lastname</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000004" smilref="Machine_Learning00002.smil#td_000004">E-mail</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000005" smilref="Machine_Learning00002.smil#td_000005">Age</td>
                  </tr>
                  <tr id="tr_000002">
                    <td class="left" rowspan="1" colspan="1" id="td_000006" smilref="Machine_Learning00002.smil#td_000006">Correct</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000007" smilref="Machine_Learning00002.smil#td_000007">Jason</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000008" smilref="Machine_Learning00002.smil#td_000008">Bell</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000009" smilref="Machine_Learning00002.smil#td_000009">me@domain.com</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000010" smilref="Machine_Learning00002.smil#td_000010">42</td>
                  </tr>
                  <tr id="tr_000003">
                    <td class="left" rowspan="1" colspan="1" id="td_000011" smilref="Machine_Learning00002.smil#td_000011">Incorrect</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000012" />
                    <td class="left" rowspan="1" colspan="1" id="td_000013" smilref="Machine_Learning00002.smil#td_000013">Bell</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000014" />
                    <td class="left" rowspan="1" colspan="1" id="td_000015" smilref="Machine_Learning00002.smil#td_000015">42</td>
                  </tr>
                </table>
              </figure>
              <p id="c02-c02-para-0079" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0079">The first name and e-mail are missing from the example, so the record should really be fixed or rejected. In theory, the data could be used if knowing the customer was not important.</p>
            </level3>
            <level3 id="level3_000052">
              <h3 xml:space="preserve" id="h3_000052" smilref="Machine_Learning00002.smil#h3_000052">Type Checks</h3>
              <p xml:space="preserve" id="p_000084" smilref="Machine_Learning00002.smil#p_000084">With relational databases you have schemas created, so there's already an expectation of what type of data is going where. If incorrect data is written to a field of a different data type, then the database engine will throw an error and complain at you.</p>
              <p id="c02-c02-para-0081" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0081">In text data, such as CSV files, that's not the case, so it's worth looking at each field and ensuring that what you're expecting to see is valid.</p>
              <p xml:space="preserve" id="p_000085"><code class="preserve-whitespace" xml:space="preserve" id="code_000025" smilref="Machine_Learning00002.smil#code_000025">#firstname, lastname, email, age
Jason,Bell,me@domain.com,42
42,Bell,me@domain.com,Jason</code></p>
              <p id="c02-c02-para-0082" xml:space="preserve"><span class="text" id="span_000082" smilref="Machine_Learning00002.smil#span_000082">From the example, you can see that the first row of data is correct, but the second is wrong because the </span><code xml:space="preserve" id="code_000026" smilref="Machine_Learning00002.smil#code_000026">firstname</code><span class="text" id="span_000083" smilref="Machine_Learning00002.smil#span_000083"> field has a number in it and not a string type. There are a couple of things you could do here. The first option is to ignore the record, as it doesn't fit the data-quality check. The other option is to see if any other records have the same e-mail address and check the name against those records.</span></p>
            </level3>
            <level3 id="level3_000053">
              <h3 xml:space="preserve" id="h3_000053" smilref="Machine_Learning00002.smil#h3_000053">Length Checks</h3>
              <p xml:space="preserve" id="p_000086" smilref="Machine_Learning00002.smil#p_000086">Field lengths must be checked, too; once again, relational databases exercise a certain amount of control, but textual data can be error-prone if people don't go with the general rules of the schema.</p>
              <figure id="figure_000003">
                <table border="1" id="table_000002">
                  <tr id="tr_000004">
                    <td class="left" rowspan="1" colspan="1" id="td_000016" smilref="Machine_Learning00002.smil#td_000016">Field</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000017" smilref="Machine_Learning00002.smil#td_000017">Length</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000018" smilref="Machine_Learning00002.smil#td_000018">Good</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000019" smilref="Machine_Learning00002.smil#td_000019">Bad</td>
                  </tr>
                  <tr id="tr_000005">
                    <td class="left" rowspan="1" colspan="1" id="td_000020">
                      <code xml:space="preserve" id="code_000027" smilref="Machine_Learning00002.smil#code_000027">Firstname</code>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000021" smilref="Machine_Learning00002.smil#td_000021">10</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000022" smilref="Machine_Learning00002.smil#td_000022">Jason</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000023" smilref="Machine_Learning00002.smil#td_000023">Mr Jason Bell</td>
                  </tr>
                  <tr id="tr_000006">
                    <td class="left" rowspan="1" colspan="1" id="td_000024">
                      <code xml:space="preserve" id="code_000028" smilref="Machine_Learning00002.smil#code_000028">Email</code>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000025" smilref="Machine_Learning00002.smil#td_000025">20</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000026" smilref="Machine_Learning00002.smil#td_000026">me@domain.com</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000027" smilref="Machine_Learning00002.smil#td_000027">jason.bell@thing.domain.com</td>
                  </tr>
                </table>
              </figure>
            </level3>
            <level3 id="level3_000054">
              <h3 xml:space="preserve" id="h3_000054" smilref="Machine_Learning00002.smil#h3_000054">Range Checks</h3>
              <pagenum epub:type="pagebreak" id="p30" page="normal" smilref="Machine_Learning00002.smil#p30">30</pagenum>
              <p xml:space="preserve" id="p_000087" smilref="Machine_Learning00002.smil#p_000087">Range or reasonableness checks are used with numeric or date ranges. Age ranges are the main talking point here. Until there are advances in scientific medicine to prolong life, you can make a fairly good assumption that the upper lifespan of someone is about 120. You can even play it safe and extend the upper range to 150; anyone who is older than that is lying or just trying to put a false value in to trip up the system.</p>
              <figure id="figure_000004">
                <table border="1" id="table_000003">
                  <tr id="tr_000007">
                    <td class="left" rowspan="1" colspan="1" id="td_000028" smilref="Machine_Learning00002.smil#td_000028">Field</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000029" smilref="Machine_Learning00002.smil#td_000029">Lower Range</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000030" smilref="Machine_Learning00002.smil#td_000030">Upper Range</td>
                  </tr>
                  <tr id="tr_000008">
                    <td class="left" rowspan="1" colspan="1" id="td_000031">
                      <code xml:space="preserve" id="code_000029" smilref="Machine_Learning00002.smil#code_000029">Age</code>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000032" smilref="Machine_Learning00002.smil#td_000032">0</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000033" smilref="Machine_Learning00002.smil#td_000033">120</td>
                  </tr>
                  <tr id="tr_000009">
                    <td class="left" rowspan="1" colspan="1" id="td_000034">
                      <code xml:space="preserve" id="code_000030" smilref="Machine_Learning00002.smil#code_000030">Month</code>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000035" smilref="Machine_Learning00002.smil#td_000035">1</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000036" smilref="Machine_Learning00002.smil#td_000036">12</td>
                  </tr>
                </table>
              </figure>
            </level3>
            <level3 id="level3_000055">
              <h3 xml:space="preserve" id="h3_000055" smilref="Machine_Learning00002.smil#h3_000055">Format Checks</h3>
              <p xml:space="preserve" id="p_000088" smilref="Machine_Learning00002.smil#p_000088">When you know that certain data must follow a given format then it's always good to check it. Regular expression knowledge is a big advantage here if you know it. E-mail addresses can be used and abused in web forms and database tables, so it's always a good idea to validate what you can at source.</p>
              <p id="c02-c02-para-0086" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0086">There's much discussion in the developer world about what a correct e-mail regular expression actually is. The official standard for the e-mail address specification is RFC 5322. Correctly matching the e-mail address as a regular expression is a huge pattern. What you're looking for is something that will catch the majority of e-mail addresses:</p>
              <p xml:space="preserve" id="p_000089"><code class="preserve-whitespace" xml:space="preserve" id="code_000031" smilref="Machine_Learning00002.smil#code_000031"> [a-z0-9!#$%&amp;'*+/=?^_`{|}˜-]+(?:\.[a-z0-9!#$%&amp;'*+/=?^_`{|}˜-]+)*@ (?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?</code></p>
              <p id="c02-c02-para-0087" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0087">The main thing to do is create a run of test cases with all the eventualities of an e-mail address you think you will come across. Don't just test it once; keep retesting it over time.</p>
              <p id="c02-c02-para-0088" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0088">Postcodes and Zip codes are another source of formatting woe—especially UK postcodes. Regular expressions also help in this case, but sometimes an odd one slips through the testing. At the end of the day, this sort of thing is better left to specialized software or expert services.</p>
            </level3>
            <level3 id="level3_000056">
              <h3 xml:space="preserve" id="h3_000056" smilref="Machine_Learning00002.smil#h3_000056">The Britney Dilemma</h3>
              <p xml:space="preserve" id="p_000090" smilref="Machine_Learning00002.smil#p_000090">Users being users will input all sorts of things, and it's really up to us to make sure that our software catches what it can. Although search strings aren't specific to machine learning, it is, however, a very interesting case of how different names can really mess up the results.</p>
              <pagenum epub:type="pagebreak" id="p31" page="normal" smilref="Machine_Learning00002.smil#p31">31</pagenum>
              <p id="c02-c02-para-0090" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0090">For instance, take the variations of the search term “Britney Spears” in a well-known search engine. In an ideal and slightly utopian vision, everyone would type her name perfectly into a text field box:</p>
              <p xml:space="preserve" id="p_000091"><code class="preserve-whitespace" xml:space="preserve" id="code_000032" smilref="Machine_Learning00002.smil#code_000032">britney spears </code></p>
              <p id="c02-c02-para-0091" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0091">Life rarely goes as planned, and users type what they think is right, such as the following:</p>
              <p xml:space="preserve" id="p_000092"><code class="preserve-whitespace" xml:space="preserve" id="code_000033" smilref="Machine_Learning00002.smil#code_000033">brittany spears
brittney spears
britany spears
britny spears
briteny spears
britteny spears
briney spears
brittny spears
brintey spears
britanny spears
britiny spears
britnet spears
britiney spears
britaney spears
britnay spears
brithney spears
brtiney spears
birtney spears
brintney spears
briteney spears
bitney spears
brinty spears
brittaney spears
brittnay spears
britey spears
brittiny spears</code></p>
              <p id="c02-c02-para-0092" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0092">If you were to put that through a Hadoop cluster looking for unique singer search terms, you'd be in a bit of a mess, as each of these would register a new result count.</p>
              <p id="c02-c02-para-0093" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0093">What you want is something to weigh each term and see what it resembles. The simplest approach is to use a classifier to weigh each search term as it comes in. You know the correct term, so it's a case of running the incoming terms against the correct one and seeing what the confidence scoring is.</p>
              <p xml:space="preserve" id="p_000093"><code class="preserve-whitespace" xml:space="preserve" id="code_000034"><strong id="strong_000002" smilref="Machine_Learning00002.smil#strong_000002">package</strong><span class="text" id="span_000084" smilref="Machine_Learning00002.smil#span_000084"> chapter2;
</span><strong id="strong_000003" smilref="Machine_Learning00002.smil#strong_000003">import</strong><span class="text" id="span_000085" smilref="Machine_Learning00002.smil#span_000085"> java.util.ArrayList;
</span><strong id="strong_000004" smilref="Machine_Learning00002.smil#strong_000004">import</strong><span class="text" id="span_000086" smilref="Machine_Learning00002.smil#span_000086"> java.util.List;
</span><strong id="strong_000005" smilref="Machine_Learning00002.smil#strong_000005">import</strong> <pagenum epub:type="pagebreak" id="p32" page="normal" smilref="Machine_Learning00002.smil#p32">32</pagenum><span class="text" id="span_000087" smilref="Machine_Learning00002.smil#span_000087">net.sf.classifier4J.ClassifierException;
</span><strong id="strong_000006" smilref="Machine_Learning00002.smil#strong_000006">import</strong><span class="text" id="span_000088" smilref="Machine_Learning00002.smil#span_000088"> net.sf.classifier4J.vector.HashMapTermVectorStorage;
</span><strong id="strong_000007" smilref="Machine_Learning00002.smil#strong_000007">import</strong><span class="text" id="span_000089" smilref="Machine_Learning00002.smil#span_000089"> net.sf.classifier4J.vector.TermVectorStorage;
</span><strong id="strong_000008" smilref="Machine_Learning00002.smil#strong_000008">import</strong><span class="text" id="span_000090" smilref="Machine_Learning00002.smil#span_000090"> net.sf.classifier4J.vector.VectorClassifier;
</span><strong id="strong_000009" smilref="Machine_Learning00002.smil#strong_000009">public</strong> <strong id="strong_000010" smilref="Machine_Learning00002.smil#strong_000010">class</strong><span class="text" id="span_000091" smilref="Machine_Learning00002.smil#span_000091"> BritneyDilemma {
    </span><strong id="strong_000011" smilref="Machine_Learning00002.smil#strong_000011">public</strong><span class="text" id="span_000092" smilref="Machine_Learning00002.smil#span_000092"> BritneyDilemma() {
        List&lt;String&gt; terms = </span><strong id="strong_000012" smilref="Machine_Learning00002.smil#strong_000012">new</strong><span class="text" id="span_000093" smilref="Machine_Learning00002.smil#span_000093"> ArrayList&lt;String&gt;();
        terms.add("brittany spears");
        terms.add("brittney spears");
        terms.add("britany spears");
        terms.add("britny spears");
        terms.add("briteny spears");
        terms.add("britteny spears");
        terms.add("briney spears");
        terms.add("brittny spears");
        terms.add("brintey spears");
        terms.add("britanny spears");
        terms.add("britiny spears");
        terms.add("britnet spears");
        terms.add("britiney spears");
        terms.add("christina aguilera");
        TermVectorStorage storage = </span><strong id="strong_000013" smilref="Machine_Learning00002.smil#strong_000013">new</strong><span class="text" id="span_000094" smilref="Machine_Learning00002.smil#span_000094"> HashMapTermVectorStorage();
        VectorClassifier vc = </span><strong id="strong_000014" smilref="Machine_Learning00002.smil#strong_000014">new</strong><span class="text" id="span_000095" smilref="Machine_Learning00002.smil#span_000095"> VectorClassifier(storage);
        String correctString = "britney spears";
        </span><strong id="strong_000015" smilref="Machine_Learning00002.smil#strong_000015">for</strong><span class="text" id="span_000096" smilref="Machine_Learning00002.smil#span_000096"> (String term: terms) {
          </span><strong id="strong_000016" smilref="Machine_Learning00002.smil#strong_000016">try</strong><span class="text" id="span_000097" smilref="Machine_Learning00002.smil#span_000097"> {
            vc.teachMatch("sterm", correctString);
            </span><strong id="strong_000017" smilref="Machine_Learning00002.smil#strong_000017">double</strong><span class="text" id="span_000098" smilref="Machine_Learning00002.smil#span_000098"> result = vc.classify("sterm", term);
            System.</span><em id="em_000014" smilref="Machine_Learning00002.smil#em_000014">out</em><span class="text" id="span_000099" smilref="Machine_Learning00002.smil#span_000099">.println(term + " = " + result);
          } </span><strong id="strong_000018" smilref="Machine_Learning00002.smil#strong_000018">catch</strong><span class="text" id="span_000100" smilref="Machine_Learning00002.smil#span_000100"> (ClassifierException e) {
            e.printStackTrace();
          }
        }
    }
    </span><strong id="strong_000019" smilref="Machine_Learning00002.smil#strong_000019">public</strong> <strong id="strong_000020" smilref="Machine_Learning00002.smil#strong_000020">static</strong> <strong id="strong_000021" smilref="Machine_Learning00002.smil#strong_000021">void</strong><span class="text" id="span_000101" smilref="Machine_Learning00002.smil#span_000101"> main(String[] args) {
        BritneyDilemma bd = </span><strong id="strong_000022" smilref="Machine_Learning00002.smil#strong_000022">new</strong><span class="text" id="span_000102" smilref="Machine_Learning00002.smil#span_000102"> BritneyDilemma();
    }
}</span></code></p>
              <p id="c02-c02-para-0094" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0094">This code sample uses the Classifer4J library to run a basic vector space search on the incoming spellings of Britney; it then ranks them against the correct string. When this code is run, you get the following output:</p>
              <p xml:space="preserve" id="p_000094"><code class="preserve-whitespace" xml:space="preserve" id="code_000035" smilref="Machine_Learning00002.smil#code_000035">brittany spears = 0.7071067811865475
brittney spears = 0.7071067811865475
britany spears = 0.7071067811865475
britny spears = 0.7071067811865475
briteny spears = 0.7071067811865475
britteny spears = 0.7071067811865475
briney spears = 0.7071067811865475
brittny spears = 0.7071067811865475
brintey spears = 0.7071067811865475
britanny spears = 0.7071067811865475
britiny spears = 0.7071067811865475
britnet spears = 0.7071067811865475
britiney spears = 0.7071067811865475
britaney spears = 0.7071067811865475
britnay spears = 0.7071067811865475
brithney spears = 0.7071067811865475
brtiney spears = 0.7071067811865475
birtney spears = 0.7071067811865475
brintney spears = 0.7071067811865475
briteney spears = 0.7071067811865475
bitney spears = 0.7071067811865475
brinty spears = 0.7071067811865475
brittaney spears = 0.7071067811865475
brittnay spears = 0.7071067811865475
britey spears = 0.7071067811865475
brittiny spears = 0.7071067811865475
christina aguilera = 0.0</code></p>
              <pagenum epub:type="pagebreak" id="p33" page="normal" smilref="Machine_Learning00002.smil#p33">33</pagenum>
              <p id="c02-c02-para-0095" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0095">The confidence is always a number between 0 and 0.9999. Just to prove that, putting the correct spelling in the list and running the program again would generate a positive score.</p>
              <p xml:space="preserve" id="p_000095"><code class="preserve-whitespace" xml:space="preserve" id="code_000036" smilref="Machine_Learning00002.smil#code_000036">britney spears = 0.9999999999999998</code></p>
              <p id="c02-c02-para-0096" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0096">Obviously, there's some preparation required, as you need to know the correct spellings of the search terms before you can run the classifier. This example just proves the point.</p>
            </level3>
            <level3 id="level3_000057">
              <h3 xml:space="preserve" id="h3_000057" smilref="Machine_Learning00002.smil#h3_000057">What's in a Country Name?</h3>
              <p xml:space="preserve" id="p_000096" smilref="Machine_Learning00002.smil#p_000096">Data cleaning needs to be done in a variety of circumstances, but the most common reason is too many options were given in the first place.</p>
              <p id="c02-c02-para-0098" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0098">A few years ago I was looking at a database for a hotel. Its data was gathered via a web-based enquiry form, but instead of offering a selection of countries from a drop-down list of countries, there was just an open text field. (Always remember that freedom of input, where it can be avoided, should be avoided.)</p>
              <p id="c02-c02-para-0099" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0099">Let's consider this for a moment. If you take a country like Ireland then you might have the following entries for country name:</p>
              <list type="ul" id="list_000026">
                <li id="li_000280" smilref="Machine_Learning00002.smil#li_000280">Ireland</li>
                <li id="li_000281" smilref="Machine_Learning00002.smil#li_000281">Republic of Ireland</li>
                <li id="li_000282" smilref="Machine_Learning00002.smil#li_000282">Eire</li>
                <li id="li_000283" smilref="Machine_Learning00002.smil#li_000283">EIR</li>
                <li id="li_000284" smilref="Machine_Learning00002.smil#li_000284">Rep. of Ireland</li>
              </list>
              <pagenum epub:type="pagebreak" id="p34" page="normal" smilref="Machine_Learning00002.smil#p34">34</pagenum>
              <p id="c02-c02-para-0100" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0100">All these are essentially the same place; the only exception would be Northern Ireland, which is still part of the United Kingdom.</p>
              <p id="c02-c02-para-0101" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0101">What you have is a huge job to clean up the country field of a database. To fix this, you would have to find all the distinct names in the country field and associate them with a two-letter country code. So, Ireland and all the other names that were associated with Ireland become IE. You would have to do this for all the countries. Where possible, it's better to have tight control of the input data, as this will make things a lot easier when it comes to processing.</p>
              <p id="c02-c02-para-0102" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0102">In programming terms, you could make each of the distinct countries a key in a HashMap and add a method to get the value of the corresponding input name.</p>
              <p xml:space="preserve" id="p_000097"><code class="preserve-whitespace" xml:space="preserve" id="code_000037"><strong id="strong_000023" smilref="Machine_Learning00002.smil#strong_000023">package</strong><span class="text" id="span_000103" smilref="Machine_Learning00002.smil#span_000103"> chapter2;
</span><strong id="strong_000024" smilref="Machine_Learning00002.smil#strong_000024">import</strong><span class="text" id="span_000104" smilref="Machine_Learning00002.smil#span_000104"> java.util.HashMap;
</span><strong id="strong_000025" smilref="Machine_Learning00002.smil#strong_000025">import</strong><span class="text" id="span_000105" smilref="Machine_Learning00002.smil#span_000105"> java.util.Map;
</span><strong id="strong_000026" smilref="Machine_Learning00002.smil#strong_000026">public</strong> <strong id="strong_000027" smilref="Machine_Learning00002.smil#strong_000027">class</strong><span class="text" id="span_000106" smilref="Machine_Learning00002.smil#span_000106"> CountryHashMap {
    </span><strong id="strong_000028" smilref="Machine_Learning00002.smil#strong_000028">private</strong><span class="text" id="span_000107" smilref="Machine_Learning00002.smil#span_000107"> Map&lt;String, String&gt; countries = </span><strong id="strong_000029" smilref="Machine_Learning00002.smil#strong_000029">new</strong><span class="text" id="span_000108" smilref="Machine_Learning00002.smil#span_000108"> HashMap&lt;String, String&gt;();
    </span><strong id="strong_000030" smilref="Machine_Learning00002.smil#strong_000030">public</strong><span class="text" id="span_000109" smilref="Machine_Learning00002.smil#span_000109"> CountryHashMap() {
        countries.put("Ireland", "IE");
        countries.put("Eire", "IE");
        countries.put("Republic of Ireland", "IE");
        countries.put("Northern Ireland", "UK");
        countries.put("England", "UK");
        // you could add more or generate from a database.
    }
    </span><strong id="strong_000031" smilref="Machine_Learning00002.smil#strong_000031">public</strong><span class="text" id="span_000110" smilref="Machine_Learning00002.smil#span_000110"> String getCountryCode(String country) {
        </span><strong id="strong_000032" smilref="Machine_Learning00002.smil#strong_000032">return</strong><span class="text" id="span_000111" smilref="Machine_Learning00002.smil#span_000111"> countries.get(country);
    }
    </span><strong id="strong_000033" smilref="Machine_Learning00002.smil#strong_000033">public</strong> <strong id="strong_000034" smilref="Machine_Learning00002.smil#strong_000034">static</strong> <strong id="strong_000035" smilref="Machine_Learning00002.smil#strong_000035">void</strong><span class="text" id="span_000112" smilref="Machine_Learning00002.smil#span_000112"> main(String[] args) {
        CountryHashMap chm = </span><strong id="strong_000036" smilref="Machine_Learning00002.smil#strong_000036">new</strong><span class="text" id="span_000113" smilref="Machine_Learning00002.smil#span_000113"> CountryHashMap();
        System.</span><em id="em_000015" smilref="Machine_Learning00002.smil#em_000015">out</em><span class="text" id="span_000114" smilref="Machine_Learning00002.smil#span_000114">.println(chm.getCountryCode("Ireland"));
        System.</span><em id="em_000016" smilref="Machine_Learning00002.smil#em_000016">out</em><span class="text" id="span_000115" smilref="Machine_Learning00002.smil#span_000115">.println(chm.getCountryCode("Northern Ireland"));
    }
}</span></code></p>
              <p id="c02-c02-para-0103" xml:space="preserve"><span class="text" id="span_000116" smilref="Machine_Learning00002.smil#span_000116">The preceding example is a basic piece of code that would automate the cleaning process in a short amount of time. However, you are strongly advised to look </span><pagenum epub:type="pagebreak" id="p35" page="normal" smilref="Machine_Learning00002.smil#p35">35</pagenum><span class="text" id="span_000117" smilref="Machine_Learning00002.smil#span_000117">at the source of the problem and refactor the input. If no change is made, then the same cost to the business will occur, as you'll have to clean the data again.</span></p>
              <p id="c02-c02-para-0104" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0104">Ideally, to avoid having to do this sort of cleaning, you would employ verification strategies at the input stage. So, for example, if you're using web forms you should use JavaScript to validate the input before it's saved to the database. Other times you inherit data and occasionally have to employ such methods.</p>
            </level3>
            <level3 id="level3_000058">
              <h3 xml:space="preserve" id="h3_000058" smilref="Machine_Learning00002.smil#h3_000058">Dates and Times</h3>
              <p xml:space="preserve" id="p_000098" smilref="Machine_Learning00002.smil#p_000098">For time series processing, you must ensure that you have a consistent set of dates to read. The format you choose is really up to you. International Standard ISO 8601 lays out the specification for date and time representations in a numerical format. The issue with the ISO 8601 standard is that it's not immune to the Y10K bug when timestamps will be incorrect after 19th January 2038. The Temps Atomique International (TAI) standard takes into account these issues.</p>
              <p id="c02-c02-para-0106" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0106">Regardless of the language you are using, make yourself aware of how the date formatting and parsing routines work. For Java, have a look at the SimpleDateFormat API, which gives you a rundown on all the settings along with some useful examples. Use caution when running code on distributed systems and also with different time zones.</p>
              <p id="c02-c02-para-0107" xml:space="preserve"><a id="c02-c02-tbl-anc-0001" href="#c02-c02-tbl-0001" external="false" smilref="Machine_Learning00002.smil#c02-c02-tbl-anc-0001">Table 2-1</a><span class="text" id="span_000118" smilref="Machine_Learning00002.smil#span_000118"> shows some of the commonly used date/time formats.</span></p>
              <figure id="figure_000005">
                <figcaption id="figcaption_000002">
                  <p xml:space="preserve" id="p_000099"><span class="figureLabel" id="span_000119"><a id="c02-c02-tbl-0001" href="#c02-c02-tbl-anc-0001" external="false"><strong id="strong_000037" smilref="Machine_Learning00002.smil#strong_000037">Table 2-1</strong></a></span><span class="text" id="span_000120" smilref="Machine_Learning00002.smil#span_000120"> Commonly Used Date/Time Formats</span></p>
                </figcaption>
                <table border="1" id="table_000004">
                  <tr id="tr_000010">
                    <td class="left" rowspan="1" colspan="1" id="td_000037" smilref="Machine_Learning00002.smil#td_000037">Date/Time Format</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000038" smilref="Machine_Learning00002.smil#td_000038">SimpleDateFormat Representation</td>
                  </tr>
                  <tr id="tr_000011">
                    <td class="left" rowspan="1" colspan="1" id="td_000039" smilref="Machine_Learning00002.smil#td_000039">2014-01-01</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000040" smilref="Machine_Learning00002.smil#td_000040">Yyyy-MM-dd</td>
                  </tr>
                  <tr id="tr_000012">
                    <td class="left" rowspan="1" colspan="1" id="td_000041" smilref="Machine_Learning00002.smil#td_000041">2014-01-01 11:59:00</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000042" smilref="Machine_Learning00002.smil#td_000042">Yyyy-MM-dd hh:mm:ss</td>
                  </tr>
                  <tr id="tr_000013">
                    <td class="left" rowspan="1" colspan="1" id="td_000043" smilref="Machine_Learning00002.smil#td_000043">1388577540</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000044" smilref="Machine_Learning00002.smil#td_000044">(Unix timestamps are like long variable types but with nano seconds added.)</td>
                  </tr>
                </table>
              </figure>
              <p id="c02-c02-para-0108" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0108">I've seen many a database table with different date formats that have been saved as string types. Things have gotten better, but it's still something I keep in mind.</p>
            </level3>
            <level3 id="level3_000059">
              <h3 xml:space="preserve" id="h3_000059" smilref="Machine_Learning00002.smil#h3_000059">Final Thoughts on Data Cleaning</h3>
              <p xml:space="preserve" id="p_000100"><span class="text" id="span_000121" smilref="Machine_Learning00002.smil#span_000121">Data cleaning is a big deal, because it increases the chances of getting better results. For some Big Data projects, 80 percent of the project time is spent on </span><pagenum epub:type="pagebreak" id="p36" page="normal" smilref="Machine_Learning00002.smil#p36">36</pagenum><span class="text" id="span_000122" smilref="Machine_Learning00002.smil#span_000122">data cleaning before the actual analysis starts. It's important to keep this step high up in the project plan and manage time accordingly.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000022">
            <h2 id="c02-c02_level1_11" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_11">Thinking about Input Data</h2>
            <p xml:space="preserve" id="p_000101" smilref="Machine_Learning00002.smil#p_000101">With any machine learning project, you need to think about the incoming data, what format it's in, and how it will be accessed by the code that's being built.</p>
            <p id="c02-c02-para-0111" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0111">Data comes in all sorts of forms, so it's a good idea to know what you're dealing with before you start crafting any code. The following sections describe some of the more common data formats.</p>
            <level3 id="level3_000060">
              <h3 xml:space="preserve" id="h3_000060" smilref="Machine_Learning00002.smil#h3_000060">Raw Text</h3>
              <p xml:space="preserve" id="p_000102" smilref="Machine_Learning00002.smil#p_000102">Basic raw text files are used in many publications. If you look at the likes of the Guttenberg Project, you'll see that you can download works in a raw text file. The data is unstructured, so it rarely has a proper form with which you can work.</p>
              <p xml:space="preserve" id="p_000103"><code class="preserve-whitespace" xml:space="preserve" id="code_000038" smilref="Machine_Learning00002.smil#code_000038">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse eget metus quis erat tempor hendrerit. Vestibulum turpis ante, bibendum vitae nisi non, euismod blandit dui. Maecenas tristique consectetur est nec elementum. Maecenas porttitor, arcu sed gravida tempus, purus tellus lacinia erat, dapibus euismod felis enim eget nisl. Nunc mollis volutpat ligula. Etiam interdum porttitor nulla non lobortis.</code></p>
              <p id="c02-c02-para-0113" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0113">Common formats for text files are Unicode, ASCII, or UTF-8. If there's any international encoding required, UTF-8 or Unicode are most common. Note that PDF documents, Rich Text Format files, and Word documents are not raw text files. Microsoft Office documents (such as Word files) are particularly troublesome because of “smart quotes” and other non-text extraneous characters that wreak havoc in Java programs.</p>
            </level3>
            <level3 id="level3_000061">
              <h3 xml:space="preserve" id="h3_000061" smilref="Machine_Learning00002.smil#h3_000061">Comma Separated Variables</h3>
              <p xml:space="preserve" id="p_000104" smilref="Machine_Learning00002.smil#p_000104">The CSV format is widely used across the data landscape. The comma character is used between each field of data. You might find that other delimiters are used, such as tabulation (TSV) and the pipe (|) symbol (PSV). Delimiters are not limited to one character either. If you look at something like the USDA Food Database you'll see ˜^˜ used as a delimiter. The following CSV file is generated from a fake name generator site. (It's always good to use fake data when you're testing things.)</p>
              <p xml:space="preserve" id="p_000105"><code class="preserve-whitespace" xml:space="preserve" id="code_000039" smilref="Machine_Learning00002.smil#code_000039">1,male,Mr.,Joe,L,Perry,50 Park Row,EDERN,,LL53 2SQ,GB,United Kingdom,JoePerry@einrot.com,Annever,eiThahph9Ah,077 6473 7650,Fry,7/4/1991,Visa,4539148712302735,342,2/2018,YB 20 98 60 A,1Z 23F 389 61 4167 727 1,Blue,Nephrology nurse,Friendly Advice,1999 Alfa Romeo 145,BadProtection.co.uk,O+,169.4,77.0,5' 10",177,a617f840-6e42-4146-b743-090ee59c2c9f,52.806493,-4.72918
2,male,Mr.,Daniel,J,Carpenter,51 Guildford Rd,EAST DRAYTON,,DN22 3GT,GB,United Kingdom,DanielCarpenter@teleworm.us,Reste1990,Eich1Kiegie,079 2890 2948,Harris,3/26/1990,MasterCard,5353722386063326,717,7/2018,KL 50 03 59 C,1Z 895 362 50 0377 620 2,Blue,Corporate administrative assistant,Hit or Miss,2000 Jeep Grand Cherokee,BiologyConvention.co.uk,AB+,175.3,79.7,5' 7",169,ac907a59-a091-4ba2-9b0f-a1276b3b5ada,52.801024,-0.719021
3,male,Mr.,Harvey,A,Hawkins,37 Shore Street,STOKE TALMAGE,,OX9 4FY,GB,United Kingdom,HarveyHawkins@armyspy.com,Spicionly,UcheeGh9xoh,077 7965 0825,Rees,3/1/1974,MasterCard,5131613608666799,523,7/2017,SS 81 32 33 C,1Z Y11 884 19 7792 722 8,Black,Education planner,Monsource,1999 BMW 740,LightingShadows.co.uk,A-,224.8,102.2,6' 1",185,6cf865fb-81ae-42af-9a9d-5b86d5da7ce9,51.573674,-1.179834
4,male,Mr.,Kyle,E,Patel,97 Cloch Rd,ST MARTIN,,TR12 6LT,GB,United Kingdom,KylePatel@superrito.com,Wilvear,de2EeJew,079 2879 6351,Hancock,6/7/1978,Visa,4916480323599950,960,4/2016,MH 93 02 76 D,1Z 590 692 15 4564 674 8,Blue,Interior decorator,Grade A Investment,2002 Proton Juara,ConsumerMenu.co.uk,AB+,189.2,86.0,5' 10",179,e977c58e-ba61-406e-a1d1-2904807be365,49.957435,-5.258628
5,male,Mr.,Dylan,A,Willis,66 Temple Way,WINWICK,,WA2 5HE,GB,United Kingdom,DylanWillis@cuvox.de,Hishound,shael7Foo,077 1105 4178,Kelly,8/16/1948,Visa,4485311140499796,423,11/2016,WG 24 10 62 D,1Z 538 4E0 39 8247 102 7,Black,Community health educator,Mr. Steak,2002 Nissan X-Trail,FakeRomance.co.uk,A+,170.1,77.3,5' 9",175,335c2508-71be-43ad-9760-4f5c186ec029,53.443749,-2.631634
6,female,Mrs.,Courtney,R,Jordan,42 Kendell Street,SHARLSTON,,WF4 1PZ,GB,United Kingdom,CourtneyJordan@fleckens.hu,Ponforsittle,Hi2oteel1,070 3469 5710,Payne,2/23/1982,MasterCard,5570815007804057,456,12/2019,CJ 87 95 98 D,1Z 853 489 84 8609 859 3,Blue,Mechanical inspector,Olson Electronics,2000 Chrysler LHS,LandscapeCovers.co.uk,B+,143.9,65.4,5' 3",161,27d229b0-6106-4700-8533-5edc2661a0bf,53.645118,-1.563952</code></p>
              <pagenum epub:type="pagebreak" id="p37" page="normal" smilref="Machine_Learning00002.smil#p37">37</pagenum>
              <p id="c02-c02-para-0115" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0115">People might refer to files as CSV files even though they are not comma separated. The best way to find out if something is really a CSV file is to open up the data and have a look.</p>
            </level3>
            <level3 id="level3_000062">
              <h3 xml:space="preserve" id="h3_000062" smilref="Machine_Learning00002.smil#h3_000062">JSON</h3>
              <p xml:space="preserve" id="p_000106"><span class="text" id="span_000123" smilref="Machine_Learning00002.smil#span_000123">JavaScript Object Notation (JSON) is a commonly used data format that utilizes key/value pairs to communicate data between machines and the web. It </span><pagenum epub:type="pagebreak" id="p38" page="normal" smilref="Machine_Learning00002.smil#p38">38</pagenum><span class="text" id="span_000124" smilref="Machine_Learning00002.smil#span_000124">was designed as an alternative to XML. Don't be fooled by the use of the word JavaScript; you don't need JavaScript in order to use this data format. There are JSON parsers for various languages. The earlier CSV example used fake name data; here's the first entry of the CSV in JSON notation:</span></p>
              <p xml:space="preserve" id="p_000107"><code class="preserve-whitespace" xml:space="preserve" id="code_000040" smilref="Machine_Learning00002.smil#code_000040">[
  {
    "Number":1,
    "Gender":"male",
    "Title":"Mr.",
    "GivenName":"Joe",
    "MiddleInitial":"L",
    "Surname":"Perry",
    "StreetAddress":"50 Park Row",
    "City":"EDERN",
    "State":"",
    "ZipCode":"LL53 2SQ",
    "Country":"GB",
    "CountryFull":"United Kingdom",
    "EmailAddress":"JoePerry@einrot.com",
    "Username":"Annever",
    "Password":"eiThahph9Ah",
    "TelephoneNumber":"077 6473 7650",
    "MothersMaiden":"Fry",
    "Birthday":"7/4/1991",
    "CCType":"Visa",
    "CCNumber":4539148712302735,
    "CVV2":342,
    "CCExpires":"2/2018",
    "NationalID":"YB 20 98 60 A",
    "UPS":"1Z 23F 389 61 4167 727 1",
    "Color":"Blue",
    "Occupation":"Nephrology nurse",
    "Company":"Friendly Advice",
    "Vehicle":"1999 Alfa Romeo 145",
    "Domain":"BadProtection.co.uk",
    "BloodType":"O+",
    "Pounds":169.4,
    "Kilograms":77.0,
    "FeetInches":"5' 10\"",
    "Centimeters":177,
    "GUID":"a617f840-6e42-4146-b743-090ee59c2c9f",
    "Latitude":52.806493,
    "Longitude":-4.72918
  }
]</code></p>
              <p id="c02-c02-para-0117" xml:space="preserve"><span class="text" id="span_000125" smilref="Machine_Learning00002.smil#span_000125">Many application-programming interfaces (APIs) use JSON to send response data back to the requesting program. Some parsers might take the JSON data </span><pagenum epub:type="pagebreak" id="p39" page="normal" smilref="Machine_Learning00002.smil#p39">39</pagenum><span class="text" id="span_000126" smilref="Machine_Learning00002.smil#span_000126">and represent it as an object. Others might be able to create a hash map of the data for you to access.</span></p>
            </level3>
            <level3 id="level3_000063">
              <h3 xml:space="preserve" id="h3_000063" smilref="Machine_Learning00002.smil#h3_000063">YAML</h3>
              <p xml:space="preserve" id="p_000108" smilref="Machine_Learning00002.smil#p_000108">Whereas JSON is a document markup format, YAML (meaning “YAML Ain't Markup Language”) is most certainly a data format. It's not as widely used as JSON but from a distance looks very similar.</p>
              <p xml:space="preserve" id="p_000109"><code class="preserve-whitespace" xml:space="preserve" id="code_000041" smilref="Machine_Learning00002.smil#code_000041">date   : 2014-01-02
bill-to: &amp;id001
    given  : Jason
    family : Bell
    address:
        lines: |
            458 Some Street Somewhere
            In Some Suburb
        city    : MyCity
        state   : CA
        postal  : 55555</code></p>
            </level3>
            <level3 id="level3_000064">
              <h3 xml:space="preserve" id="h3_000064" smilref="Machine_Learning00002.smil#h3_000064">XML</h3>
              <p xml:space="preserve" id="p_000110" smilref="Machine_Learning00002.smil#p_000110">The extensible markup language (XML) followed on from the popular use of Standard Generalized Markup Language (SGML) for document markup. The idea was for XML to be easily read by humans and also by machines. On first inspection, XML is like Hypertext Markup Language (HTML); later versions of HTML use strict XML formatting types.</p>
              <p id="c02-c02-para-0120" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0120">XML gets criticism for its complexity, especially when reading large structures. That's one reason it's popular for web-based APIs to use JSON data as its response. There are a large number of APIs delivering XML response data, so it's worthwhile to look at how it works:</p>
              <p xml:space="preserve" id="p_000111"><code class="preserve-whitespace" xml:space="preserve" id="code_000042" smilref="Machine_Learning00002.smil#code_000042">&lt;?xml version="1.0" encoding="US-ASCII" standalone="no"?&gt;&lt;!DOCTYPE WileyML3G [&lt;!ENTITY % wileyml3g.ent SYSTEM "http://v.wiley.com:3535/dtds/wileyml3g/wiley.ent"&gt;%wileyml3g.ent;]&gt;
    &lt;Customer&gt;
        &lt;Number&gt;1&lt;/Number&gt;
        &lt;Gender&gt;male&lt;/Gender&gt;
        &lt;Title&gt;Mr.&lt;/Title&gt;
        &lt;GivenName&gt;Joe&lt;/GivenName&gt;
        &lt;MiddleInitial&gt;L&lt;/MiddleInitial&gt;
        &lt;Surname&gt;Perry&lt;/Surname&gt;
        &lt;StreetAddress&gt;50 Park Row&lt;/StreetAddress&gt;
        &lt;City&gt;EDERN&lt;/City&gt;
        &lt;State/&gt;
        &lt;ZipCode&gt;LL53 2SQ&lt;/ZipCode&gt;
        &lt;Country&gt;GB&lt;/Country&gt;
        &lt;CountryFull&gt;United Kingdom&lt;/CountryFull&gt;
        &lt;EmailAddress&gt;JoePerry@einrot.com&lt;/EmailAddress&gt;
        &lt;Username&gt;Annever&lt;/Username&gt;
        &lt;Password&gt;eiThahph9Ah&lt;/Password&gt;
        &lt;TelephoneNumber&gt;077 6473 7650&lt;/TelephoneNumber&gt;
        &lt;MothersMaiden&gt;Fry&lt;/MothersMaiden&gt;
        &lt;Birthday&gt;7/4/1991&lt;/Birthday&gt;
        &lt;CCType&gt;Visa&lt;/CCType&gt;
        &lt;CCNumber&gt;4539148712302735&lt;/CCNumber&gt;
        &lt;CVV2&gt;342&lt;/CVV2&gt;
        &lt;CCExpires&gt;2/2018&lt;/CCExpires&gt;
        &lt;NationalID&gt;YB 20 98 60 A&lt;/NationalID&gt;
        &lt;UPS&gt;1Z 23F 389 61 4167 727 1&lt;/UPS&gt;
        &lt;Color&gt;Blue&lt;/Color&gt;
        &lt;Occupation&gt;Nephrology nurse&lt;/Occupation&gt;
        &lt;Company&gt;Friendly Advice&lt;/Company&gt;
        &lt;Vehicle&gt;1999 Alfa Romeo 145&lt;/Vehicle&gt;
        &lt;Domain&gt;BadProtection.co.uk&lt;/Domain&gt;
        &lt;BloodType&gt;O+&lt;/BloodType&gt;
        &lt;Pounds&gt;169.4&lt;/Pounds&gt;
        &lt;Kilograms&gt;77&lt;/Kilograms&gt;
        &lt;FeetInches&gt;5' 10"&lt;/FeetInches&gt;
        &lt;Centimeters&gt;177&lt;/Centimeters&gt;
        &lt;GUID&gt;a617f840-6e42-4146-b743-090ee59c2c9f&lt;/GUID&gt;
        &lt;Latitude&gt;52.806493&lt;/Latitude&gt;
        &lt;Longitude&gt;-4.72918&lt;/Longitude&gt;
    &lt;/Customer&gt; </code></p>
              <pagenum epub:type="pagebreak" id="p40" page="normal" smilref="Machine_Learning00002.smil#p40">40</pagenum>
              <p id="c02-c02-para-0121" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0121">Most of the common languages have XML parsers available using either a document object model (DOM) parser or the Simple API for XML (SAX) parser. Both types come with advantages and disadvantages depending on the size and complexity of the XML document with which you are working.</p>
            </level3>
            <level3 id="level3_000065">
              <h3 xml:space="preserve" id="h3_000065" smilref="Machine_Learning00002.smil#h3_000065">Spreadsheets</h3>
              <p xml:space="preserve" id="p_000112" smilref="Machine_Learning00002.smil#p_000112">Talk to any finance person in your organization, and you'll discover that their entire world revolves around spreadsheets. Programmers have a tendency to shun spreadsheets in favor of data formats that make their lives easier. You can't totally ignore them, though. Spreadsheets are the lifeblood of an organization, and they probably hold most of the organization's data.</p>
              <p id="c02-c02-para-0123" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0123">There are lots of different spreadsheet programs, but the most commonly used applications are Microsoft Excel, Google Docs Spreadsheet, and LibreOffice.</p>
              <p id="c02-c02-para-0124" xml:space="preserve"><span class="text" id="span_000127" smilref="Machine_Learning00002.smil#span_000127">Fortunately there are programming APIs that you can use to extract the data from spreadsheets directly, which saves a lot of work in converting </span><pagenum epub:type="pagebreak" id="p41" page="normal" smilref="Machine_Learning00002.smil#p41">41</pagenum><span class="text" id="span_000128" smilref="Machine_Learning00002.smil#span_000128">the spreadsheet to the likes of CSV files. It's worth studying the formulas in the spreadsheets, because there might be some algorithms lurking there that are worth their weight in gold.</span></p>
              <p id="c02-c02-para-0125" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0125">If you want your finance person to be supportive of the project, tell that person that the results will be in a spreadsheet and you'll have a friend for a long time after.</p>
              <p id="c02-c02-para-0126" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0126">The Java programming language has a few APIs to choose from that will enable you to read and write spreadsheets. The Apache POI project and JExcel API are the two most popular.</p>
            </level3>
            <level3 id="level3_000066">
              <h3 xml:space="preserve" id="h3_000066" smilref="Machine_Learning00002.smil#h3_000066">Databases</h3>
              <p xml:space="preserve" id="p_000113" smilref="Machine_Learning00002.smil#p_000113">If you've been brought up with web programming, then you might have had some exposure to databases and database tables. Common ones are MySQL, Postgres, Microsoft SQL Server, and Oracle.</p>
              <p id="c02-c02-para-0128" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0128">Recently, there's been an explosion of NoSQL (meaning Not Only SQL), such as MongoDB, CouchDB, Cassandra, Redis, and HBase, which all bring their own flavors to data storage. These document and key/value stores move away from the rigid table-like structures of traditional databases.</p>
              <p id="c02-c02-para-0129" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0129">In addition, there are graph databases such as Apache Giraph and Neo4J and in-memory systems such as Spark, memcached, and Storm. Chapter 11 is an introduction to Spark.</p>
              <p id="c02-c02-para-0130" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0130">In my opinion, all databases have their place and are worth investigating. There's nothing wrong with having a relational, document and graph database running concurrently for the project. Each has its advantages to the project that you might not have considered. As with all these things, there might be a learning curve that you need to factor in to your project time.</p>
              <level4 id="level4_000003">
                <h4 xml:space="preserve" id="h4_000003" smilref="Machine_Learning00002.smil#h4_000003">Images</h4>
                <p xml:space="preserve" id="p_000114" smilref="Machine_Learning00002.smil#p_000114">The common data formats previously mentioned mainly deal with text or numbers in different shades, but you can't discount images. There are a number of things you can learn from images. Whether you're trying to use facial recognition or emotion tracking or you're trying to determine whether an image is a cat or dog (yes, it has been done), there are several APIs that will help.</p>
                <p id="c02-c02-para-0132" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0132">The most popular formats are the portable network graphics (PNG) and JPEG images; these are regularly used on the web. If processing power is freely available then TIFF or BMP are much larger files, but they contain more image information.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000023">
            <h2 id="c02-c02_level1_12" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_12">Thinking about Output Data</h2>
            <pagenum epub:type="pagebreak" id="p42" page="normal" smilref="Machine_Learning00002.smil#p42">42</pagenum>
            <p xml:space="preserve" id="p_000115" smilref="Machine_Learning00002.smil#p_000115">Now it's time to turn your attention to the output data. This is where the stakeholders might have a say in how things are going to be done, because ultimately it will be those people who deal with the results.</p>
            <p id="c02-c02-para-0134" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0134">The primary question about the output of machine learning data is, “Who is the intended audience?” Depending on the answer to that question, your output will vary. You might need a spreadsheet for the financial folks to see the results. If the audience is comprised of website users, then it makes sense to put the data back into a database table. The machine learning results could be merged with other data to define more learning. It really comes down to what was defined in the project.</p>
            <p id="c02-c02-para-0135" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0135">There are a number of paid and free reporting tools available. Some are full-blown systems, such as Jasper Reports, BIRT, and Tableau. If you are reporting to a web-based audience, then the likes of D3 and Processing might be of help to you.</p>
          </level2>
          <level2 id="level2_000024">
            <h2 id="c02-c02_level1_13" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_13">Don't Be Afraid to Experiment</h2>
            <p xml:space="preserve" id="p_000116" smilref="Machine_Learning00002.smil#p_000116">It's safe to say that there is no “one solution fits all.” There are many components, formats, tools, and considerations to ponder on any project. In effect, every machine learning project starts with a clean sheet, and communication among all involved, from stakeholders all the way through to visualization. Tools and scripts can be reused, but every case is going to be different, so things need minor adjustments as you go along. Don't be afraid to play around with data as you acquire it; see if there's anything you can glean from it.</p>
            <p id="c02-c02-para-0137" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0137">It's also worth taking time to grab some open data and make your own scenarios and ask your own questions. It's like a musician practicing an instrument; it's worth putting in the hours, so you are ready for the day when the big gig arrives.</p>
            <p id="c02-c02-para-0138" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0138">The machine learning community is large, and there are plenty of blog posts, articles, videos, and books produced by the community. Forums are the perfect place to swap stories and experiences, too. As with most things, the more you put in, the more you will get out of it.</p>
            <p id="c02-c02-para-0139" xml:space="preserve"><span class="text" id="span_000129" smilref="Machine_Learning00002.smil#span_000129">Over the years, I've found that people are more than willing to help contribute to a solution if you're stuck on a problem. If you've not looked at the likes of </span><code xml:space="preserve" id="code_000043"><a href="http://stackoverflow.com" external="true" id="a_000274" smilref="Machine_Learning00002.smil#a_000274">http://stackoverflow.com</a></code><span class="text" id="span_000130" smilref="Machine_Learning00002.smil#span_000130">, a collaborative question and answer platform for software developers, then have a search around. Chances are that someone will have encountered the same problem as you.</span></p>
          </level2>
          <level2 id="level2_000025">
            <h2 id="c02-c02_level1_14" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02_level1_14">Summary</h2>
            <pagenum epub:type="pagebreak" id="p43" page="normal" smilref="Machine_Learning00002.smil#p43">43</pagenum>
            <p xml:space="preserve" id="p_000117" smilref="Machine_Learning00002.smil#p_000117">As with any project, planning is a key and essential part of machine learning and shouldn't be taken lightly. This chapter covered many aspects of planning, including processing, storage, privacy, and data cleaning. You were also introduced to some useful tools and commands that will help in the cleaning phases and some validation checks.</p>
            <p id="c02-c02-para-0141" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0141">The planning phase is a constantly evolving process, and the more machine learning projects you and the team perform, the more you will learn from previous mistakes.</p>
            <p id="c02-c02-para-0142" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0142">The key is to start small. Take a snapshot of the data and take a random sample with a size of 10 percent of the total. Get the team to inspect the data. Can you work with it? Do you anticipate any problems with the processing of this data?</p>
            <p id="c02-c02-para-0143" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0143">Cleaning the data might take the most time of the project; the actual processing might consume only a fraction of the overall project time. If you can supply clean data, then your results will be refined.</p>
            <p id="c02-c02-para-0144" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0144">Regardless of whether you are working on a ten-man team or on your own, be aware of your network of contacts; some might have domain knowledge that will be useful. Ask lots of questions, too. You'd be surprised how many folks are willing to answer questions in order to see you succeed.</p>
            <p id="c02-c02-para-0145" xml:space="preserve" smilref="Machine_Learning00002.smil#c02-c02-para-0145">The next few chapters examine some different machine learning techniques and put some sample code together, so you can start to apply them to your own projects.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c03">
        <section epub:type="chapter" id="section_000004">
          <header id="header_000003">
            <h1 id="c03-c3" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c3">Chapter 3 Working with Decision Trees</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p45" page="normal" smilref="Machine_Learning00002.smil#p45">45</pagenum>
          <p xml:space="preserve" id="p_000118" smilref="Machine_Learning00002.smil#p_000118">Do not be deceived by the decision tree; at first glance it might look like a simple concept, but within the simplicity lies the power. This chapter shows you how decision trees work. The examples use Weka to create a working decision tree that will also create the Java code for you.</p>
          <level2 id="level2_000026">
            <h2 id="c03-c03_level1_1" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03_level1_1">The Basics of Decision Trees</h2>
            <p xml:space="preserve" id="p_000119" smilref="Machine_Learning00002.smil#p_000119">The aim with any decision tree is to create a workable model that will predict the value of a target variable based on the set of input variables. This section explains where decision trees are used along with some of the advantages and limitations of decision trees. In this section you also find out how a decision tree is calculated manually so you can see the math involved.</p>
            <level3 id="level3_000067">
              <h3 xml:space="preserve" id="h3_000067" smilref="Machine_Learning00002.smil#h3_000067">Uses for Decision Trees</h3>
              <p xml:space="preserve" id="p_000120" smilref="Machine_Learning00002.smil#p_000120">Think about how you select different options within an automated telephone call. The options are essentially decisions that are being made for you to get to the desired department. These decision trees are used effectively in many industry areas.</p>
              <pagenum epub:type="pagebreak" id="p46" page="normal" smilref="Machine_Learning00002.smil#p46">46</pagenum>
              <p id="c03-c03-para-0004" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0004">Financial institutions use decision trees. One of the fundamental use cases is in option pricing, where a binary-like decision tree is used to predict the price of an option in either a bull or bear market.</p>
              <p id="c03-c03-para-0005" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0005">Marketers use decision trees to establish customers by type and predict whether a customer will buy a specific type of product.</p>
              <p id="c03-c03-para-0006" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0006">In the medical field, decision tree models have been designed to diagnose blood infections or even predict heart attack outcomes in chest pain patients. Variables in the decision tree include diagnosis, treatment, and patient data.</p>
              <p id="c03-c03-para-0007" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0007">The gaming industry now uses multiple decision trees in movement recognition and facial recognition. The Microsoft Kinect platform uses this method to track body movement. The Kinect team used one million images and trained three trees. Within one day, and using a 1,000-core cluster, the decision trees were classifying specific body parts across the screen.</p>
            </level3>
            <level3 id="level3_000068">
              <h3 xml:space="preserve" id="h3_000068" smilref="Machine_Learning00002.smil#h3_000068">Advantages of Decision Trees</h3>
              <p xml:space="preserve" id="p_000121" smilref="Machine_Learning00002.smil#p_000121">There are some good reasons to use decision trees. For one thing, they are easy to read. After a model is generated, it's easy to report back to others regarding how the tree works. Also, with decision trees you can handle numerical or categorized information. Later, this chapter demonstrates how to manually work through an algorithm with category values; the example walkthrough uses numerical data.</p>
              <p id="c03-c03-para-0009" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0009">In terms of data preparation, there's little to do. As long as the data is formalized in something like comma separated variables, then you can create a working model. This also makes it easy to validate the model using various tests. With decision trees you use white-box testing—meaning the internal workings can be observed but not changed; you can view the steps that are being used when the tree is being modeled.</p>
              <p id="c03-c03-para-0010" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0010">Decision trees perform well with reasonable amounts of computing power. If you have a large set of data, then decision tree learning will handle it well.</p>
            </level3>
            <level3 id="level3_000069">
              <h3 xml:space="preserve" id="h3_000069" smilref="Machine_Learning00002.smil#h3_000069">Limitations of Decision Trees</h3>
              <p xml:space="preserve" id="p_000122" smilref="Machine_Learning00002.smil#p_000122">With every set of advantages there's usually a set of disadvantages sitting in the background. One of the main issues of decision trees is that they can create overly complex models, depending on the data presented in the training set. To avoid the machine learning algorithm's over-fitting the data, it's sometimes worth reviewing the training data and pruning the values to categories, which will produce a more refined and better-tuned model.</p>
              <p id="c03-c03-para-0012" xml:space="preserve"><span class="text" id="span_000131" smilref="Machine_Learning00002.smil#span_000131">Some of the decision tree concepts can be hard to learn because the model cannot express them easily. This shortcoming sometimes results in a larger-than-normal model. </span><pagenum epub:type="pagebreak" id="p47" page="normal" smilref="Machine_Learning00002.smil#p47">47</pagenum><span class="text" id="span_000132" smilref="Machine_Learning00002.smil#span_000132">You might be required to change the model or look at different methods of machine learning.</span></p>
            </level3>
            <level3 id="level3_000070">
              <h3 xml:space="preserve" id="h3_000070" smilref="Machine_Learning00002.smil#h3_000070">Different Algorithm Types</h3>
              <p xml:space="preserve" id="p_000123" smilref="Machine_Learning00002.smil#p_000123">Over the years, there have been various algorithms developed for decision tree analysis. Some of the more common ones are listed here.</p>
              <level4 id="level4_000004">
                <h4 xml:space="preserve" id="h4_000004" smilref="Machine_Learning00002.smil#h4_000004">ID3</h4>
                <p xml:space="preserve" id="p_000124"><span class="text" id="span_000133" smilref="Machine_Learning00002.smil#span_000133">The </span><em id="em_000017" smilref="Machine_Learning00002.smil#em_000017">ID3</em><span class="text" id="span_000134" smilref="Machine_Learning00002.smil#span_000134"> (Iterative Dichotomiser 3) algorithm was invented by Ross Quinlan to create trees from datasets. By calculating the entropy for every attribute in the dataset, this could be split into subsets based on the minimum entropy value. After the set had a decision tree node created, all that was required was to recursively go through the remaining attributes in the set.</span></p>
                <p id="c03-c03-para-0015" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0015">ID3 uses the method of information gain—the measure of difference in entropy before and after an attribute is split—to decide on the root node (the node with the highest information gain).</p>
                <p id="c03-c03-para-0016" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0016">ID3 suffered from over-fitting on training data, and the algorithm was better suited to smaller trees than large ones. The ID3 algorithm is used less these days in favor of the C4.5 algorithm, which is outlined next.</p>
              </level4>
              <level4 id="level4_000005">
                <h4 xml:space="preserve" id="h4_000005" smilref="Machine_Learning00002.smil#h4_000005">C4.5</h4>
                <p xml:space="preserve" id="p_000125" smilref="Machine_Learning00002.smil#p_000125">Quinlan came back for an encore with the C4.5 algorithm. It's also based on the information gain method, but it enables the trees to be used for classification. This is a widely used algorithm in that many users run in Weka with the open source Java version of C4.5, the J48 algorithm.</p>
                <p id="c03-c03-para-0018" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0018">There are notable improvements in C4.5 over the original ID3 algorithm. With the ability to work on continuous attributes, the C4.5 method will calculate a threshold point for the split to occur. For example, with a list of values like the following:</p>
                <p id="c03-c03-para-0019" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0019">85,80,83,70,68,65,64,72,69,75,75,72,81,71</p>
                <p id="c03-c03-para-0020" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0020">C4.5 will work out a split point for the attribute (a) and give a simple decision criterion of:</p>
                <p xml:space="preserve" id="p_000126"><em id="em_000018" smilref="Machine_Learning00002.smil#em_000018">a</em><span class="text" id="span_000135" smilref="Machine_Learning00002.smil#span_000135"> &lt;= </span><em id="em_000019" smilref="Machine_Learning00002.smil#em_000019">80 or a</em><span class="text" id="span_000136" smilref="Machine_Learning00002.smil#span_000136"> &gt; </span><em id="em_000020" smilref="Machine_Learning00002.smil#em_000020">80</em></p>
                <p id="c03-c03-para-0022" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0022">C4.5 has the ability to work despite missing attribute values. The missing values are marked with a question mark (?). The gain and entropy calculations are simply skipped when there is no data available.</p>
                <pagenum epub:type="pagebreak" id="p48" page="normal" smilref="Machine_Learning00002.smil#p48">48</pagenum>
                <p id="c03-c03-para-0023" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0023">Trees created with C4.5 are pruned after creation; the algorithm will revisit the nodes and decide if a node is contributing to the result in the tree. If it isn't, then it's replaced with a leaf node.</p>
              </level4>
              <level4 id="level4_000006">
                <h4 xml:space="preserve" id="h4_000006" smilref="Machine_Learning00002.smil#h4_000006">CHAID</h4>
                <p xml:space="preserve" id="p_000127"><span class="text" id="span_000137" smilref="Machine_Learning00002.smil#span_000137">The </span><em id="em_000021" smilref="Machine_Learning00002.smil#em_000021">CHAID</em><span class="text" id="span_000138" smilref="Machine_Learning00002.smil#span_000138"> (</span><em id="em_000022" smilref="Machine_Learning00002.smil#em_000022">Chi-squared Automatic Interaction Detection</em><span class="text" id="span_000139" smilref="Machine_Learning00002.smil#span_000139">) technique was developed by Gordon V. Kass in 1980. The main use of it was within marketing, but it was also used within medical and psychiatric research.</span></p>
              </level4>
              <level4 id="level4_000007">
                <h4 xml:space="preserve" id="h4_000007" smilref="Machine_Learning00002.smil#h4_000007">MARS</h4>
                <p xml:space="preserve" id="p_000128"><span class="text" id="span_000140" smilref="Machine_Learning00002.smil#span_000140">For numerical data, it might be worth investigating the </span><em id="em_000023" smilref="Machine_Learning00002.smil#em_000023">MARS</em><span class="text" id="span_000141" smilref="Machine_Learning00002.smil#span_000141"> (</span><em id="em_000024" smilref="Machine_Learning00002.smil#em_000024">multivariate adaptive regression splines</em><span class="text" id="span_000142" smilref="Machine_Learning00002.smil#span_000142">) algorithm. You might see this as an open source alternative called “Earth,” as MARS is trademarked by Salford Systems.</span></p>
              </level4>
            </level3>
            <level3 id="level3_000071">
              <h3 xml:space="preserve" id="h3_000071" smilref="Machine_Learning00002.smil#h3_000071">How Decision Trees Work</h3>
              <p xml:space="preserve" id="p_000129"><span class="text" id="span_000143" smilref="Machine_Learning00002.smil#span_000143">Every tree is comprised of nodes. Each node is associated with one of the input variables. The edges coming from that node are the total possible values of that node. A leaf represents the value based on the values given from the input variable in the path running from the root node to the leaf. Because a picture paints a thousand words, see </span><a id="c03-c03-fig-anc-0001" href="#c03-c03-fig-0001" external="false" smilref="Machine_Learning00002.smil#c03-c03-fig-anc-0001">Figure 3-1</a><span class="text" id="span_000144" smilref="Machine_Learning00002.smil#span_000144"> for an example.</span></p>
              <figure id="figure_000006">
                <img class="center" src="images/c03f001.jpg" alt="image" id="img_000003" />
                <figcaption id="figcaption_000003">
                  <p xml:space="preserve" id="p_000130"><span class="figureLabel" id="span_000145"><a id="c03-c03-fig-0001" href="#c03-c03-fig-anc-0001" external="false"><strong id="strong_000038" smilref="Machine_Learning00002.smil#strong_000038">Figure 3-1</strong></a></span><span class="text" id="span_000146" smilref="Machine_Learning00002.smil#span_000146"> A decision tree</span></p>
                </figcaption>
              </figure>
              <p id="c03-c03-para-0027" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0027">Decision trees always start with a root node and end on a leaf. Notice that the trees don't converge at any point; they split their way out as the nodes are processed.</p>
              <p id="c03-c03-para-0028" xml:space="preserve"><a href="#c03-c03-fig-0001" external="false" id="a_000275" smilref="Machine_Learning00002.smil#a_000275">Figure 3-1</a> <pagenum epub:type="pagebreak" id="p49" page="normal" smilref="Machine_Learning00002.smil#p49">49</pagenum><span class="text" id="span_000147" smilref="Machine_Learning00002.smil#span_000147">shows a decision tree that classifies a loan decision. The root node is “Age” and has two branches that come from it, whether the customer is younger than 55 years old or older.</span></p>
              <p id="c03-c03-para-0029" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0029">The age of the client determines what happens next. If the person is younger than 55, then the tree prompts you to find out if he or she is a student. If the client is older than 55 then you are prompted to check his or her credit rating.</p>
              <p id="c03-c03-para-0030" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0030">With this type of machine learning, you are using supervised learning to deduce the optimal method to make a prediction; what I mean by “supervised learning” is that you give the classifier data with the outcomes. The real question is, “What's the best node to start with as the root node?” The next section examines how that calculation is done.</p>
              <level4 id="level4_000008">
                <h4 xml:space="preserve" id="h4_000008" smilref="Machine_Learning00002.smil#h4_000008">Building a Decision Tree</h4>
                <p xml:space="preserve" id="p_000131" smilref="Machine_Learning00002.smil#p_000131">Decision trees are built around the basic concept of this algorithm.</p>
                <list type="ul" id="list_000027">
                  <li id="li_000285" smilref="Machine_Learning00002.smil#li_000285">Check the model for the base cases.</li>
                  <li id="li_000286">
                    <span class="text" id="span_000148" smilref="Machine_Learning00002.smil#span_000148">Iterate through all the attributes (</span>
                    <code xml:space="preserve" id="code_000044" smilref="Machine_Learning00002.smil#code_000044">attr</code>
                    <span class="text" id="span_000149" smilref="Machine_Learning00002.smil#span_000149">).</span>
                  </li>
                  <li id="li_000287">
                    <span class="text" id="span_000150" smilref="Machine_Learning00002.smil#span_000150">Get the normalized information gain from splitting on</span>
                    <code xml:space="preserve" id="code_000045" smilref="Machine_Learning00002.smil#code_000045">attr</code>
                    <span class="text" id="span_000151" smilref="Machine_Learning00002.smil#span_000151">.</span>
                  </li>
                  <li id="li_000288">
                    <span class="text" id="span_000152" smilref="Machine_Learning00002.smil#span_000152">Let</span>
                    <code xml:space="preserve" id="code_000046" smilref="Machine_Learning00002.smil#code_000046">best_attr</code>
                    <span class="text" id="span_000153" smilref="Machine_Learning00002.smil#span_000153">be the attribute with the highest information gain.</span>
                  </li>
                  <li id="li_000289">
                    <span class="text" id="span_000154" smilref="Machine_Learning00002.smil#span_000154">Create a decision node that splits on the</span>
                    <code xml:space="preserve" id="code_000047" smilref="Machine_Learning00002.smil#code_000047">best_attr</code>
                    <span class="text" id="span_000155" smilref="Machine_Learning00002.smil#span_000155">attribute.</span>
                  </li>
                  <li id="li_000290">
                    <span class="text" id="span_000156" smilref="Machine_Learning00002.smil#span_000156">Work on the sublists that are obtained by splitting on</span>
                    <code xml:space="preserve" id="code_000048" smilref="Machine_Learning00002.smil#code_000048">best_attr</code>
                    <span class="text" id="span_000157" smilref="Machine_Learning00002.smil#span_000157">and add those nodes as child nodes.</span>
                  </li>
                </list>
                <p id="c03-c03-para-0032" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0032">That's the basic outline of what happens when you build a decision tree. Depending on the algorithm type, like the ones previously mentioned, there might be subtle differences in the way things are done.</p>
              </level4>
              <level4 id="level4_000009">
                <h4 xml:space="preserve" id="h4_000009" smilref="Machine_Learning00002.smil#h4_000009">Manually Walking Through an Example</h4>
                <p xml:space="preserve" id="p_000132" smilref="Machine_Learning00002.smil#p_000132">If you are interested in the basic mechanics of how the algorithm works and want to follow along, this section walks through the basics of calculating entropy and information gain. If you want to get to the hands-on part of the chapter, then you can skip this section.</p>
                <p id="c03-c03-para-0034" xml:space="preserve" smilref="Machine_Learning00002.smil#c03-c03-para-0034">The method of using information gain based on pre- and post-attribute entropy is the key method used within the ID3 and C4.5 algorithms. As these are the commonly used algorithms, this section concentrates on that basic method of finding out how the decision tree is built.</p>
                <p id="c03-c03-para-0035" xml:space="preserve"><span class="text" id="span_000158" smilref="Machine_Learning00002.smil#span_000158">With machine learning–based decision trees, you can get the algorithm to do all the work for you. It will figure out which is the best node to use as the root node. This requires finding out the purity of each node. Consider </span><a id="c03-c03-tbl-anc-0001" href="#c03-c03-tbl-0001" external="false" smilref="Machine_Learning00002.smil#c03-c03-tbl-anc-0001">Table 3-1</a><span class="text" id="span_000159" smilref="Machine_Learning00002.smil#span_000159">, </span><pagenum epub:type="pagebreak" id="p50" page="normal" smilref="Machine_Learning00002.smil#p50">50</pagenum><span class="text" id="span_000160" smilref="Machine_Learning00002.smil#span_000160">which includes only true/false values, of some user purchases through an e-commerce store.</span></p>
                <figure id="figure_000007">
                  <figcaption id="figcaption_000004">
                    <p xml:space="preserve" id="p_000133"><span class="figureLabel" id="span_000161"><a id="c03-c03-tbl-0001" href="#c03-c03-tbl-anc-0001" external="false"><strong id="strong_000039" smilref="Machine_Learning00002.smil#strong_000039">Table 3-1</strong></a></span><span class="text" id="span_000162" smilref="Machine_Learning00002.smil#span_000162"> Users' Purchase History</span></p>
                  </figcaption>
                  <table border="1" id="table_000005">
                    <tr id="tr_000014">
                      <td class="left" rowspan="1" colspan="1" id="td_000045" />
                      <td class="left" rowspan="1" colspan="1" id="td_000046" smilref="Machine_Learning00002.smil#td_000046">Has credit account?</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000047" smilref="Machine_Learning00002.smil#td_000047">Read reviews</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000048" smilref="Machine_Learning00002.smil#td_000048">Previous customer?</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000049" smilref="Machine_Learning00002.smil#td_000049">Did purchase?</td>
                    </tr>
                    <tr id="tr_000015">
                      <td class="left" rowspan="1" colspan="1" id="td_000050">
                        <strong id="strong_000040" smilref="Machine_Learning00002.smil#strong_000040">User A</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000051" smilref="Machine_Learning00002.smil#td_000051">N</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000052" smilref="Machine_Learning00002.smil#td_000052">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000053" smilref="Machine_Learning00002.smil#td_000053">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000054" smilref="Machine_Learning00002.smil#td_000054">Y</td>
                    </tr>
                    <tr id="tr_000016">
                      <td class="left" rowspan="1" colspan="1" id="td_000055">
                        <strong id="strong_000041" smilref="Machine_Learning00002.smil#strong_000041">User B</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000056" smilref="Machine_Learning00002.smil#td_000056">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000057" smilref="Machine_Learning00002.smil#td_000057">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000058" smilref="Machine_Learning00002.smil#td_000058">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000059" smilref="Machine_Learning00002.smil#td_000059">Y</td>
                    </tr>
                    <tr id="tr_000017">
                      <td class="left" rowspan="1" colspan="1" id="td_000060">
                        <strong id="strong_000042" smilref="Machine_Learning00002.smil#strong_000042">User C</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000061" smilref="Machine_Learning00002.smil#td_000061">N</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000062" smilref="Machine_Learning00002.smil#td_000062">N</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000063" smilref="Machine_Learning00003.smil#td_000063">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000064" smilref="Machine_Learning00003.smil#td_000064">N</td>
                    </tr>
                    <tr id="tr_000018">
                      <td class="left" rowspan="1" colspan="1" id="td_000065">
                        <strong id="strong_000043" smilref="Machine_Learning00003.smil#strong_000043">User D</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000066" smilref="Machine_Learning00003.smil#td_000066">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000067" smilref="Machine_Learning00003.smil#td_000067">N</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000068" smilref="Machine_Learning00003.smil#td_000068">N</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000069" smilref="Machine_Learning00003.smil#td_000069">Y</td>
                    </tr>
                    <tr id="tr_000019">
                      <td class="left" rowspan="1" colspan="1" id="td_000070">
                        <strong id="strong_000044" smilref="Machine_Learning00003.smil#strong_000044">User E</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000071" smilref="Machine_Learning00003.smil#td_000071">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000072" smilref="Machine_Learning00003.smil#td_000072">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000073" smilref="Machine_Learning00003.smil#td_000073">Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000074" smilref="Machine_Learning00003.smil#td_000074">Y</td>
                    </tr>
                  </table>
                </figure>
                <p id="c03-c03-para-0036" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0036">There are four nodes in the table:</p>
                <list type="ul" id="list_000028">
                  <li id="li_000291" smilref="Machine_Learning00003.smil#li_000291">Does the customer have an account?</li>
                  <li id="li_000292" smilref="Machine_Learning00003.smil#li_000292">Did the customer read previous product reviews?</li>
                  <li id="li_000293" smilref="Machine_Learning00003.smil#li_000293">Is the customer a returning customer?</li>
                  <li id="li_000294" smilref="Machine_Learning00003.smil#li_000294">Did the customer purchase the product?</li>
                </list>
                <p id="c03-c03-para-0037" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0037">At the start of calculating the decision tree there is no awareness of the node that will give the best result. You're looking for the node that can best predict the outcome. This requires some calculation. Enter entropy.</p>
              </level4>
              <level4 id="level4_000010">
                <h4 xml:space="preserve" id="h4_000010" smilref="Machine_Learning00003.smil#h4_000010">Calculating Entropy</h4>
                <p xml:space="preserve" id="p_000134" smilref="Machine_Learning00003.smil#p_000134">Entropy is a measure of uncertainty and is measured in bits and comes as a number between zero and 1 (entropy bits are not the same bits as used in computing terminology). Basically, you are looking for the unpredictability in a random variable.</p>
                <p id="c03-c03-para-0039" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0039">You need to calculate the gain for the positive and negative cases. I've written a quick Java program to do the calculating:</p>
                <p xml:space="preserve" id="p_000135"><code class="preserve-whitespace" xml:space="preserve" id="code_000049"><strong id="strong_000045" smilref="Machine_Learning00003.smil#strong_000045">package</strong><span class="text" id="span_000163" smilref="Machine_Learning00003.smil#span_000163"> chapter3;
</span><strong id="strong_000046" smilref="Machine_Learning00003.smil#strong_000046">public</strong> <strong id="strong_000047" smilref="Machine_Learning00003.smil#strong_000047">class</strong><span class="text" id="span_000164" smilref="Machine_Learning00003.smil#span_000164"> InformationGain {
    </span><strong id="strong_000048" smilref="Machine_Learning00003.smil#strong_000048">private</strong> <strong id="strong_000049" smilref="Machine_Learning00003.smil#strong_000049">double</strong><span class="text" id="span_000165" smilref="Machine_Learning00003.smil#span_000165"> calcLog2(</span><strong id="strong_000050" smilref="Machine_Learning00003.smil#strong_000050">double</strong><span class="text" id="span_000166" smilref="Machine_Learning00003.smil#span_000166"> value) {
        </span><strong id="strong_000051" smilref="Machine_Learning00003.smil#strong_000051">if</strong><span class="text" id="span_000167" smilref="Machine_Learning00003.smil#span_000167">(value &lt;= 0.) {
            </span><strong id="strong_000052" smilref="Machine_Learning00003.smil#strong_000052">return</strong><span class="text" id="span_000168" smilref="Machine_Learning00003.smil#span_000168"> 0.;
        }
        </span><strong id="strong_000053" smilref="Machine_Learning00003.smil#strong_000053">return</strong><span class="text" id="span_000169" smilref="Machine_Learning00003.smil#span_000169"> Math.</span><em id="em_000025" smilref="Machine_Learning00003.smil#em_000025">log10</em><span class="text" id="span_000170" smilref="Machine_Learning00003.smil#span_000170">(value) / Math.</span><em id="em_000026" smilref="Machine_Learning00003.smil#em_000026">log10</em><span class="text" id="span_000171" smilref="Machine_Learning00003.smil#span_000171">(2.);
    }
    </span><strong id="strong_000054" smilref="Machine_Learning00003.smil#strong_000054">public</strong> <strong id="strong_000055" smilref="Machine_Learning00003.smil#strong_000055">double</strong><span class="text" id="span_000172" smilref="Machine_Learning00003.smil#span_000172"> calcGain(</span><strong id="strong_000056" smilref="Machine_Learning00003.smil#strong_000056">double</strong><span class="text" id="span_000173" smilref="Machine_Learning00003.smil#span_000173"> positive, </span><strong id="strong_000057" smilref="Machine_Learning00003.smil#strong_000057">double</strong><span class="text" id="span_000174" smilref="Machine_Learning00003.smil#span_000174"> negative) {
        </span><strong id="strong_000058" smilref="Machine_Learning00003.smil#strong_000058">double</strong><span class="text" id="span_000175" smilref="Machine_Learning00003.smil#span_000175"> sum = positive + negative;
        </span><strong id="strong_000059" smilref="Machine_Learning00003.smil#strong_000059">double</strong><span class="text" id="span_000176" smilref="Machine_Learning00003.smil#span_000176"> gain = positive * calcLog2(positive/sum)/sum + negative * calcLog2(negative/sum)/sum;
        </span><strong id="strong_000060" smilref="Machine_Learning00003.smil#strong_000060">return</strong><span class="text" id="span_000177" smilref="Machine_Learning00003.smil#span_000177"> -gain;
    }
    </span><strong id="strong_000061" smilref="Machine_Learning00003.smil#strong_000061">public</strong> <strong id="strong_000062" smilref="Machine_Learning00003.smil#strong_000062">static</strong> <strong id="strong_000063" smilref="Machine_Learning00003.smil#strong_000063">void</strong><span class="text" id="span_000178" smilref="Machine_Learning00003.smil#span_000178"> main(String[] args) {
        InformationGain ig = </span><strong id="strong_000064" smilref="Machine_Learning00003.smil#strong_000064">new</strong><span class="text" id="span_000179" smilref="Machine_Learning00003.smil#span_000179"> InformationGain();
        System.</span><em id="em_000027" smilref="Machine_Learning00003.smil#em_000027">out</em><span class="text" id="span_000180" smilref="Machine_Learning00003.smil#span_000180">.println(ig.calcGain(2, 3));
    }
}</span></code></p>
                <pagenum epub:type="pagebreak" id="p51" page="normal" smilref="Machine_Learning00003.smil#p51">51</pagenum>
                <p id="c03-c03-para-0040" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0040">Looking back at the table of customers with credit accounts there are three with and two without. So calculating the gain with these variables you get the following result:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000136"><img src="images/c03_math_001.png" alt="equation" id="img_000004" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtable columnalign="left"><mtr><mtd><mtext>Gain</mtext><mfenced open="(" close=")" separators=","><mn>3</mn><mn>2</mn></mfenced><mspace width="0.6em"/><mo>=</mo><mfenced open="(" close=")"><mrow><mn>3</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>3</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced><mo>+</mo><mfenced open="(" close=")"><mrow><mn>2</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>2</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced></mtd></mtr><mtr><mtd><mspace width="3.12em"/><mo>=</mo><mn>0.97</mn></mtd></mtr></mtable></mrow></math>--></p>
                <p id="c03-c03-para-0041" xml:space="preserve"><span class="text" id="span_000181" smilref="Machine_Learning00003.smil#span_000181">log2() refers to the calculation in the </span><code xml:space="preserve" id="code_000050" smilref="Machine_Learning00003.smil#code_000050">calcLog2()</code><span class="text" id="span_000182" smilref="Machine_Learning00003.smil#span_000182"> method in the code snippet. If you don't want to type or compile the code listing, then try copying and pasting the gain equation into </span><code xml:space="preserve" id="code_000051"><a href="http://www.wolframalpha.com" external="true" id="a_000276" smilref="Machine_Learning00003.smil#a_000276">www.wolframalpha.com</a></code><span class="text" id="span_000183" smilref="Machine_Learning00003.smil#span_000183"> and you'll see the answer there. The outcomes of the variables in the </span><code xml:space="preserve" id="code_000052" smilref="Machine_Learning00003.smil#code_000052">reads reviews</code><span class="text" id="span_000184" smilref="Machine_Learning00003.smil#span_000184"> attribute linking back to the </span><code xml:space="preserve" id="code_000053" smilref="Machine_Learning00003.smil#code_000053">accounts</code><span class="text" id="span_000185" smilref="Machine_Learning00003.smil#span_000185"> attribute are the following:</span></p>
                <p class="informalEquation" xml:space="preserve" id="p_000137"><img src="images/c03_math_002.png" alt="equation" id="img_000005" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext>Reads&#x000A0;reviews</mtext><mo>=</mo><mfenced open="[" close="]"><mrow><mi mathvariant="normal">Y</mi><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">Y</mi><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">N</mi></mrow></mfenced></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext>Does&#x000A0;not&#x000A0;read&#x000A0;reviews</mtext><mo>=</mo><mfenced open="[" close="]"><mrow><mi mathvariant="normal">N</mi><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">Y</mi></mrow></mfenced></mrow></math>--></p>
                <p id="c03-c03-para-0042" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0042">You can now calculate the entropy with the split based on the first attribute:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000138"><img src="images/c03_math_003.png" alt="equation" id="img_000006" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtable columnalign="left"><mtr><mtd><mtext>Gain</mtext><mfenced open="(" close=")" separators=","><mn>2</mn><mn>1</mn></mfenced><mspace width="1.08em"/><mo>=</mo><mfenced open="(" close=")"><mrow><mn>2</mn><mo stretchy="true">/</mo><mn>3</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>2</mn><mo stretchy="true">/</mo><mn>3</mn></mrow></mfenced><mo>+</mo><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>3</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>3</mn></mrow></mfenced></mtd></mtr><mtr><mtd><mspace width="3.48em"/><mo>=</mo><mspace width="0.25em"/><mn>0.91</mn></mtd></mtr></mtable></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtable columnalign="left"><mtr><mtd><mtext>Gain</mtext><mfenced open="(" close=")" separators=","><mn>1</mn><mn>1</mn></mfenced><mspace width="1.2em"/><mo>=</mo><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>2</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>2</mn></mrow></mfenced><mo>+</mo><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>2</mn></mrow></mfenced><mo>*</mo><mrow><mi mathvariant="normal">log</mi><mo>&#x02061;</mo></mrow><mn>2</mn><mfenced open="(" close=")"><mrow><mn>1</mn><mo stretchy="true">/</mo><mn>2</mn></mrow></mfenced></mtd></mtr><mtr><mtd><mspace width="3.6em"/><mo>=</mo><mn>1</mn></mtd></mtr></mtable></mrow></math>--></p>
                <p id="c03-c03-para-0043" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0043">The net gain is finally calculated:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000139"><img src="images/c03_math_004.png" alt="equation" id="img_000007" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtable columnalign="left"><mtr><mtd><mi mathvariant="normal">N</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">t</mi><mspace width="0.25em"/><mtext>gain</mtext><mfenced open="(" close=")"><mrow><mtext>attribute</mtext><mo>=</mo><mtext>has&#x000A0;credit&#x000A0;account</mtext></mrow></mfenced></mtd></mtr><mtr><mtd><mo>=</mo><mfenced open="(" close=")"><mrow><mn>2</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced><mo>*</mo><mn>0.91</mn><mo>+</mo><mfenced open="(" close=")"><mrow><mn>3</mn><mo stretchy="true">/</mo><mn>5</mn></mrow></mfenced><mo>*</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo>=</mo><mn>0.96</mn></mtd></mtr></mtable></mrow></math>--></p>
                <p id="c03-c03-para-0044" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0044">So, you have two gains: one before the split (0.97) and one after the split (0.96).</p>
                <p id="c03-c03-para-0045" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0045">You're nearly done on this attribute. You just have to calculate the information gain.</p>
              </level4>
              <level4 id="level4_000011">
                <h4 xml:space="preserve" id="h4_000011" smilref="Machine_Learning00003.smil#h4_000011">Information Gain</h4>
                <pagenum epub:type="pagebreak" id="p52" page="normal" smilref="Machine_Learning00003.smil#p52">52</pagenum>
                <p xml:space="preserve" id="p_000140" smilref="Machine_Learning00003.smil#p_000140">When you know the gain before and after the split in the attribute, you can calculate the information gain. With the attribute to see if the customer has a credit account, your calculation will be the following:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000141"><img src="images/c03_math_005.png" alt="equation" id="img_000008" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtable columnalign="left"><mtr><mtd><mtext>InformationGain</mtext><mo>=</mo><mtext>Gain</mtext><mfenced open="(" close=")"><mrow><mtext>before&#x000A0;the&#x000A0;split</mtext></mrow></mfenced><mo>&#x02212;</mo><mtext>Gain</mtext><mfenced open="(" close=")"><mrow><mtext>after&#x000A0;the&#x000A0;split</mtext></mrow></mfenced></mtd></mtr><mtr><mtd><mspace width="4.44em"/><mo>=</mo><mspace width="0.25em"/><mn>0.97</mn><mspace width="0.25em"/><mo>&#x02013;</mo><mspace width="0.25em"/><mn>0.96</mn></mtd></mtr><mtr><mtd><mspace width="4.44em"/><mo>=</mo><mspace width="0.25em"/><mn>0.01</mn></mtd></mtr></mtable></mrow></math>--></p>
                <p id="c03-c03-para-0047" xml:space="preserve"><span class="text" id="span_000186" smilref="Machine_Learning00003.smil#span_000186">So, the information gain on the </span><code xml:space="preserve" id="code_000054" smilref="Machine_Learning00003.smil#code_000054">has credit account</code><span class="text" id="span_000187" smilref="Machine_Learning00003.smil#span_000187"> attribute is 0.01.</span></p>
              </level4>
              <level4 id="level4_000012">
                <h4 xml:space="preserve" id="h4_000012" smilref="Machine_Learning00003.smil#h4_000012">Rinse and Repeat</h4>
                <p xml:space="preserve" id="p_000142"><span class="text" id="span_000188" smilref="Machine_Learning00003.smil#span_000188">The previous two sections covered the calculation of information gain for one attribute, </span><code xml:space="preserve" id="code_000055" smilref="Machine_Learning00003.smil#code_000055">Has Credit Account</code><span class="text" id="span_000189" smilref="Machine_Learning00003.smil#span_000189">. You need to work on the other two attributes to find their information gain.</span></p>
                <p xml:space="preserve" id="p_000143"><strong id="strong_000065" smilref="Machine_Learning00003.smil#strong_000065">Reads Reviews:</strong><em id="em_000028" smilref="Machine_Learning00003.smil#em_000028">Gain</em><span class="text" id="span_000190" smilref="Machine_Learning00003.smil#span_000190">(</span><em id="em_000029" smilref="Machine_Learning00003.smil#em_000029">3</em><span class="text" id="span_000191" smilref="Machine_Learning00003.smil#span_000191">,</span><em id="em_000030" smilref="Machine_Learning00003.smil#em_000030">2</em><span class="text" id="span_000192" smilref="Machine_Learning00003.smil#span_000192">) = </span><em id="em_000031" smilref="Machine_Learning00003.smil#em_000031">0</em><span class="text" id="span_000193" smilref="Machine_Learning00003.smil#span_000193">.</span><em id="em_000032" smilref="Machine_Learning00003.smil#em_000032">97Net Gain</em><span class="text" id="span_000194" smilref="Machine_Learning00003.smil#span_000194"> = </span><em id="em_000033" smilref="Machine_Learning00003.smil#em_000033">0</em><span class="text" id="span_000195" smilref="Machine_Learning00003.smil#span_000195">.</span><em id="em_000034" smilref="Machine_Learning00003.smil#em_000034">4Information Gain</em><span class="text" id="span_000196" smilref="Machine_Learning00003.smil#span_000196"> = </span><em id="em_000035" smilref="Machine_Learning00003.smil#em_000035">0</em><span class="text" id="span_000197" smilref="Machine_Learning00003.smil#span_000197">.</span><em id="em_000036" smilref="Machine_Learning00003.smil#em_000036">57</em><strong id="strong_000066" smilref="Machine_Learning00003.smil#strong_000066">Previous Customer:</strong><em id="em_000037" smilref="Machine_Learning00003.smil#em_000037">Gain</em><span class="text" id="span_000198" smilref="Machine_Learning00003.smil#span_000198">(</span><em id="em_000038" smilref="Machine_Learning00003.smil#em_000038">4</em><span class="text" id="span_000199" smilref="Machine_Learning00003.smil#span_000199">,</span><em id="em_000039" smilref="Machine_Learning00003.smil#em_000039">1</em><span class="text" id="span_000200" smilref="Machine_Learning00003.smil#span_000200">) = </span><em id="em_000040" smilref="Machine_Learning00003.smil#em_000040">0</em><span class="text" id="span_000201" smilref="Machine_Learning00003.smil#span_000201">.</span><em id="em_000041" smilref="Machine_Learning00003.smil#em_000041">72Net Gain</em><span class="text" id="span_000202" smilref="Machine_Learning00003.smil#span_000202"> = </span><em id="em_000042" smilref="Machine_Learning00003.smil#em_000042">0</em><span class="text" id="span_000203" smilref="Machine_Learning00003.smil#span_000203">.</span><em id="em_000043" smilref="Machine_Learning00003.smil#em_000043">486Information Gain</em><span class="text" id="span_000204" smilref="Machine_Learning00003.smil#span_000204"> = </span><em id="em_000044" smilref="Machine_Learning00003.smil#em_000044">0</em><span class="text" id="span_000205" smilref="Machine_Learning00003.smil#span_000205">.</span><em id="em_000045" smilref="Machine_Learning00003.smil#em_000045">234</em></p>
                <p id="c03-c03-para-0057" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0057">With the values of information gain for all the attributes, you can now make a decision on which node to start with in the tree.</p>
                <figure id="figure_000008">
                  <table border="1" id="table_000006">
                    <tr id="tr_000020">
                      <td class="left" rowspan="1" colspan="1" id="td_000075" smilref="Machine_Learning00003.smil#td_000075">Attribute</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000076" smilref="Machine_Learning00003.smil#td_000076">Information Gain</td>
                    </tr>
                    <tr id="tr_000021">
                      <td class="left" rowspan="1" colspan="1" id="td_000077" smilref="Machine_Learning00003.smil#td_000077">Has Credit Account</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000078" smilref="Machine_Learning00003.smil#td_000078">0.01</td>
                    </tr>
                    <tr id="tr_000022">
                      <td class="left" rowspan="1" colspan="1" id="td_000079" smilref="Machine_Learning00003.smil#td_000079">Reads Reviews</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000080" smilref="Machine_Learning00003.smil#td_000080">0.57</td>
                    </tr>
                    <tr id="tr_000023">
                      <td class="left" rowspan="1" colspan="1" id="td_000081" smilref="Machine_Learning00003.smil#td_000081">Is Previous Customer</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000082" smilref="Machine_Learning00003.smil#td_000082">0.234</td>
                    </tr>
                  </table>
                </figure>
                <p id="c03-c03-para-0058" xml:space="preserve"><span class="text" id="span_000206" smilref="Machine_Learning00003.smil#span_000206">Now things are becoming clearer; the </span><code xml:space="preserve" id="code_000056" smilref="Machine_Learning00003.smil#code_000056">Reads Reviews</code><span class="text" id="span_000207" smilref="Machine_Learning00003.smil#span_000207"> attribute has the highest information gain and therefore should be the root node in the tree, then comes the Is Previous Customer node followed by Has Credit Account.</span></p>
                <p id="c03-c03-para-0059" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0059">The order of information gain determines where the node will appear in the decision tree model. The node with the highest gain becomes the root node.</p>
                <p id="c03-c03-para-0060" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0060">That's enough of the basic theory of how decision trees work. The best way to learn is to get something working, which is described in the next section.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000027">
            <h2 id="c03-c03_level1_2" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03_level1_2">Decision Trees in Weka</h2>
            <pagenum epub:type="pagebreak" id="p53" page="normal" smilref="Machine_Learning00003.smil#p53">53</pagenum>
            <p xml:space="preserve" id="p_000144" smilref="Machine_Learning00003.smil#p_000144">In this section, you'll use the Weka data-mining tool to work through some training data of the optimum sales of Lady Gaga's CDs depending on specific factors within the store. I explain the factors in question as you walk though that data.</p>
            <level3 id="level3_000072">
              <h3 xml:space="preserve" id="h3_000072" smilref="Machine_Learning00003.smil#h3_000072">The Requirement</h3>
              <p xml:space="preserve" id="p_000145" smilref="Machine_Learning00003.smil#p_000145">The requirement is to create a model that will be able to predict a customer sale on Lady Gaga CDs depending on the CDs' placement within the store. You've been given some data by the record store about where the product was placed, whether it was at eye level or not, and whether the customer actually purchased the CD or put it back on the shelf.</p>
              <p id="c03-c03-para-0063" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0063">The client wants to be able to run other sets of data through the model to determine how sales of a product will fare.</p>
              <p id="c03-c03-para-0064" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0064">Working through this methodically, you need to do the following:</p>
              <list type="ol" id="list_000029">
                <li id="li_000295" smilref="Machine_Learning00003.smil#li_000295">Run through the training data supplied and turn it into a definition file for Weka.</li>
                <li id="li_000296" smilref="Machine_Learning00003.smil#li_000296">Use the Weka workbench to build the decision tree for you and plot an output graph.</li>
                <li id="li_000297" smilref="Machine_Learning00003.smil#li_000297">Export some generated Java code with the new decision tree classifier.</li>
                <li id="li_000298" smilref="Machine_Learning00003.smil#li_000298">Test the code against some test data.</li>
                <li id="li_000299" smilref="Machine_Learning00003.smil#li_000299">Think about future iterations of the classifier.</li>
              </list>
              <p id="c03-c03-para-0065" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0065">It feels like there's a lot to do, but after you get into the routine, it's quite simple to do with the tools at hand. First look at the training data.</p>
            </level3>
            <level3 id="level3_000073">
              <h3 xml:space="preserve" id="h3_000073" smilref="Machine_Learning00003.smil#h3_000073">Training Data</h3>
              <p xml:space="preserve" id="p_000146"><span class="text" id="span_000208" smilref="Machine_Learning00003.smil#span_000208">Before anything else happens, you need some training data. The client has given you some in a </span><code xml:space="preserve" id="code_000057" smilref="Machine_Learning00003.smil#code_000057">.csv</code><span class="text" id="span_000209" smilref="Machine_Learning00003.smil#span_000209"> file, but it would be nice to formalize this. This is what you received:</span></p>
              <p xml:space="preserve" id="p_000147"><code class="preserve-whitespace" xml:space="preserve" id="code_000058" smilref="Machine_Learning00003.smil#code_000058">Placement,prominence, pricing, eye_level, customer_purchase
end_rack,85,85,FALSE,yes
end_rack,80,90,TRUE,yes
cd_spec,83,86,FALSE,no
std_rack,70,96,FALSE,no
std_rack,68,80,FALSE,no
std_rack,65,70,TRUE,yes
cd_spec,64,65,TRUE,yes
end_rack,72,95,FALSE,yes
end_rack,69,70,FALSE,yes
std_rack,75,80,FALSE,no
end_rack,75,70,TRUE,no
cd_spec,72,90,TRUE,no
cd_spec,81,75,FALSE,yes
std_rack,71,91,TRUE,yes</code></p>
              <pagenum epub:type="pagebreak" id="p54" page="normal" smilref="Machine_Learning00003.smil#p54">54</pagenum>
              <p id="c03-c03-para-0067" xml:space="preserve"><span class="text" id="span_000210" smilref="Machine_Learning00003.smil#span_000210">Weka saves the file as a </span><code xml:space="preserve" id="code_000059" smilref="Machine_Learning00003.smil#code_000059">.arff</code><span class="text" id="span_000211" smilref="Machine_Learning00003.smil#span_000211"> file to set up the attributes and let you give it some data from which to train. The </span><code xml:space="preserve" id="code_000060" smilref="Machine_Learning00003.smil#code_000060">.arff</code><span class="text" id="span_000212" smilref="Machine_Learning00003.smil#span_000212"> file is a text file that outlines the data model you are going to use:</span></p>
              <p xml:space="preserve" id="p_000148"><code class="preserve-whitespace" xml:space="preserve" id="code_000061" smilref="Machine_Learning00003.smil#code_000061">@relation ladygaga
@attribute placement {end_rack, cd_spec, std_rack}
@attribute prominence numeric
@attribute pricing numeric
@attribute eye_level {TRUE, FALSE}
@attribute customer_purchase {yes, no}
@data
end_rack,85,85,FALSE,yes
end_rack,80,90,TRUE,yes
cd_spec,83,86,FALSE,no
std_rack,70,96,FALSE,no
std_rack,68,80,FALSE,no
std_rack,65,70,TRUE,yes
cd_spec,64,65,TRUE,yes
end_rack,72,95,FALSE,yes
end_rack,69,70,FALSE,no
std_rack,75,80,FALSE,no
end_rack,75,70,TRUE,no
cd_spec,72,90,TRUE,no
cd_spec,81,75,FALSE,yes
std_rack,71,91,TRUE,yes</code></p>
              <p id="c03-c03-para-0068" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0068">The data file has a few elements to it, so let's look through it one section at a time.</p>
              <level4 id="level4_000013">
                <h4 xml:space="preserve" id="h4_000013" smilref="Machine_Learning00003.smil#h4_000013">Relation</h4>
                <p xml:space="preserve" id="p_000149"><span class="text" id="span_000213" smilref="Machine_Learning00003.smil#span_000213">The </span><code xml:space="preserve" id="code_000062" smilref="Machine_Learning00003.smil#code_000062">@relation</code><span class="text" id="span_000214" smilref="Machine_Learning00003.smil#span_000214"> tag is the name of the dataset you are using. In this instance it's Lady Gaga's CDs, so I've called it </span><code xml:space="preserve" id="code_000063" smilref="Machine_Learning00003.smil#code_000063">ladygaga</code><span class="text" id="span_000215" smilref="Machine_Learning00003.smil#span_000215">.</span></p>
              </level4>
              <level4 id="level4_000014">
                <h4 xml:space="preserve" id="h4_000014" smilref="Machine_Learning00003.smil#h4_000014">Attributes</h4>
                <pagenum epub:type="pagebreak" id="p55" page="normal" smilref="Machine_Learning00003.smil#p55">55</pagenum>
                <p xml:space="preserve" id="p_000150" smilref="Machine_Learning00003.smil#p_000150">Next, you have the attributes that are used within your data model. There are five attributes in this set that are the top line of raw CSV data that you received from the client.</p>
                <list type="ul" id="list_000030">
                  <li id="li_000300">
                    <strong id="strong_000067" smilref="Machine_Learning00003.smil#strong_000067">Placement:</strong>
                    <span class="text" id="span_000216" smilref="Machine_Learning00003.smil#span_000216">What type of stand the CD is displayed on: an end rack, special offer bucket, or a standard rack?</span>
                  </li>
                  <li id="li_000301">
                    <strong id="strong_000068" smilref="Machine_Learning00003.smil#strong_000068">Prominence:</strong>
                    <span class="text" id="span_000217" smilref="Machine_Learning00003.smil#span_000217">What percentage of the CDs on display are Lady Gaga CDs?</span>
                  </li>
                  <li id="li_000302">
                    <strong id="strong_000069" smilref="Machine_Learning00003.smil#strong_000069">Pricing:</strong>
                    <span class="text" id="span_000218" smilref="Machine_Learning00003.smil#span_000218">What percentage of the full price was the CD at the time of purchase? Very rarely is a CD sold at full price, unless it is an old, back catalog title.</span>
                  </li>
                  <li id="li_000303">
                    <strong id="strong_000070" smilref="Machine_Learning00003.smil#strong_000070">Eye Level:</strong>
                    <span class="text" id="span_000219" smilref="Machine_Learning00003.smil#span_000219">Was the product displayed at eye level position? The majority of sales will happen when a product is displayed at eye level.</span>
                  </li>
                  <li id="li_000304">
                    <strong id="strong_000071" smilref="Machine_Learning00003.smil#strong_000071">Customer Purchase:</strong>
                    <span class="text" id="span_000220" smilref="Machine_Learning00003.smil#span_000220">What was the outcome? Did the customer purchase?</span>
                  </li>
                </list>
                <p id="c03-c03-para-0071" xml:space="preserve"><span class="text" id="span_000221" smilref="Machine_Learning00003.smil#span_000221">The Prominence and Pricing attributes are both numeric values. The other three are given the nominal values that are to be expected when the algorithm is being run. Placement has three: </span><code xml:space="preserve" id="code_000064" smilref="Machine_Learning00003.smil#code_000064">end_rack</code><span class="text" id="span_000222" smilref="Machine_Learning00003.smil#span_000222">, </span><code xml:space="preserve" id="code_000065" smilref="Machine_Learning00003.smil#code_000065">cd_spec</code><span class="text" id="span_000223" smilref="Machine_Learning00003.smil#span_000223">, or </span><code xml:space="preserve" id="code_000066" smilref="Machine_Learning00003.smil#code_000066">std_rack</code><span class="text" id="span_000224" smilref="Machine_Learning00003.smil#span_000224">. The Eye Level attribute is either true or false, and the Customer Purchase attribute has two nominal values of either yes or no to show that the customer bought the product.</span></p>
              </level4>
              <level4 id="level4_000015">
                <h4 xml:space="preserve" id="h4_000015" smilref="Machine_Learning00003.smil#h4_000015">Data</h4>
                <p xml:space="preserve" id="p_000151" smilref="Machine_Learning00003.smil#p_000151">Finally, you have the data. It's comma separated in the order of the attributes (Placement, Prominence, Pricing, Eye Level, and Customer Purchase). In this sample, you know the outcomes—whether a customer purchased or not; this model is about using regression to get your predictions in tune for new data coming in.</p>
                <p id="c03-c03-para-0073" xml:space="preserve"><span class="text" id="span_000225" smilref="Machine_Learning00003.smil#span_000225">You can find all the code for this chapter on the book's companion website at </span><code xml:space="preserve" id="code_000067"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000277" smilref="Machine_Learning00003.smil#a_000277">www.wiley.com/go/machinelearning</a></code><span class="text" id="span_000226" smilref="Machine_Learning00003.smil#span_000226">.</span></p>
              </level4>
            </level3>
            <level3 id="level3_000074">
              <h3 xml:space="preserve" id="h3_000074" smilref="Machine_Learning00003.smil#h3_000074">Using Weka to Create a Decision Tree</h3>
              <p xml:space="preserve" id="p_000152"><span class="text" id="span_000227" smilref="Machine_Learning00003.smil#span_000227">Now that you have your data model in place, you can get started. When you open the Weka program you are presented with a small opening screen (see </span><a id="c03-c03-fig-anc-0002" href="#c03-c03-fig-0002" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0002">Figure 3-2</a><span class="text" id="span_000228" smilref="Machine_Learning00003.smil#span_000228">) with four buttons: Explorer, Experimenter, KnowledgeFlow, and Simple CLI. Click the Explorer button.</span></p>
              <figure id="figure_000009">
                <img class="center" src="images/c03f002.jpg" alt="image" id="img_000009" />
                <figcaption id="figcaption_000005">
                  <p xml:space="preserve" id="p_000153"><span class="figureLabel" id="span_000229"><a id="c03-c03-fig-0002" href="#c03-c03-fig-anc-0002" external="false"><strong id="strong_000072" smilref="Machine_Learning00003.smil#strong_000072">Figure 3-2</strong></a></span><span class="text" id="span_000230" smilref="Machine_Learning00003.smil#span_000230"> The Weka GUI Chooser</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p56" page="normal" smilref="Machine_Learning00003.smil#p56">56</pagenum>
              <p id="c03-c03-para-0075" xml:space="preserve"><span class="text" id="span_000231" smilref="Machine_Learning00003.smil#span_000231">When the Explorer opens, you will be confronted with another window with a number of sections and an array of buttons (see </span><a id="c03-c03-fig-anc-0003" href="#c03-c03-fig-0003" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0003">Figure 3-3</a><span class="text" id="span_000232" smilref="Machine_Learning00003.smil#span_000232">). Don't worry if it all looks confusing right now; this walkthrough takes you through it step by step.</span></p>
              <figure id="figure_000010">
                <img class="center" src="images/c03f003.jpg" alt="image" id="img_000010" />
                <figcaption id="figcaption_000006">
                  <p xml:space="preserve" id="p_000154"><span class="figureLabel" id="span_000233"><a id="c03-c03-fig-0003" href="#c03-c03-fig-anc-0003" external="false"><strong id="strong_000073" smilref="Machine_Learning00003.smil#strong_000073">Figure 3-3</strong></a></span><span class="text" id="span_000234" smilref="Machine_Learning00003.smil#span_000234"> The basic Explorer window</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p57" page="normal" smilref="Machine_Learning00003.smil#p57">57</pagenum>
              <p id="c03-c03-para-0076" xml:space="preserve"><span class="text" id="span_000235" smilref="Machine_Learning00003.smil#span_000235">Click the Open File button and select the data file called </span><code xml:space="preserve" id="code_000068" smilref="Machine_Learning00003.smil#code_000068">ladygaga.arff</code><span class="text" id="span_000236" smilref="Machine_Learning00003.smil#span_000236">. Weka parses the data model and preprocesses the data. Within no time you're already getting information based on the preprocessing of the data model and the data.</span></p>
              <p id="c03-c03-para-0077" xml:space="preserve"><span class="text" id="span_000237" smilref="Machine_Learning00003.smil#span_000237">The Select Attribute pane on the right side of the Explorer window in </span><a id="c03-c03-fig-anc-0004" href="#c03-c03-fig-0004" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0004">Figure 3-4</a><span class="text" id="span_000238" smilref="Machine_Learning00003.smil#span_000238"> shows the three distinct nominal values of the </span><code xml:space="preserve" id="code_000069" smilref="Machine_Learning00003.smil#code_000069">customer_purchase</code><span class="text" id="span_000239" smilref="Machine_Learning00003.smil#span_000239"> attribute. Weka has also noticed that you have 14 instance rows and the five attributes.</span></p>
              <figure id="figure_000011">
                <img class="center" src="images/c03f004.jpg" alt="image" id="img_000011" />
                <figcaption id="figcaption_000007">
                  <p xml:space="preserve" id="p_000155"><span class="figureLabel" id="span_000240"><a id="c03-c03-fig-0004" href="#c03-c03-fig-anc-0004" external="false"><strong id="strong_000074" smilref="Machine_Learning00003.smil#strong_000074">Figure 3-4</strong></a></span><span class="text" id="span_000241" smilref="Machine_Learning00003.smil#span_000241"> The preprocess pane with data</span></p>
                </figcaption>
              </figure>
              <p id="c03-c03-para-0078" xml:space="preserve"><span class="text" id="span_000242" smilref="Machine_Learning00003.smil#span_000242">After preprocessing comes classification. Click the Classify button in the top row of buttons. You're going to use the C4.5 classification algorithm; within Weka this is called the J48 algorithm. In the Classifier pane (see </span><a id="c03-c03-fig-anc-0005" href="#c03-c03-fig-0005" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0005">Figure 3-5</a><span class="text" id="span_000243" smilref="Machine_Learning00003.smil#span_000243">), click the Choose button and select the J48 option under the Trees menu heading. The selection pane closes automatically, and you see that the name of the classifier has changed from the default </span><code xml:space="preserve" id="code_000070" smilref="Machine_Learning00003.smil#code_000070">ZeroR</code><span class="text" id="span_000244" smilref="Machine_Learning00003.smil#span_000244"> to </span><code xml:space="preserve" id="code_000071" smilref="Machine_Learning00003.smil#code_000071">J48 –C 0.25 –M 2</code><span class="text" id="span_000245" smilref="Machine_Learning00003.smil#span_000245">. (See </span><a href="#c03-c03-fig-0005" external="false" id="a_000278" smilref="Machine_Learning00003.smil#a_000278">Figure 3-5</a><span class="text" id="span_000246" smilref="Machine_Learning00003.smil#span_000246">.)</span></p>
              <figure id="figure_000012">
                <img class="center" src="images/c03f005.jpg" alt="image" id="img_000012" />
                <figcaption id="figcaption_000008">
                  <p xml:space="preserve" id="p_000156"><span class="figureLabel" id="span_000247"><a id="c03-c03-fig-0005" href="#c03-c03-fig-anc-0005" external="false"><strong id="strong_000075" smilref="Machine_Learning00003.smil#strong_000075">Figure 3-5</strong></a></span><span class="text" id="span_000248" smilref="Machine_Learning00003.smil#span_000248"> Selecting the classifier</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p58" page="normal" smilref="Machine_Learning00003.smil#p58">58</pagenum>
              <p id="c03-c03-para-0079" xml:space="preserve"><span class="text" id="span_000249" smilref="Machine_Learning00003.smil#span_000249">The option flags used in the default J48 classifier are setting the pruning confidence (the </span><code xml:space="preserve" id="code_000072" smilref="Machine_Learning00003.smil#code_000072">–C</code><span class="text" id="span_000250" smilref="Machine_Learning00003.smil#span_000250"> flag) and the minimum number of instances (</span><code xml:space="preserve" id="code_000073" smilref="Machine_Learning00003.smil#code_000073">-M</code><span class="text" id="span_000251" smilref="Machine_Learning00003.smil#span_000251">).</span></p>
              <p id="c03-c03-para-0080" xml:space="preserve"><span class="text" id="span_000252" smilref="Machine_Learning00003.smil#span_000252">To run the classifier, click the Start button and watch the Classifier output window (see </span><a id="c03-c03-fig-anc-0006" href="#c03-c03-fig-0006" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0006">Figure 3-6</a><span class="text" id="span_000253" smilref="Machine_Learning00003.smil#span_000253">). You see the information on the run appear. The run information tells you about the scheme used and gives a run-down on the model on which Weka has worked.</span></p>
              <figure id="figure_000013">
                <img class="center" src="images/c03f006.jpg" alt="image" id="img_000013" />
                <figcaption id="figcaption_000009">
                  <p xml:space="preserve" id="p_000157"><span class="figureLabel" id="span_000254"><a id="c03-c03-fig-0006" href="#c03-c03-fig-anc-0006" external="false"><strong id="strong_000076" smilref="Machine_Learning00003.smil#strong_000076">Figure 3-6</strong></a></span><span class="text" id="span_000255" smilref="Machine_Learning00003.smil#span_000255"> Classifier with output</span></p>
                </figcaption>
              </figure>
              <p id="c03-c03-para-0081" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0081">Interesting data starts to emerge. The J48 pruned tree gives results on, in this case, the placement, as it has the highest information gain:</p>
              <p xml:space="preserve" id="p_000158"><code class="preserve-whitespace" xml:space="preserve" id="code_000074" smilref="Machine_Learning00003.smil#code_000074">J48 pruned tree
------------------
placement = end_rack: yes (5.0/1.0)
placement = cd_spec
|   pricing &lt;= 80: yes (2.0)
|   pricing &gt; 80: no (2.0)
placement = std_rack
|   eye_level = TRUE: yes (2.0)
|   eye_level = FALSE: no (3.0)
Number of Leaves  :       5
Size of the tree :  8
Time taken to build model: 0 seconds </code></p>
              <pagenum epub:type="pagebreak" id="p59" page="normal" smilref="Machine_Learning00003.smil#p59">59</pagenum>
              <p id="c03-c03-para-0082" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0082">It appears that placing product on the end rack is good for sales. For the special offer rack, it seems that pricing plays a part; if the product is too cheap customers walk away. On the standard racks, the placement of the product is a factor for sales; it sells if it's at eye level.</p>
              <p id="c03-c03-para-0083" xml:space="preserve"><span class="text" id="span_000256" smilref="Machine_Learning00003.smil#span_000256">Finally you want to plot the visualization of the tree for the management team to look at because pictures speak louder than words. On the Results List pane on the bottom left of the Explorer window you can see the time and algorithm that was run. Right-click (use Alt + click if you are using an OSX machine) and select the Visualize Tree option to see the tree in its visual representation, as shown in </span><a id="c03-c03-fig-anc-0007" href="#c03-c03-fig-0007" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0007">Figure 3-7</a><span class="text" id="span_000257" smilref="Machine_Learning00003.smil#span_000257">.</span></p>
              <figure id="figure_000014">
                <img class="center" src="images/c03f007.jpg" alt="image" id="img_000014" />
                <figcaption id="figcaption_000010">
                  <p xml:space="preserve" id="p_000159"><span class="figureLabel" id="span_000258"><a id="c03-c03-fig-0007" href="#c03-c03-fig-anc-0007" external="false"><strong id="strong_000077" smilref="Machine_Learning00003.smil#strong_000077">Figure 3-7</strong></a></span><span class="text" id="span_000259" smilref="Machine_Learning00003.smil#span_000259"> J48 visualization</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p60" page="normal" smilref="Machine_Learning00003.smil#p60">60</pagenum>
              <p id="c03-c03-para-0084" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0084">It's usually at this point where everyone pats each other on the back and says, “Job well done,” but you're not finished yet. You don't want to have to run the Weka Explorer every time you have data to run. What you want is some code that you can reuse.</p>
            </level3>
            <level3 id="level3_000075">
              <h3 xml:space="preserve" id="h3_000075" smilref="Machine_Learning00003.smil#h3_000075">Creating Java Code from the Classification</h3>
              <p xml:space="preserve" id="p_000160" smilref="Machine_Learning00003.smil#p_000160">As mentioned in Chapter 2, there is no one tool that really fits all. Weka is excellent, but you want code that you can safely run in an existing codebase. Perhaps you want to hook your newly created classification to a Hadoop job, if the incoming volume of data was sufficient to do so.</p>
              <p id="c03-c03-para-0086" xml:space="preserve"><span class="text" id="span_000260" smilref="Machine_Learning00003.smil#span_000260">With the existing classifier, click the More Options button and a new window opens with the options for the current evaluator. (See </span><a id="c03-c03-fig-anc-0008" href="#c03-c03-fig-0008" external="false" smilref="Machine_Learning00003.smil#c03-c03-fig-anc-0008">Figure 3-8</a><span class="text" id="span_000261" smilref="Machine_Learning00003.smil#span_000261">.)</span></p>
              <figure id="figure_000015">
                <img class="center" src="images/c03f008.jpg" alt="image" id="img_000015" />
                <figcaption id="figcaption_000011">
                  <p xml:space="preserve" id="p_000161"><span class="figureLabel" id="span_000262"><a id="c03-c03-fig-0008" href="#c03-c03-fig-anc-0008" external="false"><strong id="strong_000078" smilref="Machine_Learning00003.smil#strong_000078">Figure 3-8</strong></a></span><span class="text" id="span_000263" smilref="Machine_Learning00003.smil#span_000263"> Evaluation options pane</span></p>
                </figcaption>
              </figure>
              <p id="c03-c03-para-0087" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0087">The last option is to output to source code. By default, the class name will be WekaClassifier. It won't save your Java code, but it will output in the Classifier output window.</p>
              <pagenum epub:type="pagebreak" id="p61" page="normal" smilref="Machine_Learning00003.smil#p61">61</pagenum>
              <p id="c03-c03-para-0088" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0088">Start the classifier again, and in the output window you see the Java code at the end of the output information:</p>
              <p xml:space="preserve" id="p_000162"><code class="preserve-whitespace" xml:space="preserve" id="code_000075"><span class="text" id="span_000264" smilref="Machine_Learning00003.smil#span_000264">package weka.classifiers;
import weka.core.Attribute;
import weka.core.Capabilities;
import weka.core.Capabilities.Capability;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.RevisionUtils;
import weka.classifiers.Classifier;
public class WekaWrapper
  extends Classifier {
  /**
   * Returns only the toString() method.
   *
   * @return a string describing the classifier
   */
  public String globalInfo() {
    return toString();
  }
  /**
   * Returns the capabilities of this classifier.
   *
   * @return the capabilities
   */
  public Capabilities getCapabilities() {
    weka.core.Capabilities result = new weka.core.Capabilities(this);
    result.enable(weka.core.Capabilities.Capability.NOMINAL_ATTRIBUTES);
    result.enable(weka.core.Capabilities.Capability.NUMERIC_ATTRIBUTES);
    result.enable(weka.core.Capabilities.Capability.DATE_ATTRIBUTES);
    result.enable(weka.core.Capabilities.Capability.MISSING_VALUES);
    result.enable(weka.core.Capabilities.Capability.NOMINAL_CLASS);
    result.enable(weka.core.Capabilities.Capability.MISSING_CLASS_VALUES);
    result.setMinimumNumberInstances(0);
    return result;
  }
  /**
   * only </span><pagenum epub:type="pagebreak" id="p62" page="normal" smilref="Machine_Learning00003.smil#p62">62</pagenum><span class="text" id="span_000265" smilref="Machine_Learning00003.smil#span_000265">checks the data against its capabilities.
   *
   * @param i the training data
   */
  public void buildClassifier(Instances i) throws Exception {
    // can classifier handle the data?
    getCapabilities().testWithFail(i);
  }
  /**
   * Classifies the given instance.
   *
   * @param i the instance to classify
   * @return the classification result
   */
  public double classifyInstance(Instance i) throws Exception {
    Object[] s = new Object[i.numAttributes()];
    for (int j = 0; j &lt; s.length; j++) {
      if (!i.isMissing(j)) {
        if (i.attribute(j).isNominal())
          s[j] = new String(i.stringValue(j));
        else if (i.attribute(j).isNumeric())
          s[j] = new Double(i.value(j));
      }
    }
    // set </span><pagenum epub:type="pagebreak" id="p63" page="normal" smilref="Machine_Learning00003.smil#p63">63</pagenum><span class="text" id="span_000266" smilref="Machine_Learning00003.smil#span_000266">class value to missing
    s[i.classIndex()] = null;
    return WekaClassifier.classify(s);
  }
  /**
   * Returns the revision string.
   *
   * @return        the revision
   */
  public String getRevision() {
    return RevisionUtils.extract("1.0");
  }
  /**
   * Returns only the classnames and what classifier it is based on.
   *
   * @return a short description
   */
  public String toString() {
    return "Auto-generated classifier wrapper, based on weka.classifiers.trees.J48 (generated with Weka 3.6.10).\n" + this.getClass().getName() + "/WekaClassifier";
  }
  /**
   * Runs the classfier from commandline.
   *
   * @param args the commandline arguments
   */
  public static void main(String args[]) {
    runClassifier(new WekaWrapper(), args);
  }
}
class WekaClassifier {
  public static double classify(Object[] i)
    throws Exception {
    double p = Double.NaN;
    p = WekaClassifier.N32ec89882(i);
    return p;
  }
  static double N32ec89882(Object []i) {
    double p = Double.NaN;
    if (i[0] == null) {
      p = 0;
    } else if (i[0].equals("end_rack")) {
      p = 0;
    } else if (i[0].equals("cd_spec")) {
    p = WekaClassifier.N473959d63(i);
    } else if (i[0].equals("std_rack")) {
    p = WekaClassifier.N63915224(i);
    }
    return p;
  }
  static double N473959d63(Object []i) {
    double p = Double.NaN;
    if (i[2] == null) {
      p = 0;
    } else if (((Double) i[2]).doubleValue() &lt;= 80.0) {
      p = 0;
    } else if (((Double) i[2]).doubleValue() &gt; 80.0) {
      p = 1;
    }
    return p;
  }
  static double N63915224(Object []i) {
    double p = Double.NaN;
    if (i[3] == null) {
      p = 0;
    } else if (i[3].equals("TRUE")) {
      p = 0;
    } else if (i[3].equals("FALSE")) {
      p = 1;
    }
    return p;
  }
} </span></code></p>
              <pagenum epub:type="pagebreak" id="p64" page="normal" smilref="Machine_Learning00003.smil#p64">64</pagenum>
              <p id="c03-c03-para-0089" xml:space="preserve"><span class="text" id="span_000267" smilref="Machine_Learning00003.smil#span_000267">Open your text editor of choice and then copy and paste the Java code. Save the file as </span><code xml:space="preserve" id="code_000076" smilref="Machine_Learning00003.smil#code_000076">WekaClassifier.java</code><span class="text" id="span_000268" smilref="Machine_Learning00003.smil#span_000268"> (or the name of the class you specified in the options pane).</span></p>
              <p id="c03-c03-para-0090" xml:space="preserve"><span class="text" id="span_000269" smilref="Machine_Learning00003.smil#span_000269">In the source code, there are actually two classes. A wrapper class that Weka generates and a main method from which to run. The core of the classifier is in the second class, </span><code xml:space="preserve" id="code_000077" smilref="Machine_Learning00003.smil#code_000077">WekaClassifier</code><span class="text" id="span_000270" smilref="Machine_Learning00003.smil#span_000270">. This is basically a set of if/then statements based on the classified tree.</span></p>
            </level3>
            <level3 id="level3_000076">
              <h3 xml:space="preserve" id="h3_000076" smilref="Machine_Learning00003.smil#h3_000076">Testing the Classifier Code</h3>
              <p xml:space="preserve" id="p_000163"><span class="text" id="span_000271" smilref="Machine_Learning00003.smil#span_000271">Make a copy of the </span><code xml:space="preserve" id="code_000078" smilref="Machine_Learning00003.smil#code_000078">.arff</code><span class="text" id="span_000272" smilref="Machine_Learning00003.smil#span_000272"> file to test your coded classifier. Where the outcomes are yes or no, replace them with question marks (?). This means you want the classifier to work out the answer for you:</span></p>
              <p xml:space="preserve" id="p_000164"><code class="preserve-whitespace" xml:space="preserve" id="code_000079" smilref="Machine_Learning00003.smil#code_000079">end_rack,85,85,FALSE,?
end_rack,80,90,TRUE,?
cd_spec,83,86,FALSE,?
std_rack,70,96,FALSE,?
std_rack,68,80,FALSE,?
std_rack,65,70,TRUE,?
cd_spec,64,65,TRUE,?
end_rack,72,95,FALSE,?
end_rack,69,70,FALSE,?
std_rack,75,80,FALSE,?
end_rack,75,70,TRUE,?
cd_spec,72,90,TRUE,?
cd_spec,81,75,FALSE,?
std_rack,71,91,TRUE,?</code></p>
              <p id="c03-c03-para-0092" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0092">You need to write a new class to load in your test data and run each instance against the coded classifier:</p>
              <p xml:space="preserve" id="p_000165"><code class="preserve-whitespace" xml:space="preserve" id="code_000080"><strong id="strong_000079" smilref="Machine_Learning00003.smil#strong_000079">package</strong><span class="text" id="span_000273" smilref="Machine_Learning00003.smil#span_000273"> chapter3;
import java.io.BufferedReader;
import java.io.FileReader;
import weka.core.Instances;
public class TestClassifier {
    public static void main(String[] args) {
        WekaWrapper ww = new WekaWrapper();
        try {
            Instances unlabeled = new Instances(new BufferedReader(
                    new FileReader("lg2.arff")));
            unlabeled.setClassIndex(unlabeled.numAttributes() - 1);
            for (int i = 0; i &lt; unlabeled.numInstances(); i++) {
                double clsLabel =    ww.classifyInstance(unlabeled.instance(i));
                System.out.println(clsLabel + " -&gt; " + unlabeled.classAttribute().value((int) clsLabel));
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}</span></code></p>
              <p id="c03-c03-para-0093" xml:space="preserve"><span class="text" id="span_000274" smilref="Machine_Learning00003.smil#span_000274">The </span><pagenum epub:type="pagebreak" id="p65" page="normal" smilref="Machine_Learning00003.smil#p65">65</pagenum><span class="text" id="span_000275" smilref="Machine_Learning00003.smil#span_000275">instances are loaded in and then the </span><code xml:space="preserve" id="code_000081" smilref="Machine_Learning00003.smil#code_000081">for</code><span class="text" id="span_000276" smilref="Machine_Learning00003.smil#span_000276"> loop iterates and uses the generated </span><code xml:space="preserve" id="code_000082" smilref="Machine_Learning00003.smil#code_000082">classifyInstance()</code><span class="text" id="span_000277" smilref="Machine_Learning00003.smil#span_000277"> method to get the scoring from the classifier. In this example, you're looking for the decision of whether a sale will happen or not.</span></p>
              <p id="c03-c03-para-0094" xml:space="preserve"><span class="text" id="span_000278" smilref="Machine_Learning00003.smil#span_000278">Because the </span><code xml:space="preserve" id="code_000083" smilref="Machine_Learning00003.smil#code_000083">classifyInstance()</code><span class="text" id="span_000279" smilref="Machine_Learning00003.smil#span_000279"> returns the value as a double data type, you reference that against the class attribute array position. In this case, the </span><pagenum epub:type="pagebreak" id="p66" page="normal" smilref="Machine_Learning00003.smil#p66">66</pagenum><code xml:space="preserve" id="code_000084" smilref="Machine_Learning00003.smil#code_000084">customer_purchase</code><span class="text" id="span_000280" smilref="Machine_Learning00003.smil#span_000280"> attribute has only two elements “yes” and “no.” The first element in the array (0) points to “yes,” and the second element (1) points to “no.”</span></p>
              <p id="c03-c03-para-0095" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0095">Running this example generates the following output:</p>
              <p xml:space="preserve" id="p_000166"><code class="preserve-whitespace" xml:space="preserve" id="code_000085" smilref="Machine_Learning00003.smil#code_000085">0.0 -&gt; yes
0.0 -&gt; yes
1.0 -&gt; no
1.0 -&gt; no
1.0 -&gt; no
0.0 -&gt; yes
0.0 -&gt; yes
0.0 -&gt; yes
0.0 -&gt; yes
1.0 -&gt; no
0.0 -&gt; yes
1.0 -&gt; no
0.0 -&gt; yes
0.0 -&gt; yes</code></p>
              <p id="c03-c03-para-0096" xml:space="preserve"><span class="text" id="span_000281" smilref="Machine_Learning00003.smil#span_000281">You could develop this basic code further to pull the required information from a database via Java Database Connectivity (JDBC) and then store the results again. You could even dump the results into a text file by making a copy of the instances first and updating them in the </span><code xml:space="preserve" id="code_000086" smilref="Machine_Learning00003.smil#code_000086">for</code><span class="text" id="span_000282" smilref="Machine_Learning00003.smil#span_000282"> loop.</span></p>
              <p xml:space="preserve" id="p_000167"><code class="preserve-whitespace" xml:space="preserve" id="code_000087"><span class="text" id="span_000283" smilref="Machine_Learning00003.smil#span_000283">Instances unlabeled = </span><strong id="strong_000080" smilref="Machine_Learning00003.smil#strong_000080">new</strong><span class="text" id="span_000284" smilref="Machine_Learning00003.smil#span_000284"> Instances(</span><strong id="strong_000081" smilref="Machine_Learning00003.smil#strong_000081">new</strong><span class="text" id="span_000285" smilref="Machine_Learning00003.smil#span_000285"> BufferedReader(
                    </span><strong id="strong_000082" smilref="Machine_Learning00003.smil#strong_000082">new</strong><span class="text" id="span_000286" smilref="Machine_Learning00003.smil#span_000286"> FileReader("lg2.arff")));
unlabeled.setClassIndex(unlabeled.numAttributes() - 1);
</span><strong id="strong_000083" smilref="Machine_Learning00003.smil#strong_000083">Instances trained = new Instances(unlabeled);</strong>
<strong id="strong_000084" smilref="Machine_Learning00003.smil#strong_000084">for</strong><span class="text" id="span_000287" smilref="Machine_Learning00003.smil#span_000287"> (</span><strong id="strong_000085" smilref="Machine_Learning00003.smil#strong_000085">int</strong><span class="text" id="span_000288" smilref="Machine_Learning00003.smil#span_000288"> i = 0; i &lt; unlabeled.numInstances(); i++) {
    </span><strong id="strong_000086" smilref="Machine_Learning00003.smil#strong_000086">double</strong><span class="text" id="span_000289" smilref="Machine_Learning00003.smil#span_000289"> clsLabel = ww.classifyInstance(unlabeled.instance(i));
    </span><strong id="strong_000087" smilref="Machine_Learning00003.smil#strong_000087">trained.instance(i).setClassValue(clsLabel);</strong><span class="text" id="span_000290" smilref="Machine_Learning00003.smil#span_000290">
    System.</span><em id="em_000046" smilref="Machine_Learning00003.smil#em_000046">out</em><span class="text" id="span_000291" smilref="Machine_Learning00003.smil#span_000291">.println(clsLabel + " -&gt; " +     unlabeled.classAttribute().value((</span><strong id="strong_000088" smilref="Machine_Learning00003.smil#strong_000088">int</strong><span class="text" id="span_000292" smilref="Machine_Learning00003.smil#span_000292">) clsLabel));
}</span></code></p>
              <p id="c03-c03-para-0097" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0097">The changes required are labeled in bold. This would be useful if you were to output the changes of the instances to a text file, for example.</p>
              <p id="c03-c03-para-0098" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0098">In terms of the actual work, you're done. You can deliver some solid code.</p>
            </level3>
            <level3 id="level3_000077">
              <h3 xml:space="preserve" id="h3_000077" smilref="Machine_Learning00003.smil#h3_000077">Thinking about Future Iterations</h3>
              <p xml:space="preserve" id="p_000168"><span class="text" id="span_000293" smilref="Machine_Learning00003.smil#span_000293">This chapter covers a lot of ground in a short space of time: putting an </span><code xml:space="preserve" id="code_000088" smilref="Machine_Learning00003.smil#code_000088">.arff</code><span class="text" id="span_000294" smilref="Machine_Learning00003.smil#span_000294"> file together to creating a classifier, and generating the Java code with Weka and testing it with more unclassified data.</span></p>
              <p id="c03-c03-para-0100" xml:space="preserve"><span class="text" id="span_000295" smilref="Machine_Learning00003.smil#span_000295">The test data you had was small, which is fine for getting everything working. In the real world, though, you'd be processing much more data. The question is this: </span><pagenum epub:type="pagebreak" id="p67" page="normal" smilref="Machine_Learning00003.smil#p67">67</pagenum><span class="text" id="span_000296" smilref="Machine_Learning00003.smil#span_000296">How much data should you retain for training? As a guide, I use 10 percent of the total data as a starting point and work from there. It's also worth thinking about the seasonality of data, especially if you are working in retail. Creating models for certain seasonal periods can boost the information gain in your training sets.</span></p>
              <p id="c03-c03-para-0101" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03-para-0101">Time waits for no one and the same applies here. Data changes; trends change; and so do management decisions and so on. It's important to keep the classifier up to date by means of running new test data and seeing if the model can improve.</p>
            </level3>
          </level2>
          <level2 id="level2_000028">
            <h2 id="c03-c03_level1_3" xml:space="preserve" smilref="Machine_Learning00003.smil#c03-c03_level1_3">Summary</h2>
            <p xml:space="preserve" id="p_000169" smilref="Machine_Learning00003.smil#p_000169">You've seen how decision trees work and the different algorithm types that are available. At a hands-on level, you've worked on a full project to create a working classifier based on the C4.5 (J48, which is the Java open source implementation as used in Weka) algorithm to predict customer purchasing behavior on products determined by placement, prominence, and pricing. Although many people perceive decision trees as simple, do not underestimate their uses. They are easy to understand and don't need a huge amount of preparation. They are often useful regardless of whether you have category or numerical data.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c04">
        <section epub:type="chapter" id="section_000005">
          <header id="header_000004">
            <h1 id="c04-c4" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c4">Chapter 4 Bayesian Networks</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p69" page="normal" smilref="Machine_Learning00003.smil#p69">69</pagenum>
          <p xml:space="preserve" id="p_000170" smilref="Machine_Learning00003.smil#p_000170">You might hear the Bayesian Network referred to by a few different names: probabilistic directed acyclic graphical model, Bayes Network, Belief Network, or Bayesian Model. Based on a set of variables or parameters, it's possible to predict outcomes based on probabilities. These variables are connected in such a way that the resulting value of one variable will influence the output probability of another, hence the use of networked nodes. A Bayesian Network manages to combine probability theory with graph theory and provides a very handy method for dealing with complexity and uncertainty.</p>
          <p id="c04-c04-para-0002" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0002">This chapter covers simple Bayesian Networks and how they are used in industry. After you have mastered the simple concepts, then you can expand your study in this area.</p>
          <level2 id="level2_000029">
            <h2 id="c04-c04_level1_1" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04_level1_1">Pilots to Paperclips</h2>
            <p xml:space="preserve" id="p_000171" smilref="Machine_Learning00003.smil#p_000171">Bayesian Networks are found all over the place where uncertainty is in play, which turns out to be a lot of places. Where there is uncertainty, there is probability.</p>
            <p id="c04-c04-para-0004" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0004">Weather forecasting and stock option predictions are examples. The financial industry uses Bayesian Networks a lot to make reasonable predictions even when the data is not complete. Bayesian Networks are the perfect tool for the likes of the insurance, banking, and investment industries. The following are a couple of specific examples of places that Bayesian Networks are being used:</p>
            <list type="ul" id="list_000031">
              <pagenum epub:type="pagebreak" id="p70" page="normal" smilref="Machine_Learning00003.smil#p70">70</pagenum>
              <li id="li_000305" smilref="Machine_Learning00003.smil#li_000305">The College of Civil Aviation at Nanjing University in China has a Bayesian Network for measuring safety risk as a result of delayed flights based on a large set of nodes.</li>
              <li id="li_000306" smilref="Machine_Learning00003.smil#li_000306">The Lumiere Project was born out of a Microsoft research project in 1993 with the goal of developing a platform to help users as they worked. It was later used in a pilot information system in commercial aviation, data displays to flight engineers at NASA, and that paperclip that comes up in Microsoft's Office Assistant. (Yes, Clippy is a Bayesian Network.)</li>
            </list>
            <sidebar render="required" id="sidebar_000002">
              <div class="top hr" id="div_000002" />
              <level2 class="feature2" id="level2_000030">
                <h2 xml:space="preserve" id="h2_000006" smilref="Machine_Learning00003.smil#h2_000006">Note</h2>
                <p xml:space="preserve" id="p_000172" smilref="Machine_Learning00003.smil#p_000172">The name “Bayesian Network” was initially coined by Judea Pearl to emphasize the aspects of a network that could rely on Bayes' Theorem for updating information in causal networks—things that are directly related to each other.</p>
              </level2>
            </sidebar>
            <p id="c04-c04-para-0006" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0006">To get started with implementing your own Bayesian Networks, you first need to come to grips with graphs, probability, and Thomas Bayes. Then you can put it all together.</p>
          </level2>
          <level2 id="level2_000031">
            <h2 id="c04-c04_level1_2" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04_level1_2">A Little Graph Theory</h2>
            <p xml:space="preserve" id="p_000173" smilref="Machine_Learning00003.smil#p_000173">Graph theory seems to invoke the fear of spiritual beings when it's mentioned, but after you get the basics it's not that difficult. I think a lot of confusion is borne from the definitions.</p>
            <p id="c04-c04-para-0008" xml:space="preserve"><span class="text" id="span_000297" smilref="Machine_Learning00003.smil#span_000297">Math folk call what's shown in </span><a id="c04-c04-fig-anc-0001" href="#c04-c04-fig-0001" external="false" smilref="Machine_Learning00003.smil#c04-c04-fig-anc-0001">Figure 4-1</a><span class="text" id="span_000298" smilref="Machine_Learning00003.smil#span_000298"> a vertex, but I prefer to call it a node.</span></p>
            <figure id="figure_000016">
              <img class="center" src="images/c04f001.jpg" alt="image" id="img_000016" />
              <figcaption id="figcaption_000012">
                <p xml:space="preserve" id="p_000174"><span class="figureLabel" id="span_000299"><a id="c04-c04-fig-0001" href="#c04-c04-fig-anc-0001" external="false"><strong id="strong_000089" smilref="Machine_Learning00003.smil#strong_000089">Figure 4-1</strong></a></span><span class="text" id="span_000300" smilref="Machine_Learning00003.smil#span_000300"> A node (or vertex)</span></p>
              </figcaption>
            </figure>
            <p id="c04-c04-para-0009" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0009">The nodes can signify anything you want. It could be rock bands, actors, films, or proteins.</p>
            <p id="c04-c04-para-0010" xml:space="preserve"><span class="text" id="span_000301" smilref="Machine_Learning00003.smil#span_000301">You can have as many nodes as you want, but you need to find a way of connecting them together; that's where the edge (a line that connects the nodes, not the guitarist from U2) comes in, as shown in </span><a id="c04-c04-fig-anc-0002" href="#c04-c04-fig-0002" external="false" smilref="Machine_Learning00003.smil#c04-c04-fig-anc-0002">Figure 4-2</a><span class="text" id="span_000302" smilref="Machine_Learning00003.smil#span_000302">.</span></p>
            <figure id="figure_000017">
              <img class="center" src="images/c04f002.jpg" alt="image" id="img_000017" />
              <figcaption id="figcaption_000013">
                <p xml:space="preserve" id="p_000175"><span class="figureLabel" id="span_000303"><a id="c04-c04-fig-0002" href="#c04-c04-fig-anc-0002" external="false"><strong id="strong_000090" smilref="Machine_Learning00003.smil#strong_000090">Figure 4-2</strong></a></span><span class="text" id="span_000304" smilref="Machine_Learning00003.smil#span_000304"> Two nodes (or vertices) and an edge</span></p>
              </figcaption>
            </figure>
            <pagenum epub:type="pagebreak" id="p71" page="normal" smilref="Machine_Learning00003.smil#p71">71</pagenum>
            <p id="c04-c04-para-0011" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0011">You now know there's a relationship between two nodes.</p>
            <p id="c04-c04-para-0012" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0012">When you need to manipulate and traverse a lot of edges in a graph quickly, it's worth looking at using large-scale graph databases such as Neo4J, Apache Giraph, or Spark. If you are interested in a language to query the nodes, then have a look at any reference to the Cypher language, which is very similar to the following example graph.</p>
            <p xml:space="preserve" id="p_000176"><code class="preserve-whitespace" xml:space="preserve" id="code_000089" smilref="Machine_Learning00003.smil#code_000089">MATCH (actress)-[:acted_in]-&gt;(film)</code></p>
            <p id="c04-c04-para-0013" xml:space="preserve"><span class="text" id="span_000305" smilref="Machine_Learning00003.smil#span_000305">Conceptual graphs are used in computer science and support a relationship between the nodes. The relationship is defined in the edge like the previous example in </span><a href="#c04-c04-fig-0002" external="false" id="a_000279" smilref="Machine_Learning00003.smil#a_000279">Figure 4-2</a><span class="text" id="span_000306" smilref="Machine_Learning00003.smil#span_000306">.</span></p>
            <p id="c04-c04-para-0014" xml:space="preserve"><span class="text" id="span_000307" smilref="Machine_Learning00003.smil#span_000307">When you add direct arrows to the edges, you have a directed graph. These can sometimes be called arcs or directed edges. The relationship is defined by the connection and the direction of the arrow. </span><a id="c04-c04-fig-anc-0003" href="#c04-c04-fig-0003" external="false" smilref="Machine_Learning00003.smil#c04-c04-fig-anc-0003">Figure 4-3</a><span class="text" id="span_000308" smilref="Machine_Learning00003.smil#span_000308"> shows an example.</span></p>
            <figure id="figure_000018">
              <img class="center" src="images/c04f003.jpg" alt="image" id="img_000018" />
              <figcaption id="figcaption_000014">
                <p xml:space="preserve" id="p_000177"><span class="figureLabel" id="span_000309"><a id="c04-c04-fig-0003" href="#c04-c04-fig-anc-0003" external="false"><strong id="strong_000091" smilref="Machine_Learning00003.smil#strong_000091">Figure 4-3</strong></a></span><span class="text" id="span_000310" smilref="Machine_Learning00003.smil#span_000310"> Directed and undirected graphs</span></p>
              </figcaption>
            </figure>
            <p id="c04-c04-para-0015" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0015">For the purpose of explaining Bayesian Networks, this simple notation will suffice for now in terms of the theory. Next you need to turn your attention to some probability.</p>
          </level2>
          <level2 id="level2_000032">
            <h2 id="c04-c04_level1_3" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04_level1_3">A Little Probability Theory</h2>
            <pagenum epub:type="pagebreak" id="p72" page="normal" smilref="Machine_Learning00003.smil#p72">72</pagenum>
            <p xml:space="preserve" id="p_000178" smilref="Machine_Learning00003.smil#p_000178">Okay, hands up if you're having flashbacks to learning probability theory at school. Do you feel a little panicked? There is no need to fret over such things. Probability is, quite simply, the measure of the likeliness that an event will occur.</p>
            <p id="c04-c04-para-0017" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0017">The question of interest will be something along the lines of “What will the result of the next coin toss be?” You use a value between 0 and 1 as your unit of measurement; the higher the probability that the event will happen, the higher the value of the number given.</p>
            <level3 id="level3_000078">
              <h3 xml:space="preserve" id="h3_000078" smilref="Machine_Learning00003.smil#h3_000078">Coin Flips</h3>
              <p xml:space="preserve" id="p_000179" smilref="Machine_Learning00003.smil#p_000179">For a coin toss you know there are two possible outcomes—either heads or tails—with a 50 percent chance of either event occurring. There is a notation for describing probability. For the coin toss outcomes you would write the following:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000180"><img src="images/c04_math_001.png" alt="equation" id="img_000019" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mtext>Coin&#x02009;toss&#x02009;will&#x02009;be&#x02009;heads</mtext></mrow></mfenced><mo>=</mo><mn>0.5</mn><mfenced open="(" close=")"><mrow><mtext>or</mtext><mspace width="0.12em"/><mn>&#x000BD;</mn><mspace width="0.12em"/><mtext>or</mtext><mspace width="0.12em"/><mn>50</mn><mo>%</mo></mrow></mfenced></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mtext>Coin&#x02009;toss&#x02009;will&#x02009;be&#x02009;tails</mtext></mrow></mfenced><mo>=</mo><mn>0.5</mn><mspace width="0.12em"/><mfenced open="(" close=")"><mrow><mtext>or</mtext><mspace width="0.12em"/><mn>&#x000BD;</mn><mspace width="0.12em"/><mtext>or</mtext><mspace width="0.12em"/><mn>50</mn><mo>%</mo></mrow></mfenced></mrow></math>--></p>
              <p id="c04-c04-para-0019" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0019">Now that's just for one coin toss. The answer to the question “What are the chances of the next coin toss being heads?” is ½. There can only be two possible outcomes.</p>
            </level3>
            <level3 id="level3_000079">
              <h3 xml:space="preserve" id="h3_000079" smilref="Machine_Learning00003.smil#h3_000079">Conditional Probability</h3>
              <p xml:space="preserve" id="p_000181" smilref="Machine_Learning00003.smil#p_000181">So far, this chapter has concentrated on fairly mundane and highly improbable (but not impossible) day-to-day events. What about completely unconnected events? Well, you can apply conditional probability to events that have just occurred.</p>
              <p id="c04-c04-para-0021" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0021">Take a look at the coin flips again. You've already covered one coin flip has two possible outcomes: heads or tails. What are the chances that two heads show up in two coin flips?</p>
              <p id="c04-c04-para-0022" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0022">You have a series of events:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000182"><img src="images/c04_math_002.png" alt="equation" id="img_000020" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">Coin&#x02009;flip</mtext><mspace width="0.12em"/><mn mathvariant="italic">1</mn><mo>.</mo><mspace width="0.12em"/><mfenced open="(" close=")"><mi>A</mi></mfenced></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">Coin&#x02009;flip</mtext><mspace width="0.12em"/><mn mathvariant="italic">2</mn><mo>.</mo><mspace width="0.12em"/><mfenced open="(" close=")"><mi>B</mi></mfenced></mrow></math>--></p>
              <p id="c04-c04-para-0023" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0023">The probability is shown like so:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000183"><img src="images/c04_math_003.png" alt="equation" id="img_000021" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">A</mi><mo stretchy="true">|</mo><mi mathvariant="normal">B</mi></mrow></mfenced></mrow></math>--></p>
              <p id="c04-c04-para-0024" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0024">You know that with one coin there is ½ chance of turning up heads. The possible outcomes for two coins are ½ x ½, which is ¼. You're simply multiplying the number of coin flips (2) by the probability of heads showing per coin flip (½). It's time to move on to a more realistic, everyday example.</p>
            </level3>
            <level3 id="level3_000080">
              <h3 xml:space="preserve" id="h3_000080" smilref="Machine_Learning00003.smil#h3_000080">Winning the Lottery</h3>
              <pagenum epub:type="pagebreak" id="p73" page="normal" smilref="Machine_Learning00003.smil#p73">73</pagenum>
              <p xml:space="preserve" id="p_000184" smilref="Machine_Learning00003.smil#p_000184">Coin flips are helpful and in some forms of gambling the game with two coin flips is still played. But these days the lottery is a more common game of probability. Everyone wants to win the lottery, right?</p>
              <p id="c04-c04-para-0026" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0026">In the UK, the National Lottery has 49 balls. To win the jackpot prize you have to correctly guess all six numbers. With six predictions and 49 balls, what are the chances that you will win the lottery?</p>
              <p id="c04-c04-para-0027" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0027">When the first ball is picked, there are six chances to pick one of the chosen numbers with 49 balls from which to choose. Next time there are 48 balls and five chances, and so on until all six numbers are picked. This results in the following mathematical equation:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000185"><img src="images/c04_math_004.png" alt="equation" id="img_000022" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mfrac><mn>6</mn><mn>49</mn></mfrac><mo>&#x000D7;</mo><mfrac><mn>5</mn><mn>48</mn></mfrac><mo>&#x000D7;</mo><mfrac><mn>4</mn><mn>47</mn></mfrac><mo>&#x000D7;</mo><mfrac><mn>3</mn><mn>46</mn></mfrac><mo>&#x000D7;</mo><mfrac><mn>2</mn><mn>45</mn></mfrac><mo>&#x000D7;</mo><mfrac><mn>1</mn><mn>44</mn></mfrac><mo>=</mo><mfrac><mn>720</mn><mrow><mn>10</mn><mo>,</mo><mn>068</mn><mo>,</mo><mn>347</mn><mo>,</mo><mn>520</mn></mrow></mfrac></mrow></math>--></p>
              <p id="c04-c04-para-0028" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0028">The number on the bottom line is basically just more than 10 billion. So, dear reader, there is a 720 in 10,068,347,520 chance of winning the lottery jackpot, or 1 in 13,983,816.</p>
              <p id="c04-c04-para-0029" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0029">Depending on what country you live in, there are various lotteries with different possible outcomes. The Euromillons, for example, is played in a number of European countries, so the jackpot is usually higher. The downside is that, because you are looking for seven numbers (five from the main set of numbers 1–50 and two “lucky stars” numbered 1–11), the probability to win the jackpot is 1 in 116,531,800. Other lotteries play six numbers from 44 balls, some from 39 balls. Regardless of how you look at it, the chances of winning are slim but not impossible.</p>
              <p id="c04-c04-para-0030" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0030">I'm going to park probability there; I only wanted to cover what you need to know in terms of Bayesian Networks. You've marveled at how graphs work, rolled a six-sided die some number of times to calculate probability, and even played the lottery once or twice in the name of research. Now you can delve into a little bit of background about a gentleman named Thomas and a theorem named after him: Bayes' Theorem.</p>
            </level3>
          </level2>
          <level2 id="level2_000033">
            <h2 id="c04-c04_level1_4" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04_level1_4">Bayes' Theorem</h2>
            <p xml:space="preserve" id="p_000186" smilref="Machine_Learning00003.smil#p_000186">If there's one aspect of machine learning you'll hear talked about, it's the application of Bayes' Theorem. You might also hear the terms Bayes' Law or Bayes' Rule used, but all three are essentially the same thing.</p>
            <p id="c04-c04-para-0032" xml:space="preserve"><span class="text" id="span_000311" smilref="Machine_Learning00003.smil#span_000311">Thomas Bayes was born in 1701 and died in 1761. As well as being a Presbyterian minister, he was a philosopher and statistician. His theorem wasn't named after </span><pagenum epub:type="pagebreak" id="p74" page="normal" smilref="Machine_Learning00003.smil#p74">74</pagenum><span class="text" id="span_000312" smilref="Machine_Learning00003.smil#span_000312">him until after his death in 1763 when his essay, “An Essay Towards Solving a Problem in the Doctrine of Chances,” was cited by Richard Price to help prove the existence of God.</span></p>
            <p id="c04-c04-para-0033" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0033">The important part of Bayes' Theorem is the observation of previous events, or your degree of belief that something will occur. If you have a degree of belief of one event happening, you can apply it to new data and make an informed calculation to its probability. There are plenty of examples of the application of Bayes' Theorem to determine the result of more coin flips, the spread of disease, or the potential gender of offspring. I'm going to avoid all the clichéd examples and demonstrate with my own about country music.</p>
            <sidebar render="required" id="sidebar_000003">
              <div class="top hr" id="div_000003" />
              <level2 class="feature1" id="level2_000034">
                <h2 xml:space="preserve" id="h2_000007" smilref="Machine_Learning00003.smil#h2_000007">Diagnosing Country Music</h2>
                <p xml:space="preserve" id="p_000187" smilref="Machine_Learning00003.smil#p_000187">For the record, I do like country music—well, certain types of it. Please don't judge me, but for the purpose of explaining Bayes' Theorem, I'm going to use country music to get the point across.</p>
                <p xml:space="preserve" id="p_000188" smilref="Machine_Learning00003.smil#p_000188">The test for diagnosing whether or not a person likes country music is conducted by playing a mixture of Nanci Griffith, Mary Chapin Carpenter, Garth Brooks, and Lyle Lovett to the listener. Based on various brain responses, you can deduce a negative or positive response from the test.</p>
                <p xml:space="preserve" id="p_000189" smilref="Machine_Learning00003.smil#p_000189">We know a positive test is 95 percent accurate; the listener likes country music. The test is 99 percent successful in diagnosing those who do not like country music. People in the know will call this 98 percent sensitivity and 99 percent specificity. If you call the test T and whether a person likes Country music C, you have the following probability outcomes:</p>
                <list type="ol" id="list_000032">
                  <li id="li_000307" smilref="Machine_Learning00003.smil#li_000307">C likes country</li>
                  <li id="li_000308" smilref="Machine_Learning00003.smil#li_000308">˜C does not like country</li>
                  <li id="li_000309" smilref="Machine_Learning00003.smil#li_000309">T tests positive for liking country</li>
                  <li id="li_000310" smilref="Machine_Learning00003.smil#li_000310">˜T tests negative for liking country</li>
                </list>
                <p xml:space="preserve" id="p_000190" smilref="Machine_Learning00003.smil#p_000190">The probabilities are listed for sensitivity as</p>
                <p class="informalEquation" xml:space="preserve" id="p_000191"><img src="images/c04_math_005.png" alt="equation" id="img_000023" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">T</mi><mo stretchy="true">|</mo><mi mathvariant="normal">C</mi></mrow></mfenced><mo>=</mo><mn>0.95</mn></mrow></math>--></p>
                <p xml:space="preserve" id="p_000192" smilref="Machine_Learning00003.smil#p_000192">For specificity you get</p>
                <p class="informalEquation" xml:space="preserve" id="p_000193"><img src="images/c04_math_006.png" alt="equation" id="img_000024" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mo>&#x002DC;</mo><mi mathvariant="normal">T</mi><mo stretchy="true">|</mo><mo>&#x002DC;</mo><mi mathvariant="normal">C</mi></mrow></mfenced><mo>=</mo><mn>0.99</mn></mrow></math>--></p>
                <p xml:space="preserve" id="p_000194" smilref="Machine_Learning00003.smil#p_000194">And finally, you assume that 2 percent of the population will like country music:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000195"><img src="images/c04_math_007.png" alt="equation" id="img_000025" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mi mathvariant="normal">D</mi></mfenced><mo>=</mo><mn>0.02</mn></mrow></math>--></p>
                <p xml:space="preserve" id="p_000196" smilref="Machine_Learning00003.smil#p_000196">Although it's all well and good to run these experiments, you also know that false positives can creep in. There is a chance that someone will test positive for liking country music but doesn't actually like it. There are also false negatives to take into account—someone who in fact does like country music but tests negative.</p>
                <pagenum epub:type="pagebreak" id="p75" page="normal" smilref="Machine_Learning00003.smil#p75">75</pagenum>
                <p xml:space="preserve" id="p_000197" smilref="Machine_Learning00003.smil#p_000197">With Bayes' Theorem, you can calculate the probability with all the previously defined information. In scary math books, it looks like this:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000198"><img src="images/c04_math_008.png" alt="equation" id="img_000026" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>C</mi><mo stretchy="true">|</mo><mi>T</mi></mrow></mfenced><mo>=</mo><mstyle scriptlevel="+1"><mfrac><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>T</mi><mo stretchy="true">|</mo><mi>C</mi></mrow></mfenced><mi>p</mi><mfenced open="(" close=")"><mi>C</mi></mfenced></mrow><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>T</mi><mo stretchy="true">|</mo><mi>C</mi></mrow></mfenced><mi>p</mi><mfenced open="(" close=")"><mi>C</mi></mfenced><mo>+</mo><mi>p</mi><mfenced open="(" close=")"><mrow><mi>T</mi><mo stretchy="true">|</mo><mo>&#x002DC;</mo><mi>C</mi></mrow></mfenced><mi>p</mi><mfenced open="(" close=")"><mrow><mo>&#x002DC;</mo><mi>C</mi></mrow></mfenced></mrow></mfrac></mstyle></mrow></math>--></p>
                <p xml:space="preserve" id="p_000199" smilref="Machine_Learning00003.smil#p_000199">It looks complicated, doesn't it? It reads easier after you get the values in the equation. What you are really saying is this:</p>
                <p class="informalEquation" xml:space="preserve" id="p_000200"><img src="images/c04_math_009.png" alt="equation" id="img_000027" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>p</mi><mfenced open="(" close=")"><mrow><mi>C</mi><mo stretchy="true">|</mo><mi>T</mi></mrow></mfenced><mo>=</mo><mstyle scriptlevel="+1"><mfrac><mrow><mn>0.95</mn><mi>x</mi><mn>0.02</mn></mrow><mrow><mfenced open="(" close=")"><mrow><mn>0.95</mn><mi>x</mi><mn>0.02</mn></mrow></mfenced><mo>+</mo><mfenced open="(" close=")"><mrow><mn>0.02</mn><mi>x</mi><mn>0.98</mn></mrow></mfenced></mrow></mfrac></mstyle><mo>=</mo><mstyle scriptlevel="+1"><mfrac><mn>0.019</mn><mrow><mn>0.019</mn><mi>x</mi><mn>0.0184</mn></mrow></mfrac></mstyle><mo>=</mo><mn>0.51</mn></mrow></math>--></p>
                <p xml:space="preserve" id="p_000201" smilref="Machine_Learning00003.smil#p_000201">There's still a 51 percent chance that a test will return a false positive result. All that excellent music will be wasted on those subjects, as they don't really like it that much.</p>
                <p xml:space="preserve" id="p_000202" smilref="Machine_Learning00003.smil#p_000202">Those are the three building blocks of graph theory, probability, and Bayes Theorem explained in the simplest way possible. Now you can return to the actual Bayesian Network to see how it is put together.</p>
              </level2>
            </sidebar>
          </level2>
          <level2 id="level2_000035">
            <h2 id="c04-c04_level1_5" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04_level1_5">How Bayesian Networks Work</h2>
            <p xml:space="preserve" id="p_000203" smilref="Machine_Learning00003.smil#p_000203">Now that you have a basic grasp of graphs, probability, and Bayes' Theorem, look at how the network is put together.</p>
            <p id="c04-c04-para-0046" xml:space="preserve"><span class="text" id="span_000313" smilref="Machine_Learning00003.smil#span_000313">Consider the graph shown in </span><a id="c04-c04-fig-anc-0004" href="#c04-c04-fig-0004" external="false" smilref="Machine_Learning00003.smil#c04-c04-fig-anc-0004">Figure 4-4</a><span class="text" id="span_000314" smilref="Machine_Learning00003.smil#span_000314">.</span></p>
            <figure id="figure_000019">
              <img class="center" src="images/c04f004.jpg" alt="image" id="img_000028" />
              <figcaption id="figcaption_000015">
                <p xml:space="preserve" id="p_000204"><span class="figureLabel" id="span_000315"><a id="c04-c04-fig-0004" href="#c04-c04-fig-anc-0004" external="false"><strong id="strong_000092" smilref="Machine_Learning00003.smil#strong_000092">Figure 4-4</strong></a></span><span class="text" id="span_000316" smilref="Machine_Learning00003.smil#span_000316"> A basic Bayesian Network</span></p>
              </figcaption>
            </figure>
            <p id="c04-c04-para-0047" xml:space="preserve"><span class="text" id="span_000317" smilref="Machine_Learning00003.smil#span_000317">In the classic “Is my backyard wet?” graph (or “Is the grass wet” graph) shown in </span><a href="#c04-c04-fig-0004" external="false" id="a_000280" smilref="Machine_Learning00003.smil#a_000280">Figure 4-4</a><span class="text" id="span_000318" smilref="Machine_Learning00003.smil#span_000318">, you can see there are three nodes: Yard Wet, Rain, and Hose. There are two events that would cause the yard to be wet; either the owner had </span><pagenum epub:type="pagebreak" id="p76" page="normal" smilref="Machine_Learning00003.smil#p76">76</pagenum><span class="text" id="span_000319" smilref="Machine_Learning00003.smil#span_000319">hosed it or it has been raining. In any normal circumstance, you wouldn't hose the yard while it was raining.</span></p>
            <p id="c04-c04-para-0048" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0048">For each node you can assign true/false values:</p>
            <list type="ol" id="list_000033">
              <li id="li_000311" smilref="Machine_Learning00003.smil#li_000311">Y = Yard wet (True or False)</li>
              <li id="li_000312" smilref="Machine_Learning00003.smil#li_000312">R = Raining (True or False)</li>
              <li id="li_000313" smilref="Machine_Learning00003.smil#li_000313">H = Someone using the hose (True or False)</li>
            </list>
            <p id="c04-c04-para-0049" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0049">The joint probability would be written as</p>
            <p class="informalEquation" xml:space="preserve" id="p_000205"><img src="images/c04_math_010.png" alt="equation" id="img_000029" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>p</mi><mfenced open="(" close=")" separators=",,"><mi>Y</mi><mi>R</mi><mi>H</mi></mfenced><mo>=</mo><mi>p</mi><mfenced open="(" close=")"><mrow><mi>Y</mi><mo stretchy="true">|</mo><mi>R</mi><mo>,</mo><mi>H</mi></mrow></mfenced><mspace width="0.12em"/><mi>p</mi><mfenced open="(" close=")"><mrow><mi>R</mi><mo stretchy="true">|</mo><mi>H</mi></mrow></mfenced><mspace width="0.12em"/><mi>p</mi><mfenced open="(" close=")"><mi>R</mi></mfenced></mrow></math>--></p>
            <p id="c04-c04-para-0050" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0050">With these variables in hand, you can start asking some questions—for example, what's the probability that it's raining when the yard is wet?</p>
            <level3 id="level3_000081">
              <h3 xml:space="preserve" id="h3_000081" smilref="Machine_Learning00003.smil#h3_000081">Assigning Probabilities</h3>
              <p xml:space="preserve" id="p_000206" smilref="Machine_Learning00003.smil#p_000206">As mentioned earlier in the chapter, probability values are between 0 and 1. As the nodes are all either true or false, you can start to assign some basic outcomes to the nodes. First is the node Rain. Because it doesn't have any parent nodes, it is easy to assign a probability to it.</p>
              <figure id="figure_000020">
                <table border="1" id="table_000007">
                  <tr id="tr_000024">
                    <td class="left" colspan="2" rowspan="1" id="td_000083" smilref="Machine_Learning00003.smil#td_000083">Rain</td>
                  </tr>
                  <tr id="tr_000025">
                    <td class="left" rowspan="1" colspan="1" id="td_000084">
                      <strong id="strong_000093" smilref="Machine_Learning00003.smil#strong_000093">True</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000085">
                      <strong id="strong_000094" smilref="Machine_Learning00003.smil#strong_000094">False</strong>
                    </td>
                  </tr>
                  <tr id="tr_000026">
                    <td class="left" rowspan="1" colspan="1" id="td_000086" smilref="Machine_Learning00003.smil#td_000086">0.2</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000087" smilref="Machine_Learning00003.smil#td_000087">0.8</td>
                  </tr>
                </table>
              </figure>
              <p id="c04-c04-para-0052" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0052">Next, look at the Hose node; it uses the Rain node as a parent node, so you need to assign probabilities for each of the outcomes of the parent node. The outcomes table for Hose looks like the following:</p>
              <figure id="figure_000021">
                <table border="1" id="table_000008">
                  <tr id="tr_000027">
                    <td class="left" colspan="3" rowspan="1" id="td_000088" smilref="Machine_Learning00003.smil#td_000088">Hose</td>
                  </tr>
                  <tr id="tr_000028">
                    <td class="left" rowspan="1" colspan="1" id="td_000089">
                      <strong id="strong_000095" smilref="Machine_Learning00003.smil#strong_000095">Value of Rain Node</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000090">
                      <strong id="strong_000096" smilref="Machine_Learning00003.smil#strong_000096">True</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000091">
                      <strong id="strong_000097" smilref="Machine_Learning00003.smil#strong_000097">False</strong>
                    </td>
                  </tr>
                  <tr id="tr_000029">
                    <td class="left" rowspan="1" colspan="1" id="td_000092" smilref="Machine_Learning00003.smil#td_000092">False</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000093" smilref="Machine_Learning00003.smil#td_000093">0.4</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000094" smilref="Machine_Learning00003.smil#td_000094">0.6</td>
                  </tr>
                  <tr id="tr_000030">
                    <td class="left" rowspan="1" colspan="1" id="td_000095" smilref="Machine_Learning00003.smil#td_000095">True</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000096" smilref="Machine_Learning00003.smil#td_000096">0.01</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000097" smilref="Machine_Learning00003.smil#td_000097">0.99</td>
                  </tr>
                </table>
              </figure>
              <p id="c04-c04-para-0053" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0053">The main thing to note is that the values always add up to 1. If you've gone over that amount, then you need to correct it.</p>
              <p id="c04-c04-para-0054" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0054">The last node is Yard, which has two parents: Rain and Hose. You need to ensure that all the outcomes are taken into account.</p>
              <figure id="figure_000022">
                <table border="1" id="table_000009">
                  <tr id="tr_000031">
                    <td class="left" colspan="4" rowspan="1" id="td_000098" smilref="Machine_Learning00003.smil#td_000098">Yard</td>
                  </tr>
                  <tr id="tr_000032">
                    <td class="left" rowspan="1" colspan="1" id="td_000099">
                      <strong id="strong_000098" smilref="Machine_Learning00003.smil#strong_000098">Hose</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000100">
                      <strong id="strong_000099" smilref="Machine_Learning00003.smil#strong_000099">Rain</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000101">
                      <strong id="strong_000100" smilref="Machine_Learning00003.smil#strong_000100">True</strong>
                    </td>
                    <td class="left" rowspan="1" colspan="1" id="td_000102">
                      <strong id="strong_000101" smilref="Machine_Learning00003.smil#strong_000101">False</strong>
                    </td>
                  </tr>
                  <tr id="tr_000033">
                    <td class="left" rowspan="1" colspan="1" id="td_000103" smilref="Machine_Learning00003.smil#td_000103">False</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000104" smilref="Machine_Learning00003.smil#td_000104">False</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000105" smilref="Machine_Learning00003.smil#td_000105">0.0</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000106" smilref="Machine_Learning00003.smil#td_000106">1.0</td>
                  </tr>
                  <tr id="tr_000034">
                    <td class="left" rowspan="1" colspan="1" id="td_000107" smilref="Machine_Learning00003.smil#td_000107">False</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000108" smilref="Machine_Learning00003.smil#td_000108">True</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000109" smilref="Machine_Learning00003.smil#td_000109">0.8</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000110" smilref="Machine_Learning00003.smil#td_000110">0.2</td>
                  </tr>
                  <tr id="tr_000035">
                    <td class="left" rowspan="1" colspan="1" id="td_000111" smilref="Machine_Learning00003.smil#td_000111">True</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000112" smilref="Machine_Learning00003.smil#td_000112">False</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000113" smilref="Machine_Learning00003.smil#td_000113">0.9</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000114" smilref="Machine_Learning00003.smil#td_000114">0.1</td>
                  </tr>
                  <tr id="tr_000036">
                    <td class="left" rowspan="1" colspan="1" id="td_000115" smilref="Machine_Learning00003.smil#td_000115">True</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000116" smilref="Machine_Learning00003.smil#td_000116">True</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000117" smilref="Machine_Learning00003.smil#td_000117">0.99</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000118" smilref="Machine_Learning00003.smil#td_000118">0.01</td>
                  </tr>
                </table>
              </figure>
              <pagenum epub:type="pagebreak" id="p77" page="normal" smilref="Machine_Learning00003.smil#p77">77</pagenum>
              <p id="c04-c04-para-0055" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0055">The Yard node includes all the outcomes that are related to it. Once again, all the probabilities add up to 1.</p>
              <p id="c04-c04-para-0056" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0056">You have three variables, each with two possible values and all the probabilities assigned. Now you can calculate some results.</p>
            </level3>
            <level3 id="level3_000082">
              <h3 xml:space="preserve" id="h3_000082" smilref="Machine_Learning00003.smil#h3_000082">Calculating Results</h3>
              <p xml:space="preserve" id="p_000207" smilref="Machine_Learning00003.smil#p_000207">As with all good data analysis, you should start with a question. In this case, the question is “Given that the yard is wet, what's the probability that it's raining?”</p>
              <p id="c04-c04-para-0058" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0058">Start with what you know. The clues are in the question: the yard is wet (True), and we want to know if it's raining (True). The only variable you're not certain about is the state of the hose; it could be true or false as it stands.</p>
              <p id="c04-c04-para-0059" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0059">The joint probability function written at the start gives you the relationship of the nodes and their parents from a probability point of view. What you're basically saying is</p>
              <p class="informalEquation" xml:space="preserve" id="p_000208"><img src="images/c04_math_011.png" alt="equation" id="img_000030" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">Y</mi><mo>=</mo><mtext>True</mtext><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">H</mi><mo>=</mo><mtext>True</mtext><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">Y</mi><mo>=</mo><mtext>True</mtext><mo stretchy="true">|</mo><mi mathvariant="normal">H</mi><mo>=</mo><mtext>True</mtext><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced><mo>&#x000D7;</mo><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">H</mi><mo>=</mo><mtext>True</mtext><mo stretchy="true">|</mo><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced><mo>&#x000D7;</mo><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced></mrow></math>--></p>
              <p id="c04-c04-para-0060" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0060">I'll break that down a little, as it might be confusing if you're not used to reading it. What is being said is this:</p>
              <list type="ol" id="list_000034">
                <li id="li_000314">
                  <em id="em_000047" smilref="Machine_Learning00003.smil#em_000047">Multiply the values of the wet Yard probability</em>
                  <span class="text" id="span_000320" smilref="Machine_Learning00003.smil#span_000320">,</span>
                  <em id="em_000048" smilref="Machine_Learning00003.smil#em_000048">where the values for Hose and Rain are also true</em>
                  <span class="text" id="span_000321" smilref="Machine_Learning00003.smil#span_000321">,</span>
                  <em id="em_000049" smilref="Machine_Learning00003.smil#em_000049">by the probability of Hose being true with the value of Rain being true</em>
                  <span class="text" id="span_000322" smilref="Machine_Learning00003.smil#span_000322">,</span>
                  <em id="em_000050" smilref="Machine_Learning00003.smil#em_000050">by the probability of Rain being true</em>
                  <span class="text" id="span_000323" smilref="Machine_Learning00003.smil#span_000323">.</span>
                </li>
              </list>
              <p id="c04-c04-para-0061" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0061">So, the values you need are</p>
              <p class="informalEquation" xml:space="preserve" id="p_000209"><img src="images/c04_math_012.png" alt="equation" id="img_000031" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mn>0.99</mn><mspace width="0.12em"/><mfenced open="(" close=")"><mrow><mi mathvariant="normal">Y</mi><mo>=</mo><mi mathvariant="normal">T</mi><mo>,</mo><mspace width="0.25em"/><mi mathvariant="normal">H</mi><mo>=</mo><mi mathvariant="normal">T</mi><mo>,</mo><mspace width="0.25em"/><mi mathvariant="normal">R</mi><mo>=</mo><mi mathvariant="normal">T</mi></mrow></mfenced><mo>&#x000D7;</mo><mn>0.01</mn><mspace width="0.12em"/><mfenced open="(" close=")"><mrow><mi mathvariant="normal">H</mi><mo>=</mo><mi mathvariant="normal">T</mi><mo>,</mo><mspace width="0.25em"/><mi mathvariant="normal">R</mi><mo>=</mo><mi mathvariant="normal">T</mi></mrow></mfenced><mo>&#x000D7;</mo><mn>0.2</mn><mspace width="0.12em"/><mfenced open="(" close=")"><mrow><mi mathvariant="normal">R</mi><mo>=</mo><mi mathvariant="normal">T</mi></mrow></mfenced><mo>=</mo><mn>0.00198</mn></mrow></math>--></p>
              <p id="c04-c04-para-0062" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0062">Next, you work out the value of the probability if the hose was false. This is the variable you don't know, so it's important to work out the probability for it.</p>
              <p class="informalEquation" xml:space="preserve" id="p_000210"><img src="images/c04_math_013.png" alt="equation" id="img_000032" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">Y</mi><mo>=</mo><mtext>True</mtext><mo stretchy="true">|</mo><mi mathvariant="normal">H</mi><mo>=</mo><mtext>False</mtext><mo>,</mo><mspace width="0.12em"/><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced><mo>&#x000D7;</mo><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">H</mi><mo>=</mo><mtext>False</mtext><mo stretchy="true">|</mo><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced><mo>&#x000D7;</mo><mi mathvariant="normal">p</mi><mfenced open="(" close=")"><mrow><mi mathvariant="normal">R</mi><mo>=</mo><mtext>True</mtext></mrow></mfenced></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mn>0.8</mn><mo>&#x000D7;</mo><mn>0.99</mn><mo>&#x000D7;</mo><mn>0.2</mn><mo>=</mo><mn>0.1584</mn></mrow></math>--></p>
              <p id="c04-c04-para-0063" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0063">This part of the calculation is for the upper part of the equation (the numerator); now you can plug in values for the lower part (the denominator).</p>
              <p id="c04-c04-para-0064" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0064">All that happens is a repeat of the earlier equation but for the other outcomes of the yard being wet.</p>
              <p id="c04-c04-para-0065" xml:space="preserve" smilref="Machine_Learning00003.smil#c04-c04-para-0065">T,T,T = we know is 0.00198</p>
              <p id="c04-c04-para-0066" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0066">T,F,T = we know is 0.1584</p>
              <pagenum epub:type="pagebreak" id="p78" page="normal" smilref="Machine_Learning00004.smil#p78">78</pagenum>
              <p id="c04-c04-para-0067" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0067">T,T,F = 0.9 × 0.4 × 0.8 = 0.288</p>
              <p id="c04-c04-para-0068" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0068">T,F,F = 0.0 × 0.6 × 0.8 = 0.0</p>
              <p id="c04-c04-para-0069" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0069">So the final equation looks like this:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000211"><img src="images/c04_math_014.png" alt="equation" id="img_000033" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mfrac><mrow><mn>0.00198</mn><mo>+</mo><mn>0.1584</mn></mrow><mrow><mn>0.00198</mn><mo>+</mo><mn>0.288</mn><mo>+</mo><mn>0.1584</mn><mo>+</mo><mn>0.0</mn></mrow></mfrac></mrow></math>--></p>
              <p id="c04-c04-para-0070" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0070">The top divided by the bottom results in 0.3576876, but just round it up to 0.3577. As a percentage, that's 35.77 percent.</p>
            </level3>
          </level2>
          <level2 id="level2_000036">
            <h2 id="c04-c04_level1_6" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04_level1_6">Node Counts</h2>
            <p xml:space="preserve" id="p_000212" smilref="Machine_Learning00004.smil#p_000212">Bayesian Networks depend on a lot of counting. The more nodes you have, the more counting the network has to do. The earlier example has three nodes. Each node has only two probability variables. So you can compute the counts easily.</p>
            <p class="informalEquation" xml:space="preserve" id="p_000213"><img src="images/c04_math_015.png" alt="equation" id="img_000034" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mn>2</mn><mo>&#x000D7;</mo><mn>2</mn><mo>&#x000D7;</mo><mn>2</mn><mo>=</mo><mn>8</mn><mspace width="0.12em"/><mtext>counts</mtext></mrow></math>--></p>
            <p id="c04-c04-para-0072" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0072">If you had a network with 12 nodes, 7 of which had three variables and the other 5 had six variables, you would have a calculation of:</p>
            <p id="c04-c04-para-0073" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0073">3 × 3 × 3 × 3 × 3 × 3 × 3 × 6 × 6 × 6 × 6 × 6 = 17,006,112 counts</p>
            <p id="c04-c04-para-0074" xml:space="preserve"><span class="text" id="span_000324" smilref="Machine_Learning00004.smil#span_000324">You have to be aware that as you add nodes with </span><em id="em_000051" smilref="Machine_Learning00004.smil#em_000051">n</em><span class="text" id="span_000325" smilref="Machine_Learning00004.smil#span_000325"> number of variables, the performance needs of your computing will rise dramatically. It will take longer to gain results in the first instance when the computing of the network is done.</span></p>
            <p id="c04-c04-para-0075" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0075">Bayesian Networks can run into memory problems as well, so keep that in mind while you are developing your programs.</p>
          </level2>
          <level2 id="level2_000037">
            <h2 id="c04-c04_level1_7" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04_level1_7">Using Domain Experts</h2>
            <p xml:space="preserve" id="p_000214" smilref="Machine_Learning00004.smil#p_000214">One thing you might be wondering reading this chapter and the “How Bayesian Networks Work” section is “Who's dictating the initial probabilities?” Well, in this instance I decided on the probabilities by way of illustrating how the network is put together. In a real-world context it will be, more than likely, a domain expert.</p>
            <p id="c04-c04-para-0077" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0077">Software developers are great at developing software; that's what they do. However, they're not always good at knowing the rest of the business domain. If you ask them the question “Why do our customers always buy this product?” chances are they won't have the answers. Someone who knows the retail domain and how customers think will have a better understanding than they do.</p>
            <pagenum epub:type="pagebreak" id="p79" page="normal" smilref="Machine_Learning00004.smil#p79">79</pagenum>
            <p id="c04-c04-para-0078" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0078">It's important to sit down with the domain experts from the start and gather as much information as you can to get the network in a good working order to give reasonable answers. You will refine these things later on; as the algorithm gets used more and more, the results will get better after you share the output with the domain expert and the rest of the team and they update the values.</p>
          </level2>
          <level2 id="level2_000038">
            <h2 id="c04-c04_level1_8" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04_level1_8">A Bayesian Network Walkthrough</h2>
            <p xml:space="preserve" id="p_000215" smilref="Machine_Learning00004.smil#p_000215">There are a number of libraries you can use for creating and running Bayesian Networks. Weka has its own support for them and incorporates the K2 algorithm for learning. The emphasis on many tools, such as OpenMarkov and Weka, is the use of a graphical user interface (GUI) to enable you (and the domain experts) to create the graphs and assign the probabilities. For this walkthrough I will use the JavaBayes API.</p>
            <level3 id="level3_000083">
              <h3 xml:space="preserve" id="h3_000083" smilref="Machine_Learning00004.smil#h3_000083">Java APIs for Bayesian Networks</h3>
              <p xml:space="preserve" id="p_000216"><span class="text" id="span_000326" smilref="Machine_Learning00004.smil#span_000326">Because this book uses Java for the core of the work, it would be nice to use a Java API that creates nodes, their edges, and their probabilities. Netica (</span><a href="https://www.norsys.com/netica.html" external="true" id="a_000281" smilref="Machine_Learning00004.smil#a_000281">https://www.norsys.com/netica.html</a><span class="text" id="span_000327" smilref="Machine_Learning00004.smil#span_000327">) is one, but it is a commercial application (meaning you have to pay for it) and it relies on native libraries of the operating system on which you are working.</span></p>
              <p id="c04-c04-para-0081" xml:space="preserve"><span class="text" id="span_000328" smilref="Machine_Learning00004.smil#span_000328">Another library is Jayes (</span><a href="https://github.com/kutschkem/Jayes" external="true" id="a_000282" smilref="Machine_Learning00004.smil#a_000282">https://github.com/kutschkem/Jayes</a><span class="text" id="span_000329" smilref="Machine_Learning00004.smil#span_000329">) and it's used within Eclipse for code completion algorithms. It's open source; its build process is tied to Maven; and it is not the easiest to get going easily. It's certainly worth a look, though; so put it on your to-do list for when you have time.</span></p>
              <p id="c04-c04-para-0082" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0082">Lastly, there's JavaBayes. To give you an idea how old it is, it was originally written for Java 1.0.2, so it goes back quite a while. On the plus side, Joe Schweitzer at Dataworks has updated it on Github, so you can download it and use it fairly quickly.</p>
              <p id="c04-c04-para-0083" xml:space="preserve"><span class="text" id="span_000330" smilref="Machine_Learning00004.smil#span_000330">For the walkthrough, I've added the helper classes from Joe's original code samples so they are in one complete library. If you want to complete the tutorial, then you need to download the jar file from </span><a href="https://github.com/jasebell/JavaBayesAPI" external="true" id="a_000283" smilref="Machine_Learning00004.smil#a_000283">https://github.com/jasebell/JavaBayesAPI</a><span class="text" id="span_000331" smilref="Machine_Learning00004.smil#span_000331">.</span></p>
            </level3>
            <level3 id="level3_000084">
              <h3 xml:space="preserve" id="h3_000084" smilref="Machine_Learning00004.smil#h3_000084">Planning the Network</h3>
              <p xml:space="preserve" id="p_000217" smilref="Machine_Learning00004.smil#p_000217">Before you start any coding, you have to think about what needs to be done. You're creating a simple Bayesian Network in Java, and this section describes the plan.</p>
              <pagenum epub:type="pagebreak" id="p80" page="normal" smilref="Machine_Learning00004.smil#p80">80</pagenum>
              <p id="c04-c04-para-0085" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0085">The best place to plan these sorts of things is on paper; it's also handy to grab your nearest domain expert who's well versed in the domain you are working in. You'll use a real-world example that would require an expert, as it's fair to say most people already know what causes our yards and lawns to be wet.</p>
              <p id="c04-c04-para-0086" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0086">Cervical Spondylotic Myelopathy (CSM) is a spine disease and is one of the most common spinal cord dysfunctions in patients over 55 years old. Symptoms include, but are not limited to, impaired gait leading to issues walking, numbness of hands, and weakness in general. Surgical procedures are available and performed when the CSM progresses to mild or severe symptoms.</p>
              <p id="c04-c04-para-0087" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0087">You're going to design a Bayesian Network with some given information and calculate the surgical outcome based on what you know. First, you walkthrough what you need to prepare and then transfer it to code.</p>
              <level4 id="level4_000016">
                <h4 xml:space="preserve" id="h4_000016" smilref="Machine_Learning00004.smil#h4_000016">Determining Nodes</h4>
                <p xml:space="preserve" id="p_000218" smilref="Machine_Learning00004.smil#p_000218">Every node needs to be created. This example requires a bit more involved version of a Bayesian Network that has a few more nodes than the explanation previously covered. For CSM we're going to look at the following nodes:</p>
                <list type="ul" id="list_000035">
                  <li id="li_000315" smilref="Machine_Learning00004.smil#li_000315">Age of patient (A)</li>
                  <li id="li_000316" smilref="Machine_Learning00004.smil#li_000316">Does the patient smoke? (S)</li>
                  <li id="li_000317" smilref="Machine_Learning00004.smil#li_000317">Duration of symptoms (D)</li>
                  <li id="li_000318" smilref="Machine_Learning00004.smil#li_000318">Surgical outcome success (SS)</li>
                </list>
                <p id="c04-c04-para-0089" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0089">This walkthrough keeps it simple; for the aim of this tutorial there are a range of other things that you could have measured and made nodes from; they would potentially give you a more refined network. For the present, this is a good starting point.</p>
              </level4>
              <level4 id="level4_000017">
                <h4 xml:space="preserve" id="h4_000017" smilref="Machine_Learning00004.smil#h4_000017">Assigning Probabilities</h4>
                <p xml:space="preserve" id="p_000219" smilref="Machine_Learning00004.smil#p_000219">You must assign all probabilities for all nodes including the probabilities in the parent nodes. If this sounds a little confusing, try rereading the Yard/Hose/Rain example earlier in the chapter.</p>
                <p id="c04-c04-para-0091" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0091">For each of the nodes, you have the following probabilities:</p>
                <figure id="figure_000023">
                  <table border="1" id="table_000010">
                    <tr id="tr_000037">
                      <td class="left" colspan="2" rowspan="1" id="td_000119" smilref="Machine_Learning00004.smil#td_000119">Age (A)</td>
                    </tr>
                    <tr id="tr_000038">
                      <td class="left" rowspan="1" colspan="1" id="td_000120">
                        <strong id="strong_000102" smilref="Machine_Learning00004.smil#strong_000102">&lt;55</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000121">
                        <strong id="strong_000103" smilref="Machine_Learning00004.smil#strong_000103">&gt;55</strong>
                      </td>
                    </tr>
                    <tr id="tr_000039">
                      <td class="left" rowspan="1" colspan="1" id="td_000122" smilref="Machine_Learning00004.smil#td_000122">0.8</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000123" smilref="Machine_Learning00004.smil#td_000123">0.2</td>
                    </tr>
                  </table>
                </figure>
                <figure id="figure_000024">
                  <table border="1" id="table_000011">
                    <tr id="tr_000040">
                      <td class="left" colspan="3" rowspan="1" id="td_000124" smilref="Machine_Learning00004.smil#td_000124">Smoker (S)</td>
                    </tr>
                    <tr id="tr_000041">
                      <td class="left" rowspan="1" colspan="1" id="td_000125">
                        <strong id="strong_000104" smilref="Machine_Learning00004.smil#strong_000104">Value of (A)</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000126">
                        <strong id="strong_000105" smilref="Machine_Learning00004.smil#strong_000105">Smokes</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000127">
                        <strong id="strong_000106" smilref="Machine_Learning00004.smil#strong_000106">Does Not Smoke</strong>
                      </td>
                    </tr>
                    <tr id="tr_000042">
                      <td class="left" rowspan="1" colspan="1" id="td_000128" smilref="Machine_Learning00004.smil#td_000128">&lt;55</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000129" smilref="Machine_Learning00004.smil#td_000129">0.4</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000130" smilref="Machine_Learning00004.smil#td_000130">0.6</td>
                    </tr>
                    <tr id="tr_000043">
                      <td class="left" rowspan="1" colspan="1" id="td_000131" smilref="Machine_Learning00004.smil#td_000131">&gt;55</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000132" smilref="Machine_Learning00004.smil#td_000132">0.8</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000133" smilref="Machine_Learning00004.smil#td_000133">0.2</td>
                    </tr>
                  </table>
                </figure>
                <figure id="figure_000025">
                  <table border="1" id="table_000012">
                    <tr id="tr_000044">
                      <td class="left" colspan="2" rowspan="1" id="td_000134" smilref="Machine_Learning00004.smil#td_000134">Duration of Symptoms (D)</td>
                    </tr>
                    <tr id="tr_000045">
                      <td class="left" rowspan="1" colspan="1" id="td_000135">
                        <strong id="strong_000107" smilref="Machine_Learning00004.smil#strong_000107">&lt; 2 Years</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000136">
                        <strong id="strong_000108" smilref="Machine_Learning00004.smil#strong_000108">&gt; 2 Years</strong>
                      </td>
                    </tr>
                    <tr id="tr_000046">
                      <td class="left" rowspan="1" colspan="1" id="td_000137" smilref="Machine_Learning00004.smil#td_000137">0.9</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000138" smilref="Machine_Learning00004.smil#td_000138">0.1</td>
                    </tr>
                  </table>
                </figure>
                <figure id="figure_000026">
                  <table border="1" id="table_000013">
                    <tr id="tr_000047">
                      <td class="left" colspan="4" rowspan="1" id="td_000139" smilref="Machine_Learning00004.smil#td_000139">Surgical Outcome Success (SS)</td>
                    </tr>
                    <tr id="tr_000048">
                      <td class="left" rowspan="1" colspan="1" id="td_000140">
                        <strong id="strong_000109" smilref="Machine_Learning00004.smil#strong_000109">(S)</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000141">
                        <strong id="strong_000110" smilref="Machine_Learning00004.smil#strong_000110">(D)</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000142">
                        <strong id="strong_000111" smilref="Machine_Learning00004.smil#strong_000111">Positive</strong>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000143">
                        <strong id="strong_000112" smilref="Machine_Learning00004.smil#strong_000112">Negative</strong>
                      </td>
                    </tr>
                    <tr id="tr_000049">
                      <td class="left" rowspan="1" colspan="1" id="td_000144" smilref="Machine_Learning00004.smil#td_000144">Smoker</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000145" smilref="Machine_Learning00004.smil#td_000145">&lt;2Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000146" smilref="Machine_Learning00004.smil#td_000146">0.1</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000147" smilref="Machine_Learning00004.smil#td_000147">0.9</td>
                    </tr>
                    <tr id="tr_000050">
                      <td class="left" rowspan="1" colspan="1" id="td_000148" smilref="Machine_Learning00004.smil#td_000148">Smoker</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000149" smilref="Machine_Learning00004.smil#td_000149">&gt;2Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000150" smilref="Machine_Learning00004.smil#td_000150">0.01</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000151" smilref="Machine_Learning00004.smil#td_000151">0.99</td>
                    </tr>
                    <tr id="tr_000051">
                      <td class="left" rowspan="1" colspan="1" id="td_000152" smilref="Machine_Learning00004.smil#td_000152">Non smoker</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000153" smilref="Machine_Learning00004.smil#td_000153">&lt;2Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000154" smilref="Machine_Learning00004.smil#td_000154">0.8</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000155" smilref="Machine_Learning00004.smil#td_000155">0.2</td>
                    </tr>
                    <tr id="tr_000052">
                      <td class="left" rowspan="1" colspan="1" id="td_000156" smilref="Machine_Learning00004.smil#td_000156">Non smoker</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000157" smilref="Machine_Learning00004.smil#td_000157">&gt;2Y</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000158" smilref="Machine_Learning00004.smil#td_000158">0.58</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000159" smilref="Machine_Learning00004.smil#td_000159">0.42</td>
                    </tr>
                  </table>
                </figure>
                <pagenum epub:type="pagebreak" id="p81" page="normal" smilref="Machine_Learning00004.smil#p81">81</pagenum>
                <p id="c04-c04-para-0095" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0095">The tables are similar to the ones earlier in the chapter: an exhaustive list of probabilities and conditional probabilities wherever they are required, which give the basis of the outcomes of the network when it's run.</p>
                <p id="c04-c04-para-0096" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0096">With this information from the expert you can now assign the probabilities in code.</p>
              </level4>
            </level3>
            <level3 id="level3_000085">
              <h3 xml:space="preserve" id="h3_000085" smilref="Machine_Learning00004.smil#h3_000085">Coding Up the Network</h3>
              <p xml:space="preserve" id="p_000220" smilref="Machine_Learning00004.smil#p_000220">You have down on paper (sort of) what you are looking to do. The next step is to create some code. You're going to work through a complete project from start to finish. I'm using Eclipse for this project, but you can easily substitute your own integrated development environment (IDE).</p>
              <level4 id="level4_000018">
                <h4 xml:space="preserve" id="h4_000018" smilref="Machine_Learning00004.smil#h4_000018">Creating the Project</h4>
                <p xml:space="preserve" id="p_000221"><span class="text" id="span_000332" smilref="Machine_Learning00004.smil#span_000332">First, create a clean project with which to work. Click File →New →Java Project. Call this project </span><code xml:space="preserve" id="code_000090" smilref="Machine_Learning00004.smil#code_000090">BayesNetDemo</code><span class="text" id="span_000333" smilref="Machine_Learning00004.smil#span_000333">, as shown in </span><a id="c04-c04-fig-anc-0005" href="#c04-c04-fig-0005" external="false" smilref="Machine_Learning00004.smil#c04-c04-fig-anc-0005">Figure 4-5</a><span class="text" id="span_000334" smilref="Machine_Learning00004.smil#span_000334">.</span></p>
                <figure id="figure_000027">
                  <img class="center" src="images/c04f005.jpg" alt="image" id="img_000035" />
                  <figcaption id="figcaption_000016">
                    <p xml:space="preserve" id="p_000222"><span class="figureLabel" id="span_000335"><a id="c04-c04-fig-0005" href="#c04-c04-fig-anc-0005" external="false"><strong id="strong_000113" smilref="Machine_Learning00004.smil#strong_000113">Figure 4-5</strong></a></span><span class="text" id="span_000336" smilref="Machine_Learning00004.smil#span_000336"> Creating a new project</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000019">
                <h4 xml:space="preserve" id="h4_000019" smilref="Machine_Learning00004.smil#h4_000019">Adding the JavaBayes Library</h4>
                <pagenum epub:type="pagebreak" id="p82" page="normal" smilref="Machine_Learning00004.smil#p82">82</pagenum>
                <p xml:space="preserve" id="p_000223"><span class="text" id="span_000337" smilref="Machine_Learning00004.smil#span_000337">You need the JavaBayes library to complete the demo, so if you haven't done so already, get the precompiled jar file from the Github repository at </span><a href="https://github.com/jasebell/JavaBayesAPI" external="true" id="a_000284" smilref="Machine_Learning00004.smil#a_000284">https://github.com/jasebell/JavaBayesAPI</a><span class="text" id="span_000338" smilref="Machine_Learning00004.smil#span_000338">.</span></p>
                <p id="c04-c04-para-0100" xml:space="preserve"><span class="text" id="span_000339" smilref="Machine_Learning00004.smil#span_000339">Create a new directory on your filesystem and via the command line type the following (see </span><a id="c04-c04-fig-anc-0006" href="#c04-c04-fig-0006" external="false" smilref="Machine_Learning00004.smil#c04-c04-fig-anc-0006">Figure 4-6</a><span class="text" id="span_000340" smilref="Machine_Learning00004.smil#span_000340">):</span></p>
                <p xml:space="preserve" id="p_000224"><code class="preserve-whitespace" xml:space="preserve" id="code_000091" smilref="Machine_Learning00004.smil#code_000091">git clone https://github.com/jasebell/JavaBayesAPI</code></p>
                <figure id="figure_000028">
                  <img class="center" src="images/c04f006.jpg" alt="image" id="img_000036" />
                  <figcaption id="figcaption_000017">
                    <p xml:space="preserve" id="p_000225"><span class="figureLabel" id="span_000341"><a id="c04-c04-fig-0006" href="#c04-c04-fig-anc-0006" external="false"><strong id="strong_000114" smilref="Machine_Learning00004.smil#strong_000114">Figure 4-6</strong></a></span> <pagenum epub:type="pagebreak" id="p83" page="normal" smilref="Machine_Learning00004.smil#p83">83</pagenum><span class="text" id="span_000342" smilref="Machine_Learning00004.smil#span_000342">Cloning the Git repository</span></p>
                  </figcaption>
                </figure>
                <p id="c04-c04-para-0101" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0101">Back in your IDE, you need to add the jar file to your build properties so your code can see the library. In Eclipse you do this by clicking the name of the project in the project chooser window. Right-click and you see the Properties option.</p>
                <p id="c04-c04-para-0102" xml:space="preserve"><span class="text" id="span_000343" smilref="Machine_Learning00004.smil#span_000343">Click Java Build Path and then click Add External JARs, as shown in </span><a id="c04-c04-fig-anc-0007" href="#c04-c04-fig-0007" external="false" smilref="Machine_Learning00004.smil#c04-c04-fig-anc-0007">Figure 4-7</a><span class="text" id="span_000344" smilref="Machine_Learning00004.smil#span_000344">. Find the file location of the jar file and click Open.</span></p>
                <figure id="figure_000029">
                  <img class="center" src="images/c04f007.jpg" alt="image" id="img_000037" />
                  <figcaption id="figcaption_000018">
                    <p xml:space="preserve" id="p_000226"><span class="figureLabel" id="span_000345"><a id="c04-c04-fig-0007" href="#c04-c04-fig-anc-0007" external="false"><strong id="strong_000115" smilref="Machine_Learning00004.smil#strong_000115">Figure 4-7</strong></a></span><span class="text" id="span_000346" smilref="Machine_Learning00004.smil#span_000346"> Project properties</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000020">
                <h4 xml:space="preserve" id="h4_000020" smilref="Machine_Learning00004.smil#h4_000020">Creating the Base Graph</h4>
                <pagenum epub:type="pagebreak" id="p84" page="normal" smilref="Machine_Learning00004.smil#p84">84</pagenum>
                <p xml:space="preserve" id="p_000227"><span class="text" id="span_000347" smilref="Machine_Learning00004.smil#span_000347">With the library added, you can start to put some code in place. Create a new Java class called </span><code xml:space="preserve" id="code_000092" smilref="Machine_Learning00004.smil#code_000092">BayesNetExample.java</code><span class="text" id="span_000348" smilref="Machine_Learning00004.smil#span_000348">. In Eclipse, select File →New →Class, as shown in </span><a id="c04-c04-fig-anc-0008" href="#c04-c04-fig-0008" external="false" smilref="Machine_Learning00004.smil#c04-c04-fig-anc-0008">Figure 4-8</a><span class="text" id="span_000349" smilref="Machine_Learning00004.smil#span_000349">. Make sure you have a main method to run the code as well.</span></p>
                <figure id="figure_000030">
                  <img class="center" src="images/c04f008.jpg" alt="image" id="img_000038" />
                  <figcaption id="figcaption_000019">
                    <p xml:space="preserve" id="p_000228"><span class="figureLabel" id="span_000350"><a id="c04-c04-fig-0008" href="#c04-c04-fig-anc-0008" external="false"><strong id="strong_000116" smilref="Machine_Learning00004.smil#strong_000116">Figure 4-8</strong></a></span><span class="text" id="span_000351" smilref="Machine_Learning00004.smil#span_000351"> Creating a new class</span></p>
                  </figcaption>
                </figure>
                <p id="c04-c04-para-0104" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0104">Create the constructor and add an InferenceGraph class. This is your graph network; you'll use this class to do the belief calculations at the end.</p>
                <p xml:space="preserve" id="p_000229"><code class="preserve-whitespace" xml:space="preserve" id="code_000093"><strong id="strong_000117" smilref="Machine_Learning00004.smil#strong_000117">import</strong><span class="text" id="span_000352" smilref="Machine_Learning00004.smil#span_000352"> javabayes.Helpers.BayesNetHelper;
</span><strong id="strong_000118" smilref="Machine_Learning00004.smil#strong_000118">import</strong><span class="text" id="span_000353" smilref="Machine_Learning00004.smil#span_000353"> javabayes.InferenceGraphs.InferenceGraph;
</span><strong id="strong_000119" smilref="Machine_Learning00004.smil#strong_000119">import</strong><span class="text" id="span_000354" smilref="Machine_Learning00004.smil#span_000354"> javabayes.InferenceGraphs.InferenceGraphNode;
</span><strong id="strong_000120" smilref="Machine_Learning00004.smil#strong_000120">public class</strong><span class="text" id="span_000355" smilref="Machine_Learning00004.smil#span_000355"> BayesNetExample {
    </span><strong id="strong_000121" smilref="Machine_Learning00004.smil#strong_000121">public</strong><span class="text" id="span_000356" smilref="Machine_Learning00004.smil#span_000356"> BayesNetExample() {
        InferenceGraph inferenceGraph = </span><strong id="strong_000122" smilref="Machine_Learning00004.smil#strong_000122">new</strong><span class="text" id="span_000357" smilref="Machine_Learning00004.smil#span_000357"> InferenceGraph();
    }
    </span><strong id="strong_000123" smilref="Machine_Learning00004.smil#strong_000123">public static void</strong><span class="text" id="span_000358" smilref="Machine_Learning00004.smil#span_000358"> main(String[] args) {
        BayesNetExample bne = </span><strong id="strong_000124" smilref="Machine_Learning00004.smil#strong_000124">new</strong><span class="text" id="span_000359" smilref="Machine_Learning00004.smil#span_000359"> BayesNetExample();
    }
}</span></code></p>
                <p id="c04-c04-para-0105" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0105">I've added the line in the main method to ensure that the program runs.</p>
              </level4>
              <level4 id="level4_000021">
                <h4 xml:space="preserve" id="h4_000021" smilref="Machine_Learning00004.smil#h4_000021">Adding the Nodes</h4>
                <pagenum epub:type="pagebreak" id="p85" page="normal" smilref="Machine_Learning00004.smil#p85">85</pagenum>
                <p xml:space="preserve" id="p_000230" smilref="Machine_Learning00004.smil#p_000230">You have four nodes: the age of the patient, the patient's smoking status, the duration of the condition, and the surgical outcome. What's required code-wise is the creation of each node connected to the graph. First, here is a Java code representation of the age node:</p>
                <p xml:space="preserve" id="p_000231"><code class="preserve-whitespace" xml:space="preserve" id="code_000094" smilref="Machine_Learning00004.smil#code_000094">InferenceGraphNode age = BayesNetHelper.createNode(inferenceGraph,"under55", "&lt;55", "&gt;55");</code></p>
                <p id="c04-c04-para-0107" xml:space="preserve"><span class="text" id="span_000360" smilref="Machine_Learning00004.smil#span_000360">The </span><code xml:space="preserve" id="code_000095" smilref="Machine_Learning00004.smil#code_000095">InferenceGraphNode</code><span class="text" id="span_000361" smilref="Machine_Learning00004.smil#span_000361"> assigns the node to the graph class you created; you also give it a name </span><code xml:space="preserve" id="code_000096" smilref="Machine_Learning00004.smil#code_000096">“under55”</code><span class="text" id="span_000362" smilref="Machine_Learning00004.smil#span_000362"> and then the names of the two outcomes, </span><code xml:space="preserve" id="code_000097" smilref="Machine_Learning00004.smil#code_000097">“&lt;55”</code><span class="text" id="span_000363" smilref="Machine_Learning00004.smil#span_000363"> and </span><code xml:space="preserve" id="code_000098" smilref="Machine_Learning00004.smil#code_000098">“&gt;55”</code><span class="text" id="span_000364" smilref="Machine_Learning00004.smil#span_000364">. These are the true/false states of the node. You'll assign values to these shortly. To create the nodes you're using a helper class called </span><code xml:space="preserve" id="code_000099" smilref="Machine_Learning00004.smil#code_000099">BayesnNetHelper</code><span class="text" id="span_000365" smilref="Machine_Learning00004.smil#span_000365">, which has a </span><code xml:space="preserve" id="code_000100" smilref="Machine_Learning00004.smil#code_000100">createNode()</code><span class="text" id="span_000366" smilref="Machine_Learning00004.smil#span_000366"> method that does the work for you.</span></p>
                <p id="c04-c04-para-0108" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0108">One node down, three to go; here is the Java code to represent the other three nodes:</p>
                <p xml:space="preserve" id="p_000232"><code class="preserve-whitespace" xml:space="preserve" id="code_000101" smilref="Machine_Learning00004.smil#code_000101">InferenceGraphNode smoker = BayesNetHelper.createNode(inferenceGraph, "smoker", "smokes", "doesnotsmoke");
InferenceGraphNode duration = BayesNetHelper.createNode(inferenceGraph, "duration", "&lt;2Y", "&gt;2Y");
InferenceGraphNode surgical = BayesNetHelper.createNode(inferenceGraph, "surgicalOutcome", "positive", "negative");</code></p>
                <p id="c04-c04-para-0109" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0109">Right now the nodes don't know each other; there are no edges set to connect the nodes together. That's covered in the next section.</p>
              </level4>
              <level4 id="level4_000022">
                <h4 xml:space="preserve" id="h4_000022" smilref="Machine_Learning00004.smil#h4_000022">Connecting the Nodes</h4>
                <p xml:space="preserve" id="p_000233" smilref="Machine_Learning00004.smil#p_000233">Now that you have nodes, you can connect them. Remember from the yard example earlier in this chapter that certain nodes were parents of others. For this CSM model, the age node is the parent of the smoker node, which in turn is the parent of the surgical outcome node. Also, the duration node is the parent of the surgical outcome node.</p>
                <p id="c04-c04-para-0111" xml:space="preserve"><span class="text" id="span_000367" smilref="Machine_Learning00004.smil#span_000367">In the code, you connect the nodes (called arcs in the syntax of the Java code, but still graph edges to me) with the </span><code xml:space="preserve" id="code_000102" smilref="Machine_Learning00004.smil#code_000102">create_arc()</code><span class="text" id="span_000368" smilref="Machine_Learning00004.smil#span_000368"> function. It takes the following syntax.</span></p>
                <p xml:space="preserve" id="p_000234"><code class="preserve-whitespace" xml:space="preserve" id="code_000103" smilref="Machine_Learning00004.smil#code_000103">graph.create_arc(parent_node, child_node);</code></p>
                <p id="c04-c04-para-0112" xml:space="preserve"><span class="text" id="span_000369" smilref="Machine_Learning00004.smil#span_000369">The following are your newly created </span><code xml:space="preserve" id="code_000104" smilref="Machine_Learning00004.smil#code_000104">InferenceGraphNodes</code><span class="text" id="span_000370" smilref="Machine_Learning00004.smil#span_000370">; you can now create the arcs that connect them.</span></p>
                <p xml:space="preserve" id="p_000235"><code class="preserve-whitespace" xml:space="preserve" id="code_000105" smilref="Machine_Learning00004.smil#code_000105">inferenceGraph.create_arc(age, smoker);
inferenceGraph.create_arc(smoker, surgical);
inferenceGraph.create_arc(duration, surgical); </code></p>
                <pagenum epub:type="pagebreak" id="p86" page="normal" smilref="Machine_Learning00004.smil#p86">86</pagenum>
                <p id="c04-c04-para-0113" xml:space="preserve"><span class="text" id="span_000371" smilref="Machine_Learning00004.smil#span_000371">If you were to draw the graph, you'd have something along the lines of what's shown in </span><a id="c04-c04-fig-anc-0009" href="#c04-c04-fig-0009" external="false" smilref="Machine_Learning00004.smil#c04-c04-fig-anc-0009">Figure 4-9</a><span class="text" id="span_000372" smilref="Machine_Learning00004.smil#span_000372">.</span></p>
                <figure id="figure_000031">
                  <img class="center" src="images/c04f009.jpg" alt="image" id="img_000039" />
                  <figcaption id="figcaption_000020">
                    <p xml:space="preserve" id="p_000236"><span class="figureLabel" id="span_000373"><a id="c04-c04-fig-0009" href="#c04-c04-fig-anc-0009" external="false"><strong id="strong_000125" smilref="Machine_Learning00004.smil#strong_000125">Figure 4-9</strong></a></span><span class="text" id="span_000374" smilref="Machine_Learning00004.smil#span_000374"> The CSM graph</span></p>
                  </figcaption>
                </figure>
                <p id="c04-c04-para-0114" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0114">With the nodes connected, it's time to turn your attention to the probabilities.</p>
              </level4>
              <level4 id="level4_000023">
                <h4 xml:space="preserve" id="h4_000023" smilref="Machine_Learning00004.smil#h4_000023">Assigning Probabilities</h4>
                <p xml:space="preserve" id="p_000237"><span class="text" id="span_000375" smilref="Machine_Learning00004.smil#span_000375">The </span><code xml:space="preserve" id="code_000106" smilref="Machine_Learning00004.smil#code_000106">BayesNetHelper</code><span class="text" id="span_000376" smilref="Machine_Learning00004.smil#span_000376"> class enables you to set the probability values while taking away the complexity. Start with the conditional probabilities. The smoker node is conditional with the age of the patient. In pseudocode, it would look like this:</span></p>
                <p xml:space="preserve" id="p_000238"><em id="em_000052" smilref="Machine_Learning00004.smil#em_000052">if age</em><span class="text" id="span_000377" smilref="Machine_Learning00004.smil#span_000377"> &lt; </span><em id="em_000053" smilref="Machine_Learning00004.smil#em_000053">55 then smoker</em><span class="text" id="span_000378" smilref="Machine_Learning00004.smil#span_000378">(</span><em id="em_000054" smilref="Machine_Learning00004.smil#em_000054">smokes</em><span class="text" id="span_000379" smilref="Machine_Learning00004.smil#span_000379">) = </span><em id="em_000055" smilref="Machine_Learning00004.smil#em_000055">0</em><span class="text" id="span_000380" smilref="Machine_Learning00004.smil#span_000380">.</span><em id="em_000056" smilref="Machine_Learning00004.smil#em_000056">4</em><span class="text" id="span_000381" smilref="Machine_Learning00004.smil#span_000381">, </span><em id="em_000057" smilref="Machine_Learning00004.smil#em_000057">smoker</em><span class="text" id="span_000382" smilref="Machine_Learning00004.smil#span_000382">(</span><em id="em_000058" smilref="Machine_Learning00004.smil#em_000058">doesnotsmoke</em><span class="text" id="span_000383" smilref="Machine_Learning00004.smil#span_000383">) = </span><em id="em_000059" smilref="Machine_Learning00004.smil#em_000059">0</em><span class="text" id="span_000384" smilref="Machine_Learning00004.smil#span_000384">.</span><em id="em_000060" smilref="Machine_Learning00004.smil#em_000060">6if age</em><span class="text" id="span_000385" smilref="Machine_Learning00004.smil#span_000385"> &gt; </span><em id="em_000061" smilref="Machine_Learning00004.smil#em_000061">55 then smoker</em><span class="text" id="span_000386" smilref="Machine_Learning00004.smil#span_000386">(</span><em id="em_000062" smilref="Machine_Learning00004.smil#em_000062">smokes</em><span class="text" id="span_000387" smilref="Machine_Learning00004.smil#span_000387">) = </span><em id="em_000063" smilref="Machine_Learning00004.smil#em_000063">0</em><span class="text" id="span_000388" smilref="Machine_Learning00004.smil#span_000388">.</span><em id="em_000064" smilref="Machine_Learning00004.smil#em_000064">8</em><span class="text" id="span_000389" smilref="Machine_Learning00004.smil#span_000389">, </span><em id="em_000065" smilref="Machine_Learning00004.smil#em_000065">smoker</em><span class="text" id="span_000390" smilref="Machine_Learning00004.smil#span_000390">(</span><em id="em_000066" smilref="Machine_Learning00004.smil#em_000066">doesnotsmoke</em><span class="text" id="span_000391" smilref="Machine_Learning00004.smil#span_000391">) = </span><em id="em_000067" smilref="Machine_Learning00004.smil#em_000067">0</em><span class="text" id="span_000392" smilref="Machine_Learning00004.smil#span_000392">.</span><em id="em_000068" smilref="Machine_Learning00004.smil#em_000068">2</em></p>
                <p id="c04-c04-para-0118" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0118">In the Java class, you add the values with the helper class:</p>
                <p xml:space="preserve" id="p_000239"><code class="preserve-whitespace" xml:space="preserve" id="code_000107" smilref="Machine_Learning00004.smil#code_000107">BayesNetHelper.setProbabilityValues(smoker, "&lt;55", 0.4, 0.6);
BayesNetHelper.setProbabilityValues(smoker, "&gt;55", 0.8, 0.2);</code></p>
                <p id="c04-c04-para-0119" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0119">Next you set the probability values for the surgical outcome node; this one has two conditional probabilities connected to it, so you have to look at all the possible conditions and assign the probabilities accordingly:</p>
                <p xml:space="preserve" id="p_000240"><em id="em_000069" smilref="Machine_Learning00004.smil#em_000069">if smokes and duration</em><span class="text" id="span_000393" smilref="Machine_Learning00004.smil#span_000393"> &lt; </span><em id="em_000070" smilref="Machine_Learning00004.smil#em_000070">2Y then surgical</em><span class="text" id="span_000394" smilref="Machine_Learning00004.smil#span_000394">(</span><em id="em_000071" smilref="Machine_Learning00004.smil#em_000071">positive</em><span class="text" id="span_000395" smilref="Machine_Learning00004.smil#span_000395">) = </span><em id="em_000072" smilref="Machine_Learning00004.smil#em_000072">0</em><span class="text" id="span_000396" smilref="Machine_Learning00004.smil#span_000396">.</span><em id="em_000073" smilref="Machine_Learning00004.smil#em_000073">1</em><span class="text" id="span_000397" smilref="Machine_Learning00004.smil#span_000397">, </span><em id="em_000074" smilref="Machine_Learning00004.smil#em_000074">surgical</em><span class="text" id="span_000398" smilref="Machine_Learning00004.smil#span_000398">(</span><em id="em_000075" smilref="Machine_Learning00004.smil#em_000075">negative</em><span class="text" id="span_000399" smilref="Machine_Learning00004.smil#span_000399">) = </span><em id="em_000076" smilref="Machine_Learning00004.smil#em_000076">0</em><span class="text" id="span_000400" smilref="Machine_Learning00004.smil#span_000400">.</span><em id="em_000077" smilref="Machine_Learning00004.smil#em_000077">9if smokes and duration</em><span class="text" id="span_000401" smilref="Machine_Learning00004.smil#span_000401"> &gt; </span><em id="em_000078" smilref="Machine_Learning00004.smil#em_000078">2Y then surgical</em><span class="text" id="span_000402" smilref="Machine_Learning00004.smil#span_000402">(</span><em id="em_000079" smilref="Machine_Learning00004.smil#em_000079">positive</em><span class="text" id="span_000403" smilref="Machine_Learning00004.smil#span_000403">) = </span><em id="em_000080" smilref="Machine_Learning00004.smil#em_000080">0</em><span class="text" id="span_000404" smilref="Machine_Learning00004.smil#span_000404">.</span><em id="em_000081" smilref="Machine_Learning00004.smil#em_000081">01</em><span class="text" id="span_000405" smilref="Machine_Learning00004.smil#span_000405">, </span><em id="em_000082" smilref="Machine_Learning00004.smil#em_000082">surgical</em><span class="text" id="span_000406" smilref="Machine_Learning00004.smil#span_000406">(</span><em id="em_000083" smilref="Machine_Learning00004.smil#em_000083">negative</em><span class="text" id="span_000407" smilref="Machine_Learning00004.smil#span_000407">) = </span><em id="em_000084" smilref="Machine_Learning00004.smil#em_000084">0</em><span class="text" id="span_000408" smilref="Machine_Learning00004.smil#span_000408">.</span><em id="em_000085" smilref="Machine_Learning00004.smil#em_000085">99if does not smoke and duration</em><span class="text" id="span_000409" smilref="Machine_Learning00004.smil#span_000409"> &lt; </span><em id="em_000086" smilref="Machine_Learning00004.smil#em_000086">2Y then surgical</em><span class="text" id="span_000410" smilref="Machine_Learning00004.smil#span_000410">(</span><em id="em_000087" smilref="Machine_Learning00004.smil#em_000087">positive</em><span class="text" id="span_000411" smilref="Machine_Learning00004.smil#span_000411">) = </span><em id="em_000088" smilref="Machine_Learning00004.smil#em_000088">0</em><span class="text" id="span_000412" smilref="Machine_Learning00004.smil#span_000412">.</span><em id="em_000089" smilref="Machine_Learning00004.smil#em_000089">8</em><span class="text" id="span_000413" smilref="Machine_Learning00004.smil#span_000413">, </span><em id="em_000090" smilref="Machine_Learning00004.smil#em_000090">surgical</em><span class="text" id="span_000414" smilref="Machine_Learning00004.smil#span_000414">(</span><em id="em_000091" smilref="Machine_Learning00004.smil#em_000091">negative</em><span class="text" id="span_000415" smilref="Machine_Learning00004.smil#span_000415">) = </span><em id="em_000092" smilref="Machine_Learning00004.smil#em_000092">0</em><span class="text" id="span_000416" smilref="Machine_Learning00004.smil#span_000416">.</span><em id="em_000093" smilref="Machine_Learning00004.smil#em_000093">2if does not smoke and duration</em><span class="text" id="span_000417" smilref="Machine_Learning00004.smil#span_000417"> &gt; </span><em id="em_000094" smilref="Machine_Learning00004.smil#em_000094">2Y then surgical</em><span class="text" id="span_000418" smilref="Machine_Learning00004.smil#span_000418">(</span><em id="em_000095" smilref="Machine_Learning00004.smil#em_000095">positive</em><span class="text" id="span_000419" smilref="Machine_Learning00004.smil#span_000419">) = </span><em id="em_000096" smilref="Machine_Learning00004.smil#em_000096">0</em><span class="text" id="span_000420" smilref="Machine_Learning00004.smil#span_000420">.</span><em id="em_000097" smilref="Machine_Learning00004.smil#em_000097">58</em><span class="text" id="span_000421" smilref="Machine_Learning00004.smil#span_000421">, </span><em id="em_000098" smilref="Machine_Learning00004.smil#em_000098">surgical</em><span class="text" id="span_000422" smilref="Machine_Learning00004.smil#span_000422">(</span><em id="em_000099" smilref="Machine_Learning00004.smil#em_000099">negative</em><span class="text" id="span_000423" smilref="Machine_Learning00004.smil#span_000423">) = </span><em id="em_000100" smilref="Machine_Learning00004.smil#em_000100">0</em><span class="text" id="span_000424" smilref="Machine_Learning00004.smil#span_000424">.</span><em id="em_000101" smilref="Machine_Learning00004.smil#em_000101">42</em></p>
                <pagenum epub:type="pagebreak" id="p87" page="normal" smilref="Machine_Learning00004.smil#p87">87</pagenum>
                <p id="c04-c04-para-0124" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0124">In the code, you again add the probabilities with the helper class. Notice this time you use parent and the secondary parent conditions.</p>
                <p xml:space="preserve" id="p_000241"><code class="preserve-whitespace" xml:space="preserve" id="code_000108" smilref="Machine_Learning00004.smil#code_000108">BayesNetHelper.setProbabilityValues(surgical, "smokes", "&lt;2Y", 0.1, 0.9);
BayesNetHelper.setProbabilityValues(surgical, "smokes", "&gt;2Y", 0.01, 0.99);
BayesNetHelper.setProbabilityValues(surgical, "doesnotsmoke", "&lt;2Y",0.8 , 0.2);
BayesNetHelper.setProbabilityValues(surgical, "doesnotsmoke", "&gt;2Y", 0.58, 0.42);</code></p>
                <p id="c04-c04-para-0125" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0125">The last two nodes are called leaf nodes because they don't have any parents connected to them. All you have to do with these is add the true/false values via the helper. You set one for the duration node and another for the age node.</p>
                <p xml:space="preserve" id="p_000242"><code class="preserve-whitespace" xml:space="preserve" id="code_000109" smilref="Machine_Learning00004.smil#code_000109">BayesNetHelper.setProbabilityValues(duration, 0.9, 0.1);
BayesNetHelper.setProbabilityValues(age, 0.8, 0.2);</code></p>
                <p id="c04-c04-para-0126" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0126">With nodes created, edges defined, and probabilities set, you can now start getting some results from the code. Make sure you have saved your work before running it.</p>
              </level4>
              <level4 id="level4_000024">
                <h4 xml:space="preserve" id="h4_000024" smilref="Machine_Learning00004.smil#h4_000024">Testing the Belief Network</h4>
                <p xml:space="preserve" id="p_000243"><span class="text" id="span_000425" smilref="Machine_Learning00004.smil#span_000425">To get the percentage belief of the network, you have to use the helper class again. It has a method called </span><code xml:space="preserve" id="code_000110" smilref="Machine_Learning00004.smil#code_000110">getBelief()</code><span class="text" id="span_000426" smilref="Machine_Learning00004.smil#span_000426"> and it takes the graph and the node for which you want to get the belief value. First off, look at the predicted probability of a surgery's success when you have no other conditions assigned to it:</span></p>
                <p xml:space="preserve" id="p_000244"><code class="preserve-whitespace" xml:space="preserve" id="code_000111"><strong id="strong_000126" smilref="Machine_Learning00004.smil#strong_000126">double</strong><span class="text" id="span_000427" smilref="Machine_Learning00004.smil#span_000427"> belief = BayesNetHelper.</span><em id="em_000102" smilref="Machine_Learning00004.smil#em_000102">getBelief</em><span class="text" id="span_000428" smilref="Machine_Learning00004.smil#span_000428">(inferenceGraph, surgical);
System.</span><em id="em_000103" smilref="Machine_Learning00004.smil#em_000103">out</em><span class="text" id="span_000429" smilref="Machine_Learning00004.smil#span_000429">.println("The probability of surgery being positive: " + belief);</span></code></p>
                <p id="c04-c04-para-0128" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0128">You will see the output in the console window:</p>
                <p xml:space="preserve" id="p_000245"><code class="preserve-whitespace" xml:space="preserve" id="code_000112" smilref="Machine_Learning00004.smil#code_000112">The probability of surgery being positive: 0.44823999999999997</code></p>
                <p id="c04-c04-para-0129" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0129">The model's predicted probability of a surgery's being successful is 44.8 percent; remember this calculation is made without any other conditions. When you know more information about the patient, you'll run the program again and see how the model's predicted probability for a successful surgery changes for the patient. Remember that the model is based on the predicted probabilities based on the expert's recommendation. There's no assurance that the surgery is going to be successful; only the model's predicted result. The more times the surgery is performed should validate the model's accuracy in the long term.</p>
              </level4>
              <level4 id="level4_000025">
                <h4 xml:space="preserve" id="h4_000025" smilref="Machine_Learning00004.smil#h4_000025">Testing the Belief Network with a Condition</h4>
                <pagenum epub:type="pagebreak" id="p88" page="normal" smilref="Machine_Learning00004.smil#p88">88</pagenum>
                <p xml:space="preserve" id="p_000246" smilref="Machine_Learning00004.smil#p_000246">You now have some information about the patient so you can add this information to the program and see how the chances for a successful surgery look.</p>
                <p id="c04-c04-para-0131" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0131">The age of the patient is less than 55. You can set the observation within the age node itself and then run the belief calculation again.</p>
                <p xml:space="preserve" id="p_000247"><code class="preserve-whitespace" xml:space="preserve" id="code_000113"><span class="text" id="span_000430" smilref="Machine_Learning00004.smil#span_000430">age.set_observation_value("&lt;55");
belief = BayesNetHelper.</span><em id="em_000104" smilref="Machine_Learning00004.smil#em_000104">getBelief</em><span class="text" id="span_000431" smilref="Machine_Learning00004.smil#span_000431">(inferenceGraph, surgical);
System.</span><em id="em_000105" smilref="Machine_Learning00004.smil#em_000105">out</em><span class="text" id="span_000432" smilref="Machine_Learning00004.smil#span_000432">.println("The probability of surgery being positive and patient is younger than 55: " + belief);</span></code></p>
                <p id="c04-c04-para-0132" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0132">Run the program again and the model's prediction of the patient's chances improves.</p>
                <p xml:space="preserve" id="p_000248"><code class="preserve-whitespace" xml:space="preserve" id="code_000114" smilref="Machine_Learning00004.smil#code_000114">The probability of surgery being positive and patient is younger than 55 : 0.5032</code></p>
                <p id="c04-c04-para-0133" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0133">If the patient smokes, it would have an impact on the result from the model. Adding another observation to the node you now have the following to compute:</p>
                <p xml:space="preserve" id="p_000249"><code class="preserve-whitespace" xml:space="preserve" id="code_000115"><span class="text" id="span_000433" smilref="Machine_Learning00004.smil#span_000433">smoker.set_observation_value("smokes");
belief = BayesNetHelper.</span><em id="em_000106" smilref="Machine_Learning00004.smil#em_000106">getBelief</em><span class="text" id="span_000434" smilref="Machine_Learning00004.smil#span_000434">(inferenceGraph, surgical);
System.</span><em id="em_000107" smilref="Machine_Learning00004.smil#em_000107">out</em><span class="text" id="span_000435" smilref="Machine_Learning00004.smil#span_000435">.println("The probability of surgery being positive for a smoker, younger than 55: " + belief);</span></code></p>
                <p id="c04-c04-para-0134" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0134">Adding this last datum changes things drastically for the patient! While being younger than 55 is a good indicator for successful surgery, the fact he or she smokes causes the predicted probability from the network to decrease drastically.</p>
                <p xml:space="preserve" id="p_000250"><code class="preserve-whitespace" xml:space="preserve" id="code_000116" smilref="Machine_Learning00004.smil#code_000116">The probability of surgery being positive for a smoker, younger than 55: 0.09100000000000001</code></p>
                <p id="c04-c04-para-0135" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0135">The experts know that because of the location of the issue—the neck—surgery will affect the throat area, so there's a high probability the surgery will fail; many patients who desire surgery are refused on that basis alone.</p>
                <p id="c04-c04-para-0136" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0136">Lastly add the duration the patient has had the symptoms. In this patient's case it's been more than two years.</p>
                <p xml:space="preserve" id="p_000251"><code class="preserve-whitespace" xml:space="preserve" id="code_000117"><span class="text" id="span_000436" smilref="Machine_Learning00004.smil#span_000436">duration.set_observation_value("&gt;2Y");
belief = BayesNetHelper.</span><em id="em_000108" smilref="Machine_Learning00004.smil#em_000108">getBelief</em><span class="text" id="span_000437" smilref="Machine_Learning00004.smil#span_000437">(inferenceGraph, surgical);
System.</span><em id="em_000109" smilref="Machine_Learning00004.smil#em_000109">out</em><span class="text" id="span_000438" smilref="Machine_Learning00004.smil#span_000438">.println("The probability of surgery being positive for a smoker, younger than 55 with symptoms over 2 years: " + belief);</span></code></p>
                <p id="c04-c04-para-0137" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0137">Once again this decreases the chance of successful surgery.</p>
                <p xml:space="preserve" id="p_000252"><code class="preserve-whitespace" xml:space="preserve" id="code_000118" smilref="Machine_Learning00004.smil#code_000118">The probability of surgery being positive for a smoker, younger than 55 with symptoms for over 2 years: 0.01</code></p>
                <pagenum epub:type="pagebreak" id="p89" page="normal" smilref="Machine_Learning00004.smil#p89">89</pagenum>
                <p id="c04-c04-para-0138" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0138">You've created a Bayesian Network to calculate the probability of successful surgery of CSM. With the conditional parameters, you see that the probability varies enormously, especially when the age and smoking factors are taken into account.</p>
                <p id="c04-c04-para-0139" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0139">The following is the full code listing for the Bayes Network class created in this chapter.</p>
                <p class="codeTitle" xml:space="preserve" id="p_000253" smilref="Machine_Learning00004.smil#p_000253">Listing 4-1: Bayes Network class</p>
                <p xml:space="preserve" id="p_000254"><code class="preserve-whitespace" xml:space="preserve" id="code_000119"><strong id="strong_000127" smilref="Machine_Learning00004.smil#strong_000127">import</strong><span class="text" id="span_000439" smilref="Machine_Learning00004.smil#span_000439"> javabayes.Helpers.BayesNetHelper;
</span><strong id="strong_000128" smilref="Machine_Learning00004.smil#strong_000128">import</strong><span class="text" id="span_000440" smilref="Machine_Learning00004.smil#span_000440"> javabayes.InferenceGraphs.InferenceGraph;
</span><strong id="strong_000129" smilref="Machine_Learning00004.smil#strong_000129">import</strong><span class="text" id="span_000441" smilref="Machine_Learning00004.smil#span_000441"> javabayes.InferenceGraphs.InferenceGraphNode;
</span><strong id="strong_000130" smilref="Machine_Learning00004.smil#strong_000130">public class</strong><span class="text" id="span_000442" smilref="Machine_Learning00004.smil#span_000442"> BayesNetExample {
    </span><strong id="strong_000131" smilref="Machine_Learning00004.smil#strong_000131">public</strong><span class="text" id="span_000443" smilref="Machine_Learning00004.smil#span_000443"> BayesNetExample() {
        InferenceGraph inferenceGraph = </span><strong id="strong_000132" smilref="Machine_Learning00004.smil#strong_000132">new</strong><span class="text" id="span_000444" smilref="Machine_Learning00004.smil#span_000444"> InferenceGraph();
        InferenceGraphNode age = BayesNetHelper.</span><em id="em_000110" smilref="Machine_Learning00004.smil#em_000110">createNode</em><span class="text" id="span_000445" smilref="Machine_Learning00004.smil#span_000445">(inferenceGraph,"under55", "&lt;55", "&gt;55");
        InferenceGraphNode smoker = BayesNetHelper.</span><em id="em_000111" smilref="Machine_Learning00004.smil#em_000111">createNode</em><span class="text" id="span_000446" smilref="Machine_Learning00004.smil#span_000446">(inferenceGraph, "smoker", "smokes", "doesnotsmoke");
        InferenceGraphNode duration = BayesNetHelper.</span><em id="em_000112" smilref="Machine_Learning00004.smil#em_000112">createNode</em><span class="text" id="span_000447" smilref="Machine_Learning00004.smil#span_000447">(inferenceGraph, "duration", "&lt;2Y", "&gt;2Y");
        InferenceGraphNode surgical = BayesNetHelper.</span><em id="em_000113" smilref="Machine_Learning00004.smil#em_000113">createNode</em><span class="text" id="span_000448" smilref="Machine_Learning00004.smil#span_000448">(inferenceGraph, "surgicalOutcome", "positive", "negative");
        inferenceGraph.create_arc(age, smoker);
        inferenceGraph.create_arc(smoker, surgical);
        inferenceGraph.create_arc(duration, surgical);
        BayesNetHelper.</span><em id="em_000114" smilref="Machine_Learning00004.smil#em_000114">setProbabilityValues</em><span class="text" id="span_000449" smilref="Machine_Learning00004.smil#span_000449">(smoker, "&lt;55", 0.4, 0.6);
        BayesNetHelper.</span><em id="em_000115" smilref="Machine_Learning00004.smil#em_000115">setProbabilityValues</em><span class="text" id="span_000450" smilref="Machine_Learning00004.smil#span_000450">(smoker, "&gt;55", 0.8, 0.2);
        BayesNetHelper.</span><em id="em_000116" smilref="Machine_Learning00004.smil#em_000116">setProbabilityValues</em><span class="text" id="span_000451" smilref="Machine_Learning00004.smil#span_000451">(surgical, "smokes", "&lt;2Y", 0.1, 0.9);
        BayesNetHelper.</span><em id="em_000117" smilref="Machine_Learning00004.smil#em_000117">setProbabilityValues</em><span class="text" id="span_000452" smilref="Machine_Learning00004.smil#span_000452">(surgical, "smokes", "&gt;2Y", 0.01, 0.99);
        BayesNetHelper.</span><em id="em_000118" smilref="Machine_Learning00004.smil#em_000118">setProbabilityValues</em><span class="text" id="span_000453" smilref="Machine_Learning00004.smil#span_000453">(surgical, "doesnotsmoke", "&lt;2Y",0.8, 0.2);
        BayesNetHelper.</span><em id="em_000119" smilref="Machine_Learning00004.smil#em_000119">setProbabilityValues</em><span class="text" id="span_000454" smilref="Machine_Learning00004.smil#span_000454">(surgical, "doesnotsmoke", "&gt;2Y", 0.58, 0.42);
        BayesNetHelper.</span><em id="em_000120" smilref="Machine_Learning00004.smil#em_000120">setProbabilityValues</em><span class="text" id="span_000455" smilref="Machine_Learning00004.smil#span_000455">(duration, 0.9, 0.1);
        BayesNetHelper.</span><em id="em_000121" smilref="Machine_Learning00004.smil#em_000121">setProbabilityValues</em><span class="text" id="span_000456" smilref="Machine_Learning00004.smil#span_000456">(age, 0.8, 0.2);
        </span><strong id="strong_000133" smilref="Machine_Learning00004.smil#strong_000133">double</strong><span class="text" id="span_000457" smilref="Machine_Learning00004.smil#span_000457"> belief = BayesNetHelper.</span><em id="em_000122" smilref="Machine_Learning00004.smil#em_000122">getBelief</em><span class="text" id="span_000458" smilref="Machine_Learning00004.smil#span_000458">(inferenceGraph, surgical);
        System.</span><em id="em_000123" smilref="Machine_Learning00004.smil#em_000123">out</em><span class="text" id="span_000459" smilref="Machine_Learning00004.smil#span_000459">.println("The probabilty of surgery being postive: " + belief);
        age.set_observation_value("&lt;55");
        belief = BayesNetHelper.</span><em id="em_000124" smilref="Machine_Learning00004.smil#em_000124">getBelief</em><span class="text" id="span_000460" smilref="Machine_Learning00004.smil#span_000460">(inferenceGraph, surgical);
        System.</span><em id="em_000125" smilref="Machine_Learning00004.smil#em_000125">out</em><span class="text" id="span_000461" smilref="Machine_Learning00004.smil#span_000461">.println("The probability of surgery being postive and patient is younger than 55: " + belief);
        smoker.set_observation_value("smokes");
        belief = BayesNetHelper.</span><em id="em_000126" smilref="Machine_Learning00004.smil#em_000126">getBelief</em><span class="text" id="span_000462" smilref="Machine_Learning00004.smil#span_000462">(inferenceGraph, surgical);
        System.</span><em id="em_000127" smilref="Machine_Learning00004.smil#em_000127">out</em><span class="text" id="span_000463" smilref="Machine_Learning00004.smil#span_000463">.println("The probability of surgery being postive for a smoker, younger than 55: " + belief);
        duration.set_observation_value("&gt;2Y");
        belief = BayesNetHelper.</span><em id="em_000128" smilref="Machine_Learning00004.smil#em_000128">getBelief</em><span class="text" id="span_000464" smilref="Machine_Learning00004.smil#span_000464">(inferenceGraph, surgical);
        System.</span><em id="em_000129" smilref="Machine_Learning00004.smil#em_000129">out</em><span class="text" id="span_000465" smilref="Machine_Learning00004.smil#span_000465">.println("The probability of surgery being postive for a smoker, younger than 55 with symptoms over 2 years: " + belief);
    }
    </span><strong id="strong_000134" smilref="Machine_Learning00004.smil#strong_000134">public static void</strong><span class="text" id="span_000466" smilref="Machine_Learning00004.smil#span_000466"> main(String[] args) {
        BayesNetExample bne = </span><strong id="strong_000135" smilref="Machine_Learning00004.smil#strong_000135">new</strong><span class="text" id="span_000467" smilref="Machine_Learning00004.smil#span_000467"> BayesNetExample();
    }
}</span></code></p>
                <sidebar render="required" id="sidebar_000004">
                  <div class="top hr" id="div_000004" />
                  <level2 class="feature2" id="level2_000039">
                    <h2 xml:space="preserve" id="h2_000008" smilref="Machine_Learning00004.smil#h2_000008">Note</h2>
                    <pagenum epub:type="pagebreak" id="p90" page="normal" smilref="Machine_Learning00004.smil#p90">90</pagenum>
                    <p xml:space="preserve" id="p_000255" smilref="Machine_Learning00004.smil#p_000255">The probabilities in the walkthrough are just base values used for demonstration; they are not connected to any study or informed by any expert. They are merely there to illustrate how Bayesian Networks can be formulated.</p>
                  </level2>
                </sidebar>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000040">
            <h2 id="c04-c04_level1_9" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04_level1_9">Summary</h2>
            <p xml:space="preserve" id="p_000256" smilref="Machine_Learning00004.smil#p_000256">This chapter covered a lot of ground, including simple graph theory, probability, and Bayes' Theorem. The Bayesian Network examples show that it's straightforward to create a network, create the nodes and connect them, and then assign probabilities and conditional probabilities. After you apply existing observations, your overall results change due to the nature of the graph.</p>
            <p id="c04-c04-para-0142" xml:space="preserve" smilref="Machine_Learning00004.smil#c04-c04-para-0142">Coding these things can be difficult and require some proper planning on paper. Wherever you can, try to enlist a domain expert to help with the initial values of the probabilities, because this will make your final prediction output more accurate.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c05">
        <section epub:type="chapter" id="section_000006">
          <header id="header_000005">
            <h1 id="c05-c5" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c5">Chapter 5 Artificial Neural Networks</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p91" page="normal" smilref="Machine_Learning00004.smil#p91">91</pagenum>
          <p xml:space="preserve" id="p_000257" smilref="Machine_Learning00004.smil#p_000257">There's something about gathering knowledge about the human brain that makes people tick. Many people think that if we can mimic how the brain works, we'll be able to make better decisions.</p>
          <p id="c05-c05-para-0002" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0002">In this chapter, you look at how artificial neural networks work and how they are applied in the machine learning arena.</p>
          <level2 id="level2_000041">
            <h2 id="c05-c05_level1_1" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05_level1_1">What Is a Neural Network?</h2>
            <p xml:space="preserve" id="p_000258"><em id="em_000130" smilref="Machine_Learning00004.smil#em_000130">Artificial neural networks</em><span class="text" id="span_000468" smilref="Machine_Learning00004.smil#span_000468"> are essentially modeled on the parallel architecture of animal brains, not necessarily human ones. The network is based on a simple form of inputs and outputs.</span></p>
            <blockquote id="blockquote_000002">
              <p xml:space="preserve" id="p_000259" smilref="Machine_Learning00004.smil#p_000259">…a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs.</p>
              <p xml:space="preserve" id="p_000260"><em id="em_000131" smilref="Machine_Learning00004.smil#em_000131">Dr. Robert Hecht-Nielson as quoted in “Neural Network Primer: Part I” by Maureen Caudill, AI Expert, Feb. 1989</em></p>
            </blockquote>
            <p id="c05-c05-para-0005" xml:space="preserve"><span class="text" id="span_000469" smilref="Machine_Learning00004.smil#span_000469">In biology terms, a </span><em id="em_000132" smilref="Machine_Learning00004.smil#em_000132">neuron</em><span class="text" id="span_000470" smilref="Machine_Learning00004.smil#span_000470"> is a cell that can transmit and process chemical or electrical signals. The neuron is connected with other neurons to create a network; </span><pagenum epub:type="pagebreak" id="p92" page="normal" smilref="Machine_Learning00004.smil#p92">92</pagenum><span class="text" id="span_000471" smilref="Machine_Learning00004.smil#span_000471">picture the notion of graph theory with nodes and edges, and then you're picturing a neural network.</span></p>
            <p id="c05-c05-para-0006" xml:space="preserve"><span class="text" id="span_000472" smilref="Machine_Learning00004.smil#span_000472">Within humans, there are a huge number of neurons interconnected with each other—tens of billions of interconnected structures. Every neuron has an input (called the </span><em id="em_000133" smilref="Machine_Learning00004.smil#em_000133">dendrite</em><span class="text" id="span_000473" smilref="Machine_Learning00004.smil#span_000473">), a cell body, and an output (called the </span><em id="em_000134" smilref="Machine_Learning00004.smil#em_000134">axon</em><span class="text" id="span_000474" smilref="Machine_Learning00004.smil#span_000474">), as shown in </span><a id="c05-c05-fig-anc-0001" href="#c05-c05-fig-0001" external="false" smilref="Machine_Learning00004.smil#c05-c05-fig-anc-0001">Figure 5-1</a><span class="text" id="span_000475" smilref="Machine_Learning00004.smil#span_000475">.</span></p>
            <figure id="figure_000032">
              <img class="center" src="images/c05f001.jpg" alt="image" id="img_000040" />
              <figcaption id="figcaption_000021">
                <p xml:space="preserve" id="p_000261"><span class="figureLabel" id="span_000476"><a id="c05-c05-fig-0001" href="#c05-c05-fig-anc-0001" external="false"><strong id="strong_000136" smilref="Machine_Learning00004.smil#strong_000136">Figure 5-1</strong></a></span><span class="text" id="span_000477" smilref="Machine_Learning00004.smil#span_000477"> The neuron structure</span></p>
              </figcaption>
            </figure>
            <p id="c05-c05-para-0007" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0007">Outputs connect to inputs of other neurons and the network develops. Biologically, neurons can have 10,000 different inputs, but their complexity is much greater than the artificial ones I'm talking about here.</p>
            <p id="c05-c05-para-0008" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0008">Neurons are activated when the electrochemical signal is sent through the axon. The cell body determines the weight of the signal, and, if a threshold is passed, the firing continues through the output, along the dendrite.</p>
          </level2>
          <level2 id="level2_000042">
            <h2 id="c05-c05_level1_2" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05_level1_2">Artificial Neural Network Uses</h2>
            <p xml:space="preserve" id="p_000262" smilref="Machine_Learning00004.smil#p_000262">Artificial neural networks thrive on data volume and speed, so they are used within real-time or very near real-time scenarios. The following sections describe some typical use cases where artificial neural networks are used.</p>
            <level3 id="level3_000086">
              <h3 xml:space="preserve" id="h3_000086" smilref="Machine_Learning00004.smil#h3_000086">High-Frequency Trading</h3>
              <p xml:space="preserve" id="p_000263"><span class="text" id="span_000478" smilref="Machine_Learning00004.smil#span_000478">With the way artificial neural networks mimic the brain but with a much increased speed factor, they are perfect for high-speed trading. Because HFT can make decisions far faster than a human can—thousands of transactions can be done </span><pagenum epub:type="pagebreak" id="p93" page="normal" smilref="Machine_Learning00004.smil#p93">93</pagenum><span class="text" id="span_000479" smilref="Machine_Learning00004.smil#span_000479">in the same time it takes a human to make one—it's obvious why the majority of stock market systems have gone to the automated trading side.</span></p>
              <p id="c05-c05-para-0011" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0011">High-frequency trading is usually done on a supervised learning method; there is a lot of training data available from which to learn. The artificial neural network is looking for entropy from the incoming data.</p>
            </level3>
            <level3 id="level3_000087">
              <h3 xml:space="preserve" id="h3_000087" smilref="Machine_Learning00004.smil#h3_000087">Credit Applications</h3>
              <p xml:space="preserve" id="p_000264" smilref="Machine_Learning00004.smil#p_000264">Although many examples of credit applications are performed with decision trees, they are often run with artificial neural networks. With the variety of application data available, it's a fairly straightforward task to train the model to spot good and bad credit factors.</p>
            </level3>
            <level3 id="level3_000088">
              <h3 xml:space="preserve" id="h3_000088" smilref="Machine_Learning00004.smil#h3_000088">Data Center Management</h3>
              <p xml:space="preserve" id="p_000265" smilref="Machine_Learning00004.smil#p_000265">Google uses neural networks for data center management. With incoming data on loads, operating temperatures, network equipment usage, and outside air temperatures, Google can calculate efficiency of the data center and be able to adjust the settings on monitoring and cooling equipment.</p>
              <p id="c05-c05-para-0014" xml:space="preserve"><span class="text" id="span_000480" smilref="Machine_Learning00004.smil#span_000480">Jim Gao started this exercise as a Google 20 percent project (a program in which Google employees are encouraged to use 20% of their work time on their own projects) and, over time, has trained the model to be 99.6 percent accurate. If you are interested in reading more on this check out Google's blog post on the subject at </span><code xml:space="preserve" id="code_000120"><a href="http://googleblog.blogspot.ca/2014/05/better-data-centers-through-machine.html" external="true" id="a_000285" smilref="Machine_Learning00004.smil#a_000285">http://googleblog.blogspot.ca/2014/05/better-data-centers-through-machine.html</a></code><span class="text" id="span_000481" smilref="Machine_Learning00004.smil#span_000481">.</span></p>
            </level3>
            <level3 id="level3_000089">
              <h3 xml:space="preserve" id="h3_000089" smilref="Machine_Learning00004.smil#h3_000089">Robotics</h3>
              <p xml:space="preserve" id="p_000266" smilref="Machine_Learning00004.smil#p_000266">Artificial intelligence has been used in robotics for several years. Some artificial intelligence requires pattern recognition, and some requires huge amounts of sensor data to be fed into a neural network to determine what movement or action to take.</p>
              <p id="c05-c05-para-0016" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0016">Training models in robotics takes an awful long time to create, mainly because there are potentially so many different inputs and output variables to process and learn from. For example, developers of autonomous driving vehicles need hundreds of hours of previous driving data to make a model that can handle many road conditions. (Personally, I still prefer my hands on the wheel.)</p>
            </level3>
            <level3 id="level3_000090">
              <h3 xml:space="preserve" id="h3_000090" smilref="Machine_Learning00004.smil#h3_000090">Medical Monitoring</h3>
              <p xml:space="preserve" id="p_000267"><span class="text" id="span_000482" smilref="Machine_Learning00004.smil#span_000482">Medical machinery can be monitored via artificial neural networks, which involves the constant updating of many variables, such as heart rate, blood pressure, and so on. </span><pagenum epub:type="pagebreak" id="p94" page="normal" smilref="Machine_Learning00004.smil#p94">94</pagenum><span class="text" id="span_000483" smilref="Machine_Learning00004.smil#span_000483">Conditions that have multiple variations and trigger symptoms can be calculated and monitored, and staff can be alerted when the variables go over certain thresholds.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000043">
            <h2 id="c05-c05_level1_3" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05_level1_3">Breaking Down the Artificial Neural Network</h2>
            <p xml:space="preserve" id="p_000268" smilref="Machine_Learning00004.smil#p_000268">One of the keys to understanding the artificial neural network is knowing that the application of the model implies you're not exactly sure of the relationship of the input and output nodes. You might have a hunch, but you don't know for sure. The simple fact of the matter is, if you did know this, then you'd be using another machine learning algorithm.</p>
            <p id="c05-c05-para-0019" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0019">Before you jump into data and examples, have a look at the components in a neural network.</p>
            <level3 id="level3_000091">
              <h3 xml:space="preserve" id="h3_000091" smilref="Machine_Learning00004.smil#h3_000091">Perceptrons</h3>
              <p xml:space="preserve" id="p_000269"><span class="text" id="span_000484" smilref="Machine_Learning00004.smil#span_000484">The basis for a neural network is the </span><em id="em_000135" smilref="Machine_Learning00004.smil#em_000135">perceptron</em><span class="text" id="span_000485" smilref="Machine_Learning00004.smil#span_000485">. Its role is quite simple. It receives an input signal and then passes the value through some form of function. It outputs the result of the function. (See </span><a id="c05-c05-fig-anc-0002" href="#c05-c05-fig-0002" external="false" smilref="Machine_Learning00004.smil#c05-c05-fig-anc-0002">Figure 5-2</a><span class="text" id="span_000486" smilref="Machine_Learning00004.smil#span_000486">.)</span></p>
              <figure id="figure_000033">
                <img class="center" src="images/c05f002.jpg" alt="image" id="img_000041" />
                <figcaption id="figcaption_000022">
                  <p xml:space="preserve" id="p_000270"><span class="figureLabel" id="span_000487"><a id="c05-c05-fig-0002" href="#c05-c05-fig-anc-0002" external="false"><strong id="strong_000137" smilref="Machine_Learning00004.smil#strong_000137">Figure 5-2</strong></a></span><span class="text" id="span_000488" smilref="Machine_Learning00004.smil#span_000488"> A simple perceptron</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0021" xml:space="preserve"><span class="text" id="span_000489" smilref="Machine_Learning00004.smil#span_000489">Perceptrons deal with numbers when a number or vector of numbers is passed to the input. It is then passed to a function that calculates the outgoing value; this is called the </span><em id="em_000136" smilref="Machine_Learning00004.smil#em_000136">activation function</em><span class="text" id="span_000490" smilref="Machine_Learning00004.smil#span_000490">. The node can handle any number of inputs—</span><a id="c05-c05-fig-anc-0003" href="#c05-c05-fig-0003" external="false" smilref="Machine_Learning00004.smil#c05-c05-fig-anc-0003">Figure 5-3</a><span class="text" id="span_000491" smilref="Machine_Learning00004.smil#span_000491"> shows two inputs passing in to the function—and it takes the weighted sum of all the inputs.</span></p>
              <figure id="figure_000034">
                <img class="center" src="images/c05f003.jpg" alt="image" id="img_000042" />
                <figcaption id="figcaption_000023">
                  <p xml:space="preserve" id="p_000271"><span class="figureLabel" id="span_000492"><a id="c05-c05-fig-0003" href="#c05-c05-fig-anc-0003" external="false"><strong id="strong_000138" smilref="Machine_Learning00004.smil#strong_000138">Figure 5-3</strong></a></span><span class="text" id="span_000493" smilref="Machine_Learning00004.smil#span_000493"> Perceptron with two inputs</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0022" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0022">Assuming the input is a vector Z, you'd end up with something like this:</p>
              <list type="ol" id="list_000036">
                <li id="li_000319" smilref="Machine_Learning00004.smil#li_000319">Z 1 = 2</li>
                <li id="li_000320" smilref="Machine_Learning00004.smil#li_000320">Z 2 = 5</li>
                <li id="li_000321" smilref="Machine_Learning00004.smil#li_000321">Z 3 = 1</li>
                <li id="li_000322" smilref="Machine_Learning00004.smil#li_000322">Or (2,5,1)</li>
              </list>
              <p id="c05-c05-para-0023" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0023">The weighted sum of all the inputs is calculated as follows:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000272"><img src="images/c05_math_001.png" alt="equation" id="img_000043" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mstyle displaystyle="true"><munder><mo>&#x02211;</mo><mi>i</mi></munder><mrow><mtext mathvariant="italic">wiZi</mtext></mrow></mstyle></mrow></math>--></p>
              <pagenum epub:type="pagebreak" id="p95" page="normal" smilref="Machine_Learning00004.smil#p95">95</pagenum>
              <p id="c05-c05-para-0024" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0024">In other words, “add it all up.” So for the likes of me, who is not used to too much math notation, it looks like the following:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000273"><img src="images/c05_math_002.png" alt="equation" id="img_000044" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><msub><mn>2</mn><mrow><mi>w</mi><mn>1</mn></mrow></msub><mo>+</mo><msub><mn>5</mn><mrow><mi>w</mi><mn>2</mn></mrow></msub><mo>+</mo><msub><mn>1</mn><mrow><mi>w</mi><mn>3</mn></mrow></msub></mrow></math>--></p>
              <p id="c05-c05-para-0025" xml:space="preserve"><span class="text" id="span_000494" smilref="Machine_Learning00004.smil#span_000494">The outgoing part of the node has a set threshold. If the summed value is over the threshold, then the output, denoted by the </span><em id="em_000137" smilref="Machine_Learning00004.smil#em_000137">y</em><span class="text" id="span_000495" smilref="Machine_Learning00004.smil#span_000495"> variable, is 1, and if it's below the threshold, then </span><em id="em_000138" smilref="Machine_Learning00004.smil#em_000138">y</em><span class="text" id="span_000496" smilref="Machine_Learning00004.smil#span_000496"> is 0 (zero).</span></p>
              <p id="c05-c05-para-0026" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0026">You end up with the following equation:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000274"><img src="images/c05_math_003.png" alt="equation" id="img_000045" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">if</mtext><mspace width="0.12em"/><munder><msub><mi>&#x003A3;</mi><mi>i</mi></msub><mrow><mtext mathvariant="italic">else</mtext><mo>_</mo><mi>y</mi><mo>=</mo><mn>0</mn></mrow></munder><mtext mathvariant="italic">wiZi</mtext><mo>&#x02265;</mo><mi>t</mi><mspace width="0.12em"/><mtext mathvariant="italic">then</mtext><mspace width="0.12em"/><mi>y</mi><mo>=</mo><mn>1</mn></mrow></math>--></p>
              <p id="c05-c05-para-0027" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0027">The weight of the perceptron can be zero or any other value. If the weight value is zero, then it does not alter the input node value coming into the perceptron. Likewise, inputs can be positive or negative numbers. The key to the output is based on the weighted sum against the threshold.</p>
              <p id="c05-c05-para-0028" xml:space="preserve" smilref="Machine_Learning00004.smil#c05-c05-para-0028">That's the basis of a single-node perceptron. When you strip the components apart, it's quite basic in composition.</p>
            </level3>
            <level3 id="level3_000092">
              <h3 xml:space="preserve" id="h3_000092" smilref="Machine_Learning00004.smil#h3_000092">Activation Functions</h3>
              <p xml:space="preserve" id="p_000275"><span class="text" id="span_000497" smilref="Machine_Learning00004.smil#span_000497">The </span><em id="em_000139" smilref="Machine_Learning00004.smil#em_000139">activation function</em><span class="text" id="span_000498" smilref="Machine_Learning00004.smil#span_000498"> is the processing that happens after the input is passed into the neuron. The result of this function determines whether the value is passed to the output axon and onto the next neuron in the network.</span></p>
              <p id="c05-c05-para-0030" xml:space="preserve"><span class="text" id="span_000499" smilref="Machine_Learning00004.smil#span_000499">Commonly, the Sigmoid function (see </span><a id="c05-c05-fig-anc-0004" href="#c05-c05-fig-0004" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0004">Figure 5-4</a><span class="text" id="span_000500" smilref="Machine_Learning00005.smil#span_000500">) and the hyperbolic tangent are used as activation functions to calculate the output.</span></p>
              <figure id="figure_000035">
                <img class="center" src="images/c05f004.jpg" alt="image" id="img_000046" />
                <figcaption id="figcaption_000024">
                  <p xml:space="preserve" id="p_000276"><span class="figureLabel" id="span_000501"><a id="c05-c05-fig-0004" href="#c05-c05-fig-anc-0004" external="false"><strong id="strong_000139" smilref="Machine_Learning00005.smil#strong_000139">Figure 5-4</strong></a></span><span class="text" id="span_000502" smilref="Machine_Learning00005.smil#span_000502"> Sigmoid function</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0031" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0031">The Sigmoid function only outputs one of two values: 0 and 1. For the programmers, the function is written as</p>
              <p xml:space="preserve" id="p_000277"><code class="preserve-whitespace" xml:space="preserve" id="code_000121" smilref="Machine_Learning00005.smil#code_000121">return 1.0 / (1.0 + Math.exp(-x));</code></p>
              <pagenum epub:type="pagebreak" id="p96" page="normal" smilref="Machine_Learning00005.smil#p96">96</pagenum>
              <p id="c05-c05-para-0032" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0032">The sharpness of the curve could also be altered if required, but for most applications a straight function is fine.</p>
            </level3>
            <level3 id="level3_000093">
              <h3 xml:space="preserve" id="h3_000093" smilref="Machine_Learning00005.smil#h3_000093">Multilayer Perceptrons</h3>
              <p xml:space="preserve" id="p_000278" smilref="Machine_Learning00005.smil#p_000278">The problem with single-layer perceptrons is that they are linearly separable. The output is either one value or another.</p>
              <p id="c05-c05-para-0034" xml:space="preserve"><span class="text" id="span_000503" smilref="Machine_Learning00005.smil#span_000503">If you think of an AND gate in logic theory, there is only one outcome if you have two inputs, as shown in </span><a id="c05-c05-tbl-anc-0001" href="#c05-c05-tbl-0001" external="false" smilref="Machine_Learning00005.smil#c05-c05-tbl-anc-0001">Table 5-1</a><span class="text" id="span_000504" smilref="Machine_Learning00005.smil#span_000504">.</span></p>
              <figure id="figure_000036">
                <figcaption id="figcaption_000025">
                  <p xml:space="preserve" id="p_000279"><span class="figureLabel" id="span_000505"><a id="c05-c05-tbl-0001" href="#c05-c05-tbl-anc-0001" external="false"><strong id="strong_000140" smilref="Machine_Learning00005.smil#strong_000140">Table 5-1</strong></a></span><span class="text" id="span_000506" smilref="Machine_Learning00005.smil#span_000506"> AND Gate Output Table</span></p>
                </figcaption>
                <table border="1" id="table_000014">
                  <tr id="tr_000053">
                    <td class="left" rowspan="1" colspan="1" id="td_000160" smilref="Machine_Learning00005.smil#td_000160">Input</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000161" smilref="Machine_Learning00005.smil#td_000161">Output</td>
                  </tr>
                  <tr id="tr_000054">
                    <td class="left" rowspan="1" colspan="1" id="td_000162" smilref="Machine_Learning00005.smil#td_000162">Off and On</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000163" smilref="Machine_Learning00005.smil#td_000163">Off</td>
                  </tr>
                  <tr id="tr_000055">
                    <td class="left" rowspan="1" colspan="1" id="td_000164" smilref="Machine_Learning00005.smil#td_000164">On and Off</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000165" smilref="Machine_Learning00005.smil#td_000165">Off</td>
                  </tr>
                  <tr id="tr_000056">
                    <td class="left" rowspan="1" colspan="1" id="td_000166" smilref="Machine_Learning00005.smil#td_000166">Off and Off</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000167" smilref="Machine_Learning00005.smil#td_000167">Off</td>
                  </tr>
                  <tr id="tr_000057">
                    <td class="left" rowspan="1" colspan="1" id="td_000168" smilref="Machine_Learning00005.smil#td_000168">On and On</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000169" smilref="Machine_Learning00005.smil#td_000169">On</td>
                  </tr>
                </table>
              </figure>
              <p id="c05-c05-para-0035" xml:space="preserve"><span class="text" id="span_000507" smilref="Machine_Learning00005.smil#span_000507">The perceptron would be fashioned as shown in </span><a id="c05-c05-fig-anc-0005" href="#c05-c05-fig-0005" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0005">Figure 5-5</a><span class="text" id="span_000508" smilref="Machine_Learning00005.smil#span_000508">.</span></p>
              <figure id="figure_000037">
                <img class="center" src="images/c05f005.jpg" alt="image" id="img_000047" />
                <figcaption id="figcaption_000026">
                  <p xml:space="preserve" id="p_000280"><span class="figureLabel" id="span_000509"><a id="c05-c05-fig-0005" href="#c05-c05-fig-anc-0005" external="false"><strong id="strong_000141" smilref="Machine_Learning00005.smil#strong_000141">Figure 5-5</strong></a></span><span class="text" id="span_000510" smilref="Machine_Learning00005.smil#span_000510"> AND gate perceptron</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p97" page="normal" smilref="Machine_Learning00005.smil#p97">97</pagenum>
              <p id="c05-c05-para-0036" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0036">The network output equation would be the following:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000281"><img src="images/c05_math_004.png" alt="equation" id="img_000048" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">Output</mtext><mo>=</mo><mfenced open="{" close="}"><mtable columnalign="center"><mtr columnalign="center"><mtd columnalign="center"><mn>1</mn><mspace width="0.12em"/><mtext mathvariant="italic">if</mtext><mspace width="0.12em"/><mfenced open="(" close=")"><mrow><mi>W</mi><mn>00</mn><mo>&#x000D7;</mo><mi>I</mi><mn>0</mn></mrow></mfenced><mo>+</mo><mfenced open="(" close=")"><mrow><mi>W</mi><mn>01</mn><mo>&#x000D7;</mo><mi>I</mi><mn>1</mn></mrow></mfenced><mo>&#x0003E;</mo><mn>0</mn></mtd></mtr><mtr columnalign="center"><mtd columnalign="center"><mn>0</mn><mspace width="0.12em"/><mtext>Otherwise</mtext><mo>&#x02026;</mo></mtd></mtr></mtable></mfenced></mrow></math>--></p>
              <p id="c05-c05-para-0037" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0037">So far, I've covered the processing of one perceptron. Artificial neural networks have many interconnected neurons, each with its own input, output, and activation function.</p>
              <p id="c05-c05-para-0038" xml:space="preserve"><span class="text" id="span_000511" smilref="Machine_Learning00005.smil#span_000511">For most machine learning functions, artificial neural networks are used for solving problems of a nonlinear fashion. Many problems cannot be solved in a purely linear fashion, so using a single-layer perceptron for this kind of problem solving was never worth considering. If you think of an XOR gate (Exclusive OR) with the input types shown in </span><a id="c05-c05-tbl-anc-0002" href="#c05-c05-tbl-0002" external="false" smilref="Machine_Learning00005.smil#c05-c05-tbl-anc-0002">Table 5-2</a><span class="text" id="span_000512" smilref="Machine_Learning00005.smil#span_000512">, you could easily think of the network shown in </span><a id="c05-c05-fig-anc-0006" href="#c05-c05-fig-0006" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0006">Figure 5-6</a><span class="text" id="span_000513" smilref="Machine_Learning00005.smil#span_000513">.</span></p>
              <figure id="figure_000038">
                <figcaption id="figcaption_000027">
                  <p xml:space="preserve" id="p_000282"><span class="figureLabel" id="span_000514"><a id="c05-c05-tbl-0002" href="#c05-c05-tbl-anc-0002" external="false"><strong id="strong_000142" smilref="Machine_Learning00005.smil#strong_000142">Table 5-2</strong></a></span><span class="text" id="span_000515" smilref="Machine_Learning00005.smil#span_000515"> Exclusive OR Output Table</span></p>
                </figcaption>
                <table border="1" id="table_000015">
                  <tr id="tr_000058">
                    <td class="left" rowspan="1" colspan="1" id="td_000170" smilref="Machine_Learning00005.smil#td_000170">Input</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000171" smilref="Machine_Learning00005.smil#td_000171">Output</td>
                  </tr>
                  <tr id="tr_000059">
                    <td class="left" rowspan="1" colspan="1" id="td_000172" smilref="Machine_Learning00005.smil#td_000172">Off and On</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000173" smilref="Machine_Learning00005.smil#td_000173">On</td>
                  </tr>
                  <tr id="tr_000060">
                    <td class="left" rowspan="1" colspan="1" id="td_000174" smilref="Machine_Learning00005.smil#td_000174">On and Off</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000175" smilref="Machine_Learning00005.smil#td_000175">On</td>
                  </tr>
                  <tr id="tr_000061">
                    <td class="left" rowspan="1" colspan="1" id="td_000176" smilref="Machine_Learning00005.smil#td_000176">Off and Off</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000177" smilref="Machine_Learning00005.smil#td_000177">Off</td>
                  </tr>
                  <tr id="tr_000062">
                    <td class="left" rowspan="1" colspan="1" id="td_000178" smilref="Machine_Learning00005.smil#td_000178">On and On</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000179" smilref="Machine_Learning00005.smil#td_000179">Off</td>
                  </tr>
                </table>
              </figure>
              <figure id="figure_000039">
                <img class="center" src="images/c05f006.jpg" alt="image" id="img_000049" />
                <figcaption id="figcaption_000028">
                  <p xml:space="preserve" id="p_000283"><span class="figureLabel" id="span_000516"><a id="c05-c05-fig-0006" href="#c05-c05-fig-anc-0006" external="false"><strong id="strong_000143" smilref="Machine_Learning00005.smil#strong_000143">Figure 5-6</strong></a></span><span class="text" id="span_000517" smilref="Machine_Learning00005.smil#span_000517"> XOR gate network</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0039" xml:space="preserve"><span class="text" id="span_000518" smilref="Machine_Learning00005.smil#span_000518">Multilayer perceptrons have one or more layers between the input nodes and the eventual output nodes. The XOR example has a middle layer, called a hidden layer, between the input and the output (see </span><a id="c05-c05-fig-anc-0007" href="#c05-c05-fig-0007" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0007">Figure 5-7</a><span class="text" id="span_000519" smilref="Machine_Learning00005.smil#span_000519">). Although you and I know what the outputs of an XOR gate would be (I've just outlined them in the table), and we could define the middle layer ourselves, a truly automated learning platform would take some time.</span></p>
              <figure id="figure_000040">
                <img class="center" src="images/c05f007.jpg" alt="image" id="img_000050" />
                <figcaption id="figcaption_000029">
                  <p xml:space="preserve" id="p_000284"><span class="figureLabel" id="span_000520"><a id="c05-c05-fig-0007" href="#c05-c05-fig-anc-0007" external="false"><strong id="strong_000144" smilref="Machine_Learning00005.smil#strong_000144">Figure 5-7</strong></a></span><span class="text" id="span_000521" smilref="Machine_Learning00005.smil#span_000521"> Multilayer perceptron with one hidden layer</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p98" page="normal" smilref="Machine_Learning00005.smil#p98">98</pagenum>
              <p id="c05-c05-para-0040" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0040">The question is, what happens in the hidden layer? Going back to the XOR example for a moment, you can see the two input nodes with their values. These would then be fed to the hidden layer, and the input is dependent on the output of the input layer.</p>
              <p id="c05-c05-para-0041" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0041">This is where the neural network becomes useful. You can train the network for classification and pattern recognition, but it does require training. You can train an artificial neural network by unsupervised or supervised means.</p>
              <p id="c05-c05-para-0042" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0042">The issue is that you don't know what the weight values should be for the hidden layer. By changing the bias in the Sigmoid function, you can vary the output layer, an error function can be applied, and the aim is to get the value of the error function to a minimum value.</p>
              <p id="c05-c05-para-0043" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0043">I described the threshold function within the perceptron previously in the chapter, but this isn't suitable for your needs. You need something that is continuous and differentiable. With the bias option implemented in the Sigmoid function, each run of the network refines the output and the error function. This leads to a better-trained network and more reliable answers.</p>
            </level3>
            <level3 id="level3_000094">
              <h3 xml:space="preserve" id="h3_000094" smilref="Machine_Learning00005.smil#h3_000094">Back Propagation</h3>
              <p xml:space="preserve" id="p_000285"><span class="text" id="span_000522" smilref="Machine_Learning00005.smil#span_000522">Within the multilayer perceptron is the concept of </span><em id="em_000140" smilref="Machine_Learning00005.smil#em_000140">back propagation</em><span class="text" id="span_000523" smilref="Machine_Learning00005.smil#span_000523">, short for the “backward propagation of errors.” Back propagation calculates the gradients and maps the correct inputs to the correct outputs.</span></p>
              <p id="c05-c05-para-0045" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0045">There are two steps to back propagation: the propagation phase and the updating of the weight. This would occur for all the neurons in the network.</p>
              <p id="c05-c05-para-0046" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0046">If you were to look at this as pseudocode—assuming an input layer, single hidden layer, and an output layer—it would look like this:</p>
              <p xml:space="preserve" id="p_000286"><code class="preserve-whitespace" xml:space="preserve" id="code_000122"><span class="text" id="span_000524" smilref="Machine_Learning00005.smil#span_000524">initialize weights in network (random values)
while(examples to process)
  for each example x
    </span><em id="em_000141" smilref="Machine_Learning00005.smil#em_000141">prediction = neural</em><span class="text" id="span_000525" smilref="Machine_Learning00005.smil#span_000525">_output(network, x)
    </span><em id="em_000142" smilref="Machine_Learning00005.smil#em_000142">actual = trained-output(x)</em>
    <em id="em_000143" smilref="Machine_Learning00005.smil#em_000143">error is (prediction – actual) on output nodes</em>
<em id="em_000144" smilref="Machine_Learning00005.smil#em_000144">backwardpass</em><span class="text" id="span_000526" smilref="Machine_Learning00005.smil#span_000526">:
  </span><em id="em_000145" smilref="Machine_Learning00005.smil#em_000145">compute weights from hidden layer to the output layer</em>
  <em id="em_000146" smilref="Machine_Learning00005.smil#em_000146">compute weights from input layer to hidden layer</em>
  <em id="em_000147" smilref="Machine_Learning00005.smil#em_000147">update network weights</em>
  <em id="em_000148" smilref="Machine_Learning00005.smil#em_000148">until all classified correctly against training data</em>
  <em id="em_000149" smilref="Machine_Learning00005.smil#em_000149">return finalized network</em></code></p>
              <pagenum epub:type="pagebreak" id="p99" page="normal" smilref="Machine_Learning00005.smil#p99">99</pagenum>
              <p id="c05-c05-para-0047" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0047">Propagation happens, and the training is input through the network and generates the activations of the output. It then backward propagates the output activations and generates deltas of all the output and hidden layers of the network based on the target of the training pattern.</p>
              <p id="c05-c05-para-0048" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0048">In the second phase, the weight update is calculated by multiplying the output delta and input activation. This gives you the gradient weight. The percentage ratio is then subtracted from the weight. The second part is done for all the weight axons in the network.</p>
              <p id="c05-c05-para-0049" xml:space="preserve"><span class="text" id="span_000527" smilref="Machine_Learning00005.smil#span_000527">The percentage ratio is called the </span><em id="em_000150" smilref="Machine_Learning00005.smil#em_000150">learning rate</em><span class="text" id="span_000528" smilref="Machine_Learning00005.smil#span_000528">. The higher the ratio, the faster the learning. With a lower ratio you know the accuracy of the learning is good.</span></p>
              <sidebar render="required" id="sidebar_000005">
                <div class="top hr" id="div_000005" />
                <level2 class="feature2" id="level2_000044">
                  <h2 xml:space="preserve" id="h2_000009" smilref="Machine_Learning00005.smil#h2_000009">Note</h2>
                  <p xml:space="preserve" id="p_000287" smilref="Machine_Learning00005.smil#p_000287">I appreciate that it's difficult to grasp mathematical concepts on neural networks in a book that focuses on the practical aspects of getting machine learning up and running quickly. This overview gives a very general idea of how they work. The main concepts of input and output layers, perceptrons, and the notion of forward and backward propagation provide a good, although simple, grounding in the thought process.</p>
                </level2>
              </sidebar>
            </level3>
          </level2>
          <level2 id="level2_000045">
            <h2 id="c05-c05_level1_4" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05_level1_4">Data Preparation for Artificial Neural Networks</h2>
            <p xml:space="preserve" id="p_000288" smilref="Machine_Learning00005.smil#p_000288">For creating an artificial neural network, it's worth using a supervised learning method. However, this requires some thought about the data that you are going to use to train the network.</p>
            <p id="c05-c05-para-0052" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0052">Artificial neural networks work only with numerical data values. So, if there are normalized things with text values, they need to be converted. This isn't so much an issue with the likes of gender, where the common output would be Male = 0 and Female = 1, for example. Raw text wouldn't be suitable, so it will either need to be tidied up, hashed to numeric values, or removed from the test data.</p>
            <p id="c05-c05-para-0053" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0053">As with all data strategies, it's a case of thinking about what's important and what data you can live without.</p>
            <p id="c05-c05-para-0054" xml:space="preserve"><span class="text" id="span_000529" smilref="Machine_Learning00005.smil#span_000529">As more variables increase in your data for classification, you will come across the phenomenon called “the curse of dimensionality.” This is when added variables increase the total volume of training data required to get reasonable </span><pagenum epub:type="pagebreak" id="p100" page="normal" smilref="Machine_Learning00005.smil#p100">100</pagenum><span class="text" id="span_000530" smilref="Machine_Learning00005.smil#span_000530">results and insight. So, when you are thinking of adding another variable, make sure that you have enough training data to cover eventualities across all the other variables.</span></p>
            <p id="c05-c05-para-0055" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0055">Although neural networks are pretty tolerant to noisy data, it's worth trying to ensure that there aren't large outliers that could potentially cause issue with the results. Either find and remove the wayward digits or turn them into missing values.</p>
          </level2>
          <level2 id="level2_000046">
            <h2 id="c05-c05_level1_5" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05_level1_5">Artificial Neural Networks with Weka</h2>
            <p xml:space="preserve" id="p_000289" smilref="Machine_Learning00005.smil#p_000289">The Weka framework supports a multilayer perceptron and trains it with the back propagation technique I just described. In this walkthrough, you create some data and then generate a neural network.</p>
            <level3 id="level3_000095">
              <h3 xml:space="preserve" id="h3_000095" smilref="Machine_Learning00005.smil#h3_000095">Generating a Dataset</h3>
              <p xml:space="preserve" id="p_000290" smilref="Machine_Learning00005.smil#p_000290">My dataset is going to contain classifications for different types of vehicles. I'm first going to create a Java program that generates some random, but weighted, data to give us four types of vehicles: bike, car, bus, and truck.</p>
              <p id="c05-c05-para-0058" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0058">Here's the code listing:</p>
              <p xml:space="preserve" id="p_000291"><code class="preserve-whitespace" xml:space="preserve" id="code_000123"><strong id="strong_000145" smilref="Machine_Learning00005.smil#strong_000145">import java.io.BufferedWriter;</strong>
<strong id="strong_000146" smilref="Machine_Learning00005.smil#strong_000146">import java.io.FileWriter;</strong>
<strong id="strong_000147" smilref="Machine_Learning00005.smil#strong_000147">import java.io.IOException;</strong>
<strong id="strong_000148" smilref="Machine_Learning00005.smil#strong_000148">import java.util.Random;</strong>
<strong id="strong_000149" smilref="Machine_Learning00005.smil#strong_000149">public class</strong><span class="text" id="span_000531" smilref="Machine_Learning00005.smil#span_000531"> MLPData {
    </span><strong id="strong_000150" smilref="Machine_Learning00005.smil#strong_000150">private</strong><span class="text" id="span_000532" smilref="Machine_Learning00005.smil#span_000532"> String[] classtype = </span><strong id="strong_000151" smilref="Machine_Learning00005.smil#strong_000151">new</strong><span class="text" id="span_000533" smilref="Machine_Learning00005.smil#span_000533"> String[] { "Bike", "Car", "Bus", "Truck" };
    </span><strong id="strong_000152" smilref="Machine_Learning00005.smil#strong_000152">public</strong><span class="text" id="span_000534" smilref="Machine_Learning00005.smil#span_000534"> MLPData() {
        Random rand = </span><strong id="strong_000153" smilref="Machine_Learning00005.smil#strong_000153">new</strong><span class="text" id="span_000535" smilref="Machine_Learning00005.smil#span_000535"> Random(System.</span><em id="em_000151" smilref="Machine_Learning00005.smil#em_000151">nanoTime</em><span class="text" id="span_000536" smilref="Machine_Learning00005.smil#span_000536">());
        </span><strong id="strong_000154" smilref="Machine_Learning00005.smil#strong_000154">try</strong><span class="text" id="span_000537" smilref="Machine_Learning00005.smil#span_000537"> {
            BufferedWriter out = </span><strong id="strong_000155" smilref="Machine_Learning00005.smil#strong_000155">new</strong><span class="text" id="span_000538" smilref="Machine_Learning00005.smil#span_000538"> BufferedWriter(</span><strong id="strong_000156" smilref="Machine_Learning00005.smil#strong_000156">new</strong><span class="text" id="span_000539" smilref="Machine_Learning00005.smil#span_000539"> FileWriter(
                    "vehicledata.csv"));
    out.write("wheels,chassis,pax,vtype\n");
            </span><strong id="strong_000157" smilref="Machine_Learning00005.smil#strong_000157">for</strong><span class="text" id="span_000540" smilref="Machine_Learning00005.smil#span_000540"> (</span><strong id="strong_000158" smilref="Machine_Learning00005.smil#strong_000158">int</strong><span class="text" id="span_000541" smilref="Machine_Learning00005.smil#span_000541"> i = 0; i &lt; 100; i++) {
                StringBuilder sb = </span><strong id="strong_000159" smilref="Machine_Learning00005.smil#strong_000159">new</strong><span class="text" id="span_000542" smilref="Machine_Learning00005.smil#span_000542"> StringBuilder();
                </span><strong id="strong_000160" smilref="Machine_Learning00005.smil#strong_000160">switch</strong><span class="text" id="span_000543" smilref="Machine_Learning00005.smil#span_000543"> (rand.nextInt(3)) {
                </span><strong id="strong_000161" smilref="Machine_Learning00005.smil#strong_000161">case</strong><span class="text" id="span_000544" smilref="Machine_Learning00005.smil#span_000544"> 0:
                    sb.append((rand.nextInt(1) + 1) + ","); // num of wheels
                    sb.append((rand.nextInt(1) + 1) + ","); // chassis length
                    sb.append((rand.nextInt(1) + 1) + ","); // passenger number
                    sb.append(classtype[0] + "\n");
                    </span><strong id="strong_000162" smilref="Machine_Learning00005.smil#strong_000162">break;</strong>
                <strong id="strong_000163" smilref="Machine_Learning00005.smil#strong_000163">case</strong><span class="text" id="span_000545" smilref="Machine_Learning00005.smil#span_000545"> 1:
                    sb.append((rand.nextInt(2) + 4) + ","); // num of wheels
                    sb.append((rand.nextInt(4) + 1) + ","); // chassis length
                    sb.append((rand.nextInt(4) + 1) + ","); // passenger number
                    sb.append(classtype[1] + "\n");
                    </span><strong id="strong_000164" smilref="Machine_Learning00005.smil#strong_000164">break;</strong>
                <strong id="strong_000165" smilref="Machine_Learning00005.smil#strong_000165">case</strong><span class="text" id="span_000546" smilref="Machine_Learning00005.smil#span_000546"> 2:
                    sb.append((rand.nextInt(6) + 4) + ","); // num of wheels
                    sb.append((rand.nextInt(12) + 12) + ","); // chassis length
sb.append((rand.nextInt(30) + 10) + ","); // passenger number
                    sb.append(classtype[2] + "\n");
                    </span><strong id="strong_000166" smilref="Machine_Learning00005.smil#strong_000166">break;</strong>
                <strong id="strong_000167" smilref="Machine_Learning00005.smil#strong_000167">case</strong><span class="text" id="span_000547" smilref="Machine_Learning00005.smil#span_000547"> 3:
                    sb.append("18,"); // num of wheels
                    sb.append((rand.nextInt(10) + 20) + ","); // chassis length
                    sb.append((rand.nextInt(2) + 1) + ","); // passenger number
                    sb.append(classtype[3] + "\n");
                    </span><strong id="strong_000168" smilref="Machine_Learning00005.smil#strong_000168">break;</strong>
                <strong id="strong_000169" smilref="Machine_Learning00005.smil#strong_000169">default:</strong>
                    <strong id="strong_000170" smilref="Machine_Learning00005.smil#strong_000170">break</strong><span class="text" id="span_000548" smilref="Machine_Learning00005.smil#span_000548">;
                }
                out.write(sb.toString());
            }
            out.close();
        } </span><strong id="strong_000171" smilref="Machine_Learning00005.smil#strong_000171">catch</strong><span class="text" id="span_000549" smilref="Machine_Learning00005.smil#span_000549"> (IOException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000172" smilref="Machine_Learning00005.smil#strong_000172">public static void</strong><span class="text" id="span_000550" smilref="Machine_Learning00005.smil#span_000550"> main(String[] args) {
        </span><pagenum epub:type="pagebreak" id="p101" page="normal" smilref="Machine_Learning00005.smil#p101">101</pagenum><span class="text" id="span_000551" smilref="Machine_Learning00005.smil#span_000551">MLPData mlp = </span><strong id="strong_000173" smilref="Machine_Learning00005.smil#strong_000173">new</strong><span class="text" id="span_000552" smilref="Machine_Learning00005.smil#span_000552"> MLPData();
    }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p102" page="normal" smilref="Machine_Learning00005.smil#p102">102</pagenum>
              <p id="c05-c05-para-0059" xml:space="preserve"><span class="text" id="span_000553" smilref="Machine_Learning00005.smil#span_000553">When run, the preceding code creates a CSV file called </span><code xml:space="preserve" id="code_000124" smilref="Machine_Learning00005.smil#code_000124">vehicledata.csv</code><span class="text" id="span_000554" smilref="Machine_Learning00005.smil#span_000554">. Start by creating 100 rows of output:</span></p>
              <p xml:space="preserve" id="p_000292"><code class="preserve-whitespace" xml:space="preserve" id="code_000125" smilref="Machine_Learning00005.smil#code_000125">4,2,4,Car
9,20,25,Bus
5,14,18,Bus
5,2,1,Car
9,17,25,Bus
1,1,1,Bike
4,4,2,Car
9,15,36,Bus
1,1,1,Bike
5,1,4,Car
4,2,1,Car</code></p>
              <p id="c05-c05-para-0060" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0060">As discussed previously, you need to perform a fair amount of training to make the neural network accurate in its predictions.</p>
            </level3>
            <level3 id="level3_000096">
              <h3 xml:space="preserve" id="h3_000096" smilref="Machine_Learning00005.smil#h3_000096">Loading the Data into Weka</h3>
              <p xml:space="preserve" id="p_000293"><span class="text" id="span_000555" smilref="Machine_Learning00005.smil#span_000555">Open the Weka toolkit and select the Explorer function to display the Explorer shown in </span><a id="c05-c05-fig-anc-0008" href="#c05-c05-fig-0008" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0008">Figure 5-8</a><span class="text" id="span_000556" smilref="Machine_Learning00005.smil#span_000556">.</span></p>
              <figure id="figure_000041">
                <img class="center" src="images/c05f008.jpg" alt="image" id="img_000051" />
                <figcaption id="figcaption_000030">
                  <p xml:space="preserve" id="p_000294"><span class="figureLabel" id="span_000557"><a id="c05-c05-fig-0008" href="#c05-c05-fig-anc-0008" external="false"><strong id="strong_000174" smilref="Machine_Learning00005.smil#strong_000174">Figure 5-8</strong></a></span><span class="text" id="span_000558" smilref="Machine_Learning00005.smil#span_000558"> Weka Explorer</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p103" page="normal" smilref="Machine_Learning00005.smil#p103">103</pagenum>
              <p id="c05-c05-para-0062" xml:space="preserve"><span class="text" id="span_000559" smilref="Machine_Learning00005.smil#span_000559">You're going to import the CSV file that's been created. Make sure that the Preprocess window is selected and then click the Open File button and select the </span><code xml:space="preserve" id="code_000126" smilref="Machine_Learning00005.smil#code_000126">vehicledata.csv</code><span class="text" id="span_000560" smilref="Machine_Learning00005.smil#span_000560"> file. Don't forget to change the File Format drop-down menu from </span><code xml:space="preserve" id="code_000127" smilref="Machine_Learning00005.smil#code_000127">.arff</code><span class="text" id="span_000561" smilref="Machine_Learning00005.smil#span_000561"> to </span><code xml:space="preserve" id="code_000128" smilref="Machine_Learning00005.smil#code_000128">.csv</code><span class="text" id="span_000562" smilref="Machine_Learning00005.smil#span_000562">, as shown in </span><a id="c05-c05-fig-anc-0009" href="#c05-c05-fig-0009" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0009">Figure 5-9</a><span class="text" id="span_000563" smilref="Machine_Learning00005.smil#span_000563">.</span></p>
              <figure id="figure_000042">
                <img class="center" src="images/c05f009.jpg" alt="image" id="img_000052" />
                <figcaption id="figcaption_000031">
                  <p xml:space="preserve" id="p_000295"><span class="figureLabel" id="span_000564"><a id="c05-c05-fig-0009" href="#c05-c05-fig-anc-0009" external="false"><strong id="strong_000175" smilref="Machine_Learning00005.smil#strong_000175">Figure 5-9</strong></a></span><span class="text" id="span_000565" smilref="Machine_Learning00005.smil#span_000565"> Weka File dialog box</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0063" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0063">You see the data loaded with the basic representation of the relation and attribute information.</p>
            </level3>
            <level3 id="level3_000097">
              <h3 xml:space="preserve" id="h3_000097" smilref="Machine_Learning00005.smil#h3_000097">Configuring the Multilayer Perceptron</h3>
              <p xml:space="preserve" id="p_000296" smilref="Machine_Learning00005.smil#p_000296">The neural network function of Weka comes with its own graphic user interface. When run, you can see the graphical representation of the neural network.</p>
              <p id="c05-c05-para-0065" xml:space="preserve"><span class="text" id="span_000566" smilref="Machine_Learning00005.smil#span_000566">Click the Classify panel. Where the default classifier is ZeroR, click Choose and change it to MultilayerPerceptron (see </span><a id="c05-c05-fig-anc-0010" href="#c05-c05-fig-0010" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0010">Figure 5-10</a><span class="text" id="span_000567" smilref="Machine_Learning00005.smil#span_000567">), which is in the Functions branch of the tree listing.</span></p>
              <figure id="figure_000043">
                <img class="center" src="images/c05f010.jpg" alt="image" id="img_000053" />
                <figcaption id="figcaption_000032">
                  <p xml:space="preserve" id="p_000297"><span class="figureLabel" id="span_000568"><a id="c05-c05-fig-0010" href="#c05-c05-fig-anc-0010" external="false"><strong id="strong_000176" smilref="Machine_Learning00005.smil#strong_000176">Figure 5-10</strong></a></span> <pagenum epub:type="pagebreak" id="p104" page="normal" smilref="Machine_Learning00005.smil#p104">104</pagenum><span class="text" id="span_000569" smilref="Machine_Learning00005.smil#span_000569">Changing the classifier</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0066" xml:space="preserve"><span class="text" id="span_000570" smilref="Machine_Learning00005.smil#span_000570">You see the classifier change to MultilayerPerceptron with a lot of options next to it. If you click that line, a window of options opens, as shown in </span><a id="c05-c05-fig-anc-0011" href="#c05-c05-fig-0011" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0011">Figure 5-11</a><span class="text" id="span_000571" smilref="Machine_Learning00005.smil#span_000571">.</span></p>
              <figure id="figure_000044">
                <img class="center" src="images/c05f011.jpg" alt="image" id="img_000054" />
                <figcaption id="figcaption_000033">
                  <p xml:space="preserve" id="p_000298"><span class="figureLabel" id="span_000572"><a id="c05-c05-fig-0011" href="#c05-c05-fig-anc-0011" external="false"><strong id="strong_000177" smilref="Machine_Learning00005.smil#strong_000177">Figure 5-11</strong></a></span><span class="text" id="span_000573" smilref="Machine_Learning00005.smil#span_000573"> Options dialog box for MultilayerPerceptron</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p105" page="normal" smilref="Machine_Learning00005.smil#p105">105</pagenum>
              <p id="c05-c05-para-0067" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0067">Change the GUI setting to True. This setting makes the neural network display in a graphic form; the display is also interactive, and you can change the network. If the GUI setting is set to False, then Weka generates the network for you without your intervention.</p>
              <p id="c05-c05-para-0068" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0068">Although this version of the MultilayerPerceptron converts and handles your nominal values for you, it's still prudent to take the time to ensure that your data is prepared properly. The network autobuilds by default. If you want to create your own, then you can turn this off and craft the network by hand.</p>
              <p id="c05-c05-para-0069" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0069">There are a few values that are worth keeping an eye on before you let the network do its training.</p>
              <level4 id="level4_000026">
                <h4 xml:space="preserve" id="h4_000026" smilref="Machine_Learning00005.smil#h4_000026">Learning Rate</h4>
                <p xml:space="preserve" id="p_000299" smilref="Machine_Learning00005.smil#p_000299">The amount the weights are updated is defaulted at 0.3. If that seems a little heavy or too light, then you can adjust as desired.</p>
              </level4>
              <level4 id="level4_000027">
                <h4 xml:space="preserve" id="h4_000027" smilref="Machine_Learning00005.smil#h4_000027">Hidden Layers</h4>
                <p xml:space="preserve" id="p_000300" smilref="Machine_Learning00005.smil#p_000300">You can define how many hidden layers the neural network will have. By default, Weka builds four (attributes and classes/2) (set to “a”), but you can also have just the attributes (“i”), the classes (“o”) and the attributes and classes complete (“t”).</p>
              </level4>
              <level4 id="level4_000028">
                <h4 xml:space="preserve" id="h4_000028" smilref="Machine_Learning00005.smil#h4_000028">Training Time</h4>
                <p xml:space="preserve" id="p_000301" smilref="Machine_Learning00005.smil#p_000301">The number of epochs through which Weka iterates during training is set to 500. The higher the number, the lower the error rate will be. As you'll see in a moment, this can give varying results in the output.</p>
                <p id="c05-c05-para-0073" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0073">When you are happy with the options, you can click OK and go back to the Classify window.</p>
              </level4>
            </level3>
            <level3 id="level3_000098">
              <h3 xml:space="preserve" id="h3_000098" smilref="Machine_Learning00005.smil#h3_000098">Training the Network</h3>
              <p xml:space="preserve" id="p_000302" smilref="Machine_Learning00005.smil#p_000302">You have to do a few runs of neural networks to find the sweet spot where the network is coming up with good classifications. With 100 rows of data, you're not going to be solving much of any worth; regardless, it gives you an idea of how it works.</p>
              <p id="c05-c05-para-0075" xml:space="preserve"><span class="text" id="span_000574" smilref="Machine_Learning00005.smil#span_000574">Make sure the test options are set to use the whole training set. The cross-validation is fine, but it ends up running the training through all ten folds, and that can get time consuming when you just want to test. Click Start, and the neural network window shown in </span><a id="c05-c05-fig-anc-0012" href="#c05-c05-fig-0012" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0012">Figure 5-12</a><span class="text" id="span_000575" smilref="Machine_Learning00005.smil#span_000575"> displays.</span></p>
              <figure id="figure_000045">
                <img class="center" src="images/c05f012.jpg" alt="image" id="img_000055" />
                <figcaption id="figcaption_000034">
                  <p xml:space="preserve" id="p_000303"><span class="figureLabel" id="span_000576"><a id="c05-c05-fig-0012" href="#c05-c05-fig-anc-0012" external="false"><strong id="strong_000178" smilref="Machine_Learning00005.smil#strong_000178">Figure 5-12</strong></a></span><span class="text" id="span_000577" smilref="Machine_Learning00005.smil#span_000577"> Neural network GUI window</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p106" page="normal" smilref="Machine_Learning00005.smil#p106">106</pagenum>
              <p id="c05-c05-para-0076" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0076">Click Start, and you see the epoch count rise and the error rate decrease. If you click Accept by accident, then no data will have been classified and the results will be wrong.</p>
              <p id="c05-c05-para-0077" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0077">After the neural network has run, click the Accept button and you will be returned to the classification output screen.</p>
              <p id="c05-c05-para-0078" xml:space="preserve"><span class="text" id="span_000578" smilref="Machine_Learning00005.smil#span_000578">The full classifier output gives the output for the hidden layer nodes. Nodes 0, 1, 2, and 3 and the four nodes on the right side of </span><a href="#c05-c05-fig-0012" external="false" id="a_000286" smilref="Machine_Learning00005.smil#a_000286">Figure 5-12</a><span class="text" id="span_000579" smilref="Machine_Learning00005.smil#span_000579"> are the output connections are the output connections. The class attributes for classification are shown as bike, car, bus, or truck on the right hand side of the neural network output (refer to </span><a href="#c05-c05-fig-0012" external="false" id="a_000287" smilref="Machine_Learning00005.smil#a_000287">Figure 5-12</a><span class="text" id="span_000580" smilref="Machine_Learning00005.smil#span_000580">).</span></p>
              <p xml:space="preserve" id="p_000304"><code class="preserve-whitespace" xml:space="preserve" id="code_000129" smilref="Machine_Learning00005.smil#code_000129">Sigmoid Node 0
    Inputs    Weights
    Threshold    0.018993883149676594
    Node 4    -0.04038638643499096
    Node 5    0.0065483634965212145
    Node 6    -0.03873854654480489
Sigmoid Node 1
    Inputs    Weights
    Threshold    -0.0451840582741909
    Node 4    -0.002851224687941599
    Node 5    -0.012455737520358182
    Node 6    -0.0491382673800735
Sigmoid Node 2
    Inputs    Weights
    Threshold    -0.010479295335213488
    Node 4    0.02129170595398988
    Node 5    0.02877248387280648
    Node 6    -0.001813155428890656
Sigmoid Node 3
    Inputs    Weights
    Threshold    0.02680212410425596
    Node 4    0.006810392393573984
    Node 5    -0.04968676115705444
    Node 6    -0.015015642691489917</code></p>
              <p id="c05-c05-para-0079" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0079">Nodes 4, 5, and 6 comprise the hidden layer that takes the input from the input attributes for wheels, chassis, and passenger count.</p>
              <p xml:space="preserve" id="p_000305"><code class="preserve-whitespace" xml:space="preserve" id="code_000130" smilref="Machine_Learning00005.smil#code_000130">Sigmoid Node 4
    Inputs    Weights
    Threshold    0.011850776365702677
    Attrib wheels    0.0429940506718635
    Attrib chassis    -0.035625493582980464
    Attrib pax    -0.021284810000068835
Sigmoid Node 5
    Inputs    Weights
    Threshold    0.011165074786232076
    Attrib wheels    -0.018370069737576836
    Attrib chassis    -0.030938315802372954
    Attrib pax    0.01567513412449774
Sigmoid Node 6
    Inputs    Weights
    Threshold    -0.04753959806853169
    Attrib wheels    -0.00211881373779247
    Attrib chassis    0.040431974347463484
    Attrib pax    -0.017943250444400316</code></p>
              <pagenum epub:type="pagebreak" id="p107" page="normal" smilref="Machine_Learning00005.smil#p107">107</pagenum>
              <p id="c05-c05-para-0080" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0080">Each node has the input type and the weight values of the corresponding input node.</p>
              <p id="c05-c05-para-0081" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0081">The summary shows how many instances have been correctly classified, along with other values for the error data if it has occurred.</p>
              <p id="c05-c05-para-0082" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0082">In the last section, you can see how the classification counts added up in the Confusion Matrix.</p>
              <p xml:space="preserve" id="p_000306"><code class="preserve-whitespace" xml:space="preserve" id="code_000131" smilref="Machine_Learning00005.smil#code_000131">=== Confusion Matrix ===
  a  b  c  d   &lt;-- classified as
 33  0  0  0 |  a = Bus
  0 27  0  0 |  b = Car
  0  0 20  0 |  c = Bike
  0  0  0 20 |  d = Truck</code></p>
            </level3>
            <level3 id="level3_000099">
              <h3 xml:space="preserve" id="h3_000099" smilref="Machine_Learning00005.smil#h3_000099">Altering the Network</h3>
              <pagenum epub:type="pagebreak" id="p108" page="normal" smilref="Machine_Learning00005.smil#p108">108</pagenum>
              <p xml:space="preserve" id="p_000307" smilref="Machine_Learning00005.smil#p_000307">With the GUI option set to True, you can add nodes and also remove input paths to parts of the hidden layer. If you make any changes you need to retrain the neural network; the updated network will display in the GUI.</p>
              <level4 id="level4_000029">
                <h4 xml:space="preserve" id="h4_000029" smilref="Machine_Learning00005.smil#h4_000029">Which Bit Is Which?</h4>
                <p xml:space="preserve" id="p_000308" smilref="Machine_Learning00005.smil#p_000308">Working from left to right on the GUI, you see the raw input nodes as labels in the yellow boxes. Red dots are the hidden layer nodes, and the orange dots are the output nodes. The orange labels are the classes with which the orange dot nodes are associated.</p>
              </level4>
              <level4 id="level4_000030">
                <h4 xml:space="preserve" id="h4_000030" smilref="Machine_Learning00005.smil#h4_000030">Adding Nodes</h4>
                <p xml:space="preserve" id="p_000309" smilref="Machine_Learning00005.smil#p_000309">You can add a new node by clicking the GUI. The red dot appears to signify a hidden layer node. It won't be connected to anything, unless you have already selected nodes in the GUI.</p>
              </level4>
              <level4 id="level4_000031">
                <h4 xml:space="preserve" id="h4_000031" smilref="Machine_Learning00005.smil#h4_000031">Connecting Nodes</h4>
                <p xml:space="preserve" id="p_000310" smilref="Machine_Learning00005.smil#p_000310">With the node selected, you can click on another node to see the connection being made.</p>
              </level4>
              <level4 id="level4_000032">
                <h4 xml:space="preserve" id="h4_000032" smilref="Machine_Learning00005.smil#h4_000032">Removing Connections</h4>
                <p xml:space="preserve" id="p_000311" smilref="Machine_Learning00005.smil#p_000311">To remove a connection, select one of the connected nodes and then right-click the other connected node. The connecting line disappears.</p>
              </level4>
              <level4 id="level4_000033">
                <h4 xml:space="preserve" id="h4_000033" smilref="Machine_Learning00005.smil#h4_000033">Removing Nodes</h4>
                <p xml:space="preserve" id="p_000312" smilref="Machine_Learning00005.smil#p_000312">Right-clicking a node removes it and all the connections to it. Be careful to make sure that there aren't any other selected nodes, otherwise they, and their connections, will be removed, too.</p>
              </level4>
            </level3>
            <level3 id="level3_000100">
              <h3 xml:space="preserve" id="h3_000100" smilref="Machine_Learning00005.smil#h3_000100">Increasing the Test Data Size</h3>
              <p xml:space="preserve" id="p_000313"><span class="text" id="span_000581" smilref="Machine_Learning00005.smil#span_000581">Within the </span><code xml:space="preserve" id="code_000132" smilref="Machine_Learning00005.smil#code_000132">for</code><span class="text" id="span_000582" smilref="Machine_Learning00005.smil#span_000582"> loop of the </span><code xml:space="preserve" id="code_000133" smilref="Machine_Learning00005.smil#code_000133">MLPData.java</code><span class="text" id="span_000583" smilref="Machine_Learning00005.smil#span_000583"> program you created earlier in the chapter, change the loop count from 100 rows to 100,000 rows. Go back to the Preprocess window and load the new CSV file. It might take some time to load.</span></p>
              <pagenum epub:type="pagebreak" id="p109" page="normal" smilref="Machine_Learning00005.smil#p109">109</pagenum>
              <p id="c05-c05-para-0090" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0090">Now, go back to the Classify window and rerun the neural network. When the GUI window opens, you see the network looks the same as before in terms of the hidden layers. Where you had 500 epochs running against the 100 rows of data, you now have the same epoch number against all 100,000 rows of training data.</p>
              <p id="c05-c05-para-0091" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0091">Click Start and the training begins. You'll notice a difference in response time from the GUI as it trains all 100,000 rows. The main thing to look at is the errors per epoch; the number keeps reducing to the point where you get minute changes per 100 to 200 epochs. By the time the training has finished, you will have a very accurate training model.</p>
              <p id="c05-c05-para-0092" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0092">All this comes at a price of memory, though. My training set took more than two minutes:</p>
              <p xml:space="preserve" id="p_000314"><code class="preserve-whitespace" xml:space="preserve" id="code_000134" smilref="Machine_Learning00005.smil#code_000134">Time taken to build model: 124.52 seconds</code></p>
              <p id="c05-c05-para-0093" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0093">Two minutes isn't a huge amount of time in the grand scheme of things, but as I previously mentioned in regard to gathering data for neural networks, adding more variables gives the curse of dimensionality.</p>
              <p id="c05-c05-para-0094" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0094">The more rows you can use for training, the better the prediction results will be. There is a point in time to figure out when there's too much training data against the errors per epoch. It takes some practice (and everyone's data is different, so there's no hard or fast rule), and it's a case of experiment, measure, and try again.</p>
            </level3>
          </level2>
          <level2 id="level2_000047">
            <h2 id="c05-c05_level1_6" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05_level1_6">Implementing a Neural Network in Java</h2>
            <p xml:space="preserve" id="p_000315" smilref="Machine_Learning00005.smil#p_000315">With the Weka API, you can build a neural network with the same multilayer perceptron that Weka uses within the GUI.</p>
            <level3 id="level3_000101">
              <h3 xml:space="preserve" id="h3_000101" smilref="Machine_Learning00005.smil#h3_000101">Create the Project</h3>
              <p xml:space="preserve" id="p_000316"><span class="text" id="span_000584" smilref="Machine_Learning00005.smil#span_000584">Select File →New →Java Project and call it </span><code xml:space="preserve" id="code_000135" smilref="Machine_Learning00005.smil#code_000135">MLPProcessor</code><span class="text" id="span_000585" smilref="Machine_Learning00005.smil#span_000585">, as shown in </span><a id="c05-c05-fig-anc-0013" href="#c05-c05-fig-0013" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0013">Figure 5-13</a><span class="text" id="span_000586" smilref="Machine_Learning00005.smil#span_000586">.</span></p>
              <figure id="figure_000046">
                <img class="center" src="images/c05f013.jpg" alt="image" id="img_000056" />
                <figcaption id="figcaption_000035">
                  <p xml:space="preserve" id="p_000317"><span class="figureLabel" id="span_000587"><a id="c05-c05-fig-0013" href="#c05-c05-fig-anc-0013" external="false"><strong id="strong_000179" smilref="Machine_Learning00005.smil#strong_000179">Figure 5-13</strong></a></span> <pagenum epub:type="pagebreak" id="p110" page="normal" smilref="Machine_Learning00005.smil#p110">110</pagenum><span class="text" id="span_000588" smilref="Machine_Learning00005.smil#span_000588">Eclipse New Project dialog box</span></p>
                </figcaption>
              </figure>
              <p id="c05-c05-para-0097" xml:space="preserve"><span class="text" id="span_000589" smilref="Machine_Learning00005.smil#span_000589">You need to tell Eclipse where the Weka API is; it's called </span><code xml:space="preserve" id="code_000136" smilref="Machine_Learning00005.smil#code_000136">weka.jar</code><span class="text" id="span_000590" smilref="Machine_Learning00005.smil#span_000590">. On Mac OS X machines, Weka is usually installed within the Applications directory. The location on Windows machines varies depending on the specific operating system and Weka installation. In most cases it will be </span><code xml:space="preserve" id="code_000137" smilref="Machine_Learning00005.smil#code_000137">/Program Files (x86)/Weka-3-6/weka.jar</code><span class="text" id="span_000591" smilref="Machine_Learning00005.smil#span_000591">.</span></p>
              <p id="c05-c05-para-0098" xml:space="preserve"><span class="text" id="span_000592" smilref="Machine_Learning00005.smil#span_000592">With the WekaCluster project selected, select File →Properties and look for the Java Build Path. Then click the Libraries tab. Add the external </span><code xml:space="preserve" id="code_000138" smilref="Machine_Learning00005.smil#code_000138">jar</code><span class="text" id="span_000593" smilref="Machine_Learning00005.smil#span_000593"> file by clicking Add External JARs, then in the file dialog box find the </span><code xml:space="preserve" id="code_000139" smilref="Machine_Learning00005.smil#code_000139">weka.jar</code><span class="text" id="span_000594" smilref="Machine_Learning00005.smil#span_000594"> file, as shown in </span><a id="c05-c05-fig-anc-0014" href="#c05-c05-fig-0014" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0014">Figure 5-14</a><span class="text" id="span_000595" smilref="Machine_Learning00005.smil#span_000595">.</span></p>
              <figure id="figure_000047">
                <img class="center" src="images/c05f014.jpg" alt="image" id="img_000057" />
                <figcaption id="figcaption_000036">
                  <p xml:space="preserve" id="p_000318"><span class="figureLabel" id="span_000596"><a id="c05-c05-fig-0014" href="#c05-c05-fig-anc-0014" external="false"><strong id="strong_000180" smilref="Machine_Learning00005.smil#strong_000180">Figure 5-14</strong></a></span><span class="text" id="span_000597" smilref="Machine_Learning00005.smil#span_000597"> Adding external jars</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p111" page="normal" smilref="Machine_Learning00005.smil#p111">111</pagenum>
              <p id="c05-c05-para-0099" xml:space="preserve"><span class="text" id="span_000598" smilref="Machine_Learning00005.smil#span_000598">The last thing to do is create a new class called </span><code xml:space="preserve" id="code_000140" smilref="Machine_Learning00005.smil#code_000140">MLPProcessor.java</code><span class="text" id="span_000599" smilref="Machine_Learning00005.smil#span_000599"> (using File →New → Class), as shown in </span><a id="c05-c05-fig-anc-0015" href="#c05-c05-fig-0015" external="false" smilref="Machine_Learning00005.smil#c05-c05-fig-anc-0015">Figure 5-15</a><span class="text" id="span_000600" smilref="Machine_Learning00005.smil#span_000600">.</span></p>
              <figure id="figure_000048">
                <img class="center" src="images/c05f015.jpg" alt="image" id="img_000058" />
                <figcaption id="figcaption_000037">
                  <p xml:space="preserve" id="p_000319"><span class="figureLabel" id="span_000601"><a id="c05-c05-fig-0015" href="#c05-c05-fig-anc-0015" external="false"><strong id="strong_000181" smilref="Machine_Learning00005.smil#strong_000181">Figure 5-15</strong></a></span><span class="text" id="span_000602" smilref="Machine_Learning00005.smil#span_000602"> Creating a new class file</span></p>
                </figcaption>
              </figure>
            </level3>
            <level3 id="level3_000102">
              <h3 xml:space="preserve" id="h3_000102" smilref="Machine_Learning00005.smil#h3_000102">The Code</h3>
              <p xml:space="preserve" id="p_000320" smilref="Machine_Learning00005.smil#p_000320">The actual Java is straightforward. You're going to do the following:</p>
              <list type="ul" id="list_000037">
                <li id="li_000323">
                  <span class="text" id="span_000603" smilref="Machine_Learning00005.smil#span_000603">Open the training data</span>
                  <code xml:space="preserve" id="code_000141" smilref="Machine_Learning00005.smil#code_000141">.arff</code>
                  <span class="text" id="span_000604" smilref="Machine_Learning00005.smil#span_000604">file.</span>
                </li>
                <li id="li_000324" smilref="Machine_Learning00005.smil#li_000324">Create a MultilayerPerceptron and set the same options as the Weka GUI example.</li>
                <li id="li_000325" smilref="Machine_Learning00005.smil#li_000325">Build the classifier.</li>
                <li id="li_000326" smilref="Machine_Learning00005.smil#li_000326">Load in some test data.</li>
                <li id="li_000327" smilref="Machine_Learning00005.smil#li_000327">Run an evaluation test with the test data against the trained data.</li>
              </list>
              <p id="c05-c05-para-0101" xml:space="preserve"><span class="text" id="span_000605" smilref="Machine_Learning00005.smil#span_000605">You need to create a small test data file to test against the model. In a text file called </span><code xml:space="preserve" id="code_000142" smilref="Machine_Learning00005.smil#code_000142">testdata.arff</code><span class="text" id="span_000606" smilref="Machine_Learning00005.smil#span_000606"> enter the following:</span></p>
              <p xml:space="preserve" id="p_000321"><code class="preserve-whitespace" xml:space="preserve" id="code_000143" smilref="Machine_Learning00005.smil#code_000143">@relation vehicledata
@attribute wheels numeric
@attribute chassis numeric
@attribute pax numeric
@attribute vtype {Bus,Car,Truck,Bike}
@data
18,25,2,Truck
8,21,24,Bus
18,27,2,Truck
1,1,1,Bike
7,23,21,Bus
18,20,1,Truck
8,16,30,Bus
18,28,2,Truck
7,18,36,Bus
8,21,27,Bus
5,2,4,Car
18,28,1,Truck
5,1,1,Car
1,1,1,Bike
18,27,1,Truck
5,1,1,Car
6,15,38,Bus
7,21,38,Bus
18,20,2,Truck
1,1,1,Bike
18,28,2,Truck
18,24,2,Truck
18,20,1,Truck
1,1,1,Bike
5,17,18,Bus
18,27,1,Truck
4,4,3,Car
18,21,1,Truck
5,2,3,Car
4,3,3,Car
18,23,1,Truck
5,20,30,Bus
5,3,3,Car
18,28,1,Truck
5,3,1,Car
9,13,19,Bus
1,1,1,Bike
18,26,2,Truck</code></p>
              <pagenum epub:type="pagebreak" id="p112" page="normal" smilref="Machine_Learning00005.smil#p112">112</pagenum>
              <p id="c05-c05-para-0102" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0102">After you've created the test file, use the following code:</p>
              <p xml:space="preserve" id="p_000322"><code class="preserve-whitespace" xml:space="preserve" id="code_000144"><strong id="strong_000182" smilref="Machine_Learning00005.smil#strong_000182">import</strong><span class="text" id="span_000607" smilref="Machine_Learning00005.smil#span_000607"> java.io.FileNotFoundException;
</span><strong id="strong_000183" smilref="Machine_Learning00005.smil#strong_000183">import</strong><span class="text" id="span_000608" smilref="Machine_Learning00005.smil#span_000608"> java.io.FileReader;
</span><strong id="strong_000184" smilref="Machine_Learning00005.smil#strong_000184">import</strong><span class="text" id="span_000609" smilref="Machine_Learning00005.smil#span_000609"> java.io.IOException;
</span><strong id="strong_000185" smilref="Machine_Learning00005.smil#strong_000185">import</strong><span class="text" id="span_000610" smilref="Machine_Learning00005.smil#span_000610"> weka.classifiers.Evaluation;
</span><strong id="strong_000186" smilref="Machine_Learning00005.smil#strong_000186">import</strong><span class="text" id="span_000611" smilref="Machine_Learning00005.smil#span_000611"> weka.classifiers.functions.MultilayerPerceptron;
</span><strong id="strong_000187" smilref="Machine_Learning00005.smil#strong_000187">import</strong><span class="text" id="span_000612" smilref="Machine_Learning00005.smil#span_000612"> weka.core.Instances;
</span><strong id="strong_000188" smilref="Machine_Learning00005.smil#strong_000188">import</strong><span class="text" id="span_000613" smilref="Machine_Learning00005.smil#span_000613"> weka.core.Utils;
</span><strong id="strong_000189" smilref="Machine_Learning00005.smil#strong_000189">public class</strong><span class="text" id="span_000614" smilref="Machine_Learning00005.smil#span_000614"> MLPProcessor {
    </span><strong id="strong_000190" smilref="Machine_Learning00005.smil#strong_000190">public</strong><span class="text" id="span_000615" smilref="Machine_Learning00005.smil#span_000615"> MLPProcessor() {
        </span><strong id="strong_000191" smilref="Machine_Learning00005.smil#strong_000191">try</strong><span class="text" id="span_000616" smilref="Machine_Learning00005.smil#span_000616"> {
            FileReader fr = </span><strong id="strong_000192" smilref="Machine_Learning00005.smil#strong_000192">new</strong><span class="text" id="span_000617" smilref="Machine_Learning00005.smil#span_000617"> FileReader("vehicledata.arff");
            Instances training = </span><strong id="strong_000193" smilref="Machine_Learning00005.smil#strong_000193">new</strong><span class="text" id="span_000618" smilref="Machine_Learning00005.smil#span_000618"> Instances(fr);
            training.setClassIndex(training.numAttributes() -1);
            MultilayerPerceptron mlp = </span><strong id="strong_000194" smilref="Machine_Learning00005.smil#strong_000194">new</strong><span class="text" id="span_000619" smilref="Machine_Learning00005.smil#span_000619"> MultilayerPerceptron();
            mlp.setOptions(Utils.</span><em id="em_000152" smilref="Machine_Learning00005.smil#em_000152">splitOptions</em><span class="text" id="span_000620" smilref="Machine_Learning00005.smil#span_000620">("-L 0.3 -M 0.2 -N 500 -V 0 -S 0 -E 20 -H 4"));
            mlp.buildClassifier(training);
            FileReader tr = </span><strong id="strong_000195" smilref="Machine_Learning00005.smil#strong_000195">new</strong><span class="text" id="span_000621" smilref="Machine_Learning00005.smil#span_000621"> FileReader("testdata.arff");
            Instances testdata = </span><strong id="strong_000196" smilref="Machine_Learning00005.smil#strong_000196">new</strong><span class="text" id="span_000622" smilref="Machine_Learning00005.smil#span_000622"> Instances(tr);
            testdata.setClassIndex(testdata.numAttributes() -1);
            Evaluation eval = </span><strong id="strong_000197" smilref="Machine_Learning00005.smil#strong_000197">new</strong><span class="text" id="span_000623" smilref="Machine_Learning00005.smil#span_000623"> Evaluation(training);
            eval.evaluateModel(mlp, testdata);
System.</span><em id="em_000153" smilref="Machine_Learning00005.smil#em_000153">out</em><span class="text" id="span_000624" smilref="Machine_Learning00005.smil#span_000624">.println(eval.toSummaryString("\nResults\n*******\n", </span><strong id="strong_000198" smilref="Machine_Learning00005.smil#strong_000198">false</strong><span class="text" id="span_000625" smilref="Machine_Learning00005.smil#span_000625">));
            tr.close();
            fr.close();
        } </span><strong id="strong_000199" smilref="Machine_Learning00005.smil#strong_000199">catch</strong><span class="text" id="span_000626" smilref="Machine_Learning00005.smil#span_000626"> (FileNotFoundException e) {
            e.printStackTrace();
        } </span><strong id="strong_000200" smilref="Machine_Learning00005.smil#strong_000200">catch</strong><span class="text" id="span_000627" smilref="Machine_Learning00005.smil#span_000627"> (IOException e) {
            e.printStackTrace();
        } </span><strong id="strong_000201" smilref="Machine_Learning00005.smil#strong_000201">catch</strong><span class="text" id="span_000628" smilref="Machine_Learning00005.smil#span_000628"> (Exception e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000202" smilref="Machine_Learning00005.smil#strong_000202">public static void</strong><span class="text" id="span_000629" smilref="Machine_Learning00005.smil#span_000629"> main(String[] args) {
        MLPProcessor mlp = </span><strong id="strong_000203" smilref="Machine_Learning00005.smil#strong_000203">new</strong><span class="text" id="span_000630" smilref="Machine_Learning00005.smil#span_000630"> MLPProcessor();
    }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p113" page="normal" smilref="Machine_Learning00005.smil#p113">113</pagenum>
              <p id="c05-c05-para-0103" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0103">The actual neural network is taken care of within three lines of code. Create the MultilayerPerceptron, set which class you want to determine, and then build the classifier. The rest of the code is loading the training and test data in.</p>
            </level3>
            <level3 id="level3_000103">
              <h3 xml:space="preserve" id="h3_000103" smilref="Machine_Learning00005.smil#h3_000103">Converting from CSV to Arff</h3>
              <pagenum epub:type="pagebreak" id="p114" page="normal" smilref="Machine_Learning00005.smil#p114">114</pagenum>
              <p xml:space="preserve" id="p_000323"><span class="text" id="span_000631" smilref="Machine_Learning00005.smil#span_000631">CSV files don't contain the data that Weka needs. You could implement the </span><code xml:space="preserve" id="code_000145" smilref="Machine_Learning00005.smil#code_000145">CSVLoader</code><span class="text" id="span_000632" smilref="Machine_Learning00005.smil#span_000632"> class, but I prefer to know that the </span><code xml:space="preserve" id="code_000146" smilref="Machine_Learning00005.smil#code_000146">.arff</code><span class="text" id="span_000633" smilref="Machine_Learning00005.smil#span_000633"> data is ready for use. It also makes it easier for others to decode the data model if they need to.</span></p>
              <p id="c05-c05-para-0105" xml:space="preserve"><span class="text" id="span_000634" smilref="Machine_Learning00005.smil#span_000634">From the command line, you can convert the data from a </span><code xml:space="preserve" id="code_000147" smilref="Machine_Learning00005.smil#code_000147">.csv</code><span class="text" id="span_000635" smilref="Machine_Learning00005.smil#span_000635"> file to </span><code xml:space="preserve" id="code_000148" smilref="Machine_Learning00005.smil#code_000148">.arff</code><span class="text" id="span_000636" smilref="Machine_Learning00005.smil#span_000636"> in one command.</span></p>
              <p xml:space="preserve" id="p_000324"><code class="preserve-whitespace" xml:space="preserve" id="code_000149" smilref="Machine_Learning00005.smil#code_000149">java -cp /Applications/weka-3-6-10/weka.jar weka.core.converters.CSVLoader vehicledata.csv &gt; vehicledata.arff</code></p>
              <p id="c05-c05-para-0106" xml:space="preserve"><span class="text" id="span_000637" smilref="Machine_Learning00005.smil#span_000637">If you inspect the </span><code xml:space="preserve" id="code_000150" smilref="Machine_Learning00005.smil#code_000150">.arff</code><span class="text" id="span_000638" smilref="Machine_Learning00005.smil#span_000638"> file, you see the attribute information set up for you.</span></p>
              <p xml:space="preserve" id="p_000325"><code class="preserve-whitespace" xml:space="preserve" id="code_000151" smilref="Machine_Learning00005.smil#code_000151">@relation vehicledata
@attribute wheels numeric
@attribute chassis numeric
@attribute pax numeric
@attribute vtype {Bus,Car,Truck,Bike}
@data
6,20,39,Bus
8,23,11,Bus
5,3,1,Car
4,3,4,Car
5,3,1,Car
4,18,37,Bus
18,23,2,Truck</code></p>
            </level3>
            <level3 id="level3_000104">
              <h3 xml:space="preserve" id="h3_000104" smilref="Machine_Learning00005.smil#h3_000104">Running the Neural Network</h3>
              <p xml:space="preserve" id="p_000326" smilref="Machine_Learning00005.smil#p_000326">The code listing doesn't include any output messages while it's running, with the exception of the output of the evaluation. I say this because the training data could have 100,000 rows in it, and it's going take a few minutes to run.</p>
              <p id="c05-c05-para-0108" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0108">Run the class with Run→Run from Eclipse, and it starts to generate the model. After a while, you see the output from the evaluation.</p>
              <p xml:space="preserve" id="p_000327"><code class="preserve-whitespace" xml:space="preserve" id="code_000152" smilref="Machine_Learning00005.smil#code_000152">Results
======
Correctly Classified Instances          38              100      %
Incorrectly Classified Instances         0                0      %
Kappa statistic                          1
Mean absolute error                      0.0003
Root mean squared error                  0.0004
Relative absolute error                  0.0795 %
Root relative squared error              0.0949 %
Total Number of Instances               38 </code></p>
              <pagenum epub:type="pagebreak" id="p115" page="normal" smilref="Machine_Learning00005.smil#p115">115</pagenum>
              <p id="c05-c05-para-0109" xml:space="preserve"><span class="text" id="span_000639" smilref="Machine_Learning00005.smil#span_000639">Instances can be easily classified by using the multilayer perceptron </span><code xml:space="preserve" id="code_000153" smilref="Machine_Learning00005.smil#code_000153">classifyInstance()</code><span class="text" id="span_000640" smilref="Machine_Learning00005.smil#span_000640"> method, which takes in a single </span><code xml:space="preserve" id="code_000154" smilref="Machine_Learning00005.smil#code_000154">Instance</code><span class="text" id="span_000641" smilref="Machine_Learning00005.smil#span_000641"> class and outputs a numeric representation of the result. This result corresponds to your output class in the </span><code xml:space="preserve" id="code_000155" smilref="Machine_Learning00005.smil#code_000155">.arff</code><span class="text" id="span_000642" smilref="Machine_Learning00005.smil#span_000642"> training file.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000048">
            <h2 id="c05-c05_level1_7" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05_level1_7">Summary</h2>
            <p xml:space="preserve" id="p_000328" smilref="Machine_Learning00005.smil#p_000328">Perhaps it's my English nature, but I find it slightly ironic that I could spend so few pages on a subject so massive. It's about the brain, neurons, and all that kind of stuff!</p>
            <p id="c05-c05-para-0111" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0111">Seriously though, this chapter should have given you a basic grounding on how neural networks work, including a couple of examples in Weka and Java.</p>
            <p id="c05-c05-para-0112" xml:space="preserve" smilref="Machine_Learning00005.smil#c05-c05-para-0112">The key to a successful neural network project comes down to the data preparation. Too little preparation and the network won't predict right; too much and you hit memory issues. It's about finding the right set of data, the right quantity, and the right training method.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c06">
        <section epub:type="chapter" id="section_000007">
          <header id="header_000006">
            <h1 id="c06-c6" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c6">Chapter 6 Association Rules Learning</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p117" page="normal" smilref="Machine_Learning00005.smil#p117">117</pagenum>
          <p xml:space="preserve" id="p_000329" smilref="Machine_Learning00005.smil#p_000329">Among the machine learning methods available, association rules learning is probably the most used. From point-of-sale systems to web page usage mining, this method is employed frequently to examine transactions. It finds out the interesting connections among elements of the data and the sequence (behaviors) that led up to some correlated result.</p>
          <p id="c06-c06-para-0002" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0002">This chapter describes how association rules learning methods work and also goes through an example using Apache Mahout for mining baskets of purchases. This chapter also touches on the myth, the reality, and the legend of using this type of machine learning.</p>
          <level2 id="level2_000049">
            <h2 id="c06-c06_level1_1" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06_level1_1">Where Is Association Rules Learning Used?</h2>
            <p xml:space="preserve" id="p_000330"><span class="text" id="span_000643" smilref="Machine_Learning00005.smil#span_000643">The retail industry is tripping over itself to give you, the customer, offers on merchandise it </span><em id="em_000154" smilref="Machine_Learning00005.smil#em_000154">thinks</em><span class="text" id="span_000644" smilref="Machine_Learning00005.smil#span_000644"> you will buy. In order to do that, though, it needs to know what you've bought previously and what other customers, similar to you, have bought. Brands such as Tesco and Target thrive on basket analysis to see what you've purchased previously. If you think the amount of content that Twitter produces is big, then just think about point-of-sale data; it's another world. Some </span><pagenum epub:type="pagebreak" id="p118" page="normal" smilref="Machine_Learning00005.smil#p118">118</pagenum><span class="text" id="span_000645" smilref="Machine_Learning00005.smil#span_000645">supermarkets fail to adopt this technology and never look into baskets, much to their competitive disadvantage. If you can analyze baskets and act on the results, then you can see how to increase bottom-line revenue.</span></p>
            <p id="c06-c06-para-0004" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0004">Association rules learning isn't only for retail and supermarkets, though. In the field of web analytics, association rules learning is used to track, learn, and predict user behavior on websites.</p>
            <p id="c06-c06-para-0005" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0005">There are huge amounts of biological data that are being mined to gain knowledge. Bioinformatics uses association rules learning for protein and gene sequencing. It's on a smaller scale compared to something like computational biology, as it homes in on specifics compared to something like DNA. So, studies on mutations of genomes are part of a branch of bioinformatics that's probably working with it.</p>
            <level3 id="level3_000105">
              <h3 xml:space="preserve" id="h3_000105" smilref="Machine_Learning00005.smil#h3_000105">Web Usage Mining</h3>
              <p xml:space="preserve" id="p_000331" smilref="Machine_Learning00005.smil#p_000331">Knowing which pages a user is looking at and then suggesting which pages might be of interest to the user is commonplace to keep a website more compelling and “sticky.” For this type of mining, you require a mechanism for knowing which user is looking at which pages; the user could be identified by a user session, a cookie ID, or a previous user log in where sites require users to log in to see the information.</p>
              <p id="c06-c06-para-0007" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0007">If you have access to your website log files then there is opportunity for you to mine the information. Many companies use the likes of Google Analytics as it saves them mining logs themselves, but it's worthwhile doing your own analysis if you can.</p>
              <p id="c06-c06-para-0008" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0008">The basic log file, for example, has information against which you could run some basic association rules learning. Looking at the Apache Common Log Format (CLF) you can see the IP address of the request and the file it was trying to access:</p>
              <p xml:space="preserve" id="p_000332"><code class="preserve-whitespace" xml:space="preserve" id="code_000156" smilref="Machine_Learning00005.smil#code_000156">86.78.88.189 - thisuserid [10/May/2014:13:55:59 -0700] "GET /myinterestingarticle.html HTTP/1.0" 200 2326</code></p>
              <p id="c06-c06-para-0009" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0009">By extracting the URL and the IP address, the association rules could eventually suggest related content on your site that would be of interest to the user.</p>
            </level3>
            <level3 id="level3_000106">
              <h3 xml:space="preserve" id="h3_000106" smilref="Machine_Learning00005.smil#h3_000106">Beer and Diapers</h3>
              <p xml:space="preserve" id="p_000333" smilref="Machine_Learning00005.smil#p_000333">It is written on parchment dating back many years, the parable of the beer and the diapers (or nappies, as I will always call them).</p>
              <blockquote id="blockquote_000003">
                <pagenum epub:type="pagebreak" id="p119" page="normal" smilref="Machine_Learning00005.smil#p119">119</pagenum>
                <p xml:space="preserve" id="p_000334" smilref="Machine_Learning00005.smil#p_000334">Tis written on this day that the American male of the species would frequent the larger markets of super the day prior to the Sabbath. Newly attired with sleeping eyes and new child, said American male would buy device of child's dropping catching of cloth and safety pin, when, lo, he spotteth the beer of delights full appreciating he shall not make it to the inn after evensong, such be his newly acquired fatherly role. And Mart of Wal did look upon this repeated behavior and move the aisles according to the scriptures of the product of placement, thus increasing the bottom line.</p>
              </blockquote>
              <p id="c06-c06-para-0012" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0012">This story has been preached by marketing departments the world over (possibly not in the style presented here), and it's been used in everything from keynotes to short talks, from hackathons to late night codejams. However, it's a case of fact mixed with myth.</p>
              <p id="c06-c06-para-0013" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0013">When he was CEO of a company called Mindmeld, Thomas Blischok was also on the panel of a webcast on the past, present, and future of data mining and had managed the study on data that spawned the beer and nappies story. The study went back to the early 1990s when his team was looking at the basket data for Osco Drug. They did see a correlation on basket purchases between 5:00 and 7:00 p.m. and presented the findings to their client.</p>
              <p id="c06-c06-para-0014" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0014">After that point, there's some confusion about where the story actually goes. Many versions are basically myth and legend, they've generated great chat and debate around the water cooler for years and will continue to do so.</p>
              <p id="c06-c06-para-0015" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0015">The myth has now been superseded by the privacy-fearing consumer story known as the “Target can predict whether I'm pregnant or not” scenario. I, for one, have two reasons why Target could never predict my outcome: I've never shopped there, and it's biologically impossible. You don't need a two-node decision tree to figure that out. (Read Chapter 3, “Working with Decision Trees” for more information on that subject.)</p>
              <sidebar render="required" id="sidebar_000006">
                <div class="top hr" id="div_000006" />
                <level2 class="feature2" id="level2_000050">
                  <h2 xml:space="preserve" id="h2_000010" smilref="Machine_Learning00005.smil#h2_000010">Note</h2>
                  <p xml:space="preserve" id="p_000335"><span class="text" id="span_000646" smilref="Machine_Learning00005.smil#span_000646">For the full story on the Beer and Diapers legend, have a look at D.J. Power's article from November 2002 at </span><code xml:space="preserve" id="code_000157"><a href="http://www.dssresources.com/newsletters/66.php" external="true" id="a_000288" smilref="Machine_Learning00005.smil#a_000288">http://www.dssresources.com/newsletters/66.php</a></code><span class="text" id="span_000647" smilref="Machine_Learning00005.smil#span_000647">. The myth will live on forever, I'm sure (especially if you're in marketing), and it makes for good reading.</span></p>
                </level2>
              </sidebar>
            </level3>
          </level2>
          <level2 id="level2_000051">
            <h2 id="c06-c06_level1_2" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06_level1_2">How Association Rules Learning Works</h2>
            <p xml:space="preserve" id="p_000336" smilref="Machine_Learning00005.smil#p_000336">The basket analysis scenario is a good example to explain with, so I'll continue with it. Consider the following table of transactions:</p>
            <figure id="figure_000049">
              <table border="1" id="table_000016">
                <tr id="tr_000063">
                  <td class="left" rowspan="1" colspan="1" id="td_000180" smilref="Machine_Learning00005.smil#td_000180">TransactionID</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000181" smilref="Machine_Learning00005.smil#td_000181">Product1</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000182" smilref="Machine_Learning00005.smil#td_000182">Product2</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000183" smilref="Machine_Learning00005.smil#td_000183">Product3</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000184" smilref="Machine_Learning00005.smil#td_000184">Product4</td>
                </tr>
                <tr id="tr_000064">
                  <td class="left" rowspan="1" colspan="1" id="td_000185" smilref="Machine_Learning00005.smil#td_000185">1</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000186" smilref="Machine_Learning00005.smil#td_000186">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000187" smilref="Machine_Learning00005.smil#td_000187">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000188" smilref="Machine_Learning00005.smil#td_000188">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000189" smilref="Machine_Learning00005.smil#td_000189">False</td>
                </tr>
                <tr id="tr_000065">
                  <td class="left" rowspan="1" colspan="1" id="td_000190" smilref="Machine_Learning00005.smil#td_000190">2</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000191" smilref="Machine_Learning00005.smil#td_000191">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000192" smilref="Machine_Learning00005.smil#td_000192">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000193" smilref="Machine_Learning00005.smil#td_000193">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000194" smilref="Machine_Learning00005.smil#td_000194">False</td>
                </tr>
                <tr id="tr_000066">
                  <td class="left" rowspan="1" colspan="1" id="td_000195" smilref="Machine_Learning00005.smil#td_000195">3</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000196" smilref="Machine_Learning00005.smil#td_000196">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000197" smilref="Machine_Learning00005.smil#td_000197">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000198" smilref="Machine_Learning00005.smil#td_000198">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000199" smilref="Machine_Learning00005.smil#td_000199">True</td>
                </tr>
                <tr id="tr_000067">
                  <td class="left" rowspan="1" colspan="1" id="td_000200" smilref="Machine_Learning00005.smil#td_000200">4</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000201" smilref="Machine_Learning00005.smil#td_000201">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000202" smilref="Machine_Learning00005.smil#td_000202">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000203" smilref="Machine_Learning00005.smil#td_000203">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000204" smilref="Machine_Learning00005.smil#td_000204">False</td>
                </tr>
                <tr id="tr_000068">
                  <td class="left" rowspan="1" colspan="1" id="td_000205" smilref="Machine_Learning00005.smil#td_000205">5</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000206" smilref="Machine_Learning00005.smil#td_000206">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000207" smilref="Machine_Learning00005.smil#td_000207">True</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000208" smilref="Machine_Learning00005.smil#td_000208">False</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000209" smilref="Machine_Learning00005.smil#td_000209">False</td>
                </tr>
              </table>
            </figure>
            <pagenum epub:type="pagebreak" id="p120" page="normal" smilref="Machine_Learning00005.smil#p120">120</pagenum>
            <p id="c06-c06-para-0018" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0018">This is essentially an item set of transactions with a transaction ID and the products (could be milk, nappies, beer, and beans, for example).</p>
            <p id="c06-c06-para-0019" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0019">Ultimately you're looking for associations in the products. For example if a customer buys products 1 and 2, he is likely to buy product 4.</p>
            <p id="c06-c06-para-0020" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0020">So a set of items:</p>
            <p class="informalEquation" xml:space="preserve" id="p_000337"><img src="images/c06_math_001.png" alt="equation" id="img_000059" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>I</mi><mo>=</mo><mfenced open="{" close="}"><mrow><mtext mathvariant="italic">product</mtext><mn>1</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>2</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>3</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>4</mn></mrow></mfenced></mrow></math>--></p>
            <p id="c06-c06-para-0021" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0021">And a set of transactions:</p>
            <p class="informalEquation" xml:space="preserve" id="p_000338"><img src="images/c06_math_002.png" alt="equation" id="img_000060" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>T</mi><mo>=</mo><mfenced open="{" close="}"><mrow><mtext mathvariant="italic">product</mtext><mn>1</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>2</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>4</mn></mrow></mfenced></mrow></math>--></p>
            <p id="c06-c06-para-0022" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0022">Each transaction must have a unique ID for the rule to glean any information. Also, it's worth noting that this sort of rule needs hundreds of transactions before it starts to generate anything of any value to you. The larger the transaction set, the better the statistical output will be and the better the predictions will be.</p>
            <p id="c06-c06-para-0023" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0023">The rule is defined as an implication, what you're looking at is the following:</p>
            <p class="informalEquation" xml:space="preserve" id="p_000339"><img src="images/c06_math_003.png" alt="equation" id="img_000061" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">X</mi><mo>,</mo><mi mathvariant="normal">Y</mi><mo>&#x02286;</mo><mi>I</mi><mo>,</mo><mspace width="0.12em"/><mtext>where</mtext><mspace width="0.12em"/><mi mathvariant="normal">X</mi><mo>&#x02229;</mo><mi mathvariant="normal">Y</mi><mo>=</mo><mfenced open="(" close=")"><mo stretchy="true">/</mo></mfenced></mrow></math>--></p>
            <p id="c06-c06-para-0024" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0024">In plain English, what you're saying is X and Y are a subset of the item set in the intersection of X and Y.</p>
            <p id="c06-c06-para-0025" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0025">They take on the form of a set as items denoted as X and Y. In scary math books, it will look like this:</p>
            <p class="informalEquation" xml:space="preserve" id="p_000340"><img src="images/c06_math_004.png" alt="equation" id="img_000062" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">X</mi><mo>&#x021D2;</mo><mi mathvariant="normal">Y</mi></mrow></math>--></p>
            <p id="c06-c06-para-0026" xml:space="preserve"><span class="text" id="span_000648" smilref="Machine_Learning00005.smil#span_000648">The X denotes the items set before (or left of) the rule, called the </span><em id="em_000155" smilref="Machine_Learning00005.smil#em_000155">antecedent</em><span class="text" id="span_000649" smilref="Machine_Learning00005.smil#span_000649">, and the Y is the item set after (or right of) the rule, called the </span><em id="em_000156" smilref="Machine_Learning00005.smil#em_000156">consequent</em><span class="text" id="span_000650" smilref="Machine_Learning00005.smil#span_000650">.</span></p>
            <p id="c06-c06-para-0027" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0027">Getting back to the products in the basic item set:</p>
            <p class="informalEquation" xml:space="preserve" id="p_000341"><img src="images/c06_math_005.png" alt="equation" id="img_000063" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>I</mi><mo>=</mo><mfenced open="{" close="}"><mrow><mtext mathvariant="italic">product</mtext><mn>1</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>2</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>3</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>4</mn></mrow></mfenced></mrow></math>--></p>
            <p id="c06-c06-para-0028" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0028">The true/false statements show whether the item is in that basket transaction or not.</p>
            <pagenum epub:type="pagebreak" id="p121" page="normal" smilref="Machine_Learning00005.smil#p121">121</pagenum>
            <p id="c06-c06-para-0029" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0029">To get the true picture of how the rules work, you need to investigate a little further into the concepts of support, confidence, lift, and conviction.</p>
            <level3 id="level3_000107">
              <h3 xml:space="preserve" id="h3_000107" smilref="Machine_Learning00005.smil#h3_000107">Support</h3>
              <p xml:space="preserve" id="p_000342"><em id="em_000157" smilref="Machine_Learning00005.smil#em_000157">Support</em><span class="text" id="span_000651" smilref="Machine_Learning00005.smil#span_000651"> is defined as the proportion of items in the data that contain the item set. It's written like so:</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000343"><img src="images/c06_math_006.png" alt="equation" id="img_000064" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext>Supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">X</mi></mfenced><mo>=</mo><mfrac><mrow><mtext mathvariant="italic">transactions</mtext><mo>_</mo><mtext mathvariant="italic">containing</mtext><mo>_</mo><mi mathvariant="normal">X</mi></mrow><mrow><mtext mathvariant="italic">total</mtext><mo>_</mo><mtext mathvariant="italic">number</mtext><mo>_</mo><mtext mathvariant="italic">of</mtext><mo>_</mo><mtext mathvariant="italic">transactions</mtext></mrow></mfrac></mrow></math>--></p>
              <p id="c06-c06-para-0031" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0031">If you were to take transaction number 1, as an example, you'd have the following equation:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000344"><img src="images/c06_math_007.png" alt="equation" id="img_000065" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext>supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">X</mi></mfenced><mo>=</mo><mfrac><mfenced open="{" close="}"><mrow><mtext mathvariant="italic">product</mtext><mn>1</mn><mo>,</mo><mtext mathvariant="italic">product</mtext><mn>2</mn></mrow></mfenced><mn>5</mn></mfrac><mo>=</mo><mn>0.2</mn></mrow></math>--></p>
              <p id="c06-c06-para-0032" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0032">The item set appears only once in the transaction log, and there are five transactions, so the support is 1/5, which is 0.2.</p>
            </level3>
            <level3 id="level3_000108">
              <h3 xml:space="preserve" id="h3_000108" smilref="Machine_Learning00005.smil#h3_000108">Confidence</h3>
              <p xml:space="preserve" id="p_000345"><em id="em_000158" smilref="Machine_Learning00005.smil#em_000158">Confidence</em><span class="text" id="span_000652" smilref="Machine_Learning00005.smil#span_000652"> in the rule is measured as</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000346"><img src="images/c06_math_008.png" alt="equation" id="img_000066" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">conf</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x021D2;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced><mo>=</mo><mtext>supp</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x0222A;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced><mo stretchy="true">/</mo><mtext>supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">X</mi></mfenced></mrow></math>--></p>
              <p id="c06-c06-para-0034" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0034">What you're defining here is the proportion of transactions containing set X, which also contain Y. This can be interpreted as the probability of finding the right-hand side of transactions under the condition of finding them on the left-hand side.</p>
              <p id="c06-c06-para-0035" xml:space="preserve" smilref="Machine_Learning00005.smil#c06-c06-para-0035">To use an analogy, think of parimutuel betting. All bets are placed together in a pool, and after the race has finished the payout is calculated based on the total pool (minus the commission to the agent). For example, assume there are five horses racing and bets have been placed against each one:</p>
              <figure id="figure_000050">
                <table border="1" id="table_000017">
                  <tr id="tr_000069">
                    <td class="left" rowspan="1" colspan="1" id="td_000210" smilref="Machine_Learning00005.smil#td_000210">Horse Number</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000211" smilref="Machine_Learning00005.smil#td_000211">Bet</td>
                  </tr>
                  <tr id="tr_000070">
                    <td class="left" rowspan="1" colspan="1" id="td_000212" smilref="Machine_Learning00005.smil#td_000212">1</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000213" smilref="Machine_Learning00005.smil#td_000213">$40.00</td>
                  </tr>
                  <tr id="tr_000071">
                    <td class="left" rowspan="1" colspan="1" id="td_000214" smilref="Machine_Learning00005.smil#td_000214">2</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000215" smilref="Machine_Learning00005.smil#td_000215">$150.00</td>
                  </tr>
                  <tr id="tr_000072">
                    <td class="left" rowspan="1" colspan="1" id="td_000216" smilref="Machine_Learning00005.smil#td_000216">3</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000217" smilref="Machine_Learning00005.smil#td_000217">$25.00</td>
                  </tr>
                  <tr id="tr_000073">
                    <td class="left" rowspan="1" colspan="1" id="td_000218" smilref="Machine_Learning00005.smil#td_000218">4</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000219" smilref="Machine_Learning00005.smil#td_000219">$40.00</td>
                  </tr>
                  <tr id="tr_000074">
                    <td class="left" rowspan="1" colspan="1" id="td_000220" smilref="Machine_Learning00006.smil#td_000220">5</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000221" smilref="Machine_Learning00006.smil#td_000221">$30.00</td>
                  </tr>
                </table>
              </figure>
              <pagenum epub:type="pagebreak" id="p122" page="normal" smilref="Machine_Learning00006.smil#p122">122</pagenum>
              <p id="c06-c06-para-0036" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0036">The total pool comes to $285, and after the event is run and the winner is confirmed the payout can be calculated. Assuming that horse number 4 was the winner the calculation would be</p>
              <p id="c06-c06-para-0037" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0037">Pool size after commission = $285 x (1 – 0.15) = $242.25.</p>
              <p id="c06-c06-para-0038" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0038">Payout per $1 on outcome 4 = $6.05 per $1 wagered.</p>
            </level3>
            <level3 id="level3_000109">
              <h3 xml:space="preserve" id="h3_000109" smilref="Machine_Learning00006.smil#h3_000109">Lift</h3>
              <p xml:space="preserve" id="p_000347"><em id="em_000159" smilref="Machine_Learning00006.smil#em_000159">Lift</em><span class="text" id="span_000653" smilref="Machine_Learning00006.smil#span_000653"> is defined as the ratio of the observed if the X and Y item sets were independent. It's written as</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000348"><img src="images/c06_math_009.png" alt="equation" id="img_000067" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">Lift</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x021D2;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced><mo>=</mo><mfrac><mrow><mtext>supp</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x0222A;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced></mrow><mrow><mtext>supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">X</mi></mfenced><mo>&#x000D7;</mo><mtext>supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">Y</mi></mfenced></mrow></mfrac></mrow></math>--></p>
            </level3>
            <level3 id="level3_000110">
              <h3 xml:space="preserve" id="h3_000110" smilref="Machine_Learning00006.smil#h3_000110">Conviction</h3>
              <p xml:space="preserve" id="p_000349"><span class="text" id="span_000654" smilref="Machine_Learning00006.smil#span_000654">Finally there's </span><em id="em_000160" smilref="Machine_Learning00006.smil#em_000160">conviction</em><span class="text" id="span_000655" smilref="Machine_Learning00006.smil#span_000655">, which is defined as the ratio of the expected frequency that X occurs without Y:</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000350"><img src="images/c06_math_010.png" alt="equation" id="img_000068" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">conv</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x021D2;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced><mo>=</mo><mfrac><mrow><mn>1</mn><mo>&#x02212;</mo><mtext>supp</mtext><mfenced open="(" close=")"><mi mathvariant="normal">Y</mi></mfenced></mrow><mrow><mn>1</mn><mo>&#x02212;</mo><mtext mathvariant="italic">conf</mtext><mfenced open="(" close=")"><mrow><mi mathvariant="normal">X</mi><mo>&#x021D2;</mo><mi mathvariant="normal">Y</mi></mrow></mfenced></mrow></mfrac></mrow></math>--></p>
            </level3>
            <level3 id="level3_000111">
              <h3 xml:space="preserve" id="h3_000111" smilref="Machine_Learning00006.smil#h3_000111">Defining the Process</h3>
              <p xml:space="preserve" id="p_000351" smilref="Machine_Learning00006.smil#p_000351">Association rules are defined to satisfy two user-defined criteria, a minimum support value and a minimum confidence. The rules generation is done in two parts.</p>
              <p id="c06-c06-para-0042" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0042">Firstly the minimum support is applied to all the frequent item sets in the database (or file or data source). The frequent item sets along with the minimum confidence are used to form the rules.</p>
              <p id="c06-c06-para-0043" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0043">Finding frequent item sets can be hard; it involves trawling through all the possible item combinations in the item sets. The number of possible item sets is the “power set” over the item set.</p>
              <p id="c06-c06-para-0044" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0044">For example, if you have the following:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000352"><img src="images/c06_math_011.png" alt="equation" id="img_000069" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>I</mi><mspace width="0.25em"/><mo>=</mo><mspace width="0.25em"/><mfenced open="{" close="}"><mrow><mi>p</mi><mn>1</mn><mo>,</mo><mi>p</mi><mn>2</mn><mo>,</mo><mi>p</mi><mn>3</mn></mrow></mfenced></mrow></math>--></p>
              <p xml:space="preserve" id="p_000353"><span class="text" id="span_000656" smilref="Machine_Learning00006.smil#span_000656">then the power set of </span><em id="em_000161" smilref="Machine_Learning00006.smil#em_000161">I</em><span class="text" id="span_000657" smilref="Machine_Learning00006.smil#span_000657"> would be this:</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000354"><img src="images/c06_math_012.png" alt="equation" id="img_000070" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mfenced open="{" close="}"><mrow><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>1</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>2</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>3</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>1</mn><mo>,</mo><mi mathvariant="normal">p</mi><mn>2</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>1</mn><mo>,</mo><mi mathvariant="normal">p</mi><mn>3</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>2</mn><mo>,</mo><mi mathvariant="normal">p</mi><mn>3</mn></mrow></mfenced><mo>,</mo><mspace width="0.12em"/><mfenced open="{" close="}"><mrow><mi mathvariant="normal">p</mi><mn>1</mn><mo>,</mo><mi mathvariant="normal">p</mi><mn>2</mn><mo>,</mo><mi mathvariant="normal">p</mi><mn>3</mn></mrow></mfenced></mrow></mfenced></mrow></math>--></p>
              <p id="c06-c06-para-0045" xml:space="preserve"><span class="text" id="span_000658" smilref="Machine_Learning00006.smil#span_000658">Notice that the empty set ({}) is omitted in the power set; this formulation gives you a size of 2</span><sup id="sup_000001" smilref="Machine_Learning00006.smil#sup_000001">n</sup><span class="text" id="span_000659" smilref="Machine_Learning00006.smil#span_000659">-1, where n is the number of items. A small increase in the number of items causes the size of the power set to increase enormously; </span><pagenum epub:type="pagebreak" id="p123" page="normal" smilref="Machine_Learning00006.smil#p123">123</pagenum><span class="text" id="span_000660" smilref="Machine_Learning00006.smil#span_000660">therefore this method is quite hungry in memory when using something like the Apriori algorithm. Obviously, the power set of all combinations of baskets does not occur, and the calculation will be based only on those basket combinations that do. Nonetheless, it is still very expensive in time and memory to run calculations based on this method.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000052">
            <h2 id="c06-c06_level1_3" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06_level1_3">Algorithms</h2>
            <p xml:space="preserve" id="p_000355" smilref="Machine_Learning00006.smil#p_000355">There are several algorithms used in association rule learning that you'll come across; the two described in this section are the most prevalent.</p>
            <level3 id="level3_000112">
              <h3 xml:space="preserve" id="h3_000112" smilref="Machine_Learning00006.smil#h3_000112">Apriori</h3>
              <p xml:space="preserve" id="p_000356" smilref="Machine_Learning00006.smil#p_000356">Using a bottom-up approach, the Apriori algorithm works through item sets one at a time. Candidate groups are tested against the data; when no extensions to the set are found, the algorithm will stop. The support threshold for the example is 3.</p>
              <p id="c06-c06-para-0048" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0048">If you consider the following item set:</p>
              <list type="ol" id="list_000038">
                <li id="li_000328" smilref="Machine_Learning00006.smil#li_000328">{1,2,3,4}</li>
                <li id="li_000329" smilref="Machine_Learning00006.smil#li_000329">{1,3,4}</li>
                <li id="li_000330" smilref="Machine_Learning00006.smil#li_000330">{1,2}</li>
                <li id="li_000331" smilref="Machine_Learning00006.smil#li_000331">{2,3,4}</li>
                <li id="li_000332" smilref="Machine_Learning00006.smil#li_000332">{3,4}</li>
                <li id="li_000333" smilref="Machine_Learning00006.smil#li_000333">{2,4}</li>
              </list>
              <p id="c06-c06-para-0049" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0049">First, it counts the support of each item:</p>
              <list type="ol" id="list_000039">
                <li id="li_000334" smilref="Machine_Learning00006.smil#li_000334">{1} = 3</li>
                <li id="li_000335" smilref="Machine_Learning00006.smil#li_000335">{2} = 5</li>
                <li id="li_000336" smilref="Machine_Learning00006.smil#li_000336">{3} = 4</li>
                <li id="li_000337" smilref="Machine_Learning00006.smil#li_000337">{4} = 5</li>
              </list>
              <p id="c06-c06-para-0050" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0050">The next step is to look at the pairs:</p>
              <list type="ol" id="list_000040">
                <li id="li_000338" smilref="Machine_Learning00006.smil#li_000338">{1,2} = 2</li>
                <li id="li_000339" smilref="Machine_Learning00006.smil#li_000339">{1,3} = 2</li>
                <li id="li_000340" smilref="Machine_Learning00006.smil#li_000340">{1,4} = 2</li>
                <li id="li_000341" smilref="Machine_Learning00006.smil#li_000341">{2,3} = 2</li>
                <li id="li_000342" smilref="Machine_Learning00006.smil#li_000342">{2,4} = 3</li>
                <li id="li_000343" smilref="Machine_Learning00006.smil#li_000343">{3,4} = 4</li>
              </list>
              <pagenum epub:type="pagebreak" id="p124" page="normal" smilref="Machine_Learning00006.smil#p124">124</pagenum>
              <p id="c06-c06-para-0051" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0051">As {1,2}, {1,3},{1,4}, and {2,3} are under the chosen support threshold you can reject them from the triples that are in the database. In the example, there is only one triple:</p>
              <list type="ol" id="list_000041">
                <li id="li_000344" smilref="Machine_Learning00006.smil#li_000344">{2,3,4} = 1 (we've discounted one from the {1,2} group).</li>
              </list>
              <p id="c06-c06-para-0052" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0052">From that deduction, you have the frequent item sets.</p>
            </level3>
            <level3 id="level3_000113">
              <h3 xml:space="preserve" id="h3_000113" smilref="Machine_Learning00006.smil#h3_000113">FP-Growth</h3>
              <p xml:space="preserve" id="p_000357" smilref="Machine_Learning00006.smil#p_000357">The Frequent Pattern Growth algorithm (FP-Growth) works as a tree structure (called an FP-Tree). It creates the tree by counting the occurrences of the items in the database and storing them in a header table.</p>
              <p id="c06-c06-para-0054" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0054">In a second pass, the tree is built by inserting the instances it sees in the data as it goes along the header table. Items that don't meet the minimum support threshold are discarded; otherwise they are listed in descending order.</p>
              <p id="c06-c06-para-0055" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0055">You can think of the FP-Growth algorithm like a graph, as is covered in the chapter about Bayesian Networks (Chapter 4). With a reduced dataset in a tree formation, the FP-Growth algorithm starts at the bottom—the place with the longest branches—and finds all instances of the given condition. When no more single items match the attribute's support threshold, the growth ends and then it works on the next part of the FP Tree.</p>
            </level3>
          </level2>
          <level2 id="level2_000053">
            <h2 id="c06-c06_level1_4" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06_level1_4">Mining the Baskets—A Walkthrough</h2>
            <p xml:space="preserve" id="p_000358" smilref="Machine_Learning00006.smil#p_000358">This walkthrough uses Mahout to work on the data using the Apriori algorithm and to get a set of results based on the historical basket contents.</p>
            <p id="c06-c06-para-0057" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0057">The nice thing about this sort of project is that it can be easily ported to your own e-commerce platform if you're operating one. The keys are to manage how to get the data out of the database for processing and then craft a way of getting the insight back in.</p>
            <level3 id="level3_000114">
              <h3 xml:space="preserve" id="h3_000114" smilref="Machine_Learning00006.smil#h3_000114">Downloading the Raw Data</h3>
              <p xml:space="preserve" id="p_000359" smilref="Machine_Learning00006.smil#p_000359">Instead of using precious time to create data, I've used a dataset from Dr. Tariq Mahmood's website, which contains a test data file for basket analysis.</p>
              <p id="c06-c06-para-0059" xml:space="preserve"><span class="text" id="span_000661" smilref="Machine_Learning00006.smil#span_000661">You can download the CSV file from his site: </span><a href="https://sites.google.com/a/nu.edu.pk/tariq-mahmood/teaching-1/fall-12---dm/marketbasket.csv?attredirects=0&amp;d=1" external="true" id="a_000289" smilref="Machine_Learning00006.smil#a_000289">https://sites.google.com/a/nu.edu.pk/tariq-mahmood/teaching-1/fall-12---dm/marketbasket.csv?attredirects=0&amp;d=1</a><span class="text" id="span_000662" smilref="Machine_Learning00006.smil#span_000662">.</span></p>
              <pagenum epub:type="pagebreak" id="p125" page="normal" smilref="Machine_Learning00006.smil#p125">125</pagenum>
              <p id="c06-c06-para-0060" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0060">Each column represents a product type and each row represents a basket transaction from the store.</p>
              <figure id="figure_000051">
                <table border="1" id="table_000018">
                  <tr id="tr_000075">
                    <td class="left" rowspan="1" colspan="1" id="td_000222" smilref="Machine_Learning00006.smil#td_000222">Aspirin</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000223" smilref="Machine_Learning00006.smil#td_000223">Sweet Potatoes</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000224" smilref="Machine_Learning00006.smil#td_000224">Canned Tomatoes</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000225" smilref="Machine_Learning00006.smil#td_000225">Chunky Peanut Butter</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000226" smilref="Machine_Learning00006.smil#td_000226">Wood Polish</td>
                  </tr>
                  <tr id="tr_000076">
                    <td class="left" rowspan="1" colspan="1" id="td_000227" smilref="Machine_Learning00006.smil#td_000227">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000228" smilref="Machine_Learning00006.smil#td_000228">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000229" smilref="Machine_Learning00006.smil#td_000229">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000230" smilref="Machine_Learning00006.smil#td_000230">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000231" smilref="Machine_Learning00006.smil#td_000231">false</td>
                  </tr>
                  <tr id="tr_000077">
                    <td class="left" rowspan="1" colspan="1" id="td_000232" smilref="Machine_Learning00006.smil#td_000232">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000233" smilref="Machine_Learning00006.smil#td_000233">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000234" smilref="Machine_Learning00006.smil#td_000234">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000235" smilref="Machine_Learning00006.smil#td_000235">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000236" smilref="Machine_Learning00006.smil#td_000236">false</td>
                  </tr>
                  <tr id="tr_000078">
                    <td class="left" rowspan="1" colspan="1" id="td_000237" smilref="Machine_Learning00006.smil#td_000237">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000238" smilref="Machine_Learning00006.smil#td_000238">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000239" smilref="Machine_Learning00006.smil#td_000239">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000240" smilref="Machine_Learning00006.smil#td_000240">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000241" smilref="Machine_Learning00006.smil#td_000241">false</td>
                  </tr>
                  <tr id="tr_000079">
                    <td class="left" rowspan="1" colspan="1" id="td_000242" smilref="Machine_Learning00006.smil#td_000242">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000243" smilref="Machine_Learning00006.smil#td_000243">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000244" smilref="Machine_Learning00006.smil#td_000244">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000245" smilref="Machine_Learning00006.smil#td_000245">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000246" smilref="Machine_Learning00006.smil#td_000246">false</td>
                  </tr>
                  <tr id="tr_000080">
                    <td class="left" rowspan="1" colspan="1" id="td_000247" smilref="Machine_Learning00006.smil#td_000247">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000248" smilref="Machine_Learning00006.smil#td_000248">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000249" smilref="Machine_Learning00006.smil#td_000249">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000250" smilref="Machine_Learning00006.smil#td_000250">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000251" smilref="Machine_Learning00006.smil#td_000251">false</td>
                  </tr>
                  <tr id="tr_000081">
                    <td class="left" rowspan="1" colspan="1" id="td_000252" smilref="Machine_Learning00006.smil#td_000252">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000253" smilref="Machine_Learning00006.smil#td_000253">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000254" smilref="Machine_Learning00006.smil#td_000254">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000255" smilref="Machine_Learning00006.smil#td_000255">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000256" smilref="Machine_Learning00006.smil#td_000256">false</td>
                  </tr>
                  <tr id="tr_000082">
                    <td class="left" rowspan="1" colspan="1" id="td_000257" smilref="Machine_Learning00006.smil#td_000257">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000258" smilref="Machine_Learning00006.smil#td_000258">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000259" smilref="Machine_Learning00006.smil#td_000259">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000260" smilref="Machine_Learning00006.smil#td_000260">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000261" smilref="Machine_Learning00006.smil#td_000261">false</td>
                  </tr>
                  <tr id="tr_000083">
                    <td class="left" rowspan="1" colspan="1" id="td_000262" smilref="Machine_Learning00006.smil#td_000262">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000263" smilref="Machine_Learning00006.smil#td_000263">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000264" smilref="Machine_Learning00006.smil#td_000264">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000265" smilref="Machine_Learning00006.smil#td_000265">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000266" smilref="Machine_Learning00006.smil#td_000266">false</td>
                  </tr>
                  <tr id="tr_000084">
                    <td class="left" rowspan="1" colspan="1" id="td_000267" smilref="Machine_Learning00006.smil#td_000267">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000268" smilref="Machine_Learning00006.smil#td_000268">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000269" smilref="Machine_Learning00006.smil#td_000269">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000270" smilref="Machine_Learning00006.smil#td_000270">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000271" smilref="Machine_Learning00006.smil#td_000271">false</td>
                  </tr>
                  <tr id="tr_000085">
                    <td class="left" rowspan="1" colspan="1" id="td_000272" smilref="Machine_Learning00006.smil#td_000272">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000273" smilref="Machine_Learning00006.smil#td_000273">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000274" smilref="Machine_Learning00006.smil#td_000274">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000275" smilref="Machine_Learning00006.smil#td_000275">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000276" smilref="Machine_Learning00006.smil#td_000276">false</td>
                  </tr>
                  <tr id="tr_000086">
                    <td class="left" rowspan="1" colspan="1" id="td_000277" smilref="Machine_Learning00006.smil#td_000277">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000278" smilref="Machine_Learning00006.smil#td_000278">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000279" smilref="Machine_Learning00006.smil#td_000279">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000280" smilref="Machine_Learning00006.smil#td_000280">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000281" smilref="Machine_Learning00006.smil#td_000281">false</td>
                  </tr>
                  <tr id="tr_000087">
                    <td class="left" rowspan="1" colspan="1" id="td_000282" smilref="Machine_Learning00006.smil#td_000282">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000283" smilref="Machine_Learning00006.smil#td_000283">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000284" smilref="Machine_Learning00006.smil#td_000284">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000285" smilref="Machine_Learning00006.smil#td_000285">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000286" smilref="Machine_Learning00006.smil#td_000286">false</td>
                  </tr>
                  <tr id="tr_000088">
                    <td class="left" rowspan="1" colspan="1" id="td_000287" smilref="Machine_Learning00006.smil#td_000287">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000288" smilref="Machine_Learning00006.smil#td_000288">true</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000289" smilref="Machine_Learning00006.smil#td_000289">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000290" smilref="Machine_Learning00006.smil#td_000290">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000291" smilref="Machine_Learning00006.smil#td_000291">false</td>
                  </tr>
                  <tr id="tr_000089">
                    <td class="left" rowspan="1" colspan="1" id="td_000292" smilref="Machine_Learning00006.smil#td_000292">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000293" smilref="Machine_Learning00006.smil#td_000293">true</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000294" smilref="Machine_Learning00006.smil#td_000294">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000295" smilref="Machine_Learning00006.smil#td_000295">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000296" smilref="Machine_Learning00006.smil#td_000296">true</td>
                  </tr>
                  <tr id="tr_000090">
                    <td class="left" rowspan="1" colspan="1" id="td_000297" smilref="Machine_Learning00006.smil#td_000297">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000298" smilref="Machine_Learning00006.smil#td_000298">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000299" smilref="Machine_Learning00006.smil#td_000299">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000300" smilref="Machine_Learning00006.smil#td_000300">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000301" smilref="Machine_Learning00006.smil#td_000301">false</td>
                  </tr>
                  <tr id="tr_000091">
                    <td class="left" rowspan="1" colspan="1" id="td_000302" smilref="Machine_Learning00006.smil#td_000302">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000303" smilref="Machine_Learning00006.smil#td_000303">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000304" smilref="Machine_Learning00006.smil#td_000304">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000305" smilref="Machine_Learning00006.smil#td_000305">false</td>
                    <td class="left" rowspan="1" colspan="1" id="td_000306" smilref="Machine_Learning00006.smil#td_000306">false</td>
                  </tr>
                </table>
              </figure>
              <p id="c06-c06-para-0061" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0061">The data comprises 1,361 transactions against 302 products, which equals more than 411,000 transactions to mine through. Notice there are no quantities to deal with—just a notification of whether the item was purchased or not (true or false).</p>
            </level3>
            <level3 id="level3_000115">
              <h3 xml:space="preserve" id="h3_000115" smilref="Machine_Learning00006.smil#h3_000115">Setting Up the Project in Eclipse</h3>
              <p xml:space="preserve" id="p_000360" smilref="Machine_Learning00006.smil#p_000360">There are a few classes you need to create in order to get association rules learning to work from a code point of view. It's not so much a case of creating MapReduce functions or anything specific for Mahout to work from; it is more a matter of data preparation and being able to read the output after the mining has taken place.</p>
              <pagenum epub:type="pagebreak" id="p126" page="normal" smilref="Machine_Learning00006.smil#p126">126</pagenum>
              <p id="c06-c06-para-0063" xml:space="preserve"><span class="text" id="span_000663" smilref="Machine_Learning00006.smil#span_000663">Create a new project called </span><code xml:space="preserve" id="code_000158" smilref="Machine_Learning00006.smil#code_000158">ARLearning</code><span class="text" id="span_000664" smilref="Machine_Learning00006.smil#span_000664"> in Eclipse using the File →New →Java Project option as shown in </span><a id="c06-c06-fig-anc-0001" href="#c06-c06-fig-0001" external="false" smilref="Machine_Learning00006.smil#c06-c06-fig-anc-0001">Figure 6-1</a><span class="text" id="span_000665" smilref="Machine_Learning00006.smil#span_000665">.</span></p>
              <figure id="figure_000052">
                <img class="center" src="images/c06f001.jpg" alt="image" id="img_000071" />
                <figcaption id="figcaption_000038">
                  <p xml:space="preserve" id="p_000361"><span class="figureLabel" id="span_000666"><a id="c06-c06-fig-0001" href="#c06-c06-fig-anc-0001" external="false"><strong id="strong_000204" smilref="Machine_Learning00006.smil#strong_000204">Figure 6-1</strong></a></span><span class="text" id="span_000667" smilref="Machine_Learning00006.smil#span_000667"> A new Java project</span></p>
                </figcaption>
              </figure>
              <p id="c06-c06-para-0064" xml:space="preserve"><span class="text" id="span_000668" smilref="Machine_Learning00006.smil#span_000668">Within the project properties you need to add the locations for the core Hadoop library, the MySQL JDBC driver, and the core Mahout library, as shown in </span><a id="c06-c06-fig-anc-0002" href="#c06-c06-fig-0002" external="false" smilref="Machine_Learning00006.smil#c06-c06-fig-anc-0002">Figure 6-2</a><span class="text" id="span_000669" smilref="Machine_Learning00006.smil#span_000669">.</span></p>
              <sidebar render="required" id="sidebar_000007">
                <div class="top hr" id="div_000007" />
                <level2 class="feature2" id="level2_000054">
                  <h2 xml:space="preserve" id="h2_000011" smilref="Machine_Learning00006.smil#h2_000011">Note</h2>
                  <p xml:space="preserve" id="p_000362"><span class="text" id="span_000670" smilref="Machine_Learning00006.smil#span_000670">If you don't have the MySQL JDBC driver, you can download it from </span><code xml:space="preserve" id="code_000159"><a href="http://dev.mysql.com/downloads/connector/j/" external="true" id="a_000290" smilref="Machine_Learning00006.smil#a_000290">http://dev.mysql.com/downloads/connector/j/</a></code><span class="text" id="span_000671" smilref="Machine_Learning00006.smil#span_000671">.</span></p>
                </level2>
              </sidebar>
              <figure id="figure_000053">
                <img class="center" src="images/c06f002.jpg" alt="image" id="img_000072" />
                <figcaption id="figcaption_000039">
                  <p xml:space="preserve" id="p_000363"><span class="figureLabel" id="span_000672"><a id="c06-c06-fig-0002" href="#c06-c06-fig-anc-0002" external="false"><strong id="strong_000205" smilref="Machine_Learning00006.smil#strong_000205">Figure 6-2</strong></a></span><span class="text" id="span_000673" smilref="Machine_Learning00006.smil#span_000673"> Adding the required JAR files</span></p>
                </figcaption>
              </figure>
            </level3>
            <level3 id="level3_000116">
              <h3 xml:space="preserve" id="h3_000116" smilref="Machine_Learning00006.smil#h3_000116">Setting Up the Items Data File</h3>
              <p xml:space="preserve" id="p_000364" smilref="Machine_Learning00006.smil#p_000364">I'm going to store the product data (the column names) in a database table; you'll need to refer to these later when you have some results from Mahout.</p>
              <p id="c06-c06-para-0067" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0067">From the command line, type in the following MySQL commands:</p>
              <p xml:space="preserve" id="p_000365"><code class="preserve-whitespace" xml:space="preserve" id="code_000160" smilref="Machine_Learning00006.smil#code_000160">mysqladmin -u root create apriori
mysql -u root apriori</code></p>
              <pagenum epub:type="pagebreak" id="p127" page="normal" smilref="Machine_Learning00006.smil#p127">127</pagenum>
              <p id="c06-c06-para-0068" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0068">The table will only have two fields: one for the id and another for the product name:</p>
              <p xml:space="preserve" id="p_000366"><code class="preserve-whitespace" xml:space="preserve" id="code_000161" smilref="Machine_Learning00006.smil#code_000161">mysql&gt; create table products(
    -&gt; id int(11) not null default -1,
    -&gt; productname varchar(100) not null default "");</code></p>
              <p id="c06-c06-para-0069" xml:space="preserve"><span class="text" id="span_000674" smilref="Machine_Learning00006.smil#span_000674">The next task is to import the product titles into the database. I've written a small Java program to read in the </span><code xml:space="preserve" id="code_000162" smilref="Machine_Learning00006.smil#code_000162">.csv</code><span class="text" id="span_000675" smilref="Machine_Learning00006.smil#span_000675"> file and extract the first line only, iterating each column and adding the product name into the database table. It's a very straightforward piece of code, and it works for this example. Use the following code, changing the file path to the place you downloaded or prepared the </span><code xml:space="preserve" id="code_000163" smilref="Machine_Learning00006.smil#code_000163">rawdata.csv</code><span class="text" id="span_000676" smilref="Machine_Learning00006.smil#span_000676"> file:</span></p>
              <p xml:space="preserve" id="p_000367"><code class="preserve-whitespace" xml:space="preserve" id="code_000164"><strong id="strong_000206" smilref="Machine_Learning00006.smil#strong_000206">import java.io.BufferedReader;</strong>
<strong id="strong_000207" smilref="Machine_Learning00006.smil#strong_000207">import java.io.FileNotFoundException;</strong>
<strong id="strong_000208" smilref="Machine_Learning00006.smil#strong_000208">import java.io.FileReader;</strong>
<strong id="strong_000209" smilref="Machine_Learning00006.smil#strong_000209">import java.io.IOException;</strong>
<strong id="strong_000210" smilref="Machine_Learning00006.smil#strong_000210">import java.sql.Connection;</strong>
<strong id="strong_000211" smilref="Machine_Learning00006.smil#strong_000211">import java.sql.DriverManager;</strong>
<strong id="strong_000212" smilref="Machine_Learning00006.smil#strong_000212">import java.sql.PreparedStatement;</strong>
<strong id="strong_000213"><span class="text" id="span_000677" smilref="Machine_Learning00006.smil#span_000677">import</span><pagenum epub:type="pagebreak" id="p128" page="normal" smilref="Machine_Learning00006.smil#p128">128</pagenum><span class="text" id="span_000678" smilref="Machine_Learning00006.smil#span_000678"> java.sql.SQLException;</span></strong>
<strong id="strong_000214" smilref="Machine_Learning00006.smil#strong_000214">public class</strong><span class="text" id="span_000679" smilref="Machine_Learning00006.smil#span_000679"> ExtractProductNames {
    </span><strong id="strong_000215" smilref="Machine_Learning00006.smil#strong_000215">static</strong><span class="text" id="span_000680" smilref="Machine_Learning00006.smil#span_000680"> {
        </span><strong id="strong_000216" smilref="Machine_Learning00006.smil#strong_000216">try</strong><span class="text" id="span_000681" smilref="Machine_Learning00006.smil#span_000681"> {
            Class.</span><em id="em_000162" smilref="Machine_Learning00006.smil#em_000162">forName</em><span class="text" id="span_000682" smilref="Machine_Learning00006.smil#span_000682">("com.mysql.jdbc.Driver");
        } </span><strong id="strong_000217" smilref="Machine_Learning00006.smil#strong_000217">catch</strong><span class="text" id="span_000683" smilref="Machine_Learning00006.smil#span_000683"> (ClassNotFoundException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000218" smilref="Machine_Learning00006.smil#strong_000218">public</strong><span class="text" id="span_000684" smilref="Machine_Learning00006.smil#span_000684"> ExtractProductNames() {
        </span><strong id="strong_000219" smilref="Machine_Learning00006.smil#strong_000219">try</strong><span class="text" id="span_000685" smilref="Machine_Learning00006.smil#span_000685"> {
            Connection con = DriverManager.</span><em id="em_000163" smilref="Machine_Learning00006.smil#em_000163">getConnection</em><span class="text" id="span_000686" smilref="Machine_Learning00006.smil#span_000686">("jdbc:mysql://localhost/apriori","root","");
            PreparedStatement pstmt = con.prepareStatement("INSERT INTO products (id, productname) VALUES (?,?)");
            BufferedReader csvfile = </span><strong id="strong_000220" smilref="Machine_Learning00006.smil#strong_000220">new</strong><span class="text" id="span_000687" smilref="Machine_Learning00006.smil#span_000687"> BufferedReader(</span><strong id="strong_000221" smilref="Machine_Learning00006.smil#strong_000221">new</strong><span class="text" id="span_000688" smilref="Machine_Learning00006.smil#span_000688"> FileReader("/path/to/your/data/rawdata.csv"));
            String productsLine = csvfile.readLine();
            String[] products = productsLine.split(",");
            </span><strong id="strong_000222" smilref="Machine_Learning00006.smil#strong_000222">for</strong><span class="text" id="span_000689" smilref="Machine_Learning00006.smil#span_000689">(</span><strong id="strong_000223" smilref="Machine_Learning00006.smil#strong_000223">int</strong><span class="text" id="span_000690" smilref="Machine_Learning00006.smil#span_000690"> i = 0; i &lt; products.length; i++) {
                pstmt.clearParameters();
                pstmt.setInt(1, i);
                pstmt.setString(2, products[i].trim());
                pstmt.execute();
                System.</span><em id="em_000164" smilref="Machine_Learning00006.smil#em_000164">out</em><span class="text" id="span_000691" smilref="Machine_Learning00006.smil#span_000691">.println("Added: " + products[i] + " into db");
            }
            pstmt.close();
            con.close();
        } </span><strong id="strong_000224" smilref="Machine_Learning00006.smil#strong_000224">catch</strong><span class="text" id="span_000692" smilref="Machine_Learning00006.smil#span_000692"> (FileNotFoundException e) {
            e.printStackTrace();
        } </span><strong id="strong_000225" smilref="Machine_Learning00006.smil#strong_000225">catch</strong><span class="text" id="span_000693" smilref="Machine_Learning00006.smil#span_000693"> (IOException e) {
            e.printStackTrace();
        } </span><strong id="strong_000226" smilref="Machine_Learning00006.smil#strong_000226">catch</strong><span class="text" id="span_000694" smilref="Machine_Learning00006.smil#span_000694">(SQLException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000227" smilref="Machine_Learning00006.smil#strong_000227">public static void</strong><span class="text" id="span_000695" smilref="Machine_Learning00006.smil#span_000695"> main(String[] args) {
        ExtractProductNames epn = </span><strong id="strong_000228" smilref="Machine_Learning00006.smil#strong_000228">new</strong><span class="text" id="span_000696" smilref="Machine_Learning00006.smil#span_000696"> ExtractProductNames();
    }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p129" page="normal" smilref="Machine_Learning00006.smil#p129">129</pagenum>
              <p id="c06-c06-para-0070" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0070">When you run the program, you see the output of the lines as they are added into the database table:</p>
              <p xml:space="preserve" id="p_000368"><code class="preserve-whitespace" xml:space="preserve" id="code_000165" smilref="Machine_Learning00006.smil#code_000165">Added:  Salt into db
Added:  Green Beans into db
Added:  Flavored Ice into db
Added:  Imported Beer into db
Added:  Grits into db
Added:  Apple Jelly into db
Added:  Beef Jerky into db
Added:  Potatoes into db
Added:  Small Eggs into db
Added:  Silver Cleaner into db</code></p>
              <p id="c06-c06-para-0071" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0071">Now it's time to look at the actual data.</p>
            </level3>
            <level3 id="level3_000117">
              <h3 xml:space="preserve" id="h3_000117" smilref="Machine_Learning00006.smil#h3_000117">Setting Up the Data</h3>
              <p xml:space="preserve" id="p_000369"><span class="text" id="span_000697" smilref="Machine_Learning00006.smil#span_000697">The raw </span><code xml:space="preserve" id="code_000166" smilref="Machine_Learning00006.smil#code_000166">.csv</code><span class="text" id="span_000698" smilref="Machine_Learning00006.smil#span_000698"> file has the values for a customer purchase as true or false, but you need to convert it to a format that Mahout is happy to process. Mahout prefers the item ID in a comma-separated format. Now that you have item IDs set up in the database, you can use those in a data file so Mahout has the item IDs for each basket.</span></p>
              <p id="c06-c06-para-0073" xml:space="preserve"><span class="text" id="span_000699" smilref="Machine_Learning00006.smil#span_000699">Create a new Java class called </span><code xml:space="preserve" id="code_000167" smilref="Machine_Learning00006.smil#code_000167">DataConverter</code><span class="text" id="span_000700" smilref="Machine_Learning00006.smil#span_000700"> (File →New →Class). The following Java code reads in the remaining lines of the </span><code xml:space="preserve" id="code_000168" smilref="Machine_Learning00006.smil#code_000168">.csv</code><span class="text" id="span_000701" smilref="Machine_Learning00006.smil#span_000701"> file and converts the true fields into the respective ID of the product that you saved in the database:</span></p>
              <p xml:space="preserve" id="p_000370"><code class="preserve-whitespace" xml:space="preserve" id="code_000169"><strong id="strong_000229" smilref="Machine_Learning00006.smil#strong_000229">import java.io.BufferedReader;</strong>
<strong id="strong_000230" smilref="Machine_Learning00006.smil#strong_000230">import java.io.FileReader;</strong>
<strong id="strong_000231" smilref="Machine_Learning00006.smil#strong_000231">import java.io.FileWriter;</strong>
<strong id="strong_000232" smilref="Machine_Learning00006.smil#strong_000232">public class</strong><span class="text" id="span_000702" smilref="Machine_Learning00006.smil#span_000702"> DataConverter {
    </span><strong id="strong_000233" smilref="Machine_Learning00006.smil#strong_000233">public</strong><span class="text" id="span_000703" smilref="Machine_Learning00006.smil#span_000703"> DataConverter() {
        </span><strong id="strong_000234" smilref="Machine_Learning00006.smil#strong_000234">try</strong><span class="text" id="span_000704" smilref="Machine_Learning00006.smil#span_000704"> {
            FileWriter outputWriter = </span><strong id="strong_000235" smilref="Machine_Learning00006.smil#strong_000235">new</strong><span class="text" id="span_000705" smilref="Machine_Learning00006.smil#span_000705"> FileWriter(
                    "/path/to/your/data/output.dat");
            </span><strong id="strong_000236" smilref="Machine_Learning00006.smil#strong_000236">int</strong><span class="text" id="span_000706" smilref="Machine_Learning00006.smil#span_000706"> txcount = 0;
            BufferedReader csvReader = </span><strong id="strong_000237" smilref="Machine_Learning00006.smil#strong_000237">new</strong><span class="text" id="span_000707" smilref="Machine_Learning00006.smil#span_000707"> BufferedReader(</span><strong id="strong_000238" smilref="Machine_Learning00006.smil#strong_000238">new</strong><span class="text" id="span_000708" smilref="Machine_Learning00006.smil#span_000708"> FileReader(
                    "/path/to/your/data/rawdata.csv"));
            // read the first line in but do nothing with it.
            String </span><pagenum epub:type="pagebreak" id="p130" page="normal" smilref="Machine_Learning00006.smil#p130">130</pagenum><span class="text" id="span_000709" smilref="Machine_Learning00006.smil#span_000709">thisLine = csvReader.readLine();
            String[] tokens = thisLine.split(",");
            //
            </span><strong id="strong_000239" smilref="Machine_Learning00006.smil#strong_000239">int</strong><span class="text" id="span_000710" smilref="Machine_Learning00006.smil#span_000710"> i;
            </span><strong id="strong_000240" smilref="Machine_Learning00006.smil#strong_000240">while</strong><span class="text" id="span_000711" smilref="Machine_Learning00006.smil#span_000711"> (</span><strong id="strong_000241" smilref="Machine_Learning00006.smil#strong_000241">true</strong><span class="text" id="span_000712" smilref="Machine_Learning00006.smil#span_000712">) {
                thisLine = csvReader.readLine();
                </span><strong id="strong_000242" smilref="Machine_Learning00006.smil#strong_000242">if</strong><span class="text" id="span_000713" smilref="Machine_Learning00006.smil#span_000713"> (thisLine == </span><strong id="strong_000243" smilref="Machine_Learning00006.smil#strong_000243">null</strong><span class="text" id="span_000714" smilref="Machine_Learning00006.smil#span_000714">) {
                    </span><strong id="strong_000244" smilref="Machine_Learning00006.smil#strong_000244">break</strong><span class="text" id="span_000715" smilref="Machine_Learning00006.smil#span_000715">;
                }
                tokens = thisLine.split(",");
                i = 0;
                </span><strong id="strong_000245" smilref="Machine_Learning00006.smil#strong_000245">boolean</strong><span class="text" id="span_000716" smilref="Machine_Learning00006.smil#span_000716"> firstElementInRow = </span><strong id="strong_000246" smilref="Machine_Learning00006.smil#strong_000246">true</strong><span class="text" id="span_000717" smilref="Machine_Learning00006.smil#span_000717">;
                </span><strong id="strong_000247" smilref="Machine_Learning00006.smil#strong_000247">for</strong><span class="text" id="span_000718" smilref="Machine_Learning00006.smil#span_000718"> (String token: tokens) {
                    </span><strong id="strong_000248" smilref="Machine_Learning00006.smil#strong_000248">if</strong><span class="text" id="span_000719" smilref="Machine_Learning00006.smil#span_000719"> (token.trim().equals("true")) {
                        </span><strong id="strong_000249" smilref="Machine_Learning00006.smil#strong_000249">if</strong><span class="text" id="span_000720" smilref="Machine_Learning00006.smil#span_000720"> (firstElementInRow) {
                            firstElementInRow = </span><strong id="strong_000250" smilref="Machine_Learning00006.smil#strong_000250">false</strong><span class="text" id="span_000721" smilref="Machine_Learning00006.smil#span_000721">;
                        } </span><strong id="strong_000251" smilref="Machine_Learning00006.smil#strong_000251">else</strong><span class="text" id="span_000722" smilref="Machine_Learning00006.smil#span_000722"> {
                            outputWriter.append(",");
                        }
                        outputWriter.append(Integer.</span><em id="em_000165" smilref="Machine_Learning00006.smil#em_000165">toString</em><span class="text" id="span_000723" smilref="Machine_Learning00006.smil#span_000723">(i));
                    }
                    i++;
                }
                outputWriter.append("\n");
                txcount++;
            }
            outputWriter.close();
        } </span><strong id="strong_000252" smilref="Machine_Learning00006.smil#strong_000252">catch</strong><span class="text" id="span_000724" smilref="Machine_Learning00006.smil#span_000724"> (Exception e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000253" smilref="Machine_Learning00006.smil#strong_000253">public static void</strong><span class="text" id="span_000725" smilref="Machine_Learning00006.smil#span_000725"> main(String[] args) {
        DataConverter dc = </span><strong id="strong_000254" smilref="Machine_Learning00006.smil#strong_000254">new</strong><span class="text" id="span_000726" smilref="Machine_Learning00006.smil#span_000726"> DataConverter();
    }
}</span></code></p>
              <p id="c06-c06-para-0074" xml:space="preserve"><span class="text" id="span_000727" smilref="Machine_Learning00006.smil#span_000727">After you run the program, you see that a new file called </span><code xml:space="preserve" id="code_000170" smilref="Machine_Learning00006.smil#code_000170">output.dat</code><span class="text" id="span_000728" smilref="Machine_Learning00006.smil#span_000728"> has been created. It now contains the product IDs in each basket.</span></p>
              <p xml:space="preserve" id="p_000371"><code class="preserve-whitespace" xml:space="preserve" id="code_000171" smilref="Machine_Learning00006.smil#code_000171">6,7,12,53,64,89,93,109,123,151,163,182,202,207,210,243,259,287
5,7,18,23,111,127,142,155,163,202,218,244,276,279,287,290
17
1,179,213
225
286
33
89,224,271
228
93</code></p>
              <pagenum epub:type="pagebreak" id="p131" page="normal" smilref="Machine_Learning00006.smil#p131">131</pagenum>
              <p id="c06-c06-para-0075" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0075">That's all you need to do in preparation. Now, you can move on to Mahout and mining the data with association rules learning.</p>
            </level3>
            <level3 id="level3_000118">
              <h3 xml:space="preserve" id="h3_000118" smilref="Machine_Learning00006.smil#h3_000118">Running Mahout</h3>
              <p xml:space="preserve" id="p_000372"><span class="text" id="span_000729" smilref="Machine_Learning00006.smil#span_000729">You have a couple of options here: You can run Mahout standalone without Hadoop, or you can run Mahout as a map reduce job in Hadoop. Note that you will require Mahout version 0.7, which you can download from </span><code xml:space="preserve" id="code_000172"><a href="http://archive.apache.org/dist/mahout/0.7/" external="true" id="a_000291" smilref="Machine_Learning00006.smil#a_000291">http://archive.apache.org/dist/mahout/0.7/</a></code><span class="text" id="span_000730" smilref="Machine_Learning00006.smil#span_000730"> and install to a directory.</span></p>
              <level4 id="level4_000034">
                <h4 xml:space="preserve" id="h4_000034" smilref="Machine_Learning00006.smil#h4_000034">Mahout in Standalone Mode</h4>
                <p xml:space="preserve" id="p_000373" smilref="Machine_Learning00006.smil#p_000373">In the directory with the raw data file, you run the following command:</p>
                <p xml:space="preserve" id="p_000374"><code class="preserve-whitespace" xml:space="preserve" id="code_000173" smilref="Machine_Learning00006.smil#code_000173">/your/path/to/mahout/bin/mahout fpg -i output.dat -o patterns -k 10 -s 2</code></p>
                <p id="c06-c06-para-0078" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0078">Take a look at those command-line options:</p>
                <list type="ul" id="list_000042">
                  <li id="li_000345">
                    <code xml:space="preserve" id="code_000174" smilref="Machine_Learning00006.smil#code_000174">fpg</code>
                    <span class="text" id="span_000731" smilref="Machine_Learning00006.smil#span_000731">: You're using the Frequent Pattern Growth algorithm.</span>
                  </li>
                  <li id="li_000346">
                    <code xml:space="preserve" id="code_000175" smilref="Machine_Learning00006.smil#code_000175">-i</code>
                    <span class="text" id="span_000732" smilref="Machine_Learning00006.smil#span_000732">: This is the input file you're using.</span>
                  </li>
                  <li id="li_000347">
                    <code xml:space="preserve" id="code_000176" smilref="Machine_Learning00006.smil#code_000176">-k</code>
                    <span class="text" id="span_000733" smilref="Machine_Learning00006.smil#span_000733">: For every item you're mining, you want to find 10 associated items. The highest number of item associations in the basket is what you're looking for.</span>
                  </li>
                  <li id="li_000348">
                    <code xml:space="preserve" id="code_000177" smilref="Machine_Learning00006.smil#code_000177">-s</code>
                    <span class="text" id="span_000734" smilref="Machine_Learning00006.smil#span_000734">: You only consider items that appear in more than two of the transactions you're working with.</span>
                  </li>
                </list>
                <p id="c06-c06-para-0079" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0079">Depending on the machine, it can take Mahout a few seconds to show anything onscreen from the terminal. If nothing seems to be happening, be patient.</p>
                <p id="c06-c06-para-0080" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0080">The output will look like the following:</p>
                <p xml:space="preserve" id="p_000375"><code class="preserve-whitespace" xml:space="preserve" id="code_000178" smilref="Machine_Learning00006.smil#code_000178">14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Found 3 Patterns with Least Support 149
14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Mining FTree Tree for all patterns with 1
14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Found 5 Patterns with Least Support 162
14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Mining FTree Tree for all patterns with 0
14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Found 4 Patterns with Least Support 167
14/04/29 20:15:15 INFO fpgrowth.FPGrowth: Tree Cache: First Level: Cache hits=1180 Cache Misses=21972</code></p>
                <pagenum epub:type="pagebreak" id="p132" page="normal" smilref="Machine_Learning00006.smil#p132">132</pagenum>
                <p id="c06-c06-para-0081" xml:space="preserve"><span class="text" id="span_000735" smilref="Machine_Learning00006.smil#span_000735">When Mahout has finished, it dumps the results into a file called </span><code xml:space="preserve" id="code_000179" smilref="Machine_Learning00006.smil#code_000179">patterns</code><span class="text" id="span_000736" smilref="Machine_Learning00006.smil#span_000736"> with no file extension. If you attempt to read the file as-is, then it won't make much sense. You need to use Mahout again to read the sequence file. You use the sequence dumper function that's supplied with Mahout:</span></p>
                <p xml:space="preserve" id="p_000376"><code class="preserve-whitespace" xml:space="preserve" id="code_000180" smilref="Machine_Learning00006.smil#code_000180">/your/path/to/mahout/bin/mahout seqdumper -i patterns</code></p>
                <p id="c06-c06-para-0082" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0082">Then you see the actual mined output:</p>
                <p xml:space="preserve" id="p_000377"><code class="preserve-whitespace" xml:space="preserve" id="code_000181" smilref="Machine_Learning00006.smil#code_000181">Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.mahout.fpm.pfpgrowth.convertors.string.TopKStringPatterns
Key: 91: Value: ([91],7), ([133, 233, 286, 91],5), ([111, 270, 91],5), ([177, 91],5), ([179, 91],5), ([133, 142, 91],4), ([133, 17, 91],4), ([125, 91],4), ([133, 142, 17, 91],3), ([125, 133, 142, 91],3), ([142, 5, 91],3)
Key: 136: Value: ([136],7), ([136, 142, 176, 253, 286],5), ([125, 136],5), ([136, 231],5), ([125, 133, 136, 142],4), ([136, 142, 17],4), ([125, 133, 136, 142, 17],3), ([136, 142, 17, 5],3), ([136, 301, 5],3), ([125, 133, 136, 142, 17, 5],2)
Key: 57: Value: ([57],8), ([125, 57],6), ([125, 301, 57],4), ([125, 142, 301, 57],3), ([125, 133, 301, 57],3), ([125, 17, 5, 57],3), ([239, 301, 57],3), ([111, 57],3)
Key: 30: Value: ([30],8), ([125, 30],6), ([133, 142, 30],5), ([17, 30],5), ([133, 142, 17, 30],4), ([125, 133, 142, 30],4), ([125, 17, 30],4), ([125, 133, 142, 17, 30],3), ([125, 17, 30, 5],3), ([111, 125, 30, 5],3)
Key: 275: Value: ([275],8), ([133, 275],5), ([125, 275],5), ([125, 142, 17, 275],4), ([125, 133, 142, 17, 275],3), ([125, 17, 275, 5],3), ([125, 142, 275, 5],3), ([125, 133, 17, 275],3), ([133, 275, 5],3)</code></p>
                <p id="c06-c06-para-0083" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0083">The “Inspecting the Results” section makes more sense of the results. This method does not give us the whole story, as the frequent list file isn't produced, only the patterns. To get the proper results you need Hadoop to do the work for you. If you want to use Hadoop, then read the “Mahout Using Hadoop” section.</p>
              </level4>
              <level4 id="level4_000035">
                <h4 xml:space="preserve" id="h4_000035" smilref="Machine_Learning00006.smil#h4_000035">Mahout Using Hadoop</h4>
                <p xml:space="preserve" id="p_000378"><span class="text" id="span_000737" smilref="Machine_Learning00006.smil#span_000737">Assuming that the NameNode is formatted and ready to use (Chapter 10, “Machine Learning as a Batch Process,” has a very quick run-through), then it's just a case of copying the </span><code xml:space="preserve" id="code_000182" smilref="Machine_Learning00006.smil#code_000182">output.dat</code><span class="text" id="span_000738" smilref="Machine_Learning00006.smil#span_000738"> file to the Hadoop Distributed File System (HDFS):</span></p>
                <p xml:space="preserve" id="p_000379"><code class="preserve-whitespace" xml:space="preserve" id="code_000183" smilref="Machine_Learning00006.smil#code_000183">hadoop fs –put output.dat output.dat</code></p>
                <pagenum epub:type="pagebreak" id="p133" page="normal" smilref="Machine_Learning00006.smil#p133">133</pagenum>
                <p id="c06-c06-para-0085" xml:space="preserve"><span class="text" id="span_000739" smilref="Machine_Learning00006.smil#span_000739">Then you run Mahout in the same way described in the preceding section, but this time you're adding the </span><code xml:space="preserve" id="code_000184" smilref="Machine_Learning00006.smil#code_000184">–method</code><span class="text" id="span_000740" smilref="Machine_Learning00006.smil#span_000740"> flag in the command:</span></p>
                <p xml:space="preserve" id="p_000380"><code class="preserve-whitespace" xml:space="preserve" id="code_000185" smilref="Machine_Learning00006.smil#code_000185">mahout fpg –i output.dat –o patterns –k 10 –method mapreduce –s 2</code></p>
                <p id="c06-c06-para-0086" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0086">Mahout will use its MapReduce methods in Hadoop using the data stored in HDFS, which is great when there's a lot of data to process.</p>
                <p id="c06-c06-para-0087" xml:space="preserve"><span class="text" id="span_000741" smilref="Machine_Learning00006.smil#span_000741">When the task is complete, you see a directory called </span><code xml:space="preserve" id="code_000186" smilref="Machine_Learning00006.smil#code_000186">patterns</code><span class="text" id="span_000742" smilref="Machine_Learning00006.smil#span_000742"> and within that directory there will be four files:</span></p>
                <p xml:space="preserve" id="p_000381"><code class="preserve-whitespace" xml:space="preserve" id="code_000187" smilref="Machine_Learning00006.smil#code_000187">jason@myserver:˜/mahoutdemo/patterns$ ls -l
total 20
-rwxrwxrwx 1 jason jason 6098 May  1 00:06 fList
drwxrwxr-x 2 jason jason 4096 May  1 00:06 fpgrowth
drwxrwxr-x 2 jason jason 4096 May  1 00:06 frequentpatterns
drwxrwxr-x 2 jason jason 4096 May  1 00:06 parallelcounting
jason@myserver:˜/mahoutdemo/patterns$</code></p>
                <p id="c06-c06-para-0088" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0088">The output files are specific to Mahout. You need to write some code to interpret the results.</p>
              </level4>
            </level3>
            <level3 id="level3_000119">
              <h3 xml:space="preserve" id="h3_000119" smilref="Machine_Learning00006.smil#h3_000119">Inspecting the Results</h3>
              <p xml:space="preserve" id="p_000382" smilref="Machine_Learning00006.smil#p_000382">The results are in a raw format that Mahout can understand. There is a sequence dumper that's available, though, so you can have a look.</p>
              <p xml:space="preserve" id="p_000383"><code class="preserve-whitespace" xml:space="preserve" id="code_000188" smilref="Machine_Learning00006.smil#code_000188">jason@bigdatagames:˜/mahoutdemo$ /usr/local/mahout/bin/mahout seqdumper -i patterns/frequentpatterns/part-r-00000
MAHOUT_LOCAL is set, so we don't add HADOOP_CONF_DIR to classpath.
MAHOUT_LOCAL is set, running locally
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/mahout-distribution-0.8/mahout-examples-0.8-job.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/mahout-distribution-0.8/lib/slf4j-jcl-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.JCLLoggerFactory]
May 01, 2014 1:50:45 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--endPhase=[2147483647], --input=[patterns/frequentpatterns/part-r-00000], --startPhase=[0], --tempDir=[temp]}
Input Path: patterns/frequentpatterns/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.mahout.fpm.pfpgrowth.convertors.string.TopKStringPatterns
Key: 1: Value: ([1],80), ([142, 1],42), ([133, 1],42), ([125, 1],39), ([133, 142, 1],30), ([142, 125, 1],29), ([133, 125, 1],29), ([133, 142, 125, 1],22), ([133, 142, 154, 1],20), ([133, 142, 125, 154, 1],15)
Key: 10: Value: ([10],39), ([133, 10],22), ([142, 10],21), ([125, 10],21), ([142, 125, 10],15), ([133, 142, 10],15), ([133, 125, 10],14), ([133, 142, 176, 10],12), ([133, 142, 125, 10],11), ([133, 142, 125, 176, 10],10)
Key: 100: Value: ([100],35), ([17, 100],22), ([142, 100],22), ([133, 100],20), ([142, 17, 100],18), ([133, 17, 100],17), ([133, 142, 100],15), ([133, 142, 17, 100],14), ([133, 125, 100],14), ([133, 142, 125, 17, 100],12)</code></p>
              <p id="c06-c06-para-0090" xml:space="preserve"><span class="text" id="span_000743" smilref="Machine_Learning00006.smil#span_000743">The </span><pagenum epub:type="pagebreak" id="p134" page="normal" smilref="Machine_Learning00006.smil#p134">134</pagenum><span class="text" id="span_000744" smilref="Machine_Learning00006.smil#span_000744">product item number (</span><code xml:space="preserve" id="code_000189" smilref="Machine_Learning00006.smil#code_000189">Key</code><span class="text" id="span_000745" smilref="Machine_Learning00006.smil#span_000745">) is listed along with the top 10 associations. So, for example, product 1 appears in 80 transactions, and it also appears 42 times along with items 142 and 133, and so on. Code-wise it's quite long, so I've provided the edited highlights. You can see the full code listing in the code examples for this book, and you can download them from </span><code xml:space="preserve" id="code_000190"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000292" smilref="Machine_Learning00006.smil#a_000292">http://www.wiley.com/go/machinelearning</a></code><span class="text" id="span_000746" smilref="Machine_Learning00006.smil#span_000746">.</span></p>
              <p id="c06-c06-para-0091" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0091">There are two files you have to load in: the frequency file and the frequency patterns file. You read more about the latter shortly; here's the method for loading in the frequency file:</p>
              <p xml:space="preserve" id="p_000384"><code class="preserve-whitespace" xml:space="preserve" id="code_000191"><strong id="strong_000255" smilref="Machine_Learning00006.smil#strong_000255">public static</strong><span class="text" id="span_000747" smilref="Machine_Learning00006.smil#span_000747"> Map&lt;Integer, Long&gt; readFrequencyFile(Configuration configuration, String fileName) </span><strong id="strong_000256" smilref="Machine_Learning00006.smil#strong_000256">throws</strong><span class="text" id="span_000748" smilref="Machine_Learning00006.smil#span_000748"> Exception {
        FileSystem fs = FileSystem.</span><em id="em_000166" smilref="Machine_Learning00006.smil#em_000166">get</em><span class="text" id="span_000749" smilref="Machine_Learning00006.smil#span_000749">(configuration);
        org.apache.hadoop.io.SequenceFile.Reader frequencyReader = </span><strong id="strong_000257" smilref="Machine_Learning00006.smil#strong_000257">new</strong><span class="text" id="span_000750" smilref="Machine_Learning00006.smil#span_000750"> org.apache.hadoop.io.SequenceFile.Reader(fs,
                </span><strong id="strong_000258" smilref="Machine_Learning00006.smil#strong_000258">new</strong><span class="text" id="span_000751" smilref="Machine_Learning00006.smil#span_000751"> Path(fileName), configuration);
        Map&lt;Integer, Long&gt; frequency = </span><strong id="strong_000259" smilref="Machine_Learning00006.smil#strong_000259">new</strong><span class="text" id="span_000752" smilref="Machine_Learning00006.smil#span_000752"> HashMap&lt;Integer, Long&gt;();
        Text key = </span><strong id="strong_000260" smilref="Machine_Learning00006.smil#strong_000260">new</strong><span class="text" id="span_000753" smilref="Machine_Learning00006.smil#span_000753"> Text();
        LongWritable value = </span><strong id="strong_000261" smilref="Machine_Learning00006.smil#strong_000261">new</strong><span class="text" id="span_000754" smilref="Machine_Learning00006.smil#span_000754"> LongWritable();
        </span><strong id="strong_000262" smilref="Machine_Learning00006.smil#strong_000262">while</strong><span class="text" id="span_000755" smilref="Machine_Learning00006.smil#span_000755">(frequencyReader.next(key, value)) {
            frequency.put(Integer.</span><em id="em_000167" smilref="Machine_Learning00006.smil#em_000167">parseInt</em><span class="text" id="span_000756" smilref="Machine_Learning00006.smil#span_000756">(key.toString()), value.get());
        }
        </span><strong id="strong_000263" smilref="Machine_Learning00006.smil#strong_000263">return</strong><span class="text" id="span_000757" smilref="Machine_Learning00006.smil#span_000757"> frequency;
    }</span></code></p>
              <p id="c06-c06-para-0092" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0092">This part is straightforward, but you're using Hadoop's sequence file reader and not a normal file class to read in the data. After it's opened, you iterate through the keys and the values adding them to the HashMap.</p>
              <p id="c06-c06-para-0093" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0093">The products are still in your MySQL database, so you need a method to store those in a Map, too.</p>
              <p xml:space="preserve" id="p_000385"><code class="preserve-whitespace" xml:space="preserve" id="code_000192"><strong id="strong_000264" smilref="Machine_Learning00006.smil#strong_000264">public static</strong><span class="text" id="span_000758" smilref="Machine_Learning00006.smil#span_000758"> Map&lt;Integer, String&gt; loadItems() {
        Map&lt;Integer, String&gt; products = </span><strong id="strong_000265" smilref="Machine_Learning00006.smil#strong_000265">new</strong><span class="text" id="span_000759" smilref="Machine_Learning00006.smil#span_000759"> HashMap&lt;Integer, String&gt;();
        </span><strong id="strong_000266" smilref="Machine_Learning00006.smil#strong_000266">try</strong><span class="text" id="span_000760" smilref="Machine_Learning00006.smil#span_000760"> {
            Connection con = DriverManager.</span><em id="em_000168" smilref="Machine_Learning00006.smil#em_000168">getConnection</em><span class="text" id="span_000761" smilref="Machine_Learning00006.smil#span_000761">("jdbc:mysql://localhost/apriori","root","");
            PreparedStatement pstmt = con.prepareStatement("SELECT * FROM products");
            ResultSet rs = pstmt.executeQuery();
            </span><strong id="strong_000267" smilref="Machine_Learning00006.smil#strong_000267">while</strong><span class="text" id="span_000762" smilref="Machine_Learning00006.smil#span_000762">(rs.next()) {
                products.put(</span><strong id="strong_000268" smilref="Machine_Learning00006.smil#strong_000268">new</strong><span class="text" id="span_000763" smilref="Machine_Learning00006.smil#span_000763"> Integer(rs.getInt("id")), rs.getString("productname"));
            }
            rs.close();
            pstmt.close();
            con.close();
        } </span><strong id="strong_000269" smilref="Machine_Learning00006.smil#strong_000269">catch</strong><span class="text" id="span_000764" smilref="Machine_Learning00006.smil#span_000764">(Exception e) {
            e.printStackTrace();
        }
        </span><strong id="strong_000270" smilref="Machine_Learning00006.smil#strong_000270">return</strong><span class="text" id="span_000765" smilref="Machine_Learning00006.smil#span_000765"> products;
    }</span></code></p>
              <pagenum epub:type="pagebreak" id="p135" page="normal" smilref="Machine_Learning00006.smil#p135">135</pagenum>
              <p id="c06-c06-para-0094" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0094">Next, you execute the methods to calculate the lift and conviction of the results and the main method to start everything off.</p>
              <p xml:space="preserve" id="p_000386"><code class="preserve-whitespace" xml:space="preserve" id="code_000193"><strong id="strong_000271" smilref="Machine_Learning00006.smil#strong_000271">private static double</strong><span class="text" id="span_000766" smilref="Machine_Learning00006.smil#span_000766"> calcLift(</span><strong id="strong_000272" smilref="Machine_Learning00006.smil#strong_000272">double</strong><span class="text" id="span_000767" smilref="Machine_Learning00006.smil#span_000767"> occurrence, </span><strong id="strong_000273" smilref="Machine_Learning00006.smil#strong_000273">int</strong><span class="text" id="span_000768" smilref="Machine_Learning00006.smil#span_000768"> transcationcount, </span><strong id="strong_000274" smilref="Machine_Learning00006.smil#strong_000274">long</strong><span class="text" id="span_000769" smilref="Machine_Learning00006.smil#span_000769"> firstfreq, </span><strong id="strong_000275" smilref="Machine_Learning00006.smil#strong_000275">long</strong><span class="text" id="span_000770" smilref="Machine_Learning00006.smil#span_000770"> otheritemoccurences) {
        </span><strong id="strong_000276" smilref="Machine_Learning00006.smil#strong_000276">return</strong><span class="text" id="span_000771" smilref="Machine_Learning00006.smil#span_000771"> ((</span><strong id="strong_000277" smilref="Machine_Learning00006.smil#strong_000277">double</strong><span class="text" id="span_000772" smilref="Machine_Learning00006.smil#span_000772">)occurrence * transcationcount) / (firstfreq * otheritemoccurences);
    }
    </span><strong id="strong_000278" smilref="Machine_Learning00006.smil#strong_000278">private static double</strong><span class="text" id="span_000773" smilref="Machine_Learning00006.smil#span_000773"> calcConviction(</span><strong id="strong_000279" smilref="Machine_Learning00006.smil#strong_000279">double</strong><span class="text" id="span_000774" smilref="Machine_Learning00006.smil#span_000774"> confidence, </span><strong id="strong_000280" smilref="Machine_Learning00006.smil#strong_000280">int</strong><span class="text" id="span_000775" smilref="Machine_Learning00006.smil#span_000775"> transactioncount, </span><strong id="strong_000281" smilref="Machine_Learning00006.smil#strong_000281">double</strong><span class="text" id="span_000776" smilref="Machine_Learning00006.smil#span_000776"> otheroccurrences) {
        </span><strong id="strong_000282" smilref="Machine_Learning00006.smil#strong_000282">return</strong><span class="text" id="span_000777" smilref="Machine_Learning00006.smil#span_000777"> (1.0 - otheroccurrences / transactioncount) / (1.0 - confidence);
    }
    </span><strong id="strong_000283" smilref="Machine_Learning00006.smil#strong_000283">public static void</strong><span class="text" id="span_000778" smilref="Machine_Learning00006.smil#span_000778"> main(String[] args)  </span><strong id="strong_000284" smilref="Machine_Learning00006.smil#strong_000284">throws</strong><span class="text" id="span_000779" smilref="Machine_Learning00006.smil#span_000779"> Exception{
        Configuration configuration = </span><strong id="strong_000285" smilref="Machine_Learning00006.smil#strong_000285">new</strong><span class="text" id="span_000780" smilref="Machine_Learning00006.smil#span_000780"> Configuration();
        </span><em id="em_000169" smilref="Machine_Learning00006.smil#em_000169">processResults</em><span class="text" id="span_000781" smilref="Machine_Learning00006.smil#span_000781">(configuration,</span><em id="em_000170" smilref="Machine_Learning00006.smil#em_000170">loadItems</em><span class="text" id="span_000782" smilref="Machine_Learning00006.smil#span_000782">());
    }</span></code></p>
              <p id="c06-c06-para-0095" xml:space="preserve"><span class="text" id="span_000783" smilref="Machine_Learning00006.smil#span_000783">The final part is the </span><code xml:space="preserve" id="code_000194" smilref="Machine_Learning00006.smil#code_000194">processResults</code><span class="text" id="span_000784" smilref="Machine_Learning00006.smil#span_000784"> method; it's quite a long routine that reads in the frequency patterns file and then processes the data. Finally, it prints out the item and the associated item with the support, confidence, lift, and conviction.</span></p>
            </level3>
            <level3 id="level3_000120">
              <h3 xml:space="preserve" id="h3_000120" smilref="Machine_Learning00006.smil#h3_000120">Putting It All Together</h3>
              <p xml:space="preserve" id="p_000387" smilref="Machine_Learning00006.smil#p_000387">You need to extract the results from HDFS before you can process them, so you need to run the following two lines from the command line:</p>
              <p xml:space="preserve" id="p_000388"><code class="preserve-whitespace" xml:space="preserve" id="code_000195" smilref="Machine_Learning00006.smil#code_000195">hadoop fs –getmerge patterns/frequentpatterns fpatters.seq
hadoop fs –get patterns/fList flist.seq</code></p>
              <pagenum epub:type="pagebreak" id="p136" page="normal" smilref="Machine_Learning00006.smil#p136">136</pagenum>
              <p id="c06-c06-para-0097" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0097">Now, you can run the DataReader program to work through the results. When the program is run, you'll see the following output:</p>
              <p xml:space="preserve" id="p_000389"><code class="preserve-whitespace" xml:space="preserve" id="code_000196" smilref="Machine_Learning00006.smil#code_000196">White Bread &gt;&gt;2pct. Milk: support=0.051, conf=0.470, lift=3.947, conviction=1.662
Potato Chips &gt;&gt;2pct. Milk: support=0.045, conf=0.409, lift=4.189, conviction=1.528
White Bread &gt;&gt;Tomatoes: support=0.040, conf=0.611, lift=5.134, conviction=2.265
White Bread &gt;&gt;Eggs: support=0.055, conf=0.449, lift=3.773, conviction=1.599
2pct. Milk &gt;&gt;Eggs: support=0.052, conf=0.425, lift=3.883, conviction=1.549 </code></p>
              <p id="c06-c06-para-0098" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0098">Mahout doesn't handle multiple item sets, which might be a drawback to you. For many of us, though, it's a good starting point.</p>
            </level3>
            <level3 id="level3_000121">
              <h3 xml:space="preserve" id="h3_000121" smilref="Machine_Learning00006.smil#h3_000121">Further Development</h3>
              <p xml:space="preserve" id="p_000390" smilref="Machine_Learning00006.smil#p_000390">The boilerplate code offers a brief introduction on how to get association rules learning up and running in Java. By extending your use of the MySQL database, you can set up another table of the rules output.</p>
              <p xml:space="preserve" id="p_000391"><code class="preserve-whitespace" xml:space="preserve" id="code_000197" smilref="Machine_Learning00006.smil#code_000197">mysql&gt; create table associations(
    -&gt; id int(11) not null primary key auto_increment,
    -&gt; productid int(11) not null default -1,
    -&gt; associationproductid int(11) not null default -1,
    -&gt; support_value double,
    -&gt; lift_value double,
    -&gt; confidence_value double,
    -&gt; conviction_value double);
Query OK, 0 rows affected (0.26 sec)
mysql&gt; </code></p>
              <p id="c06-c06-para-0100" xml:space="preserve"><span class="text" id="span_000785" smilref="Machine_Learning00006.smil#span_000785">The </span><code xml:space="preserve" id="code_000198" smilref="Machine_Learning00006.smil#code_000198">processResults</code><span class="text" id="span_000786" smilref="Machine_Learning00006.smil#span_000786"> method can be changed so that instead of printing to the console, it can save data to this table instead. This makes retrieving information, especially in a web context, much easier.</span></p>
              <p id="c06-c06-para-0101" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0101">It's also worth varying the minimum support and confidence values, because you might see some small changes in the output that can work to your advantage.</p>
            </level3>
          </level2>
          <level2 id="level2_000055">
            <h2 id="c06-c06_level1_5" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06_level1_5">Summary</h2>
            <pagenum epub:type="pagebreak" id="p137" page="normal" smilref="Machine_Learning00006.smil#p137">137</pagenum>
            <p xml:space="preserve" id="p_000392" smilref="Machine_Learning00006.smil#p_000392">Association rules learning is very domain specific, so the case for how it will work in your organization will vary from case to case. This chapter offered a brief overview and a working demo with Mahout either in a standalone run or in Hadoop.</p>
            <p id="c06-c06-para-0103" xml:space="preserve" smilref="Machine_Learning00006.smil#c06-c06-para-0103">Chapter 10 covers the journey with Hadoop a little deeper. Chapter 7 covers support vector machines.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c07">
        <section epub:type="chapter" id="section_000008">
          <header id="header_000007">
            <h1 id="c07-c7" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c7">Chapter 7 Support Vector Machines</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p139" page="normal" smilref="Machine_Learning00006.smil#p139">139</pagenum>
          <p xml:space="preserve" id="p_000393" smilref="Machine_Learning00006.smil#p_000393">With most machine learning tasks, the aim is usually to classify something into a group that you can then inspect later. When it's a couple of class types that you're trying to classify, then it's a fairly trivial matter to perform the classification. When you are dealing with many types of classes, the process becomes more of a challenge. Support vector machines help you work through the challenging classifications.</p>
          <p id="c07-c07-para-0002" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0002">This chapter looks at support vector machines: how the basic algorithm works in a binary classification sense, and then an expanded discussion on the tool.</p>
          <level2 id="level2_000056">
            <h2 id="c07-c07_level1_1" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07_level1_1">What Is a Support Vector Machine?</h2>
            <p xml:space="preserve" id="p_000394"><span class="text" id="span_000787" smilref="Machine_Learning00006.smil#span_000787">A </span><em id="em_000171" smilref="Machine_Learning00006.smil#em_000171">support vector machine</em><span class="text" id="span_000788" smilref="Machine_Learning00006.smil#span_000788"> is essentially a technique for classifying objects. It's a supervised learning method, so the usual route for getting a support vector machine set up would be to have some training data and some data to test the algorithm. With support vector machines, you have the linear classification—it's either that object, or it's that object—or non-linear. This chapter looks at both types.</span></p>
            <p id="c07-c07-para-0004" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0004">There is a lot of comparison of using a support vector machine versus the artificial neural network, especially as some methods of finding minimum errors and the Sigmoid function are used in both.</p>
            <pagenum epub:type="pagebreak" id="p140" page="normal" smilref="Machine_Learning00006.smil#p140">140</pagenum>
            <p id="c07-c07-para-0005" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0005">It's easy to imagine a support vector machine as either a two- or three-dimensional plot with each object located within. Essentially, every object is a point in that space. If there's sufficient distance in the area, then the process of classifying is easy enough.</p>
          </level2>
          <level2 id="level2_000057">
            <h2 id="c07-c07_level1_2" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07_level1_2">Where Are Support Vector Machines Used?</h2>
            <p xml:space="preserve" id="p_000395" smilref="Machine_Learning00006.smil#p_000395">Support vector machines are used in a variety of classification scenarios, such as image recognition and hand-writing pattern recognition.</p>
            <p id="c07-c07-para-0007" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0007">Image classification can be greatly improved with the use of support vector machines. Being able to classify thousands or millions of images is becoming more and more important with the use of smartphones and applications like Instagram. Support vector machines can also do text classification on normal text or web documents, for instance.</p>
            <p id="c07-c07-para-0008" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0008">Medical science has long used support vector machines for protein classification. The National Institute of Health has even developed a support vector machine protein software library. It's a web-based tool that classifies a protein into its functional family.</p>
            <p id="c07-c07-para-0009" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0009">Some people criticize the support vector machine because it can be difficult to understand, unless you are blessed with a very good mathematician who can guide and explain to you what is going on. In some cases you are left with a black box implementation of a support vector machine that is taking in input data and producing output data, but you have little knowledge in between.</p>
            <p id="c07-c07-para-0010" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0010">Machine learning with support vector machines takes the concept of a perceptron (as explained in Chapter 5) a little bit further to maximize the geometric margin. It's one of the reasons why support vector machines and artificial neural networks are frequently compared in function and performance.</p>
          </level2>
          <level2 id="level2_000058">
            <h2 id="c07-c07_level1_3" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07_level1_3">The Basic Classification Principles</h2>
            <p xml:space="preserve" id="p_000396" smilref="Machine_Learning00006.smil#p_000396">For those who've not immersed themselves in the way classification works, this section offers an abridged version. The next section covers how the support vector machine works in terms of the classification. I'm keeping the math as simple as possible.</p>
            <level3 id="level3_000122">
              <h3 xml:space="preserve" id="h3_000122" smilref="Machine_Learning00006.smil#h3_000122">Binary and Multiclass Classification</h3>
              <p xml:space="preserve" id="p_000397"><span class="text" id="span_000789" smilref="Machine_Learning00006.smil#span_000789">Consider a basic classification problem: You want to figure out which objects are squares and which are circles. These squares and circles could represent </span><pagenum epub:type="pagebreak" id="p141" page="normal" smilref="Machine_Learning00006.smil#p141">141</pagenum><span class="text" id="span_000790" smilref="Machine_Learning00006.smil#span_000790">anything you want—cats and dogs, humans and aliens, or something else. </span><a id="c07-c07-fig-anc-0001" href="#c07-c07-fig-0001" external="false" smilref="Machine_Learning00006.smil#c07-c07-fig-anc-0001">Figure 7-1</a><span class="text" id="span_000791" smilref="Machine_Learning00006.smil#span_000791"> illustrates the two sets of objects.</span></p>
              <figure id="figure_000054">
                <img class="center" src="images/c07f001.jpg" alt="image" id="img_000073" />
                <figcaption id="figcaption_000040">
                  <p xml:space="preserve" id="p_000398"><span class="figureLabel" id="span_000792"><a id="c07-c07-fig-0001" href="#c07-c07-fig-anc-0001" external="false"><strong id="strong_000286" smilref="Machine_Learning00006.smil#strong_000286">Figure 7-1</strong></a></span><span class="text" id="span_000793" smilref="Machine_Learning00006.smil#span_000793"> Two objects to classify</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0013" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0013">This task would be considered a binary classification problem, because there are only two outcomes; it's either one object or the other. Think of it as a 0 or a 1. With some supervised learning, you could figure out pretty quickly where those classes would lie with a reasonable amount of confidence.</p>
              <p id="c07-c07-para-0014" xml:space="preserve"><span class="text" id="span_000794" smilref="Machine_Learning00006.smil#span_000794">What about when there are more than two classes? For example, you can add triangles to the mix, as shown in </span><a id="c07-c07-fig-anc-0002" href="#c07-c07-fig-0002" external="false" smilref="Machine_Learning00006.smil#c07-c07-fig-anc-0002">Figure 7-2</a><span class="text" id="span_000795" smilref="Machine_Learning00006.smil#span_000795">.</span></p>
              <figure id="figure_000055">
                <img class="center" src="images/c07f002.jpg" alt="image" id="img_000074" />
                <figcaption id="figcaption_000041">
                  <p xml:space="preserve" id="p_000399"><span class="figureLabel" id="span_000796"><a id="c07-c07-fig-0002" href="#c07-c07-fig-anc-0002" external="false"><strong id="strong_000287" smilref="Machine_Learning00006.smil#strong_000287">Figure 7-2</strong></a></span><span class="text" id="span_000797" smilref="Machine_Learning00006.smil#span_000797"> Three objects to classify</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p142" page="normal" smilref="Machine_Learning00006.smil#p142">142</pagenum>
              <p id="c07-c07-para-0015" xml:space="preserve" smilref="Machine_Learning00006.smil#c07-c07-para-0015">Binary classification isn't going to work here. You're now presented with a multiclass classification problem. Because there are more than two classes, you have to use an algorithm that can classify these classes accordingly. It's worth noting, though, that some multiclass methods use pair-wise combinations of binary classifiers to get to a prediction.</p>
            </level3>
            <level3 id="level3_000123">
              <h3 xml:space="preserve" id="h3_000123" smilref="Machine_Learning00006.smil#h3_000123">Linear Classifiers</h3>
              <p xml:space="preserve" id="p_000400"><span class="text" id="span_000798" smilref="Machine_Learning00006.smil#span_000798">To determine in which group an object belongs, you use a linear classifier to establish the locations of the objects and see if there's a neat dividing line—called a </span><em id="em_000172" smilref="Machine_Learning00006.smil#em_000172">hyperplane</em><span class="text" id="span_000799" smilref="Machine_Learning00006.smil#span_000799">—in place; there should be a group of objects clearly on one side of the line and another group of objects just as clearly on the opposite side. (That's the theory, anyway. Life is rarely like that, which is something that's covered more later in the chapter.) Assume that all your ducks are in a row…well, two separate groups.</span></p>
              <p id="c07-c07-para-0017" xml:space="preserve"><span class="text" id="span_000800" smilref="Machine_Learning00006.smil#span_000800">As shown in </span><a id="c07-c07-fig-anc-0003" href="#c07-c07-fig-0003" external="false" smilref="Machine_Learning00006.smil#c07-c07-fig-anc-0003">Figure 7-3</a><span class="text" id="span_000801" smilref="Machine_Learning00006.smil#span_000801">, visually it looks straightforward, but you need to compute it mathematically. Every object that you classify is called a point, and every point has a set of features.</span></p>
              <figure id="figure_000056">
                <img class="center" src="images/c07f003.jpg" alt="image" id="img_000075" />
                <figcaption id="figcaption_000042">
                  <p xml:space="preserve" id="p_000401"><span class="figureLabel" id="span_000802"><a id="c07-c07-fig-0003" href="#c07-c07-fig-anc-0003" external="false"><strong id="strong_000288" smilref="Machine_Learning00007.smil#strong_000288">Figure 7-3</strong></a></span><span class="text" id="span_000803" smilref="Machine_Learning00007.smil#span_000803"> Linear classification with a hyperplane</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0018" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0018">For each point in the graph, you know there is an x-axis value and there is a y-axis value. The classification point is calculated as</p>
              <p class="informalEquation" xml:space="preserve" id="p_000402"><img src="images/c07_math_001.png" alt="equation" id="img_000076" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mtext mathvariant="italic">sign</mtext><mfenced open="(" close=")"><mrow><mtext mathvariant="italic">ax</mtext><mo>+</mo><mi>b</mi><mi>y</mi><mo>+</mo><mi>c</mi></mrow></mfenced></mrow></math>--></p>
              <p id="c07-c07-para-0019" xml:space="preserve"><span class="text" id="span_000804" smilref="Machine_Learning00007.smil#span_000804">The values for a, b, and c are the values that define the line; these values are ones that you choose, and you'll need to tweak them along the way until </span><pagenum epub:type="pagebreak" id="p143" page="normal" smilref="Machine_Learning00007.smil#p143">143</pagenum><span class="text" id="span_000805" smilref="Machine_Learning00007.smil#span_000805">you get a good fit (clear separation). What you are interested in, though, is the result; you want a function that returns +1 if the result of the function is positive, signifying the point is in one category, and returns -1 when the point is in the other category. The function's resulting value (+1 or -1) must be correct for every point that you're trying to classify.</span></p>
              <p id="c07-c07-para-0020" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0020">Don't forget that you have a training file with the correctly classified data so that you can judge the function's correctness; this approach is a supervised method of learning. This step has to be done to figure out where the line fits. Points that are further away from the line show more confidence that they belong to a specific class.</p>
            </level3>
            <level3 id="level3_000124">
              <h3 xml:space="preserve" id="h3_000124" smilref="Machine_Learning00007.smil#h3_000124">Confidence</h3>
              <p xml:space="preserve" id="p_000403" smilref="Machine_Learning00007.smil#p_000403">You've just established that each point has a confidence based on its distance from the hyperplane line. The confidence can be translated into a probability. That gives the equation of</p>
              <p class="informalEquation" xml:space="preserve" id="p_000404"><img src="images/c07_math_002.png" alt="equation" id="img_000077" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>P</mi><mfenced open="[" close="]"><mrow><mi>l</mi><mo>=</mo><mo form="prefix">&#x0002B;</mo><mn>1</mn><mo stretchy="true">|</mo><mi>x</mi></mrow></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">exp</mi><mo>&#x02061;</mo><mfenced open="(" close=")"><mrow><mo>&#x02212;</mo><mfenced open="(" close=")"><mrow><mtext mathvariant="italic">ax</mtext><mo>+</mo><mi>b</mi><mi>y</mi><mo>+</mo><mi>c</mi></mrow></mfenced></mrow></mfenced></mrow></mfrac></mrow></math>--></p>
              <p id="c07-c07-para-0022" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0022">This is for one point. What you need is the probability for every set of lines; these are then assigned to each of the objects in the training data.</p>
              <p class="informalEquation" xml:space="preserve" id="p_000405"><img src="images/c07_math_003.png" alt="equation" id="img_000078" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mstyle displaystyle="true"><munderover><mo>&#x0220F;</mo><mrow><mi>i</mi><mo>&#x02212;</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>P</mi><mfenced open="[" close="]"><mrow><msub><mi>l</mi><mi>i</mi></msub><mo stretchy="true">|</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></mfenced></mrow></mstyle><mo>=</mo><mstyle displaystyle="true"><munderover><mo>&#x0220F;</mo><mrow><mi>i</mi><mo>&#x02212;</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">exp</mi><mo>&#x02061;</mo><mfenced open="(" close=")"><mrow><mo>&#x02212;</mo><msub><mi>l</mi><mi>i</mi></msub><mfenced open="(" close=")"><mrow><mi>a</mi><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mi>c</mi></mrow></mfenced></mrow></mfenced></mrow></mfrac></mrow></mstyle></mrow></math>--></p>
              <p id="c07-c07-para-0023" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0023">Probabilities are multiplied because the points have been drawn independently. You have an equation for each point that indicates how probable it is that a hyperplane is producing the correct categorization. Combining the probabilities for each point produces what is commonly defined as the “likelihood of the data”; you are looking for a number as close to 1 as possible.</p>
              <p id="c07-c07-para-0024" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0024">Remember that probability is based on a value between 0 and 1 (for a recap, check out Chapter 4). Within a set of objects, you're looking for a set of line parameters with the highest probability that confirms the categorization is correct.</p>
            </level3>
            <level3 id="level3_000125">
              <h3 xml:space="preserve" id="h3_000125" smilref="Machine_Learning00007.smil#h3_000125">Maximizing and Minimizing to Find the Line</h3>
              <p xml:space="preserve" id="p_000406" smilref="Machine_Learning00007.smil#p_000406">Using a log function that is always increasing maximizes values that are above the equation. So, you end up with a function written as</p>
              <p class="informalEquation" xml:space="preserve" id="p_000407"><img src="images/c07_math_004.png" alt="equation" id="img_000079" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mstyle displaystyle="true"><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo>&#x02212;</mo><mi mathvariant="normal">log</mi><mo>&#x02061;</mo><mfenced open="(" close=")"><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">exp</mi><mo>&#x02061;</mo><mfenced open="(" close=")"><mrow><mo>&#x02212;</mo><msub><mi>l</mi><mi>i</mi></msub><mfenced open="(" close=")"><mrow><mi>a</mi><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mi>c</mi></mrow></mfenced></mrow></mfenced></mrow></mfenced></mrow></mstyle></mrow></math>--></p>
              <pagenum epub:type="pagebreak" id="p144" page="normal" smilref="Machine_Learning00007.smil#p144">144</pagenum>
              <p id="c07-c07-para-0026" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0026">To achieve minimization, you just multiply the equation by -1. It then becomes a “cost” or “loss” function. The goal is to find line parameters that minimize this function.</p>
              <p id="c07-c07-para-0027" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0027">Linear classifiers are usually fast; they will process even large sets of objects with ease. This is a good thing when using them for document classification where the word frequencies might require measuring.</p>
            </level3>
          </level2>
          <level2 id="level2_000059">
            <h2 id="c07-c07_level1_4" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07_level1_4">How Support Vector Machines Approach Classification</h2>
            <p xml:space="preserve" id="p_000408" smilref="Machine_Learning00007.smil#p_000408">The basic explanation of linear classification is that the hyperplane creates the line that classifies one object and another. Support vector machines take that a step further.</p>
            <p id="c07-c07-para-0029" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0029">Within the short space available, I outline how support vector machines work in both linear and non-linear form. I also show you how to use Weka to do some practical work for you.</p>
            <level3 id="level3_000126">
              <h3 xml:space="preserve" id="h3_000126" smilref="Machine_Learning00007.smil#h3_000126">Using Linear Classification</h3>
              <p xml:space="preserve" id="p_000409" smilref="Machine_Learning00007.smil#p_000409">Look at the set of circle and square objects again. You know how a hyperplane divides the objects into either 1 or -1 on the plane.</p>
              <p id="c07-c07-para-0031" xml:space="preserve"><span class="text" id="span_000806" smilref="Machine_Learning00007.smil#span_000806">Extending that notion further, support vector machines define the maximum margin, assuming that the hyperplane is separated in a linear fashion. You can see this in </span><a id="c07-c07-fig-anc-0004" href="#c07-c07-fig-0004" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0004">Figure 7-4</a><span class="text" id="span_000807" smilref="Machine_Learning00007.smil#span_000807"> with the main hyperplane line giving the written notation of</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000410"><img src="images/c07_math_005.png" alt="equation" id="img_000080" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>w</mi><mo>&#x02022;</mo><mi>x</mi><mo>&#x02212;</mo><mi>b</mi><mo>=</mo><mn>0</mn></mrow></math>--></p>
              <figure id="figure_000057">
                <img class="center" src="images/c07f004.jpg" alt="image" id="img_000081" />
                <figcaption id="figcaption_000043">
                  <p xml:space="preserve" id="p_000411"><span class="figureLabel" id="span_000808"><a id="c07-c07-fig-0004" href="#c07-c07-fig-anc-0004" external="false"><strong id="strong_000289" smilref="Machine_Learning00007.smil#strong_000289">Figure 7-4</strong></a></span> <pagenum epub:type="pagebreak" id="p145" page="normal" smilref="Machine_Learning00007.smil#p145">145</pagenum><span class="text" id="span_000809" smilref="Machine_Learning00007.smil#span_000809">Support vector machines max margin hyperplane</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0032" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0032">This dot product shows the normal vector, and x is the point of the object. There is an offset of the hyperplane that goes from the origin to the normal vector.</p>
              <p id="c07-c07-para-0033" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0033">As the objects are linearly separable, you can create another two hyperplanes—edge hyperplanes—that define the offset on either side of the main hyperplane. There are no objects within the region that spans between the main hyperplane and the edge hyperplanes.</p>
              <p id="c07-c07-para-0034" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0034">On one side, there's the equation</p>
              <p class="informalEquation" xml:space="preserve" id="p_000412"><img src="images/c07_math_006.png" alt="equation" id="img_000082" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>w</mi><mo>&#x02022;</mo><mi>x</mi><mo>&#x02212;</mo><mi>b</mi><mo>=</mo><mn>1</mn></mrow></math>--></p>
              <p id="c07-c07-para-0035" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0035">and on the other side there's</p>
              <p class="informalEquation" xml:space="preserve" id="p_000413"><img src="images/c07_math_007.png" alt="equation" id="img_000083" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>w</mi><mo>&#x02022;</mo><mi>x</mi><mo>&#x02212;</mo><mi>b</mi><mo>=</mo><mo form="prefix">&#x02212;</mo><mn>1</mn><mi>v</mi></mrow></math>--></p>
              <p id="c07-c07-para-0036" xml:space="preserve"><span class="text" id="span_000810" smilref="Machine_Learning00007.smil#span_000810">The objects that lie on the edge hyperplanes are the support vectors. (See </span><a id="c07-c07-fig-anc-0005" href="#c07-c07-fig-0005" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0005">Figure 7-5</a><span class="text" id="span_000811" smilref="Machine_Learning00007.smil#span_000811">.)</span></p>
              <figure id="figure_000058">
                <img class="center" src="images/c07f005.jpg" alt="image" id="img_000084" />
                <figcaption id="figcaption_000044">
                  <p xml:space="preserve" id="p_000414"><span class="figureLabel" id="span_000812"><a id="c07-c07-fig-0005" href="#c07-c07-fig-anc-0005" external="false"><strong id="strong_000290" smilref="Machine_Learning00007.smil#strong_000290">Figure 7-5</strong></a></span><span class="text" id="span_000813" smilref="Machine_Learning00007.smil#span_000813"> The support vectors on the hyperplane edges</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0037" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0037">When new objects are added to the classification, then the hyperplane and its edges might move. The key objective is to ensure a maximum margin between the +1 edge hyperplane and the -1 edge hyperplane.</p>
              <pagenum epub:type="pagebreak" id="p146" page="normal" smilref="Machine_Learning00007.smil#p146">146</pagenum>
              <p id="c07-c07-para-0038" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0038">If you can manage to keep a big gap between the categories, then there's an increase in confidence in your predictions. Knowing the values of the hyperplane edges gives you a feel for how well your categories are separated.</p>
              <p id="c07-c07-para-0039" xml:space="preserve"><span class="text" id="span_000814" smilref="Machine_Learning00007.smil#span_000814">After minimizing the value </span><em id="em_000173" smilref="Machine_Learning00007.smil#em_000173">w</em><span class="text" id="span_000815" smilref="Machine_Learning00007.smil#span_000815"> (called ||w|| in mathematical notation), you can look at optimizing </span><em id="em_000174" smilref="Machine_Learning00007.smil#em_000174">w</em><span class="text" id="span_000816" smilref="Machine_Learning00007.smil#span_000816"> by applying the following equation:</span></p>
              <p class="informalEquation" xml:space="preserve" id="p_000415"><img src="images/c07_math_008.png" alt="equation" id="img_000085" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="true">|</mo><mspace width="0.12em"/><mo stretchy="true">|</mo><mi>w</mi><mo stretchy="true">|</mo><mspace width="0.12em"/><mo stretchy="true">|</mo><msub><mrow/><mn>2</mn></msub></mrow></math>--></p>
              <p id="c07-c07-para-0040" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0040">Basically, you're taking half of ||w|| squared instead of using the square root of ||w||. Based on Lagrange multipliers, to find the maxima and minima in the function, you can now look for a saddle point and discount other points that don't match zero (fit inside the saddle).</p>
              <sidebar render="required" id="sidebar_000008">
                <div class="top hr" id="div_000008" />
                <level2 class="feature2" id="level2_000060">
                  <h2 xml:space="preserve" id="h2_000012" smilref="Machine_Learning00007.smil#h2_000012">Note</h2>
                  <p xml:space="preserve" id="p_000416"><span class="text" id="span_000817" smilref="Machine_Learning00007.smil#span_000817">For those that don't know, a saddle point is a mathematical function where you have two variables that meet at a critical point when both function values are zero. It's called a saddle point as that's the shape it produces in graphic form. You can read more about it at this URL </span><code xml:space="preserve" id="code_000199"><a href="http://wikipedia.org/wiki/Saddle_point" external="true" id="a_000293" smilref="Machine_Learning00007.smil#a_000293">http://wikipedia.org/wiki/Saddle_point</a></code><span class="text" id="span_000818" smilref="Machine_Learning00007.smil#span_000818">.</span></p>
                </level2>
              </sidebar>
              <p id="c07-c07-para-0042" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0042">You're shaping the graph into a multidimensional space and seeing where the vectors lie in order to make the category distinctions as big as possible. With standard quadratic programming, you then apply the function expressing the training vectors as a linear combination</p>
              <p class="informalEquation" xml:space="preserve" id="p_000417"><img src="images/c07_math_009.png" alt="equation" id="img_000086" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>w</mi><mo>=</mo><mstyle displaystyle="true"><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mrow><msub><mi>&#x003B1;</mi><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow></mstyle><mtext>.</mtext></mrow></math>--></p>
              <p id="c07-c07-para-0043" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0043">Where αi is greater than zero, the xi value is a support vector.</p>
            </level3>
            <level3 id="level3_000127">
              <h3 xml:space="preserve" id="h3_000127" smilref="Machine_Learning00007.smil#h3_000127">Using Non-Linear Classification</h3>
              <p xml:space="preserve" id="p_000418"><span class="text" id="span_000819" smilref="Machine_Learning00007.smil#span_000819">In an ideal world, the objects would lie on one side of the hyperplane or the other. Life, unfortunately, is rarely like that. Instead, you see objects straying from the hyperplane, as shown in </span><a id="c07-c07-fig-anc-0006" href="#c07-c07-fig-0006" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0006">Figure 7-6</a><span class="text" id="span_000820" smilref="Machine_Learning00007.smil#span_000820">.</span></p>
              <figure id="figure_000059">
                <img class="center" src="images/c07f006.jpg" alt="image" id="img_000087" />
                <figcaption id="figcaption_000045">
                  <p xml:space="preserve" id="p_000419"><span class="figureLabel" id="span_000821"><a id="c07-c07-fig-0006" href="#c07-c07-fig-anc-0006" external="false"><strong id="strong_000291" smilref="Machine_Learning00007.smil#strong_000291">Figure 7-6</strong></a></span><span class="text" id="span_000822" smilref="Machine_Learning00007.smil#span_000822"> Objects rarely go where you want them to.</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0045" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0045">By applying the kernel function (sometimes referred to as “the kernel trick”), you can apply an algorithm to fit the hyperplane's maximum margin in a feature space. The method is very similar to the dot products discussed in the linear methods, but this replaces the dot product with a kernel function.</p>
              <p id="c07-c07-para-0046" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0046">With a radial basis function, you have a few kernel types to choose from: the hyperbolic tangent, Gaussian radial basis function (or RBF, which is supported in Weka), and two polynomial functions—one homogenous and the other inhomogeneous.</p>
              <p id="c07-c07-para-0047" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0047">The full scope of non-linear classification is beyond the means of the introductory nature of this book. If you want to try implementing them, then look at the radial basis functions in the LibSVM classes when you use Weka.</p>
              <pagenum epub:type="pagebreak" id="p147" page="normal" smilref="Machine_Learning00007.smil#p147">147</pagenum>
              <p id="c07-c07-para-0048" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0048">Now take a look at what Weka can do for you to perform support vector machine classification.</p>
            </level3>
          </level2>
          <level2 id="level2_000061">
            <h2 id="c07-c07_level1_5" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07_level1_5">Using Support Vector Machines in Weka</h2>
            <p xml:space="preserve" id="p_000420" smilref="Machine_Learning00007.smil#p_000420">Weka can classify objects using the support vector machines algorithm, but the implementation isn't complete and requires a download before you can use it. This section shows you how to set it up and run the support vector machines algorithm on some test data.</p>
            <level3 id="level3_000128">
              <h3 xml:space="preserve" id="h3_000128" smilref="Machine_Learning00007.smil#h3_000128">Installing LibSVM</h3>
              <p xml:space="preserve" id="p_000421" smilref="Machine_Learning00007.smil#p_000421">The LibSVM library is an implementation of the support vector machines algorithm. It was written by Chih-Chung Chang and Chih-Jen Lin from the National Taiwan University. The library supports a variety of languages as well as Java including C, Python, .NET, MatLab, and R.</p>
              <level4 id="level4_000036">
                <h4 xml:space="preserve" id="h4_000036" smilref="Machine_Learning00007.smil#h4_000036">Weka LibSVM Installation</h4>
                <p xml:space="preserve" id="p_000422" smilref="Machine_Learning00007.smil#p_000422">You can install LibSVM from Github. You can clone the binary distribution by running the following command (assuming you have git installed):</p>
                <p xml:space="preserve" id="p_000423"><code class="preserve-whitespace" xml:space="preserve" id="code_000200" smilref="Machine_Learning00007.smil#code_000200">git clone https://github.com/cjlin1/libsvm.git </code></p>
                <p id="c07-c07-para-0052" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0052">The required files download into a clean directory.</p>
                <pagenum epub:type="pagebreak" id="p148" page="normal" smilref="Machine_Learning00007.smil#p148">148</pagenum>
                <p id="c07-c07-para-0053" xml:space="preserve"><span class="text" id="span_000823" smilref="Machine_Learning00007.smil#span_000823">You need to copy the </span><code xml:space="preserve" id="code_000201" smilref="Machine_Learning00007.smil#code_000201">libsvm.jar</code><span class="text" id="span_000824" smilref="Machine_Learning00007.smil#span_000824"> file to the same directory as your Weka installation directory (usually in the </span><code xml:space="preserve" id="code_000202" smilref="Machine_Learning00007.smil#code_000202">/Applications</code><span class="text" id="span_000825" smilref="Machine_Learning00007.smil#span_000825"> directory). You can easily drag and drop the file if desired; I work from the command line most of the time:</span></p>
                <p xml:space="preserve" id="p_000424"><code class="preserve-whitespace" xml:space="preserve" id="code_000203" smilref="Machine_Learning00007.smil#code_000203">cp ./libsvm-3.18/java/libsvm.jar /Applications/weka-3-6-10</code></p>
                <p id="c07-c07-para-0054" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0054">With the library in place, you can start Weka. If you are a Windows user just start Weka as normal, but if you run Mac OS X or Linux then you have to do it from the command line:</p>
                <p xml:space="preserve" id="p_000425"><code class="preserve-whitespace" xml:space="preserve" id="code_000204" smilref="Machine_Learning00007.smil#code_000204">java -cp weka.jar:libsvm.jar weka.gui.GUIChooser</code></p>
                <p id="c07-c07-para-0055" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0055">If you do not start Weka from the command line, then the classifier gives you an error to let you know that the SVM libraries were not found in the classpath.</p>
              </level4>
            </level3>
            <level3 id="level3_000129">
              <h3 xml:space="preserve" id="h3_000129" smilref="Machine_Learning00007.smil#h3_000129">A Classification Walkthrough</h3>
              <p xml:space="preserve" id="p_000426"><span class="text" id="span_000826" smilref="Machine_Learning00007.smil#span_000826">You will see the GUI Chooser application open as you would when you open Weka by starting the GUI instead of using the command line (see </span><a id="c07-c07-fig-anc-0007" href="#c07-c07-fig-0007" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0007">Figure 7-7</a><span class="text" id="span_000827" smilref="Machine_Learning00007.smil#span_000827">). Choose the Explorer option.</span></p>
              <figure id="figure_000060">
                <img class="center" src="images/c07f007.jpg" alt="image" id="img_000088" />
                <figcaption id="figcaption_000046">
                  <p xml:space="preserve" id="p_000427"><span class="figureLabel" id="span_000828"><a id="c07-c07-fig-0007" href="#c07-c07-fig-anc-0007" external="false"><strong id="strong_000292" smilref="Machine_Learning00007.smil#strong_000292">Figure 7-7</strong></a></span><span class="text" id="span_000829" smilref="Machine_Learning00007.smil#span_000829"> GUI Chooser</span></p>
                </figcaption>
              </figure>
              <p id="c07-c07-para-0057" xml:space="preserve"><span class="text" id="span_000830" smilref="Machine_Learning00007.smil#span_000830">I'm going to use the 100,000 rows of vehicle data that I created in Chapter 5 for the artificial neural networks; you can do the same. Find the </span><code xml:space="preserve" id="code_000205" smilref="Machine_Learning00007.smil#code_000205">.csv</code><span class="text" id="span_000831" smilref="Machine_Learning00007.smil#span_000831"> file and open it in Weka, as shown in </span><a id="c07-c07-fig-anc-0008" href="#c07-c07-fig-0008" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0008">Figure 7-8</a><span class="text" id="span_000832" smilref="Machine_Learning00007.smil#span_000832">. Don't forget to change the file type from </span><code xml:space="preserve" id="code_000206" smilref="Machine_Learning00007.smil#code_000206">.arff</code><span class="text" id="span_000833" smilref="Machine_Learning00007.smil#span_000833"> to </span><code xml:space="preserve" id="code_000207" smilref="Machine_Learning00007.smil#code_000207">.csv</code><span class="text" id="span_000834" smilref="Machine_Learning00007.smil#span_000834">.</span></p>
              <figure id="figure_000061">
                <img class="center" src="images/c07f008.jpg" alt="image" id="img_000089" />
                <figcaption id="figcaption_000047">
                  <p xml:space="preserve" id="p_000428"><span class="figureLabel" id="span_000835"><a id="c07-c07-fig-0008" href="#c07-c07-fig-anc-0008" external="false"><strong id="strong_000293" smilref="Machine_Learning00007.smil#strong_000293">Figure 7-8</strong></a></span> <pagenum epub:type="pagebreak" id="p149" page="normal" smilref="Machine_Learning00007.smil#p149">149</pagenum><span class="text" id="span_000836" smilref="Machine_Learning00007.smil#span_000836">Loading the .csv file</span></p>
                </figcaption>
              </figure>
              <level4 id="level4_000037">
                <h4 xml:space="preserve" id="h4_000037" smilref="Machine_Learning00007.smil#h4_000037">Setting the Options</h4>
                <p xml:space="preserve" id="p_000429"><span class="text" id="span_000837" smilref="Machine_Learning00007.smil#span_000837">Click the Classify tab and then click the Choose button to select a different classification algorithm. Within the tree of algorithms, click Functions and then select LibSVM, as shown in </span><a id="c07-c07-fig-anc-0009" href="#c07-c07-fig-0009" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0009">Figure 7-9</a><span class="text" id="span_000838" smilref="Machine_Learning00007.smil#span_000838">.</span></p>
                <figure id="figure_000062">
                  <img class="center" src="images/c07f009.jpg" alt="image" id="img_000090" />
                  <figcaption id="figcaption_000048">
                    <p xml:space="preserve" id="p_000430"><span class="figureLabel" id="span_000839"><a id="c07-c07-fig-0009" href="#c07-c07-fig-anc-0009" external="false"><strong id="strong_000294" smilref="Machine_Learning00007.smil#strong_000294">Figure 7-9</strong></a></span><span class="text" id="span_000840" smilref="Machine_Learning00007.smil#span_000840"> Choosing the LibSVM classifier</span></p>
                  </figcaption>
                </figure>
                <pagenum epub:type="pagebreak" id="p150" page="normal" smilref="Machine_Learning00007.smil#p150">150</pagenum>
                <p id="c07-c07-para-0059" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0059">There are a couple of changes to make before you set the classifier off to work. First, you want a percentage split of training data against test data. In this case, you can be fairly confident that the data is not going to be difficult to classify and it's not going to be a non-linear classification problem; you can train with 10 percent of the data (10,000 rows) and test with the 90 percent to see how it performs.</p>
                <p id="c07-c07-para-0060" xml:space="preserve"><span class="text" id="span_000841" smilref="Machine_Learning00007.smil#span_000841">Click the Percentage Split option and change the default value of 66 percent to 10 percent, as shown in </span><a id="c07-c07-fig-anc-0010" href="#c07-c07-fig-0010" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0010">Figure 7-10</a><span class="text" id="span_000842" smilref="Machine_Learning00007.smil#span_000842">.</span></p>
                <figure id="figure_000063">
                  <img class="center" src="images/c07f010.jpg" alt="image" id="img_000091" />
                  <figcaption id="figcaption_000049">
                    <p xml:space="preserve" id="p_000431"><span class="figureLabel" id="span_000843"><a id="c07-c07-fig-0010" href="#c07-c07-fig-anc-0010" external="false"><strong id="strong_000295" smilref="Machine_Learning00007.smil#strong_000295">Figure 7-10</strong></a></span><span class="text" id="span_000844" smilref="Machine_Learning00007.smil#span_000844"> Changing the percentage split</span></p>
                  </figcaption>
                </figure>
                <p id="c07-c07-para-0061" xml:space="preserve"><span class="text" id="span_000845" smilref="Machine_Learning00007.smil#span_000845">You want the results of the test data, the 90 percent to be output to the Weka console so you can see how it's performing. Click the Options button and ensure that the Output Predictions checkbox is ticked, as shown in </span><a id="c07-c07-fig-anc-0011" href="#c07-c07-fig-0011" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0011">Figure 7-11</a><span class="text" id="span_000846" smilref="Machine_Learning00007.smil#span_000846">.</span></p>
                <figure id="figure_000064">
                  <img class="center" src="images/c07f011.jpg" alt="image" id="img_000092" />
                  <figcaption id="figcaption_000050">
                    <p xml:space="preserve" id="p_000432"><span class="figureLabel" id="span_000847"><a id="c07-c07-fig-0011" href="#c07-c07-fig-anc-0011" external="false"><strong id="strong_000296" smilref="Machine_Learning00007.smil#strong_000296">Figure 7-11</strong></a></span> <pagenum epub:type="pagebreak" id="p151" page="normal" smilref="Machine_Learning00007.smil#p151">151</pagenum><span class="text" id="span_000848" smilref="Machine_Learning00007.smil#span_000848">Classifer Evaluation Options dialog box</span></p>
                  </figcaption>
                </figure>
                <p id="c07-c07-para-0062" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0062">The LibSVM wrapper defaults to a radial basis function for its kernel type. Change that to the linear version you've been concentrating on by clicking on the line with all the LibSVM options. This is located next to the Choose button within the Classifer pane.</p>
                <p id="c07-c07-para-0063" xml:space="preserve"><span class="text" id="span_000849" smilref="Machine_Learning00007.smil#span_000849">Change the kernelType drop-down menu from Radial Basis Function to Linear. Leave the other options as they are. (See </span><a id="c07-c07-fig-anc-0012" href="#c07-c07-fig-0012" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0012">Figure 7-12</a><span class="text" id="span_000850" smilref="Machine_Learning00007.smil#span_000850">.)</span></p>
                <figure id="figure_000065">
                  <img class="center" src="images/c07f012.jpg" alt="image" id="img_000093" />
                  <figcaption id="figcaption_000051">
                    <p xml:space="preserve" id="p_000433"><span class="figureLabel" id="span_000851"><a id="c07-c07-fig-0012" href="#c07-c07-fig-anc-0012" external="false"><strong id="strong_000297" smilref="Machine_Learning00007.smil#strong_000297">Figure 7-12</strong></a></span><span class="text" id="span_000852" smilref="Machine_Learning00007.smil#span_000852"> Changing the kernel type</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000038">
                <h4 xml:space="preserve" id="h4_000038" smilref="Machine_Learning00007.smil#h4_000038">Running the Classifier</h4>
                <pagenum epub:type="pagebreak" id="p152" page="normal" smilref="Machine_Learning00007.smil#p152">152</pagenum>
                <p xml:space="preserve" id="p_000434" smilref="Machine_Learning00007.smil#p_000434">With everything set, you can run the classifier. Click the Start button, and you see the output window start to output information on the classification.</p>
                <p id="c07-c07-para-0065" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0065">First, you have the run information, or all the options that you just set:</p>
                <p xml:space="preserve" id="p_000435"><code class="preserve-whitespace" xml:space="preserve" id="code_000208" smilref="Machine_Learning00007.smil#code_000208">=== Run information ===
Scheme:weka.classifiers.functions.LibSVM -S 0 -K 0 -D 3 -G 0.0 -R 0.0 -N 0.5 -M 40.0 -C 1.0 -E 0.001 -P 0.1 -seed 1
Relation:     v100k
Instances:    100000
Attributes:   4
              wheels
              chassis
              pax
              vtype
Test mode:split 10.0% train, remainder test</code></p>
                <p id="c07-c07-para-0066" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0066">Next, you get some general information on the classifier model:</p>
                <p xml:space="preserve" id="p_000436"><code class="preserve-whitespace" xml:space="preserve" id="code_000209" smilref="Machine_Learning00007.smil#code_000209">=== Classifier model (full training set) ===
LibSVM wrapper, original code by Yasser EL-Manzalawy (=WLSVM)
Time taken to build model: 3.08 seconds</code></p>
                <p id="c07-c07-para-0067" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0067">On my machine, the classifier trained on 10,000 instances in just over three seconds, which is 3,246 rows per second.</p>
                <p id="c07-c07-para-0068" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0068">As you've set the output for the predictions to be shown, you get that next:</p>
                <p xml:space="preserve" id="p_000437"><code class="preserve-whitespace" xml:space="preserve" id="code_000210" smilref="Machine_Learning00007.smil#code_000210">=== Predictions on test split ===
inst#,    actual, predicted, error, probability distribution
     1     4:Bike     4:Bike          0      0      0     *1
     2     4:Bike     4:Bike          0      0      0     *1
     3    3:Truck    3:Truck          0      0     *1      0
     4      1:Bus      1:Bus         *1      0      0      0
     5      1:Bus      1:Bus         *1      0      0      0
     6      2:Car      2:Car          0     *1      0      0
     7     4:Bike     4:Bike          0      0      0     *1
     8    3:Truck    3:Truck          0      0     *1      0
     9    3:Truck    3:Truck          0      0     *1      0
    10      2:Car      2:Car          0     *1      0      0
    11     4:Bike     4:Bike          0      0      0     *1
    12      2:Car      2:Car          0     *1      0      0
    13    3:Truck    3:Truck          0      0     *1      0
    14    3:Truck    3:Truck          0      0     *1      0
    15     4:Bike     4:Bike          0      0      0     *1
    16      1:Bus      1:Bus         *1      0      0      0
    17      1:Bus      1:Bus         *1      0      0      0
    18      2:Car      2:Car          0     *1      0      0
    19      1:Bus      1:Bus         *1      0      0      0</code></p>
                <pagenum epub:type="pagebreak" id="p153" page="normal" smilref="Machine_Learning00007.smil#p153">153</pagenum>
                <p id="c07-c07-para-0069" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0069">Based on the training data of 10,000, you've instructed Weka to try and predict the remaining 90,000 rows of data. The output window will have all 90,000 rows there, but the main things to watch out for are the actual and predicted results.</p>
                <p id="c07-c07-para-0070" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0070">You get the evaluation on the test data showing the correct and incorrect assignments:</p>
                <p xml:space="preserve" id="p_000438"><code class="preserve-whitespace" xml:space="preserve" id="code_000211" smilref="Machine_Learning00007.smil#code_000211">=== Evaluation on test split ===
=== Summary ===
Correctly Classified Instances       90000              100      %
Incorrectly Classified Instances         0                0      %
Kappa statistic                          1
Mean absolute error                      0
Root mean squared error                  0
Relative absolute error                  0      %
Root relative squared error              0      %
Total Number of Instances            90000     </code></p>
                <p id="c07-c07-para-0071" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0071">The confusion matrix shows the breakdown of the test data and how it was classified:</p>
                <p xml:space="preserve" id="p_000439"><code class="preserve-whitespace" xml:space="preserve" id="code_000212" smilref="Machine_Learning00007.smil#code_000212">=== Confusion Matrix ===
     a     b     c     d   &lt;-- classified as
 22486     0     0     0 |     a = Bus
     0 22502     0     0 |     b = Car
     0     0 22604     0 |     c = Truck
     0     0     0 22408 |     d = Bike</code></p>
              </level4>
              <level4 id="level4_000039">
                <h4 xml:space="preserve" id="h4_000039" smilref="Machine_Learning00007.smil#h4_000039">Dealing with Errors from LibSVM</h4>
                <p xml:space="preserve" id="p_000440" smilref="Machine_Learning00007.smil#p_000440">There are variations of the LibSVM library around the Internet and also different ways the random number generator handles numbers on differing operating systems. If you come across an error like the following:</p>
                <p xml:space="preserve" id="p_000441"><code class="preserve-whitespace" xml:space="preserve" id="code_000213" smilref="Machine_Learning00007.smil#code_000213">java.lang.NoSuchFieldException: rand
java.lang.Class.getField(Unknown Source)
weka.classifiers.functions.LibSVM.buildClassifier(LibSVM.java:1618)
weka.gui.explorer.ClassifierPanel$16.run(ClassifierPanel.java:1432)
at java.lang.Class.getField(Unknown Source)
at weka.classifiers.functions.LibSVM.buildClassifier(LibSVM.java:1618)
at weka.gui.explorer.ClassifierPanel$16.run(ClassifierPanel.java:1432)</code></p>
                <pagenum epub:type="pagebreak" id="p154" page="normal" smilref="Machine_Learning00007.smil#p154">154</pagenum>
                <p id="c07-c07-para-0073" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0073">then it's worth looking at later versions of Weka with the new package manager (version 3.7 and later).</p>
              </level4>
              <level4 id="level4_000040">
                <h4 xml:space="preserve" id="h4_000040" smilref="Machine_Learning00007.smil#h4_000040">Saving the Model</h4>
                <p xml:space="preserve" id="p_000442" smilref="Machine_Learning00007.smil#p_000442">You can save the model for this classification. On the result list, you see the date and time that the LibSVM classification was run. Right-click (Alt-click if you are a Mac user) on functions.LibSVM and select Save Model. Find a safe place to save the model for future use.</p>
              </level4>
            </level3>
            <level3 id="level3_000130">
              <h3 xml:space="preserve" id="h3_000130" smilref="Machine_Learning00007.smil#h3_000130">Implementing LibSVM with Java</h3>
              <p xml:space="preserve" id="p_000443" smilref="Machine_Learning00007.smil#p_000443">Using LibSVM within the Weka toolkit is easy to implement, but there comes a time when you'll want to use it within your own code, so you can integrate it within your own systems.</p>
              <level4 id="level4_000041">
                <h4 xml:space="preserve" id="h4_000041" smilref="Machine_Learning00007.smil#h4_000041">Converting .csv Data to .arff Format</h4>
                <p xml:space="preserve" id="p_000444"><code xml:space="preserve" id="code_000214" smilref="Machine_Learning00007.smil#code_000214">.csv</code><span class="text" id="span_000853" smilref="Machine_Learning00007.smil#span_000853">files don't contain the data that Weka will need. You could implement the </span><code xml:space="preserve" id="code_000215" smilref="Machine_Learning00007.smil#code_000215">CSVLoader</code><span class="text" id="span_000854" smilref="Machine_Learning00007.smil#span_000854"> class, but I prefer to know that the </span><code xml:space="preserve" id="code_000216" smilref="Machine_Learning00007.smil#code_000216">.arff</code><span class="text" id="span_000855" smilref="Machine_Learning00007.smil#span_000855"> data is ready for use. It also makes it easier for others to decode the data model if they need to.</span></p>
                <p id="c07-c07-para-0077" xml:space="preserve"><span class="text" id="span_000856" smilref="Machine_Learning00007.smil#span_000856">From the command line, you can convert the data from a </span><code xml:space="preserve" id="code_000217" smilref="Machine_Learning00007.smil#code_000217">.csv</code><span class="text" id="span_000857" smilref="Machine_Learning00007.smil#span_000857"> file to </span><code xml:space="preserve" id="code_000218" smilref="Machine_Learning00007.smil#code_000218">.arff</code><span class="text" id="span_000858" smilref="Machine_Learning00007.smil#span_000858"> in one command:</span></p>
                <p xml:space="preserve" id="p_000445"><code class="preserve-whitespace" xml:space="preserve" id="code_000219" smilref="Machine_Learning00007.smil#code_000219">java -cp /Applications/weka-3-6-10/weka.jar weka.core.converters.CSVLoader v100k.csv &gt; v100k.arff</code></p>
                <p id="c07-c07-para-0078" xml:space="preserve"><span class="text" id="span_000859" smilref="Machine_Learning00007.smil#span_000859">To ensure that the conversion has worked, you can output the first 20 lines with the </span><code xml:space="preserve" id="code_000220" smilref="Machine_Learning00007.smil#code_000220">head</code><span class="text" id="span_000860" smilref="Machine_Learning00007.smil#span_000860"> command (your output should look like the following sample):</span></p>
                <p xml:space="preserve" id="p_000446"><code class="preserve-whitespace" xml:space="preserve" id="code_000221" smilref="Machine_Learning00007.smil#code_000221">$ head -n 20 v100k.arff
@relation v100k
@attribute wheels numeric
@attribute chassis numeric
@attribute pax numeric
@attribute vtype {Bus,Car,Truck,Bike}
@data
6,20,39,Bus
8,23,11,Bus
5,3,1,Car
4,3,4,Car
5,3,1,Car
4,18,37,Bus</code></p>
                <pagenum epub:type="pagebreak" id="p155" page="normal" smilref="Machine_Learning00007.smil#p155">155</pagenum>
                <p id="c07-c07-para-0079" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0079">With everything looking fine, you can now set your attention on the Eclipse side of the project.</p>
              </level4>
              <level4 id="level4_000042">
                <h4 xml:space="preserve" id="h4_000042" smilref="Machine_Learning00007.smil#h4_000042">Setting Up the Project and Libraries</h4>
                <p xml:space="preserve" id="p_000447"><span class="text" id="span_000861" smilref="Machine_Learning00007.smil#span_000861">Using the same data, create a coded example with Java using Eclipse to create the project. Create a new Java Project (select File →New →Java Project) and call it </span><code xml:space="preserve" id="code_000222" smilref="Machine_Learning00007.smil#code_000222">MLLibSVM</code><span class="text" id="span_000862" smilref="Machine_Learning00007.smil#span_000862">, as shown in </span><a id="c07-c07-fig-anc-0013" href="#c07-c07-fig-0013" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0013">Figure 7-13</a><span class="text" id="span_000863" smilref="Machine_Learning00007.smil#span_000863">.</span></p>
                <figure id="figure_000066">
                  <img class="center" src="images/c07f013.jpg" alt="image" id="img_000094" />
                  <figcaption id="figcaption_000052">
                    <p xml:space="preserve" id="p_000448"><span class="figureLabel" id="span_000864"><a id="c07-c07-fig-0013" href="#c07-c07-fig-anc-0013" external="false"><strong id="strong_000298" smilref="Machine_Learning00007.smil#strong_000298">Figure 7-13</strong></a></span><span class="text" id="span_000865" smilref="Machine_Learning00007.smil#span_000865"> Creating the new Java project</span></p>
                  </figcaption>
                </figure>
                <p id="c07-c07-para-0081" xml:space="preserve"><span class="text" id="span_000866" smilref="Machine_Learning00007.smil#span_000866">The Weka API and the LibSVM API need to be added to the project. Select File →Properties and then select Java Build Path. Click the Add External JARs button. When the File dialog box displays, locate the </span><code xml:space="preserve" id="code_000223" smilref="Machine_Learning00007.smil#code_000223">weka.jar</code><span class="text" id="span_000867" smilref="Machine_Learning00007.smil#span_000867"> and </span><code xml:space="preserve" id="code_000224" smilref="Machine_Learning00007.smil#code_000224">libsvm.jar</code><span class="text" id="span_000868" smilref="Machine_Learning00007.smil#span_000868"> files and click Open. (See </span><a id="c07-c07-fig-anc-0014" href="#c07-c07-fig-0014" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0014">Figure 7-14</a><span class="text" id="span_000869" smilref="Machine_Learning00007.smil#span_000869">.)</span></p>
                <figure id="figure_000067">
                  <img class="center" src="images/c07f014.jpg" alt="image" id="img_000095" />
                  <figcaption id="figcaption_000053">
                    <p xml:space="preserve" id="p_000449"><span class="figureLabel" id="span_000870"><a id="c07-c07-fig-0014" href="#c07-c07-fig-anc-0014" external="false"><strong id="strong_000299" smilref="Machine_Learning00007.smil#strong_000299">Figure 7-14</strong></a></span> <pagenum epub:type="pagebreak" id="p156" page="normal" smilref="Machine_Learning00007.smil#p156">156</pagenum><span class="text" id="span_000871" smilref="Machine_Learning00007.smil#span_000871">Adding the required jar files</span></p>
                  </figcaption>
                </figure>
                <p id="c07-c07-para-0082" xml:space="preserve"><span class="text" id="span_000872" smilref="Machine_Learning00007.smil#span_000872">You have everything in place, so you can create a new Java class (File →New →Class) called </span><code xml:space="preserve" id="code_000225" smilref="Machine_Learning00007.smil#code_000225">MLLibSVMTest.java</code><span class="text" id="span_000873" smilref="Machine_Learning00007.smil#span_000873"> (see </span><a id="c07-c07-fig-anc-0015" href="#c07-c07-fig-0015" external="false" smilref="Machine_Learning00007.smil#c07-c07-fig-anc-0015">Figure 7-15</a><span class="text" id="span_000874" smilref="Machine_Learning00007.smil#span_000874">) and put some code in place.</span></p>
                <figure id="figure_000068">
                  <img class="center" src="images/c07f015.jpg" alt="image" id="img_000096" />
                  <figcaption id="figcaption_000054">
                    <p xml:space="preserve" id="p_000450"><span class="figureLabel" id="span_000875"><a id="c07-c07-fig-0015" href="#c07-c07-fig-anc-0015" external="false"><strong id="strong_000300" smilref="Machine_Learning00007.smil#strong_000300">Figure 7-15</strong></a></span><span class="text" id="span_000876" smilref="Machine_Learning00007.smil#span_000876"> Creating a new Java class</span></p>
                  </figcaption>
                </figure>
                <pagenum epub:type="pagebreak" id="p157" page="normal" smilref="Machine_Learning00007.smil#p157">157</pagenum>
                <p id="c07-c07-para-0083" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0083">The basic code to get a support vector machine working in Weka is a fairly easy task.</p>
                <p xml:space="preserve" id="p_000451"><code class="preserve-whitespace" xml:space="preserve" id="code_000226"><strong id="strong_000301" smilref="Machine_Learning00007.smil#strong_000301">public class</strong><span class="text" id="span_000877" smilref="Machine_Learning00007.smil#span_000877"> MLLibSVMTest {
    </span><strong id="strong_000302" smilref="Machine_Learning00007.smil#strong_000302">public</strong><span class="text" id="span_000878" smilref="Machine_Learning00007.smil#span_000878"> MLLibSVMTest(String filepath){
        Instances data;
        </span><strong id="strong_000303" smilref="Machine_Learning00007.smil#strong_000303">try</strong><span class="text" id="span_000879" smilref="Machine_Learning00007.smil#span_000879"> {
            data = DataSource.</span><em id="em_000175" smilref="Machine_Learning00007.smil#em_000175">read</em><span class="text" id="span_000880" smilref="Machine_Learning00007.smil#span_000880">(filepath);
               if (data.classIndex() == -1)
                 data.setClassIndex(data.numAttributes() - 1);
            LibSVM svm = </span><strong id="strong_000304" smilref="Machine_Learning00007.smil#strong_000304">new</strong><span class="text" id="span_000881" smilref="Machine_Learning00007.smil#span_000881"> LibSVM();
            String[] options = weka.core.Utils.</span><em id="em_000176" smilref="Machine_Learning00007.smil#em_000176">splitOptions</em><span class="text" id="span_000882" smilref="Machine_Learning00007.smil#span_000882">("-K 0 -D 3");
            svm.setOptions(options);
                svm.buildClassifier(data);
        } </span><strong id="strong_000305" smilref="Machine_Learning00007.smil#strong_000305">catch</strong><span class="text" id="span_000883" smilref="Machine_Learning00007.smil#span_000883"> (Exception e) {
            e.printStackTrace();
        }
      }
    </span><strong id="strong_000306" smilref="Machine_Learning00007.smil#strong_000306">public static void</strong><span class="text" id="span_000884" smilref="Machine_Learning00007.smil#span_000884"> main(String[] args) {
        MLLibSVMTest mllsvm = </span><strong id="strong_000307" smilref="Machine_Learning00007.smil#strong_000307">new</strong><span class="text" id="span_000885" smilref="Machine_Learning00007.smil#span_000885"> MLLibSVMTest("v100k.arff");
    }
}</span></code></p>
                <p id="c07-c07-para-0084" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0084">There are a lot of option settings for the LibSVM library, but the main one I want to focus on is the kernel type. As in the Weka workbench, the default is the radial basis function: In the options, the number 2 designates this. For the linear kernel function, you change that to zero.</p>
                <p id="c07-c07-para-0085" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0085">To run the code from Eclipse, select Run →Run. This takes the training data and makes the model. It won't do anything else just yet.</p>
                <p xml:space="preserve" id="p_000452"><code class="preserve-whitespace" xml:space="preserve" id="code_000227" smilref="Machine_Learning00007.smil#code_000227">Zero Weights processed. Default weights will be used
*
optimization finished, #iter = 9
nu = 7.999320068325541E-7
obj = -0.019999999949535163, rho = 2.1200468836658968
nSV = 4, nBSV = 0
*
optimization finished, #iter = 9
nu = 5.508757892156424E-7
obj = -0.013793103448275858, rho = -1.013793103448276
nSV = 5, nBSV = 0
*
optimization finished, #iter = 3
nu = 3.801428938130698E-7
obj = -0.009478672985781991, rho = 1.2180094786729856
nSV = 2, nBSV = 0
*
optimization finished, #iter = 5
nu = 1.8774340639289764E-7
obj = -0.004705882352941176, rho = -1.6070588235294119
nSV = 4, nBSV = 0
*
optimization finished, #iter = 6
nu = 8.90259889118131E-6
obj = -0.22222222222222227, rho = 1.6666666666666679
nSV = 3, nBSV = 0
*
optimization finished, #iter = 3
nu = 1.2308677001852457E-7
obj = -0.003076923076923077, rho = 1.1107692307692307
nSV = 2, nBSV = 0
Total nSV = 14</code></p>
                <pagenum epub:type="pagebreak" id="p158" page="normal" smilref="Machine_Learning00007.smil#p158">158</pagenum>
                <p id="c07-c07-para-0086" xml:space="preserve"><span class="text" id="span_000886" smilref="Machine_Learning00007.smil#span_000886">The output looks confusing, but what it is telling you is the number of support vectors (</span><code xml:space="preserve" id="code_000228" smilref="Machine_Learning00007.smil#code_000228">nSV</code><span class="text" id="span_000887" smilref="Machine_Learning00007.smil#span_000887">), the number of bound support vectors (</span><code xml:space="preserve" id="code_000229" smilref="Machine_Learning00007.smil#code_000229">nBSV</code><span class="text" id="span_000888" smilref="Machine_Learning00007.smil#span_000888">), and </span><code xml:space="preserve" id="code_000230" smilref="Machine_Learning00007.smil#code_000230">obj</code><span class="text" id="span_000889" smilref="Machine_Learning00007.smil#span_000889"> is the optimum objective value of the dual support vector machine.</span></p>
              </level4>
              <level4 id="level4_000043">
                <h4 xml:space="preserve" id="h4_000043" smilref="Machine_Learning00007.smil#h4_000043">Training and Predicting with the Existing Data</h4>
                <p xml:space="preserve" id="p_000453"><span class="text" id="span_000890" smilref="Machine_Learning00007.smil#span_000890">So far, you've trained with the full 100,000 lines of data from the </span><code xml:space="preserve" id="code_000231" smilref="Machine_Learning00007.smil#code_000231">.arff</code><span class="text" id="span_000891" smilref="Machine_Learning00007.smil#span_000891"> file. I want to train with 10 percent and then predict the remaining 90 percent in the same way as the workbench walkthrough.</span></p>
                <p xml:space="preserve" id="p_000454" smilref="Machine_Learning00007.smil#p_000454">The Weka API lets you add the options as you would in the workbench, so where you split the data for training, you can do the same within the code.</p>
                <p id="c07-c07-para-0089" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0089">Amend the options line and add the training split percentage like so</p>
                <p xml:space="preserve" id="p_000455"><code class="preserve-whitespace" xml:space="preserve" id="code_000232"><span class="text" id="span_000892" smilref="Machine_Learning00007.smil#span_000892">String[] options = weka.core.Utils.</span><em id="em_000177" smilref="Machine_Learning00007.smil#em_000177">splitOptions</em><span class="text" id="span_000893" smilref="Machine_Learning00007.smil#span_000893">("-K 0 -D 3");</span></code></p>
                <p xml:space="preserve" id="p_000456" smilref="Machine_Learning00007.smil#p_000456">and it now becomes</p>
                <p xml:space="preserve" id="p_000457"><code class="preserve-whitespace" xml:space="preserve" id="code_000233"><span class="text" id="span_000894" smilref="Machine_Learning00007.smil#span_000894">String[] options = weka.core.Utils.</span><em id="em_000178" smilref="Machine_Learning00007.smil#em_000178">splitOptions</em><span class="text" id="span_000895" smilref="Machine_Learning00007.smil#span_000895">("-K 0 -D 3 -split-percentage 10");</span></code></p>
                <p id="c07-c07-para-0090" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0090">To show the predictions of the data, add a new method that iterates through the instance data:</p>
                <p xml:space="preserve" id="p_000458"><code class="preserve-whitespace" xml:space="preserve" id="code_000234" smilref="Machine_Learning00007.smil#code_000234">public void showInstanceClassifications(LibSVM svm, Instances data) {
         try {
             for (int i = 0; i &lt; data.numInstances(); i++) {
                 System.out.println("Instance " + i + " is classified as a "
                         +
             data.classAttribute().value((int)svm.classifyInstance(data.
             instance(i))));
            }
         } catch (Exception e) {
             e.printStackTrace();
         }
     }</code></p>
                <pagenum epub:type="pagebreak" id="p159" page="normal" smilref="Machine_Learning00007.smil#p159">159</pagenum>
                <p id="c07-c07-para-0091" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0091">The classifier always returns a numerical value as its result; it's up to you to turn that number into an integer and run it past the class attribute value to find out whether it's a bike, car, bus, or truck.</p>
                <p id="c07-c07-para-0092" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0092">When you run the code again, you see the classifier generate as before with 10 percent of the training data, and then it classifies the whole data set.</p>
                <p xml:space="preserve" id="p_000459"><code class="preserve-whitespace" xml:space="preserve" id="code_000235" smilref="Machine_Learning00007.smil#code_000235">Instance 99991 is classified as a Truck
Instance 99992 is classified as a Bus
Instance 99993 is classified as a Car
Instance 99994 is classified as a Truck
Instance 99995 is classified as a Car
Instance 99996 is classified as a Bus
Instance 99997 is classified as a Bike
Instance 99998 is classified as a Truck
Instance 99999 is classified as a Bike</code></p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000062">
            <h2 id="c07-c07_level1_6" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07_level1_6">Summary</h2>
            <p xml:space="preserve" id="p_000460" smilref="Machine_Learning00007.smil#p_000460">This chapter was a whistle stop tour of support vector machines. Whole books have been written on the subject, going deep into the intricacies of the vector machine and its kernel methods.</p>
            <p id="c07-c07-para-0094" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0094">From a developer's point of view, treat this chapter as a launch pad for further investigation. In a practical scenario, you might gloss over the heavy theory and make Weka do the heavy lifting on a sample or subset of your data.</p>
            <p id="c07-c07-para-0095" xml:space="preserve" smilref="Machine_Learning00007.smil#c07-c07-para-0095">Before you continue your journey, I think it's only fair that you reward yourself with your beverage of choice and a short rest before you continue into the next chapter on clustering data.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c08">
        <section epub:type="chapter" id="section_000009">
          <header id="header_000008">
            <h1 id="c08-c8" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c8">Chapter 8 Clustering</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p161" page="normal" smilref="Machine_Learning00007.smil#p161">161</pagenum>
          <p xml:space="preserve" id="p_000461" smilref="Machine_Learning00007.smil#p_000461">One of the more common machine learning strands you'll come across is clustering, mainly because it's very useful. For example, marketing companies love it because they can group customers into segments. This chapter describes the details of clustering and illustrates how clusters work and where they are used.</p>
          <sidebar render="required" id="sidebar_000009">
            <div class="top hr" id="div_000009" />
            <level2 class="feature2" id="level2_000063">
              <h2 xml:space="preserve" id="h2_000013" smilref="Machine_Learning00007.smil#h2_000013">Note</h2>
              <p xml:space="preserve" id="p_000462" smilref="Machine_Learning00007.smil#p_000462">Please don't confuse machine learning clustering with clusters of machines in a networking sense; we're talking about something very different here.</p>
            </level2>
          </sidebar>
          <level2 id="level2_000064">
            <h2 id="c08-c08_level1_1" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08_level1_1">What Is Clustering?</h2>
            <p xml:space="preserve" id="p_000463"><span class="text" id="span_000896" smilref="Machine_Learning00007.smil#span_000896">If you boil down all the definitions of clustering out there, you get “organizing a group of objects that share similar characteristics.” It's classed as an unsupervised learning method, which means there's no prior training data from which to learn. In </span><a id="c08-c08-fig-anc-0001" href="#c08-c08-fig-0001" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0001">Figure 8-1</a><span class="text" id="span_000897" smilref="Machine_Learning00007.smil#span_000897"> you see there are three distinct groupings of data; each one of those groups is a cluster.</span></p>
            <figure id="figure_000069">
              <img class="center" src="images/c08f001.jpg" alt="image" id="img_000097" />
              <figcaption id="figcaption_000055">
                <p xml:space="preserve" id="p_000464"><span class="figureLabel" id="span_000898"><a id="c08-c08-fig-0001" href="#c08-c08-fig-anc-0001" external="false"><strong id="strong_000308" smilref="Machine_Learning00007.smil#strong_000308">Figure 8-1</strong></a></span><span class="text" id="span_000899" smilref="Machine_Learning00007.smil#span_000899"> A graph representation of a cluster</span></p>
              </figcaption>
            </figure>
            <pagenum epub:type="pagebreak" id="p162" page="normal" smilref="Machine_Learning00007.smil#p162">162</pagenum>
            <p id="c08-c08-para-0004" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0004">The main aim is to find structure within a given set of data. Because there are a lot of algorithms to choose from, clustering casts a wide net. This is where experimentation comes in handy; which algorithm is the right choice? Sometimes you just need to put some code together and play with it. You'll do that shortly.</p>
          </level2>
          <level2 id="level2_000065">
            <h2 id="c08-c08_level1_2" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08_level1_2">Where Is Clustering Used?</h2>
            <p xml:space="preserve" id="p_000465" smilref="Machine_Learning00007.smil#p_000465">Clustering is a widely-used machine learning approach. Although it might seem simple, do not underestimate the importance of grouping multivariate data into refined groupings.</p>
            <level3 id="level3_000131">
              <h3 xml:space="preserve" id="h3_000131" smilref="Machine_Learning00007.smil#h3_000131">The Internet</h3>
              <p xml:space="preserve" id="p_000466" smilref="Machine_Learning00007.smil#p_000466">Social media network analysis uses clustering to determine communities of users. With so many users on Facebook, for example, using these sorts of techniques can refine advertising so that certain ads go to specific groups of customers.</p>
              <p id="c08-c08-para-0007" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0007">If you've ever searched on one of many mapping websites, you might have seen clustering at work when there are a lot of interest pins built up in a given location. Instead of showing all the pins, which would provide a bad user experience, clustering is used to define the group of pins within the given location.</p>
              <p id="c08-c08-para-0008" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0008">Website logs and search results are often clustered to show more relevant search result groups. A number of companies are using clustering to refine search engine queries.</p>
            </level3>
            <level3 id="level3_000132">
              <h3 xml:space="preserve" id="h3_000132" smilref="Machine_Learning00007.smil#h3_000132">Business and Retail</h3>
              <pagenum epub:type="pagebreak" id="p163" page="normal" smilref="Machine_Learning00007.smil#p163">163</pagenum>
              <p xml:space="preserve" id="p_000467" smilref="Machine_Learning00007.smil#p_000467">Market research companies use clustering a lot. With surveys that contain many variables, a multivariate system like clustering gives marketers better definition of groups of customers in relation to the answers given in the survey. This might be broken down by population, location, and previous buying habits, for example. With the clusters defined, the marketing companies can try to develop new products or think about testing products for certain clusters in the results.</p>
              <p id="c08-c08-para-0010" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0010">Along with association rules learning (discussed in Chapter 6), clustering is also used for basket analysis. Certain auction sites use clustering because there is no defined stock number in the listings. It's easier to run clustering and group items and preferences than use association rules.</p>
            </level3>
            <level3 id="level3_000133">
              <h3 xml:space="preserve" id="h3_000133" smilref="Machine_Learning00007.smil#h3_000133">Law Enforcement</h3>
              <p xml:space="preserve" id="p_000468" smilref="Machine_Learning00007.smil#p_000468">Crimes are logged with all the aspects of the felony listed. Police departments are running clustering and other machine learning algorithms to predict when and where future crimes will happen. The result of this might be that patrol cars are deployed to certain problem areas at certain times, or specialist help is sent to areas where certain sorts of crimes show high numbers.</p>
            </level3>
            <level3 id="level3_000134">
              <h3 xml:space="preserve" id="h3_000134" smilref="Machine_Learning00007.smil#h3_000134">Computing</h3>
              <p xml:space="preserve" id="p_000469" smilref="Machine_Learning00007.smil#p_000469">With the rise of the “Internet of Things,” we are now collecting more data from sensors than ever before. Clustering can be used to group the results of the sensors. For example, thinking of a temperature sensor, you might cluster date and time against the temperature. Another example would be motion detection; a number of passive infrared sensors could be generating data on movement within a location. Is a certain location a hotspot at a specific time? This information can be easily clustered and inspected.</p>
              <p id="c08-c08-para-0013" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0013">Course work in the education sector, especially with the advent of large-scale learning online, can be clustered into student groups and results. For example, do certain clusters of students excel at courses compared to other students?</p>
              <p id="c08-c08-para-0014" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0014">Clustering is used often in digital imaging. When large groups of images need to be segmented, it's usually a cluster algorithm that works on the set and defines the clusters. Algorithms can be trained to recognize faces, specific objects, or borders, for example.</p>
            </level3>
          </level2>
          <level2 id="level2_000066">
            <h2 id="c08-c08_level1_3" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08_level1_3">Clustering Models</h2>
            <pagenum epub:type="pagebreak" id="p164" page="normal" smilref="Machine_Learning00007.smil#p164">164</pagenum>
            <p xml:space="preserve" id="p_000470" smilref="Machine_Learning00007.smil#p_000470">As previously mentioned, the goal of clustering is to segment data into specific groups. There are many different clustering algorithms for the simple fact that there is really only one common denominator among all clusters—that you're trying to find groups of objects.</p>
            <p id="c08-c08-para-0016" xml:space="preserve"><span class="text" id="span_000900" smilref="Machine_Learning00007.smil#span_000900">For example, there are distribution models that use multivariate distributions for their modeling. Graph models can show cluster-like properties when the nodes start showing as small subsets connected with one main edge as shown in </span><a id="c08-c08-fig-anc-0002" href="#c08-c08-fig-0002" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0002">Figure 8-2</a><span class="text" id="span_000901" smilref="Machine_Learning00007.smil#span_000901">.</span></p>
            <figure id="figure_000070">
              <img class="center" src="images/c08f002.jpg" alt="image" id="img_000098" />
              <figcaption id="figcaption_000056">
                <p xml:space="preserve" id="p_000471"><span class="figureLabel" id="span_000902"><a id="c08-c08-fig-0002" href="#c08-c08-fig-anc-0002" external="false"><strong id="strong_000309" smilref="Machine_Learning00007.smil#strong_000309">Figure 8-2</strong></a></span><span class="text" id="span_000903" smilref="Machine_Learning00007.smil#span_000903"> Nodes and edges as clusters</span></p>
              </figcaption>
            </figure>
            <p id="c08-c08-para-0017" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0017">You can also approach simple clustering with groups in the same way you group in a structured query language.</p>
            <p id="c08-c08-para-0018" xml:space="preserve"><span class="text" id="span_000904" smilref="Machine_Learning00007.smil#span_000904">One of the more commonly used cluster models is the centroid model, which is where the k-means algorithm comes in. The </span><em id="em_000179" smilref="Machine_Learning00007.smil#em_000179">k-means algorithm</em><span class="text" id="span_000905" smilref="Machine_Learning00007.smil#span_000905"> is basically vector quantization. This chapter concentrates on the k-means algorithm and creates a basis of the walkthrough later in the chapter.</span></p>
            <level3 id="level3_000135">
              <h3 xml:space="preserve" id="h3_000135" smilref="Machine_Learning00007.smil#h3_000135">How the K-Means Works</h3>
              <p xml:space="preserve" id="p_000472" smilref="Machine_Learning00007.smil#p_000472">If you have a group of objects, the idea of the k-means algorithm is to define a number of clusters. What's important is that it's up to you to define how many clusters you want. For example, say I have 1000 objects and I want to find 4 clusters:</p>
              <p class="informalEquation" xml:space="preserve" id="p_000473"><img src="images/c08_math_001.png" alt="equation" id="img_000099" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">n</mi><mspace width="0.12em"/><mfenced open="(" close=")"><mtext>objects</mtext></mfenced><mo>=</mo><mn>1000</mn></mrow></math>--><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi mathvariant="normal">k</mi><mspace width="0.12em"/><mfenced open="(" close=")"><mtext>clusters</mtext></mfenced><mo>=</mo><mn>4</mn></mrow></math>--></p>
              <p id="c08-c08-para-0020" xml:space="preserve"><span class="text" id="span_000906" smilref="Machine_Learning00007.smil#span_000906">Each one of the clusters has a centroid (sometimes called the mean, hence the name “k-means”), a point where the distance of the objects will be calculated. The clusters are defined by an iterative process on the distances of the objects to </span><pagenum epub:type="pagebreak" id="p165" page="normal" smilref="Machine_Learning00007.smil#p165">165</pagenum><span class="text" id="span_000907" smilref="Machine_Learning00007.smil#span_000907">calculate which are nearest to the centroid. This is all done unsupervised; you just have to let the algorithm do its processing and inspect the results. After the iterations have taken place to the point where the objects don't move to different centroids then it's assumed that the k-means clustering is complete.</span></p>
              <p id="c08-c08-para-0021" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0021">The following pseudocode describes what's happening:</p>
              <p xml:space="preserve" id="p_000474"><code class="preserve-whitespace" xml:space="preserve" id="code_000236" smilref="Machine_Learning00007.smil#code_000236">calculate inital values for means m[1],m[2],m[3],m[4]
assign object to nearest center
while(there are changes in the mean position) {
    estimate the means to classify into clusters
    for(i in 1 to k) {
        m[i] = mean of the samples for cluster i
    }
}</code></p>
              <level4 id="level4_000044">
                <h4 xml:space="preserve" id="h4_000044" smilref="Machine_Learning00007.smil#h4_000044">Initialization</h4>
                <p xml:space="preserve" id="p_000475"><span class="text" id="span_000908" smilref="Machine_Learning00007.smil#span_000908">First, the algorithm must initialize by assigning a cluster to every observation made. The </span><em id="em_000180" smilref="Machine_Learning00007.smil#em_000180">random partition method</em><span class="text" id="span_000909" smilref="Machine_Learning00007.smil#span_000909"> places the cluster points toward the center of the dataset. Another initialization method is the </span><em id="em_000181" smilref="Machine_Learning00007.smil#em_000181">Forgy method</em><span class="text" id="span_000910" smilref="Machine_Learning00007.smil#span_000910">, which spreads out the randomness of the initial location of the cluster.</span></p>
                <p id="c08-c08-para-0023" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0023">After the initial cluster observations are assigned, you can look at the assignment and updating of the algorithm.</p>
              </level4>
              <level4 id="level4_000045">
                <h4 xml:space="preserve" id="h4_000045" smilref="Machine_Learning00007.smil#h4_000045">Assignments</h4>
                <p xml:space="preserve" id="p_000476" smilref="Machine_Learning00007.smil#p_000476">Each observed object is assigned to the clusterl; to find out which cluster centroid it's assigned to, the algorithm uses a Euclidean distance measurement. The sum of squares is then calculated by squaring the Euclidean distances to each cluster centroid, and the one with the smallest value is the cluster which the object is assigned to.</p>
                <p id="c08-c08-para-0025" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0025">To calculate the Euclidean distance is quite simple and requires only some entry-level math; if you can remember how to do Pythagoras' theorem, then you are already there.</p>
                <p id="c08-c08-para-0026" xml:space="preserve"><span class="text" id="span_000911" smilref="Machine_Learning00007.smil#span_000911">Assume a basic grid of six positions on the X-axis (horizontal) and four positions on the Y-axis (vertical). The center point of my cluster is currently at 1,6 and the object is located at 3,1, as shown in </span><a id="c08-c08-fig-anc-0003" href="#c08-c08-fig-0003" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0003">Figure 8-3</a><span class="text" id="span_000912" smilref="Machine_Learning00007.smil#span_000912">.</span></p>
                <figure id="figure_000071">
                  <img class="center" src="images/c08f003.jpg" alt="image" id="img_000100" />
                  <figcaption id="figcaption_000057">
                    <p xml:space="preserve" id="p_000477"><span class="figureLabel" id="span_000913"><a id="c08-c08-fig-0003" href="#c08-c08-fig-anc-0003" external="false"><strong id="strong_000310" smilref="Machine_Learning00007.smil#strong_000310">Figure 8-3</strong></a></span><span class="text" id="span_000914" smilref="Machine_Learning00007.smil#span_000914"> Euclidean distances</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0027" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0027">The distance is 3-1 = 2 on the vertical side and 6-1 = 5 on the horizontal axis. Using Pythagoras' theorem, the squared distance is</p>
                <p class="informalEquation" xml:space="preserve" id="p_000478"><img src="images/c08_math_002.png" alt="equation" id="img_000101" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mn>2</mn><mo>&#x0005E;</mo><mn>2</mn><mo>+</mo><mn>5</mn><mo>&#x0005E;</mo><mn>2</mn><mo>=</mo><mn>4</mn><mo>+</mo><mn>25</mn><mo>=</mo><mn>29</mn></mrow></math>--></p>
                <p id="c08-c08-para-0028" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0028">The square root of 29 is 5.38. This carries on for all the objects in the dataset that are assigned to the clusters.</p>
              </level4>
              <level4 id="level4_000046">
                <h4 xml:space="preserve" id="h4_000046" smilref="Machine_Learning00007.smil#h4_000046">Update</h4>
                <pagenum epub:type="pagebreak" id="p166" page="normal" smilref="Machine_Learning00007.smil#p166">166</pagenum>
                <p xml:space="preserve" id="p_000479" smilref="Machine_Learning00007.smil#p_000479">In the update step, you assign the object values to the cluster. The recalculation of the center points of the cluster (the centroids) is taken as the average of the values of the objects that are part of the cluster. This process carries on as a loop until the entities in each group no longer change.</p>
                <p id="c08-c08-para-0030" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0030">The k-means algorithm is very effective, but it's not without its problems. It can take a few runs with the data to get a decent fit of clusters. When you choose too few, objects can easily spill into the incorrect cluster over a period of time during the processing.</p>
              </level4>
            </level3>
            <level3 id="level3_000136">
              <h3 xml:space="preserve" id="h3_000136" smilref="Machine_Learning00007.smil#h3_000136">Calculating the Number of Clusters in a Dataset</h3>
              <p xml:space="preserve" id="p_000480" smilref="Machine_Learning00007.smil#p_000480">When presented with a dataset, it can be hard to define the number of clusters that you want to classify against. Sometimes this number will already be determined by a stakeholder. For example, in a marketing initiative you might have the following:</p>
              <list type="ul" id="list_000043">
                <li id="li_000349" smilref="Machine_Learning00007.smil#li_000349">Low Frequency, Low Value Customers</li>
                <li id="li_000350" smilref="Machine_Learning00007.smil#li_000350">Low Frequency, High Value Customers</li>
                <li id="li_000351" smilref="Machine_Learning00007.smil#li_000351">High Frequency, Low Value Customers</li>
                <li id="li_000352" smilref="Machine_Learning00007.smil#li_000352">High Frequency, High Value Customers</li>
              </list>
              <p id="c08-c08-para-0032" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0032">There are times when this information is not available, and you have to find a balance for making your decisions. There are a number of methods for calculating the optimum.</p>
              <level4 id="level4_000047">
                <h4 xml:space="preserve" id="h4_000047" smilref="Machine_Learning00007.smil#h4_000047">The Rule of Thumb Method</h4>
                <pagenum epub:type="pagebreak" id="p167" page="normal" smilref="Machine_Learning00007.smil#p167">167</pagenum>
                <p xml:space="preserve" id="p_000481" smilref="Machine_Learning00007.smil#p_000481">Nothing beats wetting your finger and sticking it in the air to see which way the wind is blowing. There's a simple calculation that is roughly the equivalent for clusters: The number of clusters (k) is equal to the square root of the number of objects divided by two.</p>
                <p class="informalEquation" xml:space="preserve" id="p_000482"><img src="images/c08_math_003.png" alt="equation" id="img_000102" /><!--<math xmlns="http://www.w3.org/1998/Math/MathML" display="block" overflow="scroll"><mrow><mi>k</mi><mo>=</mo><msqrt><mrow><mtext mathvariant="italic">objects</mtext><mo stretchy="true">/</mo><mn>2</mn></mrow></msqrt></mrow></math>--></p>
                <p id="c08-c08-para-0034" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0034">If you have 250 objects, then half of that is 125, and the square root of 125 is 11.18—so, there are 11 clusters. This can obviously be tested and reapplied depending on how the trial runs go.</p>
              </level4>
              <level4 id="level4_000048">
                <h4 xml:space="preserve" id="h4_000048" smilref="Machine_Learning00007.smil#h4_000048">The Elbow Method</h4>
                <p xml:space="preserve" id="p_000483"><span class="text" id="span_000915" smilref="Machine_Learning00007.smil#span_000915">You can calculate the variance of the dataset as a percentage and plot against the number of clusters. There's a point at which the clusters are at an optimum—that point after which adding more clusters will not make a huge difference to the final classifications. You can see in </span><a id="c08-c08-fig-anc-0004" href="#c08-c08-fig-0004" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0004">Figure 8-4</a><span class="text" id="span_000916" smilref="Machine_Learning00007.smil#span_000916"> how the elbow method shows the optimum number of clusters is four, which has classified 80 percent of the data.</span></p>
                <figure id="figure_000072">
                  <img class="center" src="images/c08f004.jpg" alt="image" id="img_000103" />
                  <figcaption id="figcaption_000058">
                    <p xml:space="preserve" id="p_000484"><span class="figureLabel" id="span_000917"><a id="c08-c08-fig-0004" href="#c08-c08-fig-anc-0004" external="false"><strong id="strong_000311" smilref="Machine_Learning00007.smil#strong_000311">Figure 8-4</strong></a></span><span class="text" id="span_000918" smilref="Machine_Learning00007.smil#span_000918"> The elbow method graph</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000049">
                <h4 xml:space="preserve" id="h4_000049" smilref="Machine_Learning00007.smil#h4_000049">The Cross-Validation Method</h4>
                <pagenum epub:type="pagebreak" id="p168" page="normal" smilref="Machine_Learning00007.smil#p168">168</pagenum>
                <p xml:space="preserve" id="p_000485" smilref="Machine_Learning00007.smil#p_000485">By splitting the dataset into separate partitions, you can apply the analysis on the dataset and then on the remaining partitions. By averaging the results of the sum of squares, you can determine the number of clusters to use.</p>
                <p id="c08-c08-para-0037" xml:space="preserve"><span class="text" id="span_000919" smilref="Machine_Learning00007.smil#span_000919">Weka supports cross-validation with the </span><code xml:space="preserve" id="code_000237" smilref="Machine_Learning00007.smil#code_000237">weka.clusterers.MakeDensityBasedClusterer</code><span class="text" id="span_000920" smilref="Machine_Learning00007.smil#span_000920"> class. This class is covered in more detail in the command-line-based walkthrough later in the chapter.</span></p>
              </level4>
              <level4 id="level4_000050">
                <h4 xml:space="preserve" id="h4_000050" smilref="Machine_Learning00007.smil#h4_000050">The Silhouette Method</h4>
                <p xml:space="preserve" id="p_000486"><span class="text" id="span_000921" smilref="Machine_Learning00007.smil#span_000921">Peter J. Rousseeuw first described the </span><em id="em_000182" smilref="Machine_Learning00007.smil#em_000182">silhouette method</em><span class="text" id="span_000922" smilref="Machine_Learning00007.smil#span_000922"> in 1986. It is a method for suggesting a way of validating where the objects lay within a cluster.</span></p>
                <p id="c08-c08-para-0039" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0039">For any object, you can calculate how similar an object is with another object within the same cluster. By calculating the averages of objects that connect to a cluster and then evaluating how dissimilar they are in relation to the other clusters, you can determine an average score. The main aim is to measure the grouping of the objects in the cluster—the lower the number the better. When comparing the averages for each cluster, they are expected to be similar. When silhouettes are very narrow and others are large, it might point to the fact that not enough clusters have been defined when the computation process began.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000067">
            <h2 id="c08-c08_level1_4" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08_level1_4">K-Means Clustering with Weka</h2>
            <p xml:space="preserve" id="p_000487"><span class="text" id="span_000923" smilref="Machine_Learning00007.smil#span_000923">The Weka machine learning application comes with an algorithm for processing k-means clusters, a class called </span><code xml:space="preserve" id="code_000238" smilref="Machine_Learning00007.smil#code_000238">SimpleKMeans</code><span class="text" id="span_000924" smilref="Machine_Learning00007.smil#span_000924">. In this walkthrough, you'll work with three approaches: one from the workbench application, one that works directly from the command line, and finally one that's a Java coded example.</span></p>
            <p id="c08-c08-para-0041" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0041">The aim is to take some marketing data and use the k-means to generate some segmentation of the customers; this will potentially give the marketing department an increase in successful transactions in the long run.</p>
            <p id="c08-c08-para-0042" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0042">Before you get into the three walkthroughs, you need to prepare some data with which to work.</p>
            <level3 id="level3_000137">
              <h3 xml:space="preserve" id="h3_000137" smilref="Machine_Learning00007.smil#h3_000137">Preparing the Data</h3>
              <p xml:space="preserve" id="p_000488"><span class="text" id="span_000925" smilref="Machine_Learning00007.smil#span_000925">The following Java code generates 75 instances of random numbers for two integer variables, x and y. You import the saved file (</span><code xml:space="preserve" id="code_000239" smilref="Machine_Learning00007.smil#code_000239">kmeansdata.csv</code><span class="text" id="span_000926" smilref="Machine_Learning00007.smil#span_000926">) into Weka and also load it in programmatically.</span></p>
              <p xml:space="preserve" id="p_000489"><code class="preserve-whitespace" xml:space="preserve" id="code_000240" smilref="Machine_Learning00007.smil#code_000240">import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.IOException;
import java.util.Random;
public class DataSet3D {
    public static void main(String[] args) {
        Random r = new Random(System.nanoTime());
        try {
            BufferedWriter out = new BufferedWriter(new FileWriter("kmeansdata.csv"));
            out.write("x,y\n");
            for(int count = 0; count &lt; 75; count++) {
                out.write(r.nextInt(125) + "," + r.nextInt(150) + "\n");
            }
            out.close();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}</code></p>
              <pagenum epub:type="pagebreak" id="p169" page="normal" smilref="Machine_Learning00007.smil#p169">169</pagenum>
              <p id="c08-c08-para-0044" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0044">The output looks something like this:</p>
              <p xml:space="preserve" id="p_000490"><code class="preserve-whitespace" xml:space="preserve" id="code_000241" smilref="Machine_Learning00007.smil#code_000241">x,y
78,29
0,55
101,19
52,146
49,140
44,97
65,45
41,49
66,141
111,100
23,128
101,1
1,113
88,100</code></p>
              <p id="c08-c08-para-0045" xml:space="preserve"><span class="text" id="span_000927" smilref="Machine_Learning00007.smil#span_000927">If you want to create more instances you can do so by adjusting the number of iterations in the </span><code xml:space="preserve" id="code_000242" smilref="Machine_Learning00007.smil#code_000242">for</code><span class="text" id="span_000928" smilref="Machine_Learning00007.smil#span_000928"> loop of the code. I've set it to 75 as a starting point. The upper limit is really based on the amount of memory your computer has.</span></p>
              <p id="c08-c08-para-0046" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0046">Have a look at the Weka workbench method first.</p>
            </level3>
            <level3 id="level3_000138">
              <h3 xml:space="preserve" id="h3_000138" smilref="Machine_Learning00007.smil#h3_000138">The Workbench Method</h3>
              <p xml:space="preserve" id="p_000491"><span class="text" id="span_000929" smilref="Machine_Learning00007.smil#span_000929">The </span><em id="em_000183" smilref="Machine_Learning00007.smil#em_000183">workbench method</em><span class="text" id="span_000930" smilref="Machine_Learning00007.smil#span_000930"> uses the Weka user interface to load, cluster, and then visualize the data. There's no actual programming involved, but it's useful to see what Weka is doing before you progress on to the command-line and coded samples.</span></p>
              <level4 id="level4_000051">
                <h4 xml:space="preserve" id="h4_000051" smilref="Machine_Learning00007.smil#h4_000051">Loading Data</h4>
                <pagenum epub:type="pagebreak" id="p170" page="normal" smilref="Machine_Learning00007.smil#p170">170</pagenum>
                <p xml:space="preserve" id="p_000492" smilref="Machine_Learning00007.smil#p_000492">The process for the workbench is very similar to other examples you've run though. The first thing you need to do is load in the CSV data.</p>
                <p id="c08-c08-para-0049" xml:space="preserve"><span class="text" id="span_000931" smilref="Machine_Learning00007.smil#span_000931">Click the Open File button and select the </span><code xml:space="preserve" id="code_000243" smilref="Machine_Learning00007.smil#code_000243">kmeansdata.csv</code><span class="text" id="span_000932" smilref="Machine_Learning00007.smil#span_000932"> file that you created earlier. Ensure that the file format drop-down menu shows CSV and not ARFF (see </span><a id="c08-c08-fig-anc-0005" href="#c08-c08-fig-0005" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0005">Figure 8-5</a><span class="text" id="span_000933" smilref="Machine_Learning00007.smil#span_000933">); otherwise you won't be able to open the file.</span></p>
                <figure id="figure_000073">
                  <img class="center" src="images/c08f005.jpg" alt="image" id="img_000104" />
                  <figcaption id="figcaption_000059">
                    <p xml:space="preserve" id="p_000493"><span class="figureLabel" id="span_000934"><a id="c08-c08-fig-0005" href="#c08-c08-fig-anc-0005" external="false"><strong id="strong_000312" smilref="Machine_Learning00007.smil#strong_000312">Figure 8-5</strong></a></span><span class="text" id="span_000935" smilref="Machine_Learning00007.smil#span_000935"> Loading CSV data into Weka</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0050" xml:space="preserve"><span class="text" id="span_000936" smilref="Machine_Learning00007.smil#span_000936">When the data has loaded, the explorer shows various pieces of information. The Current Relation pane shows that there are two attributes and 75 instances. (See </span><a id="c08-c08-fig-anc-0006" href="#c08-c08-fig-0006" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0006">Figure 8-6</a><span class="text" id="span_000937" smilref="Machine_Learning00007.smil#span_000937">.) The attribute information shows the two attributes: </span><code xml:space="preserve" id="code_000244" smilref="Machine_Learning00007.smil#code_000244">x</code><span class="text" id="span_000938" smilref="Machine_Learning00007.smil#span_000938"> and </span><code xml:space="preserve" id="code_000245" smilref="Machine_Learning00007.smil#code_000245">y</code><span class="text" id="span_000939" smilref="Machine_Learning00007.smil#span_000939">.</span></p>
                <figure id="figure_000074">
                  <img class="center" src="images/c08f006.jpg" alt="image" id="img_000105" />
                  <figcaption id="figcaption_000060">
                    <p xml:space="preserve" id="p_000494"><span class="figureLabel" id="span_000940"><a id="c08-c08-fig-0006" href="#c08-c08-fig-anc-0006" external="false"><strong id="strong_000313" smilref="Machine_Learning00007.smil#strong_000313">Figure 8-6</strong></a></span><span class="text" id="span_000941" smilref="Machine_Learning00007.smil#span_000941"> The Preprocess window</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0051" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0051">On the right-hand panel, the Selected Attribute pane shows some statistics of the data that's been loaded, which includes the minimum and maximum values along with the mean and the standard deviation. Finally, there's a graph of the distribution of the values and the frequency of them.</p>
              </level4>
              <level4 id="level4_000052">
                <h4 xml:space="preserve" id="h4_000052" smilref="Machine_Learning00007.smil#h4_000052">Clustering the Data</h4>
                <p xml:space="preserve" id="p_000495"><span class="text" id="span_000942" smilref="Machine_Learning00007.smil#span_000942">Click the Cluster tab at the top to select the clustering method. By default, the Weka clusterer uses the Simple EM method (expectation maximization). </span><pagenum epub:type="pagebreak" id="p171" page="normal" smilref="Machine_Learning00007.smil#p171">171</pagenum><span class="text" id="span_000943" smilref="Machine_Learning00007.smil#span_000943">Clicking the Choose button displays a tree of other cluster algorithms that you can use. For this example, select SimpleKMeans and then click Close; finally click Start to run the algorithm, as shown in </span><a id="c08-c08-fig-anc-0007" href="#c08-c08-fig-0007" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0007">Figure 8-7</a><span class="text" id="span_000944" smilref="Machine_Learning00007.smil#span_000944">.</span></p>
                <figure id="figure_000075">
                  <img class="center" src="images/c08f007.jpg" alt="image" id="img_000106" />
                  <figcaption id="figcaption_000061">
                    <p xml:space="preserve" id="p_000496"><span class="figureLabel" id="span_000945"><a id="c08-c08-fig-0007" href="#c08-c08-fig-anc-0007" external="false"><strong id="strong_000314" smilref="Machine_Learning00007.smil#strong_000314">Figure 8-7</strong></a></span><span class="text" id="span_000946" smilref="Machine_Learning00007.smil#span_000946"> Selecting SimpleKMeans</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0053" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0053">The clusterer line in the Clusterer output pane has updated and shows the new cluster algorithm you'll be using:</p>
                <p xml:space="preserve" id="p_000497"><code class="preserve-whitespace" xml:space="preserve" id="code_000246" smilref="Machine_Learning00007.smil#code_000246">SimpleKMeans –N 2 –A "weka.core.EuclideanDistance –R first –last" –l 500 –S 10</code></p>
                <p id="c08-c08-para-0054" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0054">There are a few flags that need a little explanation.</p>
                <list type="ul" id="list_000044">
                  <li id="li_000353">
                    <code xml:space="preserve" id="code_000247" smilref="Machine_Learning00007.smil#code_000247">-N</code>
                    <span class="text" id="span_000947" smilref="Machine_Learning00007.smil#span_000947">determines the number of clusters that the SimpleKMeans is going to create.</span>
                  </li>
                  <li id="li_000354">
                    <code xml:space="preserve" id="code_000248" smilref="Machine_Learning00007.smil#code_000248">-A</code>
                    <span class="text" id="span_000948" smilref="Machine_Learning00007.smil#span_000948">is the distance function used. It defaults to Euclidean distance and uses the entire range of values as its range to act on</span>
                    <code xml:space="preserve" id="code_000249" smilref="Machine_Learning00007.smil#code_000249">(-R first –last</code>
                    <span class="text" id="span_000949" smilref="Machine_Learning00007.smil#span_000949">).</span>
                  </li>
                  <li id="li_000355">
                    <span class="text" id="span_000950" smilref="Machine_Learning00007.smil#span_000950">The</span>
                    <code xml:space="preserve" id="code_000250" smilref="Machine_Learning00007.smil#code_000250">–l</code>
                    <span class="text" id="span_000951" smilref="Machine_Learning00007.smil#span_000951">flag defines the number of iterations the k-means does to define the cluster.</span>
                  </li>
                  <li id="li_000356">
                    <code xml:space="preserve" id="code_000251" smilref="Machine_Learning00007.smil#code_000251">-S</code>
                    <span class="text" id="span_000952" smilref="Machine_Learning00007.smil#span_000952">is a random number seed. It can be any value you want.</span>
                  </li>
                </list>
                <pagenum epub:type="pagebreak" id="p172" page="normal" smilref="Machine_Learning00007.smil#p172">172</pagenum>
                <p id="c08-c08-para-0055" xml:space="preserve"><span class="text" id="span_000953" smilref="Machine_Learning00007.smil#span_000953">Clicking the line with all the command options shown next to the Choose button displays a pop-up window where you can alter the values. In the numClusters field, change the number from </span><code xml:space="preserve" id="code_000252" smilref="Machine_Learning00007.smil#code_000252">2</code><span class="text" id="span_000954" smilref="Machine_Learning00007.smil#span_000954"> to </span><code xml:space="preserve" id="code_000253" smilref="Machine_Learning00007.smil#code_000253">4</code><span class="text" id="span_000955" smilref="Machine_Learning00007.smil#span_000955">. (See </span><a id="c08-c08-fig-anc-0008" href="#c08-c08-fig-0008" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0008">Figure 8-8</a><span class="text" id="span_000956" smilref="Machine_Learning00007.smil#span_000956">.) You're going to create four clusters with this data. Click OK to close the window.</span></p>
                <figure id="figure_000076">
                  <img class="center" src="images/c08f008.jpg" alt="image" id="img_000107" />
                  <figcaption id="figcaption_000062">
                    <p xml:space="preserve" id="p_000498"><span class="figureLabel" id="span_000957"><a id="c08-c08-fig-0008" href="#c08-c08-fig-anc-0008" external="false"><strong id="strong_000315" smilref="Machine_Learning00007.smil#strong_000315">Figure 8-8</strong></a></span><span class="text" id="span_000958" smilref="Machine_Learning00007.smil#span_000958"> Changing the SimpleKMeans options</span></p>
                  </figcaption>
                </figure>
                <pagenum epub:type="pagebreak" id="p173" page="normal" smilref="Machine_Learning00007.smil#p173">173</pagenum>
                <p id="c08-c08-para-0056" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0056">Start the clustering process by clicking the Start button. For long periods of processing, it's worth keeping an eye on the status in the bottom-left corner of the explorer.</p>
                <p id="c08-c08-para-0057" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0057">When the process is complete, you see the output appear in the Clusterer Output window. The following sections describe the output.</p>
                <level5 id="level5_000001">
                  <h5 xml:space="preserve" id="h5_000001" smilref="Machine_Learning00007.smil#h5_000001">Run Information</h5>
                  <p xml:space="preserve" id="p_000499" smilref="Machine_Learning00007.smil#p_000499">The first block of information gives the settings of the data and the algorithm selected.</p>
                  <p xml:space="preserve" id="p_000500"><code class="preserve-whitespace" xml:space="preserve" id="code_000254" smilref="Machine_Learning00007.smil#code_000254">Scheme:weka.clusterers.SimpleKMeans -N 4 -A "weka.core.EuclideanDistance -R first-last" -I 500 -S 10
Relation:     td
Instances:    75
Attributes:   2
              x
              y
Test mode:evaluate on training data</code></p>
                </level5>
                <level5 id="level5_000002">
                  <h5 xml:space="preserve" id="h5_000002" smilref="Machine_Learning00007.smil#h5_000002">K-Means</h5>
                  <p xml:space="preserve" id="p_000501" smilref="Machine_Learning00007.smil#p_000501">The k-means output shows the actual work that Weka did to reach the results. This includes the number of iterations that were performed on the data and the sum of squared errors.</p>
                  <p xml:space="preserve" id="p_000502"><code class="preserve-whitespace" xml:space="preserve" id="code_000255" smilref="Machine_Learning00007.smil#code_000255">Number of iterations: 3
Within cluster sum of squared errors: 0.8072960323968902
Missing values globally replaced with mean/mode
Cluster centroids:
                         Cluster#
Attribute    Full Data          0          1          2          3
                  (75)       (15)       (23)       (17)       (20)
==================================================================
x                54.88    68.9333     43.913    98.1765      20.15
y              92.0267       19.4   146.0435   114.8824      64.95</code></p>
                  <p id="c08-c08-para-0060" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0060">The cluster centroid data information is shown in relation to the instance data, showing the final value locations of the centroids for each cluster.</p>
                </level5>
                <level5 id="level5_000003">
                  <h5 xml:space="preserve" id="h5_000003" smilref="Machine_Learning00007.smil#h5_000003">Clustered Instances</h5>
                  <p xml:space="preserve" id="p_000503" smilref="Machine_Learning00007.smil#p_000503">Finally, the percentage of the data within each cluster is shown. It gives you an idea of how the data is distributed.</p>
                  <p xml:space="preserve" id="p_000504"><code class="preserve-whitespace" xml:space="preserve" id="code_000256" smilref="Machine_Learning00007.smil#code_000256">Clustered Instances
0      15 ( 20%)
1      23 ( 31%)
2      17 ( 23%)
3      20 ( 27%)</code></p>
                </level5>
              </level4>
              <level4 id="level4_000053">
                <h4 xml:space="preserve" id="h4_000053" smilref="Machine_Learning00007.smil#h4_000053">Visualizing the Data</h4>
                <pagenum epub:type="pagebreak" id="p174" page="normal" smilref="Machine_Learning00007.smil#p174">174</pagenum>
                <p xml:space="preserve" id="p_000505"><span class="text" id="span_000959" smilref="Machine_Learning00007.smil#span_000959">The last thing to do is look at the visualization of the clustering. In the explorer window, you see the result list on the bottom left. Right-clicking (or Alt + clicking on the Mac) the SimpleKMeans brings up the visualize window, as shown in </span><a id="c08-c08-fig-anc-0009" href="#c08-c08-fig-0009" external="false" smilref="Machine_Learning00007.smil#c08-c08-fig-anc-0009">Figure 8-9</a><span class="text" id="span_000960" smilref="Machine_Learning00007.smil#span_000960">.</span></p>
                <figure id="figure_000077">
                  <img class="center" src="images/c08f009.jpg" alt="image" id="img_000108" />
                  <figcaption id="figcaption_000063">
                    <p xml:space="preserve" id="p_000506"><span class="figureLabel" id="span_000961"><a id="c08-c08-fig-0009" href="#c08-c08-fig-anc-0009" external="false"><strong id="strong_000316" smilref="Machine_Learning00007.smil#strong_000316">Figure 8-9</strong></a></span><span class="text" id="span_000962" smilref="Machine_Learning00007.smil#span_000962"> Visualize window</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0063" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0063">Each cluster has its own color scheme, and the plot shows values. Along the top of the visualization window are two, drop-down menus. To alter the plot, select a value from each drop-down menu. To show the x and y instance values, select the X: x(Num) and Y: y(Num) values, and you see the plot update.</p>
                <p id="c08-c08-para-0064" xml:space="preserve" smilref="Machine_Learning00007.smil#c08-c08-para-0064">Using the workbench method gives you a quick route to some insight, and it is very useful if you want to get a grasp on where the clusters lie. To start automating the process, you need to look at the other two approaches, starting with the command-line method.</p>
              </level4>
            </level3>
            <level3 id="level3_000139">
              <h3 xml:space="preserve" id="h3_000139" smilref="Machine_Learning00007.smil#h3_000139">The Command-Line Method</h3>
              <p xml:space="preserve" id="p_000507"><span class="text" id="span_000963" smilref="Machine_Learning00007.smil#span_000963">The </span><em id="em_000184" smilref="Machine_Learning00007.smil#em_000184">command-line method</em><span class="text" id="span_000964" smilref="Machine_Learning00007.smil#span_000964"> is very similar to the workbench method but it gives you a little more flexibility in terms of running within </span><code xml:space="preserve" id="code_000257" smilref="Machine_Learning00007.smil#code_000257">cron</code><span class="text" id="span_000965" smilref="Machine_Learning00007.smil#span_000965"> jobs. This means that you can collate more data and rerun the analysis on a regular basis.</span></p>
              <level4 id="level4_000054">
                <h4 xml:space="preserve" id="h4_000054" smilref="Machine_Learning00007.smil#h4_000054">Converting CSV File to ARFF</h4>
                <p xml:space="preserve" id="p_000508"><span class="text" id="span_000966" smilref="Machine_Learning00007.smil#span_000966">Weka uses the </span><code xml:space="preserve" id="code_000258" smilref="Machine_Learning00007.smil#code_000258">.arff</code><span class="text" id="span_000967" smilref="Machine_Learning00007.smil#span_000967"> format to determine object types and have data ready for processing. The GUI enables you to import </span><code xml:space="preserve" id="code_000259" smilref="Machine_Learning00007.smil#code_000259">.csv</code><span class="text" id="span_000968" smilref="Machine_Learning00007.smil#span_000968"> files directly, but it's nice to have a tool that converts files for you.</span></p>
                <p id="c08-c08-para-0067" xml:space="preserve"><span class="text" id="span_000969" smilref="Machine_Learning00007.smil#span_000969">You can use the </span><code xml:space="preserve" id="code_000260" smilref="Machine_Learning00007.smil#code_000260">CVSLoader</code><span class="text" id="span_000970" smilref="Machine_Learning00007.smil#span_000970"> class on the command line to convert </span><code xml:space="preserve" id="code_000261" smilref="Machine_Learning00007.smil#code_000261">.csv</code><span class="text" id="span_000971" smilref="Machine_Learning00007.smil#span_000971"> files to </span><code xml:space="preserve" id="code_000262" smilref="Machine_Learning00007.smil#code_000262">.arff</code><span class="text" id="span_000972" smilref="Machine_Learning00007.smil#span_000972">. For example, the </span><code xml:space="preserve" id="code_000263" smilref="Machine_Learning00007.smil#code_000263">.csv</code><span class="text" id="span_000973" smilref="Machine_Learning00007.smil#span_000973"> file you created in the previous walkthrough </span><pagenum epub:type="pagebreak" id="p175" page="normal" smilref="Machine_Learning00007.smil#p175">175</pagenum><span class="text" id="span_000974" smilref="Machine_Learning00007.smil#span_000974">was </span><code xml:space="preserve" id="code_000264" smilref="Machine_Learning00007.smil#code_000264">kmeansdata.csv</code><span class="text" id="span_000975" smilref="Machine_Learning00007.smil#span_000975">. Use the converter by running the following from the terminal command line:</span></p>
                <p xml:space="preserve" id="p_000509"><code class="preserve-whitespace" xml:space="preserve" id="code_000265" smilref="Machine_Learning00007.smil#code_000265">java –cp weka.jar weka.core.converters.CSVLoader kmeansdata.csv &gt; kmeansdata.arff</code></p>
                <sidebar render="required" id="sidebar_000010">
                  <div class="top hr" id="div_000010" />
                  <level2 class="feature2" id="level2_000068">
                    <h2 xml:space="preserve" id="h2_000014" smilref="Machine_Learning00007.smil#h2_000014">Note</h2>
                    <p xml:space="preserve" id="p_000510"><span class="text" id="span_000976" smilref="Machine_Learning00007.smil#span_000976">If you're using the Windows operating system then you can omit the </span><code xml:space="preserve" id="code_000266" smilref="Machine_Learning00007.smil#code_000266">–cp weka.jar</code><span class="text" id="span_000977" smilref="Machine_Learning00007.smil#span_000977"> from the </span><code xml:space="preserve" id="code_000267" smilref="Machine_Learning00007.smil#code_000267">java</code><span class="text" id="span_000978" smilref="Machine_Learning00007.smil#span_000978"> command.</span></p>
                  </level2>
                </sidebar>
                <p id="c08-c08-para-0069" xml:space="preserve"><span class="text" id="span_000979" smilref="Machine_Learning00007.smil#span_000979">The command-line output might give some warnings about database drivers not being available, but there's no need to worry about that. The main thing is that in the </span><code xml:space="preserve" id="code_000268" smilref="Machine_Learning00007.smil#code_000268">.arff</code><span class="text" id="span_000980" smilref="Machine_Learning00007.smil#span_000980"> file you have the proper definition.</span></p>
                <p id="c08-c08-para-0070" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0070">Do a quick inspection to see the following definition:</p>
                <p xml:space="preserve" id="p_000511"><code class="preserve-whitespace" xml:space="preserve" id="code_000269" smilref="Machine_Learning00008.smil#code_000269">@relation kmeansdata
@attribute x numeric
@attribute y numeric
@data</code></p>
              </level4>
              <level4 id="level4_000055">
                <h4 xml:space="preserve" id="h4_000055" smilref="Machine_Learning00008.smil#h4_000055">The First Run</h4>
                <p xml:space="preserve" id="p_000512"><span class="text" id="span_000981" smilref="Machine_Learning00008.smil#span_000981">Test out the command-line methods by starting with just running the </span><code xml:space="preserve" id="code_000270" smilref="Machine_Learning00008.smil#code_000270">SimpleKMeans</code><span class="text" id="span_000982" smilref="Machine_Learning00008.smil#span_000982"> class as- is on the </span><code xml:space="preserve" id="code_000271" smilref="Machine_Learning00008.smil#code_000271">.arff</code><span class="text" id="span_000983" smilref="Machine_Learning00008.smil#span_000983"> file. This is your training file:</span></p>
                <p xml:space="preserve" id="p_000513"><code class="preserve-whitespace" xml:space="preserve" id="code_000272" smilref="Machine_Learning00008.smil#code_000272">java -cp /path/to/weka.jar weka.clusterers.SimpleKMeans -t kmeandata.arff</code></p>
                <p id="c08-c08-para-0072" xml:space="preserve"><span class="text" id="span_000984" smilref="Machine_Learning00008.smil#span_000984">The </span><code xml:space="preserve" id="code_000273" smilref="Machine_Learning00008.smil#code_000273">–t</code><span class="text" id="span_000985" smilref="Machine_Learning00008.smil#span_000985"> flag gives you the name of the training file that Weka is attempting to cluster. Running this as-is gives the following output:</span></p>
                <p xml:space="preserve" id="p_000514"><code class="preserve-whitespace" xml:space="preserve" id="code_000274" smilref="Machine_Learning00008.smil#code_000274">kMeans
======
Number of iterations: 3
Within cluster sum of squared errors: 5.839457872519278
Missing values globally replaced with mean/mode
Cluster centroids:
                         Cluster#
Attribute    Full Data          0          1
                  (75)       (35)       (40)
============================================
x                54.88    41.0571     66.975
y              92.0267    45.4286      132.8
=== Clustering stats for training data ===
Clustered Instances
0      35 ( 47%)
1      40 ( 53%)</code></p>
                <pagenum epub:type="pagebreak" id="p176" page="normal" smilref="Machine_Learning00008.smil#p176">176</pagenum>
                <p id="c08-c08-para-0073" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0073">That works okay, but it's only two clusters and there's a good chance there are more.</p>
              </level4>
              <level4 id="level4_000056">
                <h4 xml:space="preserve" id="h4_000056" smilref="Machine_Learning00008.smil#h4_000056">Refining the Optimum Clusters</h4>
                <p xml:space="preserve" id="p_000515"><span class="text" id="span_000986" smilref="Machine_Learning00008.smil#span_000986">Working out the optimum with the rule of thumb method described earlier in the chapter is easy enough. You can find out the number of object instances using the UNIX </span><code xml:space="preserve" id="code_000275" smilref="Machine_Learning00008.smil#code_000275">wc</code><span class="text" id="span_000987" smilref="Machine_Learning00008.smil#span_000987"> command.</span></p>
                <p xml:space="preserve" id="p_000516"><code class="preserve-whitespace" xml:space="preserve" id="code_000276" smilref="Machine_Learning00008.smil#code_000276">wc kmeansdata.csv
      75      76     494 kmeansdata.csv</code></p>
                <p id="c08-c08-para-0075" xml:space="preserve"><span class="text" id="span_000988" smilref="Machine_Learning00008.smil#span_000988">There are 74 lines (excluding the top line, which gives you the data labels </span><code xml:space="preserve" id="code_000277" smilref="Machine_Learning00008.smil#code_000277">x</code><span class="text" id="span_000989" smilref="Machine_Learning00008.smil#span_000989"> and </span><code xml:space="preserve" id="code_000278" smilref="Machine_Learning00008.smil#code_000278">y</code><span class="text" id="span_000990" smilref="Machine_Learning00008.smil#span_000990">). A quick calculation of 75 divided by 2 results in 37.5, and the square root of that is 6.12.</span></p>
                <p id="c08-c08-para-0076" xml:space="preserve"><span class="text" id="span_000991" smilref="Machine_Learning00008.smil#span_000991">By altering the command line, you can add that target cluster number (using the </span><code xml:space="preserve" id="code_000279" smilref="Machine_Learning00008.smil#code_000279">–N</code><span class="text" id="span_000992" smilref="Machine_Learning00008.smil#span_000992"> flag) along with a random seed number to work off (using the </span><code xml:space="preserve" id="code_000280" smilref="Machine_Learning00008.smil#code_000280">–S</code><span class="text" id="span_000993" smilref="Machine_Learning00008.smil#span_000993"> flag):</span></p>
                <p xml:space="preserve" id="p_000517"><code class="preserve-whitespace" xml:space="preserve" id="code_000281" smilref="Machine_Learning00008.smil#code_000281">java -cp /path/to/weka.jar weka.clusterers.SimpleKMeans -t kmeansdata.arff -N 6 -S 42</code></p>
                <p id="c08-c08-para-0077" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0077">The output this time gives the same output but with more clusters:</p>
                <p xml:space="preserve" id="p_000518"><code class="preserve-whitespace" xml:space="preserve" id="code_000282" smilref="Machine_Learning00008.smil#code_000282">kMeans
======
Number of iterations: 3
Within cluster sum of squared errors: 0.523849925862059
Missing values globally replaced with mean/mode
Cluster centroids:
                         Cluster#
Attribute  Full Data    0         1         2       3       4       5
            (75)      (10)      (12)      (15)     (5)    (10)    (23)
========================================================================
x          54.88      11.8    105.0833   68.9333  81.6    28.5   43.913
y          92.0267    65.9    118.3333   19.4    106.6    64    146.0435
=== Clustering stats for training data ===
Clustered Instances
0      10 ( 13%)
1      12 ( 16%)
2      15 ( 20%)
3       5 (  7%)
4      10 ( 13%)
5      23 ( 31%)</code></p>
                <pagenum epub:type="pagebreak" id="p177" page="normal" smilref="Machine_Learning00008.smil#p177">177</pagenum>
                <p id="c08-c08-para-0078" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0078">Now, you have six clusters with a good definition of objects going into their specific clusters. The only problem is that you don't know to which cluster the objects belong.</p>
              </level4>
              <level4 id="level4_000057">
                <h4 xml:space="preserve" id="h4_000057" smilref="Machine_Learning00008.smil#h4_000057">Name That Cluster</h4>
                <p xml:space="preserve" id="p_000519"><span class="text" id="span_000994" smilref="Machine_Learning00008.smil#span_000994">From the command line, the </span><code xml:space="preserve" id="code_000283" smilref="Machine_Learning00008.smil#code_000283">–p</code><span class="text" id="span_000995" smilref="Machine_Learning00008.smil#span_000995"> flag tells Weka to display the assignment of each row's cluster instance. To use this feature, you have to instruct Weka which data attribute to use for each row. From the command line, use the following:</span></p>
                <p xml:space="preserve" id="p_000520"><code class="preserve-whitespace" xml:space="preserve" id="code_000284" smilref="Machine_Learning00008.smil#code_000284"> java -cp /path/to/weka.jar weka.clusterers.SimpleKMeans -t kmeansdata.arff -N 6 -S 42 -p 0</code></p>
                <p id="c08-c08-para-0080" xml:space="preserve"><span class="text" id="span_000996" smilref="Machine_Learning00008.smil#span_000996">The </span><code xml:space="preserve" id="code_000285" smilref="Machine_Learning00008.smil#code_000285">–p 0</code><span class="text" id="span_000997" smilref="Machine_Learning00008.smil#span_000997"> flag tells Weka to display the row and cluster based on the row number of the data. When this is run, you see the following output to the console:</span></p>
                <p xml:space="preserve" id="p_000521"><code class="preserve-whitespace" xml:space="preserve" id="code_000286" smilref="Machine_Learning00008.smil#code_000286">0 0
1 0
2 0
3 0
4 0
5 0
6 0
7 0
8 0
9 0
10 4
11 4
12 4
13 4
14 4
15 4
16 4
17 4
18 4
19 4</code></p>
                <pagenum epub:type="pagebreak" id="p178" page="normal" smilref="Machine_Learning00008.smil#p178">178</pagenum>
                <p id="c08-c08-para-0081" xml:space="preserve"><span class="text" id="span_000998" smilref="Machine_Learning00008.smil#span_000998">All that's being shown is the row number and the numeric identifier of the cluster to which the row belongs. If you set the </span><code xml:space="preserve" id="code_000287" smilref="Machine_Learning00008.smil#code_000287">–p</code><span class="text" id="span_000999" smilref="Machine_Learning00008.smil#span_000999"> flag to </span><code xml:space="preserve" id="code_000288" smilref="Machine_Learning00008.smil#code_000288">1</code><span class="text" id="span_001000" smilref="Machine_Learning00008.smil#span_001000"> or </span><code xml:space="preserve" id="code_000289" smilref="Machine_Learning00008.smil#code_000289">2</code><span class="text" id="span_001001" smilref="Machine_Learning00008.smil#span_001001">, then you'd get the value of the x or y positions respectively.</span></p>
                <p id="c08-c08-para-0082" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0082">With these workbench and command-line examples, you should now have a good idea how all this is put together. Take a look at the Java coded method using the Weka application programming interface (API). It demonstrates how you can integrate these clustering methods into your own server-side projects.</p>
              </level4>
            </level3>
            <level3 id="level3_000140">
              <h3 xml:space="preserve" id="h3_000140" smilref="Machine_Learning00008.smil#h3_000140">The Coded Method</h3>
              <p xml:space="preserve" id="p_000522" smilref="Machine_Learning00008.smil#p_000522">The workbench works well, and the command line suits development needs better when scheduled jobs need to be done. But, for ultimate flexibility, there's nothing better than coding your own program using the API to get things done.</p>
              <p id="c08-c08-para-0084" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0084">The same core Weka classes are used by the workbench, command line, and Java coded examples. It's a case of figuring out how the data is loaded and the clustering done with the options you've used in previous examples.</p>
              <p id="c08-c08-para-0085" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0085">Creating a k-means cluster in Java is actually a fairly trivial matter; it's a matter of knowing what elements go where. You are going to create a simple Java program to complete what you've done in the previous two walkthroughs. I'll be using Eclipse.</p>
              <level4 id="level4_000058">
                <h4 xml:space="preserve" id="h4_000058" smilref="Machine_Learning00008.smil#h4_000058">Create the Project</h4>
                <p xml:space="preserve" id="p_000523"><span class="text" id="span_001002" smilref="Machine_Learning00008.smil#span_001002">Select File → New → Java Project and call it </span><code xml:space="preserve" id="code_000290" smilref="Machine_Learning00008.smil#code_000290">WekaCluster</code><span class="text" id="span_001003" smilref="Machine_Learning00008.smil#span_001003">, as shown in </span><a id="c08-c08-fig-anc-0010" href="#c08-c08-fig-0010" external="false" smilref="Machine_Learning00008.smil#c08-c08-fig-anc-0010">Figure 8-10</a><span class="text" id="span_001004" smilref="Machine_Learning00008.smil#span_001004">.</span></p>
                <figure id="figure_000078">
                  <img class="center" src="images/c08f010.jpg" alt="image" id="img_000109" />
                  <figcaption id="figcaption_000064">
                    <p xml:space="preserve" id="p_000524"><span class="figureLabel" id="span_001005"><a id="c08-c08-fig-0010" href="#c08-c08-fig-anc-0010" external="false"><strong id="strong_000317" smilref="Machine_Learning00008.smil#strong_000317">Figure 8-10</strong></a></span><span class="text" id="span_001006" smilref="Machine_Learning00008.smil#span_001006"> Eclipse New Java Project dialog box</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0087" xml:space="preserve"><span class="text" id="span_001007" smilref="Machine_Learning00008.smil#span_001007">There's only one library to install; that is the </span><code xml:space="preserve" id="code_000291" smilref="Machine_Learning00008.smil#code_000291">weka.jar</code><span class="text" id="span_001008" smilref="Machine_Learning00008.smil#span_001008"> file. On Mac OS X machines, Weka is usually installed within the Applications directory. The location on Windows machines varies depending on the specific operating system.</span></p>
                <p id="c08-c08-para-0088" xml:space="preserve"><span class="text" id="span_001009" smilref="Machine_Learning00008.smil#span_001009">With the </span><code xml:space="preserve" id="code_000292" smilref="Machine_Learning00008.smil#code_000292">WekaCluster</code><span class="text" id="span_001010" smilref="Machine_Learning00008.smil#span_001010"> project selected, click File → Properties and look for the Java Build Path. Then, click the Libraries tab. Add the external </span><code xml:space="preserve" id="code_000293" smilref="Machine_Learning00008.smil#code_000293">jar</code><span class="text" id="span_001011" smilref="Machine_Learning00008.smil#span_001011"> file by clicking Add External JARs. In the File dialog box, find the </span><code xml:space="preserve" id="code_000294" smilref="Machine_Learning00008.smil#code_000294">weka.jar</code><span class="text" id="span_001012" smilref="Machine_Learning00008.smil#span_001012"> file, as shown in </span><a id="c08-c08-fig-anc-0011" href="#c08-c08-fig-0011" external="false" smilref="Machine_Learning00008.smil#c08-c08-fig-anc-0011">Figure 8-11</a><span class="text" id="span_001013" smilref="Machine_Learning00008.smil#span_001013">.</span></p>
                <figure id="figure_000079">
                  <img class="center" src="images/c08f011.jpg" alt="image" id="img_000110" />
                  <figcaption id="figcaption_000065">
                    <p xml:space="preserve" id="p_000525"><span class="figureLabel" id="span_001014"><a id="c08-c08-fig-0011" href="#c08-c08-fig-anc-0011" external="false"><strong id="strong_000318" smilref="Machine_Learning00008.smil#strong_000318">Figure 8-11</strong></a></span><span class="text" id="span_001015" smilref="Machine_Learning00008.smil#span_001015"> Adding an external jar</span></p>
                  </figcaption>
                </figure>
                <p id="c08-c08-para-0089" xml:space="preserve"><span class="text" id="span_001016" smilref="Machine_Learning00008.smil#span_001016">The last thing to do is create a new class called </span><code xml:space="preserve" id="code_000295" smilref="Machine_Learning00008.smil#code_000295">WekaCluster.java</code><span class="text" id="span_001017" smilref="Machine_Learning00008.smil#span_001017"> (use File →New →Class); see </span><a id="c08-c08-fig-anc-0012" href="#c08-c08-fig-0012" external="false" smilref="Machine_Learning00008.smil#c08-c08-fig-anc-0012">Figure 8-12</a><span class="text" id="span_001018" smilref="Machine_Learning00008.smil#span_001018"> for what this should look like.</span></p>
                <figure id="figure_000080">
                  <img class="center" src="images/c08f012.jpg" alt="image" id="img_000111" />
                  <figcaption id="figcaption_000066">
                    <p xml:space="preserve" id="p_000526"><span class="figureLabel" id="span_001019"><a id="c08-c08-fig-0012" href="#c08-c08-fig-anc-0012" external="false"><strong id="strong_000319" smilref="Machine_Learning00008.smil#strong_000319">Figure 8-12</strong></a></span> <pagenum epub:type="pagebreak" id="p180" page="normal" smilref="Machine_Learning00008.smil#p180">180</pagenum><span class="text" id="span_001020" smilref="Machine_Learning00008.smil#span_001020">Creating a new class file</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000059">
                <h4 xml:space="preserve" id="h4_000059" smilref="Machine_Learning00008.smil#h4_000059">The Cluster Code</h4>
                <p xml:space="preserve" id="p_000527" smilref="Machine_Learning00008.smil#p_000527">You're going to do the following actions to get your cluster working:</p>
                <list type="ul" id="list_000045">
                  <li id="li_000357">
                    <span class="text" id="span_001021" smilref="Machine_Learning00008.smil#span_001021">Write the</span>
                    <code xml:space="preserve" id="code_000296" smilref="Machine_Learning00008.smil#code_000296">main</code>
                    <span class="text" id="span_001022" smilref="Machine_Learning00008.smil#span_001022">method, passing in the location of the</span>
                    <code xml:space="preserve" id="code_000297" smilref="Machine_Learning00008.smil#code_000297">.arff</code>
                    <span class="text" id="span_001023" smilref="Machine_Learning00008.smil#span_001023">file.</span>
                  </li>
                  <li id="li_000358" smilref="Machine_Learning00008.smil#li_000358">Write a rule of thumb routine to advise the number of clusters you should be aiming for.</li>
                  <li id="li_000359">
                    <span class="text" id="span_001024" smilref="Machine_Learning00008.smil#span_001024">Use Weka's</span>
                    <code xml:space="preserve" id="code_000298" smilref="Machine_Learning00008.smil#code_000298">SimpleKMeans</code>
                    <span class="text" id="span_001025" smilref="Machine_Learning00008.smil#span_001025">class to build the cluster model.</span>
                  </li>
                  <li id="li_000360" smilref="Machine_Learning00008.smil#li_000360">Print out the location of the centroids of the cluster.</li>
                  <li id="li_000361" smilref="Machine_Learning00008.smil#li_000361">Print out to which cluster each instance object belongs.</li>
                </list>
                <pagenum epub:type="pagebreak" id="p179" page="normal" smilref="Machine_Learning00008.smil#p179">179</pagenum>
                <p id="c08-c08-para-0091" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0091">This sounds like a lot of work, but it's actually quite simple. The following sections break down each individual step.</p>
                <level5 id="level5_000004">
                  <h5 xml:space="preserve" id="h5_000004" smilref="Machine_Learning00008.smil#h5_000004">The main Method</h5>
                  <p xml:space="preserve" id="p_000528"><span class="text" id="span_001026" smilref="Machine_Learning00008.smil#span_001026">The </span><code xml:space="preserve" id="code_000299" smilref="Machine_Learning00008.smil#code_000299">main</code><span class="text" id="span_001027" smilref="Machine_Learning00008.smil#span_001027"> method is the starting point for the program. It's simple—just one line to create an instance of the constructor and pass in the location of the </span><code xml:space="preserve" id="code_000300" smilref="Machine_Learning00008.smil#code_000300">.arff</code><span class="text" id="span_001028" smilref="Machine_Learning00008.smil#span_001028"> file:</span></p>
                  <p xml:space="preserve" id="p_000529"><code class="preserve-whitespace" xml:space="preserve" id="code_000301"><strong id="strong_000320" smilref="Machine_Learning00008.smil#strong_000320">public static void</strong><span class="text" id="span_001029" smilref="Machine_Learning00008.smil#span_001029"> main(String[] args) {
    // Pass the arff location and the number of clusters we want
    WekaCluster wc = </span><strong id="strong_000321" smilref="Machine_Learning00008.smil#strong_000321">new</strong><span class="text" id="span_001030" smilref="Machine_Learning00008.smil#span_001030"> WekaCluster("/Users/Jason/kmeandata.arff");
}</span></code></p>
                  <p id="c08-c08-para-0093" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0093">Because you're passing the filepath as a string, you need to reflect that in the constructor for the class. I talk more about this in a moment.</p>
                </level5>
                <level5 id="level5_000005">
                  <h5 xml:space="preserve" id="h5_000005" smilref="Machine_Learning00008.smil#h5_000005">Working Out the Cluster Rule of Thumb</h5>
                  <p xml:space="preserve" id="p_000530" smilref="Machine_Learning00008.smil#p_000530">Earlier, I established that you could quickly estimate the optimum number of clusters to generate. I've included a method to give you the number of clusters to generate based on the instance rows:</p>
                  <p xml:space="preserve" id="p_000531"><code class="preserve-whitespace" xml:space="preserve" id="code_000302"><strong id="strong_000322" smilref="Machine_Learning00008.smil#strong_000322">public int</strong><span class="text" id="span_001031" smilref="Machine_Learning00008.smil#span_001031"> calculateRuleOfThumb(</span><strong id="strong_000323" smilref="Machine_Learning00008.smil#strong_000323">int</strong><span class="text" id="span_001032" smilref="Machine_Learning00008.smil#span_001032"> rows) {
    </span><strong id="strong_000324" smilref="Machine_Learning00008.smil#strong_000324">return</strong><span class="text" id="span_001033" smilref="Machine_Learning00008.smil#span_001033"> (</span><strong id="strong_000325" smilref="Machine_Learning00008.smil#strong_000325">int</strong><span class="text" id="span_001034" smilref="Machine_Learning00008.smil#span_001034">)Math.</span><em id="em_000185" smilref="Machine_Learning00008.smil#em_000185">sqrt</em><span class="text" id="span_001035" smilref="Machine_Learning00008.smil#span_001035">(rows/2);
}</span></code></p>
                  <pagenum epub:type="pagebreak" id="p181" page="normal" smilref="Machine_Learning00008.smil#p181">181</pagenum>
                  <p id="c08-c08-para-0095" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0095">The number of rows is passed in as an integer variable. You return the square root of the row count divided by two. If you already know how many clusters you want, just hard code that number.</p>
                </level5>
                <level5 id="level5_000006">
                  <h5 xml:space="preserve" id="h5_000006" smilref="Machine_Learning00008.smil#h5_000006">Building the Cluster</h5>
                  <p xml:space="preserve" id="p_000532"><span class="text" id="span_001036" smilref="Machine_Learning00008.smil#span_001036">The </span><code xml:space="preserve" id="code_000303" smilref="Machine_Learning00008.smil#code_000303">main</code><span class="text" id="span_001037" smilref="Machine_Learning00008.smil#span_001037"> constructor handles the building of the cluster using the Weka API. As in the previous examples, you're using the </span><code xml:space="preserve" id="code_000304" smilref="Machine_Learning00008.smil#code_000304">SimpleKMeans</code><span class="text" id="span_001038" smilref="Machine_Learning00008.smil#span_001038"> class to build the cluster.</span></p>
                  <p id="c08-c08-para-0097" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0097">It's a small block of code. Weka handles things for you, so there's not a large amount of preparation to do.</p>
                  <p xml:space="preserve" id="p_000533"><code class="preserve-whitespace" xml:space="preserve" id="code_000305"><strong id="strong_000326" smilref="Machine_Learning00008.smil#strong_000326">public</strong><span class="text" id="span_001039" smilref="Machine_Learning00008.smil#span_001039"> WekaCluster(String filepath) {
        </span><strong id="strong_000327" smilref="Machine_Learning00008.smil#strong_000327">try</strong><span class="text" id="span_001040" smilref="Machine_Learning00008.smil#span_001040"> {
            Instances data = DataSource.</span><em id="em_000186" smilref="Machine_Learning00008.smil#em_000186">read</em><span class="text" id="span_001041" smilref="Machine_Learning00008.smil#span_001041">(filepath);
            </span><strong id="strong_000328" smilref="Machine_Learning00008.smil#strong_000328">int</strong><span class="text" id="span_001042" smilref="Machine_Learning00008.smil#span_001042"> clusters = calculateRuleOfThumb(data.numInstances());
            System.</span><em id="em_000187" smilref="Machine_Learning00008.smil#em_000187">out</em><span class="text" id="span_001043" smilref="Machine_Learning00008.smil#span_001043">.println("Rule of Thumb Clusters = " + clusters);
            SimpleKMeans kMeans = </span><strong id="strong_000329" smilref="Machine_Learning00008.smil#strong_000329">new SimpleKMeans();</strong>
            <strong id="strong_000330" smilref="Machine_Learning00008.smil#strong_000330">kMeans.setNumClusters(clu</strong><span class="text" id="span_001044" smilref="Machine_Learning00008.smil#span_001044">sters);
            kMeans.setSeed(42);
            kMeans.buildClusterer(data);
            showCentroids(kMeans, data);
            showInstanceInCluster(kMeans, data);
        } </span><strong id="strong_000331" smilref="Machine_Learning00008.smil#strong_000331">catch</strong><span class="text" id="span_001045" smilref="Machine_Learning00008.smil#span_001045"> (Exception e) {
            e.printStackTrace();
        }
    }</span></code></p>
                  <p id="c08-c08-para-0098" xml:space="preserve"><span class="text" id="span_001046" smilref="Machine_Learning00008.smil#span_001046">The data is read in using the </span><code xml:space="preserve" id="code_000306" smilref="Machine_Learning00008.smil#code_000306">DataSource.read()</code><span class="text" id="span_001047" smilref="Machine_Learning00008.smil#span_001047"> method. This takes the string path name (or an InputStream is preferred) and saves the data as instances.</span></p>
                  <p id="c08-c08-para-0099" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0099">Next, you calculate the number of clusters to define using the method you created earlier with the rule of thumb calculation.</p>
                  <p id="c08-c08-para-0100" xml:space="preserve"><span class="text" id="span_001048" smilref="Machine_Learning00008.smil#span_001048">The actual building of the cluster is handled in the next four lines. The </span><code xml:space="preserve" id="code_000307" smilref="Machine_Learning00008.smil#code_000307">SimpleKMeans</code><span class="text" id="span_001049" smilref="Machine_Learning00008.smil#span_001049"> class is the same as the one used in the workbench and command line. You set the number of clusters you want to define (</span><code xml:space="preserve" id="code_000308" smilref="Machine_Learning00008.smil#code_000308">setNumClusters()</code><span class="text" id="span_001050" smilref="Machine_Learning00008.smil#span_001050">) and a random number seed (</span><code xml:space="preserve" id="code_000309" smilref="Machine_Learning00008.smil#code_000309">with setSeed()</code><span class="text" id="span_001051" smilref="Machine_Learning00008.smil#span_001051">) and then build the cluster.</span></p>
                  <p id="c08-c08-para-0101" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0101">Finally, you call two methods: One shows the location of the centroids of each cluster, and the second shows in which clusters the instances are located.</p>
                </level5>
                <level5 id="level5_000007">
                  <h5 xml:space="preserve" id="h5_000007" smilref="Machine_Learning00008.smil#h5_000007">Printing the Centroids</h5>
                  <p xml:space="preserve" id="p_000534" smilref="Machine_Learning00008.smil#p_000534">Now that the model is built, you can start to show some results from it. First you print out the location of each cluster centroid.</p>
                  <p xml:space="preserve" id="p_000535"><code class="preserve-whitespace" xml:space="preserve" id="code_000310"><strong id="strong_000332" smilref="Machine_Learning00008.smil#strong_000332">public void</strong><span class="text" id="span_001052" smilref="Machine_Learning00008.smil#span_001052"> showCentroids(SimpleKMeans kMeans, Instances data) {
        Instances centroids = kMeans.getClusterCentroids();
        </span><strong id="strong_000333" smilref="Machine_Learning00008.smil#strong_000333">for</strong><span class="text" id="span_001053" smilref="Machine_Learning00008.smil#span_001053"> (</span><strong id="strong_000334" smilref="Machine_Learning00008.smil#strong_000334">int</strong><span class="text" id="span_001054" smilref="Machine_Learning00008.smil#span_001054"> i = 0; i &lt; centroids.numInstances(); i++) {
            System.</span><em id="em_000188" smilref="Machine_Learning00008.smil#em_000188">out</em><span class="text" id="span_001055" smilref="Machine_Learning00008.smil#span_001055">.println("Centroid: " + i + ": " + centroids.instance(i));
        }
    }</span></code></p>
                  <pagenum epub:type="pagebreak" id="p182" page="normal" smilref="Machine_Learning00008.smil#p182">182</pagenum>
                  <p id="c08-c08-para-0103" xml:space="preserve"><span class="text" id="span_001056" smilref="Machine_Learning00008.smil#span_001056">The </span><code xml:space="preserve" id="code_000311" smilref="Machine_Learning00008.smil#code_000311">getClusterCentroids()</code><span class="text" id="span_001057" smilref="Machine_Learning00008.smil#span_001057"> method returns a set of instances. It's a case of iterating through these and printing the result of each instance. As six clusters were created (via the rule of thumb method calculation), there should be six instances printed.</span></p>
                </level5>
              </level4>
              <level4 id="level4_000060">
                <h4 xml:space="preserve" id="h4_000060" smilref="Machine_Learning00008.smil#h4_000060">Printing the Cluster Information</h4>
                <p xml:space="preserve" id="p_000536"><span class="text" id="span_001058" smilref="Machine_Learning00008.smil#span_001058">To show which cluster the instance belongs to, the </span><code xml:space="preserve" id="code_000312" smilref="Machine_Learning00008.smil#code_000312">showInstanceInCluster()</code><span class="text" id="span_001059" smilref="Machine_Learning00008.smil#span_001059"> method takes the k-means model and the assigned instances. The code then iterates each of the instances and prints which it is assigned to based on the model.</span></p>
                <p xml:space="preserve" id="p_000537"><code class="preserve-whitespace" xml:space="preserve" id="code_000313"><strong id="strong_000335" smilref="Machine_Learning00008.smil#strong_000335">public void</strong><span class="text" id="span_001060" smilref="Machine_Learning00008.smil#span_001060"> showInstanceInCluster(SimpleKMeans kMeans, Instances data) {
        </span><strong id="strong_000336" smilref="Machine_Learning00008.smil#strong_000336">try</strong><span class="text" id="span_001061" smilref="Machine_Learning00008.smil#span_001061"> {
            </span><strong id="strong_000337" smilref="Machine_Learning00008.smil#strong_000337">for</strong><span class="text" id="span_001062" smilref="Machine_Learning00008.smil#span_001062"> (</span><strong id="strong_000338" smilref="Machine_Learning00008.smil#strong_000338">int</strong><span class="text" id="span_001063" smilref="Machine_Learning00008.smil#span_001063"> i = 0; i &lt; data.numInstances(); i++) {
                System.</span><em id="em_000189" smilref="Machine_Learning00008.smil#em_000189">out</em><span class="text" id="span_001064" smilref="Machine_Learning00008.smil#span_001064">.println("Instance " + i + " is in cluster "
                        + kMeans.clusterInstance(data.instance(i)));
            }
        } </span><strong id="strong_000339" smilref="Machine_Learning00008.smil#strong_000339">catch</strong><span class="text" id="span_001065" smilref="Machine_Learning00008.smil#span_001065"> (Exception e) {
            e.printStackTrace();
        }
    }</span></code></p>
              </level4>
              <level4 id="level4_000061">
                <h4 xml:space="preserve" id="h4_000061" smilref="Machine_Learning00008.smil#h4_000061">The Final Code Listing</h4>
                <p xml:space="preserve" id="p_000538" smilref="Machine_Learning00008.smil#p_000538">Here's the code assembled and ready to run:</p>
                <p xml:space="preserve" id="p_000539"><code class="preserve-whitespace" xml:space="preserve" id="code_000314"><strong id="strong_000340" smilref="Machine_Learning00008.smil#strong_000340">import</strong><span class="text" id="span_001066" smilref="Machine_Learning00008.smil#span_001066"> java.util.Random;
</span><strong id="strong_000341" smilref="Machine_Learning00008.smil#strong_000341">import</strong><span class="text" id="span_001067" smilref="Machine_Learning00008.smil#span_001067"> weka.clusterers.SimpleKMeans;
</span><strong id="strong_000342" smilref="Machine_Learning00008.smil#strong_000342">import</strong><span class="text" id="span_001068" smilref="Machine_Learning00008.smil#span_001068"> weka.core.Instance;
</span><strong id="strong_000343" smilref="Machine_Learning00008.smil#strong_000343">import</strong><span class="text" id="span_001069" smilref="Machine_Learning00008.smil#span_001069"> weka.core.Instances;
</span><strong id="strong_000344" smilref="Machine_Learning00008.smil#strong_000344">import</strong><span class="text" id="span_001070" smilref="Machine_Learning00008.smil#span_001070"> weka.core.converters.ConverterUtils.DataSource;
</span><strong id="strong_000345" smilref="Machine_Learning00008.smil#strong_000345">public class</strong><span class="text" id="span_001071" smilref="Machine_Learning00008.smil#span_001071"> WekaCluster {
    </span><strong id="strong_000346" smilref="Machine_Learning00008.smil#strong_000346">public</strong><span class="text" id="span_001072" smilref="Machine_Learning00008.smil#span_001072"> WekaCluster(String filepath) {
        </span><strong id="strong_000347" smilref="Machine_Learning00008.smil#strong_000347">try</strong><span class="text" id="span_001073" smilref="Machine_Learning00008.smil#span_001073"> {
            </span><pagenum epub:type="pagebreak" id="p183" page="normal" smilref="Machine_Learning00008.smil#p183">183</pagenum><span class="text" id="span_001074" smilref="Machine_Learning00008.smil#span_001074">Instances data = DataSource.</span><em id="em_000190" smilref="Machine_Learning00008.smil#em_000190">read</em><span class="text" id="span_001075" smilref="Machine_Learning00008.smil#span_001075">(filepath);
            </span><strong id="strong_000348" smilref="Machine_Learning00008.smil#strong_000348">int</strong><span class="text" id="span_001076" smilref="Machine_Learning00008.smil#span_001076"> clusters = calculateRuleOfThumb(data.numInstances());
            System.</span><em id="em_000191" smilref="Machine_Learning00008.smil#em_000191">out</em><span class="text" id="span_001077" smilref="Machine_Learning00008.smil#span_001077">.println("Rule of Thumb Clusters = " + clusters);
            SimpleKMeans kMeans = </span><strong id="strong_000349" smilref="Machine_Learning00008.smil#strong_000349">new</strong><span class="text" id="span_001078" smilref="Machine_Learning00008.smil#span_001078"> SimpleKMeans();
            kMeans.setNumClusters(clusters);
            kMeans.setSeed(42);
            kMeans.buildClusterer(data);
            showCentroids(kMeans, data);
            showInstanceInCluster(kMeans, data);
        } </span><strong id="strong_000350" smilref="Machine_Learning00008.smil#strong_000350">catch</strong><span class="text" id="span_001079" smilref="Machine_Learning00008.smil#span_001079"> (Exception e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000351" smilref="Machine_Learning00008.smil#strong_000351">public int</strong><span class="text" id="span_001080" smilref="Machine_Learning00008.smil#span_001080"> calculateRuleOfThumb(</span><strong id="strong_000352" smilref="Machine_Learning00008.smil#strong_000352">int</strong><span class="text" id="span_001081" smilref="Machine_Learning00008.smil#span_001081"> rows) {
        </span><strong id="strong_000353" smilref="Machine_Learning00008.smil#strong_000353">return</strong><span class="text" id="span_001082" smilref="Machine_Learning00008.smil#span_001082"> (</span><strong id="strong_000354" smilref="Machine_Learning00008.smil#strong_000354">int</strong><span class="text" id="span_001083" smilref="Machine_Learning00008.smil#span_001083">)Math.</span><em id="em_000192" smilref="Machine_Learning00008.smil#em_000192">sqrt</em><span class="text" id="span_001084" smilref="Machine_Learning00008.smil#span_001084">(rows/2);
    }
    </span><strong id="strong_000355" smilref="Machine_Learning00008.smil#strong_000355">public void</strong><span class="text" id="span_001085" smilref="Machine_Learning00008.smil#span_001085"> showCentroids(SimpleKMeans kMeans, Instances data) {
        Instances centroids = kMeans.getClusterCentroids();
        </span><strong id="strong_000356" smilref="Machine_Learning00008.smil#strong_000356">for</strong><span class="text" id="span_001086" smilref="Machine_Learning00008.smil#span_001086"> (</span><strong id="strong_000357" smilref="Machine_Learning00008.smil#strong_000357">int</strong><span class="text" id="span_001087" smilref="Machine_Learning00008.smil#span_001087"> i = 0; i &lt; centroids.numInstances(); i++) {
            System.</span><em id="em_000193" smilref="Machine_Learning00008.smil#em_000193">out</em><span class="text" id="span_001088" smilref="Machine_Learning00008.smil#span_001088">.println("Centroid: " + i + ": " + centroids.instance(i));
        }
    }
    </span><strong id="strong_000358" smilref="Machine_Learning00008.smil#strong_000358">public void</strong><span class="text" id="span_001089" smilref="Machine_Learning00008.smil#span_001089"> showInstanceInCluster(SimpleKMeans kMeans, Instances data) {
        </span><strong id="strong_000359" smilref="Machine_Learning00008.smil#strong_000359">try</strong><span class="text" id="span_001090" smilref="Machine_Learning00008.smil#span_001090"> {
            </span><strong id="strong_000360" smilref="Machine_Learning00008.smil#strong_000360">for</strong><span class="text" id="span_001091" smilref="Machine_Learning00008.smil#span_001091"> (</span><strong id="strong_000361" smilref="Machine_Learning00008.smil#strong_000361">int</strong><span class="text" id="span_001092" smilref="Machine_Learning00008.smil#span_001092"> i = 0; i &lt; data.numInstances(); i++) {
                System.</span><em id="em_000194" smilref="Machine_Learning00008.smil#em_000194">out</em><span class="text" id="span_001093" smilref="Machine_Learning00008.smil#span_001093">.println("Instance " + i + " is in cluster "
                        + kMeans.clusterInstance(data.instance(i)));
            }
        } </span><strong id="strong_000362" smilref="Machine_Learning00008.smil#strong_000362">catch</strong><span class="text" id="span_001094" smilref="Machine_Learning00008.smil#span_001094"> (Exception e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000363" smilref="Machine_Learning00008.smil#strong_000363">public static void</strong><span class="text" id="span_001095" smilref="Machine_Learning00008.smil#span_001095"> main(String[] args) {
        // Pass the arff location and the number of clusters we want
        WekaCluster wc = </span><strong id="strong_000364" smilref="Machine_Learning00008.smil#strong_000364">new</strong><span class="text" id="span_001096" smilref="Machine_Learning00008.smil#span_001096"> WekaCluster("/Users/Jason/kmeandata.arff");
    }
}</span></code></p>
              </level4>
              <level4 id="level4_000062">
                <h4 xml:space="preserve" id="h4_000062" smilref="Machine_Learning00008.smil#h4_000062">Running the Program</h4>
                <pagenum epub:type="pagebreak" id="p184" page="normal" smilref="Machine_Learning00008.smil#p184">184</pagenum>
                <p xml:space="preserve" id="p_000540" smilref="Machine_Learning00008.smil#p_000540">With the hard work done, you can run the program and inspect the results. From Eclipse select Run → Run and the program will start. The output in the console window should look something like this:</p>
                <p xml:space="preserve" id="p_000541"><code class="preserve-whitespace" xml:space="preserve" id="code_000315" smilref="Machine_Learning00008.smil#code_000315">
Rule of Thumb Clusters = 6
Centroid: 0: 11.8,65.9
Centroid: 1: 105.083333,118.333333
Centroid: 2: 68.933333,19.4
Centroid: 3: 81.6,106.6
Centroid: 4: 28.5,64
Centroid: 5: 43.913043,146.043478
Instance 0 is in cluster 0
Instance 1 is in cluster 0
Instance 2 is in cluster 0
Instance 3 is in cluster 0
Instance 4 is in cluster 0
Instance 5 is in cluster 0
Instance 6 is in cluster 0
Instance 7 is in cluster 0
Instance 8 is in cluster 0
Instance 9 is in cluster 0
Instance 10 is in cluster 4
….
</code></p>
                <p id="c08-c08-para-0107" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0107">As you can see, the rule of thumb calculation recommended creating six clusters. After executing the k-means clustering method, you displayed the centroid of each cluster in order to “eyeball” the distances of any data point in the cluster from its cluster's center; finally, you displayed cluster membership for each element of our original object data.</p>
              </level4>
              <level4 id="level4_000063">
                <h4 xml:space="preserve" id="h4_000063" smilref="Machine_Learning00008.smil#h4_000063">Making Predictions</h4>
                <p xml:space="preserve" id="p_000542" smilref="Machine_Learning00008.smil#p_000542">The program so far covers the creation of clusters and reporting the results of the instances. What happens when new data comes in? At present, you're not able to predict anything. It would be nice to have a method you can access that takes new values and predicts in which cluster the result would be grouped.</p>
                <p id="c08-c08-para-0109" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0109">Instances can be created within code and then run against the clustering model to see where the new values would lie. You need to create another method to return the cluster prediction.</p>
                <p xml:space="preserve" id="p_000543"><code class="preserve-whitespace" xml:space="preserve" id="code_000316"><strong id="strong_000365" smilref="Machine_Learning00008.smil#strong_000365">public int</strong><span class="text" id="span_001097" smilref="Machine_Learning00008.smil#span_001097"> predictCluster(SimpleKMeans kMeans, </span><strong id="strong_000366" smilref="Machine_Learning00008.smil#strong_000366">double</strong><span class="text" id="span_001098" smilref="Machine_Learning00008.smil#span_001098"> x, </span><strong id="strong_000367" smilref="Machine_Learning00008.smil#strong_000367">double</strong><span class="text" id="span_001099" smilref="Machine_Learning00008.smil#span_001099"> y) {
        </span><strong id="strong_000368" smilref="Machine_Learning00008.smil#strong_000368">int</strong><span class="text" id="span_001100" smilref="Machine_Learning00008.smil#span_001100"> clusterNumber = -1;
        </span><strong id="strong_000369" smilref="Machine_Learning00008.smil#strong_000369">try</strong><span class="text" id="span_001101" smilref="Machine_Learning00008.smil#span_001101"> {
            </span><strong id="strong_000370" smilref="Machine_Learning00008.smil#strong_000370">double</strong><span class="text" id="span_001102" smilref="Machine_Learning00008.smil#span_001102">[] newdata = </span><strong id="strong_000371" smilref="Machine_Learning00008.smil#strong_000371">new double</strong><span class="text" id="span_001103" smilref="Machine_Learning00008.smil#span_001103">[] { x, y };
            Instance testInstance = </span><strong id="strong_000372" smilref="Machine_Learning00008.smil#strong_000372">new</strong><span class="text" id="span_001104" smilref="Machine_Learning00008.smil#span_001104"> Instance(1.0, newdata);
            clusterNumber = kMeans.clusterInstance(testInstance);
        } </span><strong id="strong_000373" smilref="Machine_Learning00008.smil#strong_000373">catch</strong><span class="text" id="span_001105" smilref="Machine_Learning00008.smil#span_001105"> (Exception e) {
            e.printStackTrace();
        }
        </span><strong id="strong_000374" smilref="Machine_Learning00008.smil#strong_000374">return</strong><span class="text" id="span_001106" smilref="Machine_Learning00008.smil#span_001106"> clusterNumber;
    }</span></code></p>
                <pagenum epub:type="pagebreak" id="p185" page="normal" smilref="Machine_Learning00008.smil#p185">185</pagenum>
                <p id="c08-c08-para-0110" xml:space="preserve"><span class="text" id="span_001107" smilref="Machine_Learning00008.smil#span_001107">You're passing the model and the values of the </span><code xml:space="preserve" id="code_000317" smilref="Machine_Learning00008.smil#code_000317">x</code><span class="text" id="span_001108" smilref="Machine_Learning00008.smil#span_001108"> and </span><code xml:space="preserve" id="code_000318" smilref="Machine_Learning00008.smil#code_000318">y</code><span class="text" id="span_001109" smilref="Machine_Learning00008.smil#span_001109"> variables (in the same way the original data was in two attributes). A double array is created and the two values are stored.</span></p>
                <p id="c08-c08-para-0111" xml:space="preserve"><span class="text" id="span_001110" smilref="Machine_Learning00008.smil#span_001110">The </span><code xml:space="preserve" id="code_000319" smilref="Machine_Learning00008.smil#code_000319">Instance</code><span class="text" id="span_001111" smilref="Machine_Learning00008.smil#span_001111"> class is created. The first value is the weight that is to be assigned to the instance. This is a value between 0 and 1. The second value is the double array that you've just created with the x and y values.</span></p>
                <p id="c08-c08-para-0112" xml:space="preserve"><span class="text" id="span_001112" smilref="Machine_Learning00008.smil#span_001112">In the same way that you showed the cluster by using the </span><code xml:space="preserve" id="code_000320" smilref="Machine_Learning00008.smil#code_000320">clusterInstance()</code><span class="text" id="span_001113" smilref="Machine_Learning00008.smil#span_001113"> method, you run the new instance and get the cluster number. This value is then returned back to the calling method.</span></p>
                <p id="c08-c08-para-0113" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0113">To test this, I'm going to create another method, which will iterate 100 times and generate random values. Obviously, in your code you'll be calling the predictor as required.</p>
                <p xml:space="preserve" id="p_000544"><code class="preserve-whitespace" xml:space="preserve" id="code_000321"><strong id="strong_000375" smilref="Machine_Learning00008.smil#strong_000375">public void</strong><span class="text" id="span_001114" smilref="Machine_Learning00008.smil#span_001114"> testRandomInstances(SimpleKMeans kMeans) {
        Random rand = </span><strong id="strong_000376" smilref="Machine_Learning00008.smil#strong_000376">new</strong><span class="text" id="span_001115" smilref="Machine_Learning00008.smil#span_001115"> Random();
        </span><strong id="strong_000377" smilref="Machine_Learning00008.smil#strong_000377">for</strong><span class="text" id="span_001116" smilref="Machine_Learning00008.smil#span_001116"> (</span><strong id="strong_000378" smilref="Machine_Learning00008.smil#strong_000378">int</strong><span class="text" id="span_001117" smilref="Machine_Learning00008.smil#span_001117"> i = 0; i &lt; 100; i++) {
            </span><strong id="strong_000379" smilref="Machine_Learning00008.smil#strong_000379">double</strong><span class="text" id="span_001118" smilref="Machine_Learning00008.smil#span_001118"> x = rand.nextInt(200);
            </span><strong id="strong_000380" smilref="Machine_Learning00008.smil#strong_000380">double</strong><span class="text" id="span_001119" smilref="Machine_Learning00008.smil#span_001119"> y = rand.nextInt(200);
            System.</span><em id="em_000195" smilref="Machine_Learning00008.smil#em_000195">out</em><span class="text" id="span_001120" smilref="Machine_Learning00008.smil#span_001120">.println(x + "/" + y + " test in cluster " + predictCluster(kMeans, x, y));
        }
    }</span></code></p>
                <p id="c08-c08-para-0114" xml:space="preserve"><span class="text" id="span_001121" smilref="Machine_Learning00008.smil#span_001121">The method is generating random numbers for the x and y values and passing them to the prediction method. Add this to the </span><code xml:space="preserve" id="code_000322" smilref="Machine_Learning00008.smil#code_000322">main</code><span class="text" id="span_001122" smilref="Machine_Learning00008.smil#span_001122"> constructor after the centroids and clusters are first printed by inserting the line</span></p>
                <p xml:space="preserve" id="p_000545"><code class="preserve-whitespace" xml:space="preserve" id="code_000323" smilref="Machine_Learning00008.smil#code_000323">testRandomInstances(kMeans);</code></p>
                <p xml:space="preserve" id="p_000546"><span class="text" id="span_001123" smilref="Machine_Learning00008.smil#span_001123">before the </span><code xml:space="preserve" id="code_000324" smilref="Machine_Learning00008.smil#code_000324">catch</code><span class="text" id="span_001124" smilref="Machine_Learning00008.smil#span_001124"> block is reached in the </span><code xml:space="preserve" id="code_000325" smilref="Machine_Learning00008.smil#code_000325">WekaCluster</code><span class="text" id="span_001125" smilref="Machine_Learning00008.smil#span_001125"> constructor. When you rerun the program, you see the random tests:</span></p>
                <p xml:space="preserve" id="p_000547"><code class="preserve-whitespace" xml:space="preserve" id="code_000326" smilref="Machine_Learning00008.smil#code_000326">146.0/167.0 test in cluster 1
109.0/67.0 test in cluster 1
95.0/80.0 test in cluster 3
29.0/160.0 test in cluster 5
165.0/193.0 test in cluster 1
33.0/167.0 test in cluster 5
108.0/73.0 test in cluster 1
63.0/63.0 test in cluster 2
186.0/176.0 test in cluster 1
67.0/47.0 test in cluster 2
43.0/5.0 test in cluster 2
85.0/9.0 test in cluster 2
152.0/60.0 test in cluster 1
</code></p>
              </level4>
              <level4 id="level4_000064">
                <h4 xml:space="preserve" id="h4_000064" smilref="Machine_Learning00008.smil#h4_000064">Further Development</h4>
                <pagenum epub:type="pagebreak" id="p186" page="normal" smilref="Machine_Learning00008.smil#p186">186</pagenum>
                <p xml:space="preserve" id="p_000548" smilref="Machine_Learning00008.smil#p_000548">You will discover putting together a basic cluster algorithm with SimpleKMeans is a fairly straightforward matter. I've covered the main aspects of coding a solution. There are obvious developments from this point, such as connecting to a database table with Java Database Connectivity (JDBC) and extracting the data into instances.</p>
                <p id="c08-c08-para-0116" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0116">One thing to remember with Weka is that when huge volumes of data are applied, the memory performance can suffer. I suggest that most needs of enterprise are still covered using this method and can be developed with scale in mind. In particular, sampling the data to fit in Weka memory will give very good results.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000069">
            <h2 id="c08-c08_level1_5" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08_level1_5">Summary</h2>
            <p xml:space="preserve" id="p_000549" smilref="Machine_Learning00008.smil#p_000549">Clustering will be one of those machine learning techniques that you'll pull out again and again. To that end, it does need some thought before you go building clusters and seeing what happens.</p>
            <p id="c08-c08-para-0118" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0118">You've created simple k-means clusters in Weka via the workbench, the command line, and within code. Obviously, there are plenty of options from this point on, but with what you've read in this chapter, you'll be able to get a system up and working quickly.</p>
            <p id="c08-c08-para-0119" xml:space="preserve" smilref="Machine_Learning00008.smil#c08-c08-para-0119">Chapters 3 through 8 have concentrated on specific types of machine learning, their applications, and some examples in various forms. The following chapters discuss some tools that will become useful to you in data collection and processing. I could even go as far as to say you're about to unlock the door to Big Data.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c09">
        <section epub:type="chapter" id="section_000010">
          <header id="header_000009">
            <h1 id="c09-c9" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c9">Chapter 9 Machine Learning in Real Time with Spring XD</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p187" page="normal" smilref="Machine_Learning00008.smil#p187">187</pagenum>
          <p xml:space="preserve" id="p_000550" smilref="Machine_Learning00008.smil#p_000550">Consider the amount of data that is being generated as you read this paragraph. Much of that data will be produced, stored, and processed to gain insight and value—for example, a temperature monitor within the house that gives constant updates or a feed from various social media platforms. There's an awful lot of potential in the data that comes out in real time. Being able to capture, process, store, and learn from it can be difficult; but with emerging tools it's becoming easier to put solutions together.</p>
          <p id="c09-c09-para-0002" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0002">This chapter covers the use of Spring XD for consuming real-time data using the Twitter streaming application programming interface (API). The examples show you how to write custom processors in Spring XD to perform real-time analysis on the incoming Twitter data (tweets).</p>
          <level2 id="level2_000070">
            <h2 id="c09-c09_level1_1" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09_level1_1">Capturing the Firehose of Data</h2>
            <p xml:space="preserve" id="p_000551" smilref="Machine_Learning00008.smil#p_000551">Companies that provide continuous streams of data often refer to it as “the firehose”; the data just flows out, and it's up to recipients to capture the data they want and process it as required. Often, some form of agreement with the data provider must be signed before the data is made available for consumption.</p>
            <level3 id="level3_000141">
              <h3 xml:space="preserve" id="h3_000141" smilref="Machine_Learning00008.smil#h3_000141">Considerations of Using Data in Real Time</h3>
              <pagenum epub:type="pagebreak" id="p188" page="normal" smilref="Machine_Learning00008.smil#p188">188</pagenum>
              <p xml:space="preserve" id="p_000552" smilref="Machine_Learning00008.smil#p_000552">Before dashing off to your desk and coding up a real-time application that scans the entire Twitter firehose, it's worth considering if real time is actually the way to go. Just because real-time processing is available doesn't mean you should always use it.</p>
              <p id="c09-c09-para-0005" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0005">Financial services companies use real-time processing for applications that help subscribers decide whether to perform a trade on a stock; the decision to buy or to sell must be computed in milliseconds. In this context, data that's considered “old”—anything longer than 10 or 20 seconds—is not worth processing when you think about how many transactions might have occurred from other traders. The price could have changed many times within that duration.</p>
              <p id="c09-c09-para-0006" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0006">On the other hand, an e-commerce site using machine learning to generate recommendations for customers could batch up several transactions and process them periodically every 3, 6, 12, or even 24 hours. Batching up larger volumes of transactions has certain advantages. Chapter 10 covers batch processing in more detail.</p>
              <p id="c09-c09-para-0007" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0007">Newer processing systems make use of in-memory processing, which requires no slow, traditional secondary data store and obviates the traditional extract, transform, and load (ETL) as found in traditional SQL-based business intelligence systems.</p>
              <p id="c09-c09-para-0008" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0008">Another consideration is storage volume: Is it necessary to store all the data? Will storing the processed data suffice for your purpose? Or will you need to store the origin data for further processing later? It is true that the cost of storage is decreasing (Moore's Law), but storage still has major cost implications that you must consider. How will the data be stored? Where will it be stored? If the data will be stored on the cloud (on Amazon S3 buckets, for example), then are there privacy concerns that you must address? Have you considered the data safety (backups and restore service levels) and data security (privacy, secrecy, and access control) for the data?</p>
              <p id="c09-c09-para-0009" xml:space="preserve"><span class="text" id="span_001126" smilref="Machine_Learning00008.smil#span_001126">With the increasing speed of computing, the plummeting cost of storage, and the many high-performance, low-cost database systems available, there is nothing to stop you from using two or three data stores for future processing. You can consider a traditional relational database such as MySQL, a column store such as HBase, and a graph database such as Neo4J or Apache Giraffe. Consider your data lifecycle, use cases, and the strengths/purpose of each SQL and NoSQL system within your reach (</span><code xml:space="preserve" id="code_000327"><a href="http://martinfowler.com/books/nosql.html" external="true" id="a_000294" smilref="Machine_Learning00008.smil#a_000294">http://martinfowler.com/books/nosql.html</a></code><span class="text" id="span_001127" smilref="Machine_Learning00008.smil#span_001127">).</span></p>
            </level3>
            <level3 id="level3_000142">
              <h3 xml:space="preserve" id="h3_000142" smilref="Machine_Learning00008.smil#h3_000142">Potential Uses for a Real-Time System</h3>
              <p xml:space="preserve" id="p_000553"><span class="text" id="span_001128" smilref="Machine_Learning00008.smil#span_001128">The applications of a real-time data system are broad and far-reaching. With the expanding volume of valuable social media and mobile data, it's becoming increasingly important for real-time systems to enable instant connectivity </span><pagenum epub:type="pagebreak" id="p189" page="normal" smilref="Machine_Learning00008.smil#p189">189</pagenum><span class="text" id="span_001129" smilref="Machine_Learning00008.smil#span_001129">and recommendations for people wherever they are. Location-based targeted advertising is a good candidate for real-time analysis. Such a system must look for offers based on the location of the customer's device in addition to the real-time context of the customer's situation (for example, weather, traffic, time of day, day of year, and local, breaking news).</span></p>
              <p id="c09-c09-para-0011" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0011">Financial trading has previously been mentioned as a candidate for real-time processing. Companies are investing heavily into real-time algorithms that can trade at extremely high speeds (microseconds) using algorithmic trading to compute and perform many thousands of trades per second. There are a number of algorithms that can be employed for these calculations. Some systems take into account news headlines and Twitter feeds, and then they trade on the sentiment of the story. Such systems have varying degrees of success. Payments and fraud detection algorithms can analyze transactions in real time and flag problematic transactions as they happen. As processing power increases, companies can embrace more variables such as previous customer transactions, location, and purchase behavior between clicks in soft real time.</p>
              <p id="c09-c09-para-0012" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0012">In cases where an interactive response to an end user or system is required, a real-time system is worth considering. In such cases, keeping data exclusively in memory speeds things up considerably. Secondary storage should be used only to speed recovery, restarting the memory system, and if more in depth training is required over larger data sets.</p>
            </level3>
          </level2>
          <level2 id="level2_000071">
            <h2 id="c09-c09_level1_2" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09_level1_2">Using Spring XD</h2>
            <p xml:space="preserve" id="p_000554" smilref="Machine_Learning00008.smil#p_000554">This chapter uses the Spring XD framework that is designed for real-time processing. The goals of Spring XD are to simplify data ingestion, processing, and data export.</p>
            <sidebar render="required" id="sidebar_000011">
              <div class="top hr" id="div_000011" />
              <level2 class="feature2" id="level2_000072">
                <h2 xml:space="preserve" id="h2_000015" smilref="Machine_Learning00008.smil#h2_000015">Note</h2>
                <p xml:space="preserve" id="p_000555" smilref="Machine_Learning00008.smil#p_000555">Data ingestion refers to multiple sources of data, so there's no issue in consuming log data, Twitter streams, and RSS feeds at the same time.</p>
              </level2>
            </sidebar>
            <p id="c09-c09-para-0015" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0015">Spring XD runs either on a single server or on a cluster of machines in distributed mode. The examples in this chapter use a single server. The Spring XD software is released under the Apache 2 License and is completely open source, so you are free to download and use it with no restrictions. Spring has done a very good job of including the majority of common use cases in the base release; it's a good starting point to show how real-time analytics can be built quickly and with minimum effort.</p>
            <p id="c09-c09-para-0016" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0016">If you are aware how the UNIX pipe commands work, then you'll have an easy time understanding how Spring XD functions. If you're not familiar with UNIX pipe commands then please read on; I explain how the basic command pipeline and data streaming in UNIX and Spring XD work.</p>
            <level3 id="level3_000143">
              <h3 xml:space="preserve" id="h3_000143" smilref="Machine_Learning00008.smil#h3_000143">Spring XD Streams</h3>
              <pagenum epub:type="pagebreak" id="p190" page="normal" smilref="Machine_Learning00008.smil#p190">190</pagenum>
              <p xml:space="preserve" id="p_000556"><span class="text" id="span_001130" smilref="Machine_Learning00008.smil#span_001130">The Spring XD system is analogous to UNIX command pipelines, where an infinite stream of text is filtered through commands and manipulated in some way before passing the stream on to the next command. For example, in UNIX if I want to compute the frequency of letters, words, and lines from the contents of one or more text files, I can run the “concatenate and print” (</span><code xml:space="preserve" id="code_000328" smilref="Machine_Learning00008.smil#code_000328">cat</code><span class="text" id="span_001131" smilref="Machine_Learning00008.smil#span_001131">) command on the files and pipe the stream through the word count (</span><code xml:space="preserve" id="code_000329" smilref="Machine_Learning00008.smil#code_000329">wc</code><span class="text" id="span_001132" smilref="Machine_Learning00008.smil#span_001132">) command:</span></p>
              <p xml:space="preserve" id="p_000557"><code class="preserve-whitespace" xml:space="preserve" id="code_000330" smilref="Machine_Learning00008.smil#code_000330">cat *.txt | wc</code></p>
              <p id="c09-c09-para-0018" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0018">Taking this concept a step further, I might want to alter the output of the resulting word with a label:</p>
              <p xml:space="preserve" id="p_000558"><code class="preserve-whitespace" xml:space="preserve" id="code_000331" smilref="Machine_Learning00008.smil#code_000331">cat *.txt | sed 's/^/(lines, words, characters) =/'</code></p>
              <p id="c09-c09-para-0019" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0019">Spring XD streams work in a similar way to UNIX command pipelines. The server reads input data, processes it in stages, and the resulting output is sent to a specific destination. The processing stages are optional, but they become very useful in processing data for machine learning tasks. A single stream is not limited to one processing step; processing can be daisy chained along the stream.</p>
              <p id="c09-c09-para-0020" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0020">Later in the chapter, there is a full tutorial on how to set up these streams and how to process them. First you should understand the core components in the pipeline stream and how Spring XD uses them.</p>
            </level3>
            <level3 id="level3_000144">
              <h3 xml:space="preserve" id="h3_000144" smilref="Machine_Learning00008.smil#h3_000144">Input Sources, Sinks, and Processors</h3>
              <p xml:space="preserve" id="p_000559" smilref="Machine_Learning00008.smil#p_000559">Spring XD streams have three main components: an input source, an optional processor, and an output called a sink.</p>
              <level4 id="level4_000065">
                <h4 xml:space="preserve" id="h4_000065" smilref="Machine_Learning00008.smil#h4_000065">Input Sources</h4>
                <p xml:space="preserve" id="p_000560"><span class="text" id="span_001133" smilref="Machine_Learning00008.smil#span_001133">Using the Spring Integration Adaptors, the XD system provides a number of ready-to-go </span><em id="em_000196" smilref="Machine_Learning00008.smil#em_000196">input sources</em><span class="text" id="span_001134" smilref="Machine_Learning00008.smil#span_001134">. These cover a range of uses from Internet-based protocols, internal log output tools, and file-processing commands. </span><a id="c09-c09-tbl-anc-0001" href="#c09-c09-tbl-0001" external="false" smilref="Machine_Learning00008.smil#c09-c09-tbl-anc-0001">Table 9-1</a><span class="text" id="span_001135" smilref="Machine_Learning00008.smil#span_001135"> summarizes different types of input sources.</span></p>
                <figure id="figure_000081">
                  <figcaption id="figcaption_000067">
                    <p xml:space="preserve" id="p_000561"><span class="figureLabel" id="span_001136"><a id="c09-c09-tbl-0001" href="#c09-c09-tbl-anc-0001" external="false"><strong id="strong_000381" smilref="Machine_Learning00008.smil#strong_000381">Table 9-1</strong></a></span><span class="text" id="span_001137" smilref="Machine_Learning00008.smil#span_001137"> Different Types of Input Sources for Spring XD</span></p>
                  </figcaption>
                  <table border="1" id="table_000019">
                    <tr id="tr_000092">
                      <td class="left" rowspan="1" colspan="1" id="td_000307" smilref="Machine_Learning00008.smil#td_000307">Input Name</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000308" smilref="Machine_Learning00008.smil#td_000308">Description</td>
                    </tr>
                    <tr id="tr_000093">
                      <td class="left" rowspan="1" colspan="1" id="td_000309" smilref="Machine_Learning00008.smil#td_000309">HTTP</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000310" smilref="Machine_Learning00008.smil#td_000310">Reads the input data from the HTTP request—for example, a web page, RSS feed, or REST API call.</td>
                    </tr>
                    <tr id="tr_000094">
                      <td class="left" rowspan="1" colspan="1" id="td_000311" smilref="Machine_Learning00008.smil#td_000311">TCP</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000312" smilref="Machine_Learning00008.smil#td_000312">Handles the output of a raw TCP socket.</td>
                    </tr>
                    <tr id="tr_000095">
                      <td class="left" rowspan="1" colspan="1" id="td_000313" smilref="Machine_Learning00008.smil#td_000313">Mail</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000314" smilref="Machine_Learning00008.smil#td_000314">Reads incoming mail from an IMAP server.</td>
                    </tr>
                    <tr id="tr_000096">
                      <td class="left" rowspan="1" colspan="1" id="td_000315" smilref="Machine_Learning00008.smil#td_000315">JMS</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000316" smilref="Machine_Learning00008.smil#td_000316">Receives incoming messages from a Java Message Service.</td>
                    </tr>
                    <tr id="tr_000097">
                      <td class="left" rowspan="1" colspan="1" id="td_000317" smilref="Machine_Learning00008.smil#td_000317">RabbitMQ</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000318" smilref="Machine_Learning00008.smil#td_000318">Subscribes to and receives incoming messages from a RabbitMQ server.</td>
                    </tr>
                    <tr id="tr_000098">
                      <td class="left" rowspan="1" colspan="1" id="td_000319" smilref="Machine_Learning00008.smil#td_000319">Twitter Stream</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000320" smilref="Machine_Learning00008.smil#td_000320">Uses the Twitter streaming API and reads in the JSON payload of each tweet.</td>
                    </tr>
                    <tr id="tr_000099">
                      <td class="left" rowspan="1" colspan="1" id="td_000321" smilref="Machine_Learning00008.smil#td_000321">Twitter Search</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000322" smilref="Machine_Learning00008.smil#td_000322">Uses the Twitter Search API and reads in the JSON payload of each tweet.</td>
                    </tr>
                    <tr id="tr_000100">
                      <td class="left" rowspan="1" colspan="1" id="td_000323" smilref="Machine_Learning00008.smil#td_000323">File</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000324" smilref="Machine_Learning00008.smil#td_000324">Reads a stream from a file.</td>
                    </tr>
                    <tr id="tr_000101">
                      <td class="left" rowspan="1" colspan="1" id="td_000325" smilref="Machine_Learning00008.smil#td_000325">Tail</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000326" smilref="Machine_Learning00008.smil#td_000326">Reads the tailed output stream from a given file.</td>
                    </tr>
                    <tr id="tr_000102">
                      <td class="left" rowspan="1" colspan="1" id="td_000327" smilref="Machine_Learning00008.smil#td_000327">MQTT</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000328" smilref="Machine_Learning00008.smil#td_000328">Connects to an MQTT (Message Queue Telemetry Transport) server; subscribes to and receives telemetry messages.</td>
                    </tr>
                    <tr id="tr_000103">
                      <td class="left" rowspan="1" colspan="1" id="td_000329" smilref="Machine_Learning00008.smil#td_000329">Time</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000330" smilref="Machine_Learning00008.smil#td_000330">Emits a periodic “heartbeat” time stamp string of the current time as perceived by the system on which Spring XD is running, with a defined duration between heartbeat messages.</td>
                    </tr>
                    <tr id="tr_000104">
                      <td class="left" rowspan="1" colspan="1" id="td_000331" smilref="Machine_Learning00008.smil#td_000331">Gemfire</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000332" smilref="Machine_Learning00008.smil#td_000332">Listens to either region events or continuous queries from a Gemfire server.</td>
                    </tr>
                  </table>
                </figure>
                <pagenum epub:type="pagebreak" id="p191" page="normal" smilref="Machine_Learning00008.smil#p191">191</pagenum>
                <p id="c09-c09-para-0023" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0023">Each of the input sources comes with an array of configuration items that might be required before use in each source's stream definition. Some of these input sources and how to set their configurations is covered later in the chapter.</p>
              </level4>
              <level4 id="level4_000066">
                <h4 xml:space="preserve" id="h4_000066" smilref="Machine_Learning00008.smil#h4_000066">Sinks</h4>
                <p xml:space="preserve" id="p_000562"><span class="text" id="span_001138" smilref="Machine_Learning00008.smil#span_001138">To be useful, a system must produce an output, or </span><em id="em_000197" smilref="Machine_Learning00008.smil#em_000197">sink</em><span class="text" id="span_001139" smilref="Machine_Learning00008.smil#span_001139">, of some form. The most common output sinks are log files or a database table. Although Spring XD supports these log files and database tables, there are other options available. </span><a id="c09-c09-tbl-anc-0002" href="#c09-c09-tbl-0002" external="false" smilref="Machine_Learning00008.smil#c09-c09-tbl-anc-0002">Table 9-2</a><span class="text" id="span_001140" smilref="Machine_Learning00008.smil#span_001140"> lists output sinks.</span></p>
                <figure id="figure_000082">
                  <figcaption id="figcaption_000068">
                    <p xml:space="preserve" id="p_000563"><span class="figureLabel" id="span_001141"><a id="c09-c09-tbl-0002" href="#c09-c09-tbl-anc-0002" external="false"><strong id="strong_000382" smilref="Machine_Learning00008.smil#strong_000382">Table 9-2</strong></a></span><span class="text" id="span_001142" smilref="Machine_Learning00008.smil#span_001142"> Output Sinks in Spring XD</span></p>
                  </figcaption>
                  <table border="1" id="table_000020">
                    <tr id="tr_000105">
                      <td class="left" rowspan="1" colspan="1" id="td_000333" smilref="Machine_Learning00008.smil#td_000333">Output Name</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000334" smilref="Machine_Learning00008.smil#td_000334">Description</td>
                    </tr>
                    <tr id="tr_000106">
                      <td class="left" rowspan="1" colspan="1" id="td_000335" smilref="Machine_Learning00008.smil#td_000335">File</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000336" smilref="Machine_Learning00008.smil#td_000336">Output is appended to a text file on a file system.</td>
                    </tr>
                    <tr id="tr_000107">
                      <td class="left" rowspan="1" colspan="1" id="td_000337" smilref="Machine_Learning00008.smil#td_000337">Log</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000338" smilref="Machine_Learning00008.smil#td_000338">Using the internal logging function, output messages are written with INFO/WARN/ERROR as Log4J style, with rotation and time stamps.</td>
                    </tr>
                    <tr id="tr_000108">
                      <td class="left" rowspan="1" colspan="1" id="td_000339" smilref="Machine_Learning00008.smil#td_000339">JDBC</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000340" smilref="Machine_Learning00008.smil#td_000340">Saves output data to a relational database. Any database with a JDBC driver can be used. Default database is in memory HSQL.</td>
                    </tr>
                    <tr id="tr_000109">
                      <td class="left" rowspan="1" colspan="1" id="td_000341" smilref="Machine_Learning00008.smil#td_000341">Mail</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000342" smilref="Machine_Learning00008.smil#td_000342">Routes output to an SMTP mail server.</td>
                    </tr>
                    <tr id="tr_000110">
                      <td class="left" rowspan="1" colspan="1" id="td_000343" smilref="Machine_Learning00008.smil#td_000343">TCP</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000344">
                        <span class="text" id="span_001143" smilref="Machine_Learning00008.smil#span_001143">Output is routed to a TCP socket—for example, output could be routed to the</span>
                        <code xml:space="preserve" id="code_000332" smilref="Machine_Learning00008.smil#code_000332">netcat</code>
                        <span class="text" id="span_001144" smilref="Machine_Learning00008.smil#span_001144">UNIX command.</span>
                      </td>
                    </tr>
                    <tr id="tr_000111">
                      <td class="left" rowspan="1" colspan="1" id="td_000345" smilref="Machine_Learning00008.smil#td_000345">HDFS</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000346" smilref="Machine_Learning00008.smil#td_000346">Stores output data to the Hadoop Distributed File System. This is covered in more detail in Chapter 10.</td>
                    </tr>
                    <tr id="tr_000112">
                      <td class="left" rowspan="1" colspan="1" id="td_000347" smilref="Machine_Learning00008.smil#td_000347">RabbitMQ</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000348" smilref="Machine_Learning00008.smil#td_000348">Outgoing message is sent to a RabbitMQ exchange.</td>
                    </tr>
                    <tr id="tr_000113">
                      <td class="left" rowspan="1" colspan="1" id="td_000349" smilref="Machine_Learning00008.smil#td_000349">Splunk Server</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000350" smilref="Machine_Learning00008.smil#td_000350">Spring XD converts output to a SplunkEvent and is sent via TCP to a Splunk server.</td>
                    </tr>
                    <tr id="tr_000114">
                      <td class="left" rowspan="1" colspan="1" id="td_000351" smilref="Machine_Learning00008.smil#td_000351">Gemfire Server</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000352" smilref="Machine_Learning00008.smil#td_000352">Data is written to a running Gemfire Cache server. This can be to either the standard server or the JSON server.</td>
                    </tr>
                    <tr id="tr_000115">
                      <td class="left" rowspan="1" colspan="1" id="td_000353" smilref="Machine_Learning00008.smil#td_000353">MQTT</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000354" smilref="Machine_Learning00008.smil#td_000354">Output telemetry data is sent to a configured MQTT server.</td>
                    </tr>
                  </table>
                </figure>
                <p id="c09-c09-para-0025" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0025">Other sink output channels can be created if they are supported in the Spring Integration project.</p>
              </level4>
              <level4 id="level4_000067">
                <h4 xml:space="preserve" id="h4_000067" smilref="Machine_Learning00008.smil#h4_000067">Processors</h4>
                <pagenum epub:type="pagebreak" id="p192" page="normal" smilref="Machine_Learning00008.smil#p192">192</pagenum>
                <p xml:space="preserve" id="p_000564"><span class="text" id="span_001145" smilref="Machine_Learning00008.smil#span_001145">So far, this chapter has covered the input and output data types. You could easily create Spring XD streams to read an input source and then pipe the data to an output source. </span><em id="em_000198" smilref="Machine_Learning00008.smil#em_000198">Processors</em><span class="text" id="span_001146" smilref="Machine_Learning00008.smil#span_001146"> sit between the input and output sources and allow additional processing, parsing, and analyzing of the data as it passes through.</span></p>
                <p id="c09-c09-para-0027" xml:space="preserve"><span class="text" id="span_001147" smilref="Machine_Learning00008.smil#span_001147">Spring XD comes with a set of ready-to-use processors (see </span><a id="c09-c09-tbl-anc-0003" href="#c09-c09-tbl-0003" external="false" smilref="Machine_Learning00008.smil#c09-c09-tbl-anc-0003">Table 9-3</a><span class="text" id="span_001148" smilref="Machine_Learning00008.smil#span_001148">); they offer some basic filtering, data extraction, and string manipulation.</span></p>
                <figure id="figure_000083">
                  <figcaption id="figcaption_000069">
                    <p xml:space="preserve" id="p_000565"><span class="figureLabel" id="span_001149"><a id="c09-c09-tbl-0003" href="#c09-c09-tbl-anc-0003" external="false"><strong id="strong_000383" smilref="Machine_Learning00008.smil#strong_000383">Table 9-3</strong></a></span><span class="text" id="span_001150" smilref="Machine_Learning00008.smil#span_001150"> Spring XD Built-In Processors</span></p>
                  </figcaption>
                  <table border="1" id="table_000021">
                    <tr id="tr_000116">
                      <td class="left" rowspan="1" colspan="1" id="td_000355" smilref="Machine_Learning00008.smil#td_000355">Processor Name</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000356" smilref="Machine_Learning00008.smil#td_000356">Description</td>
                    </tr>
                    <tr id="tr_000117">
                      <td class="left" rowspan="1" colspan="1" id="td_000357" smilref="Machine_Learning00008.smil#td_000357">Filters</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000358" smilref="Machine_Learning00008.smil#td_000358">Performs a grep-like expression filtering on the stream. The filter can be either a Spring Expression Language (SpEL) expression or a Groovy script.</td>
                    </tr>
                    <tr id="tr_000118">
                      <td class="left" rowspan="1" colspan="1" id="td_000359" smilref="Machine_Learning00008.smil#td_000359">JSON Field Value</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000360" smilref="Machine_Learning00008.smil#td_000360">Passes message through if the value of a JSON field matches.</td>
                    </tr>
                    <tr id="tr_000119">
                      <td class="left" rowspan="1" colspan="1" id="td_000361" smilref="Machine_Learning00008.smil#td_000361">JSON Field Extractor</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000362" smilref="Machine_Learning00008.smil#td_000362">Extracts the value of a JSON field and streams the value to the output.</td>
                    </tr>
                    <tr id="tr_000120">
                      <td class="left" rowspan="1" colspan="1" id="td_000363" smilref="Machine_Learning00008.smil#td_000363">Transform</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000364" smilref="Machine_Learning00008.smil#td_000364">Converts the input source message content and sends it on to the output.</td>
                    </tr>
                    <tr id="tr_000121">
                      <td class="left" rowspan="1" colspan="1" id="td_000365" smilref="Machine_Learning00008.smil#td_000365">Split</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000366" smilref="Machine_Learning00008.smil#td_000366">Consumes the message and splits it into a number of messages based on an expression.</td>
                    </tr>
                    <tr id="tr_000122">
                      <td class="left" rowspan="1" colspan="1" id="td_000367" smilref="Machine_Learning00008.smil#td_000367">Aggregator</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000368" smilref="Machine_Learning00008.smil#td_000368">Concatenates message payloads together a number of times to create one aggregated message.</td>
                    </tr>
                  </table>
                </figure>
                <p id="c09-c09-para-0028" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0028">Although Spring XD has comprehensive built-ins, there are plenty of options for customization creating new input sources, sinks, and processors.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000073">
            <h2 id="c09-c09_level1_3" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09_level1_3">Learning from Twitter Data</h2>
            <pagenum epub:type="pagebreak" id="p193" page="normal" smilref="Machine_Learning00008.smil#p193">193</pagenum>
            <p xml:space="preserve" id="p_000566" smilref="Machine_Learning00008.smil#p_000566">The remainder of the chapter outlines a solution for analyzing data from Twitter. The Twitter streaming API provides plenty of data that can be filtered down to a reasonable size when you track a tiny subset. It also gives the perfect platform for learning how Spring XD works, how to create streams, and how to start customizing processors for your own needs.</p>
            <p id="c09-c09-para-0030" xml:space="preserve" smilref="Machine_Learning00008.smil#c09-c09-para-0030">If you haven't already installed Spring XD, please refer to the “Software Used in This Book” section of Chapter 1. There you can find instructions on where to download and how to install Spring XD.</p>
            <level3 id="level3_000145">
              <h3 xml:space="preserve" id="h3_000145" smilref="Machine_Learning00008.smil#h3_000145">The Development Plan</h3>
              <p xml:space="preserve" id="p_000567" smilref="Machine_Learning00008.smil#p_000567">This section includes step-by-step instructions for building up the full implementation of learning from the Twitter streaming data.</p>
              <level4 id="level4_000068">
                <h4 xml:space="preserve" id="h4_000068" smilref="Machine_Learning00008.smil#h4_000068">Step 1: Basic Streams in Spring XD</h4>
                <p xml:space="preserve" id="p_000568" smilref="Machine_Learning00008.smil#p_000568">The first step in the project is to get each element up and running. When you know each element is working and data can be saved to a file, then you can move forward with filtering. The basic concepts are</p>
                <list type="ul" id="list_000046">
                  <li id="li_000362" smilref="Machine_Learning00008.smil#li_000362">Setting up the Twitter API developer application</li>
                  <li id="li_000363" smilref="Machine_Learning00008.smil#li_000363">Setting up the Spring XD Twitter credentials</li>
                  <li id="li_000364" smilref="Machine_Learning00008.smil#li_000364">Testing Spring XD with a simple demo stream</li>
                  <li id="li_000365" smilref="Machine_Learning00008.smil#li_000365">Configuring the first stream to consume Twitter data</li>
                  <li id="li_000366" smilref="Machine_Learning00008.smil#li_000366">Emitting data to a file sink</li>
                </list>
              </level4>
              <level4 id="level4_000069">
                <h4 xml:space="preserve" id="h4_000069" smilref="Machine_Learning00008.smil#h4_000069">Step 2: Developing a Processing Module</h4>
                <p xml:space="preserve" id="p_000569" smilref="Machine_Learning00008.smil#p_000569">The second step introduces the development of your first processor:</p>
                <list type="ul" id="list_000047">
                  <li id="li_000367" smilref="Machine_Learning00008.smil#li_000367">Writing the processor code</li>
                  <li id="li_000368" smilref="Machine_Learning00008.smil#li_000368">Writing the XML configuration item</li>
                  <li id="li_000369" smilref="Machine_Learning00008.smil#li_000369">Installing the code and configuration in Spring XD</li>
                  <li id="li_000370" smilref="Machine_Learning00008.smil#li_000370">Reconfiguring the stream to include the new processor</li>
                </list>
              </level4>
              <level4 id="level4_000070">
                <h4 xml:space="preserve" id="h4_000070" smilref="Machine_Learning00008.smil#h4_000070">Step 3: Developing a Sentiment Analysis Module</h4>
                <p xml:space="preserve" id="p_000570"><span class="text" id="span_001151" smilref="Machine_Learning00008.smil#span_001151">The last step involves developing a more involved processor to perform sentiment analysis on the incoming Twitter stream. You also configure Spring XD to </span><pagenum epub:type="pagebreak" id="p194" page="normal" smilref="Machine_Learning00008.smil#p194">194</pagenum><span class="text" id="span_001152" smilref="Machine_Learning00008.smil#span_001152">preserve the raw Twitter data before it's processed, in case you want to do further analysis after the fact. This step can be broken down into the following tasks:</span></p>
                <list type="ul" id="list_000048">
                  <li id="li_000371" smilref="Machine_Learning00008.smil#li_000371">Writing the sentiment analysis processor</li>
                  <li id="li_000372" smilref="Machine_Learning00008.smil#li_000372">Writing the XML configuration</li>
                  <li id="li_000373" smilref="Machine_Learning00008.smil#li_000373">Installing the sentiment analysis code and configuration in Spring XD</li>
                  <li id="li_000374" smilref="Machine_Learning00008.smil#li_000374">Reconfiguring the stream to hook up the existing processor to the sentiment analysis processor</li>
                  <li id="li_000375" smilref="Machine_Learning00008.smil#li_000375">Configuring a second channel called a “Tap” enables you to store the streaming data while piping it to the sentiment analysis processor.</li>
                </list>
                <p id="c09-c09-para-0035" xml:space="preserve"><span class="text" id="span_001153" smilref="Machine_Learning00008.smil#span_001153">If the list seems overwhelming, don't worry; I've provided step-by-step instructions and code samples along the way. The full code and configuration data are also available from the Wiley website </span><code xml:space="preserve" id="code_000333"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000295" smilref="Machine_Learning00008.smil#a_000295">http://www.wiley.com/go/machinelearning</a></code><span class="text" id="span_001154" smilref="Machine_Learning00008.smil#span_001154">.</span></p>
              </level4>
            </level3>
            <level3 id="level3_000146">
              <h3 xml:space="preserve" id="h3_000146" smilref="Machine_Learning00008.smil#h3_000146">Configuring the Twitter API Developer Application</h3>
              <p xml:space="preserve" id="p_000571"><span class="text" id="span_001155" smilref="Machine_Learning00008.smil#span_001155">Before you can start consuming data from Twitter into Spring XD, you need to set up a development account and install the Twitter development environment. This setup process uses Twitter's developer site (</span><code xml:space="preserve" id="code_000334"><a href="http://dev.twitter.com" external="true" id="a_000296" smilref="Machine_Learning00008.smil#a_000296">http://dev.twitter.com</a></code><span class="text" id="span_001156" smilref="Machine_Learning00009.smil#span_001156">) and requires you to have an existing Twitter account. If you don't have a Twitter account, you can sign up for one at </span><code xml:space="preserve" id="code_000335"><a href="http://www.twitter.com" external="true" id="a_000297" smilref="Machine_Learning00009.smil#a_000297">http://www.twitter.com</a></code><span class="text" id="span_001157" smilref="Machine_Learning00009.smil#span_001157">.</span></p>
              <p id="c09-c09-para-0037" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0037">The developer website enables users to create keys for their applications to access Twitter's APIs. I'm going step-by-step, assuming you've never done it before. If you already know how to create Twitter developer access and the required credentials, then you can skip the remainder of this section.</p>
              <list type="ol" id="list_000049">
                <li id="li_000376">
                  <span class="text" id="span_001158" smilref="Machine_Learning00009.smil#span_001158">Open a web browser and go to</span>
                  <code xml:space="preserve" id="code_000336"><a href="http://dev.twitter.com" external="true" id="a_000298" smilref="Machine_Learning00009.smil#a_000298">http://dev.twitter.com</a></code>
                  <span class="text" id="span_001159" smilref="Machine_Learning00009.smil#span_001159">. Log in with your Twitter credentials.</span>
                </li>
                <li id="li_000377" smilref="Machine_Learning00009.smil#li_000377">Find your Twitter avatar image at the top right. Hover your mouse pointer over the arrow next to it. Click the My Applications link in the drop-down menu.</li>
                <pagenum epub:type="pagebreak" id="p196" page="normal" smilref="Machine_Learning00009.smil#p196">196</pagenum>
                <li id="li_000378">
                  <span class="text" id="span_001160" smilref="Machine_Learning00009.smil#span_001160">Click the Create a New Application button, as shown in</span>
                  <a id="c09-c09-fig-anc-0001" href="#c09-c09-fig-0001" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0001">Figure 9-1</a>
                  <span class="text" id="span_001161" smilref="Machine_Learning00009.smil#span_001161">.</span>
                  <p class="listpara1" id="c09-c09-para-0038" xml:space="preserve"><span class="text" id="span_001162" smilref="Machine_Learning00009.smil#span_001162">Fill in the required fields for the application name, description, and a URL for your website (see </span><a id="c09-c09-fig-anc-0002" href="#c09-c09-fig-0002" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0002">Figure 9-2</a><span class="text" id="span_001163" smilref="Machine_Learning00009.smil#span_001163">). This information is required if Twitter users decide to use their accounts with your application. You can leave the callback URL blank, because you won't be using it.</span></p>
                  <p class="listpara1" id="c09-c09-para-0039" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0039">You need to agree to Twitter's terms and conditions as well as fill in a Captcha code. Click the Create Your Twitter Application button.</p>
                  <p class="listpara1" id="c09-c09-para-0040" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0040">Assuming that all went well, you are directed to the Details configuration screen of your application. These settings include organization, authorization, settings, access keys, and an option to delete the application.</p>
                </li>
                <li id="li_000379">
                  <span class="text" id="span_001164" smilref="Machine_Learning00009.smil#span_001164">In the OAuth Settings area of the Details tab (see</span>
                  <a id="c09-c09-fig-anc-0003" href="#c09-c09-fig-0003" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0003">Figure 9-3</a>
                  <span class="text" id="span_001165" smilref="Machine_Learning00009.smil#span_001165">) is the information you require for the Spring XD system to collect Twitter streaming data. Make a note of the Consumer Key and the Consumer Secret.</span>
                </li>
                <li id="li_000380" smilref="Machine_Learning00009.smil#li_000380">Twitter requires an access token to go with your consumer key and secret. The easiest way to get one is to click the Create My Access Token button below the OAuth settings. It can take a moment for the access token to appear in the Details page. If it takes longer than 30 seconds or if the access token remains empty, refresh the page in your browser and the tokens appear.</li>
              </list>
              <figure id="figure_000084">
                <img class="center" src="images/c09f001.jpg" alt="image" id="img_000112" />
                <figcaption id="figcaption_000070">
                  <p xml:space="preserve" id="p_000572"><span class="figureLabel" id="span_001166"><a id="c09-c09-fig-0001" href="#c09-c09-fig-anc-0001" external="false"><strong id="strong_000384" smilref="Machine_Learning00009.smil#strong_000384">Figure 9-1</strong></a></span> <pagenum epub:type="pagebreak" id="p195" page="normal" smilref="Machine_Learning00009.smil#p195">195</pagenum><span class="text" id="span_001167" smilref="Machine_Learning00009.smil#span_001167">Creating a new Twitter application page</span></p>
                </figcaption>
              </figure>
              <figure id="figure_000085">
                <img class="center" src="images/c09f002.jpg" alt="image" id="img_000113" />
                <figcaption id="figcaption_000071">
                  <p xml:space="preserve" id="p_000573"><span class="figureLabel" id="span_001168"><a id="c09-c09-fig-0002" href="#c09-c09-fig-anc-0002" external="false"><strong id="strong_000385" smilref="Machine_Learning00009.smil#strong_000385">Figure 9-2</strong></a></span><span class="text" id="span_001169" smilref="Machine_Learning00009.smil#span_001169"> Completing the application detail page</span></p>
                </figcaption>
              </figure>
              <figure id="figure_000086">
                <img class="center" src="images/c09f003.jpg" alt="image" id="img_000114" />
                <figcaption id="figcaption_000072">
                  <p xml:space="preserve" id="p_000574"><span class="figureLabel" id="span_001170"><a id="c09-c09-fig-0003" href="#c09-c09-fig-anc-0003" external="false"><strong id="strong_000386" smilref="Machine_Learning00009.smil#strong_000386">Figure 9-3</strong></a></span><span class="text" id="span_001171" smilref="Machine_Learning00009.smil#span_001171"> OAuth details</span></p>
                </figcaption>
              </figure>
              <p id="c09-c09-para-0041" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0041">When the process is complete, you see the access token, an access token secret key, and the access level. A read-only token is fine for your purposes, because you'll be consuming data and not writing new tweets.</p>
            </level3>
          </level2>
          <level2 id="level2_000074">
            <h2 id="c09-c09_level1_4" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09_level1_4">Configuring Spring XD</h2>
            <p xml:space="preserve" id="p_000575"><span class="text" id="span_001172" smilref="Machine_Learning00009.smil#span_001172">Now that you have the Twitter API keys set up for your application, you can set up Spring XD itself. The XD distribution has a fair number of components. </span><pagenum epub:type="pagebreak" id="p197" page="normal" smilref="Machine_Learning00009.smil#p197">197</pagenum><span class="text" id="span_001173" smilref="Machine_Learning00009.smil#span_001173">In the main directory you can find directories for </span><code xml:space="preserve" id="code_000337" smilref="Machine_Learning00009.smil#code_000337">Gemfire</code><span class="text" id="span_001174" smilref="Machine_Learning00009.smil#span_001174"> and </span><code xml:space="preserve" id="code_000338" smilref="Machine_Learning00009.smil#code_000338">Redis</code><span class="text" id="span_001175" smilref="Machine_Learning00009.smil#span_001175">. You can install these separately; they aren't required for this walkthrough.</span></p>
            <p id="c09-c09-para-0043" xml:space="preserve"><span class="text" id="span_001176" smilref="Machine_Learning00009.smil#span_001176">You'll be using the server directory </span><code xml:space="preserve" id="code_000339" smilref="Machine_Learning00009.smil#code_000339">xd</code><span class="text" id="span_001177" smilref="Machine_Learning00009.smil#span_001177"> and the command-line program directory called </span><code xml:space="preserve" id="code_000340" smilref="Machine_Learning00009.smil#code_000340">shell</code><span class="text" id="span_001178" smilref="Machine_Learning00009.smil#span_001178">.</span></p>
            <level3 id="level3_000147">
              <h3 xml:space="preserve" id="h3_000147" smilref="Machine_Learning00009.smil#h3_000147">Starting the Spring XD Server</h3>
              <p xml:space="preserve" id="p_000576"><span class="text" id="span_001179" smilref="Machine_Learning00009.smil#span_001179">Within the Spring XD server directory called </span><code xml:space="preserve" id="code_000341" smilref="Machine_Learning00009.smil#code_000341">xd</code><span class="text" id="span_001180" smilref="Machine_Learning00009.smil#span_001180"> is a subdirectory called </span><code xml:space="preserve" id="code_000342" smilref="Machine_Learning00009.smil#code_000342">bin</code><span class="text" id="span_001181" smilref="Machine_Learning00009.smil#span_001181">. The </span><code xml:space="preserve" id="code_000343" smilref="Machine_Learning00009.smil#code_000343">bin</code><span class="text" id="span_001182" smilref="Machine_Learning00009.smil#span_001182"> directory contains the scripts used to administer the XD server. For the first few examples, you start the server in single or “stand alone” mode. This mode configures and starts Spring XD to run on one machine. After you are more familiar with the framework, you can configure it to run on a cluster of machines.</span></p>
              <p id="c09-c09-para-0045" xml:space="preserve"><span class="text" id="span_001183" smilref="Machine_Learning00009.smil#span_001183">In a UNIX shell, change to the directory where you installed Spring XD and descend into the </span><code xml:space="preserve" id="code_000344" smilref="Machine_Learning00009.smil#code_000344">xd/bin</code><span class="text" id="span_001184" smilref="Machine_Learning00009.smil#span_001184"> subdirectory. Start the server using the </span><code xml:space="preserve" id="code_000345" smilref="Machine_Learning00009.smil#code_000345">xd-singlenode</code><span class="text" id="span_001185" smilref="Machine_Learning00009.smil#span_001185"> shell script:</span></p>
              <p xml:space="preserve" id="p_000577"><code class="preserve-whitespace" xml:space="preserve" id="code_000346" smilref="Machine_Learning00009.smil#code_000346">$ cd spring-xd
$ cd xd/bin
$ ./xd-singlenode</code></p>
              <p id="c09-c09-para-0046" xml:space="preserve"><span class="text" id="span_001186" smilref="Machine_Learning00009.smil#span_001186">Within the terminal window where you issued the command, you see Spring XD emit diagnostic information about starting its required modules. When you see the string </span><code xml:space="preserve" id="code_000347" smilref="Machine_Learning00009.smil#code_000347">started container</code><span class="text" id="span_001187" smilref="Machine_Learning00009.smil#span_001187"> as shown in </span><a id="c09-c09-fig-anc-0004" href="#c09-c09-fig-0004" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0004">Figure 9-4</a><span class="text" id="span_001188" smilref="Machine_Learning00009.smil#span_001188">, then the Spring XD server is ready to accept commands.</span></p>
              <figure id="figure_000087">
                <img class="center" src="images/c09f004.jpg" alt="image" id="img_000115" />
                <figcaption id="figcaption_000073">
                  <p xml:space="preserve" id="p_000578"><span class="figureLabel" id="span_001189"><a id="c09-c09-fig-0004" href="#c09-c09-fig-anc-0004" external="false"><strong id="strong_000387" smilref="Machine_Learning00009.smil#strong_000387">Figure 9-4</strong></a></span><span class="text" id="span_001190" smilref="Machine_Learning00009.smil#span_001190"> Spring XD server startup</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p198" page="normal" smilref="Machine_Learning00009.smil#p198">198</pagenum>
              <p id="c09-c09-para-0047" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0047">You can stop the server by typing Ctrl + C in the terminal window where the server was started. Ctrl+C stops the server if it is not running as a background task in the terminal window.</p>
              <p id="c09-c09-para-0048" xml:space="preserve"><span class="text" id="span_001191" smilref="Machine_Learning00009.smil#span_001191">If the Spring XD server process is running in the background, you can send it a TERM(inate) signal using the UNIX </span><code xml:space="preserve" id="code_000348" smilref="Machine_Learning00009.smil#code_000348">kill</code><span class="text" id="span_001192" smilref="Machine_Learning00009.smil#span_001192"> command. First display all </span><code xml:space="preserve" id="code_000349" smilref="Machine_Learning00009.smil#code_000349">springxd</code><span class="text" id="span_001193" smilref="Machine_Learning00009.smil#span_001193"> processes running to identify the process ID of your server, then use the </span><code xml:space="preserve" id="code_000350" smilref="Machine_Learning00009.smil#code_000350">killall</code><span class="text" id="span_001194" smilref="Machine_Learning00009.smil#span_001194"> UNIX command interactively to send the terminate signal to your server process.</span></p>
              <p xml:space="preserve" id="p_000579"><code class="preserve-whitespace" xml:space="preserve" id="code_000351" smilref="Machine_Learning00009.smil#code_000351">$ ps –auxw | grep springxd
$ killall –i –v –TERM java</code></p>
            </level3>
            <level3 id="level3_000148">
              <h3 xml:space="preserve" id="h3_000148" smilref="Machine_Learning00009.smil#h3_000148">Creating Sample Data</h3>
              <p xml:space="preserve" id="p_000580"><span class="text" id="span_001195" smilref="Machine_Learning00009.smil#span_001195">Before you run the shell you are going to create a stream of data to read in. Assume that you want to read the uptime of the machine that you are working on. First you would write the contents of the uptime command to a file in the </span><code xml:space="preserve" id="code_000352" smilref="Machine_Learning00009.smil#code_000352">/tmp</code><span class="text" id="span_001196" smilref="Machine_Learning00009.smil#span_001196"> directory:</span></p>
              <p xml:space="preserve" id="p_000581"><code class="preserve-whitespace" xml:space="preserve" id="code_000353" smilref="Machine_Learning00009.smil#code_000353">$ while true ; do uptime &gt;&gt; /tmp/xdin ;  sleep 1 ; done &amp;</code></p>
              <p id="c09-c09-para-0050" xml:space="preserve"><span class="text" id="span_001197" smilref="Machine_Learning00009.smil#span_001197">The output file </span><code xml:space="preserve" id="code_000354" smilref="Machine_Learning00009.smil#code_000354">xdin</code><span class="text" id="span_001198" smilref="Machine_Learning00009.smil#span_001198"> contains the uptime output updated every second.</span></p>
              <p xml:space="preserve" id="p_000582"><code class="preserve-whitespace" xml:space="preserve" id="code_000355" smilref="Machine_Learning00009.smil#code_000355">19:07:47 up 35 days,  7:49,  1 user,  load average: 0.00, 0.00, 0.00
 19:07:48 up 35 days,  7:49,  1 user,  load average: 0.00, 0.00, 0.00
 19:07:49 up 35 days,  7:49,  1 user,  load average: 0.00, 0.00, 0.00
 19:07:50 up 35 days,  7:49,  1 user,  load average: 0.00, 0.00, 0.00</code></p>
            </level3>
            <level3 id="level3_000149">
              <h3 xml:space="preserve" id="h3_000149" smilref="Machine_Learning00009.smil#h3_000149">The Spring XD Shell</h3>
              <p xml:space="preserve" id="p_000583"><span class="text" id="span_001199" smilref="Machine_Learning00009.smil#span_001199">Now that the server is running you can use the client command-line shell program that comes with Spring XD. To run the interactive shell, open another terminal window, descend into the directory where you installed Spring XD, and run the </span><code xml:space="preserve" id="code_000356" smilref="Machine_Learning00009.smil#code_000356">xd-shell</code><span class="text" id="span_001200" smilref="Machine_Learning00009.smil#span_001200"> script.</span></p>
              <p xml:space="preserve" id="p_000584"><code class="preserve-whitespace" xml:space="preserve" id="code_000357" smilref="Machine_Learning00009.smil#code_000357">cd /usr/local/springxd/
cd shell/bin
./xd-shell</code></p>
              <p id="c09-c09-para-0052" xml:space="preserve"><span class="text" id="span_001201" smilref="Machine_Learning00009.smil#span_001201">The Spring XD shell prompt is </span><code xml:space="preserve" id="code_000358" smilref="Machine_Learning00009.smil#code_000358">xd:&gt;</code><span class="text" id="span_001202" smilref="Machine_Learning00009.smil#span_001202">. (See </span><a id="c09-c09-fig-anc-0005" href="#c09-c09-fig-0005" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0005">Figure 9-5</a><span class="text" id="span_001203" smilref="Machine_Learning00009.smil#span_001203">.) From this command-line shell, you can issue the server commands as well as create and control streams. There are also commands to handle modules, jobs, built-in aggregate counters, and even Hadoop. (The next chapter includes more on Hadoop.)</span></p>
              <figure id="figure_000088">
                <img class="center" src="images/c09f005.jpg" alt="image" id="img_000116" />
                <figcaption id="figcaption_000074">
                  <p xml:space="preserve" id="p_000585"><span class="figureLabel" id="span_001204"><a id="c09-c09-fig-0005" href="#c09-c09-fig-anc-0005" external="false"><strong id="strong_000388" smilref="Machine_Learning00009.smil#strong_000388">Figure 9-5</strong></a></span><span class="text" id="span_001205" smilref="Machine_Learning00009.smil#span_001205"> Spring XD shell</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p199" page="normal" smilref="Machine_Learning00009.smil#p199">199</pagenum>
              <p id="c09-c09-para-0053" xml:space="preserve"><span class="text" id="span_001206" smilref="Machine_Learning00009.smil#span_001206">To exit the shell, type </span><strong id="strong_000389" smilref="Machine_Learning00009.smil#strong_000389">exit</strong><span class="text" id="span_001207" smilref="Machine_Learning00009.smil#span_001207"> and press the Enter/Return key.</span></p>
            </level3>
            <level3 id="level3_000150">
              <h3 xml:space="preserve" id="h3_000150" smilref="Machine_Learning00009.smil#h3_000150">Streams 101</h3>
              <p xml:space="preserve" id="p_000586" smilref="Machine_Learning00009.smil#p_000586">This section covers the concept of streams in Spring XD and looks at various types of streams that can be used. You find out how to create, delete, and list active streams within Spring XD.</p>
              <level4 id="level4_000071">
                <h4 xml:space="preserve" id="h4_000071" smilref="Machine_Learning00009.smil#h4_000071">Creating Streams</h4>
                <p xml:space="preserve" id="p_000587" smilref="Machine_Learning00009.smil#p_000587">Before you dive in to working with a Twitter stream, try creating a simple stream to get comfortable with the concept. Imagine you want to log a series of timestamps to a file. Within the XD shell, you run the following command:</p>
                <p xml:space="preserve" id="p_000588"><code class="preserve-whitespace" xml:space="preserve" id="code_000359" smilref="Machine_Learning00009.smil#code_000359">xd:&gt;stream create -–name myfirststream –-definition "tail –-name=/tmp/xdin"</code></p>
                <p id="c09-c09-para-0056" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0056">I'm going to break this command down in sections. First you're creating a new stream:</p>
                <p xml:space="preserve" id="p_000589"><code class="preserve-whitespace" xml:space="preserve" id="code_000360" smilref="Machine_Learning00009.smil#code_000360">stream create</code></p>
                <pagenum epub:type="pagebreak" id="p200" page="normal" smilref="Machine_Learning00009.smil#p200">200</pagenum>
                <p id="c09-c09-para-0057" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0057">Each stream requires a name in order to monitor and manage several streams at once:</p>
                <p xml:space="preserve" id="p_000590"><code class="preserve-whitespace" xml:space="preserve" id="code_000361" smilref="Machine_Learning00009.smil#code_000361">--name myfirststream</code></p>
                <p id="c09-c09-para-0058" xml:space="preserve"><span class="text" id="span_001208" smilref="Machine_Learning00009.smil#span_001208">The definition is the process flow; this clause is required and defines the actions and pipeline of stages. In this instance, you're executing the Java equivalent of the UNIX </span><code xml:space="preserve" id="code_000362" smilref="Machine_Learning00009.smil#code_000362">time</code><span class="text" id="span_001209" smilref="Machine_Learning00009.smil#span_001209"> command and piping it to Spring XD's log:</span></p>
                <p xml:space="preserve" id="p_000591"><code class="preserve-whitespace" xml:space="preserve" id="code_000363" smilref="Machine_Learning00009.smil#code_000363">--definition "tail –-name=/tmp/xdin"</code></p>
                <p id="c09-c09-para-0059" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0059">When you run the command, the XD shell returns with a response of:</p>
                <p xml:space="preserve" id="p_000592"><code class="preserve-whitespace" xml:space="preserve" id="code_000364" smilref="Machine_Learning00009.smil#code_000364">Created new stream 'myfirststream'</code></p>
                <p id="c09-c09-para-0060" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0060">Stream names are unique; if you attempt to create a stream with an existing name, you receive the following error message:</p>
                <p xml:space="preserve" id="p_000593"><code class="preserve-whitespace" xml:space="preserve" id="code_000365" smilref="Machine_Learning00009.smil#code_000365">Command failed org.springframework.xd.rest.client.impl.SpringXDException: There is already a stream named 'myfirststream'</code></p>
                <p id="c09-c09-para-0061" xml:space="preserve"><span class="text" id="span_001210" smilref="Machine_Learning00009.smil#span_001210">As soon as the stream is created, the server deploys the stream and starts processing. If you switch to the terminal where you started the server, you see the log output of the stream on </span><code xml:space="preserve" id="code_000366" smilref="Machine_Learning00009.smil#code_000366">stderr</code><span class="text" id="span_001211" smilref="Machine_Learning00009.smil#span_001211">:</span></p>
                <p xml:space="preserve" id="p_000594"><code class="preserve-whitespace" xml:space="preserve" id="code_000367" smilref="Machine_Learning00009.smil#code_000367">17:06:03,961  WARN task-scheduler-8 logger.myfirststream:145 - 2013-12-26 17:06:03</code></p>
                <p id="c09-c09-para-0062" xml:space="preserve"><span class="text" id="span_001212" smilref="Machine_Learning00009.smil#span_001212">Note that Spring XD's default log level is </span><code xml:space="preserve" id="code_000368" smilref="Machine_Learning00009.smil#code_000368">WARN</code><span class="text" id="span_001213" smilref="Machine_Learning00009.smil#span_001213">—a warning level of logging to the </span><code xml:space="preserve" id="code_000369" smilref="Machine_Learning00009.smil#code_000369">stderr</code><span class="text" id="span_001214" smilref="Machine_Learning00009.smil#span_001214"> sink. In this case the error output is diagnostic and there is nothing to be worried about. Spring XD is processing the stream correctly and logging information to the </span><code xml:space="preserve" id="code_000370" smilref="Machine_Learning00009.smil#code_000370">stderr</code><span class="text" id="span_001215" smilref="Machine_Learning00009.smil#span_001215"> sink.</span></p>
              </level4>
              <level4 id="level4_000072">
                <h4 xml:space="preserve" id="h4_000072" smilref="Machine_Learning00009.smil#h4_000072">Listing Streams</h4>
                <p xml:space="preserve" id="p_000595" smilref="Machine_Learning00009.smil#p_000595">To list existing streams, run the following command:</p>
                <p xml:space="preserve" id="p_000596"><code class="preserve-whitespace" xml:space="preserve" id="code_000371" smilref="Machine_Learning00009.smil#code_000371">xd:&gt;stream list</code></p>
                <p id="c09-c09-para-0064" xml:space="preserve"><span class="text" id="span_001216" smilref="Machine_Learning00009.smil#span_001216">A list of the streams, their names, definitions, and current status (deployed or undeployed) will be displayed as shown in </span><a id="c09-c09-fig-anc-0006" href="#c09-c09-fig-0006" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0006">Figure 9-6</a><span class="text" id="span_001217" smilref="Machine_Learning00009.smil#span_001217">.</span></p>
                <figure id="figure_000089">
                  <img class="center" src="images/c09f006.jpg" alt="image" id="img_000117" />
                  <figcaption id="figcaption_000075">
                    <p xml:space="preserve" id="p_000597"><span class="figureLabel" id="span_001218"><a id="c09-c09-fig-0006" href="#c09-c09-fig-anc-0006" external="false"><strong id="strong_000390" smilref="Machine_Learning00009.smil#strong_000390">Figure 9-6</strong></a></span><span class="text" id="span_001219" smilref="Machine_Learning00009.smil#span_001219"> Stream XD stream lists</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000073">
                <h4 xml:space="preserve" id="h4_000073" smilref="Machine_Learning00009.smil#h4_000073">Deploying and Undeploying Streams</h4>
                <p xml:space="preserve" id="p_000598" smilref="Machine_Learning00009.smil#p_000598">Streams in the list can be deployed or undeployed at any time. When streams are created, they are deployed by default, and the server starts executing and processing the stream. To halt the stream from running, you can undeploy it:</p>
                <p xml:space="preserve" id="p_000599"><code class="preserve-whitespace" xml:space="preserve" id="code_000372" smilref="Machine_Learning00009.smil#code_000372">Xd:&gt;stream undeploy –name myfirststream</code></p>
                <pagenum epub:type="pagebreak" id="p201" page="normal" smilref="Machine_Learning00009.smil#p201">201</pagenum>
                <p id="c09-c09-para-0066" xml:space="preserve"><span class="text" id="span_001220" smilref="Machine_Learning00009.smil#span_001220">When you list the streams after this </span><code xml:space="preserve" id="code_000373" smilref="Machine_Learning00009.smil#code_000373">undeploy</code><span class="text" id="span_001221" smilref="Machine_Learning00009.smil#span_001221"> command, the name and definition are shown but the status is blank. To redeploy the stream and start processing it again, run the </span><code xml:space="preserve" id="code_000374" smilref="Machine_Learning00009.smil#code_000374">stream</code><span class="text" id="span_001222" smilref="Machine_Learning00009.smil#span_001222"> command again:</span></p>
                <p xml:space="preserve" id="p_000600"><code class="preserve-whitespace" xml:space="preserve" id="code_000375" smilref="Machine_Learning00009.smil#code_000375">Xd:&gt;stream deploy –name myfirststream</code></p>
                <p id="c09-c09-para-0067" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0067">After you deploy a stream, you can check the server output log to ensure the stream is running.</p>
              </level4>
              <level4 id="level4_000074">
                <h4 xml:space="preserve" id="h4_000074" smilref="Machine_Learning00009.smil#h4_000074">Deleting Streams</h4>
                <p xml:space="preserve" id="p_000601"><span class="text" id="span_001223" smilref="Machine_Learning00009.smil#span_001223">When you no longer require a stream, you can safely delete it from Spring XD. You do this from the shell with the </span><code xml:space="preserve" id="code_000376" smilref="Machine_Learning00009.smil#code_000376">destroy</code><span class="text" id="span_001224" smilref="Machine_Learning00009.smil#span_001224"> command.</span></p>
                <p xml:space="preserve" id="p_000602"><code class="preserve-whitespace" xml:space="preserve" id="code_000377" smilref="Machine_Learning00009.smil#code_000377">Xd:&gt;stream destroy –name myfirststream</code></p>
                <p id="c09-c09-para-0069" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0069">The stream undeploys itself from the server and then is removed from the list. In order for that stream to work again it must be re-created.</p>
              </level4>
              <level4 id="level4_000075">
                <h4 xml:space="preserve" id="h4_000075" smilref="Machine_Learning00009.smil#h4_000075">Storing Stream Definitions</h4>
                <p xml:space="preserve" id="p_000603"><span class="text" id="span_001225" smilref="Machine_Learning00009.smil#span_001225">By default, Spring XD stores definitions and state information in memory and does not persist this data to disk. The information is stored only for the duration </span><pagenum epub:type="pagebreak" id="p202" page="normal" smilref="Machine_Learning00009.smil#p202">202</pagenum><span class="text" id="span_001226" smilref="Machine_Learning00009.smil#span_001226">of time the server is running. When the server is stopped, any definition data is lost and must be re-created when the server starts again. You can persist this data to disk using the Redis key-value store. Connection and other configuration details for Redis are set in the </span><code xml:space="preserve" id="code_000378" smilref="Machine_Learning00009.smil#code_000378">redis.properties</code><span class="text" id="span_001227" smilref="Machine_Learning00009.smil#span_001227"> file in the server configuration directory. A known-working version of Redis is part of the Spring XD distribution (for Linux or Mac OS X), but it must be compiled before you can use it. If you already have a version of Redis available then you can most likely use that version. For this walkthrough, the in-memory storage will suffice. In a production situation, persisting the streams in Redis is probably the better way to proceed.</span></p>
                <p id="c09-c09-para-0071" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0071">Thus far, this chapter has covered streams and how they are created, deployed, listed, and deleted. Now you can move on to working with Twitter data streams.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000075">
            <h2 id="c09-c09_level1_5" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09_level1_5">Spring XD and Twitter</h2>
            <p xml:space="preserve" id="p_000604" smilref="Machine_Learning00009.smil#p_000604">One of the more popular uses of real-time processing is to read and analyze social media data. The volume of opinion, sentiment, and information broadcasts make this kind of data the perfect use for a tool such as Spring XD.</p>
            <level3 id="level3_000151">
              <h3 xml:space="preserve" id="h3_000151" smilref="Machine_Learning00009.smil#h3_000151">Setting the Twitter Credentials</h3>
              <p xml:space="preserve" id="p_000605" smilref="Machine_Learning00009.smil#p_000605">You need to set up the Twitter credentials in your Spring XD configuration. Locate where you installed Spring XD and go to that directory.</p>
              <p xml:space="preserve" id="p_000606"><code class="preserve-whitespace" xml:space="preserve" id="code_000379" smilref="Machine_Learning00009.smil#code_000379">cd /usr/local/springxd</code></p>
              <p id="c09-c09-para-0074" xml:space="preserve"><span class="text" id="span_001228" smilref="Machine_Learning00009.smil#span_001228">The Twitter configuration file is saved as a template within the </span><code xml:space="preserve" id="code_000380" smilref="Machine_Learning00009.smil#code_000380">xd/config</code><span class="text" id="span_001229" smilref="Machine_Learning00009.smil#span_001229"> directory. You need to make a copy of this file (or rename it), so Spring XD recognizes it when you start the server.</span></p>
              <p xml:space="preserve" id="p_000607"><code class="preserve-whitespace" xml:space="preserve" id="code_000381" smilref="Machine_Learning00009.smil#code_000381">cp twitter.properties.template twitter.properties</code></p>
              <p id="c09-c09-para-0075" xml:space="preserve"><span class="text" id="span_001230" smilref="Machine_Learning00009.smil#span_001230">Edit the </span><code xml:space="preserve" id="code_000382" smilref="Machine_Learning00009.smil#code_000382">twitter.properties</code><span class="text" id="span_001231" smilref="Machine_Learning00009.smil#span_001231"> file and add the consumer key, consumer secret, access token, and access token secret using their respective key names, as shown in </span><a id="c09-c09-fig-anc-0007" href="#c09-c09-fig-0007" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0007">Figure 9-7</a><span class="text" id="span_001232" smilref="Machine_Learning00009.smil#span_001232">.</span></p>
              <figure id="figure_000090">
                <img class="center" src="images/c09f007.jpg" alt="image" id="img_000118" />
                <figcaption id="figcaption_000076">
                  <p xml:space="preserve" id="p_000608"><span class="figureLabel" id="span_001233"><a id="c09-c09-fig-0007" href="#c09-c09-fig-anc-0007" external="false"><strong id="strong_000391" smilref="Machine_Learning00009.smil#strong_000391">Figure 9-7</strong></a></span><span class="text" id="span_001234" smilref="Machine_Learning00009.smil#span_001234"> Twitter properties file for Spring XD</span></p>
                </figcaption>
              </figure>
              <p id="c09-c09-para-0076" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0076">Save the file and exit your text editor.</p>
              <p id="c09-c09-para-0077" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0077">The assumption is that Spring XD will be using only one Twitter user to consume all the Twitter data. If you are thinking of letting more than one Twitter user retrieve data via the API, then you need to add the credentials while creating the Spring XD stream.</p>
            </level3>
            <level3 id="level3_000152">
              <h3 xml:space="preserve" id="h3_000152" smilref="Machine_Learning00009.smil#h3_000152">Creating Your First Twitter Stream</h3>
              <pagenum epub:type="pagebreak" id="p203" page="normal" smilref="Machine_Learning00009.smil#p203">203</pagenum>
              <p xml:space="preserve" id="p_000609" smilref="Machine_Learning00009.smil#p_000609">Creating a Twitter stream is similar to the streams covered in the “Streams 101” section. It's just a case of creating another definition.</p>
              <p id="c09-c09-para-0079" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0079">Streaming Twitter data is based on the public tweets of its users. It's not the complete firehose of all tweets; instead it is a very small slice of everything on Twitter from the endpoints “sample” and “filter.” Be very careful of the amount of data the stream produces without filtering for specific keywords; you will consume a huge amount of data in a very short time.</p>
              <p id="c09-c09-para-0080" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0080">The Twitter output is in JSON notation and contains a lot of information about the date, time, user, the tweet itself, retweets, location (if available), and the reply. Unless the intention is to collect, store, and process all the information (assuming you have the storage capacity), using the public stream is good. If you want to have a certain amount of control of the data coming in, then tracking specific key terms is a better way to use the stream.</p>
              <level4 id="level4_000076">
                <h4 xml:space="preserve" id="h4_000076" smilref="Machine_Learning00009.smil#h4_000076">Create the Stream Definition</h4>
                <pagenum epub:type="pagebreak" id="p204" page="normal" smilref="Machine_Learning00009.smil#p204">204</pagenum>
                <p xml:space="preserve" id="p_000610" smilref="Machine_Learning00009.smil#p_000610">To create your first Twitter stream, run the following stream command from the shell:</p>
                <p xml:space="preserve" id="p_000611"><code class="preserve-whitespace" xml:space="preserve" id="code_000383" smilref="Machine_Learning00009.smil#code_000383">xd:&gt;stream create –-name mytweetstream –-definition "twitterstream --track='#fashion' | file"</code></p>
                <p id="c09-c09-para-0082" xml:space="preserve"><span class="text" id="span_001235" smilref="Machine_Learning00009.smil#span_001235">You should already be familiar with the general stream definition. Within the definition is where the work with the Twitter API happens. The </span><code xml:space="preserve" id="code_000384" smilref="Machine_Learning00009.smil#code_000384">twitterstream</code><span class="text" id="span_001236" smilref="Machine_Learning00009.smil#span_001236"> keyword tells Spring XD that you want to use the Twitter API. The </span><code xml:space="preserve" id="code_000385" smilref="Machine_Learning00009.smil#code_000385">–-track</code><span class="text" id="span_001237" smilref="Machine_Learning00009.smil#span_001237"> flag is telling the API what streaming data it wants to receive. This could be a hashtag or a specific user mention, or, as in this instance, a keyword (for this example, the word </span><code xml:space="preserve" id="code_000386" smilref="Machine_Learning00009.smil#code_000386">fashion</code><span class="text" id="span_001238" smilref="Machine_Learning00009.smil#span_001238">).</span></p>
                <p id="c09-c09-para-0083" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0083">When the stream is deployed, check the server log to make sure it's registered correctly:</p>
                <p xml:space="preserve" id="p_000612"><code class="preserve-whitespace" xml:space="preserve" id="code_000387" smilref="Machine_Learning00009.smil#code_000387">18:49:43,248  INFO http-bio-9393-exec-9 module.SimpleModule:137 - initialized module: SimpleModule [name=twitterstream, type=source, group=myfirsttwitter, index=0 @60cde43d]
18:49:43,266  INFO http-bio-9393-exec-9 module.ModuleDeployer:231 - deployed SimpleModule [name=twitterstream, type=source, group=myfirsttwitter, index=0 @60cde43d]</code></p>
                <p id="c09-c09-para-0084" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0084">If the Twitter credentials are incorrect, the Spring XD displays the error in the server's console and also relays the error response from the Twitter API. It's always worth keeping an eye on the console log output at these early stages.</p>
              </level4>
              <level4 id="level4_000077">
                <h4 xml:space="preserve" id="h4_000077" smilref="Machine_Learning00009.smil#h4_000077">Twitter Stream Definition Flags</h4>
                <p xml:space="preserve" id="p_000613"><span class="text" id="span_001239" smilref="Machine_Learning00009.smil#span_001239">I briefly mentioned the --</span><code xml:space="preserve" id="code_000388" smilref="Machine_Learning00009.smil#code_000388">track</code><span class="text" id="span_001240" smilref="Machine_Learning00009.smil#span_001240"> flag within the definition, but </span><a id="c09-c09-tbl-anc-0004" href="#c09-c09-tbl-0004" external="false" smilref="Machine_Learning00009.smil#c09-c09-tbl-anc-0004">Table 9-4</a><span class="text" id="span_001241" smilref="Machine_Learning00009.smil#span_001241"> lists a few others of which you should take note.</span></p>
                <figure id="figure_000091">
                  <figcaption id="figcaption_000077">
                    <p xml:space="preserve" id="p_000614"><span class="figureLabel" id="span_001242"><a id="c09-c09-tbl-0004" href="#c09-c09-tbl-anc-0004" external="false"><strong id="strong_000392" smilref="Machine_Learning00009.smil#strong_000392">Table 9-4</strong></a></span><span class="text" id="span_001243" smilref="Machine_Learning00009.smil#span_001243"> Streaming API Flags for Spring XD</span></p>
                  </figcaption>
                  <table border="1" id="table_000022">
                    <tr id="tr_000123">
                      <td class="left" rowspan="1" colspan="1" id="td_000369" smilref="Machine_Learning00009.smil#td_000369">Flag name</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000370" smilref="Machine_Learning00009.smil#td_000370">Description</td>
                    </tr>
                    <tr id="tr_000124">
                      <td class="left" rowspan="1" colspan="1" id="td_000371">
                        <code xml:space="preserve" id="code_000389" smilref="Machine_Learning00009.smil#code_000389">--track</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000372" smilref="Machine_Learning00009.smil#td_000372">One or more Twitter “hashtags” to track. If you want to monitor more than one hashtag, separate them with commas.</td>
                    </tr>
                    <tr id="tr_000125">
                      <td class="left" rowspan="1" colspan="1" id="td_000373">
                        <code xml:space="preserve" id="code_000390" smilref="Machine_Learning00009.smil#code_000390">--follow</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000374" smilref="Machine_Learning00009.smil#td_000374">A list of user IDs to track. The stream returns tweets based on matching users. To track more than one user, separate usernames with commas.</td>
                    </tr>
                    <tr id="tr_000126">
                      <td class="left" rowspan="1" colspan="1" id="td_000375">
                        <code xml:space="preserve" id="code_000391" smilref="Machine_Learning00009.smil#code_000391">--locations</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000376">
                        <span class="text" id="span_001244" smilref="Machine_Learning00009.smil#span_001244">Tracks tweets within a pair of longitude/latitude points. Note if the</span>
                        <code xml:space="preserve" id="code_000392" smilref="Machine_Learning00009.smil#code_000392">locations</code>
                        <span class="text" id="span_001245" smilref="Machine_Learning00009.smil#span_001245">flag is used with the</span>
                        <code xml:space="preserve" id="code_000393" smilref="Machine_Learning00009.smil#code_000393">track</code>
                        <span class="text" id="span_001246" smilref="Machine_Learning00009.smil#span_001246">flag, matching tweets on either flag will be returned—that is, tweets matching either one or the other, not tweets matching both.</span>
                      </td>
                    </tr>
                    <tr id="tr_000127">
                      <td class="left" rowspan="1" colspan="1" id="td_000377">
                        <code xml:space="preserve" id="code_000394" smilref="Machine_Learning00009.smil#code_000394">--delimited</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000378">
                        <span class="text" id="span_001247" smilref="Machine_Learning00009.smil#span_001247">Setting this parameter to the string</span>
                        <code xml:space="preserve" id="code_000395" smilref="Machine_Learning00009.smil#code_000395">length</code>
                        <span class="text" id="span_001248" smilref="Machine_Learning00009.smil#span_001248">indicates that statuses should be delimited in the stream, so that clients know how many bytes to read before the end of the status message. Statuses are represented by a length, in bytes, a newline, and the status text that is exactly length bytes. Note that “keep-alive” newlines might be inserted before each length. It can also be set to true or false to specify if delimiters are desired.</span>
                      </td>
                    </tr>
                    <tr id="tr_000128">
                      <td class="left" rowspan="1" colspan="1" id="td_000379">
                        <code xml:space="preserve" id="code_000396" smilref="Machine_Learning00009.smil#code_000396">--stallWarnings</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000380" smilref="Machine_Learning00009.smil#td_000380">Sends warning messages to the client if the client risks being disconnected.</td>
                    </tr>
                    <tr id="tr_000129">
                      <td class="left" rowspan="1" colspan="1" id="td_000381">
                        <code xml:space="preserve" id="code_000397" smilref="Machine_Learning00009.smil#code_000397">--filterLevel</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000382">
                        <span class="text" id="span_001249" smilref="Machine_Learning00009.smil#span_001249">Sets the level of tweets given back to the user. When set to</span>
                        <code xml:space="preserve" id="code_000398" smilref="Machine_Learning00009.smil#code_000398">none</code>
                        <span class="text" id="span_001250" smilref="Machine_Learning00009.smil#span_001250">, then all available tweets are sent back.</span>
                      </td>
                    </tr>
                  </table>
                </figure>
                <pagenum epub:type="pagebreak" id="p205" page="normal" smilref="Machine_Learning00009.smil#p205">205</pagenum>
                <p id="c09-c09-para-0086" xml:space="preserve"><span class="text" id="span_001251" smilref="Machine_Learning00009.smil#span_001251">The --</span><code xml:space="preserve" id="code_000399" smilref="Machine_Learning00009.smil#code_000399">stallWarnings</code><span class="text" id="span_001252" smilref="Machine_Learning00009.smil#span_001252"> and --</span><code xml:space="preserve" id="code_000400" smilref="Machine_Learning00009.smil#code_000400">filterLevel</code><span class="text" id="span_001253" smilref="Machine_Learning00009.smil#span_001253"> flags have different parameters when accessing the Twitter API directly. It's worth experimenting with a few streams and setting different values for these flags to see how the output behaves.</span></p>
              </level4>
              <level4 id="level4_000078">
                <h4 xml:space="preserve" id="h4_000078" smilref="Machine_Learning00009.smil#h4_000078">Inspecting the Output</h4>
                <p xml:space="preserve" id="p_000615"><span class="text" id="span_001254" smilref="Machine_Learning00009.smil#span_001254">Where the sink output is set to “file,” the file stream is stored in the </span><code xml:space="preserve" id="code_000401" smilref="Machine_Learning00009.smil#code_000401">/tmp/xd/</code><span class="text" id="span_001255" smilref="Machine_Learning00009.smil#span_001255">output directory. The filename is determined by the name of the stream created. So, for the Twitter streaming example, the output is</span></p>
                <p xml:space="preserve" id="p_000616"><code class="preserve-whitespace" xml:space="preserve" id="code_000402" smilref="Machine_Learning00009.smil#code_000402">/tmp/xd/output/mytweetstream.out</code></p>
                <p id="c09-c09-para-0088" xml:space="preserve"><span class="text" id="span_001256" smilref="Machine_Learning00009.smil#span_001256">It's useful at this point to use the UNIX </span><code xml:space="preserve" id="code_000403" smilref="Machine_Learning00009.smil#code_000403">tail</code><span class="text" id="span_001257" smilref="Machine_Learning00009.smil#span_001257"> command to see the velocity of the output. When developing Spring XD streams, especially for Twitter applications, I like to have three terminal windows open: one for the server, one for the client shell, and another tailing the output in the temporary directory, as shown in </span><a id="c09-c09-fig-anc-0008" href="#c09-c09-fig-0008" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0008">Figure 9-8</a><span class="text" id="span_001258" smilref="Machine_Learning00009.smil#span_001258">.</span></p>
                <figure id="figure_000092">
                  <img class="center" src="images/c09f008.jpg" alt="image" id="img_000119" />
                  <figcaption id="figcaption_000078">
                    <p xml:space="preserve" id="p_000617"><span class="figureLabel" id="span_001259"><a id="c09-c09-fig-0008" href="#c09-c09-fig-anc-0008" external="false"><strong id="strong_000393" smilref="Machine_Learning00009.smil#strong_000393">Figure 9-8</strong></a></span><span class="text" id="span_001260" smilref="Machine_Learning00009.smil#span_001260"> JSON output from the Twitter stream</span></p>
                  </figcaption>
                </figure>
              </level4>
            </level3>
            <level3 id="level3_000153">
              <h3 xml:space="preserve" id="h3_000153" smilref="Machine_Learning00009.smil#h3_000153">Where to Go from Here</h3>
              <p xml:space="preserve" id="p_000618" smilref="Machine_Learning00009.smil#p_000618">With regard to the development plan at the start of the chapter, you've completed Step 1: getting the basics of the Spring XD server and the Twitter credentials up and running. You've gotten the basic stream up and running and inspected the output.</p>
              <p id="c09-c09-para-0090" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0090">At this stage you're only consuming data and then choosing a method to store the output. Now it's time to move on to processors and manipulating the data in real time.</p>
            </level3>
          </level2>
          <level2 id="level2_000076">
            <h2 id="c09-c09_level1_6" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09_level1_6">Introducing Processors</h2>
            <pagenum epub:type="pagebreak" id="p206" page="normal" smilref="Machine_Learning00009.smil#p206">206</pagenum>
            <p xml:space="preserve" id="p_000619" smilref="Machine_Learning00009.smil#p_000619">So far, Spring XD is consuming the incoming stream of data and saving it to a file. For some purposes, this step suffices to write further software that would parse, perform analysis, and mine the data as required. One of the benefits of Spring XD is that you can extend the stream to process the incoming data with processors as it comes in without paying the heavy overhead of file I/O. This set of features also saves writing a custom program that is external to the system and means that most of the work can be performed as Spring XD is handling the data, which prevents technical debt and maintenance.</p>
            <level3 id="level3_000154">
              <h3 xml:space="preserve" id="h3_000154" smilref="Machine_Learning00009.smil#h3_000154">How Processors Work within a Stream</h3>
              <p xml:space="preserve" id="p_000620" smilref="Machine_Learning00009.smil#p_000620">So far when creating streams, you have set an input source and an output type. Data enters via Spring XD and can be written or logged depending on the output sink you've specified.</p>
              <p id="c09-c09-para-0093" xml:space="preserve"><span class="text" id="span_001261" smilref="Machine_Learning00009.smil#span_001261">The processor is another stage in the stream definition, so instead of having what's shown in the top half of </span><a id="c09-c09-fig-anc-0009" href="#c09-c09-fig-0009" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0009">Figure 9-9</a><span class="text" id="span_001262" smilref="Machine_Learning00009.smil#span_001262">, you can add a processor in the stream and transform the data as it flows, as shown in the bottom half of </span><a href="#c09-c09-fig-0009" external="false" id="a_000299" smilref="Machine_Learning00009.smil#a_000299">Figure 9-9</a><span class="text" id="span_001263" smilref="Machine_Learning00009.smil#span_001263">.</span></p>
              <figure id="figure_000093">
                <img class="center" src="images/c09f009.jpg" alt="image" id="img_000120" />
                <figcaption id="figcaption_000079">
                  <p xml:space="preserve" id="p_000621"><span class="figureLabel" id="span_001264"><a id="c09-c09-fig-0009" href="#c09-c09-fig-anc-0009" external="false"><strong id="strong_000394" smilref="Machine_Learning00009.smil#strong_000394">Figure 9-9</strong></a></span><span class="text" id="span_001265" smilref="Machine_Learning00009.smil#span_001265"> The processor information flow</span></p>
                </figcaption>
              </figure>
              <pagenum epub:type="pagebreak" id="p207" page="normal" smilref="Machine_Learning00009.smil#p207">207</pagenum>
              <p id="c09-c09-para-0094" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0094">The nice thing about processors is that you can chain many of them together in the stream. With built-in processors, you can start transforming the data very quickly. For example, if you want to extract only the tweet text from the incoming Twitter stream then you can use Spring XD's JSON field extractor; pulling only the content becomes straightforward:</p>
              <p xml:space="preserve" id="p_000622"><code class="preserve-whitespace" xml:space="preserve" id="code_000404" smilref="Machine_Learning00009.smil#code_000404">stream create --name prctest --definition "twitterstream --track='BigData' | json-field-extractor --fieldName=location | file"</code></p>
              <p id="c09-c09-para-0095" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0095">This is very helpful for selecting single fields that you want to extract. If you want to take things further, then crafting your own processor is the better way to go.</p>
            </level3>
            <level3 id="level3_000155">
              <h3 xml:space="preserve" id="h3_000155" smilref="Machine_Learning00009.smil#h3_000155">Creating Your Own Processor</h3>
              <p xml:space="preserve" id="p_000623" smilref="Machine_Learning00009.smil#p_000623">This section walks you through creating a processor, building it, and then deploying it on Spring XD. At present, you're consuming far too much Twitter data from the stream and it's using up precious storage space. The JSON field extractor is a good start but only extracts one field name and becomes limited when extracting huge amounts of JSON data. A processor module to extract the required fields of the Twitter stream and forward those to the output sink or the next stage in the pipeline is the purpose of this example. After this step is completed, you'll extend it further to perform some simple sentiment analysis. To understand the steps to create a module and deploy it, I'm going to cover the basic data extract first and then refactor the code.</p>
              <p id="c09-c09-para-0097" xml:space="preserve"><span class="text" id="span_001266" smilref="Machine_Learning00009.smil#span_001266">Spring XD expects all modules to be deployed within </span><code xml:space="preserve" id="code_000405" smilref="Machine_Learning00009.smil#code_000405">jar</code><span class="text" id="span_001267" smilref="Machine_Learning00009.smil#span_001267"> files. Ensure that the full package structure is saved within the </span><code xml:space="preserve" id="code_000406" smilref="Machine_Learning00009.smil#code_000406">jar</code><span class="text" id="span_001268" smilref="Machine_Learning00009.smil#span_001268"> file, otherwise Spring XD does not deploy the processor. The </span><code xml:space="preserve" id="code_000407" smilref="Machine_Learning00009.smil#code_000407">jar</code><span class="text" id="span_001269" smilref="Machine_Learning00009.smil#span_001269"> files are stored under the </span><code xml:space="preserve" id="code_000408" smilref="Machine_Learning00009.smil#code_000408">/lib</code><span class="text" id="span_001270" smilref="Machine_Learning00009.smil#span_001270"> directory of your Spring XD distribution.</span></p>
              <p id="c09-c09-para-0098" xml:space="preserve"><span class="text" id="span_001271" smilref="Machine_Learning00009.smil#span_001271">The application context is saved as an XML file but not saved within the </span><code xml:space="preserve" id="code_000409" smilref="Machine_Learning00009.smil#code_000409">jar</code><span class="text" id="span_001272" smilref="Machine_Learning00009.smil#span_001272"> file. It contains the module details of the incoming and outgoing channels and </span><pagenum epub:type="pagebreak" id="p208" page="normal" smilref="Machine_Learning00009.smil#p208">208</pagenum><span class="text" id="span_001273" smilref="Machine_Learning00009.smil#span_001273">which Java class to use to perform the processing. The context file is saved under the </span><code xml:space="preserve" id="code_000410" smilref="Machine_Learning00009.smil#code_000410">/modules/processors</code><span class="text" id="span_001274" smilref="Machine_Learning00009.smil#span_001274"> directory of your Spring XD distribution.</span></p>
              <p id="c09-c09-para-0099" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0099">This walkthrough uses Eclipse to enter the code and configuration. The general concept and steps would be the same if you were using another IDE such as Netbeans or IntelliJ IDEA. The complete source code for the Spring XD processor modules is on the companion web page for this book.</p>
              <level4 id="level4_000079">
                <h4 xml:space="preserve" id="h4_000079" smilref="Machine_Learning00009.smil#h4_000079">Creating the Project</h4>
                <p xml:space="preserve" id="p_000624" smilref="Machine_Learning00009.smil#p_000624">Within Eclipse, create a new Java project using File →New →Java Project. It will hold all the package information, the code, and a directory for the required libraries to read the incoming JSON data.</p>
                <p id="c09-c09-para-0101" xml:space="preserve"><span class="text" id="span_001275" smilref="Machine_Learning00009.smil#span_001275">Call the project </span><code xml:space="preserve" id="code_000411" smilref="Machine_Learning00009.smil#code_000411">XDTwitterProcessor</code><span class="text" id="span_001276" smilref="Machine_Learning00009.smil#span_001276">, as shown in </span><a id="c09-c09-fig-anc-0010" href="#c09-c09-fig-0010" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0010">Figure 9-10</a><span class="text" id="span_001277" smilref="Machine_Learning00009.smil#span_001277">, and check the default settings. When you are happy with them, click the Finish button. Eclipse creates the project structure for you.</span></p>
                <figure id="figure_000094">
                  <img class="center" src="images/c09f010.jpg" alt="image" id="img_000121" />
                  <figcaption id="figcaption_000080">
                    <p xml:space="preserve" id="p_000625"><span class="figureLabel" id="span_001278"><a id="c09-c09-fig-0010" href="#c09-c09-fig-anc-0010" external="false"><strong id="strong_000395" smilref="Machine_Learning00009.smil#strong_000395">Figure 9-10</strong></a></span><span class="text" id="span_001279" smilref="Machine_Learning00009.smil#span_001279"> Eclipse new project dialog</span></p>
                  </figcaption>
                </figure>
                <p id="c09-c09-para-0102" xml:space="preserve"><span class="text" id="span_001280" smilref="Machine_Learning00009.smil#span_001280">Next find the location of the Jackson JSON Parser </span><code xml:space="preserve" id="code_000412" smilref="Machine_Learning00009.smil#code_000412">jar</code><span class="text" id="span_001281" smilref="Machine_Learning00009.smil#span_001281"> files and the Spring Integration </span><code xml:space="preserve" id="code_000413" smilref="Machine_Learning00009.smil#code_000413">jar</code><span class="text" id="span_001282" smilref="Machine_Learning00009.smil#span_001282"> file. They are usually under </span><code xml:space="preserve" id="code_000414" smilref="Machine_Learning00009.smil#code_000414">xd/lib</code><span class="text" id="span_001283" smilref="Machine_Learning00009.smil#span_001283"> in the Spring XD distribution. The </span><code xml:space="preserve" id="code_000415" smilref="Machine_Learning00009.smil#code_000415">XDTwitterProcessor</code><span class="text" id="span_001284" smilref="Machine_Learning00009.smil#span_001284"> project properties need the locations within the Java build path. Otherwise, trying to compile your project results in errors. To add these locations to your project's build path, right-click the project name and select Project Properties.</span></p>
                <pagenum epub:type="pagebreak" id="p209" page="normal" smilref="Machine_Learning00009.smil#p209">209</pagenum>
                <p id="c09-c09-para-0103" xml:space="preserve"><span class="text" id="span_001285" smilref="Machine_Learning00009.smil#span_001285">Click Java Build Path on the left-hand side list of options and then click the Add External JARs button, as shown in </span><a id="c09-c09-fig-anc-0011" href="#c09-c09-fig-0011" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0011">Figure 9-11</a><span class="text" id="span_001286" smilref="Machine_Learning00009.smil#span_001286">. In the dialog box that opens, find the location of the required </span><code xml:space="preserve" id="code_000416" smilref="Machine_Learning00009.smil#code_000416">jar</code><span class="text" id="span_001287" smilref="Machine_Learning00009.smil#span_001287"> files and select the following (note the version numbers might vary from release to release):</span></p>
                <list type="ul" id="list_000050">
                  <li id="li_000381">
                    <code xml:space="preserve" id="code_000417" smilref="Machine_Learning00009.smil#code_000417">jackson-core-2.2.2.jar</code>
                  </li>
                  <li id="li_000382">
                    <code xml:space="preserve" id="code_000418" smilref="Machine_Learning00009.smil#code_000418">jackson-annotations-2.2.2.jar</code>
                  </li>
                  <li id="li_000383">
                    <code xml:space="preserve" id="code_000419" smilref="Machine_Learning00009.smil#code_000419">jackson-core-asl-1.9.13.jar</code>
                  </li>
                  <li id="li_000384">
                    <code xml:space="preserve" id="code_000420" smilref="Machine_Learning00009.smil#code_000420">jackson-databind.2.2.2.jar</code>
                  </li>
                  <li id="li_000385">
                    <code xml:space="preserve" id="code_000421" smilref="Machine_Learning00009.smil#code_000421">jackson-mapper-asl.1.9.13.jar</code>
                  </li>
                  <li id="li_000386">
                    <code xml:space="preserve" id="code_000422" smilref="Machine_Learning00009.smil#code_000422">spring-integration-core-4.0.0.M1.jar</code>
                  </li>
                  <li id="li_000387">
                    <code xml:space="preserve" id="code_000423" smilref="Machine_Learning00009.smil#code_000423">spring-messaging-4.0.0-RC1.jar</code>
                  </li>
                </list>
                <figure id="figure_000095">
                  <img class="center" src="images/c09f011.jpg" alt="image" id="img_000122" />
                  <figcaption id="figcaption_000081">
                    <p xml:space="preserve" id="p_000626"><span class="figureLabel" id="span_001288"><a id="c09-c09-fig-0011" href="#c09-c09-fig-anc-0011" external="false"><strong id="strong_000396" smilref="Machine_Learning00009.smil#strong_000396">Figure 9-11</strong></a></span><span class="text" id="span_001289" smilref="Machine_Learning00009.smil#span_001289"> Eclipse project Java build properties</span></p>
                  </figcaption>
                </figure>
                <p id="c09-c09-para-0104" xml:space="preserve"><span class="text" id="span_001290" smilref="Machine_Learning00009.smil#span_001290">After you have selected the required </span><code xml:space="preserve" id="code_000424" smilref="Machine_Learning00009.smil#code_000424">jar</code><span class="text" id="span_001291" smilref="Machine_Learning00009.smil#span_001291"> files, click Open and return to the Java Build dialog box. Then click OK to save your selections.</span></p>
              </level4>
              <level4 id="level4_000080">
                <h4 xml:space="preserve" id="h4_000080" smilref="Machine_Learning00009.smil#h4_000080">A Note to Maven Users</h4>
                <p xml:space="preserve" id="p_000627" smilref="Machine_Learning00009.smil#p_000627">Developers who use the Maven build tool can add the two dependencies in the build file:</p>
                <p xml:space="preserve" id="p_000628"><code class="preserve-whitespace" xml:space="preserve" id="code_000425" smilref="Machine_Learning00009.smil#code_000425">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt;
    &lt;artifactId&gt;spring-integration-core&lt;/artifactId&gt;
    &lt;version&gt;2.2.3.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
    &lt;version&gt;2.2.0&lt;/version&gt;
&lt;/dependency&gt;</code></p>
                <pagenum epub:type="pagebreak" id="p210" page="normal" smilref="Machine_Learning00009.smil#p210">210</pagenum>
                <p id="c09-c09-para-0106" xml:space="preserve"><span class="text" id="span_001292" smilref="Machine_Learning00009.smil#span_001292">This retrieves the required libraries when you build the project. If you're not familiar with the Maven build tool, you can learn more at </span><code xml:space="preserve" id="code_000426"><a href="http://maven.apache.org" external="true" id="a_000300" smilref="Machine_Learning00009.smil#a_000300">http://maven.apache.org</a></code><span class="text" id="span_001293" smilref="Machine_Learning00009.smil#span_001293">.</span></p>
              </level4>
              <level4 id="level4_000081">
                <h4 xml:space="preserve" id="h4_000081" smilref="Machine_Learning00009.smil#h4_000081">Writing the Code</h4>
                <p xml:space="preserve" id="p_000629"><span class="text" id="span_001294" smilref="Machine_Learning00009.smil#span_001294">Now that the project is set up, you can proceed to writing some code. First of all, create a new package in the project (using File →New →Package) and give it the name </span><code xml:space="preserve" id="code_000427" smilref="Machine_Learning00009.smil#code_000427">mlbook.chapter9.processor1</code><span class="text" id="span_001295" smilref="Machine_Learning00009.smil#span_001295">.</span></p>
                <p id="c09-c09-para-0108" xml:space="preserve"><span class="text" id="span_001296" smilref="Machine_Learning00009.smil#span_001296">Next, create a new Java class (using File →New →Class) and give it the name </span><code xml:space="preserve" id="code_000428" smilref="Machine_Learning00009.smil#code_000428">TwitterStreamTransform,</code><span class="text" id="span_001297" smilref="Machine_Learning00009.smil#span_001297"> as shown in </span><a id="c09-c09-fig-anc-0012" href="#c09-c09-fig-0012" external="false" smilref="Machine_Learning00009.smil#c09-c09-fig-anc-0012">Figure 9-12</a><span class="text" id="span_001298" smilref="Machine_Learning00009.smil#span_001298">.</span></p>
                <figure id="figure_000096">
                  <img class="center" src="images/c09f012.jpg" alt="image" id="img_000123" />
                  <figcaption id="figcaption_000082">
                    <p xml:space="preserve" id="p_000630"><span class="figureLabel" id="span_001299"><a id="c09-c09-fig-0012" href="#c09-c09-fig-anc-0012" external="false"><strong id="strong_000397" smilref="Machine_Learning00009.smil#strong_000397">Figure 9-12</strong></a></span><span class="text" id="span_001300" smilref="Machine_Learning00009.smil#span_001300"> Eclipse new class dialog box</span></p>
                  </figcaption>
                </figure>
                <p id="c09-c09-para-0109" xml:space="preserve"><span class="text" id="span_001301" smilref="Machine_Learning00009.smil#span_001301">Eclipse creates the bare template of the class file for you with the package name and the class definition. You can either delete it all and type the following code or fill in the required segments around the generated template. Don't </span><pagenum epub:type="pagebreak" id="p211" page="normal" smilref="Machine_Learning00009.smil#p211">211</pagenum><span class="text" id="span_001302" smilref="Machine_Learning00009.smil#span_001302">forget to organize the imports (Source →Organize Imports), and Eclipse looks after the classes required to import from the external libraries for the project.</span></p>
                <p xml:space="preserve" id="p_000631"><code class="preserve-whitespace" xml:space="preserve" id="code_000429"><strong id="strong_000398" smilref="Machine_Learning00009.smil#strong_000398">package</strong><span class="text" id="span_001303" smilref="Machine_Learning00009.smil#span_001303"> mlbook.chapter9.processor1;
</span><strong id="strong_000399" smilref="Machine_Learning00009.smil#strong_000399">import</strong><span class="text" id="span_001304" smilref="Machine_Learning00009.smil#span_001304"> java.io.IOException;
</span><strong id="strong_000400" smilref="Machine_Learning00009.smil#strong_000400">import</strong><span class="text" id="span_001305" smilref="Machine_Learning00009.smil#span_001305"> java.util.Map;
</span><strong id="strong_000401" smilref="Machine_Learning00009.smil#strong_000401">import</strong><span class="text" id="span_001306" smilref="Machine_Learning00009.smil#span_001306"> org.codehaus.jackson.map.ObjectMapper;
</span><strong id="strong_000402" smilref="Machine_Learning00009.smil#strong_000402">import</strong><span class="text" id="span_001307" smilref="Machine_Learning00009.smil#span_001307"> org.codehaus.jackson.type.TypeReference;
</span><strong id="strong_000403" smilref="Machine_Learning00009.smil#strong_000403">import</strong><span class="text" id="span_001308" smilref="Machine_Learning00009.smil#span_001308"> org.springframework.integration.transformer.MessageTransformationException;
</span><strong id="strong_000404" smilref="Machine_Learning00009.smil#strong_000404">public</strong> <strong id="strong_000405" smilref="Machine_Learning00009.smil#strong_000405">class</strong><span class="text" id="span_001309" smilref="Machine_Learning00009.smil#span_001309"> TwitterStreamTransform {
    </span><strong id="strong_000406" smilref="Machine_Learning00009.smil#strong_000406">private</strong><span class="text" id="span_001310" smilref="Machine_Learning00009.smil#span_001310"> ObjectMapper mapper = </span><strong id="strong_000407" smilref="Machine_Learning00009.smil#strong_000407">new</strong><span class="text" id="span_001311" smilref="Machine_Learning00009.smil#span_001311"> ObjectMapper();
    </span><strong id="strong_000408" smilref="Machine_Learning00009.smil#strong_000408">public</strong><span class="text" id="span_001312" smilref="Machine_Learning00009.smil#span_001312"> String transform(String payload) {
        </span><strong id="strong_000409" smilref="Machine_Learning00009.smil#strong_000409">try</strong><span class="text" id="span_001313" smilref="Machine_Learning00009.smil#span_001313"> {
          StringBuilder sb = </span><strong id="strong_000410" smilref="Machine_Learning00009.smil#strong_000410">new</strong><span class="text" id="span_001314" smilref="Machine_Learning00009.smil#span_001314"> StringBuilder();
          Map&lt;String, Object&gt; tweet = mapper.readValue(payload,</span><strong id="strong_000411" smilref="Machine_Learning00009.smil#strong_000411">new</strong><span class="text" id="span_001315" smilref="Machine_Learning00009.smil#span_001315">
TypeReference&lt;Map&lt;String, Object&gt;&gt;() {});
          sb.append(tweet.get("created_at").toString());
          sb.append("|");
          sb.append(tweet.get("text").toString());
          </span><strong id="strong_000412" smilref="Machine_Learning00009.smil#strong_000412">return</strong><span class="text" id="span_001316" smilref="Machine_Learning00009.smil#span_001316"> sb.toString();
        } </span><strong id="strong_000413" smilref="Machine_Learning00009.smil#strong_000413">catch</strong><span class="text" id="span_001317" smilref="Machine_Learning00009.smil#span_001317"> (IOException e) {
          </span><strong id="strong_000414" smilref="Machine_Learning00009.smil#strong_000414">throw</strong> <strong id="strong_000415" smilref="Machine_Learning00009.smil#strong_000415">new</strong><span class="text" id="span_001318" smilref="Machine_Learning00009.smil#span_001318"> MessageTransformationException(
          "[MLBook] - Cannot work on this tweet: " + e.getMessage(), e);
        }
    }
}</span></code></p>
                <p id="c09-c09-para-0110" xml:space="preserve"><span class="text" id="span_001319" smilref="Machine_Learning00009.smil#span_001319">When the Twitter API sends JSON data to Spring XD, the incoming stream is called </span><code xml:space="preserve" id="code_000430" smilref="Machine_Learning00009.smil#code_000430">payload</code><span class="text" id="span_001320" smilref="Machine_Learning00009.smil#span_001320"> and is defined as a </span><code xml:space="preserve" id="code_000431" smilref="Machine_Learning00009.smil#code_000431">string</code><span class="text" id="span_001321" smilref="Machine_Learning00009.smil#span_001321"> type. The method </span><code xml:space="preserve" id="code_000432" smilref="Machine_Learning00009.smil#code_000432">transform</code><span class="text" id="span_001322" smilref="Machine_Learning00009.smil#span_001322"> takes the incoming stream and uses the Jackson JSON parser API to convert it to a </span><code xml:space="preserve" id="code_000433" smilref="Machine_Learning00009.smil#code_000433">Map</code><span class="text" id="span_001323" smilref="Machine_Learning00009.smil#span_001323">. The JSON field names now become map keys and the values are Java objects.</span></p>
                <p id="c09-c09-para-0111" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0111">For this example you're concerned only about two elements: the date the tweet was created and the actual text of the tweet.</p>
                <p id="c09-c09-para-0112" xml:space="preserve"><span class="text" id="span_001324" smilref="Machine_Learning00009.smil#span_001324">Using the </span><code xml:space="preserve" id="code_000434" smilref="Machine_Learning00009.smil#code_000434">StringBuilder</code><span class="text" id="span_001325" smilref="Machine_Learning00009.smil#span_001325"> class, the outgoing string is constructed and uses a pipe character (|) to separate the two values; the resulting string is then returned to the stream.</span></p>
              </level4>
              <level4 id="level4_000082">
                <h4 xml:space="preserve" id="h4_000082" smilref="Machine_Learning00009.smil#h4_000082">Writing the Application Context</h4>
                <p xml:space="preserve" id="p_000632"><span class="text" id="span_001326" smilref="Machine_Learning00009.smil#span_001326">Before you can deploy the processor code, you need to create the application context file so Spring XD can recognize the class you've created. Although the </span><pagenum epub:type="pagebreak" id="p212" page="normal" smilref="Machine_Learning00009.smil#p212">212</pagenum><span class="text" id="span_001327" smilref="Machine_Learning00009.smil#span_001327">XML file isn't deployed with the final </span><code xml:space="preserve" id="code_000435" smilref="Machine_Learning00009.smil#code_000435">jar</code><span class="text" id="span_001328" smilref="Machine_Learning00009.smil#span_001328"> file, it's worth creating the XML file within the project so everything is together while you are working on the development.</span></p>
                <p id="c09-c09-para-0114" xml:space="preserve"><span class="text" id="span_001329" smilref="Machine_Learning00009.smil#span_001329">Create a new file (using File →New →File) and call it </span><code xml:space="preserve" id="code_000436" smilref="Machine_Learning00009.smil#code_000436">twitterstreamtransformer.xml</code><span class="text" id="span_001330" smilref="Machine_Learning00009.smil#span_001330">. The file should be in the </span><code xml:space="preserve" id="code_000437" smilref="Machine_Learning00009.smil#code_000437">src/mlbook/chapter9/processor1</code><span class="text" id="span_001331" smilref="Machine_Learning00009.smil#span_001331"> directory under the </span><code xml:space="preserve" id="code_000438" smilref="Machine_Learning00009.smil#code_000438">XDTwitterProcessor</code><span class="text" id="span_001332" smilref="Machine_Learning00009.smil#span_001332"> project directory.</span></p>
                <p id="c09-c09-para-0115" xml:space="preserve" smilref="Machine_Learning00009.smil#c09-c09-para-0115">Add the XML markup and ensure that the start and closing tags are in place. Otherwise you'll have problems later when trying to deploy.</p>
                <p xml:space="preserve" id="p_000633"><code class="preserve-whitespace" xml:space="preserve" id="code_000439"><span class="text" id="span_001333" smilref="Machine_Learning00009.smil#span_001333">&lt;?xml version="</span><em id="em_000199" smilref="Machine_Learning00009.smil#em_000199">1</em><span class="text" id="span_001334" smilref="Machine_Learning00009.smil#span_001334">.</span><em id="em_000200" smilref="Machine_Learning00009.smil#em_000200">0</em><span class="text" id="span_001335" smilref="Machine_Learning00009.smil#span_001335">" encoding="</span><em id="em_000201" smilref="Machine_Learning00009.smil#em_000201">UTF</em><span class="text" id="span_001336" smilref="Machine_Learning00009.smil#span_001336">-</span><em id="em_000202" smilref="Machine_Learning00009.smil#em_000202">8</em><span class="text" id="span_001337" smilref="Machine_Learning00009.smil#span_001337">"?&gt;
&lt;beans:beans xmlns="</span><em id="em_000203" smilref="Machine_Learning00009.smil#em_000203">http</em><span class="text" id="span_001338" smilref="Machine_Learning00009.smil#span_001338">://</span><em id="em_000204" smilref="Machine_Learning00009.smil#em_000204">www</em><span class="text" id="span_001339" smilref="Machine_Learning00009.smil#span_001339">.</span><em id="em_000205" smilref="Machine_Learning00009.smil#em_000205">springframework</em><span class="text" id="span_001340" smilref="Machine_Learning00009.smil#span_001340">.</span><em id="em_000206" smilref="Machine_Learning00009.smil#em_000206">org</em><span class="text" id="span_001341" smilref="Machine_Learning00009.smil#span_001341">/</span><em id="em_000207" smilref="Machine_Learning00009.smil#em_000207">schema</em><span class="text" id="span_001342" smilref="Machine_Learning00009.smil#span_001342">/</span><em id="em_000208" smilref="Machine_Learning00009.smil#em_000208">integration</em><span class="text" id="span_001343" smilref="Machine_Learning00009.smil#span_001343">"
  xmlns:xsi="</span><em id="em_000209" smilref="Machine_Learning00009.smil#em_000209">http</em><span class="text" id="span_001344" smilref="Machine_Learning00009.smil#span_001344">://</span><em id="em_000210" smilref="Machine_Learning00009.smil#em_000210">www</em><span class="text" id="span_001345" smilref="Machine_Learning00009.smil#span_001345">.</span><em id="em_000211" smilref="Machine_Learning00009.smil#em_000211">w3</em><span class="text" id="span_001346" smilref="Machine_Learning00009.smil#span_001346">.</span><em id="em_000212" smilref="Machine_Learning00009.smil#em_000212">org</em><span class="text" id="span_001347" smilref="Machine_Learning00009.smil#span_001347">/</span><em id="em_000213" smilref="Machine_Learning00009.smil#em_000213">2001</em><span class="text" id="span_001348" smilref="Machine_Learning00009.smil#span_001348">/</span><em id="em_000214" smilref="Machine_Learning00009.smil#em_000214">XMLSchema</em><span class="text" id="span_001349" smilref="Machine_Learning00009.smil#span_001349">-</span><em id="em_000215" smilref="Machine_Learning00009.smil#em_000215">instance</em><span class="text" id="span_001350" smilref="Machine_Learning00009.smil#span_001350">"
  xmlns:beans="</span><em id="em_000216" smilref="Machine_Learning00009.smil#em_000216">http</em><span class="text" id="span_001351" smilref="Machine_Learning00009.smil#span_001351">://</span><em id="em_000217" smilref="Machine_Learning00009.smil#em_000217">www</em><span class="text" id="span_001352" smilref="Machine_Learning00009.smil#span_001352">.</span><em id="em_000218" smilref="Machine_Learning00009.smil#em_000218">springframework</em><span class="text" id="span_001353" smilref="Machine_Learning00009.smil#span_001353">.</span><em id="em_000219" smilref="Machine_Learning00009.smil#em_000219">org</em><span class="text" id="span_001354" smilref="Machine_Learning00009.smil#span_001354">/</span><em id="em_000220" smilref="Machine_Learning00009.smil#em_000220">schema</em><span class="text" id="span_001355" smilref="Machine_Learning00009.smil#span_001355">/</span><em id="em_000221" smilref="Machine_Learning00009.smil#em_000221">beans</em><span class="text" id="span_001356" smilref="Machine_Learning00009.smil#span_001356">"
  xsi:schemaLocation="</span><em id="em_000222" smilref="Machine_Learning00009.smil#em_000222">http</em><span class="text" id="span_001357" smilref="Machine_Learning00009.smil#span_001357">://</span><em id="em_000223" smilref="Machine_Learning00009.smil#em_000223">www</em><span class="text" id="span_001358" smilref="Machine_Learning00009.smil#span_001358">.</span><em id="em_000224" smilref="Machine_Learning00009.smil#em_000224">springframework</em><span class="text" id="span_001359" smilref="Machine_Learning00009.smil#span_001359">.</span><em id="em_000225" smilref="Machine_Learning00009.smil#em_000225">org</em><span class="text" id="span_001360" smilref="Machine_Learning00009.smil#span_001360">/</span><em id="em_000226" smilref="Machine_Learning00009.smil#em_000226">schema</em><span class="text" id="span_001361" smilref="Machine_Learning00009.smil#span_001361">/</span><em id="em_000227" smilref="Machine_Learning00009.smil#em_000227">beans</em>
    <em id="em_000228" smilref="Machine_Learning00009.smil#em_000228">http</em><span class="text" id="span_001362" smilref="Machine_Learning00009.smil#span_001362">://</span><em id="em_000229" smilref="Machine_Learning00009.smil#em_000229">www</em><span class="text" id="span_001363" smilref="Machine_Learning00009.smil#span_001363">.</span><em id="em_000230" smilref="Machine_Learning00009.smil#em_000230">springframework</em><span class="text" id="span_001364" smilref="Machine_Learning00009.smil#span_001364">.</span><em id="em_000231" smilref="Machine_Learning00009.smil#em_000231">org</em><span class="text" id="span_001365" smilref="Machine_Learning00009.smil#span_001365">/</span><em id="em_000232" smilref="Machine_Learning00009.smil#em_000232">schema</em><span class="text" id="span_001366" smilref="Machine_Learning00009.smil#span_001366">/</span><em id="em_000233" smilref="Machine_Learning00009.smil#em_000233">beans</em><span class="text" id="span_001367" smilref="Machine_Learning00009.smil#span_001367">/</span><em id="em_000234" smilref="Machine_Learning00009.smil#em_000234">spring</em><span class="text" id="span_001368" smilref="Machine_Learning00009.smil#span_001368">-</span><em id="em_000235" smilref="Machine_Learning00009.smil#em_000235">beans</em><span class="text" id="span_001369" smilref="Machine_Learning00009.smil#span_001369">.</span><em id="em_000236" smilref="Machine_Learning00009.smil#em_000236">xsd</em>
    <em id="em_000237" smilref="Machine_Learning00009.smil#em_000237">http</em><span class="text" id="span_001370" smilref="Machine_Learning00009.smil#span_001370">://</span><em id="em_000238" smilref="Machine_Learning00009.smil#em_000238">www</em><span class="text" id="span_001371" smilref="Machine_Learning00009.smil#span_001371">.</span><em id="em_000239" smilref="Machine_Learning00009.smil#em_000239">springframework</em><span class="text" id="span_001372" smilref="Machine_Learning00009.smil#span_001372">.</span><em id="em_000240" smilref="Machine_Learning00009.smil#em_000240">org</em><span class="text" id="span_001373" smilref="Machine_Learning00009.smil#span_001373">/</span><em id="em_000241" smilref="Machine_Learning00009.smil#em_000241">schema</em><span class="text" id="span_001374" smilref="Machine_Learning00009.smil#span_001374">/</span><em id="em_000242" smilref="Machine_Learning00009.smil#em_000242">integration</em>
    <em id="em_000243" smilref="Machine_Learning00009.smil#em_000243">http</em><span class="text" id="span_001375" smilref="Machine_Learning00009.smil#span_001375">://</span><em id="em_000244" smilref="Machine_Learning00010.smil#em_000244">www</em><span class="text" id="span_001376" smilref="Machine_Learning00010.smil#span_001376">.</span><em id="em_000245" smilref="Machine_Learning00010.smil#em_000245">springframework</em><span class="text" id="span_001377" smilref="Machine_Learning00010.smil#span_001377">.</span><em id="em_000246" smilref="Machine_Learning00010.smil#em_000246">org</em><span class="text" id="span_001378" smilref="Machine_Learning00010.smil#span_001378">/</span><em id="em_000247" smilref="Machine_Learning00010.smil#em_000247">schema</em><span class="text" id="span_001379" smilref="Machine_Learning00010.smil#span_001379">/</span><em id="em_000248" smilref="Machine_Learning00010.smil#em_000248">integration</em><span class="text" id="span_001380" smilref="Machine_Learning00010.smil#span_001380">/</span><em id="em_000249" smilref="Machine_Learning00010.smil#em_000249">spring</em><span class="text" id="span_001381" smilref="Machine_Learning00010.smil#span_001381">-</span><em id="em_000250" smilref="Machine_Learning00010.smil#em_000250">integration</em><span class="text" id="span_001382" smilref="Machine_Learning00010.smil#span_001382">.</span><em id="em_000251" smilref="Machine_Learning00010.smil#em_000251">xsd</em><span class="text" id="span_001383" smilref="Machine_Learning00010.smil#span_001383">"&gt;
  &lt;channel id="</span><em id="em_000252" smilref="Machine_Learning00010.smil#em_000252">input</em><span class="text" id="span_001384" smilref="Machine_Learning00010.smil#span_001384">"/&gt;
  &lt;transformer input-channel="</span><em id="em_000253" smilref="Machine_Learning00010.smil#em_000253">input</em><span class="text" id="span_001385" smilref="Machine_Learning00010.smil#span_001385">" output-channel="</span><em id="em_000254" smilref="Machine_Learning00010.smil#em_000254">output</em><span class="text" id="span_001386" smilref="Machine_Learning00010.smil#span_001386">"&gt;
    &lt;beans:bean class="</span><em id="em_000255" smilref="Machine_Learning00010.smil#em_000255">mlbook</em><span class="text" id="span_001387" smilref="Machine_Learning00010.smil#span_001387">.</span><em id="em_000256" smilref="Machine_Learning00010.smil#em_000256">chapter9</em><span class="text" id="span_001388" smilref="Machine_Learning00010.smil#span_001388">.</span><em id="em_000257" smilref="Machine_Learning00010.smil#em_000257">processor1</em><span class="text" id="span_001389" smilref="Machine_Learning00010.smil#span_001389">.</span><em id="em_000258" smilref="Machine_Learning00010.smil#em_000258">TwitterStreamTransform</em><span class="text" id="span_001390" smilref="Machine_Learning00010.smil#span_001390">"/&gt;
  &lt;/transformer&gt;
  &lt;channel id="</span><em id="em_000259" smilref="Machine_Learning00010.smil#em_000259">output</em><span class="text" id="span_001391" smilref="Machine_Learning00010.smil#span_001391">"/&gt;
&lt;/beans:beans&gt;</span></code></p>
                <p id="c09-c09-para-0116" xml:space="preserve"><span class="text" id="span_001392" smilref="Machine_Learning00010.smil#span_001392">Spring XD looks at the XML configuration and loads the specified </span><code xml:space="preserve" id="code_000440" smilref="Machine_Learning00010.smil#code_000440">bean</code><span class="text" id="span_001393" smilref="Machine_Learning00010.smil#span_001393"> class within the </span><code xml:space="preserve" id="code_000441" smilref="Machine_Learning00010.smil#code_000441">transformer</code><span class="text" id="span_001394" smilref="Machine_Learning00010.smil#span_001394"> tags. The filename of the XML file is the name that will be used in the stream definition. You'll see how it all fits when you test the processor module.</span></p>
              </level4>
              <level4 id="level4_000083">
                <h4 xml:space="preserve" id="h4_000083" smilref="Machine_Learning00010.smil#h4_000083">Exporting the jar File</h4>
                <p xml:space="preserve" id="p_000634"><span class="text" id="span_001395" smilref="Machine_Learning00010.smil#span_001395">The final step in the development process is to export the </span><code xml:space="preserve" id="code_000442" smilref="Machine_Learning00010.smil#code_000442">jar</code><span class="text" id="span_001396" smilref="Machine_Learning00010.smil#span_001396"> file. Within Eclipse it's a straightforward case of exporting the project. To export to a </span><code xml:space="preserve" id="code_000443" smilref="Machine_Learning00010.smil#code_000443">jar</code><span class="text" id="span_001397" smilref="Machine_Learning00010.smil#span_001397"> file, select File →Export and you see the Jar File option under the Java folder, as shown in </span><a id="c09-c09-fig-anc-0013" href="#c09-c09-fig-0013" external="false" smilref="Machine_Learning00010.smil#c09-c09-fig-anc-0013">Figure 9-13</a><span class="text" id="span_001398" smilref="Machine_Learning00010.smil#span_001398">.</span></p>
                <figure id="figure_000097">
                  <img class="center" src="images/c09f013.jpg" alt="image" id="img_000124" />
                  <figcaption id="figcaption_000083">
                    <p xml:space="preserve" id="p_000635"><span class="figureLabel" id="span_001399"><a id="c09-c09-fig-0013" href="#c09-c09-fig-anc-0013" external="false"><strong id="strong_000416" smilref="Machine_Learning00010.smil#strong_000416">Figure 9-13</strong></a></span><span class="text" id="span_001400" smilref="Machine_Learning00010.smil#span_001400"> Export selection dialog</span></p>
                  </figcaption>
                </figure>
                <p id="c09-c09-para-0118" xml:space="preserve"><span class="text" id="span_001401" smilref="Machine_Learning00010.smil#span_001401">Click the Next button, and you see the Jar File Specification panel. Ensure that you have the right project selected and that the Export All Output Folders for Checked Projects check box is selected. Give the </span><code xml:space="preserve" id="code_000444" smilref="Machine_Learning00010.smil#code_000444">jar</code><span class="text" id="span_001402" smilref="Machine_Learning00010.smil#span_001402"> file a name, such as </span><strong id="strong_000417" smilref="Machine_Learning00010.smil#strong_000417">XDTwitterProcessor</strong><span class="text" id="span_001403" smilref="Machine_Learning00010.smil#span_001403">. </span><pagenum epub:type="pagebreak" id="p213" page="normal" smilref="Machine_Learning00010.smil#p213">213</pagenum><span class="text" id="span_001404" smilref="Machine_Learning00010.smil#span_001404">Finally, select a target destination folder for your </span><code xml:space="preserve" id="code_000445" smilref="Machine_Learning00010.smil#code_000445">jar</code><span class="text" id="span_001405" smilref="Machine_Learning00010.smil#span_001405"> file and click Finish. (See </span><a id="c09-c09-fig-anc-0014" href="#c09-c09-fig-0014" external="false" smilref="Machine_Learning00010.smil#c09-c09-fig-anc-0014">Figure 9-14</a><span class="text" id="span_001406" smilref="Machine_Learning00010.smil#span_001406">.)</span></p>
                <figure id="figure_000098">
                  <img class="center" src="images/c09f014.jpg" alt="image" id="img_000125" />
                  <figcaption id="figcaption_000084">
                    <p xml:space="preserve" id="p_000636"><span class="figureLabel" id="span_001407"><a id="c09-c09-fig-0014" href="#c09-c09-fig-anc-0014" external="false"><strong id="strong_000418" smilref="Machine_Learning00010.smil#strong_000418">Figure 9-14</strong></a></span><span class="text" id="span_001408" smilref="Machine_Learning00010.smil#span_001408"> Jar file detail dialog</span></p>
                  </figcaption>
                </figure>
                <pagenum epub:type="pagebreak" id="p214" page="normal" smilref="Machine_Learning00010.smil#p214">214</pagenum>
                <p id="c09-c09-para-0119" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0119">The project is now complete. You've created a project with the processor module code and the required XML configuration for Spring XD. Next you'll deploy the project into Spring XD and test it.</p>
              </level4>
              <level4 id="level4_000084">
                <h4 xml:space="preserve" id="h4_000084" smilref="Machine_Learning00010.smil#h4_000084">Deploying the Project into Spring XD</h4>
                <p xml:space="preserve" id="p_000637" smilref="Machine_Learning00010.smil#p_000637">Before you can test your new module, you need to deploy it within Spring XD. If your Spring XD server is running, you need to shut it down, deploy the module, and then restart for your changes to take effect.</p>
                <p id="c09-c09-para-0121" xml:space="preserve"><span class="text" id="span_001409" smilref="Machine_Learning00010.smil#span_001409">First, copy the </span><code xml:space="preserve" id="code_000446" smilref="Machine_Learning00010.smil#code_000446">twitterstreamtransformer.xml</code><span class="text" id="span_001410" smilref="Machine_Learning00010.smil#span_001410"> file to the processor directory:</span></p>
                <p xml:space="preserve" id="p_000638"><code class="preserve-whitespace" xml:space="preserve" id="code_000447" smilref="Machine_Learning00010.smil#code_000447">cp ./twitterstreamtransformer.xml \ /usr/local/springxd/xd/modules/processor</code></p>
                <p id="c09-c09-para-0122" xml:space="preserve"><span class="text" id="span_001411" smilref="Machine_Learning00010.smil#span_001411">Next, copy the </span><code xml:space="preserve" id="code_000448" smilref="Machine_Learning00010.smil#code_000448">jar</code><span class="text" id="span_001412" smilref="Machine_Learning00010.smil#span_001412"> file you exported within Eclipse and copy that to the </span><code xml:space="preserve" id="code_000449" smilref="Machine_Learning00010.smil#code_000449">lib</code><span class="text" id="span_001413" smilref="Machine_Learning00010.smil#span_001413"> directory:</span></p>
                <p xml:space="preserve" id="p_000639"><code class="preserve-whitespace" xml:space="preserve" id="code_000450" smilref="Machine_Learning00010.smil#code_000450">cp ./twitterstreamtransformer.jar /usr/local/springxd/lib</code></p>
                <p id="c09-c09-para-0123" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0123">With those two files in place, you can restart your Spring XD server. Keep a close eye on the output while Spring XD initializes. If you see any exception traces, it's worth checking the XML context to see if it's well formed and the package and class names are correct.</p>
                <p id="c09-c09-para-0124" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0124">Assuming everything has deployed okay, you can test your new module.</p>
              </level4>
              <level4 id="level4_000085">
                <h4 xml:space="preserve" id="h4_000085" smilref="Machine_Learning00010.smil#h4_000085">Testing the New Processor Module</h4>
                <p xml:space="preserve" id="p_000640" smilref="Machine_Learning00010.smil#p_000640">Now it's time to see the fruits of your labor; after the development and the deployment comes the testing. The first thing you have to do is open a Spring XD shell. You'll create a new stream but you're going to include the new processor in the definition.</p>
                <p xml:space="preserve" id="p_000641"><code class="preserve-whitespace" xml:space="preserve" id="code_000451" smilref="Machine_Learning00010.smil#code_000451">xd:&gt;stream create -–name ttstest -–definition "twitterstream -–track='#fashion' | twitterstreamtransformer | file"</code></p>
                <p id="c09-c09-para-0126" xml:space="preserve"><span class="text" id="span_001414" smilref="Machine_Learning00010.smil#span_001414">Because you named the XML file </span><code xml:space="preserve" id="code_000452" smilref="Machine_Learning00010.smil#code_000452">twitterstreamtransformer.xml</code><span class="text" id="span_001415" smilref="Machine_Learning00010.smil#span_001415">, that's what Spring XD is expecting as the name of the processor in the stream. After the stream is created, go to your output directory and look at the text file.</span></p>
                <p xml:space="preserve" id="p_000642"><code class="preserve-whitespace" xml:space="preserve" id="code_000453" smilref="Machine_Learning00010.smil#code_000453">Sun Dec 29 19:35:54 +0000 2013|Sigue nuestro #blog y entérate de todas nuestras promociones y novedades http://t.co/b8v01LOHa8 #fashion #style http://t.co/YZfLj9myBf #moda
Sun Dec 29 19:35:55 +0000 2013|Leonardo DiCaprio Talks &lt;em&gt;Wolf&lt;/em&gt;'s Craziest Scenes http://t.co/8Si5zL0pMd #important #Jordan #movie #fashion
Sun Dec 29 19:35:58 +0000 2013|#fashion #design #styling #denim #sweatpants #hat #flannel #plaid #kibwe #sandal #birkenstock… http://t.co/Ij1ZjfM1Gs
Sun Dec 29 19:36:01 +0000 2013|http://t.co/YH4Z25C2YS Outfit of the Day #ootd #style #fashion #ootn #fbloggers http://t.co/mbviiwDUNz
Sun Dec 29 19:36:03 +0000 2013|Photo: #fashion #design #styling #denim #sweatpants #hat #flannel #plaid #kibwe #sandal #birkenstock… http://t.co/STRlQ4Llqw
Sun Dec 29 19:36:03 +0000 2013| @Argento_Fiore Awesome Silver Gemstone &amp; Shablool Jewelry #Fashion #Silver #Gemstone #Jewelry #Shop #eBay http://t.co/Ip3w8UQgPT
Sun Dec 29 19:36:06 +0000 2013|Artistic Custom Shoes - Wear Your Favorite Video Game Icons on Your Feet with These Video Game… http://t.co/zY4G8iN3qu #fashion #trends
Sun Dec 29 19:36:06 +0000 2013|Fabulous Find! It's on my mind &amp; it's on @eBay. #Style #Fashion #Deal http://t.co/Cx3Ne4vlm8
Sun Dec 29 19:36:09 +0000 2013|Los mejores #FashionFilm de las marcas de #Moda http://t.co/9ZIeG9Jcr8 #Fashion #Video
Sun Dec 29 19:36:10 +0000 2013|CONTEMPORARY ART http://t.co/YbhYv1btoo #luxury #home #decor #trending #style #elegant #interior #design #fashion #shopping #online #fb #g+
Sun Dec 29 19:36:13 +0000 2013|RT @SUNNIDAYZ: BIG ANNOUNCEMENT Coming soon from @athompsonii #Music #Sports #Film #Fashion http://t.co/cI4w8xelO6</code></p>
                <pagenum epub:type="pagebreak" id="p215" page="normal" smilref="Machine_Learning00010.smil#p215">215</pagenum>
                <p id="c09-c09-para-0127" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0127">The processor has achieved its aim by generating output for the tweet data and the text only. This sort of processor is useful for extracting what you need, but in this example you have sacrificed a little control in putting the required fields within the code.</p>
                <p id="c09-c09-para-0128" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0128">In the next example you start to add some analytics into the output by measuring the sentiment of the tweet text as it comes through and giving each tweet a score.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000077">
            <h2 id="c09-c09_level1_7" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09_level1_7">Real-Time Sentiment Analysis</h2>
            <p xml:space="preserve" id="p_000643"><span class="text" id="span_001416" smilref="Machine_Learning00010.smil#span_001416">One of the most common uses of machine learning with volumes of comment data is </span><em id="em_000260" smilref="Machine_Learning00010.smil#em_000260">sentiment analysis</em><span class="text" id="span_001417" smilref="Machine_Learning00010.smil#span_001417">. Twitter is the perfect platform for this sort of machine learning for the simple reason that the data is generated in volume and, depending on the tracked topics, the velocity can be high.</span></p>
            <p id="c09-c09-para-0130" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0130">There are a number of ways to perform sentiment analysis on text, but this second example concentrates on a simple point score on the polarity of the tweet by inspecting each word to see if it's positive or negative.</p>
            <level3 id="level3_000156">
              <h3 xml:space="preserve" id="h3_000156" smilref="Machine_Learning00010.smil#h3_000156">How the Basic Analysis Works</h3>
              <p xml:space="preserve" id="p_000644"><span class="text" id="span_001418" smilref="Machine_Learning00010.smil#span_001418">On its most basic level, sentiment analysis inspects words and, based on a list of positive and negative word lists, determines the score of the incoming string. It's </span><pagenum epub:type="pagebreak" id="p216" page="normal" smilref="Machine_Learning00010.smil#p216">216</pagenum><span class="text" id="span_001419" smilref="Machine_Learning00010.smil#span_001419">easy to implement, and for a lot of cases it works well. The longer the sentence the more accurate the sentiment score will be, so for very short tweets it might not give results.</span></p>
              <p id="c09-c09-para-0132" xml:space="preserve"><span class="text" id="span_001420" smilref="Machine_Learning00010.smil#span_001420">The word sets I'm using for this demonstration are free to use and were originally published by Bing Liu and Minqing Hu as part of their work on sentiment analysis and opinion mining at the University of Illinois. You can download the two data files from </span><code xml:space="preserve" id="code_000454"><a href="http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html" external="true" id="a_000301" smilref="Machine_Learning00010.smil#a_000301">www.cs.uic.edu/˜liub/FBS/sentiment-analysis.html</a></code><span class="text" id="span_001421" smilref="Machine_Learning00010.smil#span_001421">.</span></p>
              <p id="c09-c09-para-0133" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0133">Here are two examples of how the sentiment analysis works. Consider the following two sentences:</p>
              <list type="ul" id="list_000051">
                <li id="li_000388" smilref="Machine_Learning00010.smil#li_000388">“This is the best concert I've been to!”</li>
                <li id="li_000389" smilref="Machine_Learning00010.smil#li_000389">“That's bad, really bad, horrible!”</li>
              </list>
              <p id="c09-c09-para-0134" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0134">You can easily identify which is a positive statement and which is negative. For our two lexicons, you have to iterate the string and for each word see if it exists in the two lexicons. If it matches in the positive lexicon, then you add a point; likewise, you subtract a point if the word appears in the negative lexicon. After the string has been analyzed, the score is returned back.</p>
              <p id="c09-c09-para-0135" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0135">You can work out the scores for the two sentences:</p>
              <list type="ul" id="list_000052">
                <li id="li_000390">
                  <span class="text" id="span_001422" smilref="Machine_Learning00010.smil#span_001422">“This is the</span>
                  <strong id="strong_000419" smilref="Machine_Learning00010.smil#strong_000419">best</strong>
                  <span class="text" id="span_001423" smilref="Machine_Learning00010.smil#span_001423">concert I've been to!” = 1 (best)</span>
                </li>
                <li id="li_000391">
                  <span class="text" id="span_001424" smilref="Machine_Learning00010.smil#span_001424">“That's</span>
                  <strong id="strong_000420" smilref="Machine_Learning00010.smil#strong_000420">bad</strong>
                  <span class="text" id="span_001425" smilref="Machine_Learning00010.smil#span_001425">, really</span>
                  <strong id="strong_000421" smilref="Machine_Learning00010.smil#strong_000421">bad</strong>
                  <span class="text" id="span_001426" smilref="Machine_Learning00010.smil#span_001426">,</span>
                  <strong id="strong_000422" smilref="Machine_Learning00010.smil#strong_000422">horrible</strong>
                  <span class="text" id="span_001427" smilref="Machine_Learning00010.smil#span_001427">” = -3 (bad, bad, horrible)</span>
                </li>
              </list>
              <p id="c09-c09-para-0136" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0136">Most of the time this method works out okay, but there are some caveats you should keep in mind. Especially with Twitter data, you can never tell if a user will abbreviate or compact certain words to save space (a tweet is only 140 characters, after all). Also, this sort of analysis does not take into account false interpretations. In some local colloquialisms, it's not uncommon for seemingly negative words to be used in a positive context, and some tweets are sarcastic.</p>
              <p id="c09-c09-para-0137" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0137">For example, “That new Rihanna album is bad!” Is that a positive review or a negative one? This is where some domain knowledge of the types of subject you are dealing with comes in very helpful; you can adjust the lexicons for context if required.</p>
              <sidebar render="required" id="sidebar_000012">
                <div class="top hr" id="div_000012" />
                <level2 class="feature1" id="level2_000078">
                  <h2 xml:space="preserve" id="h2_000016" smilref="Machine_Learning00010.smil#h2_000016">A Note About Twitter Data</h2>
                  <p xml:space="preserve" id="p_000645" smilref="Machine_Learning00010.smil#p_000645">Before you start the next project, it's worth having a quick discussion about the nature of the data you're going to use. If you use Twitter regularly, you know that there's no easy route to working on tweets. The data quality is poor—”noisy”—and requires extensive “cleaning” before simple, straightforward analysis can be performed.</p>
                  <p xml:space="preserve" id="p_000646" smilref="Machine_Learning00010.smil#p_000646">The two lexicons provide positive and negative words in lowercase. The Liu and Hu collection includes the most common misspellings of certain words, because misspellings are very common in online media. You might want to add some of your own words to the lexicons for your own purposes.</p>
                  <pagenum epub:type="pagebreak" id="p217" page="normal" smilref="Machine_Learning00010.smil#p217">217</pagenum>
                  <p xml:space="preserve" id="p_000647" smilref="Machine_Learning00010.smil#p_000647">For the example given here, I'm removing the hash symbol (#) from tweets, because there are no hashtags in the lexicons, and also removing the @ sign from Twitter usernames. I'm also converting the whole string to lowercase for simpler, direct comparison to the list of words in the lexicons. The alternative would be to transform some alternatives of words to lowercase for comparison to the words in the lexicon. You might want to collapse some variations of a word to a canonical form for sentiment word list comparison but not other variations. I'm not adding any “sanity” filters or other cleanup to the stream.</p>
                </level2>
              </sidebar>
            </level3>
            <level3 id="level3_000157">
              <h3 xml:space="preserve" id="h3_000157" smilref="Machine_Learning00010.smil#h3_000157">Creating a Sentiment Processor</h3>
              <p xml:space="preserve" id="p_000648" smilref="Machine_Learning00010.smil#p_000648">Because you have a project with a processor module created, it makes sense to create the new sentiment processor in there. The steps are the same as before; create a new Java class and application context file.</p>
              <p id="c09-c09-para-0142" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0142">The process flow for this new class is fairly easy to understand. You load the positive and negative word lists and then read the incoming payload in the same way as the first project extracted the created date and the text of the tweet. Then you plug in the new processes, namely cleaning up the tweet text the best you can and calculating the sentiment score. Finally, you return the date, tweet, and score as a string.</p>
              <level4 id="level4_000086">
                <h4 xml:space="preserve" id="h4_000086" smilref="Machine_Learning00010.smil#h4_000086">Writing the Code</h4>
                <p xml:space="preserve" id="p_000649" smilref="Machine_Learning00010.smil#p_000649">Before you start, make a careful note of where the two lexicon text files are, because you'll be referring to the file paths in the code. If Spring XD can't find the text files while initializing the processor, then all your sentiment scores will be zero. It's worth keeping a close eye on the server log output while testing.</p>
                <p id="c09-c09-para-0144" xml:space="preserve"><span class="text" id="span_001428" smilref="Machine_Learning00010.smil#span_001428">With that in mind, it's time to get started. Create a new package and call it </span><strong id="strong_000423" smilref="Machine_Learning00010.smil#strong_000423">mlbook.chapter9.processor2</strong><span class="text" id="span_001429" smilref="Machine_Learning00010.smil#span_001429"> (File →New → Package).</span></p>
                <p id="c09-c09-para-0145" xml:space="preserve"><span class="text" id="span_001430" smilref="Machine_Learning00010.smil#span_001430">Next, create a new Java class and call it </span><strong id="strong_000424" smilref="Machine_Learning00010.smil#strong_000424">SentimentTweetScore</strong><span class="text" id="span_001431" smilref="Machine_Learning00010.smil#span_001431"> (File →New →Class). The code will resemble the same structure as the first processor you worked on, but this time the sentiment score will be a little more involved.</span></p>
                <p id="c09-c09-para-0146" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0146">Here's the code:</p>
                <p xml:space="preserve" id="p_000650"><code class="preserve-whitespace" xml:space="preserve" id="code_000455"><strong id="strong_000425" smilref="Machine_Learning00010.smil#strong_000425">package</strong><span class="text" id="span_001432" smilref="Machine_Learning00010.smil#span_001432"> mlbook.chapter9.processor2;
</span><strong id="strong_000426" smilref="Machine_Learning00010.smil#strong_000426">import</strong><span class="text" id="span_001433" smilref="Machine_Learning00010.smil#span_001433"> java.io.BufferedReader;
</span><strong id="strong_000427" smilref="Machine_Learning00010.smil#strong_000427">import</strong><span class="text" id="span_001434" smilref="Machine_Learning00010.smil#span_001434"> java.io.FileReader;
</span><strong id="strong_000428" smilref="Machine_Learning00010.smil#strong_000428">import</strong><span class="text" id="span_001435" smilref="Machine_Learning00010.smil#span_001435"> java.io.IOException;
</span><strong id="strong_000429" smilref="Machine_Learning00010.smil#strong_000429">import</strong><span class="text" id="span_001436" smilref="Machine_Learning00010.smil#span_001436"> java.util.HashSet;
</span><strong id="strong_000430" smilref="Machine_Learning00010.smil#strong_000430">import</strong><span class="text" id="span_001437" smilref="Machine_Learning00010.smil#span_001437"> java.util.Map;
</span><strong id="strong_000431" smilref="Machine_Learning00010.smil#strong_000431">import</strong><span class="text" id="span_001438" smilref="Machine_Learning00010.smil#span_001438"> java.util.Set;
</span><strong id="strong_000432"><span class="text" id="span_001439" smilref="Machine_Learning00010.smil#span_001439">import</span><pagenum epub:type="pagebreak" id="p218" page="normal" smilref="Machine_Learning00010.smil#p218">218</pagenum></strong><span class="text" id="span_001440" smilref="Machine_Learning00010.smil#span_001440"> java.util.StringTokenizer;
</span><strong id="strong_000433" smilref="Machine_Learning00010.smil#strong_000433">import</strong><span class="text" id="span_001441" smilref="Machine_Learning00010.smil#span_001441"> org.codehaus.jackson.map.ObjectMapper;
</span><strong id="strong_000434" smilref="Machine_Learning00010.smil#strong_000434">import</strong><span class="text" id="span_001442" smilref="Machine_Learning00010.smil#span_001442"> org.codehaus.jackson.type.TypeReference;
</span><strong id="strong_000435" smilref="Machine_Learning00010.smil#strong_000435">import</strong><span class="text" id="span_001443" smilref="Machine_Learning00010.smil#span_001443"> org.springframework.integration.transformer.MessageTransformationException;
</span><strong id="strong_000436" smilref="Machine_Learning00010.smil#strong_000436">public</strong> <strong id="strong_000437" smilref="Machine_Learning00010.smil#strong_000437">class</strong><span class="text" id="span_001444" smilref="Machine_Learning00010.smil#span_001444"> SentimentScoreTransform {
    </span><strong id="strong_000438" smilref="Machine_Learning00010.smil#strong_000438">private</strong><span class="text" id="span_001445" smilref="Machine_Learning00010.smil#span_001445"> Set&lt;String&gt; poswords = </span><strong id="strong_000439" smilref="Machine_Learning00010.smil#strong_000439">new</strong><span class="text" id="span_001446" smilref="Machine_Learning00010.smil#span_001446"> HashSet&lt;String&gt;();
    </span><strong id="strong_000440" smilref="Machine_Learning00010.smil#strong_000440">private</strong><span class="text" id="span_001447" smilref="Machine_Learning00010.smil#span_001447"> Set&lt;String&gt; negwords = </span><strong id="strong_000441" smilref="Machine_Learning00010.smil#strong_000441">new</strong><span class="text" id="span_001448" smilref="Machine_Learning00010.smil#span_001448"> HashSet&lt;String&gt;();
    </span><strong id="strong_000442" smilref="Machine_Learning00010.smil#strong_000442">public</strong><span class="text" id="span_001449" smilref="Machine_Learning00010.smil#span_001449"> SentimentScoreTransform() {
        loadWords("/usr/local/springxd/pos-words.txt", poswords);
        loadWords("/usr/local/springxd/neg-words.txt", negwords);
    }
    </span><strong id="strong_000443" smilref="Machine_Learning00010.smil#strong_000443">private</strong><span class="text" id="span_001450" smilref="Machine_Learning00010.smil#span_001450"> ObjectMapper mapper = </span><strong id="strong_000444" smilref="Machine_Learning00010.smil#strong_000444">new</strong><span class="text" id="span_001451" smilref="Machine_Learning00010.smil#span_001451"> ObjectMapper();
    </span><strong id="strong_000445" smilref="Machine_Learning00010.smil#strong_000445">public</strong><span class="text" id="span_001452" smilref="Machine_Learning00010.smil#span_001452"> String transform(String payload) {
        </span><strong id="strong_000446" smilref="Machine_Learning00010.smil#strong_000446">try</strong><span class="text" id="span_001453" smilref="Machine_Learning00010.smil#span_001453"> {
            StringBuilder sb = </span><strong id="strong_000447" smilref="Machine_Learning00010.smil#strong_000447">new</strong><span class="text" id="span_001454" smilref="Machine_Learning00010.smil#span_001454"> StringBuilder();
            Map&lt;String, Object&gt; tweet = mapper.readValue(payload,</span><strong id="strong_000448" smilref="Machine_Learning00010.smil#strong_000448">new</strong><span class="text" id="span_001455" smilref="Machine_Learning00010.smil#span_001455"> TypeReference&lt;Map&lt;String, Object&gt;&gt;() {});
            sb.append(tweet.get("created_at").toString());
            sb.append("|");
            sb.append(tweet.get("text").toString());
            sb.append("|");
            sb.append(scoreTweet(tweet.get("text").toString()));
            </span><strong id="strong_000449" smilref="Machine_Learning00010.smil#strong_000449">return</strong><span class="text" id="span_001456" smilref="Machine_Learning00010.smil#span_001456"> sb.toString();
        } </span><strong id="strong_000450" smilref="Machine_Learning00010.smil#strong_000450">catch</strong><span class="text" id="span_001457" smilref="Machine_Learning00010.smil#span_001457"> (IOException e) {
            </span><strong id="strong_000451" smilref="Machine_Learning00010.smil#strong_000451">throw</strong> <strong id="strong_000452" smilref="Machine_Learning00010.smil#strong_000452">new</strong><span class="text" id="span_001458" smilref="Machine_Learning00010.smil#span_001458"> MessageTransformationException(
                    "[MLBook] - Cannot work on this tweet: " + e.getMessage(), e);
        }
    }
    </span><strong id="strong_000453" smilref="Machine_Learning00010.smil#strong_000453">private</strong> <strong id="strong_000454" smilref="Machine_Learning00010.smil#strong_000454">void</strong><span class="text" id="span_001459" smilref="Machine_Learning00010.smil#span_001459"> loadWords(String filepath, Set&lt;String&gt; set) {
        </span><strong id="strong_000455" smilref="Machine_Learning00010.smil#strong_000455">try</strong><span class="text" id="span_001460" smilref="Machine_Learning00010.smil#span_001460"> {
            BufferedReader in = </span><strong id="strong_000456" smilref="Machine_Learning00010.smil#strong_000456">new</strong><span class="text" id="span_001461" smilref="Machine_Learning00010.smil#span_001461"> BufferedReader(</span><strong id="strong_000457" smilref="Machine_Learning00010.smil#strong_000457">new</strong><span class="text" id="span_001462" smilref="Machine_Learning00010.smil#span_001462"> FileReader(filepath));
            String str;
            </span><strong id="strong_000458" smilref="Machine_Learning00010.smil#strong_000458">while</strong><span class="text" id="span_001463" smilref="Machine_Learning00010.smil#span_001463"> ((str = in.readLine()) != </span><strong id="strong_000459" smilref="Machine_Learning00010.smil#strong_000459">null</strong><span class="text" id="span_001464" smilref="Machine_Learning00010.smil#span_001464">) {
                set.add(str);
            }
            in.close();
        } </span><strong id="strong_000460" smilref="Machine_Learning00010.smil#strong_000460">catch</strong><span class="text" id="span_001465" smilref="Machine_Learning00010.smil#span_001465"> (IOException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000461" smilref="Machine_Learning00010.smil#strong_000461">private</strong><span class="text" id="span_001466" smilref="Machine_Learning00010.smil#span_001466"> String cleanTweet(String tweet) {
        tweet = tweet.replaceAll("#", "");
        tweet = tweet.replaceAll("@", "");
        </span><strong id="strong_000462" smilref="Machine_Learning00010.smil#strong_000462">return</strong><span class="text" id="span_001467" smilref="Machine_Learning00010.smil#span_001467"> tweet.toLowerCase();
    }
    </span><strong id="strong_000463" smilref="Machine_Learning00010.smil#strong_000463">private</strong> <strong id="strong_000464" smilref="Machine_Learning00010.smil#strong_000464">int</strong><span class="text" id="span_001468" smilref="Machine_Learning00010.smil#span_001468"> scoreTweet(String tweet) {
        </span><strong id="strong_000465" smilref="Machine_Learning00010.smil#strong_000465">int</strong><span class="text" id="span_001469" smilref="Machine_Learning00010.smil#span_001469"> score = 0;
        StringTokenizer st = </span><strong id="strong_000466" smilref="Machine_Learning00010.smil#strong_000466">new</strong><span class="text" id="span_001470" smilref="Machine_Learning00010.smil#span_001470"> StringTokenizer(cleanTweet(tweet));
        String thisToken;
        </span><strong id="strong_000467" smilref="Machine_Learning00010.smil#strong_000467">while</strong><span class="text" id="span_001471" smilref="Machine_Learning00010.smil#span_001471">(st.hasMoreTokens()){
            thisToken = st.nextToken();
            </span><strong id="strong_000468" smilref="Machine_Learning00010.smil#strong_000468">if</strong><span class="text" id="span_001472" smilref="Machine_Learning00010.smil#span_001472">(poswords.contains(thisToken)) {
                score = score + 1;
            } </span><strong id="strong_000469" smilref="Machine_Learning00010.smil#strong_000469">else</strong> <strong id="strong_000470" smilref="Machine_Learning00010.smil#strong_000470">if</strong><span class="text" id="span_001473" smilref="Machine_Learning00010.smil#span_001473">(negwords.contains(thisToken)){
                score = score - 1;
            }
        }
        </span><strong id="strong_000471" smilref="Machine_Learning00010.smil#strong_000471">return</strong><span class="text" id="span_001474" smilref="Machine_Learning00010.smil#span_001474"> score;
    }
 }</span></code></p>
                <pagenum epub:type="pagebreak" id="p219" page="normal" smilref="Machine_Learning00010.smil#p219">219</pagenum>
                <p id="c09-c09-para-0147" xml:space="preserve"><span class="text" id="span_001475" smilref="Machine_Learning00010.smil#span_001475">When the class is first requested within a stream definition, Spring XD loads the class and loads the positive and negative word lexicons, storing each in its respective HashSet; this is handled by the </span><code xml:space="preserve" id="code_000456" smilref="Machine_Learning00010.smil#code_000456">loadWords</code><span class="text" id="span_001476" smilref="Machine_Learning00010.smil#span_001476"> method. Once again, you're using the Jackson JSON parser to extract the elements of the tweet you require (the date and the tweet text) but adding another part to the outgoing string: a sentiment score.</span></p>
                <p id="c09-c09-para-0148" xml:space="preserve"><span class="text" id="span_001477" smilref="Machine_Learning00010.smil#span_001477">The </span><code xml:space="preserve" id="code_000457" smilref="Machine_Learning00010.smil#code_000457">scoreTweet</code><span class="text" id="span_001478" smilref="Machine_Learning00010.smil#span_001478"> method takes the tweet text and passes it to the </span><code xml:space="preserve" id="code_000458" smilref="Machine_Learning00010.smil#code_000458">cleanTweet</code><span class="text" id="span_001479" smilref="Machine_Learning00010.smil#span_001479"> method that removes the # and @ symbols. The </span><code xml:space="preserve" id="code_000459" smilref="Machine_Learning00010.smil#code_000459">StringTokenizer</code><span class="text" id="span_001480" smilref="Machine_Learning00010.smil#span_001480"> class splits up the string by using a space as its delimiter. Iterating over each token, you check against both lexicons and, if a positive word appears, you increment the score by one point; you deduct a point if the word appears in the negative word list.</span></p>
                <p id="c09-c09-para-0149" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0149">Finally the score is written to the end of the outgoing string and sent to the stream.</p>
              </level4>
              <level4 id="level4_000087">
                <h4 xml:space="preserve" id="h4_000087" smilref="Machine_Learning00010.smil#h4_000087">Creating the Application Context</h4>
                <p xml:space="preserve" id="p_000651"><span class="text" id="span_001481" smilref="Machine_Learning00010.smil#span_001481">Each processor module requires its own application context, even if the class files required are in the same </span><code xml:space="preserve" id="code_000460" smilref="Machine_Learning00010.smil#code_000460">jar</code><span class="text" id="span_001482" smilref="Machine_Learning00010.smil#span_001482"> file as the XML configuration. Create a new XML file called </span><strong id="strong_000472" smilref="Machine_Learning00010.smil#strong_000472">sentimenttransformer.xml</strong><span class="text" id="span_001483" smilref="Machine_Learning00010.smil#span_001483"> (using File →New →File) and use the following XML definition:</span></p>
                <p xml:space="preserve" id="p_000652"><code class="preserve-whitespace" xml:space="preserve" id="code_000461"><span class="text" id="span_001484" smilref="Machine_Learning00010.smil#span_001484">&lt;?xml version="</span><em id="em_000261" smilref="Machine_Learning00010.smil#em_000261">1</em><span class="text" id="span_001485" smilref="Machine_Learning00010.smil#span_001485">.</span><em id="em_000262" smilref="Machine_Learning00010.smil#em_000262">0</em><span class="text" id="span_001486" smilref="Machine_Learning00010.smil#span_001486">" encoding="</span><em id="em_000263" smilref="Machine_Learning00010.smil#em_000263">UTF</em><span class="text" id="span_001487" smilref="Machine_Learning00010.smil#span_001487">-</span><em id="em_000264" smilref="Machine_Learning00010.smil#em_000264">8</em><span class="text" id="span_001488" smilref="Machine_Learning00010.smil#span_001488">"?&gt;
&lt;beans:beans xmlns="</span><em id="em_000265" smilref="Machine_Learning00010.smil#em_000265">http</em><span class="text" id="span_001489" smilref="Machine_Learning00010.smil#span_001489">://</span><em id="em_000266" smilref="Machine_Learning00010.smil#em_000266">www</em><span class="text" id="span_001490" smilref="Machine_Learning00010.smil#span_001490">.</span><em id="em_000267" smilref="Machine_Learning00010.smil#em_000267">springframework</em><span class="text" id="span_001491" smilref="Machine_Learning00010.smil#span_001491">.</span><em id="em_000268" smilref="Machine_Learning00010.smil#em_000268">org</em><span class="text" id="span_001492" smilref="Machine_Learning00010.smil#span_001492">/</span><em id="em_000269" smilref="Machine_Learning00010.smil#em_000269">schema</em><span class="text" id="span_001493" smilref="Machine_Learning00010.smil#span_001493">/</span><em id="em_000270" smilref="Machine_Learning00010.smil#em_000270">integration</em><span class="text" id="span_001494" smilref="Machine_Learning00010.smil#span_001494">"
  xmlns:xsi="</span><em id="em_000271" smilref="Machine_Learning00010.smil#em_000271">http</em><span class="text" id="span_001495" smilref="Machine_Learning00010.smil#span_001495">://</span><em id="em_000272" smilref="Machine_Learning00010.smil#em_000272">www</em><span class="text" id="span_001496" smilref="Machine_Learning00010.smil#span_001496">.</span><em id="em_000273" smilref="Machine_Learning00010.smil#em_000273">w3</em><span class="text" id="span_001497" smilref="Machine_Learning00010.smil#span_001497">.</span><em id="em_000274" smilref="Machine_Learning00010.smil#em_000274">org</em><span class="text" id="span_001498" smilref="Machine_Learning00010.smil#span_001498">/</span><em id="em_000275" smilref="Machine_Learning00010.smil#em_000275">2001</em><span class="text" id="span_001499" smilref="Machine_Learning00010.smil#span_001499">/</span><em id="em_000276" smilref="Machine_Learning00010.smil#em_000276">XMLSchema</em><span class="text" id="span_001500" smilref="Machine_Learning00010.smil#span_001500">-</span><em id="em_000277" smilref="Machine_Learning00010.smil#em_000277">instance</em><span class="text" id="span_001501" smilref="Machine_Learning00010.smil#span_001501">"
  xmlns:beans="</span><em id="em_000278" smilref="Machine_Learning00010.smil#em_000278">http</em><span class="text" id="span_001502" smilref="Machine_Learning00010.smil#span_001502">://</span><em id="em_000279" smilref="Machine_Learning00010.smil#em_000279">www</em><span class="text" id="span_001503" smilref="Machine_Learning00010.smil#span_001503">.</span><em id="em_000280" smilref="Machine_Learning00010.smil#em_000280">springframework</em><span class="text" id="span_001504" smilref="Machine_Learning00010.smil#span_001504">.</span><em id="em_000281" smilref="Machine_Learning00010.smil#em_000281">org</em><span class="text" id="span_001505" smilref="Machine_Learning00010.smil#span_001505">/</span><em id="em_000282" smilref="Machine_Learning00010.smil#em_000282">schema</em><span class="text" id="span_001506" smilref="Machine_Learning00010.smil#span_001506">/</span><em id="em_000283" smilref="Machine_Learning00010.smil#em_000283">beans</em><span class="text" id="span_001507" smilref="Machine_Learning00010.smil#span_001507">"
  xsi:schemaLocation="</span><em id="em_000284" smilref="Machine_Learning00010.smil#em_000284">http</em><span class="text" id="span_001508" smilref="Machine_Learning00010.smil#span_001508">://</span><em id="em_000285" smilref="Machine_Learning00010.smil#em_000285">www</em><span class="text" id="span_001509" smilref="Machine_Learning00010.smil#span_001509">.</span><em id="em_000286" smilref="Machine_Learning00010.smil#em_000286">springframework</em><span class="text" id="span_001510" smilref="Machine_Learning00010.smil#span_001510">.</span><em id="em_000287" smilref="Machine_Learning00010.smil#em_000287">org</em><span class="text" id="span_001511" smilref="Machine_Learning00010.smil#span_001511">/</span><em id="em_000288" smilref="Machine_Learning00010.smil#em_000288">schema</em><span class="text" id="span_001512" smilref="Machine_Learning00010.smil#span_001512">/</span><em id="em_000289" smilref="Machine_Learning00010.smil#em_000289">beans</em>
    <em id="em_000290" smilref="Machine_Learning00010.smil#em_000290">http</em><span class="text" id="span_001513" smilref="Machine_Learning00010.smil#span_001513">://</span><em id="em_000291" smilref="Machine_Learning00010.smil#em_000291">www</em><span class="text" id="span_001514" smilref="Machine_Learning00010.smil#span_001514">.</span><em id="em_000292" smilref="Machine_Learning00010.smil#em_000292">springframework</em><span class="text" id="span_001515" smilref="Machine_Learning00010.smil#span_001515">.</span><em id="em_000293" smilref="Machine_Learning00010.smil#em_000293">org</em><span class="text" id="span_001516" smilref="Machine_Learning00010.smil#span_001516">/</span><em id="em_000294" smilref="Machine_Learning00010.smil#em_000294">schema</em><span class="text" id="span_001517" smilref="Machine_Learning00010.smil#span_001517">/</span><em id="em_000295" smilref="Machine_Learning00010.smil#em_000295">beans</em><span class="text" id="span_001518" smilref="Machine_Learning00010.smil#span_001518">/</span><em id="em_000296" smilref="Machine_Learning00010.smil#em_000296">spring</em><span class="text" id="span_001519" smilref="Machine_Learning00010.smil#span_001519">-</span><em id="em_000297" smilref="Machine_Learning00010.smil#em_000297">beans</em><span class="text" id="span_001520" smilref="Machine_Learning00010.smil#span_001520">.</span><em id="em_000298" smilref="Machine_Learning00010.smil#em_000298">xsd</em>
    <em id="em_000299" smilref="Machine_Learning00010.smil#em_000299">http</em><span class="text" id="span_001521" smilref="Machine_Learning00010.smil#span_001521">://</span><em id="em_000300" smilref="Machine_Learning00010.smil#em_000300">www</em><span class="text" id="span_001522" smilref="Machine_Learning00010.smil#span_001522">.</span><em id="em_000301" smilref="Machine_Learning00010.smil#em_000301">springframework</em><span class="text" id="span_001523" smilref="Machine_Learning00010.smil#span_001523">.</span><em id="em_000302" smilref="Machine_Learning00010.smil#em_000302">org</em><span class="text" id="span_001524" smilref="Machine_Learning00010.smil#span_001524">/</span><em id="em_000303" smilref="Machine_Learning00010.smil#em_000303">schema</em><span class="text" id="span_001525" smilref="Machine_Learning00010.smil#span_001525">/</span><em id="em_000304" smilref="Machine_Learning00010.smil#em_000304">integration</em>
    <em id="em_000305" smilref="Machine_Learning00010.smil#em_000305">http</em><span class="text" id="span_001526" smilref="Machine_Learning00010.smil#span_001526">://</span><em id="em_000306" smilref="Machine_Learning00010.smil#em_000306">www</em><span class="text" id="span_001527" smilref="Machine_Learning00010.smil#span_001527">.</span><em id="em_000307" smilref="Machine_Learning00010.smil#em_000307">springframework</em><span class="text" id="span_001528" smilref="Machine_Learning00010.smil#span_001528">.</span><em id="em_000308" smilref="Machine_Learning00010.smil#em_000308">org</em><span class="text" id="span_001529" smilref="Machine_Learning00010.smil#span_001529">/</span><em id="em_000309" smilref="Machine_Learning00010.smil#em_000309">schema</em><span class="text" id="span_001530" smilref="Machine_Learning00010.smil#span_001530">/</span><em id="em_000310" smilref="Machine_Learning00010.smil#em_000310">integration</em><span class="text" id="span_001531" smilref="Machine_Learning00010.smil#span_001531">/</span><em id="em_000311" smilref="Machine_Learning00010.smil#em_000311">spring</em><span class="text" id="span_001532" smilref="Machine_Learning00010.smil#span_001532">-</span><em id="em_000312" smilref="Machine_Learning00010.smil#em_000312">integration</em><span class="text" id="span_001533" smilref="Machine_Learning00010.smil#span_001533">.</span><em id="em_000313" smilref="Machine_Learning00010.smil#em_000313">xsd</em><span class="text" id="span_001534" smilref="Machine_Learning00010.smil#span_001534">"&gt;
  &lt;channel id="</span><em id="em_000314" smilref="Machine_Learning00010.smil#em_000314">input</em><span class="text" id="span_001535" smilref="Machine_Learning00010.smil#span_001535">"/&gt;
  &lt;transformer input-channel="</span><em id="em_000315" smilref="Machine_Learning00010.smil#em_000315">input</em><span class="text" id="span_001536" smilref="Machine_Learning00010.smil#span_001536">" output-channel="</span><em id="em_000316" smilref="Machine_Learning00010.smil#em_000316">output</em><span class="text" id="span_001537" smilref="Machine_Learning00010.smil#span_001537">"&gt;
    &lt;beans:bean class="</span><em id="em_000317" smilref="Machine_Learning00010.smil#em_000317">mlbook</em><span class="text" id="span_001538" smilref="Machine_Learning00010.smil#span_001538">.</span><em id="em_000318" smilref="Machine_Learning00010.smil#em_000318">chapter9</em><span class="text" id="span_001539" smilref="Machine_Learning00010.smil#span_001539">.</span><em id="em_000319" smilref="Machine_Learning00010.smil#em_000319">processor2</em><span class="text" id="span_001540" smilref="Machine_Learning00010.smil#span_001540">.</span><em id="em_000320" smilref="Machine_Learning00010.smil#em_000320">SentimentScoreTransform</em><span class="text" id="span_001541" smilref="Machine_Learning00010.smil#span_001541">"/&gt;
  &lt;/transformer&gt;
  &lt;channel id="</span><em id="em_000321" smilref="Machine_Learning00010.smil#em_000321">output</em><span class="text" id="span_001542" smilref="Machine_Learning00010.smil#span_001542">"/&gt;
&lt;/beans:beans&gt;</span></code></p>
                <pagenum epub:type="pagebreak" id="p220" page="normal" smilref="Machine_Learning00010.smil#p220">220</pagenum>
                <p id="c09-c09-para-0151" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0151">The XML content is identical to the first processor you wrote except the package and class name have changed.</p>
              </level4>
              <level4 id="level4_000088">
                <h4 xml:space="preserve" id="h4_000088" smilref="Machine_Learning00010.smil#h4_000088">Packaging, Deploying, and Testing</h4>
                <p xml:space="preserve" id="p_000653"><span class="text" id="span_001543" smilref="Machine_Learning00010.smil#span_001543">You have to export the </span><code xml:space="preserve" id="code_000462" smilref="Machine_Learning00010.smil#code_000462">jar</code><span class="text" id="span_001544" smilref="Machine_Learning00010.smil#span_001544"> file again, so it includes the newly created class file for the sentiment scoring (use File →Export in Eclipse). Copy the </span><code xml:space="preserve" id="code_000463" smilref="Machine_Learning00010.smil#code_000463">jar</code><span class="text" id="span_001545" smilref="Machine_Learning00010.smil#span_001545"> file to the </span><code xml:space="preserve" id="code_000464" smilref="Machine_Learning00010.smil#code_000464">lib</code><span class="text" id="span_001546" smilref="Machine_Learning00010.smil#span_001546"> directory of your Spring XD distribution and also copy the new XML application context file to the module/processor directory.</span></p>
                <p xml:space="preserve" id="p_000654"><code class="preserve-whitespace" xml:space="preserve" id="code_000465" smilref="Machine_Learning00010.smil#code_000465">
$ cp sentimenttransformer.xml /path/to/springxd/xd/modules/processor
$ cp sentimenttransformer.jar /path/to/springxd/xd/modules/processor
</code></p>
                <p id="c09-c09-para-0153" xml:space="preserve"><span class="text" id="span_001547" smilref="Machine_Learning00010.smil#span_001547">For the new files to take effect you have to restart Spring XD. To test the new processor, all you have to do is create a new stream with the </span><code xml:space="preserve" id="code_000466" smilref="Machine_Learning00010.smil#code_000466">sentimenttransformer</code><span class="text" id="span_001548" smilref="Machine_Learning00010.smil#span_001548"> declaration:</span></p>
                <p xml:space="preserve" id="p_000655"><code class="preserve-whitespace" xml:space="preserve" id="code_000467" smilref="Machine_Learning00010.smil#code_000467">
xd:&gt;stream create --name sentimenttest --definition "twitterstream --track='#fashion' | sentimenttransformer | file"
</code></p>
                <p id="c09-c09-para-0154" xml:space="preserve"><span class="text" id="span_001549" smilref="Machine_Learning00010.smil#span_001549">Now have a look at the file output </span><code xml:space="preserve" id="code_000468" smilref="Machine_Learning00010.smil#code_000468">(/tmp/xd/output/sentimenttest.out</code><span class="text" id="span_001550" smilref="Machine_Learning00010.smil#span_001550">) and you see the tweet output and, at the end, the sentiment score based on the two lexicons. Though the output tweets are still the originals, your new class had cleaned up the text before calculating the score.</span></p>
                <p xml:space="preserve" id="p_000656"><code class="preserve-whitespace" xml:space="preserve" id="code_000469" smilref="Machine_Learning00010.smil#code_000469">
Mon Dec 30 14:29:18 +0000 2013|Miley Cyrus and Her Pink Mohawk Cover Love http://t.co/Inz6eDxCtG #fashion|1
Mon Dec 30 14:29:26 +0000 2013|RT @PalettePale: In love with my @Georgeatasda pj bottoms! So cute!  http://t.co/aoIOoJjboH #fbloggers #blog #fashion #cute #pjs #pyjamas|2
Mon Dec 30 14:29:28 +0000 2013|#Gossip #CelebrityNews Miley Cyrus Dances, Sings Along at Britney Spears' Piece of Me Concert in Las… http://t.co/JmwdvvIsKY #Fashion|-1
Mon Dec 30 14:29:30 +0000 2013|RT @PureLondonShow: Register for FREE now to Pure 2014 this February and glam up your business with the latest #fashion designs &amp; ideas htt…|2
Mon Dec 30 14:29:33 +0000 2013|#Snap #Farouushe #Nails #Pink #Fashion #Love #Girl #French #Lyon #Kiss http://t.co/DzT9HzxfQ8|1
Mon Dec 30 14:29:36 +0000 2013|RT @Fashion_Whipped: Winter fashion items you will not want to live without! http://t.co/aTE61gRX6h @toryburch @SINGER22 @shopbop #fashion …|0
Mon Dec 30 14:29:37 +0000 2013|Well, NYE is tomorrow. What are you wearing? #NYE #fashion|0
Mon Dec 30 14:29:38 +0000 2013|Mi copiloto favorito… Él no me chilla cuando aparco mal jajaja @GcrGcrshop #moda #bolsos #style #fashion #musthave http://t.co/tuJVRGaJ3m|0
Mon Dec 30 14:29:39 +0000 2013|Cute. Ootd.  @hapatime #ootd #ootn #fallfashion #tights #booties #purse #fashion #fashionistalovey… http://t.co/fjpgoet1lw|0
</code></p>
                <pagenum epub:type="pagebreak" id="p221" page="normal" smilref="Machine_Learning00010.smil#p221">221</pagenum>
                <p id="c09-c09-para-0155" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0155">So far, these two projects consumed the entire JSON payload from the tweet and extracted only two elements, namely the create date and the text of the tweet. Perhaps there'll be a time when you want to perform analysis on the rest of the data and extract other elements.</p>
                <p id="c09-c09-para-0156" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0156">The next section looks at Taps, a feature within Spring XD that enables you to intercept the stream and process the information independent of the original stream definition.</p>
              </level4>
            </level3>
            <level3 id="level3_000158">
              <h3 xml:space="preserve" id="h3_000158" smilref="Machine_Learning00010.smil#h3_000158">Spring XD Taps</h3>
              <p xml:space="preserve" id="p_000657" smilref="Machine_Learning00010.smil#p_000657">So far with Spring XD, you've concentrated on single-stream definitions with a source, a process transformer, and an output destination. One issue with this single-stream pipeline is that when there are large payloads of information, anything that's not passed along from one stage to the next is lost.</p>
              <p id="c09-c09-para-0158" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0158">Taps enables you to listen to a stream and perform another function on it in addition to the processor at that level of the stream definition.</p>
              <p id="c09-c09-para-0159" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0159">For example, suppose you want to preserve the original tweet data as it comes into Spring XD instead of extracting only date and text. Starting with the stream you created that does the sentiment scoring:</p>
              <p xml:space="preserve" id="p_000658"><code class="preserve-whitespace" xml:space="preserve" id="code_000470" smilref="Machine_Learning00010.smil#code_000470">xd:&gt;stream create --name sentimenttest --definition "twitterstream --track='#fashion' | sentimenttransformer | file"</code></p>
              <p xml:space="preserve" id="p_000659"><span class="text" id="span_001551" smilref="Machine_Learning00010.smil#span_001551">you can create a new stream but with a tap that points to the stream called </span><code xml:space="preserve" id="code_000471" smilref="Machine_Learning00010.smil#code_000471">sentimenttest</code><span class="text" id="span_001552" smilref="Machine_Learning00010.smil#span_001552">.</span></p>
              <p xml:space="preserve" id="p_000660"><code class="preserve-whitespace" xml:space="preserve" id="code_000472" smilref="Machine_Learning00010.smil#code_000472">xd:&gt;stream create --name mytap --definition "tap:stream:sentimenttest &gt; file"</code></p>
              <pagenum epub:type="pagebreak" id="p222" page="normal" smilref="Machine_Learning00010.smil#p222">222</pagenum>
              <p id="c09-c09-para-0160" xml:space="preserve"><span class="text" id="span_001553" smilref="Machine_Learning00010.smil#span_001553">In this example, you directed the output to a file called </span><code xml:space="preserve" id="code_000473" smilref="Machine_Learning00010.smil#code_000473">mytap.out</code><span class="text" id="span_001554" smilref="Machine_Learning00010.smil#span_001554"> under </span><code xml:space="preserve" id="code_000474" smilref="Machine_Learning00010.smil#code_000474">/tmp/xd/output</code><span class="text" id="span_001555" smilref="Machine_Learning00010.smil#span_001555"> along with the other files. If you have a look now, you will see that </span><code xml:space="preserve" id="code_000475" smilref="Machine_Learning00010.smil#code_000475">sentimenttest.out</code><span class="text" id="span_001556" smilref="Machine_Learning00010.smil#span_001556"> contains the date, tweet, and sentiment score separated by the pipe character (|), and </span><code xml:space="preserve" id="code_000476" smilref="Machine_Learning00010.smil#code_000476">mytap.out</code><span class="text" id="span_001557" smilref="Machine_Learning00010.smil#span_001557"> has the entire JSON payload that the Twitter streaming API sent you.</span></p>
              <p id="c09-c09-para-0161" xml:space="preserve"><span class="text" id="span_001558" smilref="Machine_Learning00010.smil#span_001558">Taps are similar to the UNIX pipeline </span><code xml:space="preserve" id="code_000477" smilref="Machine_Learning00010.smil#code_000477">tee</code><span class="text" id="span_001559" smilref="Machine_Learning00010.smil#span_001559"> command that splits (or T's) a stream into two streams or a file and a stream.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000079">
            <h2 id="c09-c09_level1_8" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09_level1_8">Summary</h2>
            <p xml:space="preserve" id="p_000661" smilref="Machine_Learning00010.smil#p_000661">As you've seen throughout this chapter, Spring XD provides a good platform for processing a variety of data streams. The potential of creating your own processing modules means you can start rolling out your own real-time analytics with relative ease.</p>
            <p id="c09-c09-para-0163" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0163">The sentiment analysis example, although simple, is used commonly in real Twitter sentiment applications, and it's a handy tool to have when monitoring incoming streams of tweet data. The same model could be applied to practically any type of social media status data—even customer reviews on e-commerce platform sites.</p>
            <p id="c09-c09-para-0164" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0164">It's worth taking some time to become familiar with the APIs before automating tasks with large systems such as Spring XD. Also, as discussed, take into consideration how you are going to store the incoming stream data and its processed output. You might want to go back and re-analyze data and learn more from it.</p>
            <p id="c09-c09-para-0165" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0165">I used Spring XD as the main platform for this chapter, because it was simple to get usable streams up and running. It's not alone, though, for a platform to consume data. You might want to investigate other systems such as Storm, Apache Flume, or RabbitMQ for constructing real-time systems. Just know that using them might require a little more planning and programming.</p>
            <p id="c09-c09-para-0166" xml:space="preserve" smilref="Machine_Learning00010.smil#c09-c09-para-0166">Chapter 10 looks at batch processing information with Hadoop, examines how the ecosystem fits together, and shows you how to perform analysis with MapReduce and Pig.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c10">
        <section epub:type="chapter" id="section_000011">
          <header id="header_000010">
            <h1 id="c10-c10" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10">Chapter 10 Machine Learning as a Batch Process</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p223" page="normal" smilref="Machine_Learning00010.smil#p223">223</pagenum>
          <p xml:space="preserve" id="p_000662" smilref="Machine_Learning00010.smil#p_000662">This chapter investigates using batch processing to mine and learn from larger amounts of data instead of streaming data. After you've considered the size of data and what you're hoping to learn from it, you then look at various tools to extract, transform, and then process the data for useful results.</p>
          <p id="c10-c10-para-0002" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0002">This chapter covers using Hadoop, Sqoop, and Pig for large-scale batch processing; these tools enable large data sets to be processed with relative ease. The chapter also discusses more traditional methods of creating programs to run batch processes on data.</p>
          <level2 id="level2_000080">
            <h2 id="c10-c010_level1_1" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c010_level1_1">Is It Big Data?</h2>
            <p xml:space="preserve" id="p_000663" smilref="Machine_Learning00010.smil#p_000663">Although this book is about machine learning, I can't ignore the term “Big Data” that is increasingly a topic in business today. The phrase is touted as the savior, because it enables companies to see new things in their existing data. The term is broad but ultimately reduces down to the concept of a data set that becomes so large that it is difficult to process with traditional tools.</p>
            <p id="c10-c10-para-0004" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0004">Depending on whom you ask, you might hear, “It's not Big Data if it's not working on petabytes of data,” or “When it becomes too big for a traditional database, then it's Big Data.” Both statements are true and valid. Personally, I like the term “data” regardless of whether the amount of data is big or small.</p>
            <pagenum epub:type="pagebreak" id="p224" page="normal" smilref="Machine_Learning00010.smil#p224">224</pagenum>
            <p id="c10-c10-para-0005" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0005">As time marches on, the answer to the “What is Big Data?” question will constantly change. The tools will also adapt, improve, and provide different insight. The key question for many organizations is “What can we do with the data we have?”</p>
          </level2>
          <level2 id="level2_000081">
            <h2 id="c10-c010_level1_2" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c010_level1_2">Considerations for Batch Processing Data</h2>
            <p xml:space="preserve" id="p_000664" smilref="Machine_Learning00010.smil#p_000664">As covered in Chapter 9's discussion about working with real-time data, you must give consideration to the data on which you want to work. The following sections cover a few key points. I'll refer to the data we used in the last chapter.</p>
            <level3 id="level3_000159">
              <h3 xml:space="preserve" id="h3_000159" smilref="Machine_Learning00010.smil#h3_000159">Volume and Frequency</h3>
              <p xml:space="preserve" id="p_000665" smilref="Machine_Learning00010.smil#p_000665">The Twitter streaming API generates a lot of JSON data. In Chapter 9 you used only one aspect of it to perform primitive sentiment analysis on the fly. The rest of the data was basically redundant during the real-time process. With batch processing, you can perform more robust and detailed processing without the time-pressure and memory constraints of a real-time system. The trade-off is that you must store the data on secondary storage; hence, you use Spring XD taps to fork the raw data before it is processed and discarded in the stream.</p>
              <p id="c10-c10-para-0008" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0008">It's important to forecast storage demand against the amount of data you'll bring into the system to be processed. Coupled with the Big Data paradigm of “delete nothing,” you should assume that a lot of data will be stored over time, whether you store it in a data warehouse, relational database, NoSQL system, or files with the idea that, at some time, it can be used.</p>
              <p id="c10-c10-para-0009" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0009">Consider the size of Twitter data, assuming you're tracking specific hashtags:</p>
              <list type="ul" id="list_000053">
                <li id="li_000392" smilref="Machine_Learning00010.smil#li_000392">1 tweet = 2 kb</li>
                <li id="li_000393" smilref="Machine_Learning00010.smil#li_000393">25 tweets a minute = 50 kb</li>
                <li id="li_000394" smilref="Machine_Learning00010.smil#li_000394">1 hour = 3,000 kb (3 megabytes)</li>
                <li id="li_000395" smilref="Machine_Learning00010.smil#li_000395">1 day = 72,000 kb (72 megabytes)</li>
                <li id="li_000396" smilref="Machine_Learning00010.smil#li_000396">1 week = 504,000 kb (504 megabytes)</li>
                <li id="li_000397" smilref="Machine_Learning00010.smil#li_000397">1 year = 26,208,000 kb (26 gigabytes)</li>
              </list>
              <p id="c10-c10-para-0010" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0010">As rough calculations go that makes sense, but in the real world I would wager that most people would be tracking more than one hashtag for analysis.</p>
              <p id="c10-c10-para-0011" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0011">Frequency is another issue. For example, I created a stream that just stored the public Twitter stream to a file. Within one minute I'd already stored 8 megabytes (8,000 kilobytes) of data. If I want to store a year of data, I'd have 4 terabytes for that one hashtag. 4 terabytes of raw, uncompressed text for only one hashtag!</p>
              <p id="c10-c10-para-0012" xml:space="preserve"><span class="text" id="span_001560" smilref="Machine_Learning00010.smil#span_001560">Twitter's public streaming API accounts for roughly 10 percent of the full firehose of data, so you can imagine the storage implications if you are to consume the full firehose. </span><pagenum epub:type="pagebreak" id="p225" page="normal" smilref="Machine_Learning00010.smil#p225">225</pagenum><span class="text" id="span_001561" smilref="Machine_Learning00010.smil#span_001561">While storage capacity increases, the costs associated are decreasing. This means that creating data warehousing for data is a workable reality for many companies, where originally it was out of reach.</span></p>
            </level3>
            <level3 id="level3_000160">
              <h3 xml:space="preserve" id="h3_000160" smilref="Machine_Learning00010.smil#h3_000160">How Much Data?</h3>
              <p xml:space="preserve" id="p_000666" smilref="Machine_Learning00010.smil#p_000666">Data relevance is often more important than the quantity of data in hand. Have you ever wondered why financial websites operate publicly with a 15-minute delay? The sole reason is that the data is for a purely historical record and can't be used for establishing trades; it's too old. There's nothing wrong with using all the available data to process; the question is, will you gain anything from it? Sometimes it's better to look at the last year, the last month, or even the last week. There's nothing stopping you from looking at all three.</p>
            </level3>
            <level3 id="level3_000161">
              <h3 xml:space="preserve" id="h3_000161" smilref="Machine_Learning00010.smil#h3_000161">Which Process Method?</h3>
              <p xml:space="preserve" id="p_000667" smilref="Machine_Learning00010.smil#p_000667">The current fashion is to unleash Hadoop on data and expect the answers to just jump out at you. I've run training sessions where someone has said, “I thought we put the data in and the answers just came out!” It's important to create a question or a hypothesis to come to some conclusion. For example, you might be looking for customers who've bought widgets A and B to determine what other widgets might be of interest to them.</p>
              <p id="c10-c10-para-0015" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0015">As you see in this chapter, it's not all Hadoop; algorithms can be crafted and used in a framework or run on their own. It's a case of planning what you're looking for within the data and defining a process to reach that conclusion.</p>
            </level3>
          </level2>
          <level2 id="level2_000082">
            <h2 id="c10-c010_level1_3" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c010_level1_3">Practical Examples of Batch Processes</h2>
            <p xml:space="preserve" id="p_000668" smilref="Machine_Learning00010.smil#p_000668">The rest of this chapter is a detailed walkthrough of different approaches to batch data processing. As discussed in Chapter 2, there's no one solution that fits all for this sort of work; solutions can be comprised of different languages, scripts, and commands to get things how you want them. This chapter looks at working with the data you gathered with Spring XD from the previous chapter and also adds some new ingredients to make it work with some batch processing tools. The following sections describe the tools covered in this chapter.</p>
            <level3 id="level3_000162">
              <h3 xml:space="preserve" id="h3_000162" smilref="Machine_Learning00010.smil#h3_000162">Hadoop</h3>
              <p xml:space="preserve" id="p_000669" smilref="Machine_Learning00010.smil#p_000669">Hadoop is a framework for the processing and storage of large volumes of data either on a single machine (called a single node) or a collection of machines. Written almost completely in Java, Hadoop was conceived in 2005 by Doug Cutting and Mike Cafarella.</p>
              <pagenum epub:type="pagebreak" id="p226" page="normal" smilref="Machine_Learning00010.smil#p226">226</pagenum>
              <p id="c10-c10-para-0018" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0018">The Hadoop system is primarily run on Linux or UNIX-based systems. If you use the Windows operating system, then there are some companies, including Microsoft and Hortonworks, which provide a distribution for Windows and cloud-based Hadoop clusters running Windows.</p>
              <p id="c10-c10-para-0019" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0019">Instructions on how to install Hadoop are found in Chapter 2. This chapter covers how to get a single-node cluster running with the Spring XD data you collected in the previous chapter.</p>
            </level3>
            <level3 id="level3_000163">
              <h3 xml:space="preserve" id="h3_000163" smilref="Machine_Learning00010.smil#h3_000163">Sqoop</h3>
              <p xml:space="preserve" id="p_000670"><span class="text" id="span_001562" smilref="Machine_Learning00010.smil#span_001562">For data stored within traditional databases, Sqoop (pronounced </span><em id="em_000322" smilref="Machine_Learning00010.smil#em_000322">scoop</em><span class="text" id="span_001563" smilref="Machine_Learning00010.smil#span_001563">, like a scoop of ice cream) is a useful tool that extracts tables or selected data and outputs it in a form that you can process with Hadoop. Sqoop also creates the required Java class files for the table structures, so implementing them into Hadoop's MapReduce framework is easier. If your database is supported with a Java database (JDBC) driver, then you can implement Sqoop to extract the data from your database and stuff it into Hadoop.</span></p>
            </level3>
            <level3 id="level3_000164">
              <h3 xml:space="preserve" id="h3_000164" smilref="Machine_Learning00010.smil#h3_000164">Pig</h3>
              <p xml:space="preserve" id="p_000671" smilref="Machine_Learning00010.smil#p_000671">The Apache Pig project is a high-level scripting language for creating MapReduce programs. It's based on the programming language Pig Latin. On the surface it looks a lot like Structured Query Language (SQL). User-defined functions can also be written in Java, Python, JavaScript, Ruby, Groovy, or other Java Virtual Machine (JVM) languages.</p>
            </level3>
            <level3 id="level3_000165">
              <h3 xml:space="preserve" id="h3_000165" smilref="Machine_Learning00010.smil#h3_000165">Mahout</h3>
              <p xml:space="preserve" id="p_000672" smilref="Machine_Learning00010.smil#p_000672">The Apache Mahout project is a collection of scalable machine learning algorithms for clustering, collaborative filtering, and classification. Later in this chapter, you build a basket recommendation system that works with the Mahout algorithms that run on Hadoop. Mahout can run independently, but it also implements the MapReduce paradigm, so it works within Hadoop and can perform machine learning over large data sets on large Hadoop clusters.</p>
            </level3>
            <level3 id="level3_000166">
              <h3 xml:space="preserve" id="h3_000166" smilref="Machine_Learning00010.smil#h3_000166">Cloud-Based Elastic Map Reduce</h3>
              <p xml:space="preserve" id="p_000673" smilref="Machine_Learning00010.smil#p_000673">If you don't have the hardware on hand for running Hadoop at a large scale, it's worth looking at some of the cloud-based offerings. Amazon has Elastic Map Reduce (Amazon EMR) as part of the Amazon Web Services offering. Google's AppEngine also hosts a MapReduce system. Microsoft offers HDInsight on its Windows Azure cloud platform.</p>
              <pagenum epub:type="pagebreak" id="p227" page="normal" smilref="Machine_Learning00010.smil#p227">227</pagenum>
              <p id="c10-c10-para-0024" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0024">Cloud providers that offer these sorts of processing services have their own control panels and processes that are not covered in this chapter. It's worth taking the time to investigate the major available options to see if one of them fits your needs better than buying, maintaining, and servicing lots of hardware yourself.</p>
            </level3>
            <level3 id="level3_000167">
              <h3 xml:space="preserve" id="h3_000167" smilref="Machine_Learning00010.smil#h3_000167">A Note about the Walkthroughs</h3>
              <p xml:space="preserve" id="p_000674" smilref="Machine_Learning00010.smil#p_000674">This chapter has four complete scenarios that walk you through the process of mining batched data from start to finish.</p>
              <p id="c10-c10-para-0026" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0026">The first scenario gives you a line-by-line tutorial on how to set up a single-node Hadoop cluster. This includes formatting a Hadoop Distributed File System (HDFS) and running a test job on your batches.</p>
              <p id="c10-c10-para-0027" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0027">The second scenario takes the work you did in Chapter 9 with Spring XD and extends it further to show you Hadoop and Spring XD working together.</p>
              <p id="c10-c10-para-0028" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0028">You then move on to recommendations using the machine learning libraries in Mahout and the bulk data collection framework Sqoop.</p>
              <p id="c10-c10-para-0029" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0029">Last, you look at sales data analysis using Pig scripts and also plain Java code, so you can see how the two compare and can become comfortable with the abstractions Pig provides.</p>
              <p id="c10-c10-para-0030" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0030">I've divided the tutorials into sections, so you can work through them one at a time, making it easier to leave off and come back and do another one when you feel you can.</p>
            </level3>
          </level2>
          <level2 id="level2_000083">
            <h2 id="c10-c010_level1_4" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c010_level1_4">Using the Hadoop Framework</h2>
            <p xml:space="preserve" id="p_000675" smilref="Machine_Learning00010.smil#p_000675">One of the misconceptions about Hadoop is that it processes your data and has the answers for you. The notion that you can just throw data at Hadoop and it provides untold stories and new facts is fanciful to say the least. There's still a large amount of planning and preparation you have to do before you can enable Hadoop to do your work properly. Ultimately, you need to know what you're trying to find out; as I've said throughout the book, you need to know the question you are trying to answer.</p>
            <p id="c10-c10-para-0032" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0032">The misconception aside, Hadoop is very effective at processing huge volumes of data. Even if you are not at the petabytes scale (where Facebook and Google are), you can do a lot with the framework. But don't forget that Hadoop is a means to an end, not an end in itself.</p>
            <level3 id="level3_000168">
              <h3 xml:space="preserve" id="h3_000168" smilref="Machine_Learning00010.smil#h3_000168">The Hadoop Architecture</h3>
              <p xml:space="preserve" id="p_000676"><span class="text" id="span_001564" smilref="Machine_Learning00010.smil#span_001564">Hadoop is built on a number of core components. The Hadoop Common package supplies the file and operating system components, the MapReduce engine </span><pagenum epub:type="pagebreak" id="p228" page="normal" smilref="Machine_Learning00010.smil#p228">228</pagenum><span class="text" id="span_001565" smilref="Machine_Learning00010.smil#span_001565">(now two versions: MR1, which is MapReduce, or the newer MR2, which is based on YARN), and the HDFS.</span></p>
              <p id="c10-c10-para-0034" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0034">There are various distributions of the Hadoop framework available from Apache, Cloudera, Hortonworks, and MapR. Each vendor has alterations from the core for performance and features, so check them out to find one that suits your needs.</p>
              <p id="c10-c10-para-0035" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0035">For these exercises I've used the older MR1 MapReduce engine from the Apache Hadoop distribution, so you can see in code how the systems are put together. When you are comfortable with this, then you can easily progress to the MR2, if you want. Existing jobs in MR1 usually work with the MR2 engine without changes.</p>
              <level4 id="level4_000089">
                <h4 xml:space="preserve" id="h4_000089" smilref="Machine_Learning00010.smil#h4_000089">Hadoop Distributed File System (HDFS)</h4>
                <p xml:space="preserve" id="p_000677" smilref="Machine_Learning00010.smil#p_000677">The HDFS is designed to store a large number of large files. Files smaller than half a gigabyte are stored and managed inefficiently in HDFS. Typical sizes for collections on HDFS are usually terabytes and frequently petabytes. HDFS assumes that it has streaming data access to all other nodes in the cluster, and ideally they are within the same local area network. The philosophy of Hadoop and MapReduce is that it is easier to move the code to the data on a large, distributed system than to send all the data to the code. Hadoop uses a master/slave architecture. MR1 Hadoop implementations have a single node called a NameNode to regulate file access to the slave nodes and also to manage the file system namespace of the cluster. Additionally, there are (many) DataNodes, normally one per machine in the cluster, that manage the disk storage on each machine on which it runs.</p>
                <p id="c10-c10-para-0037" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0037">References to blocks of data (usually between 128 MB and 512 MB in size) are assigned to DataNodes by the NameNode for processing. A file in the NameNode keeps a transaction log of all changes that happen within the distributed file system. DataNodes pass the data blocks around for replication and storage. The NameNode never passes data blocks.</p>
                <p id="c10-c10-para-0038" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0038">Because HDFS is written in Java, each component of Hadoop can be run on any platform that has a Java runtime environment. In reality, Hadoop components usually run on UNIX-based machines, although Hortonworks does provide a Windows-based platform, if that's what you prefer.</p>
                <p id="c10-c10-para-0039" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0039">The NameNode on MR1 engines is a single point of failure. If the NameNode fails, then the whole cluster fails, and data can't be processed. This issue was partially addressed in Hadoop 2.x (using the MR2 MapReduce engine) where federated NameNode service was introduced. Most corporate operations teams have implemented operational workarounds to NameNode's single-point-of-failure problem by having hardware-level and network-level fail-over. They usually use a network file system (NFS) volume for NameNode's data, enabling a “cold spare” machine to take NameNode's role in case of hardware failure.</p>
                <pagenum epub:type="pagebreak" id="p229" page="normal" smilref="Machine_Learning00010.smil#p229">229</pagenum>
                <p id="c10-c10-para-0040" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0040">In addition, the secondary NameNode acts as an inactive watcher of the transaction logs of the primary NameNode. It periodically obtains a snapshot of the current state of HDFS metadata. If there's a failure of the primary NameNode, then the new NameNode attempts to use the data stored on the secondary NameNode and continues to recover the most recent consistent state of HDFS; then, it runs the outstanding transactions to restore the cluster.</p>
              </level4>
              <level4 id="level4_000090">
                <h4 xml:space="preserve" id="h4_000090" smilref="Machine_Learning00010.smil#h4_000090">Different File System Types</h4>
                <p xml:space="preserve" id="p_000678" smilref="Machine_Learning00010.smil#p_000678">Although most texts talk about the HDFS, it is worth noting there are some other back-end storage options you can use when running Hadoop:</p>
                <list type="ul" id="list_000054">
                  <li id="li_000398" smilref="Machine_Learning00010.smil#li_000398">Amazon S3 File System</li>
                  <li id="li_000399" smilref="Machine_Learning00010.smil#li_000399">HTTP/HTTPS (working in read-only mode)</li>
                  <li id="li_000400" smilref="Machine_Learning00010.smil#li_000400">CloudStore, which is also known as the Kosmosfs and has now evolved into the Quantcast File System</li>
                  <li id="li_000401" smilref="Machine_Learning00010.smil#li_000401">Network File System (NFS) mounted volumes</li>
                </list>
                <p id="c10-c10-para-0042" xml:space="preserve" smilref="Machine_Learning00010.smil#c10-c10-para-0042">In addition, FTP enables you to store data on remote FTP servers.</p>
              </level4>
            </level3>
            <level3 id="level3_000169">
              <h3 xml:space="preserve" id="h3_000169" smilref="Machine_Learning00010.smil#h3_000169">Setting Up a Single-Node Cluster</h3>
              <p xml:space="preserve" id="p_000679" smilref="Machine_Learning00010.smil#p_000679">Before you can start working through the examples, you need to set up a single-node cluster of your Hadoop system. This is a straightforward exercise on the command line. I go through step by step to get the configuration and secure shell requirements complete. If you haven't read the basic Hadoop installation instructions in Chapter 2, you might want to read them before continuing.</p>
              <level4 id="level4_000091">
                <h4 xml:space="preserve" id="h4_000091" smilref="Machine_Learning00010.smil#h4_000091">Configuring Secure Shell (ssh)</h4>
                <p xml:space="preserve" id="p_000680"><span class="text" id="span_001566" smilref="Machine_Learning00010.smil#span_001566">Hadoop requires access to each node by way of a password-less </span><code xml:space="preserve" id="code_000478" smilref="Machine_Learning00010.smil#code_000478">ssh</code><span class="text" id="span_001567" smilref="Machine_Learning00010.smil#span_001567"> login, regardless if it's a single-node cluster or connecting to a number of machines. To create such a login, become the Hadoop user or log in to the account you will use for Hadoop and type the following command to generate the public and private keys:</span></p>
                <p xml:space="preserve" id="p_000681"><code class="preserve-whitespace" xml:space="preserve" id="code_000479" smilref="Machine_Learning00010.smil#code_000479">ssh-keygen –t rsa –P '' –f ˜/.ssh/id_rsa</code></p>
                <p id="c10-c10-para-0045" xml:space="preserve"><span class="text" id="span_001568" smilref="Machine_Learning00010.smil#span_001568">The </span><code xml:space="preserve" id="code_000480" smilref="Machine_Learning00010.smil#code_000480">–t</code><span class="text" id="span_001569" smilref="Machine_Learning00010.smil#span_001569"> flag tells </span><code xml:space="preserve" id="code_000481" smilref="Machine_Learning00010.smil#code_000481">keygen</code><span class="text" id="span_001570" smilref="Machine_Learning00010.smil#span_001570"> to use the RSA encryption method, and the </span><code xml:space="preserve" id="code_000482" smilref="Machine_Learning00011.smil#code_000482">–P</code><span class="text" id="span_001571" smilref="Machine_Learning00011.smil#span_001571"> flag is for the password. As you can see, it's two single quotes; make sure there are no spaces between them. If you have previously created a key, you are asked if you want to overwrite it. Within the </span><code xml:space="preserve" id="code_000483" smilref="Machine_Learning00011.smil#code_000483">.ssh</code><span class="text" id="span_001572" smilref="Machine_Learning00011.smil#span_001572"> directory there are two files: the private key </span><code xml:space="preserve" id="code_000484" smilref="Machine_Learning00011.smil#code_000484">id_rsa</code><span class="text" id="span_001573" smilref="Machine_Learning00011.smil#span_001573"> and the public key </span><code xml:space="preserve" id="code_000485" smilref="Machine_Learning00011.smil#code_000485">id_rsa.pub</code><span class="text" id="span_001574" smilref="Machine_Learning00011.smil#span_001574">.</span></p>
                <pagenum epub:type="pagebreak" id="p230" page="normal" smilref="Machine_Learning00011.smil#p230">230</pagenum>
                <p id="c10-c10-para-0046" xml:space="preserve"><span class="text" id="span_001575" smilref="Machine_Learning00011.smil#span_001575">Next copy the key to the </span><code xml:space="preserve" id="code_000486" smilref="Machine_Learning00011.smil#code_000486">authorized_keys</code><span class="text" id="span_001576" smilref="Machine_Learning00011.smil#span_001576"> file.</span></p>
                <p xml:space="preserve" id="p_000682"><code class="preserve-whitespace" xml:space="preserve" id="code_000487" smilref="Machine_Learning00011.smil#code_000487">cat ˜/.ssh/id_rsa.pub &gt;&gt; ˜/.ssh/authorized_keys</code></p>
                <p id="c10-c10-para-0047" xml:space="preserve"><span class="text" id="span_001577" smilref="Machine_Learning00011.smil#span_001577">Note the </span><code xml:space="preserve" id="code_000488" smilref="Machine_Learning00011.smil#code_000488">&gt;</code><code xml:space="preserve" id="code_000489" smilref="Machine_Learning00011.smil#code_000489">&gt;</code><span class="text" id="span_001578" smilref="Machine_Learning00011.smil#span_001578">in the command, which means you are appending to the file. If you use one </span><code xml:space="preserve" id="code_000490" smilref="Machine_Learning00011.smil#code_000490">&gt;</code><span class="text" id="span_001579" smilref="Machine_Learning00011.smil#span_001579">, then it creates a new file and deletes all the other keys, so be careful when executing it.</span></p>
                <p id="c10-c10-para-0048" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0048">Finally try to log in to the same machine on which you created the public/private keys:</p>
                <p xml:space="preserve" id="p_000683"><code class="preserve-whitespace" xml:space="preserve" id="code_000491" smilref="Machine_Learning00011.smil#code_000491">ssh localhost</code></p>
                <p id="c10-c10-para-0049" xml:space="preserve"><span class="text" id="span_001580" smilref="Machine_Learning00011.smil#span_001580">The first time you use the new key, </span><code xml:space="preserve" id="code_000492" smilref="Machine_Learning00011.smil#code_000492">ssh</code><span class="text" id="span_001581" smilref="Machine_Learning00011.smil#span_001581"> prompts by asking if you trust the key fingerprint. Press Return/Enter to indicate yes. Each time you </span><code xml:space="preserve" id="code_000493" smilref="Machine_Learning00011.smil#code_000493">ssh</code><span class="text" id="span_001582" smilref="Machine_Learning00011.smil#span_001582"> from the localhost to the localhost after that, you will not be prompted for a password; instead, you should immediately see a login banner and then your normal command prompt. Log out again; you're done setting up the keys.</span></p>
              </level4>
              <level4 id="level4_000092">
                <h4 xml:space="preserve" id="h4_000092" smilref="Machine_Learning00011.smil#h4_000092">Configuring HDFS</h4>
                <p xml:space="preserve" id="p_000684"><span class="text" id="span_001583" smilref="Machine_Learning00011.smil#span_001583">The HDFS requires some configuration changes before you can start processing data. Find the home directory of your Hadoop installation (I'm using </span><code xml:space="preserve" id="code_000494" smilref="Machine_Learning00011.smil#code_000494">/usr/local/hadoop</code><span class="text" id="span_001584" smilref="Machine_Learning00011.smil#span_001584"> as a guide; yours may differ) and go to the </span><code xml:space="preserve" id="code_000495" smilref="Machine_Learning00011.smil#code_000495">conf</code><span class="text" id="span_001585" smilref="Machine_Learning00011.smil#span_001585"> directory.</span></p>
                <p xml:space="preserve" id="p_000685"><code class="preserve-whitespace" xml:space="preserve" id="code_000496" smilref="Machine_Learning00011.smil#code_000496">cd /usr/local/hadoop/conf</code></p>
                <p id="c10-c10-para-0051" xml:space="preserve"><span class="text" id="span_001586" smilref="Machine_Learning00011.smil#span_001586">Use a text editor to edit the </span><code xml:space="preserve" id="code_000497" smilref="Machine_Learning00011.smil#code_000497">core-site.xml</code><span class="text" id="span_001587" smilref="Machine_Learning00011.smil#span_001587"> file. (I'm using the nano text editor.)</span></p>
                <p xml:space="preserve" id="p_000686"><code class="preserve-whitespace" xml:space="preserve" id="code_000498" smilref="Machine_Learning00011.smil#code_000498">nano core-site.xml</code></p>
                <p id="c10-c10-para-0052" xml:space="preserve"><span class="text" id="span_001588" smilref="Machine_Learning00011.smil#span_001588">In a clean installation, the </span><code xml:space="preserve" id="code_000499" smilref="Machine_Learning00011.smil#code_000499">core-site.xml</code><span class="text" id="span_001589" smilref="Machine_Learning00011.smil#span_001589"> file is basically empty except for the configuration tags. It looks like the following:</span></p>
                <p xml:space="preserve" id="p_000687"><code class="preserve-whitespace" xml:space="preserve" id="code_000500" smilref="Machine_Learning00011.smil#code_000500">&lt;configuration&gt;
&lt;/configuration&gt;</code></p>
                <p id="c10-c10-para-0053" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0053">Add the following property for the default file system name:</p>
                <p xml:space="preserve" id="p_000688"><code class="preserve-whitespace" xml:space="preserve" id="code_000501" smilref="Machine_Learning00011.smil#code_000501">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></p>
                <p id="c10-c10-para-0054" xml:space="preserve"><code xml:space="preserve" id="code_000502" smilref="Machine_Learning00011.smil#code_000502">fs.default.name</code><span class="text" id="span_001590" smilref="Machine_Learning00011.smil#span_001590">is the key name that Hadoop is looking for to set the default HDFS name. The value is set to </span><code xml:space="preserve" id="code_000503" smilref="Machine_Learning00011.smil#code_000503">localhost</code><span class="text" id="span_001591" smilref="Machine_Learning00011.smil#span_001591"> and set to port </span><code xml:space="preserve" id="code_000504" smilref="Machine_Learning00011.smil#code_000504">9000</code><span class="text" id="span_001592" smilref="Machine_Learning00011.smil#span_001592">.</span></p>
                <p id="c10-c10-para-0055" xml:space="preserve"><span class="text" id="span_001593" smilref="Machine_Learning00011.smil#span_001593">The final thing to do on HDFS is format the file system. This must be done before you start using Hadoop to analyze the data. The </span><code xml:space="preserve" id="code_000505" smilref="Machine_Learning00011.smil#code_000505">format</code><span class="text" id="span_001594" smilref="Machine_Learning00011.smil#span_001594"> command is done via the </span><code xml:space="preserve" id="code_000506" smilref="Machine_Learning00011.smil#code_000506">hadoop</code><span class="text" id="span_001595" smilref="Machine_Learning00011.smil#span_001595"> command from the command line:</span></p>
                <p xml:space="preserve" id="p_000689"><code class="preserve-whitespace" xml:space="preserve" id="code_000507" smilref="Machine_Learning00011.smil#code_000507">hadoop namenode –format</code></p>
                <pagenum epub:type="pagebreak" id="p231" page="normal" smilref="Machine_Learning00011.smil#p231">231</pagenum>
                <p id="c10-c10-para-0056" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0056">You see a few log messages output to the console, but the main thing to look out for is the success message:</p>
                <p xml:space="preserve" id="p_000690"><code class="preserve-whitespace" xml:space="preserve" id="code_000508" smilref="Machine_Learning00011.smil#code_000508">14/01/14 21:17:01 INFO common.Storage: Storage directory /tmp/hadoop-jason/dfs/name has been successfully formatted.</code></p>
                <p id="c10-c10-para-0057" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0057">With the HDFS formatted, you are now ready to start and stop the Hadoop system, run a test job, and retrieve the results.</p>
              </level4>
              <level4 id="level4_000093">
                <h4 xml:space="preserve" id="h4_000093" smilref="Machine_Learning00011.smil#h4_000093">Running a Test Hadoop Job</h4>
                <p xml:space="preserve" id="p_000691" smilref="Machine_Learning00011.smil#p_000691">So far, you've created a password-less login and formatted HDFS for use. Hadoop comes with some example jobs you can run, and one of those is the Word Count example. In Hadoop terms, the Word Count example has become the “Hello World!” of Big Data. It's become the butt of many jokes for being far too simple, but it's still a handy way to confirm your cluster is working properly.</p>
                <p id="c10-c10-para-0059" xml:space="preserve"><span class="text" id="span_001596" smilref="Machine_Learning00011.smil#span_001596">Within the Hadoop directory there is an </span><code xml:space="preserve" id="code_000509" smilref="Machine_Learning00011.smil#code_000509">examples</code> <code xml:space="preserve" id="code_000510" smilref="Machine_Learning00011.smil#code_000510">jar</code><span class="text" id="span_001597" smilref="Machine_Learning00011.smil#span_001597"> file. Make a note of the name, which is usually </span><code xml:space="preserve" id="code_000511" smilref="Machine_Learning00011.smil#code_000511">hadoop-examples-1.2.1jar</code><span class="text" id="span_001598" smilref="Machine_Learning00011.smil#span_001598">, as you'll need it when doing your test.</span></p>
                <p id="c10-c10-para-0060" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0060">First things first—you need to start your Hadoop cluster. The following shell script starts all the required services:</p>
                <p xml:space="preserve" id="p_000692"><code class="preserve-whitespace" xml:space="preserve" id="code_000512" smilref="Machine_Learning00011.smil#code_000512">/usr/local/hadoop/bin/start-all.sh</code></p>
                <p id="c10-c10-para-0061" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0061">When the startup process is complete, you can start to copy the required files to process into HDFS and run your Word Count job.</p>
                <p id="c10-c10-para-0062" xml:space="preserve"><span class="text" id="span_001599" smilref="Machine_Learning00011.smil#span_001599">To perform functions on HDFS, you have to do that within Hadoop and not from the usual UNIX commands. However, familiar UNIX-like commands are used within the file system component of the </span><code xml:space="preserve" id="code_000513" smilref="Machine_Learning00011.smil#code_000513">hadoop</code><span class="text" id="span_001600" smilref="Machine_Learning00011.smil#span_001600"> command.</span></p>
                <p id="c10-c10-para-0063" xml:space="preserve"><span class="text" id="span_001601" smilref="Machine_Learning00011.smil#span_001601">First, create an input directory called </span><code xml:space="preserve" id="code_000514" smilref="Machine_Learning00011.smil#code_000514">input</code><span class="text" id="span_001602" smilref="Machine_Learning00011.smil#span_001602">:</span></p>
                <p xml:space="preserve" id="p_000693"><code class="preserve-whitespace" xml:space="preserve" id="code_000515" smilref="Machine_Learning00011.smil#code_000515">hadoop fs –mkdir input </code></p>
                <p id="c10-c10-para-0064" xml:space="preserve"><span class="text" id="span_001603" smilref="Machine_Learning00011.smil#span_001603">Check that the directory has been created within HDFS by running </span><code xml:space="preserve" id="code_000516" smilref="Machine_Learning00011.smil#code_000516">–ls</code><span class="text" id="span_001604" smilref="Machine_Learning00011.smil#span_001604">:</span></p>
                <p xml:space="preserve" id="p_000694"><code class="preserve-whitespace" xml:space="preserve" id="code_000517" smilref="Machine_Learning00011.smil#code_000517">hadoop fs –ls </code></p>
                <p id="c10-c10-para-0065" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0065">You should see some output similar to the following:</p>
                <p xml:space="preserve" id="p_000695"><code class="preserve-whitespace" xml:space="preserve" id="code_000518" smilref="Machine_Learning00011.smil#code_000518">Found 1 items
drwxr-xr-x   - jason supergroup          0 2014-01-14 21:34 /user/jason/input</code></p>
                <p id="c10-c10-para-0066" xml:space="preserve"><span class="text" id="span_001605" smilref="Machine_Learning00011.smil#span_001605">Now that the directory exists, you can start to copy files to it. I have a public domain text file of the book </span><em id="em_000323" smilref="Machine_Learning00011.smil#em_000323">Moby Dick</em><span class="text" id="span_001606" smilref="Machine_Learning00011.smil#span_001606">, so I'm going to copy that into HDFS. You can use any text file you want, just remember to alter the filename to the name of your text file.</span></p>
                <p xml:space="preserve" id="p_000696"><code class="preserve-whitespace" xml:space="preserve" id="code_000519" smilref="Machine_Learning00011.smil#code_000519">hadoop fs –put mobydick.txt input </code></p>
                <pagenum epub:type="pagebreak" id="p232" page="normal" smilref="Machine_Learning00011.smil#p232">232</pagenum>
                <p id="c10-c10-para-0067" xml:space="preserve"><span class="text" id="span_001607" smilref="Machine_Learning00011.smil#span_001607">This command copies the file into the </span><code xml:space="preserve" id="code_000520" smilref="Machine_Learning00011.smil#code_000520">input</code><span class="text" id="span_001608" smilref="Machine_Learning00011.smil#span_001608"> directory ready for Hadoop to process. You're not limited to one file; it's a directory, and you can store as many different files in there as you want. For this exercise, though, just copy the one file.</span></p>
                <p id="c10-c10-para-0068" xml:space="preserve"><span class="text" id="span_001609" smilref="Machine_Learning00011.smil#span_001609">Now you're ready to run the Word Count job. The basic </span><code xml:space="preserve" id="code_000521" smilref="Machine_Learning00011.smil#code_000521">hadoop</code><span class="text" id="span_001610" smilref="Machine_Learning00011.smil#span_001610"> command is naming the </span><code xml:space="preserve" id="code_000522" smilref="Machine_Learning00011.smil#code_000522">jar</code><span class="text" id="span_001611" smilref="Machine_Learning00011.smil#span_001611"> file to use with the MapReduce code and the input and output directories.</span></p>
                <p xml:space="preserve" id="p_000697"><code class="preserve-whitespace" xml:space="preserve" id="code_000523" smilref="Machine_Learning00011.smil#code_000523">hadoop jar /usr/local/hadoop/hadoop-examples-1.2.1.jar wordcount input output</code></p>
                <p id="c10-c10-para-0069" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0069">When the Hadoop job runs, there is a lot of output and updates of what MapReduce is working on (you take a proper look at what MapReduce is up to shortly). Although it all looks a bit cryptic, there are some interesting lines of which to take note. First, the following line shows the number of lines of text that the mapper has processed:</p>
                <p xml:space="preserve" id="p_000698"><code class="preserve-whitespace" xml:space="preserve" id="code_000524" smilref="Machine_Learning00011.smil#code_000524">14/01/14 21:41:36 INFO mapred.JobClient:     Map input records=23244</code></p>
                <p id="c10-c10-para-0070" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0070">The second useful line to know is the number of output records that the reducer has written in the final phase:</p>
                <p xml:space="preserve" id="p_000699"><code class="preserve-whitespace" xml:space="preserve" id="code_000525" smilref="Machine_Learning00011.smil#code_000525">Map output records=214112</code></p>
                <p id="c10-c10-para-0071" xml:space="preserve"><span class="text" id="span_001612" smilref="Machine_Learning00011.smil#span_001612">As it stands, the output that Hadoop has created is still sitting within HDFS; and my preference is for it to be a text file in my home directory. With the </span><code xml:space="preserve" id="code_000526" smilref="Machine_Learning00011.smil#code_000526">hadoop</code><span class="text" id="span_001613" smilref="Machine_Learning00011.smil#span_001613"> command, you can merge all the result files within HDFS and create a file on the local file system:</span></p>
                <p xml:space="preserve" id="p_000700"><code class="preserve-whitespace" xml:space="preserve" id="code_000527" smilref="Machine_Learning00011.smil#code_000527">hadoop fs --getmerge output output.txt</code></p>
                <p id="c10-c10-para-0072" xml:space="preserve"><span class="text" id="span_001614" smilref="Machine_Learning00011.smil#span_001614">What you're telling Hadoop to do is merge all the output result files to the local file system and call the file </span><code xml:space="preserve" id="code_000528" smilref="Machine_Learning00011.smil#code_000528">output.txt</code><span class="text" id="span_001615" smilref="Machine_Learning00011.smil#span_001615">. Remember that if </span><code xml:space="preserve" id="code_000529" smilref="Machine_Learning00011.smil#code_000529">output.txt</code><span class="text" id="span_001616" smilref="Machine_Learning00011.smil#span_001616"> already exists, it will be overwritten.</span></p>
                <p id="c10-c10-para-0073" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0073">The last thing to do is to shut down the Hadoop server node. You don't want to waste memory while doing simple jobs like this:</p>
                <p xml:space="preserve" id="p_000701"><code class="preserve-whitespace" xml:space="preserve" id="code_000530" smilref="Machine_Learning00011.smil#code_000530">/usr/local/hadoop/bin/stop-all.sh</code></p>
                <p id="c10-c10-para-0074" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0074">You see all the services shut down in turn. There's no stipulation to do this, but for the sake of completeness in this walkthrough I've put it in.</p>
                <p id="c10-c10-para-0075" xml:space="preserve"><span class="text" id="span_001617" smilref="Machine_Learning00011.smil#span_001617">Now it's time to inspect the fruits of your labor. The UNIX command </span><code xml:space="preserve" id="code_000531" smilref="Machine_Learning00011.smil#code_000531">head</code><span class="text" id="span_001618" smilref="Machine_Learning00011.smil#span_001618"> shows a certain number of lines of the start of the file instead of listing the entire file:</span></p>
                <p xml:space="preserve" id="p_000702"><code class="preserve-whitespace" xml:space="preserve" id="code_000532" smilref="Machine_Learning00011.smil#code_000532">head –20 output.txt</code></p>
                <p id="c10-c10-para-0076" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0076">The first 20 lines of the MapReduce job output should look like the following:</p>
                <p xml:space="preserve" id="p_000703"><code class="preserve-whitespace" xml:space="preserve" id="code_000533" smilref="Machine_Learning00011.smil#code_000533">jason@myserver:˜$ head -n20 output.txt
"'A    3
"'Also    1
"'Are    1
"'Aye,    1
"'Aye?    1
"'Best    1
"'Better    1
"'Bout    1
"'But    2
"'Canallers!'    1
"'Canallers,    1
"'Come    1
"'Cross    1
"'Damn    1
"'Down    1
"'Excuse    1
"'Hind    1
"'How?    1
"'I    4
"'Is    2</code></p>
                <pagenum epub:type="pagebreak" id="p233" page="normal" smilref="Machine_Learning00011.smil#p233">233</pagenum>
                <p id="c10-c10-para-0077" xml:space="preserve"><span class="text" id="span_001619" smilref="Machine_Learning00011.smil#span_001619">The basic Word Count example that comes with the Hadoop distribution splits a sentence by every space. If there are special characters within text files, such as quotation marks and apostrophes, then they'll be included. This is the reason that ‘</span><code xml:space="preserve" id="code_000534" smilref="Machine_Learning00011.smil#code_000534">Aye,</code><span class="text" id="span_001620" smilref="Machine_Learning00011.smil#span_001620"> and ‘</span><code xml:space="preserve" id="code_000535" smilref="Machine_Learning00011.smil#code_000535">Aye?</code><span class="text" id="span_001621" smilref="Machine_Learning00011.smil#span_001621"> are treated as two separate words during the mapping and reducing phases. I discuss more about these things in the “Mining the Hashtags” section of this chapter.</span></p>
              </level4>
              <level4 id="level4_000094">
                <h4 xml:space="preserve" id="h4_000094" smilref="Machine_Learning00011.smil#h4_000094">Quick Summary</h4>
                <p xml:space="preserve" id="p_000704" smilref="Machine_Learning00011.smil#p_000704">Over the last few pages, you've set up the basic Hadoop single-node cluster, including creating a secure login with no password, formatting HDFS, and running a basic test job using the Hadoop examples. Next, you expand on this knowledge and create your own MapReduce job to extract the hashtags from the data collated from Spring XD.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000084">
            <h2 id="c10-c010_level1_5" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c010_level1_5">How MapReduce Works</h2>
            <p xml:space="preserve" id="p_000705" smilref="Machine_Learning00011.smil#p_000705">When you hear the name Hadoop, the phrase MapReduce isn't far behind. MapReduce is a programming model, a way of doing things, and it's not a unique feature of Hadoop.</p>
            <p id="c10-c10-para-0080" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0080">So, how does the Word Count example work? Here's a really brief explanation for those who would like to know but don't want a bunch of jargon.</p>
            <p id="c10-c10-para-0081" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0081">When the NameNode sends a block of data to be processed, it's sent to the Map phase first. Consider the following piece of text:</p>
            <list type="ol" id="list_000055">
              <li id="li_000402" smilref="Machine_Learning00011.smil#li_000402">Red lorry yellow lorry</li>
              <li id="li_000403" smilref="Machine_Learning00011.smil#li_000403">Red lorry yellow lorry</li>
              <li id="li_000404" smilref="Machine_Learning00011.smil#li_000404">Red lorry yellow lorry</li>
            </list>
            <pagenum epub:type="pagebreak" id="p234" page="normal" smilref="Machine_Learning00011.smil#p234">234</pagenum>
            <p id="c10-c10-para-0082" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0082">The mapper receives that data (let's assume one line at a time), and for each word the mapper assigns the number count of one.</p>
            <list type="ol" id="list_000056">
              <li id="li_000405" smilref="Machine_Learning00011.smil#li_000405">Red 1</li>
              <li id="li_000406" smilref="Machine_Learning00011.smil#li_000406">Lorry 1</li>
              <li id="li_000407" smilref="Machine_Learning00011.smil#li_000407">Yellow 1</li>
              <li id="li_000408" smilref="Machine_Learning00011.smil#li_000408">Lorry 1</li>
              <li id="li_000409" smilref="Machine_Learning00011.smil#li_000409">Red 1</li>
              <li id="li_000410" smilref="Machine_Learning00011.smil#li_000410">Lorry 1</li>
              <li id="li_000411" smilref="Machine_Learning00011.smil#li_000411">…and so on.</li>
            </list>
            <p id="c10-c10-para-0083" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0083">In pseudo code it would look like this:</p>
            <p xml:space="preserve" id="p_000706"><code class="preserve-whitespace" xml:space="preserve" id="code_000536" smilref="Machine_Learning00011.smil#code_000536">function mapper(String text)
    for each word wd in text:
    collect(wd, 1)</code></p>
            <p id="c10-c10-para-0084" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0084">The data is sent back to the NameNode, and the mapper is free to process another block. When all the blocks are complete, then the reducer can collate the results and add up the occurrences of each word.</p>
            <p xml:space="preserve" id="p_000707"><code class="preserve-whitespace" xml:space="preserve" id="code_000537" smilref="Machine_Learning00011.smil#code_000537">function reducer(String word, Iterator wordCounts)
    total = 0
        for each wordCount in wordCounts:
        total += wordCount
        return (word, total)</code></p>
            <p id="c10-c10-para-0085" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0085">The final output will look like:</p>
            <list type="ol" id="list_000057">
              <li id="li_000412" smilref="Machine_Learning00011.smil#li_000412">Red 3</li>
              <li id="li_000413" smilref="Machine_Learning00011.smil#li_000413">Lorry 6</li>
              <li id="li_000414" smilref="Machine_Learning00011.smil#li_000414">Yellow 3</li>
            </list>
            <p id="c10-c10-para-0086" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0086">It's a simple yet very powerful model, and when it's worked in parallel with many nodes, it enables Hadoop to process huge volumes of data over a number of machines. I avoided getting bogged down with large amounts of theory because it's far more fun coding your own and watching it work. So, it's time to do that and move on to mining the hashtags.</p>
          </level2>
          <level2 id="level2_000085">
            <h2 id="c10-c010_level1_6" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c010_level1_6">Mining the Hashtags</h2>
            <p xml:space="preserve" id="p_000708" smilref="Machine_Learning00011.smil#p_000708">In the previous chapter, you used Spring XD to consume streaming Twitter data and store it on the file system. Using a custom processor, you extracted the data you wanted (the actual text of the tweet) and used a tap to preserve the full JSON payload that came in.</p>
            <pagenum epub:type="pagebreak" id="p235" page="normal" smilref="Machine_Learning00011.smil#p235">235</pagenum>
            <p id="c10-c10-para-0088" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0088">The one thing you haven't done is explored what was in that data apart from ranking each tweet with a basic sentiment score. With your single-node Hadoop cluster ready for action, you can take things further and make Spring XD and Hadoop integrate to work together.</p>
            <level3 id="level3_000170">
              <h3 xml:space="preserve" id="h3_000170" smilref="Machine_Learning00011.smil#h3_000170">Hadoop Support in Spring XD</h3>
              <p xml:space="preserve" id="p_000709"><span class="text" id="span_001622" smilref="Machine_Learning00011.smil#span_001622">You might have noticed when starting up Spring XD that within the XD configuration output there was an </span><code xml:space="preserve" id="code_000538" smilref="Machine_Learning00011.smil#code_000538">XD_HADOOP_DISTRO</code><span class="text" id="span_001623" smilref="Machine_Learning00011.smil#span_001623"> flag. This flag is telling Spring XD which version of Hadoop to use. At the time of writing, the following distributions are supported:</span></p>
              <list type="ul" id="list_000058">
                <li id="li_000415">
                  <strong id="strong_000473" smilref="Machine_Learning00011.smil#strong_000473">Apache Hadoop 1.2.1 (as default)</strong>
                  <span class="text" id="span_001624" smilref="Machine_Learning00011.smil#span_001624">:</span>
                  <code xml:space="preserve" id="code_000539" smilref="Machine_Learning00011.smil#code_000539">hadoop12</code>
                </li>
                <li id="li_000416">
                  <strong id="strong_000474" smilref="Machine_Learning00011.smil#strong_000474">Apache Hadoop 2.2.0</strong>
                  <span class="text" id="span_001625" smilref="Machine_Learning00011.smil#span_001625">:</span>
                  <code xml:space="preserve" id="code_000540" smilref="Machine_Learning00011.smil#code_000540">hadoop20</code>
                </li>
                <li id="li_000417">
                  <strong id="strong_000475" smilref="Machine_Learning00011.smil#strong_000475">Pivotal HD 1.1</strong>
                  <span class="text" id="span_001626" smilref="Machine_Learning00011.smil#span_001626">:</span>
                  <code xml:space="preserve" id="code_000541" smilref="Machine_Learning00011.smil#code_000541">phd1</code>
                </li>
                <li id="li_000418">
                  <strong id="strong_000476" smilref="Machine_Learning00011.smil#strong_000476">Cloudera CHD 4.3.1</strong>
                  <span class="text" id="span_001627" smilref="Machine_Learning00011.smil#span_001627">:</span>
                  <code xml:space="preserve" id="code_000542" smilref="Machine_Learning00011.smil#code_000542">cdh4</code>
                </li>
                <li id="li_000419">
                  <strong id="strong_000477" smilref="Machine_Learning00011.smil#strong_000477">Hortonworks Data Platform 1.3</strong>
                  <span class="text" id="span_001628" smilref="Machine_Learning00011.smil#span_001628">:</span>
                  <code xml:space="preserve" id="code_000543" smilref="Machine_Learning00011.smil#code_000543">hdp13</code>
                </li>
              </list>
              <p id="c10-c10-para-0090" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0090">Because you're working with Hadoop 1.2.1, you don't need to change anything in the configuration. If you were to use a different distribution, you would have to tell the shell which one you were using.</p>
              <p xml:space="preserve" id="p_000710"><code class="preserve-whitespace" xml:space="preserve" id="code_000544" smilref="Machine_Learning00011.smil#code_000544">./xd-shell --hadoopDistro &lt;your_distribution_number&gt;</code></p>
              <p id="c10-c10-para-0091" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0091">You're going to use Spring XD to output the processed tweet data directly to HDFS instead of to a file. This removes a lot of file system commands that are required to move the data from the local file system to HDFS. Spring XD takes care of all that for you.</p>
            </level3>
            <level3 id="level3_000171">
              <h3 xml:space="preserve" id="h3_000171" smilref="Machine_Learning00011.smil#h3_000171">Objectives for This Walkthrough</h3>
              <p xml:space="preserve" id="p_000711" smilref="Machine_Learning00011.smil#p_000711">Remember, you're not dealing with one technology; you're using Hadoop for mining the hashtags based on the output that Spring XD has collated. For the custom MapReduce functions, you're going to use a Java program that uses the Hadoop framework.</p>
              <p id="c10-c10-para-0093" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0093">After the routine is written, you turn your attention to Spring XD and reconfigure the stream to output to HDFS. Last, you run the Hadoop job to extract the hashtags and tell which is the most popular.</p>
            </level3>
            <level3 id="level3_000172">
              <h3 xml:space="preserve" id="h3_000172" smilref="Machine_Learning00011.smil#h3_000172">What's a Hashtag?</h3>
              <p xml:space="preserve" id="p_000712"><span class="text" id="span_001629" smilref="Machine_Learning00011.smil#span_001629">Say the word “hashtag” to most people and they automatically think of Twitter. However, the hashtag has been around a lot longer than some people imagine. </span><pagenum epub:type="pagebreak" id="p236" page="normal" smilref="Machine_Learning00011.smil#p236">236</pagenum><span class="text" id="span_001630" smilref="Machine_Learning00011.smil#span_001630">Hashtags were used to emphasize special meaning within the technology arena. Later, hashtags became widely used in Internet relay chat (IRC) as a means to label specific groups of information.</span></p>
              <p id="c10-c10-para-0095" xml:space="preserve"><span class="text" id="span_001631" smilref="Machine_Learning00011.smil#span_001631">Hashtags are made up of unspaced words with a hash sign (#) at the beginning. So the hashtag </span><code xml:space="preserve" id="code_000545" smilref="Machine_Learning00011.smil#code_000545">#MachineLearning</code><span class="text" id="span_001632" smilref="Machine_Learning00011.smil#span_001632"> is valid but </span><code xml:space="preserve" id="code_000546" smilref="Machine_Learning00011.smil#code_000546">#Machine Learning</code><span class="text" id="span_001633" smilref="Machine_Learning00011.smil#span_001633"> is not because there is a space between the two words.</span></p>
              <p id="c10-c10-para-0096" xml:space="preserve"><span class="text" id="span_001634" smilref="Machine_Learning00011.smil#span_001634">So looking at the </span><code xml:space="preserve" id="code_000547" smilref="Machine_Learning00011.smil#code_000547">#fashion</code><span class="text" id="span_001635" smilref="Machine_Learning00011.smil#span_001635"> tweet stream you created in Chapter 9, there are plenty of hashtags to be mined:</span></p>
              <p xml:space="preserve" id="p_000713"><code class="preserve-whitespace" xml:space="preserve" id="code_000548" smilref="Machine_Learning00011.smil#code_000548">Sun Jan 19 11:04:11 +0000 2014|Billie Jean - Sporting Club - #top #talent #pop #show #star #swag #smile #fashion #goodmorning … http://t.co/0VCPvcjVBl
Sun Jan 19 11:04:16 +0000 2014|Incredible gift from my grandparents #katemoss #book #fashion #photography #kate #moss http://t.co/hWBKWxLPzx
Sun Jan 19 11:04:16 +0000 2014|RT @wallpapermag: At @LANVINofficial, designer Lukas Ossendrijver makes a case for rollneck rebels #fashion #Lanvin http://t.co/4oaZBZx1YW
Sun Jan 19 11:04:16 +0000 2014|#Gossip #CelebrityNews 2014 SAG Awards: Cate Blanchett Wins Best Actress, Throws a Little Bit of Shade… http://t.co/qH9SwUFigT #Fashion
Sun Jan 19 11:04:17 +0000 2014|NEW #NATURAL #BUTT #LIFTER WITH NO PADDING (X-Large) #shapewear #curves #Fashion #Accessory #Deal http://t.co/Hk5zFSXjc9
Sun Jan 19 11:04:19 +0000 2014|#shoes #fashion
Dolce &amp; Gabbana Leopard Print Pony Skin Peep Toe Sling Back 40 UK 7</code></p>
              <p id="c10-c10-para-0097" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0097">All you have to do is create a MapReduce job to extract the hashtags and record each one. This is much like the way the Word Count example worked at the start of the chapter, but you refine the data at the mapping phase to ensure it's cleaned up. Doing so reduces the number of duplicate wordings recorded with punctuation characters.</p>
            </level3>
            <level3 id="level3_000173">
              <h3 xml:space="preserve" id="h3_000173" smilref="Machine_Learning00011.smil#h3_000173">Creating the MapReduce Classes</h3>
              <p xml:space="preserve" id="p_000714" smilref="Machine_Learning00011.smil#p_000714">Every MapReduce is comprised of a job configuration, mapper class, and, optionally, a reducer. I say optionally for the reducer because, under some circumstances, you don't want to reduce results; instead, you just use the mapper as a means to allocate blocks of data to be processed. This example, though, requires a reducer to collate all the hashtags that were recorded.</p>
              <level4 id="level4_000095">
                <h4 xml:space="preserve" id="h4_000095" smilref="Machine_Learning00011.smil#h4_000095">Creating the Project</h4>
                <p xml:space="preserve" id="p_000715"><span class="text" id="span_001636" smilref="Machine_Learning00011.smil#span_001636">Open your integrated development environment (IDE) and create a new project. (I'm using Eclipse as my IDE.) Call it </span><code xml:space="preserve" id="code_000549" smilref="Machine_Learning00011.smil#code_000549">HashTagsMapReduce</code><span class="text" id="span_001637" smilref="Machine_Learning00011.smil#span_001637">, as shown in </span><a id="c10-c10-fig-anc-0001" href="#c10-c10-fig-0001" external="false" smilref="Machine_Learning00011.smil#c10-c10-fig-anc-0001">Figure 10-1</a><span class="text" id="span_001638" smilref="Machine_Learning00011.smil#span_001638">.</span></p>
                <figure id="figure_000099">
                  <img class="center" src="images/c10f001.jpg" alt="image" id="img_000126" />
                  <figcaption id="figcaption_000085">
                    <p xml:space="preserve" id="p_000716"><span class="figureLabel" id="span_001639"><a id="c10-c10-fig-0001" href="#c10-c10-fig-anc-0001" external="false"><strong id="strong_000478" smilref="Machine_Learning00011.smil#strong_000478">Figure 10-1</strong></a></span> <pagenum epub:type="pagebreak" id="p237" page="normal" smilref="Machine_Learning00011.smil#p237">237</pagenum><span class="text" id="span_001640" smilref="Machine_Learning00011.smil#span_001640">Creating a new project</span></p>
                  </figcaption>
                </figure>
                <p id="c10-c10-para-0100" xml:space="preserve"><span class="text" id="span_001641" smilref="Machine_Learning00011.smil#span_001641">There's no need for any folders to hold any </span><code xml:space="preserve" id="code_000550" smilref="Machine_Learning00011.smil#code_000550">jar</code><span class="text" id="span_001642" smilref="Machine_Learning00011.smil#span_001642"> files. You only use one within the build—the core Hadoop libraries.</span></p>
              </level4>
              <level4 id="level4_000096">
                <h4 xml:space="preserve" id="h4_000096" smilref="Machine_Learning00011.smil#h4_000096">Adding the Required Files for the Build</h4>
                <p xml:space="preserve" id="p_000717"><span class="text" id="span_001643" smilref="Machine_Learning00011.smil#span_001643">Go to the project properties by right-clicking the project and selecting Properties; alternatively, you can select Project →Properties. Next, select Java Build Path from the left-hand menu and then click Add External Jar and find the main Hadoop core libraries: </span><code xml:space="preserve" id="code_000551" smilref="Machine_Learning00011.smil#code_000551">hadoop-core-1.2.1.jar</code><span class="text" id="span_001644" smilref="Machine_Learning00011.smil#span_001644">. (See </span><a id="c10-c10-fig-anc-0002" href="#c10-c10-fig-0002" external="false" smilref="Machine_Learning00011.smil#c10-c10-fig-anc-0002">Figure 10-2</a><span class="text" id="span_001645" smilref="Machine_Learning00011.smil#span_001645">.)</span></p>
                <figure id="figure_000100">
                  <img class="center" src="images/c10f002.jpg" alt="image" id="img_000127" />
                  <figcaption id="figcaption_000086">
                    <p xml:space="preserve" id="p_000718"><span class="figureLabel" id="span_001646"><a id="c10-c10-fig-0002" href="#c10-c10-fig-anc-0002" external="false"><strong id="strong_000479" smilref="Machine_Learning00011.smil#strong_000479">Figure 10-2</strong></a></span><span class="text" id="span_001647" smilref="Machine_Learning00011.smil#span_001647"> Adding the required libraries</span></p>
                  </figcaption>
                </figure>
                <p id="c10-c10-para-0102" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0102">Click OK and the project updates with the new libraries registered for use. Now you can start to create some code.</p>
              </level4>
              <level4 id="level4_000097">
                <h4 xml:space="preserve" id="h4_000097" smilref="Machine_Learning00011.smil#h4_000097">Creating the Mapper</h4>
                <p xml:space="preserve" id="p_000719"><span class="text" id="span_001648" smilref="Machine_Learning00011.smil#span_001648">Have a look at the </span><code xml:space="preserve" id="code_000552" smilref="Machine_Learning00011.smil#code_000552">mapper</code><span class="text" id="span_001649" smilref="Machine_Learning00011.smil#span_001649"> class first; there are some considerations you need to make with regard to it. The </span><code xml:space="preserve" id="code_000553" smilref="Machine_Learning00011.smil#code_000553">mapper</code><span class="text" id="span_001650" smilref="Machine_Learning00011.smil#span_001650"> class reads in each line of text and extracts what you're looking for (in this instance a hashtag). The saved data from Spring XD is the tweet date and then the content of the tweet. The data is pipe delimited, so you have to split that first.</span></p>
                <pagenum epub:type="pagebreak" id="p238" page="normal" smilref="Machine_Learning00011.smil#p238">238</pagenum>
                <p id="c10-c10-para-0104" xml:space="preserve"><span class="text" id="span_001651" smilref="Machine_Learning00011.smil#span_001651">Using a perl extended regular expression (peregex) as implemented in the Java language, you can easily match all the hashtags within the tweet. In a Java regular expression, there is a special, single-character matching pattern, </span><code xml:space="preserve" id="code_000554" smilref="Machine_Learning00011.smil#code_000554">\w</code><span class="text" id="span_001652" smilref="Machine_Learning00011.smil#span_001652">, that matches a single character that is either a letter, a digit, or the underscore (</span><code xml:space="preserve" id="code_000555" smilref="Machine_Learning00011.smil#code_000555">_</code><span class="text" id="span_001653" smilref="Machine_Learning00011.smil#span_001653">) character. (The mnemonic is “word” character.) So to match a hashtag, you can use a simple regular expression:</span></p>
                <p xml:space="preserve" id="p_000720"><code class="preserve-whitespace" xml:space="preserve" id="code_000556" smilref="Machine_Learning00011.smil#code_000556">#[\w]+ </code></p>
                <p id="c10-c10-para-0105" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0105">This expression matches a “pound sign” or “hash” (#), and the set that contains a word character repeated one or more times.</p>
                <p id="c10-c10-para-0106" xml:space="preserve"><span class="text" id="span_001654" smilref="Machine_Learning00011.smil#span_001654">Now it's time to put all that into practice in a Java class. Create a new </span><code xml:space="preserve" id="code_000557" smilref="Machine_Learning00011.smil#code_000557">Java</code><span class="text" id="span_001655" smilref="Machine_Learning00011.smil#span_001655"> class (using File →New →Class) and call it </span><code xml:space="preserve" id="code_000558" smilref="Machine_Learning00011.smil#code_000558">HashtagMapper.java</code><span class="text" id="span_001656" smilref="Machine_Learning00011.smil#span_001656">, as shown in </span><a id="c10-c10-fig-anc-0003" href="#c10-c10-fig-0003" external="false" smilref="Machine_Learning00011.smil#c10-c10-fig-anc-0003">Figure 10-3</a><span class="text" id="span_001657" smilref="Machine_Learning00011.smil#span_001657">. I'm using an empty package, but you can use your own naming methods if you want to.</span></p>
                <figure id="figure_000101">
                  <img class="center" src="images/c10f003.jpg" alt="image" id="img_000128" />
                  <figcaption id="figcaption_000087">
                    <p xml:space="preserve" id="p_000721"><span class="figureLabel" id="span_001658"><a id="c10-c10-fig-0003" href="#c10-c10-fig-anc-0003" external="false"><strong id="strong_000480" smilref="Machine_Learning00011.smil#strong_000480">Figure 10-3</strong></a></span><span class="text" id="span_001659" smilref="Machine_Learning00011.smil#span_001659"> Creating the new mapper</span></p>
                  </figcaption>
                </figure>
                <pagenum epub:type="pagebreak" id="p239" page="normal" smilref="Machine_Learning00011.smil#p239">239</pagenum>
                <p id="c10-c10-para-0107" xml:space="preserve"><span class="text" id="span_001660" smilref="Machine_Learning00011.smil#span_001660">Use the following </span><code xml:space="preserve" id="code_000559" smilref="Machine_Learning00011.smil#code_000559">mapper</code><span class="text" id="span_001661" smilref="Machine_Learning00011.smil#span_001661"> code within your class:</span></p>
                <p xml:space="preserve" id="p_000722"><code class="preserve-whitespace" xml:space="preserve" id="code_000560"><strong id="strong_000481" smilref="Machine_Learning00011.smil#strong_000481">import</strong><span class="text" id="span_001662" smilref="Machine_Learning00011.smil#span_001662"> java.io.IOException;
</span><strong id="strong_000482" smilref="Machine_Learning00011.smil#strong_000482">import</strong><span class="text" id="span_001663" smilref="Machine_Learning00011.smil#span_001663"> java.util.regex.Matcher;
</span><strong id="strong_000483" smilref="Machine_Learning00011.smil#strong_000483">import</strong><span class="text" id="span_001664" smilref="Machine_Learning00011.smil#span_001664"> java.util.regex.Pattern;
</span><strong id="strong_000484" smilref="Machine_Learning00011.smil#strong_000484">import</strong><span class="text" id="span_001665" smilref="Machine_Learning00011.smil#span_001665"> org.apache.hadoop.io.IntWritable;
</span><strong id="strong_000485" smilref="Machine_Learning00011.smil#strong_000485">import</strong><span class="text" id="span_001666" smilref="Machine_Learning00011.smil#span_001666"> org.apache.hadoop.io.LongWritable;
</span><strong id="strong_000486" smilref="Machine_Learning00011.smil#strong_000486">import</strong><span class="text" id="span_001667" smilref="Machine_Learning00011.smil#span_001667"> org.apache.hadoop.io.Text;
</span><strong id="strong_000487" smilref="Machine_Learning00011.smil#strong_000487">import</strong><span class="text" id="span_001668" smilref="Machine_Learning00011.smil#span_001668"> org.apache.hadoop.mapred.MapReduceBase;
</span><strong id="strong_000488" smilref="Machine_Learning00011.smil#strong_000488">import</strong><span class="text" id="span_001669" smilref="Machine_Learning00011.smil#span_001669"> org.apache.hadoop.mapred.Mapper;
</span><strong id="strong_000489" smilref="Machine_Learning00011.smil#strong_000489">import</strong><span class="text" id="span_001670" smilref="Machine_Learning00011.smil#span_001670"> org.apache.hadoop.mapred.OutputCollector;
</span><strong id="strong_000490" smilref="Machine_Learning00011.smil#strong_000490">import</strong><span class="text" id="span_001671" smilref="Machine_Learning00011.smil#span_001671"> org.apache.hadoop.mapred.Reporter;
</span><strong id="strong_000491" smilref="Machine_Learning00011.smil#strong_000491">public</strong> <strong id="strong_000492" smilref="Machine_Learning00011.smil#strong_000492">class</strong><span class="text" id="span_001672" smilref="Machine_Learning00011.smil#span_001672"> HashtagMapper </span><strong id="strong_000493" smilref="Machine_Learning00011.smil#strong_000493">extends</strong><span class="text" id="span_001673" smilref="Machine_Learning00011.smil#span_001673"> MapReduceBase </span><strong id="strong_000494" smilref="Machine_Learning00011.smil#strong_000494">implements</strong><span class="text" id="span_001674" smilref="Machine_Learning00011.smil#span_001674">
        Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    </span><strong id="strong_000495" smilref="Machine_Learning00011.smil#strong_000495">private</strong> <strong id="strong_000496" smilref="Machine_Learning00011.smil#strong_000496">final</strong> <strong id="strong_000497" smilref="Machine_Learning00011.smil#strong_000497">static</strong><span class="text" id="span_001675" smilref="Machine_Learning00011.smil#span_001675"> IntWritable </span><em id="em_000324" smilref="Machine_Learning00011.smil#em_000324">one</em><span class="text" id="span_001676" smilref="Machine_Learning00011.smil#span_001676"> = </span><strong id="strong_000498" smilref="Machine_Learning00011.smil#strong_000498">new</strong><span class="text" id="span_001677" smilref="Machine_Learning00011.smil#span_001677"> IntWritable(1);
    </span><strong id="strong_000499" smilref="Machine_Learning00011.smil#strong_000499">private</strong><span class="text" id="span_001678" smilref="Machine_Learning00011.smil#span_001678"> Text word = </span><strong id="strong_000500" smilref="Machine_Learning00011.smil#strong_000500">new</strong><span class="text" id="span_001679" smilref="Machine_Learning00011.smil#span_001679"> Text();
    @Override
    </span><strong id="strong_000501" smilref="Machine_Learning00011.smil#strong_000501">public</strong> <strong id="strong_000502" smilref="Machine_Learning00011.smil#strong_000502">void</strong><span class="text" id="span_001680" smilref="Machine_Learning00011.smil#span_001680"> map(LongWritable key, Text value,
            OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)
            </span><strong id="strong_000503" smilref="Machine_Learning00011.smil#strong_000503">throws</strong><span class="text" id="span_001681" smilref="Machine_Learning00011.smil#span_001681"> IOException {
        String inputLine = value.toString().toLowerCase();
        String[] splitLine = inputLine.split("\\|");
        Pattern pattern = Pattern.</span><em id="em_000325" smilref="Machine_Learning00011.smil#em_000325">compile</em><span class="text" id="span_001682" smilref="Machine_Learning00011.smil#span_001682">("#[\\w]+");
        </span><strong id="strong_000504" smilref="Machine_Learning00011.smil#strong_000504">if</strong><span class="text" id="span_001683" smilref="Machine_Learning00011.smil#span_001683"> (splitLine.length &gt; 1) {
            Matcher matcher = pattern.matcher(splitLine[1]);
            </span><strong id="strong_000505" smilref="Machine_Learning00011.smil#strong_000505">while</strong><span class="text" id="span_001684" smilref="Machine_Learning00011.smil#span_001684"> (matcher.find()) {
                word.set(matcher.group());
                output.collect(word, </span><em id="em_000326" smilref="Machine_Learning00011.smil#em_000326">one</em><span class="text" id="span_001685" smilref="Machine_Learning00011.smil#span_001685">);
            }
        }
    }
}</span></code></p>
                <pagenum epub:type="pagebreak" id="p240" page="normal" smilref="Machine_Learning00011.smil#p240">240</pagenum>
                <p id="c10-c10-para-0108" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0108">As you can see, it's a simple class. You're going to scale it with Hadoop to cope with large volumes of data. Try walking through it line by line.</p>
                <p id="c10-c10-para-0109" xml:space="preserve"><span class="text" id="span_001686" smilref="Machine_Learning00011.smil#span_001686">When a line of text is mapped, it's passed through the map method. The </span><code xml:space="preserve" id="code_000561" smilref="Machine_Learning00011.smil#code_000561">Text</code><span class="text" id="span_001687" smilref="Machine_Learning00011.smil#span_001687"> value saves that as a Java string and converts it to lowercase. Why lowercase? The mapping phase, for example, sees the words </span><code xml:space="preserve" id="code_000562" smilref="Machine_Learning00011.smil#code_000562">#Fashion</code><span class="text" id="span_001688" smilref="Machine_Learning00011.smil#span_001688">, </span><code xml:space="preserve" id="code_000563" smilref="Machine_Learning00011.smil#code_000563">#fashion</code><span class="text" id="span_001689" smilref="Machine_Learning00011.smil#span_001689">, and </span><code xml:space="preserve" id="code_000564" smilref="Machine_Learning00011.smil#code_000564">#FASHION</code><span class="text" id="span_001690" smilref="Machine_Learning00011.smil#span_001690"> as three separate entries and is scored accordingly. By converting them to lowercase, you have one hashtag that would be counted three times. It's cleaner and saves in post processing after the Hadoop job is finished.</span></p>
                <p id="c10-c10-para-0110" xml:space="preserve" smilref="Machine_Learning00011.smil#c10-c10-para-0110">Because the incoming data is pipe delimited, I've split that line into a string array. The date is going to be ignored, but you will process the tweet content.</p>
                <p id="c10-c10-para-0111" xml:space="preserve"><span class="text" id="span_001691" smilref="Machine_Learning00011.smil#span_001691">Using Java's regular expression engine, you create a basic pattern to match all the hashtags that appear in the content. For every matched hashtag, the </span><code xml:space="preserve" id="code_000565" smilref="Machine_Learning00011.smil#code_000565">mapper</code><span class="text" id="span_001692" smilref="Machine_Learning00011.smil#span_001692"> registers the matched word and assigns the value 1 to it.</span></p>
                <p id="c10-c10-para-0112" xml:space="preserve"><span class="text" id="span_001693" smilref="Machine_Learning00011.smil#span_001693">That's the basic </span><code xml:space="preserve" id="code_000566" smilref="Machine_Learning00011.smil#code_000566">mapper</code><span class="text" id="span_001694" smilref="Machine_Learning00011.smil#span_001694">. As you can see, it's a simple piece of code that consumes the text and matches all the hashtags. The next section examines the </span><code xml:space="preserve" id="code_000567" smilref="Machine_Learning00011.smil#code_000567">reducer</code><span class="text" id="span_001695" smilref="Machine_Learning00011.smil#span_001695"> class.</span></p>
              </level4>
              <level4 id="level4_000098">
                <h4 xml:space="preserve" id="h4_000098" smilref="Machine_Learning00011.smil#h4_000098">Creating the Reducer</h4>
                <p xml:space="preserve" id="p_000723"><span class="text" id="span_001696" smilref="Machine_Learning00011.smil#span_001696">At present you have a </span><code xml:space="preserve" id="code_000568" smilref="Machine_Learning00011.smil#code_000568">mapper</code><span class="text" id="span_001697" smilref="Machine_Learning00011.smil#span_001697"> that is registering the value of 1 to every matching hashtag from the regular expression. The </span><code xml:space="preserve" id="code_000569" smilref="Machine_Learning00011.smil#code_000569">reducer</code><span class="text" id="span_001698" smilref="Machine_Learning00011.smil#span_001698"> collates all that data and comes up with the final total for each key (hashtag) that it finds.</span></p>
                <p id="c10-c10-para-0114" xml:space="preserve"><span class="text" id="span_001699" smilref="Machine_Learning00011.smil#span_001699">Create a new class called </span><code xml:space="preserve" id="code_000570" smilref="Machine_Learning00011.smil#code_000570">HashtagReducer.java</code><span class="text" id="span_001700" smilref="Machine_Learning00011.smil#span_001700"> and copy the following code into it:</span></p>
                <p xml:space="preserve" id="p_000724"><code class="preserve-whitespace" xml:space="preserve" id="code_000571"><strong id="strong_000506" smilref="Machine_Learning00011.smil#strong_000506">import</strong><span class="text" id="span_001701" smilref="Machine_Learning00011.smil#span_001701"> java.io.IOException;
</span><strong id="strong_000507" smilref="Machine_Learning00011.smil#strong_000507">import</strong><span class="text" id="span_001702" smilref="Machine_Learning00011.smil#span_001702"> java.util.Iterator;
</span><strong id="strong_000508" smilref="Machine_Learning00011.smil#strong_000508">import</strong><span class="text" id="span_001703" smilref="Machine_Learning00011.smil#span_001703"> org.apache.hadoop.io.IntWritable;
</span><strong id="strong_000509" smilref="Machine_Learning00011.smil#strong_000509">import</strong><span class="text" id="span_001704" smilref="Machine_Learning00011.smil#span_001704"> org.apache.hadoop.io.Text;
</span><strong id="strong_000510" smilref="Machine_Learning00011.smil#strong_000510">import</strong><span class="text" id="span_001705" smilref="Machine_Learning00011.smil#span_001705"> org.apache.hadoop.mapred.MapReduceBase;
</span><strong id="strong_000511" smilref="Machine_Learning00011.smil#strong_000511">import</strong><span class="text" id="span_001706" smilref="Machine_Learning00011.smil#span_001706"> org.apache.hadoop.mapred.OutputCollector;
</span><strong id="strong_000512" smilref="Machine_Learning00011.smil#strong_000512">import</strong><span class="text" id="span_001707" smilref="Machine_Learning00011.smil#span_001707"> org.apache.hadoop.mapred.Reducer;
</span><strong id="strong_000513" smilref="Machine_Learning00011.smil#strong_000513">import</strong><span class="text" id="span_001708" smilref="Machine_Learning00011.smil#span_001708"> org.apache.hadoop.mapred.Reporter;
</span><strong id="strong_000514" smilref="Machine_Learning00011.smil#strong_000514">public</strong> <strong id="strong_000515" smilref="Machine_Learning00011.smil#strong_000515">class</strong><span class="text" id="span_001709" smilref="Machine_Learning00011.smil#span_001709"> HashtagReducer </span><strong id="strong_000516" smilref="Machine_Learning00011.smil#strong_000516">extends</strong><span class="text" id="span_001710" smilref="Machine_Learning00011.smil#span_001710"> MapReduceBase </span><strong id="strong_000517" smilref="Machine_Learning00011.smil#strong_000517">implements</strong><span class="text" id="span_001711" smilref="Machine_Learning00011.smil#span_001711">
Reducer&lt;Text, IntWritable, Text, IntWritable&gt;{
    @Override
    </span><strong id="strong_000518" smilref="Machine_Learning00011.smil#strong_000518">public</strong> <strong id="strong_000519" smilref="Machine_Learning00011.smil#strong_000519">void</strong><span class="text" id="span_001712" smilref="Machine_Learning00011.smil#span_001712"> reduce(Text key, Iterator&lt;IntWritable&gt; values,
            OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)
            </span><strong id="strong_000520" smilref="Machine_Learning00011.smil#strong_000520">throws</strong><span class="text" id="span_001713" smilref="Machine_Learning00011.smil#span_001713"> IOException {
        </span><strong id="strong_000521" smilref="Machine_Learning00011.smil#strong_000521">int</strong><span class="text" id="span_001714" smilref="Machine_Learning00011.smil#span_001714"> sum = 0;
        </span><strong id="strong_000522" smilref="Machine_Learning00011.smil#strong_000522">while</strong><span class="text" id="span_001715" smilref="Machine_Learning00011.smil#span_001715"> (values.hasNext()) {
            sum += values.next().get();
        }
        output.collect(key, </span><strong id="strong_000523" smilref="Machine_Learning00011.smil#strong_000523">new</strong><span class="text" id="span_001716" smilref="Machine_Learning00011.smil#span_001716"> IntWritable(sum));
    }
}</span></code></p>
                <pagenum epub:type="pagebreak" id="p241" page="normal" smilref="Machine_Learning00011.smil#p241">241</pagenum>
                <p id="c10-c10-para-0115" xml:space="preserve"><span class="text" id="span_001717" smilref="Machine_Learning00011.smil#span_001717">The </span><code xml:space="preserve" id="code_000572" smilref="Machine_Learning00011.smil#code_000572">reducer</code><span class="text" id="span_001718" smilref="Machine_Learning00011.smil#span_001718"> takes every word that has been recorded by the </span><code xml:space="preserve" id="code_000573" smilref="Machine_Learning00011.smil#code_000573">mapper</code><span class="text" id="span_001719" smilref="Machine_Learning00011.smil#span_001719"> and adds the totals. So, for example, the </span><code xml:space="preserve" id="code_000574" smilref="Machine_Learning00011.smil#code_000574">mapper</code><span class="text" id="span_001720" smilref="Machine_Learning00011.smil#span_001720"> has recorded the following:</span></p>
                <p xml:space="preserve" id="p_000725"><code class="preserve-whitespace" xml:space="preserve" id="code_000575" smilref="Machine_Learning00011.smil#code_000575">#fashion,1
#shoes,1
#shoes,1
#fashion,1
#fashion,1</code></p>
                <p id="c10-c10-para-0116" xml:space="preserve"><span class="text" id="span_001721" smilref="Machine_Learning00011.smil#span_001721">The </span><code xml:space="preserve" id="code_000576" smilref="Machine_Learning00011.smil#code_000576">reducer</code><span class="text" id="span_001722" smilref="Machine_Learning00011.smil#span_001722"> combines the results of each key (each hashtag in this case) and adds them, so the final result looks like the following:</span></p>
                <p xml:space="preserve" id="p_000726"><code class="preserve-whitespace" xml:space="preserve" id="code_000577" smilref="Machine_Learning00011.smil#code_000577">#fashion,3
#shoes,2</code></p>
                <p id="c10-c10-para-0117" xml:space="preserve"><span class="text" id="span_001723" smilref="Machine_Learning00011.smil#span_001723">You have your </span><code xml:space="preserve" id="code_000578" smilref="Machine_Learning00011.smil#code_000578">mapper</code><span class="text" id="span_001724" smilref="Machine_Learning00011.smil#span_001724"> and a </span><code xml:space="preserve" id="code_000579" smilref="Machine_Learning00011.smil#code_000579">reducer</code><span class="text" id="span_001725" smilref="Machine_Learning00011.smil#span_001725">. The last thing to do is create a job configuration class so Hadoop can run the job.</span></p>
              </level4>
              <level4 id="level4_000099">
                <h4 xml:space="preserve" id="h4_000099" smilref="Machine_Learning00011.smil#h4_000099">Creating the Job Configuration</h4>
                <p xml:space="preserve" id="p_000727"><span class="text" id="span_001726" smilref="Machine_Learning00011.smil#span_001726">The job configuration is made up of a number of components that tell Hadoop what </span><code xml:space="preserve" id="code_000580" smilref="Machine_Learning00011.smil#code_000580">mapper</code><span class="text" id="span_001727" smilref="Machine_Learning00011.smil#span_001727"> and </span><code xml:space="preserve" id="code_000581" smilref="Machine_Learning00011.smil#code_000581">reducer</code><span class="text" id="span_001728" smilref="Machine_Learning00011.smil#span_001728"> classes to use and where to expect the input and output files to live.</span></p>
                <p id="c10-c10-para-0119" xml:space="preserve"><span class="text" id="span_001729" smilref="Machine_Learning00011.smil#span_001729">Create a new </span><code xml:space="preserve" id="code_000582" smilref="Machine_Learning00011.smil#code_000582">Java</code><span class="text" id="span_001730" smilref="Machine_Learning00011.smil#span_001730"> class and call it </span><code xml:space="preserve" id="code_000583" smilref="Machine_Learning00011.smil#code_000583">HashtagJob.java</code><span class="text" id="span_001731" smilref="Machine_Learning00011.smil#span_001731">. Then use the following code:</span></p>
                <p xml:space="preserve" id="p_000728"><code class="preserve-whitespace" xml:space="preserve" id="code_000584"><strong id="strong_000524" smilref="Machine_Learning00011.smil#strong_000524">import</strong><span class="text" id="span_001732" smilref="Machine_Learning00011.smil#span_001732"> org.apache.hadoop.fs.Path;
</span><strong id="strong_000525" smilref="Machine_Learning00011.smil#strong_000525">import</strong><span class="text" id="span_001733" smilref="Machine_Learning00011.smil#span_001733"> org.apache.hadoop.io.IntWritable;
</span><strong id="strong_000526" smilref="Machine_Learning00011.smil#strong_000526">import</strong><span class="text" id="span_001734" smilref="Machine_Learning00011.smil#span_001734"> org.apache.hadoop.io.Text;
</span><strong id="strong_000527" smilref="Machine_Learning00011.smil#strong_000527">import</strong><span class="text" id="span_001735" smilref="Machine_Learning00011.smil#span_001735"> org.apache.hadoop.mapred.JobClient;
</span><strong id="strong_000528" smilref="Machine_Learning00011.smil#strong_000528">import</strong><span class="text" id="span_001736" smilref="Machine_Learning00011.smil#span_001736"> org.apache.hadoop.mapred.JobConf;
</span><strong id="strong_000529" smilref="Machine_Learning00011.smil#strong_000529">import</strong><span class="text" id="span_001737" smilref="Machine_Learning00011.smil#span_001737"> org.apache.hadoop.mapred.TextInputFormat;
</span><strong id="strong_000530" smilref="Machine_Learning00011.smil#strong_000530">import</strong><span class="text" id="span_001738" smilref="Machine_Learning00011.smil#span_001738"> org.apache.hadoop.mapred.TextOutputFormat;
</span><strong id="strong_000531" smilref="Machine_Learning00011.smil#strong_000531">import</strong><span class="text" id="span_001739" smilref="Machine_Learning00011.smil#span_001739"> org.apache.hadoop.mapred.FileInputFormat;
</span><strong id="strong_000532" smilref="Machine_Learning00011.smil#strong_000532">import</strong><span class="text" id="span_001740" smilref="Machine_Learning00011.smil#span_001740"> org.apache.hadoop.mapred.FileOutputFormat;
</span><strong id="strong_000533" smilref="Machine_Learning00011.smil#strong_000533">public</strong> <strong id="strong_000534" smilref="Machine_Learning00011.smil#strong_000534">class</strong><span class="text" id="span_001741" smilref="Machine_Learning00011.smil#span_001741"> HashtagJob {
    </span><strong id="strong_000535" smilref="Machine_Learning00011.smil#strong_000535">public</strong> <strong id="strong_000536" smilref="Machine_Learning00011.smil#strong_000536">static</strong> <strong id="strong_000537" smilref="Machine_Learning00011.smil#strong_000537">void</strong><span class="text" id="span_001742" smilref="Machine_Learning00011.smil#span_001742"> main(String[] args) </span><strong id="strong_000538" smilref="Machine_Learning00011.smil#strong_000538">throws</strong><span class="text" id="span_001743" smilref="Machine_Learning00011.smil#span_001743"> Exception {
        JobConf conf = </span><strong id="strong_000539" smilref="Machine_Learning00011.smil#strong_000539">new</strong><span class="text" id="span_001744" smilref="Machine_Learning00011.smil#span_001744"> JobConf(HashtagJob.</span><strong id="strong_000540" smilref="Machine_Learning00011.smil#strong_000540">class</strong><span class="text" id="span_001745" smilref="Machine_Learning00011.smil#span_001745">);
        conf.setJobName("HashtagMiner");
        conf.setOutputKeyClass(Text.</span><strong id="strong_000541" smilref="Machine_Learning00011.smil#strong_000541">class</strong><span class="text" id="span_001746" smilref="Machine_Learning00011.smil#span_001746">);
        conf.setOutputValueClass(IntWritable.</span><strong id="strong_000542" smilref="Machine_Learning00011.smil#strong_000542">class</strong><span class="text" id="span_001747" smilref="Machine_Learning00011.smil#span_001747">);
        conf.setMapperClass(HashtagMapper.</span><strong id="strong_000543" smilref="Machine_Learning00011.smil#strong_000543">class</strong><span class="text" id="span_001748" smilref="Machine_Learning00011.smil#span_001748">);
        conf.setReducerClass(HashtagReducer.</span><strong id="strong_000544" smilref="Machine_Learning00011.smil#strong_000544">class</strong><span class="text" id="span_001749" smilref="Machine_Learning00011.smil#span_001749">);
        conf.setInputFormat(TextInputFormat.</span><strong id="strong_000545" smilref="Machine_Learning00011.smil#strong_000545">class</strong><span class="text" id="span_001750" smilref="Machine_Learning00011.smil#span_001750">);
        conf.setOutputFormat(TextOutputFormat.</span><strong id="strong_000546" smilref="Machine_Learning00011.smil#strong_000546">class</strong><span class="text" id="span_001751" smilref="Machine_Learning00011.smil#span_001751">);
        FileInputFormat.</span><em id="em_000327" smilref="Machine_Learning00011.smil#em_000327">setInputPaths</em><span class="text" id="span_001752" smilref="Machine_Learning00011.smil#span_001752">(conf, </span><strong id="strong_000547" smilref="Machine_Learning00011.smil#strong_000547">new</strong><span class="text" id="span_001753" smilref="Machine_Learning00011.smil#span_001753"> Path(args[0]));
        FileOutputFormat.</span><em id="em_000328" smilref="Machine_Learning00011.smil#em_000328">setOutputPath</em><span class="text" id="span_001754" smilref="Machine_Learning00011.smil#span_001754">(conf, </span><strong id="strong_000548" smilref="Machine_Learning00011.smil#strong_000548">new</strong><span class="text" id="span_001755" smilref="Machine_Learning00011.smil#span_001755"> Path(args[1]));
        JobClient.</span><em id="em_000329" smilref="Machine_Learning00011.smil#em_000329">runJob</em><span class="text" id="span_001756" smilref="Machine_Learning00011.smil#span_001756">(conf);
    }
}</span></code></p>
                <pagenum epub:type="pagebreak" id="p242" page="normal" smilref="Machine_Learning00011.smil#p242">242</pagenum>
                <p id="c10-c10-para-0120" xml:space="preserve"><span class="text" id="span_001757" smilref="Machine_Learning00011.smil#span_001757">The output key and values are set (text and an integer). Next, you tell the job configuration which </span><code xml:space="preserve" id="code_000585" smilref="Machine_Learning00011.smil#code_000585">mapper</code><span class="text" id="span_001758" smilref="Machine_Learning00011.smil#span_001758"> and </span><code xml:space="preserve" id="code_000586" smilref="Machine_Learning00011.smil#code_000586">reducer</code><span class="text" id="span_001759" smilref="Machine_Learning00011.smil#span_001759"> classes to use. The input and output file types are defined—both text format for this example—and you specify where the input and output folders on the file system will live.</span></p>
                <p id="c10-c10-para-0121" xml:space="preserve"><span class="text" id="span_001760" smilref="Machine_Learning00011.smil#span_001760">Notice that the file system folders are read in from the values of the command line, </span><code xml:space="preserve" id="code_000587" smilref="Machine_Learning00011.smil#code_000587">args[0]</code><span class="text" id="span_001761" smilref="Machine_Learning00011.smil#span_001761"> for the input directory and </span><code xml:space="preserve" id="code_000588" smilref="Machine_Learning00011.smil#code_000588">args[1]</code><span class="text" id="span_001762" smilref="Machine_Learning00011.smil#span_001762"> for the output directory.</span></p>
                <p id="c10-c10-para-0122" xml:space="preserve"><span class="text" id="span_001763" smilref="Machine_Learning00011.smil#span_001763">The final line of the class is Hadoop's </span><code xml:space="preserve" id="code_000589" smilref="Machine_Learning00011.smil#code_000589">JobClient</code><span class="text" id="span_001764" smilref="Machine_Learning00011.smil#span_001764"> running the job configuration. The only thing left to do is export the </span><code xml:space="preserve" id="code_000590" smilref="Machine_Learning00011.smil#code_000590">jar</code><span class="text" id="span_001765" smilref="Machine_Learning00011.smil#span_001765"> file, and then you can do a first test.</span></p>
              </level4>
              <level4 id="level4_000100">
                <h4 xml:space="preserve" id="h4_000100" smilref="Machine_Learning00011.smil#h4_000100">Exporting the Jar</h4>
                <p xml:space="preserve" id="p_000729"><span class="text" id="span_001766" smilref="Machine_Learning00011.smil#span_001766">The </span><code xml:space="preserve" id="code_000591" smilref="Machine_Learning00011.smil#code_000591">jar</code><span class="text" id="span_001767" smilref="Machine_Learning00011.smil#span_001767"> file is comprised of the </span><code xml:space="preserve" id="code_000592" smilref="Machine_Learning00011.smil#code_000592">mapper</code><span class="text" id="span_001768" smilref="Machine_Learning00011.smil#span_001768">, the </span><code xml:space="preserve" id="code_000593" smilref="Machine_Learning00011.smil#code_000593">reducer</code><span class="text" id="span_001769" smilref="Machine_Learning00011.smil#span_001769">, and the job configuration. You can have as many classes in there as you want (if you have multiple jobs and functions), but I find it easier to stick with one specific function (in this case mining hashtags) in one </span><code xml:space="preserve" id="code_000594" smilref="Machine_Learning00011.smil#code_000594">jar</code><span class="text" id="span_001770" smilref="Machine_Learning00011.smil#span_001770"> file.</span></p>
                <p id="c10-c10-para-0124" xml:space="preserve"><span class="text" id="span_001771" smilref="Machine_Learning00011.smil#span_001771">To export the </span><code xml:space="preserve" id="code_000595" smilref="Machine_Learning00011.smil#code_000595">jar</code><span class="text" id="span_001772" smilref="Machine_Learning00011.smil#span_001772"> file, select File →Export and select Jar File insert (see </span><a id="c10-c10-fig-anc-0004" href="#c10-c10-fig-0004" external="false" smilref="Machine_Learning00011.smil#c10-c10-fig-anc-0004">Figure 10-4</a><span class="text" id="span_001773" smilref="Machine_Learning00011.smil#span_001773">). Ensure that you have the correct project selected and that you've selected the Export All Output Folders option. Call the </span><code xml:space="preserve" id="code_000596" smilref="Machine_Learning00011.smil#code_000596">jar</code><span class="text" id="span_001774" smilref="Machine_Learning00011.smil#span_001774"> file </span><strong id="strong_000549" smilref="Machine_Learning00011.smil#strong_000549">hashtagmining.jar</strong><span class="text" id="span_001775" smilref="Machine_Learning00011.smil#span_001775"> and click Finish.</span></p>
                <figure id="figure_000102">
                  <img class="center" src="images/c10f004.jpg" alt="image" id="img_000129" />
                  <figcaption id="figcaption_000088">
                    <p xml:space="preserve" id="p_000730"><span class="figureLabel" id="span_001776"><a id="c10-c10-fig-0004" href="#c10-c10-fig-anc-0004" external="false"><strong id="strong_000550" smilref="Machine_Learning00011.smil#strong_000550">Figure 10-4</strong></a></span><span class="text" id="span_001777" smilref="Machine_Learning00011.smil#span_001777"> Exporting the jar file</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000101">
                <h4 xml:space="preserve" id="h4_000101" smilref="Machine_Learning00011.smil#h4_000101">Testing on a File</h4>
                <p xml:space="preserve" id="p_000731" smilref="Machine_Learning00011.smil#p_000731">It's always a good idea to test the new MapReduce algorithm against a small sample of data to ensure that the output is what you're expecting. I know it sounds like common sense, but experience has shown me many things.</p>
                <pagenum epub:type="pagebreak" id="p243" page="normal" smilref="Machine_Learning00011.smil#p243">243</pagenum>
                <p id="c10-c10-para-0126" xml:space="preserve"><span class="text" id="span_001778" smilref="Machine_Learning00011.smil#span_001778">First things first, create a directory for the test to happen; I'm going to call mine </span><code xml:space="preserve" id="code_000597" smilref="Machine_Learning00011.smil#code_000597">hashtagtest</code><span class="text" id="span_001779" smilref="Machine_Learning00011.smil#span_001779">. Within that directory, create another directory called </span><code xml:space="preserve" id="code_000598" smilref="Machine_Learning00011.smil#code_000598">input</code><span class="text" id="span_001780" smilref="Machine_Learning00011.smil#span_001780">.</span></p>
                <p xml:space="preserve" id="p_000732"><code class="preserve-whitespace" xml:space="preserve" id="code_000599" smilref="Machine_Learning00011.smil#code_000599">mkdir hashtagtest
cd hashtagtest
mkdir input</code></p>
                <p id="c10-c10-para-0127" xml:space="preserve"><span class="text" id="span_001781" smilref="Machine_Learning00011.smil#span_001781">I like to keep </span><code xml:space="preserve" id="code_000600" smilref="Machine_Learning00011.smil#code_000600">jar</code><span class="text" id="span_001782" smilref="Machine_Learning00011.smil#span_001782"> files within the testing directory, as it makes things easier when working with the command line. Therefore, I'm going to copy my </span><code xml:space="preserve" id="code_000601" smilref="Machine_Learning00011.smil#code_000601">jar</code><span class="text" id="span_001783" smilref="Machine_Learning00011.smil#span_001783"> file to the </span><code xml:space="preserve" id="code_000602" smilref="Machine_Learning00011.smil#code_000602">hashtagtest</code><span class="text" id="span_001784" smilref="Machine_Learning00011.smil#span_001784"> directory:</span></p>
                <p xml:space="preserve" id="p_000733"><code class="preserve-whitespace" xml:space="preserve" id="code_000603" smilref="Machine_Learning00011.smil#code_000603">cp /home/jason/hashtagmining.jar ./</code></p>
                <p id="c10-c10-para-0128" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0128">Assuming that you have the processed data output from Chapter 9, you can dump a certain number of lines into a new text file to use for the testing:</p>
                <p xml:space="preserve" id="p_000734"><code class="preserve-whitespace" xml:space="preserve" id="code_000604" smilref="Machine_Learning00012.smil#code_000604">head –n 200 /tmp/xd/output/fashiontweets.out &gt; ./input/input.txt</code></p>
                <p id="c10-c10-para-0129" xml:space="preserve"><span class="text" id="span_001785" smilref="Machine_Learning00012.smil#span_001785">The </span><code xml:space="preserve" id="code_000605" smilref="Machine_Learning00012.smil#code_000605">head</code><span class="text" id="span_001786" smilref="Machine_Learning00012.smil#span_001786"> command should be familiar to you, as you used it earlier in this chapter. This time it's taking the first 200 lines of the processed tweets and directing the output to a new text file called </span><code xml:space="preserve" id="code_000606" smilref="Machine_Learning00012.smil#code_000606">input.txt</code><span class="text" id="span_001787" smilref="Machine_Learning00012.smil#span_001787"> in the </span><code xml:space="preserve" id="code_000607" smilref="Machine_Learning00012.smil#code_000607">input</code><span class="text" id="span_001788" smilref="Machine_Learning00012.smil#span_001788"> directory. Everything's in place now, and you can run the basic test.</span></p>
                <p id="c10-c10-para-0130" xml:space="preserve"><span class="text" id="span_001789" smilref="Machine_Learning00012.smil#span_001789">Hadoop has three running modes: a single-node cluster, a multi-node cluster, and a local mode. On a development machine it's nice to have a local version of Hadoop on hand, so you can test your code before it's deployed to the main cluster. </span><pagenum epub:type="pagebreak" id="p244" page="normal" smilref="Machine_Learning00012.smil#p244">244</pagenum><span class="text" id="span_001790" smilref="Machine_Learning00012.smil#span_001790">The local mode doesn't use HDFS; instead it uses the data that's in the local file system. This is perfect for testing, as it means you're not copying small amounts of data to HDFS for testing. Nothing changes from the command-line perspective, so to test the new </span><code xml:space="preserve" id="code_000608" smilref="Machine_Learning00012.smil#code_000608">jar</code><span class="text" id="span_001791" smilref="Machine_Learning00012.smil#span_001791"> file you run the following command:</span></p>
                <p xml:space="preserve" id="p_000735"><code class="preserve-whitespace" xml:space="preserve" id="code_000609" smilref="Machine_Learning00012.smil#code_000609">hadoop jar hashtagmining.jar HashtagJob input output</code></p>
                <p id="c10-c10-para-0131" xml:space="preserve"><span class="text" id="span_001792" smilref="Machine_Learning00012.smil#span_001792">You see the MapReduce job run in exactly the same way as it did when the single-node cluster was tested in the first walkthrough. After it's finished, go to the output directory and you see two files. The first is a file called </span><code xml:space="preserve" id="code_000610" smilref="Machine_Learning00012.smil#code_000610">_SUCCESS</code><span class="text" id="span_001793" smilref="Machine_Learning00012.smil#span_001793"> to show that Hadoop had completed the job without any problems. The second file is called </span><code xml:space="preserve" id="code_000611" smilref="Machine_Learning00012.smil#code_000611">part-00000</code><span class="text" id="span_001794" smilref="Machine_Learning00012.smil#span_001794">; this is the text file with the results from the MapReduce test.</span></p>
                <p id="c10-c10-para-0132" xml:space="preserve"><span class="text" id="span_001795" smilref="Machine_Learning00012.smil#span_001795">Use the </span><code xml:space="preserve" id="code_000612" smilref="Machine_Learning00012.smil#code_000612">more</code><span class="text" id="span_001796" smilref="Machine_Learning00012.smil#span_001796"> command to dump the contents of the file out to the terminal screen, one screen (page) at a time:</span></p>
                <p xml:space="preserve" id="p_000736"><code class="preserve-whitespace" xml:space="preserve" id="code_000613" smilref="Machine_Learning00012.smil#code_000613">more  output/part-00000</code></p>
                <p id="c10-c10-para-0133" xml:space="preserve"><span class="text" id="span_001797" smilref="Machine_Learning00012.smil#span_001797">The basic MapReduce job you created doesn't order the results; it just outputs the hashtag and number of times it was found. For a quick look at the most popular hashtags, you can use the </span><code xml:space="preserve" id="code_000614" smilref="Machine_Learning00012.smil#code_000614">sort</code><span class="text" id="span_001798" smilref="Machine_Learning00012.smil#span_001798"> and </span><code xml:space="preserve" id="code_000615" smilref="Machine_Learning00012.smil#code_000615">head</code><span class="text" id="span_001799" smilref="Machine_Learning00012.smil#span_001799"> commands to show the top 20 hashtags.</span></p>
                <p xml:space="preserve" id="p_000737"><code class="preserve-whitespace" xml:space="preserve" id="code_000616" smilref="Machine_Learning00012.smil#code_000616">sort -k 2 -n -r output/part-00000 | head -20 </code></p>
                <p id="c10-c10-para-0134" xml:space="preserve"><span class="text" id="span_001800" smilref="Machine_Learning00012.smil#span_001800">The </span><code xml:space="preserve" id="code_000617" smilref="Machine_Learning00012.smil#code_000617">sort</code><span class="text" id="span_001801" smilref="Machine_Learning00012.smil#span_001801"> command is using three flags to process the output: The –</span><code xml:space="preserve" id="code_000618" smilref="Machine_Learning00012.smil#code_000618">k 2</code><span class="text" id="span_001802" smilref="Machine_Learning00012.smil#span_001802"> flag means that you're sorting on the second key position (the numeric output from the results); </span><code xml:space="preserve" id="code_000619" smilref="Machine_Learning00012.smil#code_000619">-n</code><span class="text" id="span_001803" smilref="Machine_Learning00012.smil#span_001803"> is to show a numeric sort; and </span><code xml:space="preserve" id="code_000620" smilref="Machine_Learning00012.smil#code_000620">–r</code><span class="text" id="span_001804" smilref="Machine_Learning00012.smil#span_001804"> is to show the results in reverse order. You see output that's something like the following:</span></p>
                <p xml:space="preserve" id="p_000738"><code class="preserve-whitespace" xml:space="preserve" id="code_000621" smilref="Machine_Learning00012.smil#code_000621">Jason-Bells-MacBook-Pro:output Jason$ sort –k 2 –n -r part-00000 | head -n 20
#fashion    157
#style    19
#etsy    12
#jewelry    12
#skirt    11
#outfit    10
#pencil    8
#vintage    8
#buciki    7
#fashionable    7
#fashionblogger    7
#fashiondiaries    7
#fashionstyle    7
#instafashion    7
#nowe    7
#sale    7
#szpilki    7
#deal    6
#dress    6
#cute    5</code></p>
                <pagenum epub:type="pagebreak" id="p245" page="normal" smilref="Machine_Learning00012.smil#p245">245</pagenum>
                <p id="c10-c10-para-0135" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0135">With the test working as expected, you can turn your attention to Spring XD again. It's time to get Hadoop and Spring XD to talk to each other.</p>
              </level4>
              <level4 id="level4_000102">
                <h4 xml:space="preserve" id="h4_000102" smilref="Machine_Learning00012.smil#h4_000102">Configuring Spring XD</h4>
                <p xml:space="preserve" id="p_000739" smilref="Machine_Learning00012.smil#p_000739">Until now, the streams that were created directed their output sinks to a file or logged on to the console. Within Spring XD there is an option to output directly to HDFS. You're running Apache Hadoop 1.2.1, so there is nothing to change in the configuration because this is what Spring XD defaults to.</p>
                <p id="c10-c10-para-0137" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0137">Previously, you've created Twitter streams that were piped through a customer processor to extract the date and content of the tweet. Here's a reminder from the XD shell:</p>
                <p xml:space="preserve" id="p_000740"><code class="preserve-whitespace" xml:space="preserve" id="code_000622" smilref="Machine_Learning00012.smil#code_000622">xd:&gt;stream create --name fashiontweets --definition "twitterstream --track='#fashion' | twitterstreamtransformer | file"</code></p>
                <p id="c10-c10-para-0138" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0138">To configure to use HDFS as the output sink, you need to stop that stream and create a new one. Before you do anything, you first need to tell Spring XD about your Hadoop NameNode:</p>
                <p xml:space="preserve" id="p_000741"><code class="preserve-whitespace" xml:space="preserve" id="code_000623" smilref="Machine_Learning00012.smil#code_000623">xd:&gt;hadoop config fs --namenode hdfs://localhost:9000</code></p>
                <p id="c10-c10-para-0139" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0139">Make sure your Hadoop single-node cluster is running, then you can create a new stream.</p>
                <p xml:space="preserve" id="p_000742"><code class="preserve-whitespace" xml:space="preserve" id="code_000624" smilref="Machine_Learning00012.smil#code_000624">xd:&gt;stream create --name fashiontweets --definition "twitterstream --track='#fashion' | twitterstreamtransformer | hdfs"</code></p>
                <p id="c10-c10-para-0140" xml:space="preserve"><span class="text" id="span_001805" smilref="Machine_Learning00012.smil#span_001805">From the operating system command line, you can see the output now being stored within HDFS. Using the </span><code xml:space="preserve" id="code_000625" smilref="Machine_Learning00012.smil#code_000625">hadoop</code><span class="text" id="span_001806" smilref="Machine_Learning00012.smil#span_001806"> command you can list the data:</span></p>
                <p xml:space="preserve" id="p_000743"><code class="preserve-whitespace" xml:space="preserve" id="code_000626" smilref="Machine_Learning00012.smil#code_000626">hadoop fs --ls /xd/fashiontweets</code></p>
                <p id="c10-c10-para-0141" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0141">You see the output listed within HDFS:</p>
                <p xml:space="preserve" id="p_000744"><code class="preserve-whitespace" xml:space="preserve" id="code_000627" smilref="Machine_Learning00012.smil#code_000627">jason@bigdatagames:˜$ hadoop fs  --ls /xd/fashiontweets
Found 2 items
-rw-r--r--   3 jason supergroup      22753 2014-01-19 20:07 /xd/fashiontweets/fashiontweets-0.log</code></p>
                <p id="c10-c10-para-0142" xml:space="preserve"><span class="text" id="span_001807" smilref="Machine_Learning00012.smil#span_001807">If Spring XD is writing to the file while you are inspecting it, then the file has </span><code xml:space="preserve" id="code_000628" smilref="Machine_Learning00012.smil#code_000628">.tmp</code><span class="text" id="span_001808" smilref="Machine_Learning00012.smil#span_001808"> on the end of it. You're not limited to one file being dumped within HDFS. With the </span><code xml:space="preserve" id="code_000629" smilref="Machine_Learning00012.smil#code_000629">–rollover</code><span class="text" id="span_001809" smilref="Machine_Learning00012.smil#span_001809"> flag, you can control how big the file can be before a new one is created.</span></p>
                <p xml:space="preserve" id="p_000745"><code class="preserve-whitespace" xml:space="preserve" id="code_000630" smilref="Machine_Learning00012.smil#code_000630">xd:&gt;stream create --name fashiontweets –definition  "twitterstream --track='#fashion' | twitterstreamtransformer | hdfs -–rollover=64M"
stream create --name fashiontweets --definition "twitterstream --track='#fashion' | twitterstreamtransformer | hdfs --rollover=64M"
18:46:26,272  WARN Spring Shell client.RestTemplate:566 - POST request for "http://localhost:9393/streams" resulted in 500 (Internal Server Error); invoking error handler
Command failed org.springframework.xd.rest.client.impl.SpringXDException: error occurred in message handler [moduleDeployer]</code></p>
                <pagenum epub:type="pagebreak" id="p246" page="normal" smilref="Machine_Learning00012.smil#p246">246</pagenum>
                <p id="c10-c10-para-0143" xml:space="preserve"><span class="text" id="span_001810" smilref="Machine_Learning00012.smil#span_001810">This would create a new text file when the current output file is 64 megabytes in size. You can still use the </span><code xml:space="preserve" id="code_000631" smilref="Machine_Learning00012.smil#code_000631">taps</code><span class="text" id="span_001811" smilref="Machine_Learning00012.smil#span_001811"> functions to write raw data to the file system as you want, but the data for analysis—the hashtag content—now goes to HDFS. With Spring XD configured you can run your Hadoop MapReduce job properly.</span></p>
              </level4>
              <level4 id="level4_000103">
                <h4 xml:space="preserve" id="h4_000103" smilref="Machine_Learning00012.smil#h4_000103">Testing on Streaming Data</h4>
                <p xml:space="preserve" id="p_000746" smilref="Machine_Learning00012.smil#p_000746">With your MapReduce job ready and Spring XD now sending streaming Twitter data directly to HDFS, you can perform some mining of hashtags.</p>
                <p id="c10-c10-para-0145" xml:space="preserve"><span class="text" id="span_001812" smilref="Machine_Learning00012.smil#span_001812">Find the directory where your exported </span><code xml:space="preserve" id="code_000632" smilref="Machine_Learning00012.smil#code_000632">jar</code><span class="text" id="span_001813" smilref="Machine_Learning00012.smil#span_001813"> file is and run the following </span><code xml:space="preserve" id="code_000633" smilref="Machine_Learning00012.smil#code_000633">hadoop</code><span class="text" id="span_001814" smilref="Machine_Learning00012.smil#span_001814"> command:</span></p>
                <p xml:space="preserve" id="p_000747"><code class="preserve-whitespace" xml:space="preserve" id="code_000634" smilref="Machine_Learning00012.smil#code_000634">hadoop jar hashtagmining.jar HashtagJob /xd/fashiontweets /fashionoutput </code></p>
                <p id="c10-c10-para-0146" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0146">Hadoop processes the data within HDFS in the same way it did in the local test. The output is still held within HDFS, so you need to merge it and save it to the local file system.</p>
                <p xml:space="preserve" id="p_000748"><code class="preserve-whitespace" xml:space="preserve" id="code_000635" smilref="Machine_Learning00012.smil#code_000635">hadoop fs -getmerge /fashionoutput fashionoutput.txt </code></p>
                <p id="c10-c10-para-0147" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0147">As you inspect the output on the local file system, you can see the most popular hashtags at the moment:</p>
                <p xml:space="preserve" id="p_000749"><code class="preserve-whitespace" xml:space="preserve" id="code_000636" smilref="Machine_Learning00012.smil#code_000636">jason@bigdatagames:˜$ sort -k2nr fashionoutput.txt | head -n20
#fashion    145
#style    35
#deal    31
#love    8
#skirt    8
#jewelry    6
#me    5
#pencil    5
#vintage    5
#cool    4
#dress    4
#earrings    4
#model    4
#outfit    4
#smile    4
#swag    4
#80s    3
#accessories    3
#black    3
#fashionable    3</code></p>
                <pagenum epub:type="pagebreak" id="p247" page="normal" smilref="Machine_Learning00012.smil#p247">247</pagenum>
                <p id="c10-c10-para-0148" xml:space="preserve"><span class="text" id="span_001815" smilref="Machine_Learning00012.smil#span_001815">Although you can easily discard the </span><code xml:space="preserve" id="code_000637" smilref="Machine_Learning00012.smil#code_000637">#fashion</code><span class="text" id="span_001816" smilref="Machine_Learning00012.smil#span_001816"> hashtag, as you know that's going to be the most popular, there are some interesting tags of note. It seems that skirts, jewelry, and vintage are all talking points on this day. If you were analyzing this data for an e-commerce site, you could have some routines to respond to the originators of the tweets to show them sites of special offers and so forth.</span></p>
              </level4>
              <level4 id="level4_000104">
                <h4 xml:space="preserve" id="h4_000104" smilref="Machine_Learning00012.smil#h4_000104">MapReduce Conclusions</h4>
                <p xml:space="preserve" id="p_000750" smilref="Machine_Learning00012.smil#p_000750">This walkthrough gives you the basic grounding of creating your own MapReduce functions to work with Hadoop. Along with the Spring XD framework, these are the basic components of a system that enable you to monitor Twitter data and get trends on the incoming data. There are other aspects of the data you could mine along with measuring sentiment, finding the most mentioned users, and finding out who's tweeting the most about a specific hashtag. Using the data coming out of Spring XD, with modifications to MapReduce files you have the basis for a good Twitter monitoring system.</p>
              </level4>
            </level3>
            <level3 id="level3_000174">
              <h3 xml:space="preserve" id="h3_000174" smilref="Machine_Learning00012.smil#h3_000174">Performing ETL on Existing Data</h3>
              <p xml:space="preserve" id="p_000751" smilref="Machine_Learning00012.smil#p_000751">The last exercise was about collating information and processing it in a prompt, distributed manner. The Hadoop routines you wrote could have been run every ten minutes, hour, day, week, and so on. This tackles only the problem of data hosed out of specific application programming interfaces (APIs)—in our case the Twitter streaming API—and dealing with the data in real time or batching up and processing when required.</p>
              <p id="c10-c10-para-0151" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0151">Companies are sitting on silos of existing data. It might be customer data, sales data, or even point-of-sale data that might be able to give some extra insight to customer behavior patterns. The emphasis isn't on creating new data; it's about making sense with the existing sets.</p>
              <p id="c10-c10-para-0152" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0152">Historical data might be held in a number of different formats: text, spreadsheet, or relational database. With text, it's a case of copying it to HDFS and then doing the work on it with the required MapReduce classes. When you have data to extract from a database, then things become a little more involved.</p>
              <p id="c10-c10-para-0153" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0153">The Sqoop project was designed to manage the bulk movement of data from relational databases to Hadoop. Any database server that has a JDBC driver associated with it can be used.</p>
              <p id="c10-c10-para-0154" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0154">In times gone by, business intelligence specialists would talk about extract, transform, and load (ETL). Sqoop does the same thing for our relational data by extracting it from the database table, transforming it to a comma-separated file and loading it in the Hadoop's HDFS. Additionally, Sqoop also creates a template Java file of the imported data for use within MapReduce, which reduces the development time required to work with the newly acquired data.</p>
              <level4 id="level4_000105">
                <h4 xml:space="preserve" id="h4_000105" smilref="Machine_Learning00012.smil#h4_000105">Installing Sqoop</h4>
                <pagenum epub:type="pagebreak" id="p248" page="normal" smilref="Machine_Learning00012.smil#p248">248</pagenum>
                <p xml:space="preserve" id="p_000752" smilref="Machine_Learning00012.smil#p_000752">To install Sqoop, you need a Hadoop distribution to be available on the same machine, because Sqoop uses Hadoop's MapReduce functions to extract the data. The Hadoop distribution you are using determines which Sqoop version you need to download. Sqoop1 is used for the Hadoop MR1 engine, and Sqoop2 for the MR2 engine.</p>
                <p id="c10-c10-para-0156" xml:space="preserve"><span class="text" id="span_001817" smilref="Machine_Learning00012.smil#span_001817">You can download Sqoop (I'm using 1.4.4 for use with the Hadoop 1.2.1 version) from the Apache download site at </span><code xml:space="preserve" id="code_000638"><a href="http://www.apache.org/dyn/closer.cgi/sqoop/1.4.4" external="true" id="a_000302" smilref="Machine_Learning00012.smil#a_000302">www.apache.org/dyn/closer.cgi/sqoop/1.4.4</a></code><span class="text" id="span_001818" smilref="Machine_Learning00012.smil#span_001818">.</span></p>
                <p id="c10-c10-para-0157" xml:space="preserve"><span class="text" id="span_001819" smilref="Machine_Learning00012.smil#span_001819">Extract the tarred file to a directory and export the </span><code xml:space="preserve" id="code_000639" smilref="Machine_Learning00012.smil#code_000639">PATH</code><span class="text" id="span_001820" smilref="Machine_Learning00012.smil#span_001820"> variable to include Sqoop's </span><code xml:space="preserve" id="code_000640" smilref="Machine_Learning00012.smil#code_000640">bin</code><span class="text" id="span_001821" smilref="Machine_Learning00012.smil#span_001821"> directory. You also need to tell Sqoop where your Hadoop installation is. With the following three lines from the command line, everything should be set up and ready to use:</span></p>
                <p xml:space="preserve" id="p_000753"><code class="preserve-whitespace" xml:space="preserve" id="code_000641" smilref="Machine_Learning00012.smil#code_000641">export PATH=$PATH:/usr/local/sqoop/bin
export HADOOP_COMMON_HOME=/usr/local/hadoop
export HADOOP_MAPRED_HOME=/usr/local/hadoop</code></p>
                <p id="c10-c10-para-0158" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0158">You can now run Sqoop to make sure that everything is set up okay. You should see output similar to the following:</p>
                <p xml:space="preserve" id="p_000754"><code class="preserve-whitespace" xml:space="preserve" id="code_000642" smilref="Machine_Learning00012.smil#code_000642">jason@bigdatagames:/usr/local/hadoop$ sqoop version
Warning: /usr/lib/hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: $HADOOP_HOME is deprecated.
Sqoop 1.4.4
git commit id 050a2015514533bc25f3134a33401470ee9353ad
Compiled by vasanthkumar on Mon Jul 22 20:01:26 IST 2013
jason@bigdatagames:/usr/local/hadoop$</code></p>
                <sidebar render="required" id="sidebar_000013">
                  <div class="top hr" id="div_000013" />
                  <level2 class="feature2" id="level2_000086">
                    <h2 xml:space="preserve" id="h2_000017" smilref="Machine_Learning00012.smil#h2_000017">Note</h2>
                    <p xml:space="preserve" id="p_000755" smilref="Machine_Learning00012.smil#p_000755">Don't worry about the warnings, because they're related to HBase and HCatalog, and you're not using those.</p>
                  </level2>
                </sidebar>
              </level4>
              <level4 id="level4_000106">
                <h4 xml:space="preserve" id="h4_000106" smilref="Machine_Learning00012.smil#h4_000106">Installing the JDBC Driver</h4>
                <p xml:space="preserve" id="p_000756"><span class="text" id="span_001822" smilref="Machine_Learning00012.smil#span_001822">Sqoop requires a copy of the JDBC driver to be in the </span><code xml:space="preserve" id="code_000643" smilref="Machine_Learning00012.smil#code_000643">lib</code><span class="text" id="span_001823" smilref="Machine_Learning00012.smil#span_001823"> directory so it can interact with your database. For this walkthrough, I'm using MySQL as the database and the </span><code xml:space="preserve" id="code_000644" smilref="Machine_Learning00012.smil#code_000644">Connector/J</code><span class="text" id="span_001824" smilref="Machine_Learning00012.smil#span_001824"> JDBC driver, which is available from </span><code xml:space="preserve" id="code_000645"><a href="http://www.mysql.com/" external="true" id="a_000303" smilref="Machine_Learning00012.smil#a_000303">www.mysql.com/</a></code><span class="text" id="span_001825" smilref="Machine_Learning00012.smil#span_001825">.</span></p>
              </level4>
              <level4 id="level4_000107">
                <h4 xml:space="preserve" id="h4_000107" smilref="Machine_Learning00012.smil#h4_000107">Basic Sqoop Usage</h4>
                <p xml:space="preserve" id="p_000757"><span class="text" id="span_001826" smilref="Machine_Learning00012.smil#span_001826">Sqoop is run from the command line, and with a number of flags you can start to extract data. Let's assume you have a MySQL database called “mydb” and </span><pagenum epub:type="pagebreak" id="p249" page="normal" smilref="Machine_Learning00012.smil#p249">249</pagenum><span class="text" id="span_001827" smilref="Machine_Learning00012.smil#span_001827">within a table called “mytable,” to extract an entire table from the database you would run the command:</span></p>
                <p xml:space="preserve" id="p_000758"><code class="preserve-whitespace" xml:space="preserve" id="code_000646" smilref="Machine_Learning00012.smil#code_000646">sqoop import --connect jdbc:mysql://localhost/mydb --username myuser --table mytable</code></p>
                <p id="c10-c10-para-0162" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0162">As you can see, Sqoop makes a connection to the database using the standard JDBC connection string like it would if it were connecting within Java code.</p>
                <p id="c10-c10-para-0163" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0163">Sqoop lets you save the command-line options into a file where each line in the file is a separate command-line option.</p>
                <p xml:space="preserve" id="p_000759"><code class="preserve-whitespace" xml:space="preserve" id="code_000647" smilref="Machine_Learning00012.smil#code_000647">import
--connect
jdbc:mysql://localhost/mydb
--username
myuser</code></p>
                <p id="c10-c10-para-0164" xml:space="preserve"><span class="text" id="span_001828" smilref="Machine_Learning00012.smil#span_001828">This is saved as a text file, and then it's passed to the Sqoop from the command line with the </span><code xml:space="preserve" id="code_000648" smilref="Machine_Learning00012.smil#code_000648">–options-file</code><span class="text" id="span_001829" smilref="Machine_Learning00012.smil#span_001829"> flag:</span></p>
                <p xml:space="preserve" id="p_000760"><code class="preserve-whitespace" xml:space="preserve" id="code_000649" smilref="Machine_Learning00012.smil#code_000649">sqoop import –options-file /home/jason/options.txt</code></p>
                <p id="c10-c10-para-0165" xml:space="preserve"><span class="text" id="span_001830" smilref="Machine_Learning00012.smil#span_001830">If you are repeatedly using Sqoop commands with a set of common options, then it makes sense to keep all the options in a text file. You can use your favorite text editor instead of the command-line editor to make tweaks and changes. If you apply this technique, consider adding a shell function or alias in your shell's startup configuration (for example, </span><code xml:space="preserve" id="code_000650" smilref="Machine_Learning00012.smil#code_000650">˜/.bashrc</code><span class="text" id="span_001831" smilref="Machine_Learning00012.smil#span_001831">).</span></p>
                <p xml:space="preserve" id="p_000761"><code class="preserve-whitespace" xml:space="preserve" id="code_000651" smilref="Machine_Learning00012.smil#code_000651">.alias sq='sqoop import –options-file /home/Jason/options.txt'</code></p>
              </level4>
              <level4 id="level4_000108">
                <h4 xml:space="preserve" id="h4_000108" smilref="Machine_Learning00012.smil#h4_000108">Handling Database Passwords</h4>
                <p xml:space="preserve" id="p_000762" smilref="Machine_Learning00012.smil#p_000762">The majority of the time the database tables are protected. There are two methods to use a password with Sqoop. The first method is just to include the password in plain text in the command line:</p>
                <p xml:space="preserve" id="p_000763"><code class="preserve-whitespace" xml:space="preserve" id="code_000652" smilref="Machine_Learning00012.smil#code_000652">sqoop import –connect jdbc:mysql://localhost/mydb –username myuser –password mypass –table mytable</code></p>
                <p id="c10-c10-para-0167" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0167">As you can imagine, this is not an ideal solution, as you are showing the plain password to anyone who happens to be passing your terminal, anyone who happens to look at what is running on the system, or even someone who looks back at what was run on the system in the past. It's a very big security risk.</p>
                <p id="c10-c10-para-0168" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0168">The more sensible and preferred approach is to hide the password in a file and reference the file with Sqoop:</p>
                <p xml:space="preserve" id="p_000764"><code class="preserve-whitespace" xml:space="preserve" id="code_000653" smilref="Machine_Learning00012.smil#code_000653">echo [your password] &gt; ˜/.password
chmod 400 .password</code></p>
                <p id="c10-c10-para-0169" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0169">Now when you run Sqoop you can add the password file to the command-line arguments:</p>
                <p xml:space="preserve" id="p_000765"><code class="preserve-whitespace" xml:space="preserve" id="code_000654" smilref="Machine_Learning00012.smil#code_000654">sqoop import --connect jdbc:mysql://localhost/mydb --username myuser --password-file /home/Jason/.password –table mytable</code></p>
                <pagenum epub:type="pagebreak" id="p250" page="normal" smilref="Machine_Learning00012.smil#p250">250</pagenum>
                <p id="c10-c10-para-0170" xml:space="preserve"><span class="text" id="span_001832" smilref="Machine_Learning00012.smil#span_001832">The job configuration now has no direct access to the password. It also means that if another user peeks into the process table (for example, runs the command to show running processes [</span><code xml:space="preserve" id="code_000655" smilref="Machine_Learning00012.smil#code_000655">ps</code><span class="text" id="span_001833" smilref="Machine_Learning00012.smil#span_001833">] in UNIX) that person does not see the password referenced in the process list.</span></p>
              </level4>
            </level3>
            <level3 id="level3_000175">
              <h3 xml:space="preserve" id="h3_000175" smilref="Machine_Learning00012.smil#h3_000175">Product Recommendation with Mahout</h3>
              <p xml:space="preserve" id="p_000766" smilref="Machine_Learning00012.smil#p_000766">To show you Sqoop in action, you're going to create an e-commerce recommendation system. You'll use Hadoop and the Mahout machine learning libraries as well.</p>
              <p id="c10-c10-para-0172" xml:space="preserve"><span class="text" id="span_001834" smilref="Machine_Learning00012.smil#span_001834">The source code and the database import files are on the Github repository that accompanies this book. You can download the full code from </span><code xml:space="preserve" id="code_000656"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000304" smilref="Machine_Learning00012.smil#a_000304">http://www.wiley.com/go/machinelearning</a></code><span class="text" id="span_001835" smilref="Machine_Learning00012.smil#span_001835">.</span></p>
              <sidebar render="required" id="sidebar_000014">
                <div class="top hr" id="div_000014" />
                <level2 class="feature2" id="level2_000087">
                  <h2 xml:space="preserve" id="h2_000018" smilref="Machine_Learning00012.smil#h2_000018">Note</h2>
                  <p xml:space="preserve" id="p_000767"><span class="text" id="span_001836" smilref="Machine_Learning00012.smil#span_001836">There are many e-commerce websites available today, and they sell pretty much everything. When the topic of product recommendation comes up, the main business many people talk about is </span><code xml:space="preserve" id="code_000657"><a href="http://Amazon.com" external="true" id="a_000305" smilref="Machine_Learning00012.smil#a_000305">Amazon.com</a></code><span class="text" id="span_001837" smilref="Machine_Learning00012.smil#span_001837">, because that company really got to grips with mining the data early on. Making recommendations based on what shoppers have previously purchased and just viewed is a powerful seller's tool in the right hands. Harnessing this data is now critical to the success of all retail merchants. The ability to push a product in front of customers with a degree of targeting increases the top line (sales) of any company.</span></p>
                </level2>
              </sidebar>
              <level4 id="level4_000109">
                <h4 xml:space="preserve" id="h4_000109" smilref="Machine_Learning00012.smil#h4_000109">So What's in a Recommendation?</h4>
                <p xml:space="preserve" id="p_000768" smilref="Machine_Learning00012.smil#p_000768">Consider what a recommendation is for a second. Imagine an online store with many product items and many customers. Now offer each customer the honor of rating an item from 1 (worst) to 5 (best). The database table is very simple.</p>
                <list type="ul" id="list_000059">
                  <li id="li_000420" smilref="Machine_Learning00012.smil#li_000420">User ID</li>
                  <li id="li_000421" smilref="Machine_Learning00012.smil#li_000421">Stock ID</li>
                  <li id="li_000422" smilref="Machine_Learning00012.smil#li_000422">A rating</li>
                  <li id="li_000423" smilref="Machine_Learning00012.smil#li_000423">A timestamp</li>
                </list>
                <p id="c10-c10-para-0175" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0175">Over time, you collect many user ratings in that table and periodically mine them to give users recommendations on products rated by other users. It doesn't matter what type of items or the background of the users (age range, income bracket, and so on); all that matters is who rated what.</p>
                <pagenum epub:type="pagebreak" id="p251" page="normal" smilref="Machine_Learning00012.smil#p251">251</pagenum>
                <p id="c10-c10-para-0176" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0176">Using Mahout's similarity co-occurrence algorithm, similar items that users have rated can be recommended to users who viewed or purchased the other items.</p>
                <list type="ol" id="list_000060">
                  <li id="li_000424" smilref="Machine_Learning00012.smil#li_000424">Bill gives King Crimson's album Discipline five stars.</li>
                  <li id="li_000425" smilref="Machine_Learning00012.smil#li_000425">Sid gives King Crimson's album Discipline five stars.</li>
                  <li id="li_000426" smilref="Machine_Learning00012.smil#li_000426">Sid gives King Crimson's album Beat five stars.</li>
                </list>
                <p id="c10-c10-para-0177" xml:space="preserve"><span class="text" id="span_001838" smilref="Machine_Learning00012.smil#span_001838">Then we can recommend </span><em id="em_000330" smilref="Machine_Learning00012.smil#em_000330">Beat</em><span class="text" id="span_001839" smilref="Machine_Learning00012.smil#span_001839"> to Bill, as both Sid and Bill gave </span><em id="em_000331" smilref="Machine_Learning00012.smil#em_000331">Discipline</em><span class="text" id="span_001840" smilref="Machine_Learning00012.smil#span_001840"> a good rating. Now, at scale you might have thousands of albums for sale, tens of thousands of customers, and millions of ratings. The more data you have, the better the mining and recommending that can be done. Too few ratings, and you won't have enough data to do decent calculations.</span></p>
                <p id="c10-c10-para-0178" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0178">I know what you're thinking: “This sounds like a lot of programming.”</p>
                <p id="c10-c10-para-0179" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0179">The reality is that all this correlation is already in place with Mahout's API, so the only real programming involved it is to interpret the output of the recommendations for each user.</p>
                <p id="c10-c10-para-0180" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0180">Although I'm using Java, it would be easy to put this together in PHP, Python, or Ruby.</p>
              </level4>
              <level4 id="level4_000110">
                <h4 xml:space="preserve" id="h4_000110" smilref="Machine_Learning00012.smil#h4_000110">Setting Up the Database</h4>
                <p xml:space="preserve" id="p_000769" smilref="Machine_Learning00012.smil#p_000769">I'm going to use MySQL as my database of choice. From the command line, I'm going to create the database:</p>
                <p xml:space="preserve" id="p_000770"><code class="preserve-whitespace" xml:space="preserve" id="code_000658" smilref="Machine_Learning00012.smil#code_000658">mysqladmin –u root create mahoutratings</code></p>
                <p id="c10-c10-para-0182" xml:space="preserve"><span class="text" id="span_001841" smilref="Machine_Learning00012.smil#span_001841">The next thing to do is create two tables: one for the stock items and another for the user ratings. The easiest way is to copy the following SQL code and save it to a text file called </span><code xml:space="preserve" id="code_000659" smilref="Machine_Learning00012.smil#code_000659">stockitems.sql</code><span class="text" id="span_001842" smilref="Machine_Learning00012.smil#span_001842">:</span></p>
                <p xml:space="preserve" id="p_000771"><code class="preserve-whitespace" xml:space="preserve" id="code_000660" smilref="Machine_Learning00012.smil#code_000660">create table stockitems (
    id int(11) not null primary key auto_increment,
    albumartist varchar(200) not null default "",
    albumname varchar(200) not null default ""
);</code></p>
                <p id="c10-c10-para-0183" xml:space="preserve"><span class="text" id="span_001843" smilref="Machine_Learning00012.smil#span_001843">Next, create a text file for the user ratings table and call it </span><code xml:space="preserve" id="code_000661" smilref="Machine_Learning00012.smil#code_000661">userratings.sql</code><span class="text" id="span_001844" smilref="Machine_Learning00012.smil#span_001844">:</span></p>
                <p xml:space="preserve" id="p_000772"><code class="preserve-whitespace" xml:space="preserve" id="code_000662" smilref="Machine_Learning00012.smil#code_000662">create table userratings (
    userid int(11) not null default -1,
    stockid int(11) not null default -1,
    rating int(4) not null default 3,
    created_at int(11) not null default -1
);</code></p>
                <p id="c10-c10-para-0184" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0184">With these two text files, you can now create the tables in MySQL from the command line:</p>
                <p xml:space="preserve" id="p_000773"><code class="preserve-whitespace" xml:space="preserve" id="code_000663" smilref="Machine_Learning00012.smil#code_000663">mysql –u root mahoutratings &lt; stockitems.sql
mysql –u root mahoutratings &lt; userratings.sql</code></p>
                <pagenum epub:type="pagebreak" id="p252" page="normal" smilref="Machine_Learning00012.smil#p252">252</pagenum>
                <p id="c10-c10-para-0185" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0185">That's the bare database. Now, you need to add some data before you do any analysis on it.</p>
              </level4>
              <level4 id="level4_000111">
                <h4 xml:space="preserve" id="h4_000111" smilref="Machine_Learning00012.smil#h4_000111">Importing the Initial Data</h4>
                <p xml:space="preserve" id="p_000774" smilref="Machine_Learning00012.smil#p_000774">I've created the basic data for you; this saves writing programs to create random data and so on. From the command line, you run the two commands into MySQL:</p>
                <p xml:space="preserve" id="p_000775"><code class="preserve-whitespace" xml:space="preserve" id="code_000664" smilref="Machine_Learning00012.smil#code_000664">mysql –u root mahoutratings &lt; stockdata.sql
mysql –u root mahoutratings &lt; ratingsdata.sql</code></p>
                <p id="c10-c10-para-0187" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0187">To make sure that all went well with the import, use the MySQL client to confirm:</p>
                <p xml:space="preserve" id="p_000776"><code class="preserve-whitespace" xml:space="preserve" id="code_000665" smilref="Machine_Learning00012.smil#code_000665">mysql –u root mahoutratings</code></p>
                <p id="c10-c10-para-0188" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0188">Then, from the MySQL client command line, type the following commands:</p>
                <p xml:space="preserve" id="p_000777"><code class="preserve-whitespace" xml:space="preserve" id="code_000666" smilref="Machine_Learning00012.smil#code_000666">mysql&gt;select count(*) from stockitems;
mysql&gt;select count(*) from userratings;</code></p>
                <p id="c10-c10-para-0189" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0189">If the tables are empty, then make sure that you typed the import commands correctly and try again.</p>
              </level4>
              <level4 id="level4_000112">
                <h4 xml:space="preserve" id="h4_000112" smilref="Machine_Learning00012.smil#h4_000112">Installing the Mahout Libraries</h4>
                <p xml:space="preserve" id="p_000778"><span class="text" id="span_001845" smilref="Machine_Learning00012.smil#span_001845">The Mahout libraries are extra to the Hadoop distribution, so they need to be downloaded and installed before you start. You can download the Mahout binary package from </span><code xml:space="preserve" id="code_000667"><a href="http://www.apache.org/dyn/closer.cgi/mahout/" external="true" id="a_000306" smilref="Machine_Learning00012.smil#a_000306">www.apache.org/dyn/closer.cgi/mahout/</a></code><span class="text" id="span_001846" smilref="Machine_Learning00012.smil#span_001846">.</span></p>
                <p id="c10-c10-para-0191" xml:space="preserve"><span class="text" id="span_001847" smilref="Machine_Learning00012.smil#span_001847">To install it, either untar or unzip the file to a directory. Keep a note of the directory because you'll need it for finding the core </span><code xml:space="preserve" id="code_000668" smilref="Machine_Learning00012.smil#code_000668">jar</code><span class="text" id="span_001848" smilref="Machine_Learning00012.smil#span_001848"> files. The routines you're going to use are working in conjunction with Hadoop, so please make sure you have HDFS working and the Hadoop processes running before you start mining the data. If you need a reminder on how to set up your single-node Hadoop cluster then look at the “Setting Up a Single Node Cluster” section earlier in this chapter.</span></p>
              </level4>
              <level4 id="level4_000113">
                <h4 xml:space="preserve" id="h4_000113" smilref="Machine_Learning00012.smil#h4_000113">Extracting Data with Sqoop</h4>
                <p xml:space="preserve" id="p_000779" smilref="Machine_Learning00012.smil#p_000779">The plan of execution is simple. Extract the data from the database and then copy to HDFS. Have Mahout run its recommender job on the data. This generates the results with recommendations for each user.</p>
                <p id="c10-c10-para-0193" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0193">Last, you create a small Java program to read the results and show the actual stock items recommended for a specific user ID.</p>
                <pagenum epub:type="pagebreak" id="p253" page="normal" smilref="Machine_Learning00012.smil#p253">253</pagenum>
                <p id="c10-c10-para-0194" xml:space="preserve"><span class="text" id="span_001849" smilref="Machine_Learning00012.smil#span_001849">From Sqoop, you can pull the entire contents of the </span><code xml:space="preserve" id="code_000669" smilref="Machine_Learning00012.smil#code_000669">userratings</code><span class="text" id="span_001850" smilref="Machine_Learning00012.smil#span_001850"> table out in one line:</span></p>
                <p xml:space="preserve" id="p_000780"><code class="preserve-whitespace" xml:space="preserve" id="code_000670" smilref="Machine_Learning00012.smil#code_000670">sqoop -–connect jdbc:mysql://localhost/mahoutratings -–username root -–table userratings</code></p>
                <p id="c10-c10-para-0195" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0195">Sqoop extracts the table contents and writes them as a CSV file. Now, you need to copy that into HDFS so Hadoop and Mahout can do their work on it. It's also worthwhile to rename the output file that Sqoop created so you know exactly what it is:</p>
                <p xml:space="preserve" id="p_000781"><code class="preserve-whitespace" xml:space="preserve" id="code_000671" smilref="Machine_Learning00012.smil#code_000671">mv part-00000 userratings.csv</code></p>
                <p id="c10-c10-para-0196" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0196">Then copy that to HDFS:</p>
                <p xml:space="preserve" id="p_000782"><code class="preserve-whitespace" xml:space="preserve" id="code_000672" smilref="Machine_Learning00012.smil#code_000672">hadoop fs –put userratings.csv userratings.csv</code></p>
                <p id="c10-c10-para-0197" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0197">With the data in HDFS, you can perform the Hadoop job on the data and let it generate the recommendations.</p>
              </level4>
              <level4 id="level4_000114">
                <h4 xml:space="preserve" id="h4_000114" smilref="Machine_Learning00012.smil#h4_000114">Running Hadoop</h4>
                <p xml:space="preserve" id="p_000783" smilref="Machine_Learning00012.smil#p_000783">When you installed the Mahout libraries, I said to keep a note of the installation directory. Now, you're going to use it with the Hadoop command to do the recommendation processing.</p>
                <p id="c10-c10-para-0199" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0199">To set everything going, run the following command (all in one line):</p>
                <p xml:space="preserve" id="p_000784"><code class="preserve-whitespace" xml:space="preserve" id="code_000673" smilref="Machine_Learning00012.smil#code_000673">hadoop jar [path to mahout]/ mahout-core-0.8-job.jar org.apache.mahout.cf.taste.hadoop.item.RecommenderJob –s SIMILARITY_COOCCURRENCE –input userratings.csv --output recommendationoutput</code></p>
                <p id="c10-c10-para-0200" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0200">Mahout runs a series of MapReduce jobs to complete the recommendations. It can take some time to complete. Obviously this is not something you'd really want to do in real time, but it's a perfect use of batch processing.</p>
              </level4>
              <level4 id="level4_000115">
                <h4 xml:space="preserve" id="h4_000115" smilref="Machine_Learning00012.smil#h4_000115">Inspecting the Results</h4>
                <p xml:space="preserve" id="p_000785" smilref="Machine_Learning00012.smil#p_000785">When the job is complete, you can get the results from HDFS and inspect them:</p>
                <p xml:space="preserve" id="p_000786"><code class="preserve-whitespace" xml:space="preserve" id="code_000674" smilref="Machine_Learning00012.smil#code_000674">hadoop fs –getmerge recommendationoutput recommendations.txt</code></p>
                <p id="c10-c10-para-0202" xml:space="preserve"><span class="text" id="span_001851" smilref="Machine_Learning00012.smil#span_001851">Looking at </span><code xml:space="preserve" id="code_000675" smilref="Machine_Learning00012.smil#code_000675">recommendations.txt</code><span class="text" id="span_001852" smilref="Machine_Learning00012.smil#span_001852"> you see the customer ID and then a set of numbers. These numbers are the stock item IDs that Mahout has recommended for that customer based on the other user ratings made.</span></p>
                <p id="c10-c10-para-0203" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0203">To make sense of the results, I've quickly coded up a Java program that reads in a customer ID and extracts the recommendations:</p>
                <p xml:space="preserve" id="p_000787"><code class="preserve-whitespace" xml:space="preserve" id="code_000676"><strong id="strong_000551" smilref="Machine_Learning00012.smil#strong_000551">package</strong> <pagenum epub:type="pagebreak" id="p254" page="normal" smilref="Machine_Learning00012.smil#p254">254</pagenum><span class="text" id="span_001853" smilref="Machine_Learning00012.smil#span_001853">chapter10;
</span><strong id="strong_000552" smilref="Machine_Learning00012.smil#strong_000552">import</strong><span class="text" id="span_001854" smilref="Machine_Learning00012.smil#span_001854"> java.io.BufferedReader;
</span><strong id="strong_000553" smilref="Machine_Learning00012.smil#strong_000553">import</strong><span class="text" id="span_001855" smilref="Machine_Learning00012.smil#span_001855"> java.io.FileReader;
</span><strong id="strong_000554" smilref="Machine_Learning00012.smil#strong_000554">import</strong><span class="text" id="span_001856" smilref="Machine_Learning00012.smil#span_001856"> java.io.IOException;
</span><strong id="strong_000555" smilref="Machine_Learning00012.smil#strong_000555">import</strong><span class="text" id="span_001857" smilref="Machine_Learning00012.smil#span_001857"> java.sql.Connection;
</span><strong id="strong_000556" smilref="Machine_Learning00012.smil#strong_000556">import</strong><span class="text" id="span_001858" smilref="Machine_Learning00012.smil#span_001858"> java.sql.DriverManager;
</span><strong id="strong_000557" smilref="Machine_Learning00012.smil#strong_000557">import</strong><span class="text" id="span_001859" smilref="Machine_Learning00012.smil#span_001859"> java.sql.PreparedStatement;
</span><strong id="strong_000558" smilref="Machine_Learning00012.smil#strong_000558">import</strong><span class="text" id="span_001860" smilref="Machine_Learning00012.smil#span_001860"> java.sql.ResultSet;
</span><strong id="strong_000559" smilref="Machine_Learning00012.smil#strong_000559">import</strong><span class="text" id="span_001861" smilref="Machine_Learning00012.smil#span_001861"> java.sql.SQLException;
</span><strong id="strong_000560" smilref="Machine_Learning00012.smil#strong_000560">import</strong><span class="text" id="span_001862" smilref="Machine_Learning00012.smil#span_001862"> java.util.HashMap;
</span><strong id="strong_000561" smilref="Machine_Learning00012.smil#strong_000561">import</strong><span class="text" id="span_001863" smilref="Machine_Learning00012.smil#span_001863"> java.util.Map;
</span><strong id="strong_000562" smilref="Machine_Learning00012.smil#strong_000562">public</strong> <strong id="strong_000563" smilref="Machine_Learning00012.smil#strong_000563">class</strong><span class="text" id="span_001864" smilref="Machine_Learning00012.smil#span_001864"> ShowRecommendations {
    </span><strong id="strong_000564" smilref="Machine_Learning00012.smil#strong_000564">static</strong><span class="text" id="span_001865" smilref="Machine_Learning00012.smil#span_001865"> {
        </span><strong id="strong_000565" smilref="Machine_Learning00012.smil#strong_000565">try</strong><span class="text" id="span_001866" smilref="Machine_Learning00012.smil#span_001866"> {
            Class.</span><em id="em_000332" smilref="Machine_Learning00012.smil#em_000332">forName</em><span class="text" id="span_001867" smilref="Machine_Learning00012.smil#span_001867">("com.mysql.jdbc.Driver");
        } </span><strong id="strong_000566" smilref="Machine_Learning00012.smil#strong_000566">catch</strong><span class="text" id="span_001868" smilref="Machine_Learning00012.smil#span_001868"> (ClassNotFoundException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000567" smilref="Machine_Learning00012.smil#strong_000567">private</strong><span class="text" id="span_001869" smilref="Machine_Learning00012.smil#span_001869"> Map&lt;Integer, String&gt; recommendations = </span><strong id="strong_000568" smilref="Machine_Learning00012.smil#strong_000568">new</strong><span class="text" id="span_001870" smilref="Machine_Learning00012.smil#span_001870"> HashMap&lt;Integer, String&gt;();
    </span><strong id="strong_000569" smilref="Machine_Learning00012.smil#strong_000569">public</strong><span class="text" id="span_001871" smilref="Machine_Learning00012.smil#span_001871"> ShowRecommendations(</span><strong id="strong_000570" smilref="Machine_Learning00012.smil#strong_000570">int</strong><span class="text" id="span_001872" smilref="Machine_Learning00012.smil#span_001872"> customerid) {
        initMap(); // load the recommendations in to the hash map
        </span><strong id="strong_000571" smilref="Machine_Learning00012.smil#strong_000571">try</strong><span class="text" id="span_001873" smilref="Machine_Learning00012.smil#span_001873"> {
            String rec = recommendations.get(</span><strong id="strong_000572" smilref="Machine_Learning00012.smil#strong_000572">new</strong><span class="text" id="span_001874" smilref="Machine_Learning00012.smil#span_001874"> Integer(customerid));
            String output = generateRecommendation(rec);
            System.</span><em id="em_000333" smilref="Machine_Learning00012.smil#em_000333">out</em><span class="text" id="span_001875" smilref="Machine_Learning00012.smil#span_001875">.println("Customer: " + customerid + "\n" + output);
        } </span><strong id="strong_000573" smilref="Machine_Learning00012.smil#strong_000573">catch</strong><span class="text" id="span_001876" smilref="Machine_Learning00012.smil#span_001876"> (Exception e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000574" smilref="Machine_Learning00012.smil#strong_000574">private</strong><span class="text" id="span_001877" smilref="Machine_Learning00012.smil#span_001877"> String generateRecommendation(String input) </span><strong id="strong_000575" smilref="Machine_Learning00012.smil#strong_000575">throws</strong><span class="text" id="span_001878" smilref="Machine_Learning00012.smil#span_001878"> SQLException {
        StringBuilder sb = </span><strong id="strong_000576" smilref="Machine_Learning00012.smil#strong_000576">new</strong><span class="text" id="span_001879" smilref="Machine_Learning00012.smil#span_001879"> StringBuilder();
        System.</span><em id="em_000334" smilref="Machine_Learning00012.smil#em_000334">out</em><span class="text" id="span_001880" smilref="Machine_Learning00012.smil#span_001880">.println("Working on " + input);
        String tempstring = input.substring(1,input.length()-1);
        String[] products = tempstring.split(",");
        System.</span><em id="em_000335" smilref="Machine_Learning00012.smil#em_000335">out</em><span class="text" id="span_001881" smilref="Machine_Learning00012.smil#span_001881">.println("products = " + products.length);
        Connection con = DriverManager.</span><em id="em_000336" smilref="Machine_Learning00012.smil#em_000336">getConnection</em><span class="text" id="span_001882" smilref="Machine_Learning00012.smil#span_001882">(
                "jdbc:mysql://localhost/mahoutratings", "root", "");
        PreparedStatement pstmt = con
                .prepareStatement("SELECT albumname, albumartist FROM stockitems WHERE id=?");
        ResultSet rs = </span><strong id="strong_000577" smilref="Machine_Learning00012.smil#strong_000577">null</strong><span class="text" id="span_001883" smilref="Machine_Learning00012.smil#span_001883">;
        </span><strong id="strong_000578" smilref="Machine_Learning00012.smil#strong_000578">for</strong><span class="text" id="span_001884" smilref="Machine_Learning00012.smil#span_001884"> (</span><strong id="strong_000579" smilref="Machine_Learning00012.smil#strong_000579">int</strong><span class="text" id="span_001885" smilref="Machine_Learning00012.smil#span_001885"> i = 0; i &lt; products.length; i++) {
            String[] itemSplit = products[i].split(":");
            pstmt.setInt(1, Integer.</span><em id="em_000337" smilref="Machine_Learning00012.smil#em_000337">parseInt</em><span class="text" id="span_001886" smilref="Machine_Learning00012.smil#span_001886">(itemSplit[0]));
            rs = pstmt.executeQuery();
            </span><strong id="strong_000580" smilref="Machine_Learning00012.smil#strong_000580">if</strong><span class="text" id="span_001887" smilref="Machine_Learning00012.smil#span_001887"> (rs.next()) {
                sb.append("Album: " + rs.getString("albumname") + " by "
                        + rs.getString("albumartist") + " rating: "
                        + itemSplit[1] + "\n");
            }
        }
        rs.close();
        pstmt.close();
        con.close();
        </span><strong id="strong_000581" smilref="Machine_Learning00012.smil#strong_000581">return</strong><span class="text" id="span_001888" smilref="Machine_Learning00012.smil#span_001888"> sb.toString();
    }
    </span><strong id="strong_000582" smilref="Machine_Learning00012.smil#strong_000582">private</strong> <strong id="strong_000583" smilref="Machine_Learning00012.smil#strong_000583">void</strong><span class="text" id="span_001889" smilref="Machine_Learning00012.smil#span_001889"> initMap() {
        </span><strong id="strong_000584" smilref="Machine_Learning00012.smil#strong_000584">try</strong><span class="text" id="span_001890" smilref="Machine_Learning00012.smil#span_001890"> {
            BufferedReader in = </span><strong id="strong_000585" smilref="Machine_Learning00012.smil#strong_000585">new</strong><span class="text" id="span_001891" smilref="Machine_Learning00012.smil#span_001891"> BufferedReader(</span><strong id="strong_000586" smilref="Machine_Learning00012.smil#strong_000586">new</strong><span class="text" id="span_001892" smilref="Machine_Learning00012.smil#span_001892"> FileReader(
                    "/Users/Jason/mahouttest.txt"));
            String str;
            </span><strong id="strong_000587" smilref="Machine_Learning00012.smil#strong_000587">while</strong><span class="text" id="span_001893" smilref="Machine_Learning00012.smil#span_001893"> ((str = in.readLine()) != </span><strong id="strong_000588" smilref="Machine_Learning00012.smil#strong_000588">null</strong><span class="text" id="span_001894" smilref="Machine_Learning00012.smil#span_001894">) {
                String[] split = str.split("[ ]+");
                System.</span><em id="em_000338" smilref="Machine_Learning00012.smil#em_000338">out</em><span class="text" id="span_001895" smilref="Machine_Learning00012.smil#span_001895">.println("adding: " + split[0] + "=" + split[1]);
                recommendations.put(Integer.</span><em id="em_000339" smilref="Machine_Learning00012.smil#em_000339">parseInt</em><span class="text" id="span_001896" smilref="Machine_Learning00012.smil#span_001896">(split[0]), split[1]);
            }
            in.close();
        } </span><strong id="strong_000589" smilref="Machine_Learning00012.smil#strong_000589">catch</strong><span class="text" id="span_001897" smilref="Machine_Learning00012.smil#span_001897"> (IOException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000590" smilref="Machine_Learning00012.smil#strong_000590">public</strong> <strong id="strong_000591" smilref="Machine_Learning00012.smil#strong_000591">static</strong> <strong id="strong_000592" smilref="Machine_Learning00012.smil#strong_000592">void</strong><span class="text" id="span_001898" smilref="Machine_Learning00012.smil#span_001898"> main(String[] args) {
        </span><strong id="strong_000593" smilref="Machine_Learning00012.smil#strong_000593">if</strong><span class="text" id="span_001899" smilref="Machine_Learning00012.smil#span_001899"> (args.length &lt; 1) {
            System.</span><em id="em_000340" smilref="Machine_Learning00012.smil#em_000340">out</em><span class="text" id="span_001900" smilref="Machine_Learning00012.smil#span_001900">.println("Usage: ShowRecommendations [customerid]");
        } </span><strong id="strong_000594" smilref="Machine_Learning00012.smil#strong_000594">else</strong><span class="text" id="span_001901" smilref="Machine_Learning00012.smil#span_001901"> {
            ShowRecommendations sr = </span><strong id="strong_000595" smilref="Machine_Learning00012.smil#strong_000595">new</strong><span class="text" id="span_001902" smilref="Machine_Learning00012.smil#span_001902"> ShowRecommendations(Integer.</span><em id="em_000341" smilref="Machine_Learning00012.smil#em_000341">parseInt</em><span class="text" id="span_001903" smilref="Machine_Learning00012.smil#span_001903">(args[0]));
        }
    }
}</span></code></p>
                <p id="c10-c10-para-0204" xml:space="preserve"><span class="text" id="span_001904" smilref="Machine_Learning00012.smil#span_001904">A </span><pagenum epub:type="pagebreak" id="p255" page="normal" smilref="Machine_Learning00012.smil#p255">255</pagenum><span class="text" id="span_001905" smilref="Machine_Learning00012.smil#span_001905">quick test on customer ID 9 returns the following output:</span></p>
                <p xml:space="preserve" id="p_000788"><code class="preserve-whitespace" xml:space="preserve" id="code_000677" smilref="Machine_Learning00012.smil#code_000677">Customer: 9
Album: AlbumName_739 by AlbumArtist_739 rating: 5.0
Album: AlbumName_550 by AlbumArtist_550 rating: 5.0
Album: AlbumName_546 by AlbumArtist_546 rating: 5.0
Album: AlbumName_11 by AlbumArtist_11 rating: 5.0
Album: AlbumName_527 by AlbumArtist_527 rating: 5.0
Album: AlbumName_523 by AlbumArtist_523 rating: 5.0
Album: AlbumName_514 by AlbumArtist_514 rating: 5.0
Album: AlbumName_511 by AlbumArtist_511 rating: 5.0
Album: AlbumName_508 by AlbumArtist_508 rating: 5.0
Album: AlbumName_498 by AlbumArtist_498 rating: 5.0</code></p>
                <pagenum epub:type="pagebreak" id="p256" page="normal" smilref="Machine_Learning00012.smil#p256">256</pagenum>
                <p id="c10-c10-para-0205" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0205">The code could easily be modified to store the recommendations back to the database table, so it could be easily used in the e-commerce code for a website.</p>
              </level4>
              <level4 id="level4_000116">
                <h4 xml:space="preserve" id="h4_000116" smilref="Machine_Learning00012.smil#h4_000116">Extending This Project Further</h4>
                <p xml:space="preserve" id="p_000789" smilref="Machine_Learning00012.smil#p_000789">There's plenty of scope for this project to be used in a real-world situation. The more data you generate, the better the recommendations you can give. Although you could perform the Mahout functions via code within a program, I prefer to use them away from the web application. This choice is more about personal preference than anything else, but I have some good reasons. I don't want the database or the web application to be slowed down by heavy memory processing. As you've probably gathered, I prefer a more batch-oriented approach by extracting the data from the database, running the recommendation algorithm, and then sending it back to the database for the web application to access.</p>
                <p id="c10-c10-para-0207" xml:space="preserve"><span class="text" id="span_001906" smilref="Machine_Learning00012.smil#span_001906">To run this routine periodically, set up a UNIX </span><code xml:space="preserve" id="code_000678" smilref="Machine_Learning00012.smil#code_000678">cron</code><span class="text" id="span_001907" smilref="Machine_Learning00012.smil#span_001907"> job (setting up a </span><code xml:space="preserve" id="code_000679" smilref="Machine_Learning00012.smil#code_000679">cron</code><span class="text" id="span_001908" smilref="Machine_Learning00012.smil#span_001908"> job is covered in the section “Scheduling Batch Jobs” at the end of this chapter). Depending on the volume of ratings you get, this could be run once an hour, twice a day, or once a day. There's nothing wrong with trying a few variations of time difference to find out which works best for you.</span></p>
              </level4>
              <level4 id="level4_000117">
                <h4 xml:space="preserve" id="h4_000117" smilref="Machine_Learning00012.smil#h4_000117">Mahout Conclusions</h4>
                <p xml:space="preserve" id="p_000790" smilref="Machine_Learning00012.smil#p_000790">The Mahout tutorial gave you a robust recommendation engine without the need for programming. Using Sqoop to extract data from a database and then using Hadoop to perform the Mahout processing in parallel gave you good recommendations on a large amount of data in a short space of time. The Mahout libraries give a lot of options of memory caching to improve processing performance, but it's still worth taking the processing away from the main application and performing it in batches.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000088">
            <h2 id="c10-c010_level1_7" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c010_level1_7">Mining Sales Data</h2>
            <p xml:space="preserve" id="p_000791"><span class="text" id="span_001909" smilref="Machine_Learning00012.smil#span_001909">For all the Big Data problems in the world, there's a large lean toward the social media side of things. It's mostly text and can be mined with relative ease. Back in the real world where commerce is based on numbers, hashtag counts might </span><pagenum epub:type="pagebreak" id="p257" page="normal" smilref="Machine_Learning00012.smil#p257">257</pagenum><span class="text" id="span_001910" smilref="Machine_Learning00012.smil#span_001910">not be the most important thing on a CEO's mind. Finding out which customers are worth retaining, however, probably is.</span></p>
            <p id="c10-c10-para-0210" xml:space="preserve"><span class="text" id="span_001911" smilref="Machine_Learning00012.smil#span_001911">This walkthrough looks at developing some code to perform calculations and then moves the code into Hadoop. Finally, you move the data through Pig, which is a MapReduce scripting-like language. You can download the code and the data from </span><code xml:space="preserve" id="code_000680"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000307" smilref="Machine_Learning00012.smil#a_000307">http://www.wiley.com/go/machinelearning</a></code><span class="text" id="span_001912" smilref="Machine_Learning00012.smil#span_001912">.</span></p>
            <level3 id="level3_000176">
              <h3 xml:space="preserve" id="h3_000176" smilref="Machine_Learning00012.smil#h3_000176">Welcome to My Coffee Shop!</h3>
              <p xml:space="preserve" id="p_000792" smilref="Machine_Learning00012.smil#p_000792">To be fair, it's an odd coffee shop because it sells only one sort of coffee: lattes. It's been open for just more than a year, and I have a good set of data for my 20,000 customers (it's a large coffee shop). Okay, I don't have a coffee shop, but you can use your imagination for this exercise.</p>
              <p id="c10-c10-para-0212" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0212">The data is made up of a customer ID and the sales for 13 months. Here's what the data looks like for the first ten customers:</p>
              <p xml:space="preserve" id="p_000793"><code class="preserve-whitespace" xml:space="preserve" id="code_000681" smilref="Machine_Learning00012.smil#code_000681">1,3,11,6,10,7,10,12,9,7,6,10,14,5
2,1,13,10,0,5,12,1,13,1,3,7,5,14
3,14,2,3,8,10,12,13,6,13,2,1,7,2
4,14,1,11,14,11,1,12,10,0,1,14,5,9
5,1,3,11,14,3,8,10,9,7,3,0,5,6
6,3,3,1,14,5,0,4,8,9,11,8,0,5
7,8,1,11,8,13,2,13,4,6,2,7,14,14
8,13,6,8,12,8,10,14,0,13,6,14,2,9
9,11,1,13,0,11,13,6,3,10,8,8,5,1
10,1,10,2,0,5,0,4,12,12,10,6,6,9</code></p>
              <p id="c10-c10-para-0213" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0213">It's a standard CSV file full of integers. I've been neat in my data collection over time. What I want to do now is answer some questions that have been on my mind.</p>
              <list type="ul" id="list_000061">
                <li id="li_000427" smilref="Machine_Learning00012.smil#li_000427">How many lattes do my customers purchase?</li>
                <li id="li_000428" smilref="Machine_Learning00012.smil#li_000428">What is the sales drop for each customer?</li>
                <li id="li_000429" smilref="Machine_Learning00012.smil#li_000429">What is the duration of the sales drop?</li>
              </list>
              <p id="c10-c10-para-0214" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0214">Armed with these stakeholder questions, you can put some actions into place. Fortunately, these questions are simple to answer with a little bit of simple math:</p>
              <list type="ul" id="list_000062">
                <li id="li_000430">
                  <span class="text" id="span_001913" smilref="Machine_Learning00012.smil#span_001913">How many lattes do my customers purchase?</span>
                  <p xml:space="preserve" id="p_000794"><strong id="strong_000596" smilref="Machine_Learning00012.smil#strong_000596">Calculate the mean sales on months 1-12.</strong></p>
                </li>
                <li id="li_000431">
                  <span class="text" id="span_001914" smilref="Machine_Learning00012.smil#span_001914">What is the sales drop for each customer?</span>
                  <p xml:space="preserve" id="p_000795"><strong id="strong_000597" smilref="Machine_Learning00012.smil#strong_000597">Subtract the month 13 sales from the mean.</strong></p>
                </li>
                <li id="li_000432">
                  <span class="text" id="span_001915" smilref="Machine_Learning00012.smil#span_001915">What is the duration of the sales drop?</span>
                  <p xml:space="preserve" id="p_000796"><strong id="strong_000598" smilref="Machine_Learning00012.smil#strong_000598">Calculate the number of months in which sales were below 40 percent of the mean.</strong></p>
                </li>
              </list>
              <pagenum epub:type="pagebreak" id="p258" page="normal" smilref="Machine_Learning00012.smil#p258">258</pagenum>
              <p id="c10-c10-para-0221" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0221">If you had a handful of customers, you could do this with a calc ulator or spreadsheet. Even with 20,000 customers, a spreadsheet would do the job fine. If my coffee shop goes worldwide and scales up to 20 million customers, then I'd have a job on my hands, and that's where these tools become useful.</p>
            </level3>
            <level3 id="level3_000177">
              <h3 xml:space="preserve" id="h3_000177" smilref="Machine_Learning00012.smil#h3_000177">Going Small Scale</h3>
              <p xml:space="preserve" id="p_000797"><span class="text" id="span_001916" smilref="Machine_Learning00012.smil#span_001916">You need to start small and develop some code that answers the questions posed without processing all the data. Create a small training and testing data set using the UNIX </span><code xml:space="preserve" id="code_000682" smilref="Machine_Learning00012.smil#code_000682">head</code><span class="text" id="span_001917" smilref="Machine_Learning00012.smil#span_001917"> command:</span></p>
              <p xml:space="preserve" id="p_000798"><code class="preserve-whitespace" xml:space="preserve" id="code_000683" smilref="Machine_Learning00012.smil#code_000683">head –n20 salesdata.csv &gt; training.csv</code></p>
              <p id="c10-c10-para-0223" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0223">With small sets of data, you can write the core of your logic, test it, and then port it to a Hadoop MapReduce job later.</p>
            </level3>
            <level3 id="level3_000178">
              <h3 xml:space="preserve" id="h3_000178" smilref="Machine_Learning00012.smil#h3_000178">Writing the Core Methods</h3>
              <p xml:space="preserve" id="p_000799" smilref="Machine_Learning00012.smil#p_000799">In the stakeholder list of requirements, there are three methods you need to code up. Add a file reader to pull the CSV file in and loop through each customer record:</p>
              <p xml:space="preserve" id="p_000800"><code class="preserve-whitespace" xml:space="preserve" id="code_000684"><strong id="strong_000599" smilref="Machine_Learning00012.smil#strong_000599">package</strong><span class="text" id="span_001918" smilref="Machine_Learning00012.smil#span_001918"> chapter10;
</span><strong id="strong_000600" smilref="Machine_Learning00012.smil#strong_000600">import</strong><span class="text" id="span_001919" smilref="Machine_Learning00012.smil#span_001919"> java.io.BufferedReader;
</span><strong id="strong_000601" smilref="Machine_Learning00012.smil#strong_000601">import</strong><span class="text" id="span_001920" smilref="Machine_Learning00012.smil#span_001920"> java.io.FileReader;
</span><strong id="strong_000602" smilref="Machine_Learning00012.smil#strong_000602">import</strong><span class="text" id="span_001921" smilref="Machine_Learning00012.smil#span_001921"> java.io.IOException;
</span><strong id="strong_000603" smilref="Machine_Learning00012.smil#strong_000603">public</strong> <strong id="strong_000604" smilref="Machine_Learning00012.smil#strong_000604">class</strong><span class="text" id="span_001922" smilref="Machine_Learning00012.smil#span_001922"> CoreMethods {
    </span><strong id="strong_000605" smilref="Machine_Learning00012.smil#strong_000605">public</strong><span class="text" id="span_001923" smilref="Machine_Learning00012.smil#span_001923"> CoreMethods() {
        </span><strong id="strong_000606" smilref="Machine_Learning00012.smil#strong_000606">try</strong><span class="text" id="span_001924" smilref="Machine_Learning00012.smil#span_001924"> {
            BufferedReader in = </span><strong id="strong_000607" smilref="Machine_Learning00012.smil#strong_000607">new</strong><span class="text" id="span_001925" smilref="Machine_Learning00012.smil#span_001925"> BufferedReader(</span><strong id="strong_000608" smilref="Machine_Learning00012.smil#strong_000608">new</strong><span class="text" id="span_001926" smilref="Machine_Learning00012.smil#span_001926"> FileReader(
                    tmpdata.csv"));
            String str;
            </span><strong id="strong_000609" smilref="Machine_Learning00012.smil#strong_000609">while</strong><span class="text" id="span_001927" smilref="Machine_Learning00012.smil#span_001927"> ((str = in.readLine()) != </span><strong id="strong_000610" smilref="Machine_Learning00012.smil#strong_000610">null</strong><span class="text" id="span_001928" smilref="Machine_Learning00012.smil#span_001928">) {
                String[] split = str.split(",");
                </span><strong id="strong_000611" smilref="Machine_Learning00012.smil#strong_000611">double</strong><span class="text" id="span_001929" smilref="Machine_Learning00012.smil#span_001929">[] values = </span><strong id="strong_000612" smilref="Machine_Learning00012.smil#strong_000612">new</strong> <strong id="strong_000613" smilref="Machine_Learning00012.smil#strong_000613">double</strong><span class="text" id="span_001930" smilref="Machine_Learning00012.smil#span_001930">[12];
                // 0 = userid
                // 1 - 13 = months sales. Jan - Jan, Mar - Mar etc
                </span><strong id="strong_000614" smilref="Machine_Learning00012.smil#strong_000614">for</strong><span class="text" id="span_001931" smilref="Machine_Learning00012.smil#span_001931"> (</span><strong id="strong_000615" smilref="Machine_Learning00012.smil#strong_000615">int</strong><span class="text" id="span_001932" smilref="Machine_Learning00012.smil#span_001932"> i = 1; i &lt;= 12; i++) {
                    values[i-1] = Double.</span><em id="em_000342" smilref="Machine_Learning00012.smil#em_000342">parseDouble</em><span class="text" id="span_001933" smilref="Machine_Learning00012.smil#span_001933">(split[i]);
                }
                </span><strong id="strong_000616" smilref="Machine_Learning00012.smil#strong_000616">double</strong><span class="text" id="span_001934" smilref="Machine_Learning00012.smil#span_001934"> mean = getMean(values);
                System.</span><em id="em_000343" smilref="Machine_Learning00012.smil#em_000343">out</em><span class="text" id="span_001935" smilref="Machine_Learning00012.smil#span_001935">.println("User id: " + split[0]);
                System.</span><em id="em_000344" smilref="Machine_Learning00012.smil#em_000344">out</em><span class="text" id="span_001936" smilref="Machine_Learning00012.smil#span_001936">.println("\tMean: " + mean);
                System.</span><em id="em_000345" smilref="Machine_Learning00012.smil#em_000345">out</em><span class="text" id="span_001937" smilref="Machine_Learning00012.smil#span_001937">.println("\tMonth 13 Sales Drop = " + calcSalesDrop(Double.</span><em id="em_000346" smilref="Machine_Learning00012.smil#em_000346">parseDouble</em><span class="text" id="span_001938" smilref="Machine_Learning00012.smil#span_001938">(split[13]), mean));
                System.</span><em id="em_000347" smilref="Machine_Learning00012.smil#em_000347">out</em><span class="text" id="span_001939" smilref="Machine_Learning00012.smil#span_001939">.println("\tMonths 40% below mean: " + monthsBelow(values, mean));
            }
            in.close();
        } </span><strong id="strong_000617" smilref="Machine_Learning00012.smil#strong_000617">catch</strong><span class="text" id="span_001940" smilref="Machine_Learning00012.smil#span_001940"> (IOException e) {
            e.printStackTrace();
        }
    }
    </span><strong id="strong_000618" smilref="Machine_Learning00012.smil#strong_000618">private</strong> <strong id="strong_000619" smilref="Machine_Learning00012.smil#strong_000619">int</strong><span class="text" id="span_001941" smilref="Machine_Learning00012.smil#span_001941"> calcSalesDrop(</span><strong id="strong_000620" smilref="Machine_Learning00012.smil#strong_000620">double</strong><span class="text" id="span_001942" smilref="Machine_Learning00012.smil#span_001942"> lastMonth, </span><strong id="strong_000621" smilref="Machine_Learning00012.smil#strong_000621">double</strong><span class="text" id="span_001943" smilref="Machine_Learning00012.smil#span_001943"> mean) {
        </span><strong id="strong_000622" smilref="Machine_Learning00012.smil#strong_000622">return</strong><span class="text" id="span_001944" smilref="Machine_Learning00012.smil#span_001944"> (</span><strong id="strong_000623" smilref="Machine_Learning00012.smil#strong_000623">int</strong><span class="text" id="span_001945" smilref="Machine_Learning00012.smil#span_001945">)(lastMonth - mean) &lt; 0? 0: (</span><strong id="strong_000624" smilref="Machine_Learning00012.smil#strong_000624">int</strong><span class="text" id="span_001946" smilref="Machine_Learning00012.smil#span_001946">)(lastMonth - mean);
    }
    </span><strong id="strong_000625" smilref="Machine_Learning00012.smil#strong_000625">private</strong> <strong id="strong_000626" smilref="Machine_Learning00012.smil#strong_000626">int</strong><span class="text" id="span_001947" smilref="Machine_Learning00012.smil#span_001947"> monthsBelow(</span><strong id="strong_000627" smilref="Machine_Learning00012.smil#strong_000627">double</strong><span class="text" id="span_001948" smilref="Machine_Learning00012.smil#span_001948">[] data, </span><strong id="strong_000628" smilref="Machine_Learning00012.smil#strong_000628">double</strong><span class="text" id="span_001949" smilref="Machine_Learning00012.smil#span_001949"> mean) {
        </span><strong id="strong_000629" smilref="Machine_Learning00012.smil#strong_000629">int</strong><span class="text" id="span_001950" smilref="Machine_Learning00012.smil#span_001950"> count = 0;
        </span><strong id="strong_000630" smilref="Machine_Learning00012.smil#strong_000630">for</strong><span class="text" id="span_001951" smilref="Machine_Learning00012.smil#span_001951">(</span><strong id="strong_000631" smilref="Machine_Learning00012.smil#strong_000631">double</strong><span class="text" id="span_001952" smilref="Machine_Learning00012.smil#span_001952"> a: data) {
            </span><strong id="strong_000632" smilref="Machine_Learning00012.smil#strong_000632">if</strong><span class="text" id="span_001953" smilref="Machine_Learning00012.smil#span_001953">((a &lt; (mean * 0.40))) count++;
        }
        </span><strong id="strong_000633" smilref="Machine_Learning00012.smil#strong_000633">return</strong><span class="text" id="span_001954" smilref="Machine_Learning00012.smil#span_001954"> count;
    }
    </span><strong id="strong_000634" smilref="Machine_Learning00012.smil#strong_000634">private</strong> <strong id="strong_000635" smilref="Machine_Learning00012.smil#strong_000635">double</strong><span class="text" id="span_001955" smilref="Machine_Learning00012.smil#span_001955"> getMean(</span><strong id="strong_000636" smilref="Machine_Learning00012.smil#strong_000636">double</strong><span class="text" id="span_001956" smilref="Machine_Learning00012.smil#span_001956">[] data) {
        </span><strong id="strong_000637" smilref="Machine_Learning00012.smil#strong_000637">double</strong><span class="text" id="span_001957" smilref="Machine_Learning00012.smil#span_001957"> sum = 0.0;
        </span><strong id="strong_000638" smilref="Machine_Learning00012.smil#strong_000638">for</strong><span class="text" id="span_001958" smilref="Machine_Learning00012.smil#span_001958">(</span><strong id="strong_000639" smilref="Machine_Learning00012.smil#strong_000639">double</strong><span class="text" id="span_001959" smilref="Machine_Learning00012.smil#span_001959"> a: data) {
            sum += a;
        }
        </span><strong id="strong_000640" smilref="Machine_Learning00012.smil#strong_000640">return</strong><span class="text" id="span_001960" smilref="Machine_Learning00012.smil#span_001960"> sum/data.length;
    }
    </span><strong id="strong_000641" smilref="Machine_Learning00012.smil#strong_000641">public</strong> <strong id="strong_000642" smilref="Machine_Learning00012.smil#strong_000642">static</strong> <strong id="strong_000643" smilref="Machine_Learning00012.smil#strong_000643">void</strong><span class="text" id="span_001961" smilref="Machine_Learning00012.smil#span_001961"> main(String[] args) {
        CoreMethods coreMethods = </span><strong id="strong_000644" smilref="Machine_Learning00012.smil#strong_000644">new</strong><span class="text" id="span_001962" smilref="Machine_Learning00012.smil#span_001962"> CoreMethods();
    }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p259" page="normal" smilref="Machine_Learning00012.smil#p259">259</pagenum>
              <p id="c10-c10-para-0225" xml:space="preserve"><span class="text" id="span_001963" smilref="Machine_Learning00012.smil#span_001963">As you can see, there are three private methods. The </span><code xml:space="preserve" id="code_000685" smilref="Machine_Learning00012.smil#code_000685">getMean()</code><span class="text" id="span_001964" smilref="Machine_Learning00012.smil#span_001964"> method takes the array of the sales data from month 1 to 12. The </span><code xml:space="preserve" id="code_000686" smilref="Machine_Learning00012.smil#code_000686">calcSalesDrop()</code><span class="text" id="span_001965" smilref="Machine_Learning00012.smil#span_001965"> method takes the value of the last month of sales (month 13) and subtracts the mean. If it's a negative number, then it just returns zero. Last, the </span><code xml:space="preserve" id="code_000687" smilref="Machine_Learning00012.smil#code_000687">monthsBelow()</code><span class="text" id="span_001966" smilref="Machine_Learning00012.smil#span_001966"> method iterates through each of the 12 months, and anything below 40 percent of the mean is added to the count variable.</span></p>
              <p id="c10-c10-para-0226" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0226">Programmatically the methods are simple math functions, but they serve their purposes perfectly.</p>
              <p id="c10-c10-para-0227" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0227">Running the program with the test data, you get the following output:</p>
              <p xml:space="preserve" id="p_000801"><code class="preserve-whitespace" xml:space="preserve" id="code_000688" smilref="Machine_Learning00012.smil#code_000688">User id: 1
    Mean: 8.75
    Month 13 Sales Drop = 0
    Months 40% below mean: 1
User id: 2
    Mean: 5.916666666666667
    Month 13 Sales Drop = 8
    Months 40% below mean: 4
User id: 3
    Mean: 7.583333333333333
    Month 13 Sales Drop = 0
    Months 40% below mean: 4
User id: 4
    Mean: 7.833333333333333
    Month 13 Sales Drop = 1
    Months 40% below mean: 4
User id: 5
    Mean: 6.166666666666667
    Month 13 Sales Drop = 0
    Months 40% below mean: 2
User id: 6
    Mean: 5.5
    Month 13 Sales Drop = 0
    Months 40% below mean: 3</code></p>
              <pagenum epub:type="pagebreak" id="p260" page="normal" smilref="Machine_Learning00012.smil#p260">260</pagenum>
              <p id="c10-c10-para-0228" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0228">If this were a small coffee shop with a few hundred customers, then that would do fine. No need to complicate matters with Hadoop clusters or anything like that—it's computing power you just don't need. On the chance that the coffee shop acquires a global chain of shops and the customer count increases to millions of customers, then you have to start looking at alternatives.</p>
              <p id="c10-c10-para-0229" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0229">The next section looks at scaling it up using the Hadoop framework.</p>
            </level3>
            <level3 id="level3_000179">
              <h3 xml:space="preserve" id="h3_000179" smilref="Machine_Learning00012.smil#h3_000179">Using Hadoop and MapReduce</h3>
              <p xml:space="preserve" id="p_000802" smilref="Machine_Learning00012.smil#p_000802">You can reuse the core methods you created in the last program within the Hadoop framework. In terms of modification, it's a case of adding those three methods to within the map phase of the MapReduce job. The main difference between this code and the MapReduce job you created for the hashtag mining is that you don't require a reducer.</p>
              <p id="c10-c10-para-0231" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0231">In this instance, the mapper is going to work through each line of the sales data and output the results. The job configuration does not have any reducers set, so the output is the same number of records that goes in.</p>
              <p id="c10-c10-para-0232" xml:space="preserve" smilref="Machine_Learning00012.smil#c10-c10-para-0232">This time around, you add the job configuration in the same Java class as the mapper, just to keep everything together.</p>
              <p xml:space="preserve" id="p_000803"><code class="preserve-whitespace" xml:space="preserve" id="code_000689"><strong id="strong_000645" smilref="Machine_Learning00012.smil#strong_000645">package</strong><span class="text" id="span_001967" smilref="Machine_Learning00012.smil#span_001967"> chapter10;
</span><strong id="strong_000646" smilref="Machine_Learning00012.smil#strong_000646">import</strong><span class="text" id="span_001968" smilref="Machine_Learning00012.smil#span_001968"> java.io.IOException;
</span><strong id="strong_000647" smilref="Machine_Learning00012.smil#strong_000647">import</strong><span class="text" id="span_001969" smilref="Machine_Learning00012.smil#span_001969"> org.apache.hadoop.fs.Path;
</span><strong id="strong_000648" smilref="Machine_Learning00012.smil#strong_000648">import</strong><span class="text" id="span_001970" smilref="Machine_Learning00012.smil#span_001970"> org.apache.hadoop.io.LongWritable;
</span><strong id="strong_000649" smilref="Machine_Learning00012.smil#strong_000649">import</strong><span class="text" id="span_001971" smilref="Machine_Learning00013.smil#span_001971"> org.apache.hadoop.io.Text;
</span><strong id="strong_000650" smilref="Machine_Learning00013.smil#strong_000650">import</strong> <pagenum epub:type="pagebreak" id="p261" page="normal" smilref="Machine_Learning00013.smil#p261">261</pagenum><span class="text" id="span_001972" smilref="Machine_Learning00013.smil#span_001972">org.apache.hadoop.mapred.FileInputFormat;
</span><strong id="strong_000651" smilref="Machine_Learning00013.smil#strong_000651">import</strong><span class="text" id="span_001973" smilref="Machine_Learning00013.smil#span_001973"> org.apache.hadoop.mapred.JobClient;
</span><strong id="strong_000652" smilref="Machine_Learning00013.smil#strong_000652">import</strong><span class="text" id="span_001974" smilref="Machine_Learning00013.smil#span_001974"> org.apache.hadoop.mapred.JobConf;
</span><strong id="strong_000653" smilref="Machine_Learning00013.smil#strong_000653">import</strong><span class="text" id="span_001975" smilref="Machine_Learning00013.smil#span_001975"> org.apache.hadoop.mapred.MapReduceBase;
</span><strong id="strong_000654" smilref="Machine_Learning00013.smil#strong_000654">import</strong><span class="text" id="span_001976" smilref="Machine_Learning00013.smil#span_001976"> org.apache.hadoop.mapred.Mapper;
</span><strong id="strong_000655" smilref="Machine_Learning00013.smil#strong_000655">import</strong><span class="text" id="span_001977" smilref="Machine_Learning00013.smil#span_001977"> org.apache.hadoop.mapred.OutputCollector;
</span><strong id="strong_000656" smilref="Machine_Learning00013.smil#strong_000656">import</strong><span class="text" id="span_001978" smilref="Machine_Learning00013.smil#span_001978"> org.apache.hadoop.mapred.Reporter;
</span><strong id="strong_000657" smilref="Machine_Learning00013.smil#strong_000657">import</strong><span class="text" id="span_001979" smilref="Machine_Learning00013.smil#span_001979"> org.apache.hadoop.mapred.TextInputFormat;
</span><strong id="strong_000658" smilref="Machine_Learning00013.smil#strong_000658">import</strong><span class="text" id="span_001980" smilref="Machine_Learning00013.smil#span_001980"> org.apache.hadoop.mapred.TextOutputFormat;
</span><strong id="strong_000659" smilref="Machine_Learning00013.smil#strong_000659">import</strong><span class="text" id="span_001981" smilref="Machine_Learning00013.smil#span_001981"> org.apache.hadoop.mapred.FileOutputFormat;
</span><strong id="strong_000660" smilref="Machine_Learning00013.smil#strong_000660">public</strong> <strong id="strong_000661" smilref="Machine_Learning00013.smil#strong_000661">class</strong><span class="text" id="span_001982" smilref="Machine_Learning00013.smil#span_001982"> CoreMethodsMapper {
    </span><strong id="strong_000662" smilref="Machine_Learning00013.smil#strong_000662">public</strong> <strong id="strong_000663" smilref="Machine_Learning00013.smil#strong_000663">static</strong> <strong id="strong_000664" smilref="Machine_Learning00013.smil#strong_000664">class</strong><span class="text" id="span_001983" smilref="Machine_Learning00013.smil#span_001983"> Map </span><strong id="strong_000665" smilref="Machine_Learning00013.smil#strong_000665">extends</strong><span class="text" id="span_001984" smilref="Machine_Learning00013.smil#span_001984"> MapReduceBase </span><strong id="strong_000666" smilref="Machine_Learning00013.smil#strong_000666">implements</strong><span class="text" id="span_001985" smilref="Machine_Learning00013.smil#span_001985">
            Mapper&lt;LongWritable, Text, Text, Text&gt; {
        </span><strong id="strong_000667" smilref="Machine_Learning00013.smil#strong_000667">private</strong><span class="text" id="span_001986" smilref="Machine_Learning00013.smil#span_001986"> Text userid = </span><strong id="strong_000668" smilref="Machine_Learning00013.smil#strong_000668">new</strong><span class="text" id="span_001987" smilref="Machine_Learning00013.smil#span_001987"> Text();
        </span><strong id="strong_000669" smilref="Machine_Learning00013.smil#strong_000669">private</strong><span class="text" id="span_001988" smilref="Machine_Learning00013.smil#span_001988"> Text userinfo = </span><strong id="strong_000670" smilref="Machine_Learning00013.smil#strong_000670">new</strong><span class="text" id="span_001989" smilref="Machine_Learning00013.smil#span_001989"> Text();
        </span><strong id="strong_000671" smilref="Machine_Learning00013.smil#strong_000671">public</strong> <strong id="strong_000672" smilref="Machine_Learning00013.smil#strong_000672">void</strong><span class="text" id="span_001990" smilref="Machine_Learning00013.smil#span_001990"> map(LongWritable key, Text value,
                OutputCollector&lt;Text, Text&gt; output, Reporter reporter)
                </span><strong id="strong_000673" smilref="Machine_Learning00013.smil#strong_000673">throws</strong><span class="text" id="span_001991" smilref="Machine_Learning00013.smil#span_001991"> IOException {
            String[] split = value.toString().split(",");
            </span><strong id="strong_000674" smilref="Machine_Learning00013.smil#strong_000674">double</strong><span class="text" id="span_001992" smilref="Machine_Learning00013.smil#span_001992">[] datavalues = </span><strong id="strong_000675" smilref="Machine_Learning00013.smil#strong_000675">new</strong> <strong id="strong_000676" smilref="Machine_Learning00013.smil#strong_000676">double</strong><span class="text" id="span_001993" smilref="Machine_Learning00013.smil#span_001993">[12];
            </span><strong id="strong_000677" smilref="Machine_Learning00013.smil#strong_000677">for</strong><span class="text" id="span_001994" smilref="Machine_Learning00013.smil#span_001994"> (</span><strong id="strong_000678" smilref="Machine_Learning00013.smil#strong_000678">int</strong><span class="text" id="span_001995" smilref="Machine_Learning00013.smil#span_001995"> i = 1; i &lt;= 12; i++) {
                datavalues[i - 1] = Double.</span><em id="em_000348" smilref="Machine_Learning00013.smil#em_000348">parseDouble</em><span class="text" id="span_001996" smilref="Machine_Learning00013.smil#span_001996">(split[i]);
            }
            </span><strong id="strong_000679" smilref="Machine_Learning00013.smil#strong_000679">double</strong><span class="text" id="span_001997" smilref="Machine_Learning00013.smil#span_001997"> mean = getMean(datavalues);
            StringBuilder sb = </span><strong id="strong_000680" smilref="Machine_Learning00013.smil#strong_000680">new</strong><span class="text" id="span_001998" smilref="Machine_Learning00013.smil#span_001998"> StringBuilder()
                    .append(mean + "\t")
                    .append(calcSalesDrop(Double.</span><em id="em_000349" smilref="Machine_Learning00013.smil#em_000349">parseDouble</em><span class="text" id="span_001999" smilref="Machine_Learning00013.smil#span_001999">(split[13]), mean)
                            + "\t").append(monthsBelow(datavalues, mean));
            userid.set(split[0]); // define our output key, the user id
            userinfo.set(sb.toString()); // define the output data
            output.collect(userid, userinfo);
        }
        </span><strong id="strong_000681" smilref="Machine_Learning00013.smil#strong_000681">private</strong> <strong id="strong_000682" smilref="Machine_Learning00013.smil#strong_000682">int</strong><span class="text" id="span_002000" smilref="Machine_Learning00013.smil#span_002000"> calcSalesDrop(</span><strong id="strong_000683" smilref="Machine_Learning00013.smil#strong_000683">double</strong><span class="text" id="span_002001" smilref="Machine_Learning00013.smil#span_002001"> lastMonth, </span><strong id="strong_000684" smilref="Machine_Learning00013.smil#strong_000684">double</strong><span class="text" id="span_002002" smilref="Machine_Learning00013.smil#span_002002"> mean) {
            </span><strong id="strong_000685" smilref="Machine_Learning00013.smil#strong_000685">return</strong><span class="text" id="span_002003" smilref="Machine_Learning00013.smil#span_002003"> (</span><strong id="strong_000686" smilref="Machine_Learning00013.smil#strong_000686">int</strong><span class="text" id="span_002004" smilref="Machine_Learning00013.smil#span_002004">) (lastMonth - mean) &lt; 0? 0: (</span><strong id="strong_000687" smilref="Machine_Learning00013.smil#strong_000687">int</strong><span class="text" id="span_002005" smilref="Machine_Learning00013.smil#span_002005">) (lastMonth - mean);
        }
        </span><strong id="strong_000688" smilref="Machine_Learning00013.smil#strong_000688">private</strong> <strong id="strong_000689" smilref="Machine_Learning00013.smil#strong_000689">int</strong><span class="text" id="span_002006" smilref="Machine_Learning00013.smil#span_002006"> monthsBelow(</span><strong id="strong_000690" smilref="Machine_Learning00013.smil#strong_000690">double</strong><span class="text" id="span_002007" smilref="Machine_Learning00013.smil#span_002007">[] data, </span><strong id="strong_000691" smilref="Machine_Learning00013.smil#strong_000691">double</strong><span class="text" id="span_002008" smilref="Machine_Learning00013.smil#span_002008"> mean) {
            </span><strong id="strong_000692" smilref="Machine_Learning00013.smil#strong_000692">int</strong><span class="text" id="span_002009" smilref="Machine_Learning00013.smil#span_002009"> count = 0;
            </span><strong id="strong_000693" smilref="Machine_Learning00013.smil#strong_000693">for</strong><span class="text" id="span_002010" smilref="Machine_Learning00013.smil#span_002010"> (</span><strong id="strong_000694" smilref="Machine_Learning00013.smil#strong_000694">double</strong><span class="text" id="span_002011" smilref="Machine_Learning00013.smil#span_002011"> a: data) {
                </span><strong id="strong_000695" smilref="Machine_Learning00013.smil#strong_000695">if</strong><span class="text" id="span_002012" smilref="Machine_Learning00013.smil#span_002012"> ((a &lt; (mean * 0.40)))
                    count++;
            }
            </span><strong id="strong_000696" smilref="Machine_Learning00013.smil#strong_000696">return</strong><span class="text" id="span_002013" smilref="Machine_Learning00013.smil#span_002013"> count;
        }
        </span><strong id="strong_000697" smilref="Machine_Learning00013.smil#strong_000697">private</strong> <strong id="strong_000698" smilref="Machine_Learning00013.smil#strong_000698">double</strong><span class="text" id="span_002014" smilref="Machine_Learning00013.smil#span_002014"> getMean(</span><strong id="strong_000699" smilref="Machine_Learning00013.smil#strong_000699">double</strong><span class="text" id="span_002015" smilref="Machine_Learning00013.smil#span_002015">[] data) {
            </span><strong id="strong_000700" smilref="Machine_Learning00013.smil#strong_000700">double</strong><span class="text" id="span_002016" smilref="Machine_Learning00013.smil#span_002016"> sum = 0.0;
            </span><strong id="strong_000701" smilref="Machine_Learning00013.smil#strong_000701">for</strong><span class="text" id="span_002017" smilref="Machine_Learning00013.smil#span_002017"> (</span><strong id="strong_000702" smilref="Machine_Learning00013.smil#strong_000702">double</strong><span class="text" id="span_002018" smilref="Machine_Learning00013.smil#span_002018"> a: data) {
                sum += a;
            }
            </span><strong id="strong_000703" smilref="Machine_Learning00013.smil#strong_000703">return</strong><span class="text" id="span_002019" smilref="Machine_Learning00013.smil#span_002019"> sum / data.length;
        }
    }
    </span><strong id="strong_000704" smilref="Machine_Learning00013.smil#strong_000704">public</strong> <strong id="strong_000705" smilref="Machine_Learning00013.smil#strong_000705">static</strong> <strong id="strong_000706" smilref="Machine_Learning00013.smil#strong_000706">void</strong><span class="text" id="span_002020" smilref="Machine_Learning00013.smil#span_002020"> main(String args[]) </span><strong id="strong_000707" smilref="Machine_Learning00013.smil#strong_000707">throws</strong><span class="text" id="span_002021" smilref="Machine_Learning00013.smil#span_002021"> IOException {
        JobConf conf = </span><strong id="strong_000708" smilref="Machine_Learning00013.smil#strong_000708">new</strong><span class="text" id="span_002022" smilref="Machine_Learning00013.smil#span_002022"> JobConf(CoreMethodsMapper.</span><strong id="strong_000709" smilref="Machine_Learning00013.smil#strong_000709">class</strong><span class="text" id="span_002023" smilref="Machine_Learning00013.smil#span_002023">);
        conf.setJobName("CoreMethods Sales Data");
        conf.setNumReduceTasks(0); // no reducers!
        conf.setOutputKeyClass(Text.</span><strong id="strong_000710" smilref="Machine_Learning00013.smil#strong_000710">class</strong><span class="text" id="span_002024" smilref="Machine_Learning00013.smil#span_002024">);
        conf.setOutputValueClass(Text.</span><strong id="strong_000711" smilref="Machine_Learning00013.smil#strong_000711">class</strong><span class="text" id="span_002025" smilref="Machine_Learning00013.smil#span_002025">);
        conf.setMapperClass(Map.</span><strong id="strong_000712" smilref="Machine_Learning00013.smil#strong_000712">class</strong><span class="text" id="span_002026" smilref="Machine_Learning00013.smil#span_002026">); // the map class within this code
        conf.setInputFormat(TextInputFormat.</span><strong id="strong_000713" smilref="Machine_Learning00013.smil#strong_000713">class</strong><span class="text" id="span_002027" smilref="Machine_Learning00013.smil#span_002027">);
        conf.setOutputFormat(TextOutputFormat.</span><strong id="strong_000714" smilref="Machine_Learning00013.smil#strong_000714">class</strong><span class="text" id="span_002028" smilref="Machine_Learning00013.smil#span_002028">);
        FileInputFormat.</span><em id="em_000350" smilref="Machine_Learning00013.smil#em_000350">setInputPaths</em><span class="text" id="span_002029" smilref="Machine_Learning00013.smil#span_002029">(conf, </span><strong id="strong_000715" smilref="Machine_Learning00013.smil#strong_000715">new</strong><span class="text" id="span_002030" smilref="Machine_Learning00013.smil#span_002030"> Path(args[0]));
        FileOutputFormat.</span><em id="em_000351" smilref="Machine_Learning00013.smil#em_000351">setOutputPath</em><span class="text" id="span_002031" smilref="Machine_Learning00013.smil#span_002031">(conf, </span><strong id="strong_000716" smilref="Machine_Learning00013.smil#strong_000716">new</strong><span class="text" id="span_002032" smilref="Machine_Learning00013.smil#span_002032"> Path(args[1]));
        JobClient.</span><em id="em_000352" smilref="Machine_Learning00013.smil#em_000352">runJob</em><span class="text" id="span_002033" smilref="Machine_Learning00013.smil#span_002033">(conf);
    }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p262" page="normal" smilref="Machine_Learning00013.smil#p262">262</pagenum>
              <p id="c10-c10-para-0233" xml:space="preserve"><span class="text" id="span_002034" smilref="Machine_Learning00013.smil#span_002034">The main method contains the job configuration; notice that there's a method called </span><code xml:space="preserve" id="code_000690" smilref="Machine_Learning00013.smil#code_000690">setNumReduceTasks()</code><span class="text" id="span_002035" smilref="Machine_Learning00013.smil#span_002035"> and it's set to zero. You're telling Hadoop not to perform any reducers and just write out what the mapper is sending.</span></p>
              <p id="c10-c10-para-0234" xml:space="preserve"><span class="text" id="span_002036" smilref="Machine_Learning00013.smil#span_002036">Copy the entire 20,000-record sales data set into the </span><code xml:space="preserve" id="code_000691" smilref="Machine_Learning00013.smil#code_000691">input</code><span class="text" id="span_002037" smilref="Machine_Learning00013.smil#span_002037"> directory.</span></p>
              <p id="c10-c10-para-0235" xml:space="preserve"><span class="text" id="span_002038" smilref="Machine_Learning00013.smil#span_002038">To run the job, you have to export the </span><code xml:space="preserve" id="code_000692" smilref="Machine_Learning00013.smil#code_000692">jar</code><span class="text" id="span_002039" smilref="Machine_Learning00013.smil#span_002039"> file with the class file inside and use Hadoop to run it. (If you need a reminder on how to create the </span><code xml:space="preserve" id="code_000693" smilref="Machine_Learning00013.smil#code_000693">jar</code><span class="text" id="span_002040" smilref="Machine_Learning00013.smil#span_002040"> files and run them with Hadoop, there are examples earlier in this chapter.)</span></p>
              <p xml:space="preserve" id="p_000804"><code class="preserve-whitespace" xml:space="preserve" id="code_000694" smilref="Machine_Learning00013.smil#code_000694">hadoop jar coremethodstest.jar chapter10.CoreMethodsMapper input output</code></p>
              <pagenum epub:type="pagebreak" id="p263" page="normal" smilref="Machine_Learning00013.smil#p263">263</pagenum>
              <p id="c10-c10-para-0236" xml:space="preserve"><span class="text" id="span_002041" smilref="Machine_Learning00013.smil#span_002041">The output is sent to the </span><code xml:space="preserve" id="code_000695" smilref="Machine_Learning00013.smil#code_000695">output</code><span class="text" id="span_002042" smilref="Machine_Learning00013.smil#span_002042"> folder, and within the </span><code xml:space="preserve" id="code_000696" smilref="Machine_Learning00013.smil#code_000696">part-00000</code><span class="text" id="span_002043" smilref="Machine_Learning00013.smil#span_002043"> file you see all the records in order with their mean, sales drop, and months below average:</span></p>
              <p xml:space="preserve" id="p_000805"><code class="preserve-whitespace" xml:space="preserve" id="code_000697" smilref="Machine_Learning00013.smil#code_000697">head -n 20 output/part-00000
1    8.75    0    1
2    5.916666666666667    8    4
3    7.583333333333333    0    4
4    7.833333333333333    1    4
5    6.166666666666667    0    2
6    5.5    0    3
7    7.416666666666667    6    3
8    8.833333333333334    0    2
9    7.416666666666667    0    2
10    5.666666666666667    3    4
11    7.75    0    3
12    6.75    6    2
13    7.333333333333333    0    1
14    8.666666666666666    0    1
15    7.833333333333333    0    3
16    5.583333333333333    0    1
17    8.0    0    2
18    7.0    0    2
19    7.333333333333333    0    1
20    8.416666666666666    0    1</code></p>
              <p id="c10-c10-para-0237" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0237">The output is tab delimited, so you can easily import it into a database or a spreadsheet if you need to.</p>
              <p id="c10-c10-para-0238" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0238">Hadoop can be used for many applications, and, although the main emphasis is on the MapReduce programming model, sometimes there's no need for the reducer. The mapper acts as a very handy parallel work distributor.</p>
              <p id="c10-c10-para-0239" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0239">One of the issues with the Hadoop framework is that there's programming knowledge required to construct the mapper and reducer code. So, what happens if there aren't any programmers in your organization that would perhaps struggle with crafting a MapReduce program? Then you need to think about a way of scripting a MapReduce job in a more abstract way that does not require deep programming skill.</p>
            </level3>
            <level3 id="level3_000180">
              <h3 xml:space="preserve" id="h3_000180" smilref="Machine_Learning00013.smil#h3_000180">Using Pig to Mine Sales Data</h3>
              <p xml:space="preserve" id="p_000806" smilref="Machine_Learning00013.smil#p_000806">Coding MapReduce jobs can be a bit of a chore, as there's a lot of coding that goes into a basic MapReduce job. It is worth noting that you're not limited to using Java to create the jobs; with the Hadoop streaming facility you can use languages such as Ruby, Python, and R for processing the data. All those languages require good scripters or programmers to code solutions. With Pig, though, you can produce MapReduce models with a basic scripting language that looks very much like SQL.</p>
              <pagenum epub:type="pagebreak" id="p264" page="normal" smilref="Machine_Learning00013.smil#p264">264</pagenum>
              <p id="c10-c10-para-0241" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0241">Why the name Pig? It's derived from the Pig Latin language. Pig abstracts the MapReduce model and converts it into a higher-level language that's a lot easier to understand. I must stress, though, that Pig is not SQL; it just looks a bit like it.</p>
              <level4 id="level4_000118">
                <h4 xml:space="preserve" id="h4_000118" smilref="Machine_Learning00013.smil#h4_000118">Installing Pig</h4>
                <p xml:space="preserve" id="p_000807"><span class="text" id="span_002044" smilref="Machine_Learning00013.smil#span_002044">The Pig downloads are available from </span><code xml:space="preserve" id="code_000698"><a href="http://www.apache.org/dyn/closer.cgi/pig" external="true" id="a_000308" smilref="Machine_Learning00013.smil#a_000308">www.apache.org/dyn/closer.cgi/pig</a></code><span class="text" id="span_002045" smilref="Machine_Learning00013.smil#span_002045">. After you have downloaded a release, you need to unzip and then untar it to your chosen directory.</span></p>
                <p id="c10-c10-para-0243" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0243">For these examples, I use Pig in local mode (on a single machine with no parallel processing) and later use the batch mode where I save Pig scripts in their own files. You can use Pig in MapReduce mode and that uses the Hadoop cluster to connect and access the HDFS file system.</p>
              </level4>
              <level4 id="level4_000119">
                <h4 xml:space="preserve" id="h4_000119" smilref="Machine_Learning00013.smil#h4_000119">Starting the Pig Console</h4>
                <p xml:space="preserve" id="p_000808" smilref="Machine_Learning00013.smil#p_000808">To start the console in local mode, you run the following from the command line:</p>
                <p xml:space="preserve" id="p_000809"><code class="preserve-whitespace" xml:space="preserve" id="code_000699" smilref="Machine_Learning00013.smil#code_000699">pig –x local</code></p>
                <p id="c10-c10-para-0245" xml:space="preserve"><span class="text" id="span_002046" smilref="Machine_Learning00013.smil#span_002046">After it's loaded, you see Pig's command prompt, </span><code xml:space="preserve" id="code_000700" smilref="Machine_Learning00013.smil#code_000700">grunt&gt;</code><span class="text" id="span_002047" smilref="Machine_Learning00013.smil#span_002047">, and you're ready to get started.</span></p>
                <p id="c10-c10-para-0246" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0246">Before you can do anything, you need to load some data. Use the sales data that you've previously been working on.</p>
              </level4>
              <level4 id="level4_000120">
                <h4 xml:space="preserve" id="h4_000120" smilref="Machine_Learning00013.smil#h4_000120">Loading Data into Pig</h4>
                <p xml:space="preserve" id="p_000810"><span class="text" id="span_002048" smilref="Machine_Learning00013.smil#span_002048">The </span><code xml:space="preserve" id="code_000701" smilref="Machine_Learning00013.smil#code_000701">LOAD</code><span class="text" id="span_002049" smilref="Machine_Learning00013.smil#span_002049"> command reads in the data. In its most basic form it is a very greedy command:</span></p>
                <p xml:space="preserve" id="p_000811"><code class="preserve-whitespace" xml:space="preserve" id="code_000702" smilref="Machine_Learning00013.smil#code_000702">grunt&gt; SD = LOAD 'salesdata.csv ' USING PigStorage(' ,');</code></p>
                <p id="c10-c10-para-0248" xml:space="preserve"><span class="text" id="span_002050" smilref="Machine_Learning00013.smil#span_002050">This loads the sales data into a Pig variable called </span><code xml:space="preserve" id="code_000703" smilref="Machine_Learning00013.smil#code_000703">SD</code><span class="text" id="span_002051" smilref="Machine_Learning00013.smil#span_002051"> (that's the name I gave it and not a Pig-defined one). The </span><code xml:space="preserve" id="code_000704" smilref="Machine_Learning00013.smil#code_000704">PigStorage</code><span class="text" id="span_002052" smilref="Machine_Learning00013.smil#span_002052"> function is a storage type that Pig uses as a loading and storing utility. It acts as a parser to the input records. We're supplying the </span><code xml:space="preserve" id="code_000705" smilref="Machine_Learning00013.smil#code_000705">PigStorage</code><span class="text" id="span_002053" smilref="Machine_Learning00013.smil#span_002053"> with the comma to parse on.</span></p>
                <p id="c10-c10-para-0249" xml:space="preserve"><span class="text" id="span_002054" smilref="Machine_Learning00013.smil#span_002054">To make sure the data has loaded into Pig, you can run the </span><code xml:space="preserve" id="code_000706" smilref="Machine_Learning00013.smil#code_000706">DUMP</code><span class="text" id="span_002055" smilref="Machine_Learning00013.smil#span_002055"> command to see what the input looks like.</span></p>
                <p xml:space="preserve" id="p_000812"><code class="preserve-whitespace" xml:space="preserve" id="code_000707" smilref="Machine_Learning00013.smil#code_000707">grunt&gt; DUMP SD;</code></p>
                <p id="c10-c10-para-0250" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0250">You see the output sent to the console; here are the last few lines of the sales data:</p>
                <p xml:space="preserve" id="p_000813"><code class="preserve-whitespace" xml:space="preserve" id="code_000708" smilref="Machine_Learning00013.smil#code_000708">(19985,3,5,1,13,13,8,6,14,4,9,7,2,6)
(19986,2,9,3,13,5,1,12,7,12,0,12,7,12)
(19987,7,11,11,6,13,3,2,5,6,11,4,7,9)
(19988,6,4,2,7,13,3,7,11,13,2,11,12,12)
(19989,12,0,3,0,14,7,0,5,6,8,9,1,5)
(19990,6,2,10,9,1,12,9,8,10,2,2,8,8)
(19991,2,11,14,4,14,10,10,8,13,8,1,9,1)
(19992,9,12,1,14,12,3,0,7,12,2,0,5,13)
(19993,1,2,13,8,6,9,10,14,9,2,2,14,2)
(19994,9,4,4,2,11,9,10,4,2,3,13,9,0)
(19995,5,2,1,1,14,4,9,12,4,13,6,7,14)
(19996,3,6,6,13,8,1,14,10,5,0,7,9,14)
(19997,4,8,13,3,14,11,4,2,11,12,13,8,1)
(19998,8,10,5,8,12,9,7,8,14,8,14,7,12)
(19999,10,13,14,4,10,14,2,9,11,14,9,14,8)
(20000,2,4,7,2,9,10,8,13,7,1,5,9,3)</code></p>
                <pagenum epub:type="pagebreak" id="p265" page="normal" smilref="Machine_Learning00013.smil#p265">265</pagenum>
                <p id="c10-c10-para-0251" xml:space="preserve"><span class="text" id="span_002056" smilref="Machine_Learning00013.smil#span_002056">Notice how you've not told Pig what the schema is; it's just assuming that there's something there, regardless of whether it's numbers or text. Pig is very greedy on these terms; it guesses its way around and basically consumes any data that's loaded in. To define what data the </span><code xml:space="preserve" id="code_000709" smilref="Machine_Learning00013.smil#code_000709">PigStorage</code><span class="text" id="span_002057" smilref="Machine_Learning00013.smil#span_002057"> is to expect, you can define a schema:</span></p>
                <p xml:space="preserve" id="p_000814"><code class="preserve-whitespace" xml:space="preserve" id="code_000710" smilref="Machine_Learning00013.smil#code_000710">grunt&gt; SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);</code></p>
                <p id="c10-c10-para-0252" xml:space="preserve"><span class="text" id="span_002058" smilref="Machine_Learning00013.smil#span_002058">All the values are integers and the schema is basic; it's a customer ID and then the values for the 13 months of sales. There are identifiers for the values too: </span><code xml:space="preserve" id="code_000711" smilref="Machine_Learning00013.smil#code_000711">custid</code><span class="text" id="span_002059" smilref="Machine_Learning00013.smil#span_002059">, </span><code xml:space="preserve" id="code_000712" smilref="Machine_Learning00013.smil#code_000712">m1</code><span class="text" id="span_002060" smilref="Machine_Learning00013.smil#span_002060">, </span><code xml:space="preserve" id="code_000713" smilref="Machine_Learning00013.smil#code_000713">m2</code><span class="text" id="span_002061" smilref="Machine_Learning00013.smil#span_002061">, and so on. If relation names are not defined then you can reference by position using the dollar sign: $0, $1, $2, and so on.</span></p>
                <p id="c10-c10-para-0253" xml:space="preserve"><span class="text" id="span_002062" smilref="Machine_Learning00013.smil#span_002062">When a schema is presented in the </span><code xml:space="preserve" id="code_000714" smilref="Machine_Learning00013.smil#code_000714">LOAD</code><span class="text" id="span_002063" smilref="Machine_Learning00013.smil#span_002063"> statement, then Pig tries to conform the best it can. If it comes across data that doesn't match the schema, it either returns a null value or throws an error.</span></p>
              </level4>
              <level4 id="level4_000121">
                <h4 xml:space="preserve" id="h4_000121" smilref="Machine_Learning00013.smil#h4_000121">Data Types in Pig</h4>
                <p xml:space="preserve" id="p_000815"><span class="text" id="span_002064" smilref="Machine_Learning00013.smil#span_002064">For now you're using integer data types, but the other data types that Pig supports are listed in </span><a id="c10-c10-tbl-anc-0001" href="#c10-c10-tbl-0001" external="false" smilref="Machine_Learning00013.smil#c10-c10-tbl-anc-0001">Tables 10-1</a><span class="text" id="span_002065" smilref="Machine_Learning00013.smil#span_002065"> and </span><a id="c10-c10-tbl-anc-0002" href="#c10-c10-tbl-0002" external="false" smilref="Machine_Learning00013.smil#c10-c10-tbl-anc-0002">10-2</a><span class="text" id="span_002066" smilref="Machine_Learning00013.smil#span_002066"> for reference. Further in the walkthrough, I bring in more data types when I cover joining tables of data together.</span></p>
                <figure id="figure_000103">
                  <figcaption id="figcaption_000089">
                    <p xml:space="preserve" id="p_000816"><span class="figureLabel" id="span_002067"><a id="c10-c10-tbl-0001" href="#c10-c10-tbl-anc-0001" external="false"><strong id="strong_000717" smilref="Machine_Learning00013.smil#strong_000717">Table 10-1</strong></a></span> <pagenum epub:type="pagebreak" id="p266" page="normal" smilref="Machine_Learning00013.smil#p266">266</pagenum><span class="text" id="span_002068" smilref="Machine_Learning00013.smil#span_002068">Simple Data Types</span></p>
                  </figcaption>
                  <table border="1" id="table_000023">
                    <tr id="tr_000130">
                      <td class="left" rowspan="1" colspan="1" id="td_000383" smilref="Machine_Learning00013.smil#td_000383">Data Type</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000384" smilref="Machine_Learning00013.smil#td_000384">Description</td>
                    </tr>
                    <tr id="tr_000131">
                      <td class="left" rowspan="1" colspan="1" id="td_000385">
                        <code xml:space="preserve" id="code_000715" smilref="Machine_Learning00013.smil#code_000715">chararray</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000386" smilref="Machine_Learning00013.smil#td_000386">A character array string formatted in Unicode UTF-8</td>
                    </tr>
                    <tr id="tr_000132">
                      <td class="left" rowspan="1" colspan="1" id="td_000387">
                        <code xml:space="preserve" id="code_000716" smilref="Machine_Learning00013.smil#code_000716">bytearray</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000388" smilref="Machine_Learning00013.smil#td_000388">Byte array (blob)</td>
                    </tr>
                    <tr id="tr_000133">
                      <td class="left" rowspan="1" colspan="1" id="td_000389">
                        <code xml:space="preserve" id="code_000717" smilref="Machine_Learning00013.smil#code_000717">int</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000390" smilref="Machine_Learning00013.smil#td_000390">Signed 32-bit integer</td>
                    </tr>
                    <tr id="tr_000134">
                      <td class="left" rowspan="1" colspan="1" id="td_000391">
                        <code xml:space="preserve" id="code_000718" smilref="Machine_Learning00013.smil#code_000718">long</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000392" smilref="Machine_Learning00013.smil#td_000392">Signed 64-bit integer</td>
                    </tr>
                    <tr id="tr_000135">
                      <td class="left" rowspan="1" colspan="1" id="td_000393">
                        <code xml:space="preserve" id="code_000719" smilref="Machine_Learning00013.smil#code_000719">float</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000394" smilref="Machine_Learning00013.smil#td_000394">32-bit floating point</td>
                    </tr>
                    <tr id="tr_000136">
                      <td class="left" rowspan="1" colspan="1" id="td_000395">
                        <code xml:space="preserve" id="code_000720" smilref="Machine_Learning00013.smil#code_000720">double</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000396" smilref="Machine_Learning00013.smil#td_000396">64-bit floating point</td>
                    </tr>
                  </table>
                </figure>
                <figure id="figure_000104">
                  <figcaption id="figcaption_000090">
                    <p xml:space="preserve" id="p_000817"><span class="figureLabel" id="span_002069"><a id="c10-c10-tbl-0002" href="#c10-c10-tbl-anc-0002" external="false"><strong id="strong_000718" smilref="Machine_Learning00013.smil#strong_000718">Table 10-2</strong></a></span><span class="text" id="span_002070" smilref="Machine_Learning00013.smil#span_002070"> Complex Data Types</span></p>
                  </figcaption>
                  <table border="1" id="table_000024">
                    <tr id="tr_000137">
                      <td class="left" rowspan="1" colspan="1" id="td_000397" smilref="Machine_Learning00013.smil#td_000397">Data Type</td>
                      <td class="left" rowspan="1" colspan="1" id="td_000398" smilref="Machine_Learning00013.smil#td_000398">Description</td>
                    </tr>
                    <tr id="tr_000138">
                      <td class="left" rowspan="1" colspan="1" id="td_000399">
                        <code xml:space="preserve" id="code_000721" smilref="Machine_Learning00013.smil#code_000721">tuple</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000400" smilref="Machine_Learning00013.smil#td_000400">An ordered set of fields.Example: (1,2,8,2,3,0)</td>
                    </tr>
                    <tr id="tr_000139">
                      <td class="left" rowspan="1" colspan="1" id="td_000401">
                        <code xml:space="preserve" id="code_000722" smilref="Machine_Learning00013.smil#code_000722">bag</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000402" smilref="Machine_Learning00013.smil#td_000402">A collection of tuples.Example: {(1,2),(4,2),(9,8)}</td>
                    </tr>
                    <tr id="tr_000140">
                      <td class="left" rowspan="1" colspan="1" id="td_000403">
                        <code xml:space="preserve" id="code_000723" smilref="Machine_Learning00013.smil#code_000723">map</code>
                      </td>
                      <td class="left" rowspan="1" colspan="1" id="td_000404" smilref="Machine_Learning00013.smil#td_000404">A set of key value pairs.Example: [mykey#myvalue]</td>
                    </tr>
                  </table>
                </figure>
                <p id="c10-c10-para-0261" xml:space="preserve"><span class="text" id="span_002071" smilref="Machine_Learning00013.smil#span_002071">If a schema is not present, then Pig defaults to the type </span><code xml:space="preserve" id="code_000724" smilref="Machine_Learning00013.smil#code_000724">bytearray</code><span class="text" id="span_002072" smilref="Machine_Learning00013.smil#span_002072"> and attempts to convert the data, depending on the context in which you are using that data.</span></p>
              </level4>
              <level4 id="level4_000122">
                <h4 xml:space="preserve" id="h4_000122" smilref="Machine_Learning00013.smil#h4_000122">Running the Sales Data as a Pig Script</h4>
                <p xml:space="preserve" id="p_000818" smilref="Machine_Learning00013.smil#p_000818">With a bit of Pig theory under your belt, you can concentrate on the sales data again. Up to now you've done the major processing of any data in Java either as a plain program or using the Hadoop framework to run MapReduce on larger volumes. Quickly review what you need to do with the data:</p>
                <list type="ul" id="list_000063">
                  <li id="li_000433">
                    <span class="text" id="span_002073" smilref="Machine_Learning00013.smil#span_002073">How many lattes do my customers purchase?</span>
                    <p xml:space="preserve" id="p_000819"><strong id="strong_000719" smilref="Machine_Learning00013.smil#strong_000719">Calculate the mean sales on months 1-12.</strong></p>
                  </li>
                  <li id="li_000434">
                    <span class="text" id="span_002074" smilref="Machine_Learning00013.smil#span_002074">What is the sales drop for each customer?</span>
                    <p xml:space="preserve" id="p_000820"><strong id="strong_000720" smilref="Machine_Learning00013.smil#strong_000720">Subtract the month 13 sales from the mean.</strong></p>
                  </li>
                  <li id="li_000435">
                    <span class="text" id="span_002075" smilref="Machine_Learning00013.smil#span_002075">What is the duration of the sales drop?</span>
                    <p xml:space="preserve" id="p_000821"><strong id="strong_000721" smilref="Machine_Learning00013.smil#strong_000721">Calculate the number of months in which sales were below 40 percent of the mean.</strong></p>
                  </li>
                </list>
                <p id="c10-c10-para-0269" xml:space="preserve"><span class="text" id="span_002076" smilref="Machine_Learning00013.smil#span_002076">It's easier to create scripts in a text editor and run from the command line. If you're still within the Pig shell, then exit using the </span><code xml:space="preserve" id="code_000725" smilref="Machine_Learning00013.smil#code_000725">quit</code><span class="text" id="span_002077" smilref="Machine_Learning00013.smil#span_002077"> command and you return to the command prompt.</span></p>
                <p id="c10-c10-para-0270" xml:space="preserve"><span class="text" id="span_002078" smilref="Machine_Learning00013.smil#span_002078">Open your text editor of choice. Call the file </span><code xml:space="preserve" id="code_000726" smilref="Machine_Learning00013.smil#code_000726">salesdata.pig</code><span class="text" id="span_002079" smilref="Machine_Learning00013.smil#span_002079">; it will contain your script. The first two items on the list are straightforward and the last requires some thought.</span></p>
                <p xml:space="preserve" id="p_000822"><code class="preserve-whitespace" xml:space="preserve" id="code_000727" smilref="Machine_Learning00013.smil#code_000727">SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);
AVGDATA =  FOREACH SD GENERATE custid,
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12}),
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12})-m13;
DUMP AVGDATA; </code></p>
                <pagenum epub:type="pagebreak" id="p267" page="normal" smilref="Machine_Learning00013.smil#p267">267</pagenum>
                <p id="c10-c10-para-0271" xml:space="preserve"><span class="text" id="span_002080" smilref="Machine_Learning00013.smil#span_002080">The script is basic, but as a first pass it already fulfills the first type requirements. On the first line, you import the data using a set schema with the customer ID and then the months. The imported data is saved in a variable called </span><code xml:space="preserve" id="code_000728" smilref="Machine_Learning00013.smil#code_000728">SD</code><span class="text" id="span_002081" smilref="Machine_Learning00013.smil#span_002081">.</span></p>
                <p id="c10-c10-para-0272" xml:space="preserve"><span class="text" id="span_002082" smilref="Machine_Learning00013.smil#span_002082">You create a new variable called </span><code xml:space="preserve" id="code_000729" smilref="Machine_Learning00013.smil#code_000729">AVGDATA</code><span class="text" id="span_002083" smilref="Machine_Learning00013.smil#span_002083"> by iterating through each line of </span><code xml:space="preserve" id="code_000730" smilref="Machine_Learning00013.smil#code_000730">SD</code><span class="text" id="span_002084" smilref="Machine_Learning00013.smil#span_002084"> and storing the customer ID and the average of months 1 through 12 sales, and then calculating the sales drop. Last, you output the new calculations to the console.</span></p>
                <p id="c10-c10-para-0273" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0273">Save the script in your text editor and exit. Make sure that the data is in the same directory as the Pig script and run the following command:</p>
                <p xml:space="preserve" id="p_000823"><code class="preserve-whitespace" xml:space="preserve" id="code_000731" smilref="Machine_Learning00013.smil#code_000731">pig –x local salesdata.pig</code></p>
                <p id="c10-c10-para-0274" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0274">You see Pig start processing the script and the data. If all is well, you see all 20,000 records output to the console with the customer ID, average sales, and the sales drop.</p>
                <p xml:space="preserve" id="p_000824"><code class="preserve-whitespace" xml:space="preserve" id="code_000732" smilref="Machine_Learning00013.smil#code_000732">(19989,5.416666666666667,0.41666666666666696)
(19990,6.583333333333333,-1.416666666666667)
(19991,8.666666666666666,7.666666666666666)
(19992,6.416666666666667,-6.583333333333333)
(19993,7.5,5.5)
(19994,6.666666666666667,6.666666666666667)
(19995,6.5,-7.5)
(19996,6.833333333333333,-7.166666666666667)
(19997,8.583333333333334,7.583333333333334)
(19998,9.166666666666666,-2.833333333333334)
(19999,10.333333333333334,2.333333333333334)
(20000,6.416666666666667,3.416666666666667)</code></p>
                <p id="c10-c10-para-0275" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0275">The data is stored as tuples. You can see the parenthesis in the output data. Note, this is just output to the console and hasn't been stored. I cover that in a moment. There's still one requirement left to fix.</p>
                <p id="c10-c10-para-0276" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0276">I'm creating a custom function to calculate the months below the average sales. Pig lets you create user-defined functions (UDF) in Java (and other scripting languages), so the more complex evaluations can be crafted to your requirements.</p>
                <p id="c10-c10-para-0277" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0277">Look at the Java class that will do the work. I'm going to reuse some of the methods in the core and Hadoop jobs that I created earlier to calculate the mean and figure out how many months' sales were below the mean.</p>
                <p xml:space="preserve" id="p_000825"><code class="preserve-whitespace" xml:space="preserve" id="code_000733"><strong id="strong_000722" smilref="Machine_Learning00013.smil#strong_000722">import</strong><span class="text" id="span_002085" smilref="Machine_Learning00013.smil#span_002085"> java.io.IOException;
</span><strong id="strong_000723" smilref="Machine_Learning00013.smil#strong_000723">import</strong><span class="text" id="span_002086" smilref="Machine_Learning00013.smil#span_002086"> org.apache.pig.EvalFunc;
</span><strong id="strong_000724" smilref="Machine_Learning00013.smil#strong_000724">import</strong><span class="text" id="span_002087" smilref="Machine_Learning00013.smil#span_002087"> org.apache.pig.data.Tuple;
</span><strong id="strong_000725" smilref="Machine_Learning00013.smil#strong_000725">public</strong> <strong id="strong_000726" smilref="Machine_Learning00013.smil#strong_000726">class</strong><span class="text" id="span_002088" smilref="Machine_Learning00013.smil#span_002088"> PigCalcMonthsBelow </span><strong id="strong_000727" smilref="Machine_Learning00013.smil#strong_000727">extends</strong><span class="text" id="span_002089" smilref="Machine_Learning00013.smil#span_002089"> EvalFunc&lt;Integer&gt; {
       @Override
       </span><strong id="strong_000728" smilref="Machine_Learning00013.smil#strong_000728">public</strong><span class="text" id="span_002090" smilref="Machine_Learning00013.smil#span_002090"> Integer exec(Tuple tuple) </span><strong id="strong_000729" smilref="Machine_Learning00013.smil#strong_000729">throws</strong><span class="text" id="span_002091" smilref="Machine_Learning00013.smil#span_002091"> IOException {
           </span><strong id="strong_000730" smilref="Machine_Learning00013.smil#strong_000730">int</strong><span class="text" id="span_002092" smilref="Machine_Learning00013.smil#span_002092">[] months = </span><strong id="strong_000731" smilref="Machine_Learning00013.smil#strong_000731">new</strong> <strong id="strong_000732" smilref="Machine_Learning00013.smil#strong_000732">int</strong><span class="text" id="span_002093" smilref="Machine_Learning00013.smil#span_002093">[12];
           </span><strong id="strong_000733" smilref="Machine_Learning00013.smil#strong_000733">for</strong><span class="text" id="span_002094" smilref="Machine_Learning00013.smil#span_002094">(</span><strong id="strong_000734" smilref="Machine_Learning00013.smil#strong_000734">int</strong><span class="text" id="span_002095" smilref="Machine_Learning00013.smil#span_002095"> count = 1; count &lt;= 12; count++) {
           months[count-1] = (Integer)tuple.get(count);
    }
       </span><strong id="strong_000735" smilref="Machine_Learning00013.smil#strong_000735">return</strong><span class="text" id="span_002096" smilref="Machine_Learning00013.smil#span_002096"> monthsBelow(months, getMean(months));
}
</span><strong id="strong_000736" smilref="Machine_Learning00013.smil#strong_000736">private</strong> <strong id="strong_000737" smilref="Machine_Learning00013.smil#strong_000737">int</strong><span class="text" id="span_002097" smilref="Machine_Learning00013.smil#span_002097"> monthsBelow(</span><strong id="strong_000738" smilref="Machine_Learning00013.smil#strong_000738">int</strong><span class="text" id="span_002098" smilref="Machine_Learning00013.smil#span_002098">[] data, </span><strong id="strong_000739" smilref="Machine_Learning00013.smil#strong_000739">double</strong><span class="text" id="span_002099" smilref="Machine_Learning00013.smil#span_002099"> mean) {
       </span><strong id="strong_000740" smilref="Machine_Learning00013.smil#strong_000740">int</strong><span class="text" id="span_002100" smilref="Machine_Learning00013.smil#span_002100"> count = 0;
       </span><strong id="strong_000741" smilref="Machine_Learning00013.smil#strong_000741">for</strong><span class="text" id="span_002101" smilref="Machine_Learning00013.smil#span_002101">(</span><strong id="strong_000742" smilref="Machine_Learning00013.smil#strong_000742">double</strong><span class="text" id="span_002102" smilref="Machine_Learning00013.smil#span_002102"> a: data) {
       </span><strong id="strong_000743" smilref="Machine_Learning00013.smil#strong_000743">if</strong><span class="text" id="span_002103" smilref="Machine_Learning00013.smil#span_002103">((a &lt; (mean * 0.40))) count++;
}
       </span><strong id="strong_000744" smilref="Machine_Learning00013.smil#strong_000744">return</strong><span class="text" id="span_002104" smilref="Machine_Learning00013.smil#span_002104"> count;
}
</span><strong id="strong_000745" smilref="Machine_Learning00013.smil#strong_000745">private</strong> <strong id="strong_000746" smilref="Machine_Learning00013.smil#strong_000746">double</strong><span class="text" id="span_002105" smilref="Machine_Learning00013.smil#span_002105"> getMean(</span><strong id="strong_000747" smilref="Machine_Learning00013.smil#strong_000747">int</strong><span class="text" id="span_002106" smilref="Machine_Learning00013.smil#span_002106">[] data) {
       </span><strong id="strong_000748" smilref="Machine_Learning00013.smil#strong_000748">double</strong><span class="text" id="span_002107" smilref="Machine_Learning00013.smil#span_002107"> sum = 0.0;
       </span><strong id="strong_000749" smilref="Machine_Learning00013.smil#strong_000749">for</strong><span class="text" id="span_002108" smilref="Machine_Learning00013.smil#span_002108">(</span><strong id="strong_000750" smilref="Machine_Learning00013.smil#strong_000750">double</strong><span class="text" id="span_002109" smilref="Machine_Learning00013.smil#span_002109"> a: data) {
       sum += a;
}
       </span><strong id="strong_000751" smilref="Machine_Learning00013.smil#strong_000751">return</strong><span class="text" id="span_002110" smilref="Machine_Learning00013.smil#span_002110"> sum/data.length;
       }
}    </span></code></p>
                <pagenum epub:type="pagebreak" id="p268" page="normal" smilref="Machine_Learning00013.smil#p268">268</pagenum>
                <p id="c10-c10-para-0278" xml:space="preserve"><span class="text" id="span_002111" smilref="Machine_Learning00013.smil#span_002111">It's a basic class, but as you can see there is some Pig-related code in there with the </span><code xml:space="preserve" id="code_000734" smilref="Machine_Learning00013.smil#code_000734">exec</code><span class="text" id="span_002112" smilref="Machine_Learning00013.smil#span_002112"> function, which does the work for you. (This is the method that is used when the Pig script calls the function.)</span></p>
                <p id="c10-c10-para-0279" xml:space="preserve"><span class="text" id="span_002113" smilref="Machine_Learning00013.smil#span_002113">After this class is exported to a </span><code xml:space="preserve" id="code_000735" smilref="Machine_Learning00013.smil#code_000735">jar</code><span class="text" id="span_002114" smilref="Machine_Learning00013.smil#span_002114"> file, then you can use it within your Pig script. The </span><code xml:space="preserve" id="code_000736" smilref="Machine_Learning00013.smil#code_000736">REGISTER</code><span class="text" id="span_002115" smilref="Machine_Learning00013.smil#span_002115"> command loads the </span><code xml:space="preserve" id="code_000737" smilref="Machine_Learning00013.smil#code_000737">jar</code><span class="text" id="span_002116" smilref="Machine_Learning00013.smil#span_002116"> file into Pig for you. To call your custom function, you can use the name of the class including the full package name.</span></p>
                <p xml:space="preserve" id="p_000826"><code class="preserve-whitespace" xml:space="preserve" id="code_000738" smilref="Machine_Learning00013.smil#code_000738">REGISTER salesudp.jar
SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);
AVGDATA =  FOREACH SD GENERATE custid,
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12}),
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12})-m13,
           PigCalcMonthsBelow(*);
DUMP(AVGDATA);</code></p>
                <p id="c10-c10-para-0280" xml:space="preserve"><span class="text" id="span_002117" smilref="Machine_Learning00013.smil#span_002117">In this instance, the whole tuple of your data has been passed into the </span><code xml:space="preserve" id="code_000739" smilref="Machine_Learning00013.smil#code_000739">exec</code><span class="text" id="span_002118" smilref="Machine_Learning00013.smil#span_002118"> function of the Java class. It iterates the month data and creates a </span><code xml:space="preserve" id="code_000740" smilref="Machine_Learning00013.smil#code_000740">double[]</code><span class="text" id="span_002119" smilref="Machine_Learning00013.smil#span_002119"> array </span><pagenum epub:type="pagebreak" id="p269" page="normal" smilref="Machine_Learning00013.smil#p269">269</pagenum><span class="text" id="span_002120" smilref="Machine_Learning00013.smil#span_002120">and also stores the month 13 value. Then it calculates the mean and the months below 40 percent of the average sales and passes that number back to Pig.</span></p>
              </level4>
              <level4 id="level4_000123">
                <h4 xml:space="preserve" id="h4_000123" smilref="Machine_Learning00013.smil#h4_000123">Storing the Output Data</h4>
                <p xml:space="preserve" id="p_000827"><span class="text" id="span_002121" smilref="Machine_Learning00013.smil#span_002121">So far, the only output you've done is to the console. This is far from helpful when other people want to see the data. The </span><code xml:space="preserve" id="code_000741" smilref="Machine_Learning00013.smil#code_000741">STORE</code><span class="text" id="span_002122" smilref="Machine_Learning00013.smil#span_002122"> function writes the output data to a file. It's very similar to the </span><code xml:space="preserve" id="code_000742" smilref="Machine_Learning00013.smil#code_000742">LOAD</code><span class="text" id="span_002123" smilref="Machine_Learning00013.smil#span_002123"> function that you used earlier:</span></p>
                <p xml:space="preserve" id="p_000828"><code class="preserve-whitespace" xml:space="preserve" id="code_000743" smilref="Machine_Learning00013.smil#code_000743">STORE DATA INTO 'myoutputfile' USING PigStorage(',');</code></p>
                <p id="c10-c10-para-0282" xml:space="preserve"><span class="text" id="span_002124" smilref="Machine_Learning00013.smil#span_002124">This command would store the tuple data in </span><code xml:space="preserve" id="code_000744" smilref="Machine_Learning00013.smil#code_000744">DATA</code><span class="text" id="span_002125" smilref="Machine_Learning00013.smil#span_002125"> into a comma-separated text file called </span><code xml:space="preserve" id="code_000745" smilref="Machine_Learning00013.smil#code_000745">myoutputfile</code><span class="text" id="span_002126" smilref="Machine_Learning00013.smil#span_002126">. So, to complete your task. you amend your Pig script accordingly:</span></p>
                <p xml:space="preserve" id="p_000829"><code class="preserve-whitespace" xml:space="preserve" id="code_000746" smilref="Machine_Learning00013.smil#code_000746">REGISTER salesudp.jar
SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);
AVGDATA =  FOREACH SD GENERATE custid,
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12}),
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12})-m13,
           PigCalcMonthsBelow(*);
STORE AVGDATA INTO 'salesoutput' USING PigStorage(',');</code></p>
                <p id="c10-c10-para-0283" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0283">When the job is run this time, you see Pig go through its usual routines and process the script. Instead of dumping the entire output to the console this time, you see the following:</p>
                <p xml:space="preserve" id="p_000830"><code class="preserve-whitespace" xml:space="preserve" id="code_000747" smilref="Machine_Learning00013.smil#code_000747">HadoopVersion    PigVersion    UserId    StartedAt    FinishedAt    Features
1.2.1    0.12.0    Jason    2014-01-26 07:56:12    2014-01-26 07:56:15    UNKNOWN
Success!
Job Stats (time in seconds):
JobId    Alias    Feature    Outputs
job_local1303731742_0001    AVGDATA,SD    MAP_ONLY    file:///Users/Jason/cmepart2/salesoutput,
Input(s):
Successfully read records from: "file:///Users/Jason/cmepart2/salesdata.csv"
Output(s):
Successfully stored records in: "file:///Users/Jason/cmepart2/salesoutput"
Job DAG:
job_local1303731742_0001</code></p>
                <pagenum epub:type="pagebreak" id="p270" page="normal" smilref="Machine_Learning00013.smil#p270">270</pagenum>
                <p id="c10-c10-para-0284" xml:space="preserve"><span class="text" id="span_002127" smilref="Machine_Learning00013.smil#span_002127">This gives the status of the job and, most importantly, the state of the output. In this instance, it's been successful. The output lives in a directory using the name you specified in the </span><code xml:space="preserve" id="code_000748" smilref="Machine_Learning00013.smil#code_000748">STORE</code><span class="text" id="span_002128" smilref="Machine_Learning00013.smil#span_002128"> command. Change into that directory and you see a Hadoop-like output named file </span><code xml:space="preserve" id="code_000749" smilref="Machine_Learning00013.smil#code_000749">part-m-00000</code><span class="text" id="span_002129" smilref="Machine_Learning00013.smil#span_002129"> that contains the output.</span></p>
              </level4>
              <level4 id="level4_000124">
                <h4 xml:space="preserve" id="h4_000124" smilref="Machine_Learning00013.smil#h4_000124">Joining the Customer Details Table</h4>
                <p xml:space="preserve" id="p_000831" smilref="Machine_Learning00013.smil#p_000831">So far, you've been working on one table. The customer ID is hardly the politest way of reporting customer information back to the stakeholders. Under some circumstances you would not want to be sharing personal information with anyone, but I'm using this scenario solely as a way of illustration to join two tables of information together with Pig (for more information on PII please look at Chapter 2).</p>
                <p id="c10-c10-para-0286" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0286">Within Pig, you can join tables of information together very much like a relational database would.</p>
                <p id="c10-c10-para-0287" xml:space="preserve"><span class="text" id="span_002130" smilref="Machine_Learning00013.smil#span_002130">Assume that I have a customer table within the company database or that I could export the customers out of the customer relationship management (CRM) system. The schema is basic; it's just a customer ID, e-mail address, first name, and last name. (I've used </span><code xml:space="preserve" id="code_000750"><a href="http://www.fakenamegenerator.com" external="true" id="a_000309" smilref="Machine_Learning00013.smil#a_000309">www.fakenamegenerator.com</a></code><span class="text" id="span_002131" smilref="Machine_Learning00013.smil#span_002131"> to generate my customer data; none of it is real.)</span></p>
                <p xml:space="preserve" id="p_000832"><code class="preserve-whitespace" xml:space="preserve" id="code_000751" smilref="Machine_Learning00013.smil#code_000751">10,LouieThornton@cuvox.de,Louie,Thornton
11,NicholasWong@dayrep.com,Nicholas,Wong
12,HarrietBrennan@teleworm.us,Harriet,Brennan
13,AimeeHill@armyspy.com,Aimee,Hill
14,LaraBoyle@rhyta.com,Lara,Boyle
15,AmelieHowell@superrito.com,Amelie,Howell
16,GeorgiaAbbott@gustr.com,Georgia,Abbott
17,BradleyShah@einrot.com,Bradley,Shah
18,EvieRoss@teleworm.us,Evie,Ross
19,EllaOSullivan@einrot.com,Ella,O'Sullivan
20,ReeceEvans@cuvox.de,Reece,Evans
21,HenryPalmer@rhyta.com,Henry,Palmer
22,KayleighMoss@teleworm.us,Kayleigh,Moss
23,RobertHobbs@einrot.com,Robert,Hobbs
24,LoganGraham@superrito.com,Logan,Graham</code></p>
                <p id="c10-c10-para-0288" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0288">Within the Pig script, you need to load both sets of data: the customers and the sales data:</p>
                <p xml:space="preserve" id="p_000833"><code class="preserve-whitespace" xml:space="preserve" id="code_000752" smilref="Machine_Learning00013.smil#code_000752">CONSUMER = LOAD 'customer.csv' USING PigStorage(',') AS (custid:int, email:chararray, firstname:chararray, lastname:chararray);
SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);</code></p>
                <pagenum epub:type="pagebreak" id="p271" page="normal" smilref="Machine_Learning00013.smil#p271">271</pagenum>
                <p id="c10-c10-para-0289" xml:space="preserve"><span class="text" id="span_002132" smilref="Machine_Learning00013.smil#span_002132">You can see that the schema for the customer data </span><code xml:space="preserve" id="code_000753" smilref="Machine_Learning00013.smil#code_000753">LOAD</code><span class="text" id="span_002133" smilref="Machine_Learning00013.smil#span_002133"> statement has the data type </span><code xml:space="preserve" id="code_000754" smilref="Machine_Learning00013.smil#code_000754">chararray</code><span class="text" id="span_002134" smilref="Machine_Learning00013.smil#span_002134"> for the e-mail, first name, and last name. The sales data is loaded into a different variable reference, so there are now two data sets defined. They're just not joined together.</span></p>
                <p id="c10-c10-para-0290" xml:space="preserve"><span class="text" id="span_002135" smilref="Machine_Learning00013.smil#span_002135">To join two data sets together in Pig is a simple matter of using the </span><code xml:space="preserve" id="code_000755" smilref="Machine_Learning00013.smil#code_000755">JOIN</code><span class="text" id="span_002136" smilref="Machine_Learning00013.smil#span_002136"> command. It takes two data sets with a common ID (in our case the customer ID) and joins them into a new data set:</span></p>
                <p xml:space="preserve" id="p_000834"><code class="preserve-whitespace" xml:space="preserve" id="code_000756" smilref="Machine_Learning00013.smil#code_000756">FULLDATA = JOIN CONSUMER BY (custid), SD BY (custid);</code></p>
                <p id="c10-c10-para-0291" xml:space="preserve"><span class="text" id="span_002137" smilref="Machine_Learning00013.smil#span_002137">If you dumped out the </span><code xml:space="preserve" id="code_000757" smilref="Machine_Learning00013.smil#code_000757">FULLDATA</code><span class="text" id="span_002138" smilref="Machine_Learning00013.smil#span_002138"> tuple after joining the two data sets, the output would look like the following:</span></p>
                <p xml:space="preserve" id="p_000835"><code class="preserve-whitespace" xml:space="preserve" id="code_000758" smilref="Machine_Learning00013.smil#code_000758">(19994,FreddieWoodward@teleworm.us,Freddie,Woodward,19994,9,4,4,2,11,9,10,4,2,3,13,9,0)
(19995,LillyMahmood@cuvox.de,Lilly,Mahmood,19995,5,2,1,1,14,4,9,12,4,13,6,7,14)
(19996,DavidHudson@cuvox.de,David,Hudson,19996,3,6,6,13,8,1,14,10,5,0,7,9,14)
(19997,AliciaSmart@teleworm.us,Alicia,Smart,19997,4,8,13,3,14,11,4,2,11,12,13,8,1)
(19998,EmmaGrant@teleworm.us,Emma,Grant,19998,8,10,5,8,12,9,7,8,14,8,14,7,12)
(19999,JoshGallagher@superrito.com,Josh,Gallagher,19999,10,13,14,4,10,14,2,9,11,14,9,14,8)
(20000,HenryColeman@armyspy.com,Henry,Coleman,20000,2,4,7,2,9,10,8,13,7,1,5,9,3)</code></p>
              </level4>
              <level4 id="level4_000125">
                <h4 xml:space="preserve" id="h4_000125" smilref="Machine_Learning00013.smil#h4_000125">Piecing It All Together</h4>
                <p xml:space="preserve" id="p_000836" smilref="Machine_Learning00013.smil#p_000836">With all the knowledge you've acquired about Pig and creating custom functions with UDFs, you can now look at completing the original task:</p>
                <p xml:space="preserve" id="p_000837"><code class="preserve-whitespace" xml:space="preserve" id="code_000759" smilref="Machine_Learning00013.smil#code_000759">REGISTER salesudp.jar
SD = LOAD 'salesdata.csv' USING PigStorage(',') AS (custid:int, m1:int, m2:int, m3:int, m4:int, m5:int, m6:int, m7:int, m8:int, m9:int, m10:int, m11:int, m12:int, m13:int);
CONSUMER = LOAD 'customers.csv' USING PigStorage(',') AS (custid:int, email:chararray, firstname:chararray, lastname:chararray);
AVGDATA =  FOREACH SD GENERATE custid,
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12}),
           AVG({m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12})-m13,
           PigCalcMonthsBelow(*);
FULLDATA = JOIN CONSUMER BY (custid), AVGDATA BY (custid);
STORE FULLDATA INTO 'salesoutput' USING PigStorage(',');</code></p>
                <pagenum epub:type="pagebreak" id="p272" page="normal" smilref="Machine_Learning00013.smil#p272">272</pagenum>
                <p id="c10-c10-para-0293" xml:space="preserve"><span class="text" id="span_002139" smilref="Machine_Learning00013.smil#span_002139">First, the custom </span><code xml:space="preserve" id="code_000760" smilref="Machine_Learning00013.smil#code_000760">jar</code><span class="text" id="span_002140" smilref="Machine_Learning00013.smil#span_002140"> file is loaded into Pig; you then load the two data sets into two separate variables (</span><code xml:space="preserve" id="code_000761" smilref="Machine_Learning00013.smil#code_000761">SD</code><span class="text" id="span_002141" smilref="Machine_Learning00013.smil#span_002141"> for the sales data and </span><code xml:space="preserve" id="code_000762" smilref="Machine_Learning00013.smil#code_000762">CONSUMER</code><span class="text" id="span_002142" smilref="Machine_Learning00013.smil#span_002142"> for the customer data). You join the two data sets together using the customer ID as the key, creating a new data set called </span><code xml:space="preserve" id="code_000763" smilref="Machine_Learning00013.smil#code_000763">FULLDATA</code><span class="text" id="span_002143" smilref="Machine_Learning00013.smil#span_002143">, then iterate through the data to do your calculations for the average sales, the sales drop, and the months below the average. Finally, you write the results into a new comma-separated file.</span></p>
                <p id="c10-c10-para-0294" xml:space="preserve"><span class="text" id="span_002144" smilref="Machine_Learning00013.smil#span_002144">Once Pig has run you can inspect the output in the </span><code xml:space="preserve" id="code_000764" smilref="Machine_Learning00013.smil#code_000764">salesoutput</code><span class="text" id="span_002145" smilref="Machine_Learning00013.smil#span_002145"> folder.</span></p>
                <p xml:space="preserve" id="p_000838"><code class="preserve-whitespace" xml:space="preserve" id="code_000765" smilref="Machine_Learning00013.smil#code_000765">1,EloiseBradley@dayrep.com,Eloise,Bradley,1,8.75,3.75,1
2,ChloeJohnston@einrot.com,Chloe,Johnston,2,5.916666666666667,-8.083333333333332,4
3,TomClark@rhyta.com,Tom,Clark,3,7.583333333333333,5.583333333333333,4
4,AliciaArmstrong@armyspy.com,Alicia,Armstrong,4,7.833333333333333,-1.166666666666667,4
5,RobertLong@superrito.com,Robert,Long,5,6.166666666666667,0.16666666666666696,2
6,OliviaOsborne@cuvox.de,Olivia,Osborne,6,5.5,0.5,3
7,EllieChandler@dayrep.com,Ellie,Chandler,7,7.416666666666667,-6.583333333333333,3
8,SophieDean@gustr.com,Sophie,Dean,8,8.833333333333334,-0.16666666666666607,2
9,DeclanBruce@gustr.com,Declan,Bruce,9,7.416666666666667,6.416666666666667,2
10,LouieThornton@cuvox.de,Louie,Thornton,10,5.666666666666667,-3.333333333333333,4</code></p>
                <p id="c10-c10-para-0295" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0295">What this section aimed to do was give you a broad overview of what could be achieved with a set of data-processing tools in a real-world context. Word count examples are all good, but they only scratch the surface of what's possible.</p>
                <p id="c10-c10-para-0296" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0296">I've tried to avoid explaining how the core of each technology works, because some of those subjects require books in themselves. Instead, I offered a hands-on “get-it-working” approach that can be used in your projects quickly. To further your learning on Hadoop, Pig, Mahout, and Sqoop, have a look at the “Further Reading” appendix at the end of this book.</p>
                <p id="c10-c10-para-0297" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0297">You now have a framework for giving recommendations, exporting data from existing data sources, and mining sales data. You can easily modify these tutorials for your own means. Just sit down, plan, and think about what question you're trying to answer. Have a proper talk with stakeholders in the company to find out what benefit the data could bring to them. Sometimes the answers and ideas are surprising.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000089">
            <h2 id="c10-c010_level1_8" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c010_level1_8">Scheduling Batch Jobs</h2>
            <pagenum epub:type="pagebreak" id="p273" page="normal" smilref="Machine_Learning00013.smil#p273">273</pagenum>
            <p xml:space="preserve" id="p_000839"><span class="text" id="span_002146" smilref="Machine_Learning00013.smil#span_002146">Within this chapter you've dealt with batch processing but not with repeating the task over and over again. The obvious choice for scheduling something to run is by using a scheduled task, Launch Daemon job, or </span><code xml:space="preserve" id="code_000766" smilref="Machine_Learning00013.smil#code_000766">cron</code><span class="text" id="span_002147" smilref="Machine_Learning00013.smil#span_002147"> job.</span></p>
            <p id="c10-c10-para-0299" xml:space="preserve"><span class="text" id="span_002148" smilref="Machine_Learning00013.smil#span_002148">To set up a </span><code xml:space="preserve" id="code_000767" smilref="Machine_Learning00013.smil#code_000767">cron</code><span class="text" id="span_002149" smilref="Machine_Learning00013.smil#span_002149"> job on a UNIX system or Mac OS X, you need to amend the </span><code xml:space="preserve" id="code_000768" smilref="Machine_Learning00013.smil#code_000768">crontab</code><span class="text" id="span_002150" smilref="Machine_Learning00013.smil#span_002150"> file. From the command line, run the following command:</span></p>
            <p xml:space="preserve" id="p_000840"><code class="preserve-whitespace" xml:space="preserve" id="code_000769" smilref="Machine_Learning00013.smil#code_000769">crontab –e </code></p>
            <p id="c10-c10-para-0300" xml:space="preserve"><span class="text" id="span_002151" smilref="Machine_Learning00013.smil#span_002151">Depending on the operating system of your machine, if a default text editor hasn't been defined, then you are prompted for one. After the text editor has opened, then you can create your </span><code xml:space="preserve" id="code_000770" smilref="Machine_Learning00013.smil#code_000770">cron</code><span class="text" id="span_002152" smilref="Machine_Learning00013.smil#span_002152"> job.</span></p>
            <p id="c10-c10-para-0301" xml:space="preserve"><span class="text" id="span_002153" smilref="Machine_Learning00013.smil#span_002153">A </span><code xml:space="preserve" id="code_000771" smilref="Machine_Learning00013.smil#code_000771">cron</code><span class="text" id="span_002154" smilref="Machine_Learning00013.smil#span_002154"> job is specified as a time when the job is scheduled to be run and this is represented as white-space-separated fields comprising the minutes, hours, day of month, month, and day of week, followed by the command to run. For example, to run a job every day at 11:30 a.m., the </span><code xml:space="preserve" id="code_000772" smilref="Machine_Learning00013.smil#code_000772">cron</code><span class="text" id="span_002155" smilref="Machine_Learning00013.smil#span_002155"> job syntax would look like the following:</span></p>
            <p xml:space="preserve" id="p_000841"><code class="preserve-whitespace" xml:space="preserve" id="code_000773" smilref="Machine_Learning00013.smil#code_000773">30 11 * * *  echo "It's 11:30am"</code></p>
            <p id="c10-c10-para-0302" xml:space="preserve"><span class="text" id="span_002156" smilref="Machine_Learning00013.smil#span_002156">After the text editor saves the </span><code xml:space="preserve" id="code_000774" smilref="Machine_Learning00013.smil#code_000774">cron</code><span class="text" id="span_002157" smilref="Machine_Learning00013.smil#span_002157"> job line, then </span><code xml:space="preserve" id="code_000775" smilref="Machine_Learning00013.smil#code_000775">crontab</code><span class="text" id="span_002158" smilref="Machine_Learning00013.smil#span_002158"> stores the schedule and runs the process at the desired time.</span></p>
            <p id="c10-c10-para-0303" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0303">To put this in context of your hashtags example, perhaps you want to check every hour what top-trending tags are from Spring XD (remember it's streaming the data into HDFS for you already), so you can write a shell script to run the task:</p>
            <p xml:space="preserve" id="p_000842"><code class="preserve-whitespace" xml:space="preserve" id="code_000776" smilref="Machine_Learning00013.smil#code_000776">#!/usr/bin/env bash
# runhashtag.sh – Hadoop shell script for Spring XD hashtags
hadoop jar hashtagmining.jar HashtagJob /xd/fashiontweets /fashionoutput
hadoop fs -getmerge /fashionoutput fashionoutput.txt
sort –k2nr fashionoutput.txt | head -20 &gt; hourlytrends.txt</code></p>
            <p id="c10-c10-para-0304" xml:space="preserve"><span class="text" id="span_002159" smilref="Machine_Learning00013.smil#span_002159">The following </span><code xml:space="preserve" id="code_000777" smilref="Machine_Learning00013.smil#code_000777">crontab</code><span class="text" id="span_002160" smilref="Machine_Learning00013.smil#span_002160"> entry would run the shell script every hour on the hour and output the top 20 results to a text file:</span></p>
            <p xml:space="preserve" id="p_000843"><code class="preserve-whitespace" xml:space="preserve" id="code_000778" smilref="Machine_Learning00013.smil#code_000778">0 * * * * svc –o /path/to/script/runhashtag.sh </code></p>
            <p id="c10-c10-para-0305" xml:space="preserve"><span class="text" id="span_002161" smilref="Machine_Learning00013.smil#span_002161">If you want to learn more about </span><code xml:space="preserve" id="code_000779" smilref="Machine_Learning00013.smil#code_000779">crontab</code><span class="text" id="span_002162" smilref="Machine_Learning00013.smil#span_002162">, you can either read the manual pages on your UNIX distribution (type </span><strong id="strong_000752" smilref="Machine_Learning00013.smil#strong_000752">man cron</strong><span class="text" id="span_002163" smilref="Machine_Learning00013.smil#span_002163"> at the command line) or consult the Wikipedia page on </span><code xml:space="preserve" id="code_000780" smilref="Machine_Learning00013.smil#code_000780">cron</code><span class="text" id="span_002164" smilref="Machine_Learning00013.smil#span_002164"> at </span><code xml:space="preserve" id="code_000781"><a href="http://en.wikipedia.org/wiki/Cron" external="true" id="a_000310" smilref="Machine_Learning00013.smil#a_000310">http://en.wikipedia.org/wiki/Cron</a></code><span class="text" id="span_002165" smilref="Machine_Learning00013.smil#span_002165">.</span></p>
            <p id="c10-c10-para-0306" xml:space="preserve"><span class="text" id="span_002166" smilref="Machine_Learning00013.smil#span_002166">Although this is a simple approach, you must be careful. If the volumes of data become great, you might reach a stage where the processing is taking longer to produce results than the time difference you leave in between the </span><code xml:space="preserve" id="code_000782" smilref="Machine_Learning00013.smil#code_000782">cron</code><span class="text" id="span_002167" smilref="Machine_Learning00013.smil#span_002167"> job.</span></p>
            <p id="c10-c10-para-0307" xml:space="preserve"><span class="text" id="span_002168" smilref="Machine_Learning00013.smil#span_002168">It's worth adding mutual exclusion to your job and having it exit if an earlier incarnation of itself is running, skipping those hours where earlier jobs have </span><pagenum epub:type="pagebreak" id="p274" page="normal" smilref="Machine_Learning00013.smil#p274">274</pagenum><span class="text" id="span_002169" smilref="Machine_Learning00013.smil#span_002169">taken too long to complete. It might also be worth having the job “give up” and exit before it completes, if it takes much too long (perhaps 3 hours).</span></p>
          </level2>
          <level2 id="level2_000090">
            <h2 id="c10-c010_level1_9" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c010_level1_9">Summary</h2>
            <p xml:space="preserve" id="p_000844" smilref="Machine_Learning00013.smil#p_000844">Hadoop is an important technology, and it's worth putting some time aside to craft some MapReduce programs that might be of use in your organization. You also have to think about the openly available data that's available to you. Weather data is a gold mine if you are in the retail business, and with a carefully crafted algorithm you could consume the weather data and compare it with sales data. Do sales increase in certain weather conditions? If the weather can be predicted five days out, then can you do the same with the potential sales?</p>
            <p id="c10-c10-para-0309" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0309">If crafting MapReduce seems like a lot of work, then think about using Pig instead. It might be just as quick to solve simple problems against large sets of data. Remember that Pig is designed to work with data flow, so when complexity creeps in, it might be worth looking at a coded solution.</p>
            <p id="c10-c10-para-0310" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0310">Machine learning sometimes isn't so much about designing heavy-duty algorithms as it is a case of finding the right tools to do the simple job.</p>
            <p id="c10-c10-para-0311" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0311">With a small amount of exposure to Hadoop, Sqoop, Mahout, and Pig, there's a broad set of tools for extracting, processing, and learning from existing and newly acquired data. Coupling this with the different types of machine learning outlined in the chapters of this book will give you a good grounding in what's possible.</p>
            <p id="c10-c10-para-0312" xml:space="preserve" smilref="Machine_Learning00013.smil#c10-c10-para-0312">I used Hadoop version 1 because it gives a good grounding on how MapReduce jobs are put together. In a real-world context you would be using Hadoop version 2 because it performs better and also has the added feature of YARN (Yet Another Resource Negotiator) for job deployment. It's also worth noting that in memory systems like Spark are gaining in popularity; read on to Chapter 11 for more information about Spark.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c11">
        <section epub:type="chapter" id="section_000012">
          <header id="header_000011">
            <h1 id="c11-c11" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c11">Chapter 11 Apache Spark</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p275" page="normal" smilref="Machine_Learning00013.smil#p275">275</pagenum>
          <p xml:space="preserve" id="p_000845" smilref="Machine_Learning00013.smil#p_000845">The Apache Spark project was created by the AMPLab at UC Berkeley as a data analytics cluster computing framework. This chapter is a quick overview of the Scala language and its use within the Spark framework. The chapter also looks at the external libraries for machine learning, SQL-like queries, and streaming data with Spark.</p>
          <level2 id="level2_000091">
            <h2 id="c11-c011_level1_1" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c011_level1_1">Spark: A Hadoop Replacement?</h2>
            <p xml:space="preserve" id="p_000846" smilref="Machine_Learning00013.smil#p_000846">The debate about whether Spark is a Hadoop replacement might rage on longer than some would like. One of the problems with Hadoop is the same thing that made it famous: MapReduce. The programming model can take time to master for certain tasks. If it's a case of straight totaling up frequencies of data, then MapReduce is fine, but after you get past that point, you're left with some hard decisions to make.</p>
            <p id="c11-c11-para-0003" xml:space="preserve"><span class="text" id="span_002170" smilref="Machine_Learning00013.smil#span_002170">Hadoop2 gets beyond the issue of using Hadoop only for MapReduce. With the introduction of YARN (Yet Another Resource Negotiator) Hadoop acts as an operating system for data with YARN controlling resources against the cluster. These resources weren't limited to MapReduce jobs; they could be any job that could be executed. An excellent example of this was the deployment of JBoss application server containers in the book </span><em id="em_000353" smilref="Machine_Learning00013.smil#em_000353">Apache Hadoop YARN</em><span class="text" id="span_002171" smilref="Machine_Learning00013.smil#span_002171"> by Arun </span><pagenum epub:type="pagebreak" id="p276" page="normal" smilref="Machine_Learning00013.smil#p276">276</pagenum><span class="text" id="span_002172" smilref="Machine_Learning00013.smil#span_002172">C. Murthy and Vinod Kumar Vavilapalli (Addison-Wesley Professional, 2014; see the “Further Reading” section at the end of this book for more details).</span></p>
            <p id="c11-c11-para-0004" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c11-para-0004">The Spark project doesn't rely on MapReduce, which gives it a speed advantage. The claim is that it's 100 times faster than in-memory Hadoop and 10 times faster on disk. If speed is an issue for you, then Spark is certainly up there on the list of things to look at. As for the argument that it's a replacement for Hadoop. well, I'll leave that for the technical press to suss out. It all boils down to the fundamental element of what question you are trying to answer. The tools are just that—tools.</p>
          </level2>
          <level2 id="level2_000092">
            <h2 id="c11-c011_level1_2" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c011_level1_2">Java, Scala, or Python?</h2>
            <p xml:space="preserve" id="p_000847" smilref="Machine_Learning00013.smil#p_000847">Spark jobs can be written in Java, Scala, or Python. As usual, which language you use tends to be a matter of personal preference. Because it is written in the JVM language Scala, the primary language for Spark is Scala and, with the inclusion of a command-line tool, this makes life easier when you want to get answers more quickly.</p>
            <p id="c11-c11-para-0006" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c11-para-0006">The application programming interface (API) is available to Java developers, but there's more work required in getting programs ready. The Python language is also supported, and it, like Scala, comes with a command-line interpreter for Spark jobs.</p>
            <p id="c11-c11-para-0007" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c11-para-0007">The bottom line is, if you want to work on the command line, then you should use Scala or Python. If the thought of Scala scares you, read on and I'll attempt to help make you feel better. On the other hand, if you want to skip this part, then you can proceed to the “Downloading and Installing Spark” section.</p>
            <p id="c11-c11-para-0008" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c11-para-0008">As you progress through this chapter, you might come to the conclusion that Java is too bulky for quickly writing Spark jobs. Remember, it's a matter of personal preference, so you should use the language in which you're most comfortable.</p>
          </level2>
          <level2 id="level2_000093">
            <h2 id="c11-c011_level1_3" xml:space="preserve" smilref="Machine_Learning00013.smil#c11-c011_level1_3">Scala Crash Course</h2>
            <p xml:space="preserve" id="p_000848" smilref="Machine_Learning00013.smil#p_000848">If you are a Java programmer and you want to move to Scala, this section covers the essentials in a few digestible pages.</p>
            <p id="c11-c11-para-0010" xml:space="preserve"><span class="text" id="span_002173" smilref="Machine_Learning00013.smil#span_002173">For a more detailed look at the Scala language, try the site documentation at </span><code xml:space="preserve" id="code_000783"><a href="http://www.scala-lang.org/documentation" external="true" id="a_000311" smilref="Machine_Learning00013.smil#a_000311">www.scala-lang.org/documentation</a></code><span class="text" id="span_002174" smilref="Machine_Learning00013.smil#span_002174">.</span></p>
            <level3 id="level3_000181">
              <h3 xml:space="preserve" id="h3_000181" smilref="Machine_Learning00013.smil#h3_000181">Installing Scala</h3>
              <p xml:space="preserve" id="p_000849"><span class="text" id="span_002175" smilref="Machine_Learning00013.smil#span_002175">Scala is classed as a Java Virtual Machine (JVM) language, because it uses the JVM to execute its bytecodes. There is a download that you need to perform </span><pagenum epub:type="pagebreak" id="p277" page="normal" smilref="Machine_Learning00013.smil#p277">277</pagenum><span class="text" id="span_002176" smilref="Machine_Learning00013.smil#span_002176">before you get into the basics. If you are happy to use Spark on its own, then you don't need to download Scala, because the libraries are in the distribution. On the other hand, if you want to write some Scala programs to run on Spark afterward then it's prudent to download the Scala distribution file and install it. You can find the downloads at </span><code xml:space="preserve" id="code_000784"><a href="http://www.scala-lang.org/download/all.html" external="true" id="a_000312" smilref="Machine_Learning00013.smil#a_000312">www.scala-lang.org/download/all.html</a></code><span class="text" id="span_002177" smilref="Machine_Learning00013.smil#span_002177">.</span></p>
              <p id="c11-c11-para-0012" xml:space="preserve"><span class="text" id="span_002178" smilref="Machine_Learning00013.smil#span_002178">Pick a fairly recent version for your operating system (nothing too cutting edge) and download it. After it has downloaded, find a place for it to live and then uncompress the archive (usually a </span><code xml:space="preserve" id="code_000785" smilref="Machine_Learning00013.smil#code_000785">.tgz</code><span class="text" id="span_002179" smilref="Machine_Learning00013.smil#span_002179"> file for Mac OS X/Linux or a Zip file for Windows users).</span></p>
              <p id="c11-c11-para-0013" xml:space="preserve"><span class="text" id="span_002180" smilref="Machine_Learning00013.smil#span_002180">Ensure that the path to the </span><code xml:space="preserve" id="code_000786" smilref="Machine_Learning00013.smil#code_000786">bin</code><span class="text" id="span_002181" smilref="Machine_Learning00013.smil#span_002181"> directory is set, so you can access the programs from your command line. When you have all that done, you can proceed.</span></p>
            </level3>
            <level3 id="level3_000182">
              <h3 xml:space="preserve" id="h3_000182" smilref="Machine_Learning00013.smil#h3_000182">Packages</h3>
              <p xml:space="preserve" id="p_000850"><span class="text" id="span_002182" smilref="Machine_Learning00014.smil#span_002182">Package imports behave in the same way as Java imports, but instead of using the </span><code xml:space="preserve" id="code_000787" smilref="Machine_Learning00014.smil#code_000787">*</code><span class="text" id="span_002183" smilref="Machine_Learning00014.smil#span_002183"> as you do in Java, you use </span><code xml:space="preserve" id="code_000788" smilref="Machine_Learning00014.smil#code_000788">_</code><span class="text" id="span_002184" smilref="Machine_Learning00014.smil#span_002184"> in Scala.</span></p>
              <p xml:space="preserve" id="p_000851"><code class="preserve-whitespace" xml:space="preserve" id="code_000789" smilref="Machine_Learning00014.smil#code_000789">import java.util._
import org.my.thing._</code></p>
              <p id="c11-c11-para-0015" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0015">Scala is based on the JVM, so you can import and use Java libraries and third-party libraries.</p>
            </level3>
            <level3 id="level3_000183">
              <h3 xml:space="preserve" id="h3_000183" smilref="Machine_Learning00014.smil#h3_000183">Data Types</h3>
              <p xml:space="preserve" id="p_000852" smilref="Machine_Learning00014.smil#p_000852">Scala supports the following seven numeric data types. They are classes. Scala doesn't support primitive data types like Java does.</p>
              <list type="ul" id="list_000064">
                <li id="li_000436" smilref="Machine_Learning00014.smil#li_000436">Byte</li>
                <li id="li_000437" smilref="Machine_Learning00014.smil#li_000437">Char</li>
                <li id="li_000438" smilref="Machine_Learning00014.smil#li_000438">Short</li>
                <li id="li_000439" smilref="Machine_Learning00014.smil#li_000439">Int</li>
                <li id="li_000440" smilref="Machine_Learning00014.smil#li_000440">Long</li>
                <li id="li_000441" smilref="Machine_Learning00014.smil#li_000441">Float</li>
                <li id="li_000442" smilref="Machine_Learning00014.smil#li_000442">Double</li>
                <li id="li_000443" smilref="Machine_Learning00014.smil#li_000443">Boolean</li>
              </list>
              <p id="c11-c11-para-0017" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0017">Because they are all classes, you can use the class methods to manipulate them in the same way as Java:</p>
              <p xml:space="preserve" id="p_000853"><code class="preserve-whitespace" xml:space="preserve" id="code_000790" smilref="Machine_Learning00014.smil#code_000790">scala&gt; 1000.toString
res10: String = 1000
scala&gt; 1000.toDouble
res11: Double = 1000.0
scala&gt; 1000.toInt
res13: Int = 1000</code></p>
              <pagenum epub:type="pagebreak" id="p278" page="normal" smilref="Machine_Learning00014.smil#p278">278</pagenum>
              <p id="c11-c11-para-0018" xml:space="preserve"><span class="text" id="span_002185" smilref="Machine_Learning00014.smil#span_002185">Declarations of constants and variables are defined as </span><code xml:space="preserve" id="code_000791" smilref="Machine_Learning00014.smil#code_000791">val</code><span class="text" id="span_002186" smilref="Machine_Learning00014.smil#span_002186"> or </span><code xml:space="preserve" id="code_000792" smilref="Machine_Learning00014.smil#code_000792">var</code><span class="text" id="span_002187" smilref="Machine_Learning00014.smil#span_002187">; it's not a big deal which one you use.</span></p>
            </level3>
            <level3 id="level3_000184">
              <h3 xml:space="preserve" id="h3_000184" smilref="Machine_Learning00014.smil#h3_000184">Classes</h3>
              <p xml:space="preserve" id="p_000854" smilref="Machine_Learning00014.smil#p_000854">Scala source files can contain as many classes as you want in the same way as Java:</p>
              <p xml:space="preserve" id="p_000855"><code class="preserve-whitespace" xml:space="preserve" id="code_000793" smilref="Machine_Learning00014.smil#code_000793">class MyClass {
    var myval = 0
}</code></p>
              <p id="c11-c11-para-0020" xml:space="preserve"><span class="text" id="span_002188" smilref="Machine_Learning00014.smil#span_002188">Like Plain Old Java Objects (POJOs), where you create a public variable name and then create two getter and setter methods, Scala is doing the same. The variable (</span><code xml:space="preserve" id="code_000794" smilref="Machine_Learning00014.smil#code_000794">myval</code><span class="text" id="span_002189" smilref="Machine_Learning00014.smil#span_002189"> in the example) is accessed like so:</span></p>
              <p xml:space="preserve" id="p_000856"><code class="preserve-whitespace" xml:space="preserve" id="code_000795" smilref="Machine_Learning00014.smil#code_000795">val newclass = new Myclass
newclass.myval = 42
println(newclass.myval)</code></p>
              <p id="c11-c11-para-0021" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0021">The primary constructor in Scala classes is public. All variables have to be initialized within Scala code; it's not an optional thing.</p>
              <p id="c11-c11-para-0022" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0022">Within classes you can define methods in the same way as you can in Java. So, a basic void method would look like the following:</p>
              <p xml:space="preserve" id="p_000857"><code class="preserve-whitespace" xml:space="preserve" id="code_000796" smilref="Machine_Learning00014.smil#code_000796">def myMethod() {
}</code></p>
              <p id="c11-c11-para-0023" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0023">You can also add return types as you do in Java. So, assuming you want to return an integer data type from your method, you'd type:</p>
              <p xml:space="preserve" id="p_000858"><code class="preserve-whitespace" xml:space="preserve" id="code_000797" smilref="Machine_Learning00014.smil#code_000797">def myMethod(): Int = {
    Return 42
}</code></p>
              <p id="c11-c11-para-0024" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0024">The final example shows how you pass values into the function. Add two numbers together and return the answer, like so:</p>
              <p xml:space="preserve" id="p_000859"><code class="preserve-whitespace" xml:space="preserve" id="code_000798" smilref="Machine_Learning00014.smil#code_000798">def addNums(a: Int, b: Int) : Int = {
return a + b
}</code></p>
            </level3>
            <level3 id="level3_000185">
              <h3 xml:space="preserve" id="h3_000185" smilref="Machine_Learning00014.smil#h3_000185">Calling Functions</h3>
              <p xml:space="preserve" id="p_000860"><span class="text" id="span_002190" smilref="Machine_Learning00014.smil#span_002190">Function calls in Scala are very much the same as in Java. Using the dot notation against the object you can call the method name. If no values are to be passed (like </span><code xml:space="preserve" id="code_000799" smilref="Machine_Learning00014.smil#code_000799">.addNumber(1,2)</code><span class="text" id="span_002191" smilref="Machine_Learning00014.smil#span_002191">, for example), then the parentheses are optional. Unlike Java, though, there are no static methods in Scala.</span></p>
            </level3>
            <level3 id="level3_000186">
              <h3 xml:space="preserve" id="h3_000186" smilref="Machine_Learning00014.smil#h3_000186">Operators</h3>
              <pagenum epub:type="pagebreak" id="p279" page="normal" smilref="Machine_Learning00014.smil#p279">279</pagenum>
              <p xml:space="preserve" id="p_000861" smilref="Machine_Learning00014.smil#p_000861">The operators in Scala operate in the same way as the majority of the Java operators.</p>
            </level3>
            <level3 id="level3_000187">
              <h3 xml:space="preserve" id="h3_000187" smilref="Machine_Learning00014.smil#h3_000187">Control Structures</h3>
              <p xml:space="preserve" id="p_000862"><span class="text" id="span_002192" smilref="Machine_Learning00014.smil#span_002192">Scala supports the usual mix of </span><code xml:space="preserve" id="code_000800" smilref="Machine_Learning00014.smil#code_000800">if</code><span class="text" id="span_002193" smilref="Machine_Learning00014.smil#span_002193">, </span><code xml:space="preserve" id="code_000801" smilref="Machine_Learning00014.smil#code_000801">while</code><span class="text" id="span_002194" smilref="Machine_Learning00014.smil#span_002194">, and </span><code xml:space="preserve" id="code_000802" smilref="Machine_Learning00014.smil#code_000802">for</code><span class="text" id="span_002195" smilref="Machine_Learning00014.smil#span_002195"> control structures.</span></p>
              <level4 id="level4_000126">
                <h4 xml:space="preserve" id="h4_000126" smilref="Machine_Learning00014.smil#h4_000126">for Loops</h4>
                <p xml:space="preserve" id="p_000863"><code xml:space="preserve" id="code_000803" smilref="Machine_Learning00014.smil#code_000803">for</code><span class="text" id="span_002196" smilref="Machine_Learning00014.smil#span_002196">loops can work on any collection. For example:</span></p>
                <p xml:space="preserve" id="p_000864"><code class="preserve-whitespace" xml:space="preserve" id="code_000804" smilref="Machine_Learning00014.smil#code_000804">val filesInDir = (new java.io.File("/home/user/").listFiles
for(thisFile &lt;- filesInDir)
    println(thisFile)</code></p>
                <p id="c11-c11-para-0029" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0029">You also have ranges at your disposal, which is simpler than the Java equivalent:</p>
                <p xml:space="preserve" id="p_000865"><code class="preserve-whitespace" xml:space="preserve" id="code_000805" smilref="Machine_Learning00014.smil#code_000805">for(i &lt;- 1 until 10)
    println(i)
for(i &lt;- 1 to 10)
    println(i)</code></p>
                <p id="c11-c11-para-0030" xml:space="preserve"><span class="text" id="span_002197" smilref="Machine_Learning00014.smil#span_002197">You can also filter within the </span><code xml:space="preserve" id="code_000806" smilref="Machine_Learning00014.smil#code_000806">for</code><span class="text" id="span_002198" smilref="Machine_Learning00014.smil#span_002198"> loop. The following is an example with the output from my home directory. (I've made the actual commands bold.)</span></p>
                <p xml:space="preserve" id="p_000866"><code class="preserve-whitespace" xml:space="preserve" id="code_000807"><span class="text" id="span_002199" smilref="Machine_Learning00014.smil#span_002199">scala&gt; </span><strong id="strong_000753" smilref="Machine_Learning00014.smil#strong_000753">val fileshere = (new java.io.File("/home/jason/").listFiles)</strong><span class="text" id="span_002200" smilref="Machine_Learning00014.smil#span_002200">
fileshere: Array[java.io.File] = Array(/home/jason/twitterstream.jar, /home/jason/.ssh, /home/jason/.profile, /home/jason/spring-shell.log, /home/jason/testyarn.jar, /home/jason/twitterstreamtransformer.xml, /home/jason/.bashrc, /home/jason/worldbrain.txt, /home/jason/.bash_logout, /home/jason/.spark_history, /home/jason/.bash_history)
scala&gt; </span><strong id="strong_000754" smilref="Machine_Learning00014.smil#strong_000754">for(file &lt;- fileshere if file.getName.endsWith(".xml")) print(file)</strong><span class="text" id="span_002201" smilref="Machine_Learning00014.smil#span_002201">
/home/jason/twitterstreamtransformer.xml</span></code></p>
              </level4>
              <level4 id="level4_000127">
                <h4 xml:space="preserve" id="h4_000127" smilref="Machine_Learning00014.smil#h4_000127">while Loops</h4>
                <p xml:space="preserve" id="p_000867"><code xml:space="preserve" id="code_000808" smilref="Machine_Learning00014.smil#code_000808">while</code><span class="text" id="span_002202" smilref="Machine_Learning00014.smil#span_002202">loops operate in the same way as Java </span><code xml:space="preserve" id="code_000809" smilref="Machine_Learning00014.smil#code_000809">while</code><span class="text" id="span_002203" smilref="Machine_Learning00014.smil#span_002203"> loops:</span></p>
                <p xml:space="preserve" id="p_000868"><code class="preserve-whitespace" xml:space="preserve" id="code_000810" smilref="Machine_Learning00014.smil#code_000810">while(value != 100) {
    value += 1
}</code></p>
              </level4>
              <level4 id="level4_000128">
                <h4 xml:space="preserve" id="h4_000128" smilref="Machine_Learning00014.smil#h4_000128">if Statements</h4>
                <pagenum epub:type="pagebreak" id="p280" page="normal" smilref="Machine_Learning00014.smil#p280">280</pagenum>
                <p xml:space="preserve" id="p_000869"><span class="text" id="span_002204" smilref="Machine_Learning00014.smil#span_002204">As you'd expect, </span><code xml:space="preserve" id="code_000811" smilref="Machine_Learning00014.smil#code_000811">if</code><span class="text" id="span_002205" smilref="Machine_Learning00014.smil#span_002205"> statements in Scala are similar to Java </span><code xml:space="preserve" id="code_000812" smilref="Machine_Learning00014.smil#code_000812">if</code><span class="text" id="span_002206" smilref="Machine_Learning00014.smil#span_002206"> statements. Scala supports ternary operators as Java does.</span></p>
                <p xml:space="preserve" id="p_000870"><code class="preserve-whitespace" xml:space="preserve" id="code_000813" smilref="Machine_Learning00014.smil#code_000813">Java:
boolean debug = server.equals("localhost") ? true : false;
Scala:
var debug = if (server.equals("localhost")) true else false;</code></p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000094">
            <h2 id="c11-c011_level1_4" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_4">Downloading and Installing Spark</h2>
            <p xml:space="preserve" id="p_000871" smilref="Machine_Learning00014.smil#p_000871">There are a few ways to download and use Spark. The easiest way is to use the prebuilt packages that are available from the Spark website. Before you download one, check which version of Hadoop you (or your organization) is running as it will determine the download you want. At the time of writing, Spark was available for</p>
            <list type="ul" id="list_000065">
              <li id="li_000444" smilref="Machine_Learning00014.smil#li_000444">Hadoop 1—(Hortonworks HDP1 and Cloudera CDH3)</li>
              <li id="li_000445" smilref="Machine_Learning00014.smil#li_000445">Hadoop 2—(Hortonworks HDP2 and Cloudera CDH5)</li>
              <li id="li_000446" smilref="Machine_Learning00014.smil#li_000446">Cloudera CDH4</li>
            </list>
            <p id="c11-c11-para-0034" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0034">You are not required to exclusively run Hortonworks or Cloudera. Spark works fine on a download of Hadoop 1 or 2 from the Apache site.</p>
            <p id="c11-c11-para-0035" xml:space="preserve"><span class="text" id="span_002207" smilref="Machine_Learning00014.smil#span_002207">After you have downloaded the file for your Hadoop version, you can install it by moving the downloaded file to the directory you want to install it to. The file is a </span><code xml:space="preserve" id="code_000814" smilref="Machine_Learning00014.smil#code_000814">.tgz</code><span class="text" id="span_002208" smilref="Machine_Learning00014.smil#span_002208"> file, so you can unarchive it in one command:</span></p>
            <p xml:space="preserve" id="p_000872"><code class="preserve-whitespace" xml:space="preserve" id="code_000815" smilref="Machine_Learning00014.smil#code_000815">tar xvzf spark-1.0.0-bin-hadoop2.tgz</code></p>
            <p id="c11-c11-para-0036" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0036">The contents of the file will unarchive and be ready for use.</p>
          </level2>
          <level2 id="level2_000095">
            <h2 id="c11-c011_level1_5" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_5">A Quick Intro to Spark</h2>
            <p xml:space="preserve" id="p_000873" smilref="Machine_Learning00014.smil#p_000873">The interactive shell in Scala gives you a quick and easy way to see what Spark can do in a very short span of time. If you read the really short introduction to Scala earlier in the chapter, then you should cope well with the following examples.</p>
            <level3 id="level3_000188">
              <h3 xml:space="preserve" id="h3_000188" smilref="Machine_Learning00014.smil#h3_000188">Starting the Shell</h3>
              <pagenum epub:type="pagebreak" id="p281" page="normal" smilref="Machine_Learning00014.smil#p281">281</pagenum>
              <p xml:space="preserve" id="p_000874" smilref="Machine_Learning00014.smil#p_000874">From the directory where you installed Spark, type the following command to launch the shell:</p>
              <p xml:space="preserve" id="p_000875"><code class="preserve-whitespace" xml:space="preserve" id="code_000816" smilref="Machine_Learning00014.smil#code_000816">./bin/spark-shell</code></p>
              <p id="c11-c11-para-0039" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0039">You see the following output while Spark boots up:</p>
              <p xml:space="preserve" id="p_000876"><code class="preserve-whitespace" xml:space="preserve" id="code_000817" smilref="Machine_Learning00014.smil#code_000817">jason@cloudatics:/usr/local/spark$ bin/spark-shell
Spark assembly has been built with Hive, including Datanucleus jars on classpath
14/07/05 09:28:44 INFO SecurityManager: Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/07/05 09:28:44 INFO SecurityManager: Changing view acls to: jason
14/07/05 09:28:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jason)
14/07/05 09:28:44 INFO HttpServer: Starting HTTP Server
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.0.0
      /_/
Using Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.6.0_31)
Type in expressions to have them evaluated.
Type :help for more information.
14/07/05 09:28:51 INFO SecurityManager: Changing view acls to: jason
14/07/05 09:28:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jason)
14/07/05 09:28:52 INFO Slf4jLogger: Slf4jLogger started
14/07/05 09:28:52 INFO Remoting: Starting remoting
14/07/05 09:28:52 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@cloudatics.com:38921]
14/07/05 09:28:52 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@cloudatics.com:38921]
14/07/05 09:28:52 INFO SparkEnv: Registering MapOutputTracker
14/07/05 09:28:52 INFO SparkEnv: Registering BlockManagerMaster
14/07/05 09:28:52 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140705092852-2f00
14/07/05 09:28:52 INFO MemoryStore: MemoryStore started with capacity 297.0 MB.
14/07/05 09:28:53 INFO ConnectionManager: Bound socket to port 48513 with id = ConnectionManagerId(cloudatics.com,48513)
14/07/05 09:28:53 INFO BlockManagerMaster: Trying to register BlockManager
14/07/05 09:28:53 INFO BlockManagerInfo: Registering block manager cloudatics.com:48513 with 297.0 MB RAM
14/07/05 09:28:53 INFO BlockManagerMaster: Registered BlockManager
14/07/05 09:28:53 INFO HttpServer: Starting HTTP Server
14/07/05 09:28:53 INFO HttpBroadcast: Broadcast server started at http://176.67.170.176:41692
14/07/05 09:28:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-c6a5efed-113d-4dd9-9cd0-7618d901f389
14/07/05 09:28:53 INFO HttpServer: Starting HTTP Server
14/07/05 09:28:53 INFO SparkUI: Started SparkUI at http://cloudatics.com:4040
14/07/05 09:28:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable
14/07/05 09:28:54 INFO Executor: Using REPL class URI: http://176.67.170.176:39192
14/07/05 09:28:54 INFO SparkILoop: Created spark context..
Spark context available as sc.
scala&gt;</code></p>
              <pagenum epub:type="pagebreak" id="p282" page="normal" smilref="Machine_Learning00014.smil#p282">282</pagenum>
              <p id="c11-c11-para-0040" xml:space="preserve"><span class="text" id="span_002209" smilref="Machine_Learning00014.smil#span_002209">I'm showing all the messages, because there are a few interesting things I want to show you in a moment. For now, though, you should see the </span><code xml:space="preserve" id="code_000818" smilref="Machine_Learning00014.smil#code_000818">scala&gt;</code><span class="text" id="span_002210" smilref="Machine_Learning00014.smil#span_002210"> prompt at the bottom, which means you're ready.</span></p>
            </level3>
            <level3 id="level3_000189">
              <h3 xml:space="preserve" id="h3_000189" smilref="Machine_Learning00014.smil#h3_000189">Data Sources</h3>
              <p xml:space="preserve" id="p_000877"><span class="text" id="span_002211" smilref="Machine_Learning00014.smil#span_002211">Spark supports the same input file systems as Hadoop. If your data store is supported by the </span><code xml:space="preserve" id="code_000819" smilref="Machine_Learning00014.smil#code_000819">InputFormat</code><span class="text" id="span_002212" smilref="Machine_Learning00014.smil#span_002212"> method in Hadoop, then you can read it into Spark without too much effort.</span></p>
              <p id="c11-c11-para-0042" xml:space="preserve"><span class="text" id="span_002213" smilref="Machine_Learning00014.smil#span_002213">The obvious ones that come to mind are the local filesystem, Amazon S3 buckets, HBase, Cassandra, and files already on a Hadoop Distributed File System (HDFS). As you see in the next section, you're using the </span><code xml:space="preserve" id="code_000820" smilref="Machine_Learning00014.smil#code_000820">sc.textFile</code><span class="text" id="span_002214" smilref="Machine_Learning00014.smil#span_002214"> method to load in data. This isn't limited to specific files; you can use that method to process wildcards on files, zipped files, and directories as well.</span></p>
            </level3>
            <level3 id="level3_000190">
              <h3 xml:space="preserve" id="h3_000190" smilref="Machine_Learning00014.smil#h3_000190">Testing Spark</h3>
              <p xml:space="preserve" id="p_000878" smilref="Machine_Learning00014.smil#p_000878">Find a text file with which to test Spark and follow along with the rest of this section. I'm using a file from the local filesystem for this example.</p>
              <level4 id="level4_000129">
                <h4 xml:space="preserve" id="h4_000129" smilref="Machine_Learning00014.smil#h4_000129">Load the Text File</h4>
                <p xml:space="preserve" id="p_000879" smilref="Machine_Learning00014.smil#p_000879">First, load the text file. From the Scala command line, type</p>
                <p xml:space="preserve" id="p_000880"><code class="preserve-whitespace" xml:space="preserve" id="code_000821" smilref="Machine_Learning00014.smil#code_000821">scala&gt; var textF = sc.textFile("/home/jason/worldbrain.txt")</code></p>
                <pagenum epub:type="pagebreak" id="p283" page="normal" smilref="Machine_Learning00014.smil#p283">283</pagenum>
                <p id="c11-c11-para-0045" xml:space="preserve"><span class="text" id="span_002215" smilref="Machine_Learning00014.smil#span_002215">Basically you're storing the contents of the text file into a Scala variable called </span><code xml:space="preserve" id="code_000822" smilref="Machine_Learning00014.smil#code_000822">textF</code><span class="text" id="span_002216" smilref="Machine_Learning00014.smil#span_002216">. Spark responds with output along the lines of the following:</span></p>
                <p xml:space="preserve" id="p_000881"><code class="preserve-whitespace" xml:space="preserve" id="code_000823" smilref="Machine_Learning00014.smil#code_000823">14/07/05 09:40:08 INFO MemoryStore: ensureFreeSpace(146579) called with curMem=0, maxMem=311387750
14/07/05 09:40:08 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 143.1 KB, free 296.8 MB)
textF: org.apache.spark.rdd.RDD[String] = MappedRDD[1] at textFile at &lt;console&gt;:12
scala&gt;</code></p>
                <p id="c11-c11-para-0046" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0046">Spark uses a concept called Resilient Distributed Datasets (RDDs), so in the output you can see that you now have a MappedRDD containing strings. With the text file loaded, you can start to inspect it and get some results.</p>
              </level4>
              <level4 id="level4_000130">
                <h4 xml:space="preserve" id="h4_000130" smilref="Machine_Learning00014.smil#h4_000130">Make Some Quick Inspections</h4>
                <p xml:space="preserve" id="p_000882" smilref="Machine_Learning00014.smil#p_000882">With the data loaded, you can do some quick inspections. First, how many elements of data do you have in the RDD?</p>
                <p xml:space="preserve" id="p_000883"><code class="preserve-whitespace" xml:space="preserve" id="code_000824" smilref="Machine_Learning00014.smil#code_000824">scala&gt; textF.count()</code></p>
                <p id="c11-c11-para-0048" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0048">You get the output:</p>
                <p xml:space="preserve" id="p_000884"><code class="preserve-whitespace" xml:space="preserve" id="code_000825" smilref="Machine_Learning00014.smil#code_000825">14/07/05 09:58:01 INFO SparkContext: Job finished: count at &lt;console&gt;:15, took 0.036546484 s
res4: Long = 469
scala&gt;</code></p>
                <p id="c11-c11-para-0049" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0049">This count represents the number of elements in the RDD and not the number of lines in the text file. You can pull the first element from the RDD:</p>
                <p xml:space="preserve" id="p_000885"><code class="preserve-whitespace" xml:space="preserve" id="code_000826" smilref="Machine_Learning00014.smil#code_000826">scala&gt; textF.first()
And the output appears:
14/07/05 10:00:20 INFO SparkContext: Job finished: first at &lt;console&gt;:15, took 0.007266678 s
res5: String = THE papers and addresses I have collected in this little book are submitted as contributions,......
scala&gt;</code></p>
                <p id="c11-c11-para-0050" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0050">As you can see from the output, these results are returning very quickly as the RDD is based in memory.</p>
              </level4>
              <level4 id="level4_000131">
                <h4 xml:space="preserve" id="h4_000131" smilref="Machine_Learning00014.smil#h4_000131">Filter Text from the RDD</h4>
                <pagenum epub:type="pagebreak" id="p284" page="normal" smilref="Machine_Learning00014.smil#p284">284</pagenum>
                <p xml:space="preserve" id="p_000886"><span class="text" id="span_002217" smilref="Machine_Learning00014.smil#span_002217">With the </span><code xml:space="preserve" id="code_000827" smilref="Machine_Learning00014.smil#code_000827">.filter</code><span class="text" id="span_002218" smilref="Machine_Learning00014.smil#span_002218"> function, you can start to inspect specific things within the text file. Assuming that you want to see how many times the word “statistical” occurs in the document, you can run the following:</span></p>
                <p xml:space="preserve" id="p_000887"><code class="preserve-whitespace" xml:space="preserve" id="code_000828" smilref="Machine_Learning00014.smil#code_000828">scala&gt; textF.filter(line =&gt; line.contains("statistical")).count()</code></p>
                <p id="c11-c11-para-0052" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0052">One line in Scala and the Spark filter iterate the RDD and inspect the lines. Because you've appended the count at the end, you get the following result:</p>
                <p xml:space="preserve" id="p_000888"><code class="preserve-whitespace" xml:space="preserve" id="code_000829" smilref="Machine_Learning00014.smil#code_000829">14/07/05 10:16:55 INFO SparkContext: Job finished: count at &lt;console&gt;:15, took 0.042640019 s
res7: Long = 2</code></p>
                <p id="c11-c11-para-0053" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0053">So, there are two mentions of the word “statistical” in the entire document, and all completed in 0.04 seconds. If required, you could save this output to another Scala array:</p>
                <p xml:space="preserve" id="p_000889"><code class="preserve-whitespace" xml:space="preserve" id="code_000830" smilref="Machine_Learning00014.smil#code_000830">scala&gt; var filtered = textF.filter(line =&gt; line.contains("statistical"))
filtered: org.apache.spark.rdd.RDD[String] = FilteredRDD[4] at filter at &lt;console&gt;:14
scala&gt; filtered.count
14/07/08 09:20:16 INFO SparkContext: Job finished: count at &lt;console&gt;:17, took 0.067395793 s
res4: Long = 2</code></p>
                <p id="c11-c11-para-0054" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0054">With the aid of concise commands in Scala and the power of in-memory processing of distributed datasets (the RDDs), you have a neat system to get large amounts of crunching done quickly.</p>
              </level4>
            </level3>
            <level3 id="level3_000191">
              <h3 xml:space="preserve" id="h3_000191" smilref="Machine_Learning00014.smil#h3_000191">Spark Monitor</h3>
              <p xml:space="preserve" id="p_000890"><span class="text" id="span_002219" smilref="Machine_Learning00014.smil#span_002219">Earlier, I mentioned that when you start Spark a few things are being run. One of them is the web-based monitor. If you point your browser to </span><code xml:space="preserve" id="code_000831"><a href="http://yourdomain:4040" external="true" id="a_000313" smilref="Machine_Learning00014.smil#a_000313">http://yourdomain:4040</a></code><span class="text" id="span_002220" smilref="Machine_Learning00014.smil#span_002220">, you should get the website shown in </span><a id="c11-c11-fig-anc-0001" href="#c11-c11-fig-0001" external="false" smilref="Machine_Learning00014.smil#c11-c11-fig-anc-0001">Figure 11-1</a><span class="text" id="span_002221" smilref="Machine_Learning00014.smil#span_002221">, assuming Spark is still running.</span></p>
              <figure id="figure_000105">
                <img class="center" src="images/c11f001.jpg" alt="image" id="img_000130" />
                <figcaption id="figcaption_000091">
                  <p xml:space="preserve" id="p_000891"><span class="figureLabel" id="span_002222"><a id="c11-c11-fig-0001" href="#c11-c11-fig-anc-0001" external="false"><strong id="strong_000755" smilref="Machine_Learning00014.smil#strong_000755">Figure 11-1</strong></a></span><span class="text" id="span_002223" smilref="Machine_Learning00014.smil#span_002223"> Spark web console</span></p>
                </figcaption>
              </figure>
              <p id="c11-c11-para-0056" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0056">As far as Spark is concerned, every line you run is a job, so Spark logs it accordingly, giving its duration and outcome. There's also information on the storage and runtime environment.</p>
              <p id="c11-c11-para-0057" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0057">You can click on each of the stages to see full details of the job and its execution output. If one of your jobs is causing trouble, then it's handy to look here first and get a bird's eye view of things.</p>
            </level3>
          </level2>
          <level2 id="level2_000096">
            <h2 id="c11-c011_level1_6" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_6">Comparing Hadoop MapReduce to Spark</h2>
            <pagenum epub:type="pagebreak" id="p285" page="normal" smilref="Machine_Learning00014.smil#p285">285</pagenum>
            <p xml:space="preserve" id="p_000892" smilref="Machine_Learning00014.smil#p_000892">Recall from Chapter 10 that it required a certain amount of effort to create a MapReduce program in Java to work with Hadoop.</p>
            <p id="c11-c11-para-0059" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0059">The basic Java code boilerplate is usually along the lines of the map and reduce phases:</p>
            <p xml:space="preserve" id="p_000893"><code class="preserve-whitespace" xml:space="preserve" id="code_000832" smilref="Machine_Learning00014.smil#code_000832">public static class Map extends MapReduceBase implements
            Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();
        public void map(LongWritable key, Text value,
                OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)
                throws IOException {
            // ususally emit something to the reducer here….
        }
    }
    public static class Reduce extends MapReduceBase implements
            Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
        public void reduce(Text key, Iterator&lt;IntWritable&gt; values,
                OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter)
                throws IOException {
            // reducer would add the value +1 for example
        }
    }</code></p>
            <p id="c11-c11-para-0060" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0060">Then a job definition enables it to run within the Hadoop framework:</p>
            <p xml:space="preserve" id="p_000894"><code class="preserve-whitespace" xml:space="preserve" id="code_000833" smilref="Machine_Learning00014.smil#code_000833">public static void main(String[] args) throws IOException {
        JobConf conf = new JobConf(BlankHadoopJob.class);
        conf.setJobName("BlankHadoopJob");
        conf.setOutputKeyClass(Text.class);
        conf.setOutputValueClass(IntWritable.class);
        conf.setMapperClass(Map.class);
        conf.setCombinerClass(Reduce.class);
        conf.setReducerClass(Reduce.class);
        conf.setInputFormat(TextInputFormat.class);
        conf.setOutputFormat(TextOutputFormat.class);
        FileInputFormat.setInputPaths(conf, new Path(args[0]));
        FileOutputFormat.setOutputPath(conf, new Path(args[1]));
        JobClient.runJob(conf);
    }</code></p>
            <pagenum epub:type="pagebreak" id="p286" page="normal" smilref="Machine_Learning00014.smil#p286">286</pagenum>
            <p id="c11-c11-para-0061" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0061">Some developers complain about the amount of code you need to write in Java to get MapReduce working. It's never been an issue for me (as I have templates set up), but when I show you how it works in Spark, you'll realize why they were complaining.</p>
            <p id="c11-c11-para-0062" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0062">In Spark, you can put together a quick word count MapReduce routine that demonstrates how easy it is to do. Using the same text file you used earlier, you can run a MapReduce process from the Spark shell. First load the text file:</p>
            <p xml:space="preserve" id="p_000895"><code class="preserve-whitespace" xml:space="preserve" id="code_000834" smilref="Machine_Learning00014.smil#code_000834">scala&gt; var textF  = sc.textFile("/home/jason/worldbrain.txt")</code></p>
            <p id="c11-c11-para-0063" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0063">Then create a new variable with the results of the MapReduce:</p>
            <p xml:space="preserve" id="p_000896"><code class="preserve-whitespace" xml:space="preserve" id="code_000835" smilref="Machine_Learning00014.smil#code_000835">scala&gt; var mapred = textF.flatMap(line =&gt; line.split(" ")).map(word =&gt; (word, 1)).reduceByKey((a,b) =&gt; a+b)</code></p>
            <pagenum epub:type="pagebreak" id="p287" page="normal" smilref="Machine_Learning00014.smil#p287">287</pagenum>
            <p id="c11-c11-para-0064" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0064">Then output the results:</p>
            <p xml:space="preserve" id="p_000897"><code class="preserve-whitespace" xml:space="preserve" id="code_000836" smilref="Machine_Learning00014.smil#code_000836">scala&gt; mapred.collect</code></p>
            <p id="c11-c11-para-0065" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0065">You see a block of the output appear in the shell:</p>
            <p xml:space="preserve" id="p_000898"><code class="preserve-whitespace" xml:space="preserve" id="code_000837" smilref="Machine_Learning00014.smil#code_000837">14/07/08 09:28:29 INFO SparkContext: Job finished: collect at &lt;console&gt;:17, took 0.78279487 s
res7: Array[(String, Int)] = Array((professors,,1), (mattered,1), (intimately,1), (better.,3), (someone,3), (House,1), (manifestly,1), (order,13), (socialism.,1), (apprehension,4), (conclusively,1), (gowns,2), (behind,3), (Out″,,1), (merge,1), (wasn't,1), (been,125), (Judea;,1), (gap,5), (underrate,1), (aspects;,1), (knows,8), (informative,15), (divorced,1), (are,259), (records,4), (2.,1), (Western,3), (politician,,1), (room—and,1), (newspapers,,3), (picture.,1), (interchange—from,1), (prete</code></p>
            <p id="c11-c11-para-0066" xml:space="preserve"><span class="text" id="span_002224" smilref="Machine_Learning00014.smil#span_002224">To save the results, use the </span><code xml:space="preserve" id="code_000838" smilref="Machine_Learning00014.smil#code_000838">.saveAsTextFile</code><span class="text" id="span_002225" smilref="Machine_Learning00014.smil#span_002225"> method on the RDD to output as text:</span></p>
            <p xml:space="preserve" id="p_000899"><code class="preserve-whitespace" xml:space="preserve" id="code_000839" smilref="Machine_Learning00014.smil#code_000839">scala&gt; mapred.saveAsTextFile("/home/jason/testoutput")</code></p>
            <p id="c11-c11-para-0067" xml:space="preserve"><span class="text" id="span_002226" smilref="Machine_Learning00014.smil#span_002226">Spark, in the same way as Hadoop, saves the files in a directory (I called this one </span><code xml:space="preserve" id="code_000840" smilref="Machine_Learning00014.smil#code_000840">testoutput</code><span class="text" id="span_002227" smilref="Machine_Learning00014.smil#span_002227">). Within it you see the </span><code xml:space="preserve" id="code_000841" smilref="Machine_Learning00014.smil#code_000841">part-00000</code><span class="text" id="span_002228" smilref="Machine_Learning00014.smil#span_002228"> files:</span></p>
            <p xml:space="preserve" id="p_000900"><code class="preserve-whitespace" xml:space="preserve" id="code_000842" smilref="Machine_Learning00014.smil#code_000842">-rw-r--r-- 1 1234 1234 52961 Jul  8 13:47 part-00000
-rw-r--r-- 1 1234 1234 52861 Jul  8 13:47 part-00001
-rw-r--r-- 1 1234 1234     0 Jul  8 13:47 _SUCCESS</code></p>
            <p id="c11-c11-para-0068" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0068">The output of those files contains the basic word count:</p>
            <p xml:space="preserve" id="p_000901"><code class="preserve-whitespace" xml:space="preserve" id="code_000843" smilref="Machine_Learning00014.smil#code_000843">(lags—throughout,1)
(however,9)
(cry.,1)
(eminent,2)
(dangerous,5)
(varieties,1)
(History.,1)
(behind,,1)
(late,3)
(nineteenth,6)
(helpless,1)
(throwing,2)
(aesthetic,4)
(leapt,2)</code></p>
            <pagenum epub:type="pagebreak" id="p288" page="normal" smilref="Machine_Learning00014.smil#p288">288</pagenum>
            <p id="c11-c11-para-0069" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0069">In three lines you performed a basic MapReduce program on some raw text. Notice that I didn't remove odd characters and convert everything to lowercase, but essentially it gave us the word count output.</p>
          </level2>
          <level2 id="level2_000097">
            <h2 id="c11-c011_level1_7" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_7">Writing Standalone Programs with Spark</h2>
            <p xml:space="preserve" id="p_000902" smilref="Machine_Learning00014.smil#p_000902">The brief introduction to Spark has shown you that it's fast, and you can perform certain tasks with ease. The shell is useful for inspecting datasets and getting a basic set of answers, counts, or frequencies from the data. There are times, though, when full programs are required to be written. As previously discussed, Spark programs can be written in Scala, Java, or Python, because there's a supporting API for each of them. This section concentrates on Scala and Java.</p>
            <sidebar render="required" id="sidebar_000015">
              <div class="top hr" id="div_000015" />
              <level2 class="feature2" id="level2_000098">
                <h2 xml:space="preserve" id="h2_000019" smilref="Machine_Learning00014.smil#h2_000019">Note</h2>
                <p xml:space="preserve" id="p_000903" smilref="Machine_Learning00014.smil#p_000903">The Scala program requires the Scala libraries and compiler. Instructions on how to install them are provided earlier in this chapter.</p>
              </level2>
            </sidebar>
            <level3 id="level3_000192">
              <h3 xml:space="preserve" id="h3_000192" smilref="Machine_Learning00014.smil#h3_000192">Spark Programs in Scala</h3>
              <p xml:space="preserve" id="p_000904"><span class="text" id="span_002229" smilref="Machine_Learning00014.smil#span_002229">Scala applications are very similar to Java applications in their construction. With the Scala Build Tool (</span><code xml:space="preserve" id="code_000844" smilref="Machine_Learning00014.smil#code_000844">sbt</code><span class="text" id="span_002230" smilref="Machine_Learning00014.smil#span_002230">), you can manage the building of everything in one place, too.</span></p>
              <p id="c11-c11-para-0073" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0073">It's worth treating programs as small projects, so keeping the code in its own directory makes maintenance more manageable.</p>
            </level3>
            <level3 id="level3_000193">
              <h3 xml:space="preserve" id="h3_000193" smilref="Machine_Learning00014.smil#h3_000193">Installing SBT</h3>
              <p xml:space="preserve" id="p_000905"><span class="text" id="span_002231" smilref="Machine_Learning00014.smil#span_002231">The Scala Build Tool is a separate download from the main Scala libraries, so you need to download and install that as well. The downloads are available from </span><code xml:space="preserve" id="code_000845"><a href="http://www.scala-sbt.org/download.html" external="true" id="a_000314" smilref="Machine_Learning00014.smil#a_000314">www.scala-sbt.org/download.html</a></code><span class="text" id="span_002232" smilref="Machine_Learning00014.smil#span_002232">. Download the file that's appropriate for your operating system and unarchive it. Make sure the binary is in your path, so you can execute the </span><code xml:space="preserve" id="code_000846" smilref="Machine_Learning00014.smil#code_000846">sbt</code><span class="text" id="span_002233" smilref="Machine_Learning00014.smil#span_002233"> file.</span></p>
              <level4 id="level4_000132">
                <h4 xml:space="preserve" id="h4_000132" smilref="Machine_Learning00014.smil#h4_000132">The Scala Program Code</h4>
                <p xml:space="preserve" id="p_000906"><span class="text" id="span_002234" smilref="Machine_Learning00014.smil#span_002234">Create a project called </span><code xml:space="preserve" id="code_000847" smilref="Machine_Learning00014.smil#code_000847">ScalaMRExample</code><span class="text" id="span_002235" smilref="Machine_Learning00014.smil#span_002235">, then create the </span><code xml:space="preserve" id="code_000848" smilref="Machine_Learning00014.smil#code_000848">src</code><span class="text" id="span_002236" smilref="Machine_Learning00014.smil#span_002236"> and </span><code xml:space="preserve" id="code_000849" smilref="Machine_Learning00014.smil#code_000849">main</code><span class="text" id="span_002237" smilref="Machine_Learning00014.smil#span_002237"> directories within it:</span></p>
                <p xml:space="preserve" id="p_000907"><code class="preserve-whitespace" xml:space="preserve" id="code_000850" smilref="Machine_Learning00014.smil#code_000850">mkdir –p ScalaMRExample/src/main</code></p>
                <pagenum epub:type="pagebreak" id="p289" page="normal" smilref="Machine_Learning00014.smil#p289">289</pagenum>
                <p id="c11-c11-para-0076" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0076">Keeping the MapReduce example in mind, the Spark application, in a file named “ScalaMRExample.scala” would look like so:</p>
                <p xml:space="preserve" id="p_000908"><code class="preserve-whitespace" xml:space="preserve" id="code_000851" smilref="Machine_Learning00014.smil#code_000851">import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
object ScalaMRExample {
  def main(args: Array[String]) {
    val configuration = new SparkConf().setAppName("Scala MapReduce Example")
    val sc = new SparkContext(conf)
    val textFile = "/home/jason/worldbrain.txt"
    val textSc = sc.textFile(textFile)
    val mapred = textFile.flatMap(line =&gt; line.split(" ")).map(word =&gt; (word, 1)).reduceByKey((a,b) =&gt; a+b)
    mapred.collect
    mapred.saveAsTextFile("wboutput")
  }
}</code></p>
                <p id="c11-c11-para-0077" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0077">You must adjust the filenames and paths for your environment, of course. The program imports the required Spark libraries and then sets up the object name and the main method to run. As you can see, it's very similar to Java in those respects.</p>
                <p id="c11-c11-para-0078" xml:space="preserve"><span class="text" id="span_002238" smilref="Machine_Learning00014.smil#span_002238">To load the system properties and the active classpath, you create a </span><code xml:space="preserve" id="code_000852" smilref="Machine_Learning00014.smil#code_000852">SparkConf</code><span class="text" id="span_002239" smilref="Machine_Learning00014.smil#span_002239"> object and pass in the name of your application, in this case </span><code xml:space="preserve" id="code_000853" smilref="Machine_Learning00014.smil#code_000853">ScalaMapReduce Example</code><span class="text" id="span_002240" smilref="Machine_Learning00014.smil#span_002240">. The remainder of the program is the same as what has been previously covered. Load in the text file, run the simple MapReduce, output the results, and then save the output results to a location.</span></p>
              </level4>
              <level4 id="level4_000133">
                <h4 xml:space="preserve" id="h4_000133" smilref="Machine_Learning00014.smil#h4_000133">The Scala Build Tool File</h4>
                <p xml:space="preserve" id="p_000909"><span class="text" id="span_002241" smilref="Machine_Learning00014.smil#span_002241">The Scala Build Tool is similar to Java build tools such as Ant and Maven. You need a build file in the </span><code xml:space="preserve" id="code_000854" smilref="Machine_Learning00014.smil#code_000854">ScalaMRExample</code><span class="text" id="span_002242" smilref="Machine_Learning00014.smil#span_002242"> directory that tells Scala about the project, its dependencies, and where to get them:</span></p>
                <p xml:space="preserve" id="p_000910"><code class="preserve-whitespace" xml:space="preserve" id="code_000855" smilref="Machine_Learning00014.smil#code_000855">name := "ScalaMRExample"
version := "0.1"
scalaVersion := "2.10.4"
libraryDependencies += "org.apache.spark" %% "spark-core" % "1.0.0"
resolvers += "Akka Repository" at "http://repo.akka.io/releases/" </code></p>
                <pagenum epub:type="pagebreak" id="p290" page="normal" smilref="Machine_Learning00014.smil#p290">290</pagenum>
                <p id="c11-c11-para-0080" xml:space="preserve"><span class="text" id="span_002243" smilref="Machine_Learning00014.smil#span_002243">Save this file as </span><code xml:space="preserve" id="code_000856" smilref="Machine_Learning00014.smil#code_000856">scalamrexample.sbt</code><span class="text" id="span_002244" smilref="Machine_Learning00014.smil#span_002244">, and then you can use </span><code xml:space="preserve" id="code_000857" smilref="Machine_Learning00014.smil#code_000857">sbt</code><span class="text" id="span_002245" smilref="Machine_Learning00014.smil#span_002245"> to package up the project. Inspect the directory structure to make sure everything is in place. In Linux/MacOS X, you can use the </span><code xml:space="preserve" id="code_000858" smilref="Machine_Learning00014.smil#code_000858">find</code><span class="text" id="span_002246" smilref="Machine_Learning00014.smil#span_002246"> command:</span></p>
                <p xml:space="preserve" id="p_000911"><code class="preserve-whitespace" xml:space="preserve" id="code_000859" smilref="Machine_Learning00014.smil#code_000859">Jason-Bells-MacBook-Pro:ScalaMRExample Jason$ find . -print
.
./scalamrexample.sbt
./src
./src/main
./src/main/scala
./src/main/scala/ScalaMRExample.scala</code></p>
                <p id="c11-c11-para-0081" xml:space="preserve"><span class="text" id="span_002247" smilref="Machine_Learning00014.smil#span_002247">When you're happy with the file listing (it should look like the preceding code), then you can package it up using </span><code xml:space="preserve" id="code_000860" smilref="Machine_Learning00014.smil#code_000860">sbt</code><span class="text" id="span_002248" smilref="Machine_Learning00014.smil#span_002248">. Make sure you are in the top-level ScalaMRExample.</span></p>
                <p xml:space="preserve" id="p_000912"><code class="preserve-whitespace" xml:space="preserve" id="code_000861" smilref="Machine_Learning00014.smil#code_000861">sbt package</code></p>
                <p id="c11-c11-para-0082" xml:space="preserve"><span class="text" id="span_002249" smilref="Machine_Learning00014.smil#span_002249">The first run might take some time, as </span><code xml:space="preserve" id="code_000862" smilref="Machine_Learning00014.smil#code_000862">sbt</code><span class="text" id="span_002250" smilref="Machine_Learning00014.smil#span_002250"> might have to download external libraries. When that's happened, though, the code compiles and the package is created:</span></p>
                <p xml:space="preserve" id="p_000913"><code class="preserve-whitespace" xml:space="preserve" id="code_000863" smilref="Machine_Learning00014.smil#code_000863">Jason-Bells-MacBook-Pro:ScalaMRExample Jason$ sbt package[info] Set current project to ScalaMRExample (in build file:/Users/Jason/work/scala/ScalaMRExample/)
[info] Compiling 1 Scala source to /Users/Jason/work/scala/ScalaMRExample/target/scala-2.10/classes…
[info] Packaging /Users/Jason/work/scala/ScalaMRExample/target/scala-2.10/scalamrexample_2.10-1.0.jar …
[info] Done packaging.
[success] Total time: 8 s, completed 09-Jul-2014 17:25:49</code></p>
                <p id="c11-c11-para-0083" xml:space="preserve"><span class="text" id="span_002251" smilref="Machine_Learning00014.smil#span_002251">You see the newly compiled package in the </span><code xml:space="preserve" id="code_000864" smilref="Machine_Learning00014.smil#code_000864">target/scala-2.10</code><span class="text" id="span_002252" smilref="Machine_Learning00014.smil#span_002252"> directory:</span></p>
                <p xml:space="preserve" id="p_000914"><code class="preserve-whitespace" xml:space="preserve" id="code_000865" smilref="Machine_Learning00014.smil#code_000865">Jason-Bells-MacBook-Pro:ScalaMRExample Jason$ cd target/scala-2.10/
Jason-Bells-MacBook-Pro:scala-2.10 Jason$ ls -l
total 16
drwxr-xr-x  7 Jason  staff   238  9 Jul 17:25 classes
-rw-r--r--  1 Jason  staff  4495  9 Jul 17:25 scalamrexample_2.10-1.0.jar
Jason-Bells-MacBook-Pro:scala-2.10 Jason$</code></p>
              </level4>
              <level4 id="level4_000134">
                <h4 xml:space="preserve" id="h4_000134" smilref="Machine_Learning00014.smil#h4_000134">Executing the Spark Project</h4>
                <pagenum epub:type="pagebreak" id="p291" page="normal" smilref="Machine_Learning00014.smil#p291">291</pagenum>
                <p xml:space="preserve" id="p_000915"><span class="text" id="span_002253" smilref="Machine_Learning00014.smil#span_002253">It's the </span><code xml:space="preserve" id="code_000866" smilref="Machine_Learning00014.smil#code_000866">jar</code><span class="text" id="span_002254" smilref="Machine_Learning00014.smil#span_002254"> file that you need to use with Spark. Assuming you are in the same directory where the </span><code xml:space="preserve" id="code_000867" smilref="Machine_Learning00014.smil#code_000867">jar</code><span class="text" id="span_002255" smilref="Machine_Learning00014.smil#span_002255"> file resides, use the </span><code xml:space="preserve" id="code_000868" smilref="Machine_Learning00014.smil#code_000868">spark-submit</code><span class="text" id="span_002256" smilref="Machine_Learning00014.smil#span_002256"> script to run the file:</span></p>
                <p xml:space="preserve" id="p_000916"><code class="preserve-whitespace" xml:space="preserve" id="code_000869" smilref="Machine_Learning00014.smil#code_000869">/usr/local/spark/bin/spark-submit --class "ScalaMRExample" \
--master local[4] scalamrexample_2.10-1.0.jar</code></p>
                <p id="c11-c11-para-0085" xml:space="preserve"><span class="text" id="span_002257" smilref="Machine_Learning00014.smil#span_002257">The </span><code xml:space="preserve" id="code_000870" smilref="Machine_Learning00014.smil#code_000870">--master local[4]</code><span class="text" id="span_002258" smilref="Machine_Learning00014.smil#span_002258"> option tells Spark to create four local nodes when it starts up. If all goes according the plan, you see Spark whirr into action and perform the task:</span></p>
                <p xml:space="preserve" id="p_000917"><code class="preserve-whitespace" xml:space="preserve" id="code_000871" smilref="Machine_Learning00014.smil#code_000871">14/07/09 19:32:42 INFO TaskSetManager: Finished TID 5 in 922 ms on localhost (progress: 2/2)
14/07/09 19:32:42 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
14/07/09 19:32:42 INFO DAGScheduler: Completed ResultTask(2, 1)
14/07/09 19:32:42 INFO DAGScheduler: Stage 2 (saveAsTextFile at ScalaMRExample.scala:15) finished in 0.924 s
14/07/09 19:32:42 INFO SparkContext: Job finished: saveAsTextFile at ScalaMRExample.scala:15, took 1.014446651 s</code></p>
                <p id="c11-c11-para-0086" xml:space="preserve"><span class="text" id="span_002259" smilref="Machine_Learning00014.smil#span_002259">As you used </span><code xml:space="preserve" id="code_000872" smilref="Machine_Learning00014.smil#code_000872">wboutput</code><span class="text" id="span_002260" smilref="Machine_Learning00014.smil#span_002260"> as the target directory to save the text output to, you see that in your directory structure. You see that using Scala means that creating MapReduce-based programs becomes a simple matter, compared to the Hadoop way of doing things. I'm not saying that one is better than the other; it's just another way of doing things. Take a look at the Java way of creating Spark programs.</span></p>
              </level4>
            </level3>
            <level3 id="level3_000194">
              <h3 xml:space="preserve" id="h3_000194" smilref="Machine_Learning00014.smil#h3_000194">Spark Programs in Java</h3>
              <p xml:space="preserve" id="p_000918" smilref="Machine_Learning00014.smil#p_000918">The concept of creating a Spark program written in Java is very much the same as the Scala example just covered. The main difference is the language and the build tool.</p>
              <p id="c11-c11-para-0088" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0088">The Spark API for Java requires a little more thought than the Scala examples. You can't just rattle out a four-line program to perform a MapReduce task.</p>
              <p xml:space="preserve" id="p_000919"><code class="preserve-whitespace" xml:space="preserve" id="code_000873"><span class="text" id="span_002261" smilref="Machine_Learning00014.smil#span_002261">import scala.Tuple2;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import </span><pagenum epub:type="pagebreak" id="p292" page="normal" smilref="Machine_Learning00014.smil#p292">292</pagenum><span class="text" id="span_002262" smilref="Machine_Learning00014.smil#span_002262">java.util.Arrays;
import java.util.List;
import java.util.regex.Pattern;
public final class JavaMRExample {
  private static final Pattern spacePattern = Pattern.compile(" ");
  public static void main(String[] args) throws Exception {
    SparkConf configuration = new SparkConf().setAppName("JavaMRExample");
    JavaSparkContext ctx = new JavaSparkContext(configuration);
    JavaRDD&lt;String&gt; linesOfText = ctx.textFile("/home/jason/worldbrain.txt", 1);
    JavaRDD&lt;String&gt; findWords = linesOfText.flatMap(new FlatMapFunction&lt;String, String&gt;() {
      @Override
      public Iterable&lt;String&gt; call(String thisString) {
        return Arrays.asList(spacePattern.split(thisString));
      }
    });
    JavaPairRDD&lt;String, Integer&gt; getTheOnes = findWords.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {
      @Override
      public Tuple2&lt;String, Integer&gt; call(String thisString) {
        return new Tuple2&lt;String, Integer&gt;(thisString, 1);
      }
    });
    JavaPairRDD&lt;String, Integer&gt; finalCounts = getTheOnes.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {
      @Override
      public Integer call(Integer i1, Integer i2) {
        return i1 + i2;
      }
    });
    List&lt;Tuple2&lt;String, Integer&gt;&gt;thisOutput = finalCounts.collect();
    for (Tuple2&lt;?,?&gt; tuple: thisOutput) {
      System.out.println(tuple._1() + ": " + tuple._2());
    }
    ctx.stop();
  }
}</span></code></p>
              <pagenum epub:type="pagebreak" id="p293" page="normal" smilref="Machine_Learning00014.smil#p293">293</pagenum>
              <p id="c11-c11-para-0089" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0089">There's a lot more code to put together than in the Scala MapReduce example program. The Java Spark API requires a little more thought in execution:</p>
              <list type="ul" id="list_000066">
                <li id="li_000447" smilref="Machine_Learning00014.smil#li_000447">Splitting the words</li>
                <li id="li_000448" smilref="Machine_Learning00014.smil#li_000448">Assigning a count of 1 for each word</li>
                <li id="li_000449" smilref="Machine_Learning00014.smil#li_000449">Adding up the counts for each unique word</li>
                <li id="li_000450" smilref="Machine_Learning00014.smil#li_000450">Generating the output</li>
              </list>
              <level4 id="level4_000135">
                <h4 xml:space="preserve" id="h4_000135" smilref="Machine_Learning00014.smil#h4_000135">Using Maven to Build the Project</h4>
                <p xml:space="preserve" id="p_000920"><span class="text" id="span_002263" smilref="Machine_Learning00014.smil#span_002263">Throughout the book, I've used Eclipse to generate the projects and handle the build for me. Maven is a build tool (</span><code xml:space="preserve" id="code_000874" smilref="Machine_Learning00014.smil#code_000874">sbt</code><span class="text" id="span_002264" smilref="Machine_Learning00014.smil#span_002264"> was pretty much inspired by the Maven build process in my opinion) and, along with Ant, is the mainstay of Java build tools. If you don't have Maven installed, you can download it from </span><code xml:space="preserve" id="code_000875"><a href="http://maven.apache.org" external="true" id="a_000315" smilref="Machine_Learning00014.smil#a_000315">http://maven.apache.org</a></code><span class="text" id="span_002265" smilref="Machine_Learning00014.smil#span_002265"> and unarchive the file.</span></p>
                <p id="c11-c11-para-0091" xml:space="preserve"><span class="text" id="span_002266" smilref="Machine_Learning00014.smil#span_002266">For every project, you need a Maven build file; this is called </span><code xml:space="preserve" id="code_000876" smilref="Machine_Learning00014.smil#code_000876">pom.xml</code><span class="text" id="span_002267" smilref="Machine_Learning00014.smil#span_002267">.</span></p>
                <p xml:space="preserve" id="p_000921"><code class="preserve-whitespace" xml:space="preserve" id="code_000877" smilref="Machine_Learning00014.smil#code_000877">&lt;project&gt;
  &lt;groupId&gt;com.mlbook&lt;/groupId&gt;
  &lt;artifactId&gt;javamrexample&lt;/artifactId&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;name&gt;Java MR Example&lt;/name&gt;
  &lt;packaging&gt;jar&lt;/packaging&gt;
  &lt;version&gt;1.0&lt;/version&gt;
  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;Akka repository&lt;/id&gt;
      &lt;url&gt;http://repo.akka.io/releases&lt;/url&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;
      &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/project&gt;</code></p>
                <p id="c11-c11-para-0092" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0092">This gives you the basic outline of the project and which repositories to pull any required dependencies from. For Spark projects, you need to have the Spark API in the dependencies declaration.</p>
              </level4>
              <level4 id="level4_000136">
                <h4 xml:space="preserve" id="h4_000136" smilref="Machine_Learning00014.smil#h4_000136">Creating Packages in Maven</h4>
                <pagenum epub:type="pagebreak" id="p294" page="normal" smilref="Machine_Learning00014.smil#p294">294</pagenum>
                <p xml:space="preserve" id="p_000922" smilref="Machine_Learning00014.smil#p_000922">To create the package, you run Maven from the command line:</p>
                <p xml:space="preserve" id="p_000923"><code class="preserve-whitespace" xml:space="preserve" id="code_000878" smilref="Machine_Learning00014.smil#code_000878">mvn package</code></p>
                <p id="c11-c11-para-0094" xml:space="preserve"><span class="text" id="span_002268" smilref="Machine_Learning00014.smil#span_002268">The Maven build tool looks after the downloading of the dependencies, creates the class files, and then packages the </span><code xml:space="preserve" id="code_000879" smilref="Machine_Learning00014.smil#code_000879">jar</code><span class="text" id="span_002269" smilref="Machine_Learning00014.smil#span_002269"> file with the required classes. After it's built, a directory called </span><code xml:space="preserve" id="code_000880" smilref="Machine_Learning00014.smil#code_000880">target</code><span class="text" id="span_002270" smilref="Machine_Learning00014.smil#span_002270"> is created and you see the </span><code xml:space="preserve" id="code_000881" smilref="Machine_Learning00014.smil#code_000881">jar</code><span class="text" id="span_002271" smilref="Machine_Learning00014.smil#span_002271"> file there.</span></p>
                <p xml:space="preserve" id="p_000924"><code class="preserve-whitespace" xml:space="preserve" id="code_000882" smilref="Machine_Learning00014.smil#code_000882">Jason-Bells-MacBook-Pro:JavaMRExample Jason$ cd target/
Jason-Bells-MacBook-Pro:target Jason$ ls -l
total 24
drwxr-xr-x  10 Jason  staff   340  9 Jul 18:19 classes
-rw-r--r--   1 Jason  staff  8679  9 Jul 18:19 javamrexample-1.0.jar
drwxr-xr-x   3 Jason  staff   102  9 Jul 18:04 maven-archiver
Jason-Bells-MacBook-Pro:target Jason$</code></p>
                <p id="c11-c11-para-0095" xml:space="preserve"><span class="text" id="span_002272" smilref="Machine_Learning00014.smil#span_002272">To run the project with Spark, you need to use the </span><code xml:space="preserve" id="code_000883" smilref="Machine_Learning00014.smil#code_000883">spark-submit</code><span class="text" id="span_002273" smilref="Machine_Learning00014.smil#span_002273"> program like you did in the previous Scala example:</span></p>
                <p xml:space="preserve" id="p_000925"><code class="preserve-whitespace" xml:space="preserve" id="code_000884" smilref="Machine_Learning00014.smil#code_000884">jason@cloudatics:˜$ /usr/local/spark/bin/spark-submit --class "JavaMRExample" \
--master local[4] javamrexample-1.0.jar</code></p>
                <p id="c11-c11-para-0096" xml:space="preserve"><span class="text" id="span_002274" smilref="Machine_Learning00014.smil#span_002274">Spark executes the </span><code xml:space="preserve" id="code_000885" smilref="Machine_Learning00014.smil#code_000885">jar</code><span class="text" id="span_002275" smilref="Machine_Learning00014.smil#span_002275"> file, and you see the MapReduce output in the console:</span></p>
                <p xml:space="preserve" id="p_000926"><code class="preserve-whitespace" xml:space="preserve" id="code_000886" smilref="Machine_Learning00014.smil#code_000886">14/07/09 20:37:08 INFO DAGScheduler: Stage 0 (collect at JavaMRExample.java:44) finished in 0.784 s
14/07/09 20:37:08 INFO SparkContext: Job finished: collect at JavaMRExample.java:44, took 2.47317507 s
young: 29
mattered: 1
intimately: 1
journeys.: 1
Let: 7
House: 1
(Socialism),: 1
instance,: 1
superannuated.: 1
proportions,: 1
Contributed: 1
secure: 4
incoherent.: 1
everyone.: 1
gowns: 2
well-informed: 1</code></p>
              </level4>
            </level3>
            <level3 id="level3_000195">
              <h3 xml:space="preserve" id="h3_000195" smilref="Machine_Learning00014.smil#h3_000195">Spark Program Summary</h3>
              <pagenum epub:type="pagebreak" id="p295" page="normal" smilref="Machine_Learning00014.smil#p295">295</pagenum>
              <p xml:space="preserve" id="p_000927" smilref="Machine_Learning00014.smil#p_000927">You've now seen two methods for quickly creating and building projects for the Spark framework. As previously mentioned, the decision about whether to use Java or Scala really depends on your comfort level. For production work, you really don't want to be using experimental code in a language with which you're not 100percent comfortable.</p>
              <p id="c11-c11-para-0098" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0098">So, with the basics of Spark and creating standalone applications, you can now move forward and look at some of the libraries that are available for use within Spark.</p>
            </level3>
          </level2>
          <level2 id="level2_000099">
            <h2 id="c11-c011_level1_8" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_8">Spark SQL</h2>
            <p xml:space="preserve" id="p_000928" smilref="Machine_Learning00014.smil#p_000928">One of the great discussions in the Hadoop world has been “Can I run SQL (Structured Query Language)-like queries?” There's still something intrinsic in people who deal with data and their use of SQL. It's easy to see why; SQL is nice and language friendly. The Pig scripting language in Hadoop was close to getting to English-like MapReduce jobs, but the lure of true SQL queries is just too much for some, so they ask if it exists.</p>
            <p id="c11-c11-para-0100" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0100">SparkSQL is just that—SQL-like queries within the Spark framework. It's just limited to SQL, so you can run Scala queries or even HiveSQL queries within the Spark framework. The data can be held within an external datastore like Apache Hive or loaded into memory as an RDD and queried that way.</p>
            <sidebar render="required" id="sidebar_000016">
              <div class="top hr" id="div_000016" />
              <level2 class="feature2" id="level2_000100">
                <h2 xml:space="preserve" id="h2_000020" smilref="Machine_Learning00014.smil#h2_000020">Note</h2>
                <p xml:space="preserve" id="p_000929" smilref="Machine_Learning00014.smil#p_000929">The SQL parser in SparkSQL will be useful for most people, but it's not as advanced as some might expect in a full database system. If you need that full flexibility, then you are advised to look at HiveSQL as an alternative. For the remainder of the section I concentrate on the SparkSQL parser by way of an introduction.</p>
              </level2>
            </sidebar>
            <level3 id="level3_000196">
              <h3 xml:space="preserve" id="h3_000196" smilref="Machine_Learning00014.smil#h3_000196">Basic Concepts</h3>
              <p xml:space="preserve" id="p_000930"><span class="text" id="span_002276" smilref="Machine_Learning00014.smil#span_002276">With the </span><code xml:space="preserve" id="code_000887" smilref="Machine_Learning00014.smil#code_000887">SparkContext</code><span class="text" id="span_002277" smilref="Machine_Learning00014.smil#span_002277"> in place, you can easily create a SparkSQL instance and associate that with the current context. This can be done within the shell in Scala or as a standalone program with Scala, Java, or Python. The program method is easier if you have maintenance of code in mind.</span></p>
              <p id="c11-c11-para-0103" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0103">The basic code to incorporate the SparkSQL libraries is as follows:</p>
              <p xml:space="preserve" id="p_000931"><code class="preserve-whitespace" xml:space="preserve" id="code_000888" smilref="Machine_Learning00014.smil#code_000888">import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
object SparkSQLExample {
  def main(args: Array[String]) {
    val configuration = new SparkConf().setAppName("SparkSQL Example")
    val sc = new SparkContext(configuration)
    val sql = new org.apache.spark.sql.SQLContext(sc)
    // program continues.
  }
}</code></p>
              <p id="c11-c11-para-0104" xml:space="preserve"><span class="text" id="span_002278" smilref="Machine_Learning00014.smil#span_002278">You need to add the SparkSQL library to the required dependencies in your </span><code xml:space="preserve" id="code_000889" smilref="Machine_Learning00014.smil#code_000889">sbt</code><span class="text" id="span_002279" smilref="Machine_Learning00014.smil#span_002279"> build file. I've created a new build file for the code:</span></p>
              <p xml:space="preserve" id="p_000932"><code class="preserve-whitespace" xml:space="preserve" id="code_000890" smilref="Machine_Learning00014.smil#code_000890">name := "SparkSQLExample"
version := "1.0"
scalaVersion := "2.10.4"
libraryDependencies += "org.apache.spark" %% "spark-core" % "1.0.0"
libraryDependencies += "org.apache.spark" %% "spark-sql" % "1.0.0"
resolvers += "Akka Repository" at http://repo.akka.io/releases/</code></p>
              <pagenum epub:type="pagebreak" id="p296" page="normal" smilref="Machine_Learning00014.smil#p296">296</pagenum>
              <p id="c11-c11-para-0105" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0105">Don't forget to ensure there is a blank line between each text line. Otherwise, the build tool throws an error during the build.</p>
            </level3>
            <level3 id="level3_000197">
              <h3 xml:space="preserve" id="h3_000197" smilref="Machine_Learning00014.smil#h3_000197">Using SparkSQL with RDDs</h3>
              <p xml:space="preserve" id="p_000933"><span class="text" id="span_002280" smilref="Machine_Learning00014.smil#span_002280">It's time to create a real-world example of the SparkSQL system using the internal RDD as a storage system. With the data being held, in memory it will be fast. In addition, you'll open up the Scala language a little bit to show you an application with more than one </span><code xml:space="preserve" id="code_000891" smilref="Machine_Learning00014.smil#code_000891">.scala</code><span class="text" id="span_002281" smilref="Machine_Learning00014.smil#span_002281"> file in the build.</span></p>
              <level4 id="level4_000137">
                <h4 xml:space="preserve" id="h4_000137" smilref="Machine_Learning00014.smil#h4_000137">Generating Data</h4>
                <p xml:space="preserve" id="p_000934"><span class="text" id="span_002282" smilref="Machine_Learning00014.smil#span_002282">This example uses a </span><code xml:space="preserve" id="code_000892" smilref="Machine_Learning00014.smil#code_000892">.csv</code><span class="text" id="span_002283" smilref="Machine_Learning00014.smil#span_002283"> file with the following information:</span></p>
                <list type="ul" id="list_000067">
                  <li id="li_000451" smilref="Machine_Learning00014.smil#li_000451">Unique Id</li>
                  <li id="li_000452" smilref="Machine_Learning00014.smil#li_000452">First name</li>
                  <li id="li_000453" smilref="Machine_Learning00014.smil#li_000453">Surname</li>
                  <li id="li_000454" smilref="Machine_Learning00014.smil#li_000454">UK Postcode</li>
                  <pagenum epub:type="pagebreak" id="p297" page="normal" smilref="Machine_Learning00014.smil#p297">297</pagenum>
                  <li id="li_000455" smilref="Machine_Learning00014.smil#li_000455">Date of Birth (month/day/year format)</li>
                  <li id="li_000456" smilref="Machine_Learning00014.smil#li_000456">Latitude</li>
                  <li id="li_000457" smilref="Machine_Learning00014.smil#li_000457">Longitude</li>
                </list>
                <p id="c11-c11-para-0108" xml:space="preserve"><span class="text" id="span_002284" smilref="Machine_Learning00014.smil#span_002284">This could represent some form of customer database. You can either generate your own data or use a service such as </span><code xml:space="preserve" id="code_000893"><a href="http://fakenamegenerator.com" external="true" id="a_000316" smilref="Machine_Learning00014.smil#a_000316">fakenamegenerator.com</a></code><span class="text" id="span_002285" smilref="Machine_Learning00014.smil#span_002285"> to create a dataset for you. If you do use that service, ensure that you do not have the field names on the top line of the </span><code xml:space="preserve" id="code_000894" smilref="Machine_Learning00014.smil#code_000894">.csv</code><span class="text" id="span_002286" smilref="Machine_Learning00014.smil#span_002286"> file; delete it if necessary.</span></p>
                <p id="c11-c11-para-0109" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0109">A sample of the data looks like this:</p>
                <p xml:space="preserve" id="p_000935"><code class="preserve-whitespace" xml:space="preserve" id="code_000895" smilref="Machine_Learning00014.smil#code_000895">72215385-fad0-45fd-b932-a3d4fa07fb6d,William,Winter,DG3 7AL,1/4/1969,55.282416,-3.831666
71efb06f-63a7-4312-abe2-1fc4c8bd52e5,Billy,Noble,DD6 7FU,9/11/1969,55.597429,-3.170968
eac7b8f6-2d71-49a7-8e4d-a780826ce893,Kayleigh,Atkins,DG8 9ES,1/20/1932,54.73341,-4.407141
337d498d-9bed-4663-b688-6ec2651bcd9d,Emma,Perry,IM3 2GE,4/16/1935,54.173625,-4.480233
c3b0cc54-1f2f-416f-9b91-17a0700a4dc1,Liam,Carr,EX32 8AA,1/3/1991,50.682015,-3.119895
ea6acc38-1b69-424f-b885-09b078f6eaf2,Alex,Dodd,PH2 0QJ,6/24/1993,55.982172,-3.592573</code></p>
                <p id="c11-c11-para-0110" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0110">With the data in place, you can turn your attention to the code.</p>
              </level4>
              <level4 id="level4_000138">
                <h4 xml:space="preserve" id="h4_000138" smilref="Machine_Learning00014.smil#h4_000138">The Scala Application</h4>
                <p xml:space="preserve" id="p_000936" smilref="Machine_Learning00014.smil#p_000936">I'm going to split this application up logically. One Scala object to run the main program and Spark configuration and another to do the query work. The main program is going to output some log information as well, making it easier to keep track of what's going on while the program is being run. Take a look at the basic breakdown with the configuration:</p>
                <p xml:space="preserve" id="p_000937"><code class="preserve-whitespace" xml:space="preserve" id="code_000896" smilref="Machine_Learning00014.smil#code_000896">import java.io._
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
import org.apache.spark.sql.SQLContext
object SparkSQLExample {
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("SparkSQLExample").setMaster("local")
    conf.set("spark.eventLog.enabled", "true")
    conf.set("spark.eventLog.dir", "file:///home/jason/sparksqltest/myeventlog/eventlog.out")
    val logger = new PrintWriter(new File("logging/sparksql.out"))
    val sc = new SparkContext(conf)
    val sql = SparkQueries.importDataToRDD(sc)
    logger.write("Sending Query " + System.currentTimeMillis() + "\n")
    SparkQueries.getUserLocations(sql, sc)
    System.exit(0)
  }
}</code></p>
                <pagenum epub:type="pagebreak" id="p298" page="normal" smilref="Machine_Learning00014.smil#p298">298</pagenum>
                <p id="c11-c11-para-0112" xml:space="preserve"><span class="text" id="span_002287" smilref="Machine_Learning00014.smil#span_002287">As in the previous example, you create a </span><code xml:space="preserve" id="code_000897" smilref="Machine_Learning00014.smil#code_000897">SparkConfiguration</code><span class="text" id="span_002288" smilref="Machine_Learning00014.smil#span_002288"> object and give the application a name. You're also adding the master node of the Spark deployment (in this instance </span><code xml:space="preserve" id="code_000898" smilref="Machine_Learning00014.smil#code_000898">local</code><span class="text" id="span_002289" smilref="Machine_Learning00014.smil#span_002289"> as it's on the local machine).</span></p>
                <p id="c11-c11-para-0113" xml:space="preserve"><span class="text" id="span_002290" smilref="Machine_Learning00014.smil#span_002290">You've enabled the logging as well and given the name of the directory and file to write the event log to. You could extend the configuration and give the Spark scheduler a priority schedule for running the application in favor of others in the queue, but that's not a concern right now. You will also see the object </span><code xml:space="preserve" id="code_000899" smilref="Machine_Learning00014.smil#code_000899">SparkQueries</code><span class="text" id="span_002291" smilref="Machine_Learning00014.smil#span_002291"> being called to import the data to the RDD and run another method called </span><code xml:space="preserve" id="code_000900" smilref="Machine_Learning00014.smil#code_000900">getUserLocations</code><span class="text" id="span_002292" smilref="Machine_Learning00014.smil#span_002292"> to run a SQL query.</span></p>
              </level4>
              <level4 id="level4_000139">
                <h4 xml:space="preserve" id="h4_000139" smilref="Machine_Learning00014.smil#h4_000139">Building the Queries</h4>
                <p xml:space="preserve" id="p_000938" smilref="Machine_Learning00014.smil#p_000938">I suggest that you create a separate object for the queries to keep everything clean in terms of code. There's one object to run the job and one for the worker, very much like the Java MapReduce jobs.</p>
                <p id="c11-c11-para-0115" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0115">As I said at the start of the section, you're going to use the RDD to hold the data. This example creates a case class to define the schema object. If you think of a POJO, it's very similar in definition.</p>
                <p xml:space="preserve" id="p_000939"><code class="preserve-whitespace" xml:space="preserve" id="code_000901" smilref="Machine_Learning00014.smil#code_000901">case class Customer(guid: String, firstname: String, lastname: String, postcode: String, dob: String, latitude: Double, longitude: Double)</code></p>
                <p id="c11-c11-para-0116" xml:space="preserve"><span class="text" id="span_002293" smilref="Machine_Learning00014.smil#span_002293">You now need a way of importing the data from the </span><code xml:space="preserve" id="code_000902" smilref="Machine_Learning00014.smil#code_000902">.csv</code><span class="text" id="span_002294" smilref="Machine_Learning00014.smil#span_002294"> file into the Customer object. Previously in this chapter, you used the </span><code xml:space="preserve" id="code_000903" smilref="Machine_Learning00014.smil#code_000903">sc.textFile()</code><span class="text" id="span_002295" smilref="Machine_Learning00014.smil#span_002295"> method to pull in the data and store it as an RDD as an array datatype. With the new Customer object, you can map the values from each row of the </span><code xml:space="preserve" id="code_000904" smilref="Machine_Learning00014.smil#code_000904">.csv</code><span class="text" id="span_002296" smilref="Machine_Learning00014.smil#span_002296"> into the object:</span></p>
                <p xml:space="preserve" id="p_000940"><code class="preserve-whitespace" xml:space="preserve" id="code_000905" smilref="Machine_Learning00014.smil#code_000905">def importDataToRDD(sc: SparkContext) : SQLContext = {
    val sqlContext = new SQLContext(sc)
    val customers = sc.textFile("customers.csv").map(_.split(",")).map(c=&gt; Customer(c(0), c(1), c(2), c(3), c(4), c(5), c(6).toDouble, c(7).toDouble))
    customers.registerAsTable("customers")
    cacheTable("customers")
    sqlContext
  }</code></p>
                <pagenum epub:type="pagebreak" id="p299" page="normal" smilref="Machine_Learning00014.smil#p299">299</pagenum>
                <p id="c11-c11-para-0117" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0117">All the customer data is now in memory, so you can create a query to look at the data. The SparkSQL dialect is very similar to standard ANSI SQL. In this example, I create separate functions for each of my queries, mainly to keep the code readable and clean, and I pass in the Spark context and SQL context in the parameters:</p>
                <p xml:space="preserve" id="p_000941"><code class="preserve-whitespace" xml:space="preserve" id="code_000906" smilref="Machine_Learning00014.smil#code_000906">def getUserLocations(sqlContext: SQLContext, sc: SparkContext) {
    val query = "SELECT lastname, firstname, latitude, longitude FROM customers"
    sc.setJobDescription(query)
    val result = sqlContext.sql(cmd).collect.foreach(println)
  }</code></p>
                <p id="c11-c11-para-0118" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0118">The full object code looks like this:</p>
                <p xml:space="preserve" id="p_000942"><code class="preserve-whitespace" xml:space="preserve" id="code_000907" smilref="Machine_Learning00014.smil#code_000907">import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
import org.apache.spark.sql.SQLContext
case class Customer(guid: String,
    firstname: String,
    lastname: String,
    postcode: String,
    dob: String,
    latitude: Double,
    longitude: Double)
//This code just copied from shark context testing
object SparkQueries {
  def importDataToRDD(sc: SparkContext) : SQLContext = {
    val sqlContext = new SQLContext(sc)
    import sqlContext._
    val customers = sc.textFile("customers.csv").map(_.split(",")).map(c=&gt; Customer(c(0), c(1), c(2), c(3), c(4), c(5).toDouble, c(6).toDouble))
    customers.registerAsTable("customers")
    cacheTable("customers")
    sqlContext
  }
  def getUserLocations(sqlContext: SQLContext, sc: SparkContext) {
    val query = "SELECT lastname, firstname, latitude, longitude FROM customers"
    sc.setJobDescription(query)
    val result = sqlContext.sql(query).collect.foreach(println)
  }
}</code></p>
                <pagenum epub:type="pagebreak" id="p300" page="normal" smilref="Machine_Learning00014.smil#p300">300</pagenum>
                <p id="c11-c11-para-0119" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0119">With the two object files complete, you can build the project:</p>
                <p xml:space="preserve" id="p_000943"><code class="preserve-whitespace" xml:space="preserve" id="code_000908" smilref="Machine_Learning00014.smil#code_000908">Jason-Bells-MacBook-Pro:SparkSQLExample$ sbt package
[info] Set current project to SparkSQLExample (in build file:/Users/Jason/work/scala/SparkSQLExample/)
[info] Compiling 2 Scala sources to /Users/Jason/work/scala/SparkSQLExample/target/scala-2.10/classes…
[info] Packaging /Users/Jason/work/scala/SparkSQLExample/target/scala-2.10/sparksqlexample_2.10-1.0.jar …
[info] Done packaging.
[success] Total time: 9 s, completed 12-Jul-2014 14:25:05</code></p>
              </level4>
              <level4 id="level4_000140">
                <h4 xml:space="preserve" id="h4_000140" smilref="Machine_Learning00014.smil#h4_000140">Running the Project</h4>
                <p xml:space="preserve" id="p_000944"><span class="text" id="span_002297" smilref="Machine_Learning00014.smil#span_002297">Put the required </span><code xml:space="preserve" id="code_000909" smilref="Machine_Learning00014.smil#code_000909">jar</code><span class="text" id="span_002298" smilref="Machine_Learning00014.smil#span_002298"> file and the </span><code xml:space="preserve" id="code_000910" smilref="Machine_Learning00014.smil#code_000910">.csv</code><span class="text" id="span_002299" smilref="Machine_Learning00014.smil#span_002299"> data in a directory called </span><code xml:space="preserve" id="code_000911" smilref="Machine_Learning00014.smil#code_000911">sparksqldemo</code><span class="text" id="span_002300" smilref="Machine_Learning00014.smil#span_002300">:</span></p>
                <p xml:space="preserve" id="p_000945"><code class="preserve-whitespace" xml:space="preserve" id="code_000912" smilref="Machine_Learning00014.smil#code_000912">jason@cloudatics:˜/sparksqldemo$ ls -l
total 292
-rw------- 1 jason jason 269781 Jul 12 16:51 customers.csv
drwxr-xr-x 2 jason jason   4096 Jul 12 16:47 logging
drwxr-xr-x 3 jason jason   4096 Jul 12 16:47 myeventlog
-rw-r--r-- 1 jason jason  12673 Jul 12 16:50 sparksqlexample_2.10-1.0.jar
jason@cloudatics:˜/sparksqldemo$</code></p>
                <p id="c11-c11-para-0121" xml:space="preserve"><span class="text" id="span_002301" smilref="Machine_Learning00014.smil#span_002301">To run the program under Spark, use the </span><code xml:space="preserve" id="code_000913" smilref="Machine_Learning00014.smil#code_000913">spark-submit</code><span class="text" id="span_002302" smilref="Machine_Learning00014.smil#span_002302"> program:</span></p>
                <p xml:space="preserve" id="p_000946"><code class="preserve-whitespace" xml:space="preserve" id="code_000914" smilref="Machine_Learning00014.smil#code_000914">
/usr/local/spark/bin/spark-submit --class "SparkSQLExample" --master local[4] sparksqlexample_2.10-1.0.jar
</code></p>
                <p id="c11-c11-para-0122" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0122">There's a lot of console output when Spark runs the program, but there are some interesting things to look out for. First of all, you see SparkSQL importing the data into memory:</p>
                <p xml:space="preserve" id="p_000947"><code class="preserve-whitespace" xml:space="preserve" id="code_000915" smilref="Machine_Learning00014.smil#code_000915">14/07/12 17:00:44 INFO StringColumnBuilder: Compressor for [guid]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@2ce10a23, ratio: 1.0
14/07/12 17:00:44 INFO StringColumnBuilder: Compressor for [firstname]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@6a6096d9, ratio: 1.0
14/07/12 17:00:44 INFO StringColumnBuilder: Compressor for [lastname]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@6b4fb71e, ratio: 1.0
14/07/12 17:00:44 INFO StringColumnBuilder: Compressor for [postcode]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@3e7f499c, ratio: 1.0
14/07/12 17:00:44 INFO StringColumnBuilder: Compressor for [dob]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@16b9c0d2, ratio: 1.0
14/07/12 17:00:44 INFO FloatColumnBuilder: Compressor for [latitude]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@7d2226a5, ratio: 1.0
14/07/12 17:00:44 INFO FloatColumnBuilder: Compressor for [longitude]: org.apache.spark.sql.columnar.compression.PassThrough$Encoder@4d175ad1, ratio: 1.0</code></p>
                <pagenum epub:type="pagebreak" id="p301" page="normal" smilref="Machine_Learning00014.smil#p301">301</pagenum>
                <p id="c11-c11-para-0123" xml:space="preserve"><span class="text" id="span_002303" smilref="Machine_Learning00014.smil#span_002303">The query plan then shows the query that's running. The first line tells you the fields that are being returned. (In this example, they are </span><code xml:space="preserve" id="code_000916" smilref="Machine_Learning00014.smil#code_000916">lastname</code><span class="text" id="span_002304" smilref="Machine_Learning00014.smil#span_002304">, </span><code xml:space="preserve" id="code_000917" smilref="Machine_Learning00014.smil#code_000917">firstname</code><span class="text" id="span_002305" smilref="Machine_Learning00014.smil#span_002305">, </span><code xml:space="preserve" id="code_000918" smilref="Machine_Learning00014.smil#code_000918">latitude</code><span class="text" id="span_002306" smilref="Machine_Learning00014.smil#span_002306">, and </span><code xml:space="preserve" id="code_000919" smilref="Machine_Learning00014.smil#code_000919">longitude</code><span class="text" id="span_002307" smilref="Machine_Learning00014.smil#span_002307">).</span></p>
                <p xml:space="preserve" id="p_000948"><code class="preserve-whitespace" xml:space="preserve" id="code_000920" smilref="Machine_Learning00014.smil#code_000920">== Query Plan ==
Project [lastname#2:2,firstname#1:1,latitude#5:5,longitude#6:6]
 InMemoryColumnarTableScan [guid#0,firstname#1,lastname#2,postcode#3,dob#4,latitude#5,longitude#6], (ExistingRdd [guid#0,firstname#1,lastname#2,postcode#3,dob#4,latitude#5,longitude#6], MapPartitionsRDD[4] at mapPartitions at basicOperators.scala:174), false)
14/07/12 17:00:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
14/07/12 17:00:44 INFO TaskSetManager: Starting task 1.0:0 as TID 1 on executor localhost: localhost (PROCESS_LOCAL)
14/07/12 17:00:44 INFO TaskSetManager: Serialized task 1.0:0 as 2883 bytes in 0 ms
14/07/12 17:00:44 INFO Executor: Running task ID 1
14/07/12 17:00:44 INFO BlockManager: Found block broadcast_0 locally
14/07/12 17:00:44 INFO BlockManager: Found block rdd_7_0 locally
14/07/12 17:00:44 INFO Executor: Serialized size of result for 1 is 162709
14/07/12 17:00:44 INFO Executor: Sending result for 1 directly to driver
14/07/12 17:00:44 INFO Executor: Finished task ID 1
14/07/12 17:00:44 INFO TaskSetManager: Finished TID 1 in 543 ms on localhost (progress: 1/1)
14/07/12 17:00:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
14/07/12 17:00:44 INFO DAGScheduler: Completed ResultTask(1, 0)
14/07/12 17:00:44 INFO DAGScheduler: Stage 1 (collect at SparkQueries.scala:30) finished in 0.808 s
14/07/12 17:00:44 INFO SparkContext: Job finished: collect at SparkQueries.scala:30, took 0.849306003 s
[Thorpe,Maya,52.541897,1.624524]
[Cox,Ethan,52.67349,-2.078559]
[Glover,Imogen,52.47305,-0.963058]
[Smith,Sarah,50.54306,-3.720899]
[Reid,Christopher,50.855225,-0.599943]
[Iqbal,Oliver,50.808296,-2.644681]
[Little,Evie,52.01529,-1.95964]
[Flynn,Finley,51.381012,-3.258463]
</code></p>
              </level4>
              <level4 id="level4_000141">
                <h4 xml:space="preserve" id="h4_000141" smilref="Machine_Learning00014.smil#h4_000141">Using Object-Based Queries</h4>
                <pagenum epub:type="pagebreak" id="p302" page="normal" smilref="Machine_Learning00014.smil#p302">302</pagenum>
                <p xml:space="preserve" id="p_000949"><span class="text" id="span_002308" smilref="Machine_Learning00014.smil#span_002308">You're not just restricted to SQL-based queries. If you are used to object mapping, you might be more interested in object-based queries. Assuming that I have the customer objects in the RDD called Customers, I could easily query all the </span><code xml:space="preserve" id="code_000921" smilref="Machine_Learning00014.smil#code_000921">firstname</code><span class="text" id="span_002309" smilref="Machine_Learning00014.smil#span_002309">s with “George” as follows:</span></p>
                <p xml:space="preserve" id="p_000950"><code class="preserve-whitespace" xml:space="preserve" id="code_000922" smilref="Machine_Learning00014.smil#code_000922">val georges = customers.where('firstname="George").select('lastname)</code></p>
              </level4>
              <level4 id="level4_000142">
                <h4 xml:space="preserve" id="h4_000142" smilref="Machine_Learning00014.smil#h4_000142">A Java SparkSQL Example</h4>
                <p xml:space="preserve" id="p_000951"><span class="text" id="span_002310" smilref="Machine_Learning00014.smil#span_002310">As you can imagine, the Java version of the code is similar to the Scala version. Using a POJO for the </span><code xml:space="preserve" id="code_000923" smilref="Machine_Learning00014.smil#code_000923">customer</code><span class="text" id="span_002311" smilref="Machine_Learning00014.smil#span_002311"> class, you import the data into the RDD:</span></p>
                <p xml:space="preserve" id="p_000952"><code class="preserve-whitespace" xml:space="preserve" id="code_000924"><span class="text" id="span_002312" smilref="Machine_Learning00014.smil#span_002312">
import java.io.Serializable;
import java.util.List;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.sql.api.java.JavaSQLContext;
import org.apache.spark.sql.api.java.JavaSchemaRDD;
import org.apache.spark.sql.api.java.Row;
public class JavaSQLExample {
    public static class Customer implements Serializable {
        private String guid;
        private String firstname;
        private String lastname;
        private String postcode;
        private String dob;
        private Float latitude;
        private Float longitude;
        </span><pagenum epub:type="pagebreak" id="p303" page="normal" smilref="Machine_Learning00014.smil#p303">303</pagenum><span class="text" id="span_002313" smilref="Machine_Learning00014.smil#span_002313">public String getGuid() {
            return guid;
        }
        public void setGuid(String guid) {
            this.guid = guid;
        }
        public String getFirstname() {
            return firstname;
        }
        public void setFirstname(String firstname) {
            this.firstname = firstname;
        }
        public String getLastname() {
            return lastname;
        }
        public void setLastname(String lastname) {
            this.lastname = lastname;
        }
        public String getPostcode() {
            return postcode;
        }
        public void setPostcode(String postcode) {
            this.postcode = postcode;
        }
        public String getDob() {
            return dob;
        }
        public void setDob(String dob) {
            this.dob = dob;
        }
        public Float getLatitude() {
            return latitude;
        }
        public void setLatitude(Float latitude) {
            this.latitude = latitude;
        }
        public Float getLongitude() {
            return longitude;
        }
        </span><pagenum epub:type="pagebreak" id="p304" page="normal" smilref="Machine_Learning00014.smil#p304">304</pagenum><span class="text" id="span_002314" smilref="Machine_Learning00014.smil#span_002314">public void setLongitude(Float longitude) {
            this.longitude = longitude;
        }
    }
    public static void main(String[] args) throws Exception {
        SparkConf sparkConf = new SparkConf().setAppName("JavaSQLExample");
        JavaSparkContext ctx = new JavaSparkContext(sparkConf);
        JavaSQLContext sqlCtx = new JavaSQLContext(ctx);
        System.out.println("Load csv file into RDD");
        JavaRDD&lt;Customer&gt; customers = ctx.textFile("customers.csv").map(
          new Function&lt;String, Customer&gt;() {
            public Customer call(String line) throws Exception {
              String[] split = line.split(",");
              Customer customer = new Customer();
                customer.setGuid(split[0]);
                customer.setFirstname(split[1]);
                customer.setLastname(split[2]);
                customer.setPostcode(split[3]);
                customer.setDob(split[4]);
                customer.setLatitude(Float.parseFloat(split[5]));
                customer.setLongitude(Float.parseFloat(split[6]));
              return customer;
            }
          });
        JavaSchemaRDD customerSchema = sqlCtx.applySchema(customers, Customer.class);
        customerSchema.registerAsTable("customers");
        JavaSchemaRDD georges = sqlCtx.sql("SELECT lastname FROM customers WHERE firstname='George'");
        List&lt;String&gt; georgeList = georges.map(new Function&lt;Row, String&gt;() {
          public String call(Row row) {
            return "Lastname: " + row.getString(0);
          }
        }).collect();
        for (String lastname: georgeList) {
          System.out.println(lastname);
        }
    }
}
</span></code></p>
                <pagenum epub:type="pagebreak" id="p305" page="normal" smilref="Machine_Learning00014.smil#p305">305</pagenum>
                <p id="c11-c11-para-0126" xml:space="preserve"><span class="text" id="span_002315" smilref="Machine_Learning00014.smil#span_002315">To run the example, just run Maven to package up the </span><code xml:space="preserve" id="code_000925" smilref="Machine_Learning00014.smil#code_000925">jar</code><span class="text" id="span_002316" smilref="Machine_Learning00014.smil#span_002316"> file and then run with the </span><code xml:space="preserve" id="code_000926" smilref="Machine_Learning00014.smil#code_000926">spark-submit</code><span class="text" id="span_002317" smilref="Machine_Learning00014.smil#span_002317"> tool.</span></p>
                <p xml:space="preserve" id="p_000953"><code class="preserve-whitespace" xml:space="preserve" id="code_000927" smilref="Machine_Learning00014.smil#code_000927">$ /usr/local/spark/bin/spark-submit --class "JavaSQLExample" --master local[4] javasqlexample-1.0.jar</code></p>
                <p id="c11-c11-para-0127" xml:space="preserve"><span class="text" id="span_002318" smilref="Machine_Learning00014.smil#span_002318">Spark generates a lot of output while it starts up and imports the </span><code xml:space="preserve" id="code_000928" smilref="Machine_Learning00014.smil#code_000928">.csv</code><span class="text" id="span_002319" smilref="Machine_Learning00014.smil#span_002319"> file into memory. Finally the query runs and you see the results output to the console:</span></p>
                <p xml:space="preserve" id="p_000954"><code class="preserve-whitespace" xml:space="preserve" id="code_000929" smilref="Machine_Learning00014.smil#code_000929">14/08/25 23:03:19 INFO SparkContext: Job finished: collect at JavaSQLExample.java:110, took 1.664090864 s
Lastname: Dawson
Lastname: Power
Lastname: Stewart
Lastname: Stewart
Lastname: Young
Lastname: Cartwright
Lastname: Carr
Lastname: Chandler
Lastname: Begum
</code></p>
              </level4>
              <level4 id="level4_000143">
                <h4 xml:space="preserve" id="h4_000143" smilref="Machine_Learning00014.smil#h4_000143">Wrapping Up SparkSQL</h4>
                <p xml:space="preserve" id="p_000955" smilref="Machine_Learning00014.smil#p_000955">If you, or any of your team, have good knowledge of SQL, then it makes sense to look at SparkSQL, especially if you are trying to extract data from the RDDs. Although there are limitations of the SparkSQL language range, it covers the needs of most people in terms of SELECT and JOINS and so on.</p>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000101">
            <h2 id="c11-c011_level1_9" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c011_level1_9">Spark Streaming</h2>
            <p xml:space="preserve" id="p_000956" smilref="Machine_Learning00014.smil#p_000956">Chapter 9 discusses using Spring XD as a mechanism for ingesting data from various sources. Spark has a streaming ingestion engine, too, by way of Spark Streaming.</p>
            <level3 id="level3_000198">
              <h3 xml:space="preserve" id="h3_000198" smilref="Machine_Learning00014.smil#h3_000198">Basic Concepts</h3>
              <p xml:space="preserve" id="p_000957"><span class="text" id="span_002320" smilref="Machine_Learning00014.smil#span_002320">Spark Streaming can ingest data from a range of sources, such as ZeroMQ, Kafka, Flume, Twitter (more on that in a moment), and raw TCP sockets. As with Spring XD, </span><pagenum epub:type="pagebreak" id="p306" page="normal" smilref="Machine_Learning00014.smil#p306">306</pagenum><span class="text" id="span_002321" smilref="Machine_Learning00014.smil#span_002321">after data has entered the system, you have the option to process and manipulate the data coming in and then store it to an outbound location.</span></p>
              <p id="c11-c11-para-0131" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0131">Spark Streaming divides data into batches for processing, rather than handling one piece of data at a time as Spring XD does. Then Spark Streaming processes and hands those batches to the requested output. Spark calls them “micro batches.”</p>
              <p id="c11-c11-para-0132" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0132">Try creating a really basic example of a stream. You can use the raw TCP socket to emit some data and Spark Streaming to ingest it. Spark Streaming uses the concept of a DStream—a discretized stream—which is a continuous stream of data coming in for processing.</p>
            </level3>
            <level3 id="level3_000199">
              <h3 xml:space="preserve" id="h3_000199" smilref="Machine_Learning00014.smil#h3_000199">Creating Your First Stream with Scala</h3>
              <p xml:space="preserve" id="p_000958"><code xml:space="preserve" id="code_000930" smilref="Machine_Learning00014.smil#code_000930">StreamingContext</code><span class="text" id="span_002322" smilref="Machine_Learning00014.smil#span_002322">replaces the standard </span><code xml:space="preserve" id="code_000931" smilref="Machine_Learning00014.smil#code_000931">SparkContext</code><span class="text" id="span_002323" smilref="Machine_Learning00014.smil#span_002323"> as the main entry point. The code listing is pretty simple; it listens to the raw socket on port 9898 on localhost and then does a quick word count on the data coming in.</span></p>
              <p xml:space="preserve" id="p_000959"><code class="preserve-whitespace" xml:space="preserve" id="code_000932" smilref="Machine_Learning00014.smil#code_000932">import org.apache.spark.SparkConf
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.streaming.StreamingContext._
import org.apache.spark.storage.StorageLevel
object TCPIngester {
  def main(args: Array[String]) {
    val sparkConf = new SparkConf().setAppName("TCPIngester")
    val ssc = new StreamingContext(sparkConf, Seconds(1))
    val incomingLines = ssc.socketTextStream("localhost", 9898, StorageLevel.MEMORY_AND_DISK_SER)
    val words = lines.flatMap(_.split(" "))
    val counts = words.map(w =&gt; (w, 1)).reduceByKey(_ + _)
    counts.print()
    ssc.start()
    ssc.awaitTermination()
  }
}</code></p>
              <p id="c11-c11-para-0134" xml:space="preserve"><span class="text" id="span_002324" smilref="Machine_Learning00014.smil#span_002324">The code is very similar to the previous word count examples in this chapter. </span><code xml:space="preserve" id="code_000933" smilref="Machine_Learning00014.smil#code_000933">StreamingContext</code><span class="text" id="span_002325" smilref="Machine_Learning00014.smil#span_002325"> takes the configuration and also defines the amount of time to wait between processing the batches of data. In this example, you've asked for one second. The last two lines, though, are new, and they are required to ensure that Spark Streaming runs and monitors the stream.</span></p>
              <level4 id="level4_000144">
                <h4 xml:space="preserve" id="h4_000144" smilref="Machine_Learning00014.smil#h4_000144">The Build File</h4>
                <pagenum epub:type="pagebreak" id="p307" page="normal" smilref="Machine_Learning00014.smil#p307">307</pagenum>
                <p xml:space="preserve" id="p_000960" smilref="Machine_Learning00014.smil#p_000960">Use the following build file to ensure that the streaming example compiles and packages up properly:</p>
                <p xml:space="preserve" id="p_000961"><code class="preserve-whitespace" xml:space="preserve" id="code_000934" smilref="Machine_Learning00014.smil#code_000934">name := "StreamingExample"
version := "1.0"
scalaVersion := "2.10.4"
libraryDependencies += "org.apache.spark" %% "spark-core" % "1.0.0"
libraryDependencies += "org.apache.spark" % "spark-streaming_2.10" % "1.0.0"
resolvers += "Akka Repository" at "http://repo.akka.io/releases/"</code></p>
                <p id="c11-c11-para-0136" xml:space="preserve"><span class="text" id="span_002326" smilref="Machine_Learning00014.smil#span_002326">Then use the </span><code xml:space="preserve" id="code_000935" smilref="Machine_Learning00014.smil#code_000935">sbt</code><span class="text" id="span_002327" smilref="Machine_Learning00014.smil#span_002327"> tool to build the project. It might take a few minutes for the streaming libraries and its dependencies to download.</span></p>
                <p xml:space="preserve" id="p_000962"><code class="preserve-whitespace" xml:space="preserve" id="code_000936" smilref="Machine_Learning00014.smil#code_000936">Jason-Bells-MacBook-Pro:SparkStreaming Jason$ sbt package
[info] Set current project to StreamingExample (in build file:/Users/Jason/work/scala/SparkStreaming/)
[info] Updating {file:/Users/Jason/work/scala/SparkStreaming/}sparkstreaming…
[info] Resolving org.fusesource.jansi#jansi;1.4 …
[info] Done updating.
[info] Packaging /Users/Jason/work/scala/SparkStreaming/target/scala-2.10/streamingexample_2.10-1.0.jar …
[info] Done packaging.
[success] Total time: 9 s, completed 13-Jul-2014 10:48:58</code></p>
                <p id="c11-c11-para-0137" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0137">With everything compiled and packaged up you can test the project.</p>
              </level4>
              <level4 id="level4_000145">
                <h4 xml:space="preserve" id="h4_000145" smilref="Machine_Learning00014.smil#h4_000145">Testing the Project</h4>
                <p xml:space="preserve" id="p_000963" smilref="Machine_Learning00014.smil#p_000963">There are two parts to this test. One is the Spark Streaming program you've just created, and the second is finding some data to stream in.</p>
                <p id="c11-c11-para-0139" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0139">The example uses netcat to send the data out and uses the same port number (9898), to which the project will be listening. Start netcat first; otherwise, the Spark Streaming program will fail to bind to the host and port number and then throw an exception.</p>
                <pagenum epub:type="pagebreak" id="p308" page="normal" smilref="Machine_Learning00014.smil#p308">308</pagenum>
                <p id="c11-c11-para-0140" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0140">It's best to have two terminal windows open to perform this test. In a terminal window, start up netcat:</p>
                <p xml:space="preserve" id="p_000964"><code class="preserve-whitespace" xml:space="preserve" id="code_000937" smilref="Machine_Learning00014.smil#code_000937">nc -lp 10000</code></p>
                <p id="c11-c11-para-0141" xml:space="preserve"><span class="text" id="span_002328" smilref="Machine_Learning00014.smil#span_002328">There'll be no output to say it's started, it will just sit there waiting for input. In the other terminal window, you need to start the Spark Streaming project. Ensure that you have two local nodes running (as denoted by </span><code xml:space="preserve" id="code_000938" smilref="Machine_Learning00014.smil#code_000938">local[2]</code><span class="text" id="span_002329" smilref="Machine_Learning00014.smil#span_002329"> in the command line); otherwise, you won't get the reduced output:</span></p>
                <p xml:space="preserve" id="p_000965"><code class="preserve-whitespace" xml:space="preserve" id="code_000939" smilref="Machine_Learning00014.smil#code_000939">/usr/local/spark/bin/spark-submit --class "TCPIngester" --master local[2] streamingexample_2.-1.0.jar</code></p>
                <p id="c11-c11-para-0142" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0142">It's worth having the two terminal windows side by side, so you don't miss the output. Type some text into the terminal running netcat, and you see the stream ingesting the information:</p>
                <p xml:space="preserve" id="p_000966"><code class="preserve-whitespace" xml:space="preserve" id="code_000940" smilref="Machine_Learning00014.smil#code_000940">14/07/13 15:53:42 INFO BlockManagerInfo: Added input-0-1405256022600 in memory on cloudatics.com:55995 (size: 18.0 B, free: 297.0 MB)</code></p>
                <p id="c11-c11-para-0143" xml:space="preserve" smilref="Machine_Learning00014.smil#c11-c11-para-0143">You also see the reduced output:</p>
                <p xml:space="preserve" id="p_000967"><code class="preserve-whitespace" xml:space="preserve" id="code_000941" smilref="Machine_Learning00014.smil#code_000941">-------------------------------------------
Time: 1405258766000 ms
-------------------------------------------
(this,1)
(is,1)
(another,1)
(a,2)
(and,2)
(wibble,3)</code></p>
              </level4>
              <level4 id="level4_000146">
                <h4 xml:space="preserve" id="h4_000146" smilref="Machine_Learning00014.smil#h4_000146">Saving the Output</h4>
                <p xml:space="preserve" id="p_000968"><span class="text" id="span_002330" smilref="Machine_Learning00014.smil#span_002330">It's easy to extend this program further, adding the </span><code xml:space="preserve" id="code_000942" smilref="Machine_Learning00014.smil#code_000942">saveAsTextFiles</code><span class="text" id="span_002331" smilref="Machine_Learning00014.smil#span_002331"> method:</span></p>
                <p xml:space="preserve" id="p_000969"><code class="preserve-whitespace" xml:space="preserve" id="code_000943" smilref="Machine_Learning00014.smil#code_000943">counts.saveAsTextFiles("mystream_",".txt")</code></p>
                <p id="c11-c11-para-0145" xml:space="preserve"><span class="text" id="span_002332" smilref="Machine_Learning00014.smil#span_002332">After you've rebuilt the package with </span><code xml:space="preserve" id="code_000944" smilref="Machine_Learning00014.smil#code_000944">sbt</code><span class="text" id="span_002333" smilref="Machine_Learning00014.smil#span_002333"> and run the project again, you see the output written every second as a directory with an output file. With the stream processor running every second, it's sometimes hard to see what file the output is in, but using the </span><code xml:space="preserve" id="code_000945" smilref="Machine_Learning00014.smil#code_000945">find</code><span class="text" id="span_002334" smilref="Machine_Learning00014.smil#span_002334"> command can easily solve that.</span></p>
                <p xml:space="preserve" id="p_000970"><code class="preserve-whitespace" xml:space="preserve" id="code_000946" smilref="Machine_Learning00014.smil#code_000946">jason@cloudatics:˜/streamtestout$ ls -l
total 108
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259285000..txt
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259286000..txt
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259287000…txt
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259288000…txt
.
.
. (and so on ….)
.
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259309000…txt
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259310000…txt
drwxr-xr-x 2 jason jason 4096 Jul 13 16:48 mystream_-1405259311000…txt
jason@cloudatics:˜/streamtestout$ find . -type f -exec grep "ipsum" {} \; -print
(ipsum.,1)
(ipsum,1)
./mystream_-1405259294000…txt/part-00000</code></p>
              </level4>
            </level3>
            <level3 id="level3_000200">
              <h3 xml:space="preserve" id="h3_000200" smilref="Machine_Learning00014.smil#h3_000200">Creating Your First Stream with Java</h3>
              <pagenum epub:type="pagebreak" id="p309" page="normal" smilref="Machine_Learning00014.smil#p309">309</pagenum>
              <p xml:space="preserve" id="p_000971" smilref="Machine_Learning00014.smil#p_000971">The Java example works in the same way logically as the Scala example:</p>
              <p xml:space="preserve" id="p_000972"><code class="preserve-whitespace" xml:space="preserve" id="code_000947" smilref="Machine_Learning00014.smil#code_000947">import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import scala.Tuple2;
import com.google.common.collect.Lists;
import java.util.regex.Pattern;
public final class JavaStreaming {
  private static final Pattern SPACE = Pattern.compile(" ");
  public static void main(String[] args) {
    SparkConf sparkConf = new SparkConf().setAppName("JavaStreaming");
    JavaStreamingContext jsc = new JavaStreamingContext(sparkConf,  new Duration(1000));
    JavaReceiverInputDStream&lt;String&gt; incomingLines = ssc.socketTextStream(
            "127.0.0.1", 10000, StorageLevels.MEMORY_AND_DISK_SER);
    JavaDStream&lt;String&gt; words = incomingLines.flatMap(new FlatMapFunction&lt;String, String&gt;() {
      @Override
      public Iterable&lt;String&gt; call(String incomingLine) {
        return Lists.newArrayList(SPACE.split(incomingLine));
      }
    });
    JavaPairDStream&lt;String, Integer&gt; counts = words.mapToPair(
      new PairFunction&lt;String, String, Integer&gt;() {
        @Override
        public Tuple2&lt;String, Integer&gt; call(String s) {
          return new Tuple2&lt;String, Integer&gt;(s, 1);
        }
      }).reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {
        @Override
        public Integer call(Integer i1, Integer i2) {
          return i1 + i2;
        }
      });
    counts.print();
    jsc.start();
    jsc.awaitTermination();
  }
}</code></p>
              <pagenum epub:type="pagebreak" id="p310" page="normal" smilref="Machine_Learning00014.smil#p310">310</pagenum>
              <p id="c11-c11-para-0147" xml:space="preserve"><span class="text" id="span_002335" smilref="Machine_Learning00014.smil#span_002335">The </span><code xml:space="preserve" id="code_000948" smilref="Machine_Learning00014.smil#code_000948">pom.xml</code><span class="text" id="span_002336" smilref="Machine_Learning00014.smil#span_002336"> Maven build file has the dependencies for the Spark Streaming libraries and Google Guava libraries:</span></p>
              <p xml:space="preserve" id="p_000973"><code class="preserve-whitespace" xml:space="preserve" id="code_000949" smilref="Machine_Learning00014.smil#code_000949">&lt;project&gt;
  &lt;groupId&gt;com.mlbook&lt;/groupId&gt;
  &lt;artifactId&gt;javastreaming&lt;/artifactId&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;name&gt;Java Streaming Example&lt;/name&gt;
  &lt;packaging&gt;jar&lt;/packaging&gt;
  &lt;version&gt;1.0&lt;/version&gt;
  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;Akka repository&lt;/id&gt;
      &lt;url&gt;http://repo.akka.io/releases&lt;/url&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
      &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;
      &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;/dependency&gt;
      &lt;dependency&gt;
          &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
          &lt;artifactId&gt;spark-streaming_2.10&lt;/artifactId&gt;
          &lt;version&gt;1.0.0&lt;/version&gt;
      &lt;/dependency&gt;
     &lt;dependency&gt;
        &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
        &lt;artifactId&gt;guava&lt;/artifactId&gt;
        &lt;version&gt;17.0&lt;/version&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
&lt;/project&gt;</code></p>
              <pagenum epub:type="pagebreak" id="p311" page="normal" smilref="Machine_Learning00014.smil#p311">311</pagenum>
              <p id="c11-c11-para-0148" xml:space="preserve"><span class="text" id="span_002337" smilref="Machine_Learning00014.smil#span_002337">Running and testing the project is the same as the Scala version previously covered; all you need to do is run netcat and then ensure you're using the </span><code xml:space="preserve" id="code_000950" smilref="Machine_Learning00014.smil#code_000950">jar</code><span class="text" id="span_002338" smilref="Machine_Learning00014.smil#span_002338"> file that Maven has created with the following command:</span></p>
              <p xml:space="preserve" id="p_000974"><code class="preserve-whitespace" xml:space="preserve" id="code_000951" smilref="Machine_Learning00014.smil#code_000951">/usr/local/spark/bin/spark-submit --class "JavaStreaming" --master local[2] javastreaming-1.0.jar</code></p>
            </level3>
          </level2>
          <level2 id="level2_000102">
            <h2 id="c11-c011_level1_10" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c011_level1_10">MLib: The Machine Learning Library</h2>
            <p xml:space="preserve" id="p_000975" smilref="Machine_Learning00015.smil#p_000975">The Spark Machine Learning libraries provide Spark with some of the concepts covered earlier in the book with Weka. MLib provides the following,</p>
            <list type="ul" id="list_000068">
              <li id="li_000458" smilref="Machine_Learning00015.smil#li_000458">Support Vector Machines</li>
              <li id="li_000459" smilref="Machine_Learning00015.smil#li_000459">Linear Least Squares</li>
              <li id="li_000460" smilref="Machine_Learning00015.smil#li_000460">Decision Trees</li>
              <li id="li_000461" smilref="Machine_Learning00015.smil#li_000461">Naïve Bayes</li>
              <li id="li_000462" smilref="Machine_Learning00015.smil#li_000462">K-means Clustering</li>
            </list>
            <level3 id="level3_000201">
              <h3 xml:space="preserve" id="h3_000201" smilref="Machine_Learning00015.smil#h3_000201">Dependencies</h3>
              <p xml:space="preserve" id="p_000976" smilref="Machine_Learning00015.smil#p_000976">This is where things get a little involved. MLib is dependent on the ScalaNLP library called Breeze, which is dependent on netlib-java and jbias. If you're just going to want the use of linear calculations, then it might be a better idea to use other existing libraries, such as the Weka framework or the Apache Commons Math libraries.</p>
              <pagenum epub:type="pagebreak" id="p312" page="normal" smilref="Machine_Learning00015.smil#p312">312</pagenum>
              <p id="c11-c11-para-0151" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0151">Netlib-java requires low-level libraries to be installed. I'm going to concentrate on Linux-based systems (Debian and Ubuntu especially).</p>
              <p xml:space="preserve" id="p_000977"><code class="preserve-whitespace" xml:space="preserve" id="code_000952" smilref="Machine_Learning00015.smil#code_000952">sudo apt-get install libatlas3gf-base</code></p>
              <p id="c11-c11-para-0152" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0152">This installs the libfortran3 library as well. The netlib-java library is a required dependency to be added to the build file of any MLib project you are working on; it's not included in the Spark system.</p>
              <p xml:space="preserve" id="p_000978"><code class="preserve-whitespace" xml:space="preserve" id="code_000953"><span class="text" id="span_002339" smilref="Machine_Learning00015.smil#span_002339">"com.github.fommil.netlib" </span><strong id="strong_000756" smilref="Machine_Learning00015.smil#strong_000756">%</strong><span class="text" id="span_002340" smilref="Machine_Learning00015.smil#span_002340"> "all" </span><strong id="strong_000757" smilref="Machine_Learning00015.smil#strong_000757">%</strong><span class="text" id="span_002341" smilref="Machine_Learning00015.smil#span_002341"> "1.1.1" pomOnly</span><strong id="strong_000758" smilref="Machine_Learning00015.smil#strong_000758">()</strong></code></p>
              <p id="c11-c11-para-0153" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0153">The next two sections cover a couple of examples.</p>
            </level3>
            <level3 id="level3_000202">
              <h3 xml:space="preserve" id="h3_000202" smilref="Machine_Learning00015.smil#h3_000202">Decision Trees</h3>
              <p xml:space="preserve" id="p_000979" smilref="Machine_Learning00015.smil#p_000979">Chapter 3 covers decision trees and uses Weka to produce a system to decide the best place to put a CD based on previous sales patterns. The walkthrough of the theory examines the notion of entropy-based classification.</p>
              <p id="c11-c11-para-0155" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0155">Try walking through the code block by block. First, you need to import some data from a file (or a datastore) and convert it into vector classes. Be careful, as the vectors in MLib are different than the Java and Scala vectors. If you run into problems, make sure that you are importing the right ones.</p>
              <p xml:space="preserve" id="p_000980"><code class="preserve-whitespace" xml:space="preserve" id="code_000954" smilref="Machine_Learning00015.smil#code_000954">val inputData = sc.textFile("/home/jason/mlibtestdata.csv")
val mldata = data.map { line =&gt;
  val parts = line.split(',').map(_.toDouble)
  LabeledPoint(parts(0), Vectors.dense(parts.tail))
}</code></p>
              <p id="c11-c11-para-0156" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0156">Then run the algorithm to determine the decision tree:</p>
              <p xml:space="preserve" id="p_000981"><code class="preserve-whitespace" xml:space="preserve" id="code_000955" smilref="Machine_Learning00015.smil#code_000955">val model = DecisionTree.train(mldata, Classification, Entropy, 5)</code></p>
              <p id="c11-c11-para-0157" xml:space="preserve"><span class="text" id="span_002342" smilref="Machine_Learning00015.smil#span_002342">The </span><code xml:space="preserve" id="code_000956" smilref="Machine_Learning00015.smil#code_000956">.train</code><span class="text" id="span_002343" smilref="Machine_Learning00015.smil#span_002343"> method takes the loaded data, the algorithm (in this case </span><code xml:space="preserve" id="code_000957" smilref="Machine_Learning00015.smil#code_000957">Classification</code><span class="text" id="span_002344" smilref="Machine_Learning00015.smil#span_002344">), an impurity type (</span><code xml:space="preserve" id="code_000958" smilref="Machine_Learning00015.smil#code_000958">Entropy</code><span class="text" id="span_002345" smilref="Machine_Learning00015.smil#span_002345">, but you could have chosen </span><code xml:space="preserve" id="code_000959" smilref="Machine_Learning00015.smil#code_000959">Gini</code><span class="text" id="span_002346" smilref="Machine_Learning00015.smil#span_002346">), and the maximum depth of the tree.</span></p>
              <p id="c11-c11-para-0158" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0158">You can evaluate the classification and look at the predictions the algorithm has calculated. Finally, you output the training error rate (if there is one):</p>
              <p xml:space="preserve" id="p_000982"><code class="preserve-whitespace" xml:space="preserve" id="code_000960" smilref="Machine_Learning00015.smil#code_000960">val labelAndPreds = mldata.map { point =&gt;
  val prediction = model.predict(point.features)
  (point.label, prediction)
}
val trainErr = labelAndPreds.filter(r =&gt; r._1 != r._2).count.toDouble / parsedData.count
println("Training Error = " + trainErr)</code></p>
              <pagenum epub:type="pagebreak" id="p313" page="normal" smilref="Machine_Learning00015.smil#p313">313</pagenum>
              <p id="c11-c11-para-0159" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0159">If you extend this basic code further, you could store the final model so it can be reused.</p>
            </level3>
            <level3 id="level3_000203">
              <h3 xml:space="preserve" id="h3_000203" smilref="Machine_Learning00015.smil#h3_000203">Clustering</h3>
              <p xml:space="preserve" id="p_000983" smilref="Machine_Learning00015.smil#p_000983">The k-means clustering algorithm is very useful to construct within Spark MLib. It's so easy that it could be run in the Spark shell to test it.</p>
              <p id="c11-c11-para-0161" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0161">Like the decision tree example, you load in some data and then define the algorithm you're going to use:</p>
              <p xml:space="preserve" id="p_000984"><code class="preserve-whitespace" xml:space="preserve" id="code_000961" smilref="Machine_Learning00015.smil#code_000961">val inputData = sc.textFile("/home/jason/mlibkmeans/trainingdata.txt")
val parsedData = inputData.map(s =&gt; Vectors.dense(s.split(' ').map(_.toDouble)))</code></p>
              <p id="c11-c11-para-0162" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0162">In this case, the k-means object trains the data, and you need to define the number of clusters and the number of iterations you want the algorithm to run:</p>
              <p xml:space="preserve" id="p_000985"><code class="preserve-whitespace" xml:space="preserve" id="code_000962" smilref="Machine_Learning00015.smil#code_000962">val numberOfClusters = 4
val numberOfIterations = 40
val clusters = KMeans.train(parsedData, numberOfClusters, numberOfIterations)</code></p>
              <p id="c11-c11-para-0163" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0163">You can finally show the “Within Set Sum of Squared Errors” based on the trained k-means algorithm:</p>
              <p xml:space="preserve" id="p_000986"><code class="preserve-whitespace" xml:space="preserve" id="code_000963" smilref="Machine_Learning00015.smil#code_000963">val WSSSE = clusters.computeCost(parsedData)
println("WSSSE = " + WSSSE)</code></p>
            </level3>
          </level2>
          <level2 id="level2_000103">
            <h2 id="c11-c011_level1_11" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c011_level1_11">Summary</h2>
            <p xml:space="preserve" id="p_000987" smilref="Machine_Learning00015.smil#p_000987">This chapter is a whistle-stop tour of the core Spark system and a number of the projects that work along with it. At the time of writing, Spark had just hit version 1.0, but it's still considered cutting edge in terms of the landscape of machine learning and data tools.</p>
            <p id="c11-c11-para-0165" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0165">That hasn't stopped folks from calling it the Hadoop replacement, but at the end of the day it comes down to finding the tools that work for you, not against you. If you have a good resource of Scala developers, then perhaps Spark is a good fit.</p>
            <p id="c11-c11-para-0166" xml:space="preserve" smilref="Machine_Learning00015.smil#c11-c11-para-0166">One thing to keep in mind with these sorts of cutting-edge projects is that the codebase is liable to change from version to version, and it's worth keeping on top of the mailing list discussions to see how the landscape is emerging.</p>
          </level2>
        </section>
      </level1>
      <level1 id="c12">
        <section epub:type="chapter" id="section_000013">
          <header id="header_000012">
            <h1 id="c12-c12" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12">Chapter 12 Machine Learning with R</h1>
          </header>
          <pagenum epub:type="pagebreak" id="p315" page="normal" smilref="Machine_Learning00015.smil#p315">315</pagenum>
          <p xml:space="preserve" id="p_000988"><span class="text" id="span_002347" smilref="Machine_Learning00015.smil#span_002347">When you're in a room of data scientists, statisticians, and math types, you'll hear one letter crop up again and again: the letter </span><em id="em_000354" smilref="Machine_Learning00015.smil#em_000354">R</em><span class="text" id="span_002348" smilref="Machine_Learning00015.smil#span_002348">. R is a programming language, and it's basically command-line driven. If you used the Spark shell in Chapter 11, then you're already familiar with the shell concept; R is the same. In addition to being used in the command-line shell, R can be written in code form and run.</span></p>
          <p id="c12-c12-para-0002" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0002">Why am I telling you all this? Well, on top of the programming skills that get mentioned, you might also be asked, “Do you do R?” After this chapter, you'll hopefully have a starting point to reply, “Yes!”</p>
          <level2 id="level2_000104">
            <h2 id="c12-c012_level1_1" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_1">Installing R</h2>
            <p xml:space="preserve" id="p_000989"><span class="text" id="span_002349" smilref="Machine_Learning00015.smil#span_002349">The R language comes ready to use for a number of operating systems. The download page at </span><code xml:space="preserve" id="code_000964"><a href="http://www.r-project.org" external="true" id="a_000317" smilref="Machine_Learning00015.smil#a_000317">http://www.r-project.org</a></code><span class="text" id="span_002350" smilref="Machine_Learning00015.smil#span_002350"> has a number of mirror sites, so pick a mirror that's closest to you. From the mirror, choose the download for your operating system.</span></p>
            <level3 id="level3_000204">
              <h3 xml:space="preserve" id="h3_000204" smilref="Machine_Learning00015.smil#h3_000204">Mac OSX</h3>
              <p xml:space="preserve" id="p_000990"><span class="text" id="span_002351" smilref="Machine_Learning00015.smil#span_002351">The current version of R (3.1.1 at time of writing) comes in two separate download types: one for users running Snow Leopard and the other for Mavericks. </span><pagenum epub:type="pagebreak" id="p316" page="normal" smilref="Machine_Learning00015.smil#p316">316</pagenum><span class="text" id="span_002352" smilref="Machine_Learning00015.smil#span_002352">The latter is built on XCode5 compiler binaries. Download the file and open it to install. It installs the R binaries to the </span><code xml:space="preserve" id="code_000965" smilref="Machine_Learning00015.smil#code_000965">/Applications</code><span class="text" id="span_002353" smilref="Machine_Learning00015.smil#span_002353"> folder.</span></p>
            </level3>
            <level3 id="level3_000205">
              <h3 xml:space="preserve" id="h3_000205" smilref="Machine_Learning00015.smil#h3_000205">Windows</h3>
              <p xml:space="preserve" id="p_000991"><span class="text" id="span_002354" smilref="Machine_Learning00015.smil#span_002354">The </span><code xml:space="preserve" id="code_000966" smilref="Machine_Learning00015.smil#code_000966">.exe</code><span class="text" id="span_002355" smilref="Machine_Learning00015.smil#span_002355"> download for Windows provides binaries for running on 32- or 64-bit machines. The base package download will provide you with everything you need to get started.</span></p>
            </level3>
            <level3 id="level3_000206">
              <h3 xml:space="preserve" id="h3_000206" smilref="Machine_Learning00015.smil#h3_000206">Linux</h3>
              <p xml:space="preserve" id="p_000992"><span class="text" id="span_002356" smilref="Machine_Learning00015.smil#span_002356">Binary downloads are available for Debian, Ubuntu, Red Hat, and SUSE Linux distributions. If you want to save some time (and effort) and you're running Debian or Ubuntu, then you can use </span><code xml:space="preserve" id="code_000967" smilref="Machine_Learning00015.smil#code_000967">apt-get</code><span class="text" id="span_002357" smilref="Machine_Learning00015.smil#span_002357"> to install the r-base and r-base-dev packages. Ensure that the repository package base is up-to-date first. For users of the RedHat family of distributions use the command </span><code xml:space="preserve" id="code_000968" smilref="Machine_Learning00015.smil#code_000968">sudo yum install R</code><span class="text" id="span_002358" smilref="Machine_Learning00015.smil#span_002358">.</span></p>
            </level3>
          </level2>
          <level2 id="level2_000105">
            <h2 id="c12-c012_level1_2" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_2">Your First Run</h2>
            <p xml:space="preserve" id="p_000993"><span class="text" id="span_002359" smilref="Machine_Learning00015.smil#span_002359">When you run R, you're presented with the basic R shell, as shown in </span><a id="c12-c12-fig-anc-0001" href="#c12-c12-fig-0001" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0001">Figure 12-1</a><span class="text" id="span_002360" smilref="Machine_Learning00015.smil#span_002360">. This is the main place where the work is done. It's sparse, but it does the job fine.</span></p>
            <figure id="figure_000106">
              <img class="center" src="images/c12f001.jpg" alt="image" id="img_000131" />
              <figcaption id="figcaption_000092">
                <p xml:space="preserve" id="p_000994"><span class="figureLabel" id="span_002361"><a id="c12-c12-fig-0001" href="#c12-c12-fig-anc-0001" external="false"><strong id="strong_000759" smilref="Machine_Learning00015.smil#strong_000759">Figure 12-1</strong></a></span><span class="text" id="span_002362" smilref="Machine_Learning00015.smil#span_002362"> The R Shell</span></p>
              </figcaption>
            </figure>
            <pagenum epub:type="pagebreak" id="p317" page="normal" smilref="Machine_Learning00015.smil#p317">317</pagenum>
            <p id="c12-c12-para-0008" xml:space="preserve"><span class="text" id="span_002363" smilref="Machine_Learning00015.smil#span_002363">If at any time you want help on a topic, you can use the </span><code xml:space="preserve" id="code_000969" smilref="Machine_Learning00015.smil#code_000969">help</code><span class="text" id="span_002364" smilref="Machine_Learning00015.smil#span_002364"> command. For example, if you want to know about Standard Deviation, just type </span><code xml:space="preserve" id="code_000970"><strong id="strong_000760" smilref="Machine_Learning00015.smil#strong_000760">help</strong><span class="text" id="span_002365" smilref="Machine_Learning00015.smil#span_002365">(</span><strong id="strong_000761" smilref="Machine_Learning00015.smil#strong_000761">sd</strong><span class="text" id="span_002366" smilref="Machine_Learning00015.smil#span_002366">)</span></code><span class="text" id="span_002367" smilref="Machine_Learning00015.smil#span_002367">, and R opens a new window with the information (see </span><a id="c12-c12-fig-anc-0002" href="#c12-c12-fig-0002" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0002">Figure 12-2</a><span class="text" id="span_002368" smilref="Machine_Learning00015.smil#span_002368">).</span></p>
            <figure id="figure_000107">
              <img class="center" src="images/c12f002.jpg" alt="image" id="img_000132" />
              <figcaption id="figcaption_000093">
                <p xml:space="preserve" id="p_000995"><span class="figureLabel" id="span_002369"><a id="c12-c12-fig-0002" href="#c12-c12-fig-anc-0002" external="false"><strong id="strong_000762" smilref="Machine_Learning00015.smil#strong_000762">Figure 12-2</strong></a></span><span class="text" id="span_002370" smilref="Machine_Learning00015.smil#span_002370"> R's help system</span></p>
              </figcaption>
            </figure>
            <p id="c12-c12-para-0009" xml:space="preserve"><span class="text" id="span_002371" smilref="Machine_Learning00015.smil#span_002371">You can quit the shell by either clicking the light switch on the top right of the program window (refer to </span><a href="#c12-c12-fig-0001" external="false" id="a_000318" smilref="Machine_Learning00015.smil#a_000318">Figure 12-1</a><span class="text" id="span_002372" smilref="Machine_Learning00015.smil#span_002372">) or by typing </span><strong id="strong_000763" smilref="Machine_Learning00015.smil#strong_000763">quit</strong><span class="text" id="span_002373" smilref="Machine_Learning00015.smil#span_002373">() on the command line.</span></p>
            <p id="c12-c12-para-0010" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0010">For basic needs, the R shell is fine and does the job well. For an actual development environment, you have to install some more software such as R-Studio.</p>
          </level2>
          <level2 id="level2_000106">
            <h2 id="c12-c012_level1_3" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_3">Installing R-Studio</h2>
            <p xml:space="preserve" id="p_000996"><span class="text" id="span_002374" smilref="Machine_Learning00015.smil#span_002374">The R-Studio project (see </span><a id="c12-c12-fig-anc-0003" href="#c12-c12-fig-0003" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0003">Figure 12-3</a><span class="text" id="span_002375" smilref="Machine_Learning00015.smil#span_002375">) is a commercial integrated development environment (IDE) for R. It comes in an open source community edition that is free to use. To download R-Studio IDE, visit </span><code xml:space="preserve" id="code_000971"><a href="http://www.rstudio.com/products/rstudio/download" external="true" id="a_000319" smilref="Machine_Learning00015.smil#a_000319">http://www.rstudio.com/products/rstudio/download</a></code><span class="text" id="span_002376" smilref="Machine_Learning00015.smil#span_002376"> and select your operating system type. Make sure that the R base binary is installed as described in the preceding section before you download R-Studio.</span></p>
            <figure id="figure_000108">
              <img class="center" src="images/c12f003.jpg" alt="image" id="img_000133" />
              <figcaption id="figcaption_000094">
                <p xml:space="preserve" id="p_000997"><span class="figureLabel" id="span_002377"><a id="c12-c12-fig-0003" href="#c12-c12-fig-anc-0003" external="false"><strong id="strong_000764" smilref="Machine_Learning00015.smil#strong_000764">Figure 12-3</strong></a></span><span class="text" id="span_002378" smilref="Machine_Learning00015.smil#span_002378"> R-Studio</span></p>
              </figcaption>
            </figure>
          </level2>
          <level2 id="level2_000107">
            <h2 id="c12-c012_level1_4" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_4">The R Basics</h2>
            <pagenum epub:type="pagebreak" id="p318" page="normal" smilref="Machine_Learning00015.smil#p318">318</pagenum>
            <p xml:space="preserve" id="p_000998"><span class="text" id="span_002379" smilref="Machine_Learning00015.smil#span_002379">To run through the R basics, I'm going to use the standard R development environment. The command-line prompt is a simple greater than sign (</span><code xml:space="preserve" id="code_000972" smilref="Machine_Learning00015.smil#code_000972">&gt;</code><span class="text" id="span_002380" smilref="Machine_Learning00015.smil#span_002380">).</span></p>
            <p id="c12-c12-para-0013" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0013">You can perform calculations on the command line, so adding numbers together is a trivial process, like so:</p>
            <p xml:space="preserve" id="p_000999"><code class="preserve-whitespace" xml:space="preserve" id="code_000973" smilref="Machine_Learning00015.smil#code_000973">&gt; 1+2
[1] 3
&gt;</code></p>
            <p id="c12-c12-para-0014" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0014">To get proper use from R, though, you need to think a little more programmatically.</p>
            <level3 id="level3_000207">
              <h3 xml:space="preserve" id="h3_000207" smilref="Machine_Learning00015.smil#h3_000207">Variables and Vectors</h3>
              <p xml:space="preserve" id="p_001000"><span class="text" id="span_002381" smilref="Machine_Learning00015.smil#span_002381">R supports variables as you would expect. To assign them, you can either use the equal sign (</span><code xml:space="preserve" id="code_000974" smilref="Machine_Learning00015.smil#code_000974">=</code><span class="text" id="span_002382" smilref="Machine_Learning00015.smil#span_002382">) or the less than sign and a hyphen together (</span><code xml:space="preserve" id="code_000975" smilref="Machine_Learning00015.smil#code_000975">&lt;-</code><span class="text" id="span_002383" smilref="Machine_Learning00015.smil#span_002383">):</span></p>
              <p xml:space="preserve" id="p_001001"><code class="preserve-whitespace" xml:space="preserve" id="code_000976" smilref="Machine_Learning00015.smil#code_000976">&gt; myage = 21
&gt; myageagain &lt;- 21
&gt; myage
[1] 21
&gt; myageagain
[1] 21
&gt;</code></p>
              <pagenum epub:type="pagebreak" id="p319" page="normal" smilref="Machine_Learning00015.smil#p319">319</pagenum>
              <p id="c12-c12-para-0016" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0016">Variables can also store string variables and other data types. The one you'll use most are numeric values.</p>
              <p id="c12-c12-para-0017" xml:space="preserve"><span class="text" id="span_002384" smilref="Machine_Learning00015.smil#span_002384">Lists of data are held in arrays, called </span><em id="em_000355" smilref="Machine_Learning00015.smil#em_000355">vectors</em><span class="text" id="span_002385" smilref="Machine_Learning00015.smil#span_002385"> in R, and are defined with the </span><code xml:space="preserve" id="code_000977" smilref="Machine_Learning00015.smil#code_000977">c()</code><span class="text" id="span_002386" smilref="Machine_Learning00015.smil#span_002386"> function.</span></p>
              <p xml:space="preserve" id="p_001002"><code class="preserve-whitespace" xml:space="preserve" id="code_000978" smilref="Machine_Learning00015.smil#code_000978">&gt; lotterynums &lt;- c(2,7,20,35,36,42)
&gt; lotterynums
[1]  2  7 20 35 36 42</code></p>
              <p id="c12-c12-para-0018" xml:space="preserve"><span class="text" id="span_002387" smilref="Machine_Learning00015.smil#span_002387">Vectors can also hold strings. Using the </span><code xml:space="preserve" id="code_000979" smilref="Machine_Learning00015.smil#code_000979">length()</code><span class="text" id="span_002388" smilref="Machine_Learning00015.smil#span_002388"> function tells you how many elements are in the array.</span></p>
              <p xml:space="preserve" id="p_001003"><code class="preserve-whitespace" xml:space="preserve" id="code_000980" smilref="Machine_Learning00015.smil#code_000980">&gt; kc &lt;- c("Robert", "Adrian", "Tony", "Bill", "Pat", "Trey")
&gt; kc
[1] "Robert" "Adrian" "Tony"   "Bill"   "Pat"    "Trey"
&gt; length(kc)
[1] 6
&gt;</code></p>
              <p id="c12-c12-para-0019" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0019">To show specific values in the array, you can use the variable name and the element you want to show.</p>
              <p xml:space="preserve" id="p_001004"><code class="preserve-whitespace" xml:space="preserve" id="code_000981" smilref="Machine_Learning00015.smil#code_000981">&gt; kc[5]
[1] "Pat"</code></p>
            </level3>
            <level3 id="level3_000208">
              <h3 xml:space="preserve" id="h3_000208" smilref="Machine_Learning00015.smil#h3_000208">Matrices</h3>
              <p xml:space="preserve" id="p_001005" smilref="Machine_Learning00015.smil#p_001005">Now that you know how vector lists of numbers work, you can convert them into a matrix. To define a matrix, you take the data and then define how many rows and columns you require.</p>
              <p xml:space="preserve" id="p_001006"><code class="preserve-whitespace" xml:space="preserve" id="code_000982" smilref="Machine_Learning00015.smil#code_000982">&gt; mymatrix &lt;- matrix(c(1,2,3,4,5,6,7,8,9,10), nrow=2, ncol=5, byrow=TRUE)
&gt; mymatrix
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    2    3    4    5
[2,]    6    7    8    9   10
&gt;</code></p>
              <p id="c12-c12-para-0021" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0021">You can then retrieve data based on the row and column position.</p>
              <p xml:space="preserve" id="p_001007"><code class="preserve-whitespace" xml:space="preserve" id="code_000983" smilref="Machine_Learning00015.smil#code_000983">&gt; # by row, col
&gt; mymatrix[2,4]
[1] 9
&gt; # entire row
&gt; mymatrix[2,]
[1]  6  7  8  9 10
&gt; # entire col
&gt; mymatrix[,4]
[1] 4 9
&gt;</code></p>
              <pagenum epub:type="pagebreak" id="p320" page="normal" smilref="Machine_Learning00015.smil#p320">320</pagenum>
              <p id="c12-c12-para-0022" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0022">Instead of numeric row and column names, you can define text label names to make things more readable.</p>
              <p xml:space="preserve" id="p_001008"><code class="preserve-whitespace" xml:space="preserve" id="code_000984" smilref="Machine_Learning00015.smil#code_000984">&gt; dimnames(mymatrix) &lt;- list(c("row1","row2"),c("c1","c2","c3","c4","c5"))
&gt; mymatrix
     c1 c2 c3 c4 c5
row1  1  2  3  4  5
row2  6  7  8  9 10
&gt;</code></p>
              <p id="c12-c12-para-0023" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0023">You can reference data by row and column by using the row and column names you've just defined.</p>
              <p xml:space="preserve" id="p_001009"><code class="preserve-whitespace" xml:space="preserve" id="code_000985" smilref="Machine_Learning00015.smil#code_000985">&gt; mymatrix["row2", "c5"]
[1] 10</code></p>
            </level3>
            <level3 id="level3_000209">
              <h3 xml:space="preserve" id="h3_000209" smilref="Machine_Learning00015.smil#h3_000209">Lists</h3>
              <p xml:space="preserve" id="p_001010"><span class="text" id="span_002389" smilref="Machine_Learning00015.smil#span_002389">A </span><em id="em_000356" smilref="Machine_Learning00015.smil#em_000356">list</em><span class="text" id="span_002390" smilref="Machine_Learning00015.smil#span_002390"> is a vector containing other objects. This can be a mixture of objects (numeric, Boolean, and strings, for example) or other vectors within the list.</span></p>
              <p xml:space="preserve" id="p_001011"><code class="preserve-whitespace" xml:space="preserve" id="code_000986" smilref="Machine_Learning00015.smil#code_000986">&gt; nums &lt;- c(1,2,3,4,5)
&gt; strings &lt;- c("hello", "world", "again")
&gt; bools &lt;- (TRUE, FALSE)
Error: unexpected ',' in "bools &lt;- (TRUE,"
&gt; bools &lt;- c(TRUE, FALSE)
&gt; mylist &lt;- list(bools, strings, nums)
&gt; mylist
[[1]]
[1]  TRUE FALSE
[[2]]
[1] "hello" "world" "again"
[[3]]
[1] 1 2 3 4 5</code></p>
              <p id="c12-c12-para-0025" xml:space="preserve"><span class="text" id="span_002391" smilref="Machine_Learning00015.smil#span_002391">To retrieve the strings on their own, you can slice the list accordingly with the </span><code xml:space="preserve" id="code_000987" smilref="Machine_Learning00015.smil#code_000987">[]</code><span class="text" id="span_002392" smilref="Machine_Learning00015.smil#span_002392"> notation.</span></p>
              <p xml:space="preserve" id="p_001012"><code class="preserve-whitespace" xml:space="preserve" id="code_000988" smilref="Machine_Learning00015.smil#code_000988">
&gt; mylist[2]
[[1]]
[1] "hello" "world" "again"</code></p>
              <pagenum epub:type="pagebreak" id="p321" page="normal" smilref="Machine_Learning00015.smil#p321">321</pagenum>
              <p id="c12-c12-para-0026" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0026">To reference a member of the listed object directly, you have to use a double squared bracket. You can modify the member within the list as well.</p>
              <p xml:space="preserve" id="p_001013"><code class="preserve-whitespace" xml:space="preserve" id="code_000989" smilref="Machine_Learning00015.smil#code_000989">&gt; mylist[[2]][1]
[1] "hello"
&gt; mylist[[2]][1] &lt;- "goodbye"
&gt; mylist
[[1]]
[1]  TRUE FALSE
[[2]]
[1] "goodbye" "world"   "again"
[[3]]
[1] 1 2 3 4 5
&gt;
</code></p>
            </level3>
            <level3 id="level3_000210">
              <h3 xml:space="preserve" id="h3_000210" smilref="Machine_Learning00015.smil#h3_000210">Data Frames</h3>
              <p xml:space="preserve" id="p_001014"><em id="em_000357" smilref="Machine_Learning00015.smil#em_000357">Data frames</em><span class="text" id="span_002393" smilref="Machine_Learning00015.smil#span_002393"> are basically lists of vectors. The column count is the same in the vectors. R comes with some predefined data frames to play with. Using the </span><code xml:space="preserve" id="code_000990" smilref="Machine_Learning00015.smil#code_000990">head()</code><span class="text" id="span_002394" smilref="Machine_Learning00015.smil#span_002394"> function, you can see the top few lines of the data frame. This saves the entire contents of the frame being shown in the command line.</span></p>
              <p xml:space="preserve" id="p_001015"><code class="preserve-whitespace" xml:space="preserve" id="code_000991" smilref="Machine_Learning00015.smil#code_000991">&gt; data(USArrests)
&gt; head(USArrests)
           Murder Assault UrbanPop Rape
Alabama      13.2     236       58 21.2
Alaska       10.0     263       48 44.5
Arizona       8.1     294       80 31.0
Arkansas      8.8     190       50 19.5
California    9.0     276       91 40.6
Colorado      7.9     204       78 38.7</code></p>
              <p id="c12-c12-para-0028" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0028">You can reference data with the row and column positioning like you did with the matrices.</p>
              <p xml:space="preserve" id="p_001016"><code class="preserve-whitespace" xml:space="preserve" id="code_000992" smilref="Machine_Learning00015.smil#code_000992">&gt; USArrests["New York",]
         Murder Assault UrbanPop Rape
New York   11.1     254       86 26.1
&gt; USArrests["New York", "Assault"]
[1] 254</code></p>
            </level3>
            <level3 id="level3_000211">
              <h3 xml:space="preserve" id="h3_000211" smilref="Machine_Learning00015.smil#h3_000211">Installing Packages</h3>
              <pagenum epub:type="pagebreak" id="p322" page="normal" smilref="Machine_Learning00015.smil#p322">322</pagenum>
              <p xml:space="preserve" id="p_001017"><span class="text" id="span_002395" smilref="Machine_Learning00015.smil#span_002395">R comes with a comprehensive selection of packages that are available to download. You can see the Comprehensive R Archive Network (usually referred to as “CRAN”) packages that are available on the R website at </span><code xml:space="preserve" id="code_000993"><a href="http://www.r-project.org" external="true" id="a_000320" smilref="Machine_Learning00015.smil#a_000320">www.r-project.org</a></code><code xml:space="preserve" id="code_000994" smilref="Machine_Learning00015.smil#code_000994">/</code><span class="text" id="span_002396" smilref="Machine_Learning00015.smil#span_002396">. They are a broad spectrum of statistics, data-processing, and other tools.</span></p>
              <p id="c12-c12-para-0030" xml:space="preserve"><span class="text" id="span_002397" smilref="Machine_Learning00015.smil#span_002397">To install the packages, you use the </span><code xml:space="preserve" id="code_000995" smilref="Machine_Learning00015.smil#code_000995">install.packages()</code><span class="text" id="span_002398" smilref="Machine_Learning00015.smil#span_002398"> function from the R command line. It takes care of everything for you.</span></p>
              <p id="c12-c12-para-0031" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0031">For example, to install the tools for Approximate Bayesian Computation (ABC), you install the “abc” package:</p>
              <p xml:space="preserve" id="p_001018"><code class="preserve-whitespace" xml:space="preserve" id="code_000996" smilref="Machine_Learning00015.smil#code_000996">&gt;install.packages("abc")</code></p>
              <p id="c12-c12-para-0032" xml:space="preserve"><span class="text" id="span_002399" smilref="Machine_Learning00015.smil#span_002399">Some packages might require dependencies to be installed first, so it's prudent to use the </span><code xml:space="preserve" id="code_000997" smilref="Machine_Learning00015.smil#code_000997">dependencies</code><span class="text" id="span_002400" smilref="Machine_Learning00015.smil#span_002400"> flag to ensure they are installed, too.</span></p>
              <p xml:space="preserve" id="p_001019"><code class="preserve-whitespace" xml:space="preserve" id="code_000998" smilref="Machine_Learning00015.smil#code_000998">&gt;
also installing the dependencies 'SparseM', 'quantreg', 'locfit'
trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/SparseM_1.03.tgz'
Content type 'application/x-gzip' length 825491 bytes (806 Kb)
opened URL
==================================================
downloaded 806 Kb
trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/quantreg_5.05.tgz'
Content type 'application/x-gzip' length 1846783 bytes (1.8 Mb)
opened URL
==================================================
downloaded 1.8 Mb
trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/locfit_1.5-9.1.tgz'
Content type 'application/x-gzip' length 597404 bytes (583 Kb)
opened URL
==================================================
downloaded 583 Kb
trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/abc_2.0.tgz'
Content type 'application/x-gzip' length 5303210 bytes (5.1 Mb)
opened URL
==================================================
downloaded 5.1 Mb
The downloaded binary packages are in
/var/folders/b5/fz_57qk522nd6vqk2pd4lytr0000gn/T//RtmpOqHaEV/downloaded_packages</code></p>
              <pagenum epub:type="pagebreak" id="p323" page="normal" smilref="Machine_Learning00015.smil#p323">323</pagenum>
              <p id="c12-c12-para-0033" xml:space="preserve"><span class="text" id="span_002401" smilref="Machine_Learning00015.smil#span_002401">To use the library after it's installed, you call it with the </span><code xml:space="preserve" id="code_000999" smilref="Machine_Learning00015.smil#code_000999">library()</code><span class="text" id="span_002402" smilref="Machine_Learning00015.smil#span_002402"> function. It initializes and gives notice of the dependencies it has also loaded.</span></p>
              <p xml:space="preserve" id="p_001020"><code class="preserve-whitespace" xml:space="preserve" id="code_001000" smilref="Machine_Learning00015.smil#code_001000">&gt; library(abc)
Loading required package: nnet
Loading required package: quantreg
Loading required package: SparseM
Attaching package: 'SparseM'
The following object is masked from 'package:base':
    backsolve
Loading required package: MASS
Loading required package: locfit
locfit 1.5-9.1 2013-03-22</code></p>
            </level3>
            <level3 id="level3_000212">
              <h3 xml:space="preserve" id="h3_000212" smilref="Machine_Learning00015.smil#h3_000212">Loading in Data</h3>
              <p xml:space="preserve" id="p_001021" smilref="Machine_Learning00015.smil#p_001021">With the basic notions of variables, lists, and vectors in place, it's time to look at getting some data loaded into R.</p>
              <level4 id="level4_000147">
                <h4 xml:space="preserve" id="h4_000147" smilref="Machine_Learning00015.smil#h4_000147">CSV Files</h4>
                <p xml:space="preserve" id="p_001022"><span class="text" id="span_002403" smilref="Machine_Learning00015.smil#span_002403">The </span><code xml:space="preserve" id="code_001001" smilref="Machine_Learning00015.smil#code_001001">read.csv</code><span class="text" id="span_002404" smilref="Machine_Learning00015.smil#span_002404"> function reads a </span><code xml:space="preserve" id="code_001002" smilref="Machine_Learning00015.smil#code_001002">.csv</code><span class="text" id="span_002405" smilref="Machine_Learning00015.smil#span_002405"> file and loads it into a data frame.</span></p>
                <p xml:space="preserve" id="p_001023"><code class="preserve-whitespace" xml:space="preserve" id="code_001003" smilref="Machine_Learning00015.smil#code_001003">&gt; trans &lt;- read.csv('vdata.csv', header=TRUE, sep=',')
&gt; head(trans)
  wheels chassis pax vtype
1      4       2   4   Car
2      9      20  25   Bus
3      5      14  18   Bus
4      5       2   1   Car
5      9      17  25   Bus
6      1       1   1  Bike
&gt;</code></p>
                <p id="c12-c12-para-0036" xml:space="preserve"><span class="text" id="span_002406" smilref="Machine_Learning00015.smil#span_002406">If your </span><code xml:space="preserve" id="code_001004" smilref="Machine_Learning00015.smil#code_001004">.csv</code><span class="text" id="span_002407" smilref="Machine_Learning00015.smil#span_002407"> file has the column names in the first line, then use </span><code xml:space="preserve" id="code_001005" smilref="Machine_Learning00015.smil#code_001005">header=TRUE</code><span class="text" id="span_002408" smilref="Machine_Learning00015.smil#span_002408">; otherwise, set it to </span><code xml:space="preserve" id="code_001006" smilref="Machine_Learning00015.smil#code_001006">FALSE</code><span class="text" id="span_002409" smilref="Machine_Learning00015.smil#span_002409">. The separator is defined with the </span><code xml:space="preserve" id="code_001007" smilref="Machine_Learning00015.smil#code_001007">sep</code><span class="text" id="span_002410" smilref="Machine_Learning00015.smil#span_002410"> keyword, and you define whatever delimiter you want. If you have missing values, then it's wise to use the </span><code xml:space="preserve" id="code_001008" smilref="Machine_Learning00015.smil#code_001008">fill</code><span class="text" id="span_002411" smilref="Machine_Learning00015.smil#span_002411"> flag as well to ensure that your data will have the correct number of elements in each row.</span></p>
              </level4>
              <level4 id="level4_000148">
                <h4 xml:space="preserve" id="h4_000148" smilref="Machine_Learning00015.smil#h4_000148">MySQL Queries</h4>
                <pagenum epub:type="pagebreak" id="p324" page="normal" smilref="Machine_Learning00015.smil#p324">324</pagenum>
                <p xml:space="preserve" id="p_001024" smilref="Machine_Learning00015.smil#p_001024">Installing the RMySQL package gives you access to MySQL databases. You can pull queries into R so they can be processed.</p>
                <p xml:space="preserve" id="p_001025"><code class="preserve-whitespace" xml:space="preserve" id="code_001009" smilref="Machine_Learning00015.smil#code_001009">&gt;install.packages("RMySQL", dependencies=TRUE)</code></p>
                <p id="c12-c12-para-0038" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0038">If you are working on a Windows-based system then the library requires building for the source files. Two environment variables are required for the library to compile:</p>
                <p xml:space="preserve" id="p_001026"><code class="preserve-whitespace" xml:space="preserve" id="code_001010" smilref="Machine_Learning00015.smil#code_001010">&gt; Sys.setenv(PKG_CPPFLAGS = "-I/path/to/mysql/include/dir")
&gt; Sys.setenv(PKG_LIBS = "-L/path/to/library/dir -lmysqlclient")
&gt; install.packages("RMySQL", type = "source")</code></p>
                <p id="c12-c12-para-0039" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0039">As with Java code, you need to define a connection to the database before you can query it.</p>
                <p xml:space="preserve" id="p_001027"><code class="preserve-whitespace" xml:space="preserve" id="code_001011" smilref="Machine_Learning00015.smil#code_001011">&gt;con &lt;- dbConnect(MySQL(), user="myuser", password="mypass", dbname="mydb", host="localhost")</code></p>
                <p id="c12-c12-para-0040" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0040">From there, after you have a connection, you can see what tables are in the database.</p>
                <p xml:space="preserve" id="p_001028"><code class="preserve-whitespace" xml:space="preserve" id="code_001012" smilref="Machine_Learning00015.smil#code_001012">&gt;dbListTables(con)</code></p>
                <p id="c12-c12-para-0041" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0041">You then query a table. The data from the query is returned as a data frame.</p>
                <p xml:space="preserve" id="p_001029"><code class="preserve-whitespace" xml:space="preserve" id="code_001013" smilref="Machine_Learning00015.smil#code_001013">&gt;dta &lt;- dbGetQuery(con, "SELECT * FROM mytable")</code></p>
                <p id="c12-c12-para-0042" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0042">There are a number of other databases supported in R, including SQLite3, Postgresql, and Oracle.</p>
              </level4>
              <level4 id="level4_000149">
                <h4 xml:space="preserve" id="h4_000149" smilref="Machine_Learning00015.smil#h4_000149">Creating Random Sample Data</h4>
                <p xml:space="preserve" id="p_001030"><span class="text" id="span_002412" smilref="Machine_Learning00015.smil#span_002412">Perhaps you don't have any data to load or you just want to have a random sample of numbers to play with. Using the </span><code xml:space="preserve" id="code_001014" smilref="Machine_Learning00015.smil#code_001014">sample</code><span class="text" id="span_002413" smilref="Machine_Learning00015.smil#span_002413"> function, you can create a handy vector of numbers.</span></p>
                <p xml:space="preserve" id="p_001031"><code class="preserve-whitespace" xml:space="preserve" id="code_001015" smilref="Machine_Learning00015.smil#code_001015">&gt; sam &lt;- sample.int(1000, 20, replace=TRUE)
&gt; sam
 [1]  32 192 783 654 250 261 150 687 619 332 549 225 545 175 508 782 237 748 334 804</code></p>
              </level4>
            </level3>
            <level3 id="level3_000213">
              <h3 xml:space="preserve" id="h3_000213" smilref="Machine_Learning00015.smil#h3_000213">Plotting Data</h3>
              <p xml:space="preserve" id="p_001032" smilref="Machine_Learning00015.smil#p_001032">R supports basic plots of your data. They can take a little amount of getting use to with regard to the syntax, so the following sections provide a short primer.</p>
              <level4 id="level4_000150">
                <h4 xml:space="preserve" id="h4_000150" smilref="Machine_Learning00015.smil#h4_000150">Bar Charts</h4>
                <pagenum epub:type="pagebreak" id="p325" page="normal" smilref="Machine_Learning00015.smil#p325">325</pagenum>
                <p xml:space="preserve" id="p_001033"><span class="text" id="span_002414" smilref="Machine_Learning00015.smil#span_002414">How many bar charts did you draw at school? I drew far more than I care to remember, but R makes it easy for me now. (See </span><a id="c12-c12-fig-anc-0004" href="#c12-c12-fig-0004" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0004">Figure 12-4</a><span class="text" id="span_002415" smilref="Machine_Learning00015.smil#span_002415">.)</span></p>
                <p xml:space="preserve" id="p_001034"><code class="preserve-whitespace" xml:space="preserve" id="code_001016" smilref="Machine_Learning00015.smil#code_001016">&gt; sam &lt;- sample.int(1000, 20, replace=TRUE)
&gt; sam
 [1]  32 192 783 654 250 261 150 687 619 332 549 225 545 175 508 782 237 748 334 804
&gt; barplot(sam, main="My first plot", horiz=TRUE)</code></p>
                <figure id="figure_000109">
                  <img class="center" src="images/c12f004.jpg" alt="image" id="img_000134" />
                  <figcaption id="figcaption_000095">
                    <p xml:space="preserve" id="p_001035"><span class="figureLabel" id="span_002416"><a id="c12-c12-fig-0004" href="#c12-c12-fig-anc-0004" external="false"><strong id="strong_000765" smilref="Machine_Learning00015.smil#strong_000765">Figure 12-4</strong></a></span><span class="text" id="span_002417" smilref="Machine_Learning00015.smil#span_002417"> Horizontal bar chart</span></p>
                  </figcaption>
                </figure>
                <p id="c12-c12-para-0046" xml:space="preserve"><span class="text" id="span_002418" smilref="Machine_Learning00015.smil#span_002418">If you remove the </span><code xml:space="preserve" id="code_001017" smilref="Machine_Learning00015.smil#code_001017">horiz</code><span class="text" id="span_002419" smilref="Machine_Learning00015.smil#span_002419"> option, you get the bars travelling in a vertical direction, as shown in </span><a id="c12-c12-fig-anc-0005" href="#c12-c12-fig-0005" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0005">Figure 12-5</a><span class="text" id="span_002420" smilref="Machine_Learning00015.smil#span_002420">.</span></p>
                <p xml:space="preserve" id="p_001036"><code class="preserve-whitespace" xml:space="preserve" id="code_001018" smilref="Machine_Learning00015.smil#code_001018">&gt; barplot(sam, main="My first plot")</code></p>
                <figure id="figure_000110">
                  <img class="center" src="images/c12f005.jpg" alt="image" id="img_000135" />
                  <figcaption id="figcaption_000096">
                    <p xml:space="preserve" id="p_001037"><span class="figureLabel" id="span_002421"><a id="c12-c12-fig-0005" href="#c12-c12-fig-anc-0005" external="false"><strong id="strong_000766" smilref="Machine_Learning00015.smil#strong_000766">Figure 12-5</strong></a></span> <pagenum epub:type="pagebreak" id="p326" page="normal" smilref="Machine_Learning00015.smil#p326">326</pagenum><span class="text" id="span_002422" smilref="Machine_Learning00015.smil#span_002422">Vertical bar chart</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000151">
                <h4 xml:space="preserve" id="h4_000151" smilref="Machine_Learning00015.smil#h4_000151">Pie Charts</h4>
                <p xml:space="preserve" id="p_001038"><span class="text" id="span_002423" smilref="Machine_Learning00015.smil#span_002423">The pie charts in R are basic (see </span><a id="c12-c12-fig-anc-0006" href="#c12-c12-fig-0006" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0006">Figure 12-6</a><span class="text" id="span_002424" smilref="Machine_Learning00015.smil#span_002424">), but they get the job done. It's just a case of giving the pie chart values and labels. You can easily expand on this if necessary.</span></p>
                <p xml:space="preserve" id="p_001039"><code class="preserve-whitespace" xml:space="preserve" id="code_001019" smilref="Machine_Learning00015.smil#code_001019">&gt; pie(sam, main="First Pie Chart", labels=sam)</code></p>
                <figure id="figure_000111">
                  <img class="center" src="images/c12f006.jpg" alt="image" id="img_000136" />
                  <figcaption id="figcaption_000097">
                    <p xml:space="preserve" id="p_001040"><span class="figureLabel" id="span_002425"><a id="c12-c12-fig-0006" href="#c12-c12-fig-anc-0006" external="false"><strong id="strong_000767" smilref="Machine_Learning00015.smil#strong_000767">Figure 12-6</strong></a></span><span class="text" id="span_002426" smilref="Machine_Learning00015.smil#span_002426"> Simple pie chart</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000152">
                <h4 xml:space="preserve" id="h4_000152" smilref="Machine_Learning00015.smil#h4_000152">Dot Plots</h4>
                <p xml:space="preserve" id="p_001041"><span class="text" id="span_002427" smilref="Machine_Learning00015.smil#span_002427">The dot plot function (see </span><a id="c12-c12-fig-anc-0007" href="#c12-c12-fig-0007" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0007">Figure 12-7</a><span class="text" id="span_002428" smilref="Machine_Learning00015.smil#span_002428">) is a simple case of specifying a vector. You can also group the dot plot into specific sections if required.</span></p>
                <p xml:space="preserve" id="p_001042"><code class="preserve-whitespace" xml:space="preserve" id="code_001020" smilref="Machine_Learning00015.smil#code_001020">&gt; dotchart(sam, main="My Dot Chart", labels="Value", xlab="Frequency")</code></p>
                <figure id="figure_000112">
                  <img class="center" src="images/c12f007.jpg" alt="image" id="img_000137" />
                  <figcaption id="figcaption_000098">
                    <p xml:space="preserve" id="p_001043"><span class="figureLabel" id="span_002429"><a id="c12-c12-fig-0007" href="#c12-c12-fig-anc-0007" external="false"><strong id="strong_000768" smilref="Machine_Learning00015.smil#strong_000768">Figure 12-7</strong></a></span><span class="text" id="span_002430" smilref="Machine_Learning00015.smil#span_002430"> Simple dot plot</span></p>
                  </figcaption>
                </figure>
              </level4>
              <level4 id="level4_000153">
                <h4 xml:space="preserve" id="h4_000153" smilref="Machine_Learning00015.smil#h4_000153">Line Charts</h4>
                <pagenum epub:type="pagebreak" id="p327" page="normal" smilref="Machine_Learning00015.smil#p327">327</pagenum>
                <p xml:space="preserve" id="p_001044"><span class="text" id="span_002431" smilref="Machine_Learning00015.smil#span_002431">With two vectors of numbers, you can create a line chart, as shown in </span><a id="c12-c12-fig-anc-0008" href="#c12-c12-fig-0008" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0008">Figure 12-8</a><span class="text" id="span_002432" smilref="Machine_Learning00015.smil#span_002432">.</span></p>
                <p xml:space="preserve" id="p_001045"><code class="preserve-whitespace" xml:space="preserve" id="code_001021" smilref="Machine_Learning00015.smil#code_001021">&gt; sam1 &lt;- sample.int(10, 12, replace=TRUE)
&gt; sam1
 [1]  5 10  4  8  2  2  2  4  2  5  2  6
&gt; sam2 &lt;- sam1
&gt; plot(sam1, sam2)
&gt; lines(sam1, sam2, type="l")</code></p>
                <figure id="figure_000113">
                  <img class="center" src="images/c12f008.jpg" alt="image" id="img_000138" />
                  <figcaption id="figcaption_000099">
                    <p xml:space="preserve" id="p_001046"><span class="figureLabel" id="span_002433"><a id="c12-c12-fig-0008" href="#c12-c12-fig-anc-0008" external="false"><strong id="strong_000769" smilref="Machine_Learning00015.smil#strong_000769">Figure 12-8</strong></a></span><span class="text" id="span_002434" smilref="Machine_Learning00015.smil#span_002434"> Simple line chart</span></p>
                  </figcaption>
                </figure>
              </level4>
            </level3>
          </level2>
          <level2 id="level2_000108">
            <h2 id="c12-c012_level1_5" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_5">Simple Statistics</h2>
            <p xml:space="preserve" id="p_001047" smilref="Machine_Learning00015.smil#p_001047">R is about statistics; that's what it's built for. Unlike Java, Scala, or Python, R's syntax is a little unforgiving, but after a few sessions it becomes more natural.</p>
            <p id="c12-c12-para-0051" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0051">Try creating a simple vector of numbers, and then you can work through some functions. Start with the basics.</p>
            <p xml:space="preserve" id="p_001048"><code class="preserve-whitespace" xml:space="preserve" id="code_001022" smilref="Machine_Learning00015.smil#code_001022">&gt; s &lt;- sample(100, 12, replace=TRUE)
&gt; # get a basic summary of the vector: lowest value, 1st quartile, median, mean, 3rd quartile and maximum value
&gt; summary(s)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
   1.00    9.25   28.50   37.58   58.25   97.00
&gt; # just get the minimum
&gt; min(s)
[1] 1
&gt; # get the maximum value
&gt; max(s)
[1] 97
&gt; # get the average
&gt; mean(s)
[1] 37.58333
&gt; # get the median
&gt; median(s)
&gt; # get the standard deviation
&gt; sd(s)
[1] 31.57807
&gt; # use the table function to see the frequency of the data
&gt; table(s)
s
 1  5  7 10 22 25 32 55 57 62 78 97
 1  1  1  1  1  1  1  1  1  1  1  1</code></p>
            <pagenum epub:type="pagebreak" id="p328" page="normal" smilref="Machine_Learning00015.smil#p328">328</pagenum>
            <p id="c12-c12-para-0052" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0052">Obviously, you can reassign these function results as new variables or vectors. This gives you the basic outline of how the summaries work.</p>
          </level2>
          <level2 id="level2_000109">
            <h2 id="c12-c012_level1_6" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_6">Simple Linear Regression</h2>
            <pagenum epub:type="pagebreak" id="p329" page="normal" smilref="Machine_Learning00015.smil#p329">329</pagenum>
            <p xml:space="preserve" id="p_001049" smilref="Machine_Learning00015.smil#p_001049">This section gives an example of simple linear regression in R. It will give you a good idea of how things are put together. Here's the story: You have profit made based on the number of seconds that the sales team is on a call. If you know the profit made, can you calculate how long the call took?</p>
            <level3 id="level3_000214">
              <h3 xml:space="preserve" id="h3_000214" smilref="Machine_Learning00015.smil#h3_000214">Creating the Data</h3>
              <p xml:space="preserve" id="p_001050"><span class="text" id="span_002435" smilref="Machine_Learning00015.smil#span_002435">First, create two separate vectors: one for the number of seconds in the call (</span><code xml:space="preserve" id="code_001023" smilref="Machine_Learning00015.smil#code_001023">secondsCall</code><span class="text" id="span_002436" smilref="Machine_Learning00015.smil#span_002436">) and another for the amount of profit that was made (</span><code xml:space="preserve" id="code_001024" smilref="Machine_Learning00015.smil#code_001024">dollarProfit</code><span class="text" id="span_002437" smilref="Machine_Learning00015.smil#span_002437">).</span></p>
              <p xml:space="preserve" id="p_001051"><code class="preserve-whitespace" xml:space="preserve" id="code_001025" smilref="Machine_Learning00015.smil#code_001025">&gt; # setup the data
&gt; secondsCall &lt;- c(23,28,39,48,64,75,88,96,97,109,118,149,150,156,165)
&gt; dollarProfit &lt;- c(1,2,3,3,4,4,5,6,6,7,8,8,9,10,10)</code></p>
            </level3>
            <level3 id="level3_000215">
              <h3 xml:space="preserve" id="h3_000215" smilref="Machine_Learning00015.smil#h3_000215">The Initial Graph</h3>
              <p xml:space="preserve" id="p_001052"><span class="text" id="span_002438" smilref="Machine_Learning00015.smil#span_002438">You can create a simple plot for those values (see </span><a id="c12-c12-fig-anc-0009" href="#c12-c12-fig-0009" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0009">Figure 12-9</a><span class="text" id="span_002439" smilref="Machine_Learning00015.smil#span_002439">) by using the </span><code xml:space="preserve" id="code_001026" smilref="Machine_Learning00015.smil#code_001026">plot</code><span class="text" id="span_002440" smilref="Machine_Learning00015.smil#span_002440"> command.</span></p>
              <p xml:space="preserve" id="p_001053"><code class="preserve-whitespace" xml:space="preserve" id="code_001027" smilref="Machine_Learning00015.smil#code_001027">&gt; # create a simple plot
&gt; plot(secondsCall, dollarProfit)</code></p>
              <figure id="figure_000114">
                <img class="center" src="images/c12f009.jpg" alt="image" id="img_000139" />
                <figcaption id="figcaption_000100">
                  <p xml:space="preserve" id="p_001054"><span class="figureLabel" id="span_002441"><a id="c12-c12-fig-0009" href="#c12-c12-fig-anc-0009" external="false"><strong id="strong_000770" smilref="Machine_Learning00015.smil#strong_000770">Figure 12-9</strong></a></span><span class="text" id="span_002442" smilref="Machine_Learning00015.smil#span_002442"> Seconds/dollar plot</span></p>
                </figcaption>
              </figure>
            </level3>
            <level3 id="level3_000216">
              <h3 xml:space="preserve" id="h3_000216" smilref="Machine_Learning00015.smil#h3_000216">Regression with the Linear Model</h3>
              <pagenum epub:type="pagebreak" id="p330" page="normal" smilref="Machine_Learning00015.smil#p330">330</pagenum>
              <p xml:space="preserve" id="p_001055"><span class="text" id="span_002443" smilref="Machine_Learning00015.smil#span_002443">Within R, there is a command that will do the linear model for you: </span><code xml:space="preserve" id="code_001028" smilref="Machine_Learning00015.smil#code_001028">lm</code><span class="text" id="span_002444" smilref="Machine_Learning00015.smil#span_002444">. You can define the model and save it as a variable. The order of variables is dependent (</span><code xml:space="preserve" id="code_001029" smilref="Machine_Learning00015.smil#code_001029">secondsCall</code><span class="text" id="span_002445" smilref="Machine_Learning00015.smil#span_002445">), followed by a tilde symbol (</span><code xml:space="preserve" id="code_001030" smilref="Machine_Learning00015.smil#code_001030">˜</code><span class="text" id="span_002446" smilref="Machine_Learning00015.smil#span_002446">), and finally the independent variables (</span><code xml:space="preserve" id="code_001031" smilref="Machine_Learning00015.smil#code_001031">dollarProfit</code><span class="text" id="span_002447" smilref="Machine_Learning00015.smil#span_002447">).</span></p>
              <p xml:space="preserve" id="p_001056"><code class="preserve-whitespace" xml:space="preserve" id="code_001032" smilref="Machine_Learning00015.smil#code_001032">&gt; # define the linear model
&gt; model &lt;- lm(secondsCall ˜ dollarProfit)
&gt; model
Call:
lm(formula = secondsCall ˜ dollarProfit)
Coefficients:
 (Intercept)  dollarProfit
      0.6226       16.2286
&gt;</code></p>
              <p id="c12-c12-para-0057" xml:space="preserve"><span class="text" id="span_002448" smilref="Machine_Learning00015.smil#span_002448">So, you now know the intercept (0.6226) and the dollar profit amount of 16.22. You can expand on the model information using the </span><code xml:space="preserve" id="code_001033" smilref="Machine_Learning00015.smil#code_001033">summary</code><span class="text" id="span_002449" smilref="Machine_Learning00015.smil#span_002449"> command.</span></p>
              <p xml:space="preserve" id="p_001057"><code class="preserve-whitespace" xml:space="preserve" id="code_001034" smilref="Machine_Learning00015.smil#code_001034">&gt; # expend the summary of the model
&gt; summary(model)
Call:
lm(formula = secondsCall ˜ dollarProfit)
Residuals:
    Min      1Q  Median      3Q     Max
-12.451  -5.151  -1.308   4.734  18.549
Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)    0.6226     4.8981   0.127    0.901
dollarProfit  16.2286     0.7681  21.129  1.9e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 8.306 on 13 degrees of freedom
Multiple R-squared:  0.9717, Adjusted R-squared:  0.9695
F-statistic: 446.4 on 1 and 13 DF,  p-value: 1.898e-11</code></p>
              <p id="c12-c12-para-0058" xml:space="preserve"><span class="text" id="span_002450" smilref="Machine_Learning00015.smil#span_002450">So, you have a basic model that gives you a regression equation of </span><em id="em_000358" smilref="Machine_Learning00015.smil#em_000358">secondsCall</em><span class="text" id="span_002451" smilref="Machine_Learning00015.smil#span_002451"> = </span><em id="em_000359" smilref="Machine_Learning00015.smil#em_000359">0</em><span class="text" id="span_002452" smilref="Machine_Learning00015.smil#span_002452">.</span><em id="em_000360" smilref="Machine_Learning00015.smil#em_000360">6226</em><span class="text" id="span_002453" smilref="Machine_Learning00015.smil#span_002453"> + </span><em id="em_000361" smilref="Machine_Learning00015.smil#em_000361">16</em><span class="text" id="span_002454" smilref="Machine_Learning00015.smil#span_002454">.</span><em id="em_000362" smilref="Machine_Learning00015.smil#em_000362">2268</em><span class="text" id="span_002455" smilref="Machine_Learning00015.smil#span_002455"> * </span><em id="em_000363" smilref="Machine_Learning00015.smil#em_000363">profit amount</em><span class="text" id="span_002456" smilref="Machine_Learning00015.smil#span_002456">. To put the regression line on the plot, use the </span><code xml:space="preserve" id="code_001035" smilref="Machine_Learning00015.smil#code_001035">abline</code><span class="text" id="span_002457" smilref="Machine_Learning00015.smil#span_002457"> function.</span></p>
              <p xml:space="preserve" id="p_001058"><code class="preserve-whitespace" xml:space="preserve" id="code_001036" smilref="Machine_Learning00015.smil#code_001036">&gt; abline(model)</code></p>
            </level3>
            <level3 id="level3_000217">
              <h3 xml:space="preserve" id="h3_000217" smilref="Machine_Learning00015.smil#h3_000217">Making a Prediction</h3>
              <pagenum epub:type="pagebreak" id="p331" page="normal" smilref="Machine_Learning00015.smil#p331">331</pagenum>
              <p xml:space="preserve" id="p_001059"><span class="text" id="span_002458" smilref="Machine_Learning00015.smil#span_002458">Assume that someone made a $5 profit, and you want to know the duration of the call based on the model you've just created. Using the </span><code xml:space="preserve" id="code_001037" smilref="Machine_Learning00015.smil#code_001037">predict</code><span class="text" id="span_002459" smilref="Machine_Learning00015.smil#span_002459"> command, you can make the prediction.</span></p>
              <p xml:space="preserve" id="p_001060"><code class="preserve-whitespace" xml:space="preserve" id="code_001038" smilref="Machine_Learning00015.smil#code_001038">&gt; # make a basic prediction of someone making $5.
&gt; predict(model, newdata=data.frame(dollarProfit=5))
       1
81.76568
&gt;</code></p>
              <p id="c12-c12-para-0060" xml:space="preserve"><span class="text" id="span_002460" smilref="Machine_Learning00015.smil#span_002460">The prediction is that the person was on a call for 81 seconds. You can extend that by adding different </span><code xml:space="preserve" id="code_001039" smilref="Machine_Learning00015.smil#code_001039">interval</code><span class="text" id="span_002461" smilref="Machine_Learning00015.smil#span_002461"> types, which will give you the upper and lower prediction amounts based on the model.</span></p>
              <p xml:space="preserve" id="p_001061"><code class="preserve-whitespace" xml:space="preserve" id="code_001040" smilref="Machine_Learning00015.smil#code_001040">&gt; predict(model, newdata=data.frame(dollarProfit=5), interval="pred")
       fit      lwr      upr
1 81.76568 63.19372 100.3376
&gt; predict(model, newdata=data.frame(dollarProfit=5), interval="confidence")
       fit      lwr      upr
1 81.76568 76.97553 86.55583</code></p>
            </level3>
          </level2>
          <level2 id="level2_000110">
            <h2 id="c12-c012_level1_7" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_7">Basic Sentiment Analysis</h2>
            <p xml:space="preserve" id="p_001062" smilref="Machine_Learning00015.smil#p_001062">Chapter 9, where you ingested tweet data and showed the positive and negative scoring, covers basic sentiment analysis. The same is achievable in R with some basic coding. The text to rate could be anything from simple sentences typed in to reading in a Twitter stream or a file.</p>
            <level3 id="level3_000218">
              <h3 xml:space="preserve" id="h3_000218" smilref="Machine_Learning00015.smil#h3_000218">Functions to Load in Word Lists</h3>
              <p xml:space="preserve" id="p_001063" smilref="Machine_Learning00015.smil#p_001063">You need two sets of text files: one with the positive words and one with the negative words. You can write two quick functions to load the text files and save them to two separate lists.</p>
              <p xml:space="preserve" id="p_001064"><code class="preserve-whitespace" xml:space="preserve" id="code_001041" smilref="Machine_Learning00015.smil#code_001041">LoadPosWordSet&lt;-function(){
 iu.pos = scan("positive-words.txt", what='character', comment.char=";")
 pos.words = c(iu.pos)
 return(pos.words)
}</code></p>
              <pagenum epub:type="pagebreak" id="p332" page="normal" smilref="Machine_Learning00015.smil#p332">332</pagenum>
              <p id="c12-c12-para-0063" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0063">Then you do the same for the negative word list:</p>
              <p xml:space="preserve" id="p_001065"><code class="preserve-whitespace" xml:space="preserve" id="code_001042" smilref="Machine_Learning00015.smil#code_001042">LoadNegWordSet&lt;-function(){
 iu.neg = scan("negative-words.txt", what='character', comment.char=";")
 neg.words = c(iu.neg)
 return(neg.words)
}</code></p>
            </level3>
            <level3 id="level3_000219">
              <h3 xml:space="preserve" id="h3_000219" smilref="Machine_Learning00015.smil#h3_000219">Writing a Function to Score Sentiment</h3>
              <p xml:space="preserve" id="p_001066" smilref="Machine_Learning00015.smil#p_001066">You have a function that takes in a sentence and two word lists (positive and negative sentiment words). So now you can test it.</p>
              <p xml:space="preserve" id="p_001067"><code class="preserve-whitespace" xml:space="preserve" id="code_001043" smilref="Machine_Learning00015.smil#code_001043">GetScore&lt;-function(sentence, pos.words, neg.words) {
 sentence = gsub('[[:punct:]]', '', sentence)
 sentence = gsub('[[:cntrl:]]', '', sentence)
 sentence = gsub('\\d+', '', sentence)
 sentence = tolower(sentence)
 word.list = str_split(sentence, '\\s+')
 words = unlist(word.list)
 pos.matches = match(words, pos.words)
 neg.matches = match(words, neg.words)
 pos.matches = !is.na(pos.matches)
 neg.matches = !is.na(neg.matches)
 score = sum(pos.matches) - sum(neg.matches)
 return(score)
}</code></p>
              <p id="c12-c12-para-0065" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0065">The first thing that happens is the sentence is cleaned up with punctuation, control characters, and numbers removed. That should give you just a sentence of words; you then convert it into all lowercase letters.</p>
              <p id="c12-c12-para-0066" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0066">You split the sentence into a list of words and find out how many times the words match in the positive word list. You also do the same with the negative word list.</p>
              <p id="c12-c12-para-0067" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0067">With a positive score and negative score, you take the negative away from the positive to get the final score.</p>
              <p id="c12-c12-para-0068" xml:space="preserve"><span class="text" id="span_002462" smilref="Machine_Learning00015.smil#span_002462">You can save the functions as an R source file. You can either create it in a text editor or use the R-Studio editor to create the source file. For the purpose of this example, I save it all in a file called </span><code xml:space="preserve" id="code_001044" smilref="Machine_Learning00015.smil#code_001044">sentiment.r</code><span class="text" id="span_002463" smilref="Machine_Learning00015.smil#span_002463">.</span></p>
            </level3>
            <level3 id="level3_000220">
              <h3 xml:space="preserve" id="h3_000220" smilref="Machine_Learning00015.smil#h3_000220">Testing the Function</h3>
              <pagenum epub:type="pagebreak" id="p333" page="normal" smilref="Machine_Learning00015.smil#p333">333</pagenum>
              <p xml:space="preserve" id="p_001068" smilref="Machine_Learning00015.smil#p_001068">To test the sentiment code, you first need to load the code and the required library into R:</p>
              <p xml:space="preserve" id="p_001069"><code class="preserve-whitespace" xml:space="preserve" id="code_001045" smilref="Machine_Learning00015.smil#code_001045">&gt;install.packages("stringr")
&gt;library(stringr)
&gt;source('sentiment.r')
&gt; pos.words &lt;- LoadPosWordSet()
Read 2006 items
&gt; neg.words &lt;- LoadNegWordSet()
Read 4783 items</code></p>
              <p id="c12-c12-para-0070" xml:space="preserve"><span class="text" id="span_002464" smilref="Machine_Learning00015.smil#span_002464">So, you have 2,006 positive words and 4,783 negative words loaded. By using the </span><code xml:space="preserve" id="code_001046" smilref="Machine_Learning00015.smil#code_001046">GetScore</code><span class="text" id="span_002465" smilref="Machine_Learning00015.smil#span_002465"> method, you can get a score now on some text, and you can make up some to test. For example, here's a positive one:</span></p>
              <p xml:space="preserve" id="p_001070"><code class="preserve-whitespace" xml:space="preserve" id="code_001047" smilref="Machine_Learning00015.smil#code_001047">&gt; testscore&lt;-GetScore("This concert is the best thing I've been to!", pos.words, neg.words)
&gt; testscore
[1] 1</code></p>
              <p id="c12-c12-para-0071" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0071">As you can see the sentiment analysis gave a score of +1, so it's positive. Try a negative sentence:</p>
              <p xml:space="preserve" id="p_001071"><code class="preserve-whitespace" xml:space="preserve" id="code_001048" smilref="Machine_Learning00015.smil#code_001048">&gt; testscore2&lt;-GetScore("That's bad real bad, horrible", pos.words, neg.words)
&gt; testscore2
[1] -3</code></p>
              <p id="c12-c12-para-0072" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0072">With a negative string, you get a score of -3. With this basic function, you could process a list of sentences and create a bar graph of the scoring.</p>
            </level3>
          </level2>
          <level2 id="level2_000111">
            <h2 id="c12-c012_level1_8" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_8">Apriori Association Rules</h2>
            <p xml:space="preserve" id="p_001072"><span class="text" id="span_002466" smilref="Machine_Learning00015.smil#span_002466">With a set of transactions, you can run a basic Apriori algorithm. The R base system requires a package called </span><code xml:space="preserve" id="code_001049" smilref="Machine_Learning00015.smil#code_001049">arules</code><span class="text" id="span_002467" smilref="Machine_Learning00015.smil#span_002467"> to be installed before use.</span></p>
            <level3 id="level3_000221">
              <h3 xml:space="preserve" id="h3_000221" smilref="Machine_Learning00015.smil#h3_000221">Installing the ARules Package</h3>
              <pagenum epub:type="pagebreak" id="p334" page="normal" smilref="Machine_Learning00015.smil#p334">334</pagenum>
              <p xml:space="preserve" id="p_001073"><span class="text" id="span_002468" smilref="Machine_Learning00015.smil#span_002468">Before you get started you have to install the </span><code xml:space="preserve" id="code_001050" smilref="Machine_Learning00015.smil#code_001050">arules</code><span class="text" id="span_002469" smilref="Machine_Learning00015.smil#span_002469"> package:</span></p>
              <p xml:space="preserve" id="p_001074"><code class="preserve-whitespace" xml:space="preserve" id="code_001051" smilref="Machine_Learning00015.smil#code_001051">&gt; install.packages("arules", dependencies=TRUE)
also installing the dependencies 'colorspace', 'TSP', 'gclus', 'scatterplot3d', 'vcd', 'seriation', 'igraph', 'pmml', 'XML', 'arulesViz', 'testthat'
The downloaded binary packages are in /var/folders/b5/fz_57qk522nd6vqk2pd4lytr0000gn/T//Rtmpgp3zNQ/downloaded_packages
&gt; library(arules)
Loading required package: Matrix
Attaching package: 'arules'
The following objects are masked from 'package:base':
%in%, write
&gt;</code></p>
            </level3>
            <level3 id="level3_000222">
              <h3 xml:space="preserve" id="h3_000222" smilref="Machine_Learning00015.smil#h3_000222">The Training Data</h3>
              <p xml:space="preserve" id="p_001075"><span class="text" id="span_002470" smilref="Machine_Learning00015.smil#span_002470">I have prepared a basic </span><code xml:space="preserve" id="code_001052" smilref="Machine_Learning00015.smil#code_001052">.csv</code><span class="text" id="span_002471" smilref="Machine_Learning00015.smil#span_002471"> file with the basket ID and one item per line. You can see that there are repeating basket IDs to show that the basket contains multiple items. I've called my file </span><code xml:space="preserve" id="code_001053" smilref="Machine_Learning00015.smil#code_001053">transactions.csv</code><span class="text" id="span_002472" smilref="Machine_Learning00015.smil#span_002472">.</span></p>
              <p xml:space="preserve" id="p_001076"><code class="preserve-whitespace" xml:space="preserve" id="code_001054" smilref="Machine_Learning00015.smil#code_001054">1001,Fries
1001,Coffee
1001,Milk
1002,Coffee
1002,Fries
1003,Coffee
1003,Coke
1003,Eraser
1004,Coffee
1004,Fries
1004,Cookies
1005,Milk
1006,Coffee
1006,Milk
1007,Coffee
1007,Fries
1008,Fries
1008,Coke</code></p>
            </level3>
            <level3 id="level3_000223">
              <h3 xml:space="preserve" id="h3_000223" smilref="Machine_Learning00015.smil#h3_000223">Importing the Transaction Data</h3>
              <pagenum epub:type="pagebreak" id="p335" page="normal" smilref="Machine_Learning00015.smil#p335">335</pagenum>
              <p xml:space="preserve" id="p_001077"><span class="text" id="span_002473" smilref="Machine_Learning00015.smil#span_002473">With the </span><code xml:space="preserve" id="code_001055" smilref="Machine_Learning00015.smil#code_001055">read.transactions</code><span class="text" id="span_002474" smilref="Machine_Learning00015.smil#span_002474"> method, you load the </span><code xml:space="preserve" id="code_001056" smilref="Machine_Learning00015.smil#code_001056">.csv</code><span class="text" id="span_002475" smilref="Machine_Learning00015.smil#span_002475"> data into a </span><code xml:space="preserve" id="code_001057" smilref="Machine_Learning00015.smil#code_001057">transactions</code><span class="text" id="span_002476" smilref="Machine_Learning00015.smil#span_002476"> object. It works in a similar way to the </span><code xml:space="preserve" id="code_001058" smilref="Machine_Learning00015.smil#code_001058">read.csv</code><span class="text" id="span_002477" smilref="Machine_Learning00015.smil#span_002477"> function you saw at the start of the chapter.</span></p>
              <p id="c12-c12-para-0077" xml:space="preserve"><span class="text" id="span_002478" smilref="Machine_Learning00015.smil#span_002478">I'm setting the </span><code xml:space="preserve" id="code_001059" smilref="Machine_Learning00015.smil#code_001059">rm.duplicates</code><span class="text" id="span_002479" smilref="Machine_Learning00015.smil#span_002479"> flag to </span><code xml:space="preserve" id="code_001060" smilref="Machine_Learning00015.smil#code_001060">FALSE</code><span class="text" id="span_002480" smilref="Machine_Learning00015.smil#span_002480">, because I don't want basket items to be removed.</span></p>
              <p xml:space="preserve" id="p_001078"><code class="preserve-whitespace" xml:space="preserve" id="code_001061" smilref="Machine_Learning00015.smil#code_001061">&gt; transactions &lt;- read.transactions(file="transactions.csv", rm.duplicates=FALSE, format="single", sep=",", cols=c(1,2))
&gt; transactions
transactions in sparse format with
 8 transactions (rows) and
 6 items (columns)
&gt;</code></p>
              <p id="c12-c12-para-0078" xml:space="preserve"><span class="text" id="span_002481" smilref="Machine_Learning00015.smil#span_002481">As you can see, the </span><code xml:space="preserve" id="code_001062" smilref="Machine_Learning00015.smil#code_001062">transaction</code><span class="text" id="span_002482" smilref="Machine_Learning00015.smil#span_002482"> object knows there are eight transactions with six items. You can see the relative frequency of items graphically by using the </span><code xml:space="preserve" id="code_001063" smilref="Machine_Learning00015.smil#code_001063">itemFrequencyPlot</code><span class="text" id="span_002483" smilref="Machine_Learning00015.smil#span_002483"> function, which generates a graph like the one in </span><a id="c12-c12-fig-anc-0010" href="#c12-c12-fig-0010" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0010">Figure 12-10</a><span class="text" id="span_002484" smilref="Machine_Learning00015.smil#span_002484">.</span></p>
              <p xml:space="preserve" id="p_001079"><code class="preserve-whitespace" xml:space="preserve" id="code_001064" smilref="Machine_Learning00015.smil#code_001064">&gt; itemFrequencyPlot(transactions)</code></p>
              <figure id="figure_000115">
                <img class="center" src="images/c12f010.jpg" alt="image" id="img_000140" />
                <figcaption id="figcaption_000101">
                  <p xml:space="preserve" id="p_001080"><span class="figureLabel" id="span_002485"><a id="c12-c12-fig-0010" href="#c12-c12-fig-anc-0010" external="false"><strong id="strong_000771" smilref="Machine_Learning00015.smil#strong_000771">Figure 12-10</strong></a></span><span class="text" id="span_002486" smilref="Machine_Learning00015.smil#span_002486"> Transaction frequencies</span></p>
                </figcaption>
              </figure>
            </level3>
            <level3 id="level3_000224">
              <h3 xml:space="preserve" id="h3_000224" smilref="Machine_Learning00015.smil#h3_000224">Running the Apriori Algorithm</h3>
              <pagenum epub:type="pagebreak" id="p336" page="normal" smilref="Machine_Learning00015.smil#p336">336</pagenum>
              <p xml:space="preserve" id="p_001081" smilref="Machine_Learning00015.smil#p_001081">The function to run the algorithm is done in one line. You supply the transaction objects and a set of parameters. When you run the algorithm, you're presented with the resulting output. So, with a support of 0.5 and a confidence of 0.8 (the system is 80% confident), you get one association rule:</p>
              <p xml:space="preserve" id="p_001082"><code class="preserve-whitespace" xml:space="preserve" id="code_001065" smilref="Machine_Learning00015.smil#code_001065">&gt; minedbasketrules &lt;- apriori(transactions, parameter=list(sup=0.5, conf=0.8, target="rules"))
parameter specification:
 confidence minval smax arem  aval originalSupport support minlen maxlen target   ext
        0.8    0.1    1 none FALSE            TRUE     0.5      1     10  rules FALSE
algorithmic control:
 filter tree heap memopt load sort verbose
    0.1 TRUE TRUE  FALSE TRUE    2    TRUE
apriori - find association rules with the apriori algorithm
version 4.21 (2004.05.09)        (c) 1996-2004   Christian Borgelt
set item appearances …[0 item(s)] done [0.00s].
set transactions …[6 item(s), 8 transaction(s)] done [0.00s].
sorting and recoding items … [2 item(s)] done [0.00s].
creating transaction tree … done [0.00s].
checking subsets of size 1 2 done [0.00s].
writing … [1 rule(s)] done [0.00s].
creating S4 object  … done [0.00s].
&gt;</code></p>
            </level3>
            <level3 id="level3_000225">
              <h3 xml:space="preserve" id="h3_000225" smilref="Machine_Learning00015.smil#h3_000225">Inspecting the Results</h3>
              <p xml:space="preserve" id="p_001083"><span class="text" id="span_002487" smilref="Machine_Learning00015.smil#span_002487">Have a look at the one rule and see what it is. You use the </span><code xml:space="preserve" id="code_001066" smilref="Machine_Learning00015.smil#code_001066">inspect</code><span class="text" id="span_002488" smilref="Machine_Learning00015.smil#span_002488"> command to look at the result:</span></p>
              <p xml:space="preserve" id="p_001084"><code class="preserve-whitespace" xml:space="preserve" id="code_001067" smilref="Machine_Learning00015.smil#code_001067">&gt; inspect(minedbasketrules)
  lhs        rhs      support confidence     lift
1 {Fries} =&gt; {Coffee}     0.5        0.8 1.066667
&gt;</code></p>
              <p id="c12-c12-para-0081" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0081">There's an 80 percent chance that if someone buys fries, they'll also buy a coffee. If you had thousands or tens of thousands of transactions, then you would raise the confidence level and also be able to see more rules appearing.</p>
            </level3>
          </level2>
          <level2 id="level2_000112">
            <h2 id="c12-c012_level1_9" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c012_level1_9">Accessing R from Java</h2>
            <pagenum epub:type="pagebreak" id="p337" page="normal" smilref="Machine_Learning00015.smil#p337">337</pagenum>
            <p xml:space="preserve" id="p_001085"><span class="text" id="span_002489" smilref="Machine_Learning00015.smil#span_002489">Like the power of the Weka workbench can be accessed from a Java program, so too can R code. With the </span><code xml:space="preserve" id="code_001068" smilref="Machine_Learning00015.smil#code_001068">rJava</code><span class="text" id="span_002490" smilref="Machine_Learning00015.smil#span_002490"> bridge, you can run R within Java code and Java within R code.</span></p>
            <level3 id="level3_000226">
              <h3 xml:space="preserve" id="h3_000226" smilref="Machine_Learning00015.smil#h3_000226">Installing the rJava Package</h3>
              <p xml:space="preserve" id="p_001086"><span class="text" id="span_002491" smilref="Machine_Learning00015.smil#span_002491">Originally the </span><code xml:space="preserve" id="code_001069" smilref="Machine_Learning00015.smil#code_001069">rJava</code><span class="text" id="span_002492" smilref="Machine_Learning00015.smil#span_002492"> package was split along with the JRI package; installing them was a technical process at the time. Fortunately, that has all been replaced with a single binary that covers both packages.</span></p>
              <p xml:space="preserve" id="p_001087"><code class="preserve-whitespace" xml:space="preserve" id="code_001070" smilref="Machine_Learning00015.smil#code_001070">&gt; install.packages("rJava")
trying URL 'http://cran.rstudio.com/bin/macosx/mavericks/contrib/3.1/rJava_0.9-6.tgz'
Content type 'application/x-gzip' length 600621 bytes (586 Kb)
opened URL
==================================================
downloaded 586 Kb
The downloaded binary packages are in
/var/folders/b5/fz_57qk522nd6vqk2pd4lytr0000gn/T//Rtmpgp3zNQ/downloaded_packages
&gt;</code></p>
              <p id="c12-c12-para-0084" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0084">The rJava package uses JNI to talk to Java libraries. From the point of view of working within R, things might seem a little cumbersome, but they do work fine.</p>
            </level3>
            <level3 id="level3_000227">
              <h3 xml:space="preserve" id="h3_000227" smilref="Machine_Learning00015.smil#h3_000227">Your First Java Code in R</h3>
              <p xml:space="preserve" id="p_001088" smilref="Machine_Learning00015.smil#p_001088">Open your R console or R-Studio. Assuming you've installed the package as described earlier in this chapter, you can do the following:</p>
              <p xml:space="preserve" id="p_001089"><code class="preserve-whitespace" xml:space="preserve" id="code_001071" smilref="Machine_Learning00015.smil#code_001071">&gt; library(rJava)
&gt; .jinit()
&gt; stringobj &lt;- .jnew("java/lang/String", "This is a string as a Java object, in R!")
&gt; stringobj
[1] "Java-Object{This is a string as a Java object, in R!}"</code></p>
              <p id="c12-c12-para-0086" xml:space="preserve"><span class="text" id="span_002493" smilref="Machine_Learning00015.smil#span_002493">After the library is loaded, you need to initialize the rJava system with the </span><code xml:space="preserve" id="code_001072" smilref="Machine_Learning00015.smil#code_001072">.jinit()</code><span class="text" id="span_002494" smilref="Machine_Learning00015.smil#span_002494"> method. You then create a new variable in R that is going to contain </span><pagenum epub:type="pagebreak" id="p338" page="normal" smilref="Machine_Learning00015.smil#p338">338</pagenum><span class="text" id="span_002495" smilref="Machine_Learning00015.smil#span_002495">a Java string object. The </span><code xml:space="preserve" id="code_001073" smilref="Machine_Learning00015.smil#code_001073">.jnew()</code><span class="text" id="span_002496" smilref="Machine_Learning00015.smil#span_002496"> method creates a new String object and populates the string. Notice that you have to put the full Java package name in with a slashed notation and not the dotted one.</span></p>
              <p id="c12-c12-para-0087" xml:space="preserve"><span class="text" id="span_002497" smilref="Machine_Learning00015.smil#span_002497">If you want to find the location of the word “Java” in the string, you use Java's </span><code xml:space="preserve" id="code_001074" smilref="Machine_Learning00015.smil#code_001074">indexOf</code><span class="text" id="span_002498" smilref="Machine_Learning00015.smil#span_002498"> method. You can call it with rJava by executing the following:</span></p>
              <p xml:space="preserve" id="p_001090"><code class="preserve-whitespace" xml:space="preserve" id="code_001075" smilref="Machine_Learning00015.smil#code_001075">[1] "Java-Object{This is a string as a Java object, in R!}"
&gt; .jcall(stringobj, "I", "indexOf", "Java")
[1] 22</code></p>
              <p id="c12-c12-para-0088" xml:space="preserve"><span class="text" id="span_002499" smilref="Machine_Learning00015.smil#span_002499">The command looks involved. The first parameter is the existing object you previously created. The next is the return type </span><code xml:space="preserve" id="code_001076" smilref="Machine_Learning00015.smil#code_001076">from</code><span class="text" id="span_002500" smilref="Machine_Learning00015.smil#span_002500"> method; because the </span><code xml:space="preserve" id="code_001077" smilref="Machine_Learning00015.smil#code_001077">indexOf</code><span class="text" id="span_002501" smilref="Machine_Learning00015.smil#span_002501"> method returns an integer, you use the </span><code xml:space="preserve" id="code_001078" smilref="Machine_Learning00015.smil#code_001078">“I”</code><span class="text" id="span_002502" smilref="Machine_Learning00015.smil#span_002502"> in the calling method. Next is the method name—</span><code xml:space="preserve" id="code_001079" smilref="Machine_Learning00015.smil#code_001079">“indexOf”</code><span class="text" id="span_002503" smilref="Machine_Learning00015.smil#span_002503">—and last is the thing you're looking for, </span><code xml:space="preserve" id="code_001080" smilref="Machine_Learning00015.smil#code_001080">“Java”</code><span class="text" id="span_002504" smilref="Machine_Learning00015.smil#span_002504">. You see the result on the line underneath.</span></p>
              <p id="c12-c12-para-0089" xml:space="preserve"><span class="text" id="span_002505" smilref="Machine_Learning00015.smil#span_002505">For the full package information for the rJava interface, have a look at the method list at </span><code xml:space="preserve" id="code_001081"><a href="http://rforge.net/doc/packages/rJava/00Index.html" external="true" id="a_000321" smilref="Machine_Learning00015.smil#a_000321">http://rforge.net/doc/packages/rJava/00Index.html</a></code><span class="text" id="span_002506" smilref="Machine_Learning00015.smil#span_002506">.</span></p>
            </level3>
            <level3 id="level3_000228">
              <h3 xml:space="preserve" id="h3_000228" smilref="Machine_Learning00015.smil#h3_000228">Calling R from Java Programs</h3>
              <p xml:space="preserve" id="p_001091"><span class="text" id="span_002507" smilref="Machine_Learning00015.smil#span_002507">The interface for calling R from Java is called JRI. The files required to do this are all in the library that was installed from R. There are two components that your Java project requires: the </span><code xml:space="preserve" id="code_001082" smilref="Machine_Learning00015.smil#code_001082">jar</code><span class="text" id="span_002508" smilref="Machine_Learning00015.smil#span_002508"> file (called </span><code xml:space="preserve" id="code_001083" smilref="Machine_Learning00015.smil#code_001083">JRI.jar</code><span class="text" id="span_002509" smilref="Machine_Learning00015.smil#span_002509">) and the native library file (the name changes depending on the operating system you are using—on Mac OS X, it's called </span><code xml:space="preserve" id="code_001084" smilref="Machine_Learning00015.smil#code_001084">libjri.jnilib</code><span class="text" id="span_002510" smilref="Machine_Learning00015.smil#span_002510">).</span></p>
              <p xml:space="preserve" id="p_001092"><code class="preserve-whitespace" xml:space="preserve" id="code_001085" smilref="Machine_Learning00015.smil#code_001085">Jason-Bells-MacBook-Pro:jri Jason$ pwd
/Library/Frameworks/R.framework/Resources/library/rJava/jri
Jason-Bells-MacBook-Pro:jri Jason$ ls -l
total 256
-rw-r--r--  1 Jason  admin  31384 24 Apr 16:02 JRI.jar
-rw-r--r--  1 Jason  admin  10272 24 Apr 16:02 JRIEngine.jar
-rw-r--r--  1 Jason  admin  32354 24 Apr 16:02 REngine.jar
drwxr-xr-x  8 Jason  admin    272 24 Apr 16:02 examples
-rwxr-xr-x  1 Jason  admin  47500 24 Apr 16:02 libjri.jnilib
-rwxr-xr-x  1 Jason  admin    833 24 Apr 16:02 run
Jason-Bells-MacBook-Pro:jri Jason$ </code></p>
              <p id="c12-c12-para-0091" xml:space="preserve" smilref="Machine_Learning00015.smil#c12-c12-para-0091">You'll set up a basic Eclipse project and then you can see how the parts fit together. I developed the example on the Mac OS X operating system, but the variations on the other operating systems, such as Windows or Linux, are not that different.</p>
            </level3>
            <level3 id="level3_000229">
              <h3 xml:space="preserve" id="h3_000229" smilref="Machine_Learning00015.smil#h3_000229">Setting Up an Eclipse Project</h3>
              <p xml:space="preserve" id="p_001093"><span class="text" id="span_002511" smilref="Machine_Learning00015.smil#span_002511">Create a Java project and call it </span><code xml:space="preserve" id="code_001086" smilref="Machine_Learning00015.smil#code_001086">JRITest</code><span class="text" id="span_002512" smilref="Machine_Learning00015.smil#span_002512">. Go to the properties, click the Java Build Path, and add an external </span><code xml:space="preserve" id="code_001087" smilref="Machine_Learning00015.smil#code_001087">jar</code><span class="text" id="span_002513" smilref="Machine_Learning00015.smil#span_002513"> file. Now look for the </span><code xml:space="preserve" id="code_001088" smilref="Machine_Learning00015.smil#code_001088">JRI.jar</code><span class="text" id="span_002514" smilref="Machine_Learning00015.smil#span_002514"> file, which </span><pagenum epub:type="pagebreak" id="p339" page="normal" smilref="Machine_Learning00015.smil#p339">339</pagenum><span class="text" id="span_002515" smilref="Machine_Learning00015.smil#span_002515">is normally located in the </span><code xml:space="preserve" id="code_001089" smilref="Machine_Learning00015.smil#code_001089">/Library/Frameworks/R.framework/Resources/library/rJava/jri</code><span class="text" id="span_002516" smilref="Machine_Learning00015.smil#span_002516"> folder. (See </span><a id="c12-c12-fig-anc-0011" href="#c12-c12-fig-0011" external="false" smilref="Machine_Learning00015.smil#c12-c12-fig-anc-0011">Figure 12-11</a><span class="text" id="span_002517" smilref="Machine_Learning00015.smil#span_002517">.)</span></p>
              <figure id="figure_000116">
                <img class="center" src="images/c12f011.jpg" alt="image" id="img_000141" />
                <figcaption id="figcaption_000102">
                  <p xml:space="preserve" id="p_001094"><span class="figureLabel" id="span_002518"><a id="c12-c12-fig-0011" href="#c12-c12-fig-anc-0011" external="false"><strong id="strong_000772" smilref="Machine_Learning00015.smil#strong_000772">Figure 12-11</strong></a></span><span class="text" id="span_002519" smilref="Machine_Learning00015.smil#span_002519"> Adding the JRI.jar file to the project</span></p>
                </figcaption>
              </figure>
              <p id="c12-c12-para-0093" xml:space="preserve"><span class="text" id="span_002520" smilref="Machine_Learning00015.smil#span_002520">To make sure the R engine is working within Java, you're going to create a small test file to initialize the engine, load the built-in </span><code xml:space="preserve" id="code_001090" smilref="Machine_Learning00015.smil#code_001090">iris</code><span class="text" id="span_002521" smilref="Machine_Learning00015.smil#span_002521"> dataset, and iterate through an evaluation.</span></p>
            </level3>
            <level3 id="level3_000230">
              <h3 xml:space="preserve" id="h3_000230" smilref="Machine_Learning00015.smil#h3_000230">Creating the Java/R Class</h3>
              <p xml:space="preserve" id="p_001095" smilref="Machine_Learning00015.smil#p_001095">To create a new class, select File →New →Class and call the new file TestR.java.</p>
              <p xml:space="preserve" id="p_001096"><code class="preserve-whitespace" xml:space="preserve" id="code_001091"><strong id="strong_000773" smilref="Machine_Learning00015.smil#strong_000773">import</strong><span class="text" id="span_002522" smilref="Machine_Learning00015.smil#span_002522"> java.util.Enumeration;
</span><strong id="strong_000774" smilref="Machine_Learning00016.smil#strong_000774">import</strong><span class="text" id="span_002523" smilref="Machine_Learning00016.smil#span_002523"> org.rosuda.JRI.REXP;
</span><strong id="strong_000775" smilref="Machine_Learning00016.smil#strong_000775">import</strong><span class="text" id="span_002524" smilref="Machine_Learning00016.smil#span_002524"> org.rosuda.JRI.RVector;
</span><strong id="strong_000776" smilref="Machine_Learning00016.smil#strong_000776">import</strong><span class="text" id="span_002525" smilref="Machine_Learning00016.smil#span_002525"> org.rosuda.JRI.Rengine;
</span><strong id="strong_000777" smilref="Machine_Learning00016.smil#strong_000777">public</strong> <strong id="strong_000778" smilref="Machine_Learning00016.smil#strong_000778">class</strong><span class="text" id="span_002526" smilref="Machine_Learning00016.smil#span_002526"> TestR {
    </span><strong id="strong_000779" smilref="Machine_Learning00016.smil#strong_000779">public</strong> <strong id="strong_000780" smilref="Machine_Learning00016.smil#strong_000780">static</strong> <strong id="strong_000781" smilref="Machine_Learning00016.smil#strong_000781">void</strong><span class="text" id="span_002527" smilref="Machine_Learning00016.smil#span_002527"> main(String[] args) {
        Rengine rEngine = </span><strong id="strong_000782" smilref="Machine_Learning00016.smil#strong_000782">new</strong><span class="text" id="span_002528" smilref="Machine_Learning00016.smil#span_002528"> Rengine(</span><strong id="strong_000783" smilref="Machine_Learning00016.smil#strong_000783">new</strong><span class="text" id="span_002529" smilref="Machine_Learning00016.smil#span_002529"> String[] { "--vanilla" }, </span><strong id="strong_000784" smilref="Machine_Learning00016.smil#strong_000784">false</strong><span class="text" id="span_002530" smilref="Machine_Learning00016.smil#span_002530">, </span><strong id="strong_000785" smilref="Machine_Learning00016.smil#strong_000785">null</strong><span class="text" id="span_002531" smilref="Machine_Learning00016.smil#span_002531">);
        System.</span><em id="em_000364" smilref="Machine_Learning00016.smil#em_000364">out</em><span class="text" id="span_002532" smilref="Machine_Learning00016.smil#span_002532">.println("Waiting for R to create the engine.");
        </span><strong id="strong_000786" smilref="Machine_Learning00016.smil#strong_000786">if</strong><span class="text" id="span_002533" smilref="Machine_Learning00016.smil#span_002533"> (!rEngine.waitForR()) {
            System.</span><em id="em_000365" smilref="Machine_Learning00016.smil#em_000365">out</em><span class="text" id="span_002534" smilref="Machine_Learning00016.smil#span_002534">.println("Cannot load R engine.");
            </span><strong id="strong_000787" smilref="Machine_Learning00016.smil#strong_000787">return</strong><span class="text" id="span_002535" smilref="Machine_Learning00016.smil#span_002535">;
        }
        rEngine.eval("data(iris)", </span><strong id="strong_000788" smilref="Machine_Learning00016.smil#strong_000788">false</strong><span class="text" id="span_002536" smilref="Machine_Learning00016.smil#span_002536">);
        REXP exp = rEngine.eval("iris");
        RVector vector = exp.asVector();
        System.</span><em id="em_000366" smilref="Machine_Learning00016.smil#em_000366">out</em><span class="text" id="span_002537" smilref="Machine_Learning00016.smil#span_002537">.println("Outputting data:");
        </span><strong id="strong_000789" smilref="Machine_Learning00016.smil#strong_000789">for</strong><span class="text" id="span_002538" smilref="Machine_Learning00016.smil#span_002538"> (Enumeration e = vector.getNames().elements(); e.hasMoreElements();) {
            System.</span><em id="em_000367" smilref="Machine_Learning00016.smil#em_000367">out</em><span class="text" id="span_002539" smilref="Machine_Learning00016.smil#span_002539">.println(e.nextElement());
        }
      }
}</span></code></p>
              <p id="c12-c12-para-0095" xml:space="preserve"><span class="text" id="span_002540" smilref="Machine_Learning00016.smil#span_002540">The first thing that happens within the </span><code xml:space="preserve" id="code_001092" smilref="Machine_Learning00016.smil#code_001092">main</code><span class="text" id="span_002541" smilref="Machine_Learning00016.smil#span_002541"> method is to start up an R engine. Nothing works until this step is complete.</span></p>
              <p id="c12-c12-para-0096" xml:space="preserve"><span class="text" id="span_002542" smilref="Machine_Learning00016.smil#span_002542">Next, you pass an R command to load the </span><code xml:space="preserve" id="code_001093" smilref="Machine_Learning00016.smil#code_001093">iris</code><span class="text" id="span_002543" smilref="Machine_Learning00016.smil#span_002543"> data using the </span><code xml:space="preserve" id="code_001094" smilref="Machine_Learning00016.smil#code_001094">REngine.eval</code><span class="text" id="span_002544" smilref="Machine_Learning00016.smil#span_002544"> function. Last, you initialize an R vector within Java, convert the </span><code xml:space="preserve" id="code_001095" smilref="Machine_Learning00016.smil#code_001095">iris</code><span class="text" id="span_002545" smilref="Machine_Learning00016.smil#span_002545"> data to a vector, and then iterate the output.</span></p>
            </level3>
            <level3 id="level3_000231">
              <h3 xml:space="preserve" id="h3_000231" smilref="Machine_Learning00016.smil#h3_000231">Running the Example</h3>
              <p xml:space="preserve" id="p_001097" smilref="Machine_Learning00016.smil#p_001097">If you attempt to run the class now, you will get an error from Eclipse, because the R runtime library isn't linked to the project. You get the following error if the library isn't linked:</p>
              <p xml:space="preserve" id="p_001098"><code class="preserve-whitespace" xml:space="preserve" id="code_001096" smilref="Machine_Learning00016.smil#code_001096">Cannot find JRI native library!
Please make sure that the JRI native library is in a directory listed in java.library.path.
java.lang.UnsatisfiedLinkError: no jri in java.library.path
    at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1764)
    at java.lang.Runtime.loadLibrary0(Runtime.java:823)
    at java.lang.System.loadLibrary(System.java:1044)
    at org.rosuda.JRI.Rengine.&lt;clinit&gt;(Rengine.java:19)
    at TestR.main(TestR.java:10)</code></p>
              <p id="c12-c12-para-0098" xml:space="preserve"><span class="text" id="span_002546" smilref="Machine_Learning00016.smil#span_002546">To set that up, you need to look at the run configurations for the project. Select Run →Run Configurations and then click the </span><code xml:space="preserve" id="code_001097" smilref="Machine_Learning00016.smil#code_001097">TestR</code><span class="text" id="span_002547" smilref="Machine_Learning00016.smil#span_002547"> class. On the Arguments tab, you need to add a </span><code xml:space="preserve" id="code_001098" smilref="Machine_Learning00016.smil#code_001098">–D</code><span class="text" id="span_002548" smilref="Machine_Learning00016.smil#span_002548"> flag to the virtual machine arguments, as shown in </span><a id="c12-c12-fig-anc-0012" href="#c12-c12-fig-0012" external="false" smilref="Machine_Learning00016.smil#c12-c12-fig-anc-0012">Figure 12-12</a><span class="text" id="span_002549" smilref="Machine_Learning00016.smil#span_002549">.</span></p>
              <figure id="figure_000117">
                <img class="center" src="images/c12f012.jpg" alt="image" id="img_000142" />
                <figcaption id="figcaption_000103">
                  <p xml:space="preserve" id="p_001099"><span class="figureLabel" id="span_002550"><a id="c12-c12-fig-0012" href="#c12-c12-fig-anc-0012" external="false"><strong id="strong_000790" smilref="Machine_Learning00016.smil#strong_000790">Figure 12-12</strong></a></span> <pagenum epub:type="pagebreak" id="p341" page="normal" smilref="Machine_Learning00016.smil#p341">341</pagenum><span class="text" id="span_002551" smilref="Machine_Learning00016.smil#span_002551">Adding the JRI library path</span></p>
                </figcaption>
              </figure>
              <p id="c12-c12-para-0099" xml:space="preserve"><span class="text" id="span_002552" smilref="Machine_Learning00016.smil#span_002552">If you get an error about the </span><code xml:space="preserve" id="code_001099" smilref="Machine_Learning00016.smil#code_001099">R_HOME</code><span class="text" id="span_002553" smilref="Machine_Learning00016.smil#span_002553"> path not being set, then reopen the run configuration and click the Environments tab, as shown in </span><a id="c12-c12-fig-anc-0013" href="#c12-c12-fig-0013" external="false" smilref="Machine_Learning00016.smil#c12-c12-fig-anc-0013">Figure 12-13</a><span class="text" id="span_002554" smilref="Machine_Learning00016.smil#span_002554">. If you use windows locate the </span><code xml:space="preserve" id="code_001100" smilref="Machine_Learning00016.smil#code_001100">R.dll</code><span class="text" id="span_002555" smilref="Machine_Learning00016.smil#span_002555"> file on your system and add it to your Path.</span></p>
              <figure id="figure_000118">
                <img class="center" src="images/c12f013.jpg" alt="image" id="img_000143" />
                <figcaption id="figcaption_000104">
                  <p xml:space="preserve" id="p_001100"><span class="figureLabel" id="span_002556"><a id="c12-c12-fig-0013" href="#c12-c12-fig-anc-0013" external="false"><strong id="strong_000791" smilref="Machine_Learning00016.smil#strong_000791">Figure 12-13</strong></a></span><span class="text" id="span_002557" smilref="Machine_Learning00016.smil#span_002557"> Adding the environment R_HOME path</span></p>
                </figcaption>
              </figure>
              <p id="c12-c12-para-0100" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0100">Click Run and try again. This time you should see the correct output.</p>
              <p xml:space="preserve" id="p_001101"><code class="preserve-whitespace" xml:space="preserve" id="code_001101" smilref="Machine_Learning00016.smil#code_001101">Waiting for R to create the engine.
Outputting names:
Sepal.Length
Sepal.Width
Petal.Length
Petal.Width
Species</code></p>
            </level3>
            <level3 id="level3_000232">
              <h3 xml:space="preserve" id="h3_000232" smilref="Machine_Learning00016.smil#h3_000232">Extending Your R Implementations</h3>
              <pagenum epub:type="pagebreak" id="p342" page="normal" smilref="Machine_Learning00016.smil#p342">342</pagenum>
              <p xml:space="preserve" id="p_001102" smilref="Machine_Learning00016.smil#p_001102">The code you've just walked through gives you the basic framework for getting R functions and commands working from a Java program. The R examples you've seen in this chapter could be easily converted to a Java program using this method if you want. If you have an R expert on your team, then it might be prudent to have that person write the R functions first and then port them to Java.</p>
            </level3>
          </level2>
          <level2 id="level2_000113">
            <h2 id="c12-c012_level1_10" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c012_level1_10">R and Hadoop</h2>
            <p xml:space="preserve" id="p_001103" smilref="Machine_Learning00016.smil#p_001103">If you are of a delicate nature, then you might want to look away from this section. It is possible to run R jobs with Hadoop. When you look back at the date when the likes of R and Weka were first developed, the notion of the MapReduce paradigm existed, but it was not on the top of the list of most data crunchers.</p>
            <p id="c12-c12-para-0103" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0103">Over time, though, the volumes of data have increased dramatically. What hasn't progressed as much are the older tools. With large volumes of data, the memory implications make R difficult to use on a day-to-day basis. For small work, it's fine; when used for larger, more memory-intensive work, things might eventually break.</p>
            <level3 id="level3_000233">
              <h3 xml:space="preserve" id="h3_000233" smilref="Machine_Learning00016.smil#h3_000233">The RHadoop Project</h3>
              <p xml:space="preserve" id="p_001104" smilref="Machine_Learning00016.smil#p_001104">Revolution Analytics developed the RHadoop libraries, which enable you to use Hadoop to scale R jobs. This gives you full MapReduce capabilities on one or more Hadoop nodes.</p>
              <p id="c12-c12-para-0105" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0105">The RHadoop project requires you to have Hadoop 1.0.2 or later (Cloudera CDH3). R installs on each node that you are intending to use with a copy of the rmr2 package installed as well.</p>
              <p id="c12-c12-para-0106" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0106">Before you can download and install the rmr2 package you are required to have the following R packages installed:</p>
              <list type="ul" id="list_000069">
                <li id="li_000463" smilref="Machine_Learning00016.smil#li_000463">Rcpp</li>
                <li id="li_000464" smilref="Machine_Learning00016.smil#li_000464">RJSONIO (&gt;=0.8-2)</li>
                <li id="li_000465" smilref="Machine_Learning00016.smil#li_000465">Bitops</li>
                <li id="li_000466" smilref="Machine_Learning00016.smil#li_000466">Digest</li>
                <li id="li_000467" smilref="Machine_Learning00016.smil#li_000467">Functional</li>
                <li id="li_000468" smilref="Machine_Learning00016.smil#li_000468">reshape2</li>
                <li id="li_000469" smilref="Machine_Learning00016.smil#li_000469">stringr</li>
                <li id="li_000470" smilref="Machine_Learning00016.smil#li_000470">plyr</li>
                <li id="li_000471" smilref="Machine_Learning00016.smil#li_000471">caTools (&gt;=1.16)</li>
              </list>
              <pagenum epub:type="pagebreak" id="p343" page="normal" smilref="Machine_Learning00016.smil#p343">343</pagenum>
              <p id="c12-c12-para-0107" xml:space="preserve"><span class="text" id="span_002558" smilref="Machine_Learning00016.smil#span_002558">To install the rmr2 package, you have to manually download it from Revolution Analytics' Github repository (</span><a href="https://github.com/RevolutionAnalytics/rmr2" external="true" id="a_000322" smilref="Machine_Learning00016.smil#a_000322">https://github.com/RevolutionAnalytics/rmr2</a><span class="text" id="span_002559" smilref="Machine_Learning00016.smil#span_002559">) and run the following command from a terminal shell:</span></p>
              <p xml:space="preserve" id="p_001105"><code class="preserve-whitespace" xml:space="preserve" id="code_001102" smilref="Machine_Learning00016.smil#code_001102">$ R CMD INSTALL rmr2_&lt;the_version_number&gt;.tar.gz . rmr2</code></p>
              <p id="c12-c12-para-0108" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0108">The rmr2 package is not available on the CRAN package manager at present.</p>
              <p id="c12-c12-para-0109" xml:space="preserve"><span class="text" id="span_002560" smilref="Machine_Learning00016.smil#span_002560">Finally the environment variable for </span><code xml:space="preserve" id="code_001103" smilref="Machine_Learning00016.smil#code_001103">HADOOP_HOME</code><span class="text" id="span_002561" smilref="Machine_Learning00016.smil#span_002561"> needs to be set and the location of the streaming </span><code xml:space="preserve" id="code_001104" smilref="Machine_Learning00016.smil#code_001104">jar</code><span class="text" id="span_002562" smilref="Machine_Learning00016.smil#span_002562"> file set for </span><code xml:space="preserve" id="code_001105" smilref="Machine_Learning00016.smil#code_001105">HADOOP_STREAMING</code><span class="text" id="span_002563" smilref="Machine_Learning00016.smil#span_002563">.</span></p>
            </level3>
            <level3 id="level3_000234">
              <h3 xml:space="preserve" id="h3_000234" smilref="Machine_Learning00016.smil#h3_000234">A Sample Map Reduce Job in RHadoop</h3>
              <p xml:space="preserve" id="p_001106" smilref="Machine_Learning00016.smil#p_001106">I'm going to break down a basic word count job in R using the RHadoop packages. I'm assuming you've already copied some text data into the Hadoop Distributed File System (HDFS).</p>
              <level4 id="level4_000154">
                <h4 xml:space="preserve" id="h4_000154" smilref="Machine_Learning00016.smil#h4_000154">The Map Phase</h4>
                <pagenum epub:type="pagebreak" id="p340" page="normal" smilref="Machine_Learning00016.smil#p340">340</pagenum>
                <p xml:space="preserve" id="p_001107" smilref="Machine_Learning00016.smil#p_001107">The first thing you do is load the rmr2 library package into memory. The map splits the incoming lines by a space character, which gives you a list of words. You're emitting a value of 1 for each word.</p>
                <p xml:space="preserve" id="p_001108"><code class="preserve-whitespace" xml:space="preserve" id="code_001106" smilref="Machine_Learning00016.smil#code_001106">library(rmr2)
map &lt;- function(x,inputLines) {
  words.list &lt;- strsplit(inputLines, '\\s')
  words &lt;- unlist(words.list)
  return( keyval(words, 1) )
}</code></p>
              </level4>
              <level4 id="level4_000155">
                <h4 xml:space="preserve" id="h4_000155" smilref="Machine_Learning00016.smil#h4_000155">The Reduce Phase</h4>
                <p xml:space="preserve" id="p_001109" smilref="Machine_Learning00016.smil#p_001109">The reduce phase is a function that takes a word and its counts and reduces them to a word and a sum of the counts, This is then passed back to the calling function.</p>
                <p xml:space="preserve" id="p_001110"><code class="preserve-whitespace" xml:space="preserve" id="code_001107" smilref="Machine_Learning00016.smil#code_001107">## reduce function
reduce &lt;- function(word, counts) {
  keyval(word, sum(counts))
}</code></p>
              </level4>
              <level4 id="level4_000156">
                <h4 xml:space="preserve" id="h4_000156" smilref="Machine_Learning00016.smil#h4_000156">Setting Up the WordCount Job</h4>
                <pagenum epub:type="pagebreak" id="p344" page="normal" smilref="Machine_Learning00016.smil#p344">344</pagenum>
                <p xml:space="preserve" id="p_001111" smilref="Machine_Learning00016.smil#p_001111">You create a function to take in the input and output detail to the job and set up the basic map and reduce functions—the ones we've just created.</p>
                <p xml:space="preserve" id="p_001112"><code class="preserve-whitespace" xml:space="preserve" id="code_001108" smilref="Machine_Learning00016.smil#code_001108">wordcount &lt;- function (inputObject, outputObject=NULL) {
  mapreduce(input= inputObject, output= outputObject, input.format="text", map=map, reduce=reduce)
}</code></p>
              </level4>
              <level4 id="level4_000157">
                <h4 xml:space="preserve" id="h4_000157" smilref="Machine_Learning00016.smil#h4_000157">Running the Job</h4>
                <p xml:space="preserve" id="p_001113" smilref="Machine_Learning00016.smil#p_001113">The first thing you do is delete any references to the existing output data in HDFS. Hadoop fails if the output directory already exists.</p>
                <p id="c12-c12-para-0115" xml:space="preserve"><span class="text" id="span_002564" smilref="Machine_Learning00016.smil#span_002564">Next, create your job with the input and output paths and then set a variable object to the output of the </span><code xml:space="preserve" id="code_001109" smilref="Machine_Learning00016.smil#code_001109">wordcount</code><span class="text" id="span_002565" smilref="Machine_Learning00016.smil#span_002565"> function you created earlier:</span></p>
                <p xml:space="preserve" id="p_001114"><code class="preserve-whitespace" xml:space="preserve" id="code_001110" smilref="Machine_Learning00016.smil#code_001110">system("hadoop fs -rmr wordcount/outputdata")
hdfs.root &lt;- 'wordcount'
hdfs.data &lt;- file.path(hdfs.root, 'inputdata')
hdfs.out &lt;- file.path(hdfs.root, 'outputdata')
out &lt;- wordcount(hdfs.data, hdfs.out)</code></p>
              </level4>
              <level4 id="level4_000158">
                <h4 xml:space="preserve" id="h4_000158" smilref="Machine_Learning00016.smil#h4_000158">Checking the Results</h4>
                <p xml:space="preserve" id="p_001115"><span class="text" id="span_002566" smilref="Machine_Learning00016.smil#span_002566">You extract the output data from HDFS and then create a dataframe that reads in the results. Two column names are created for the top of the output: </span><code xml:space="preserve" id="code_001111" smilref="Machine_Learning00016.smil#code_001111">inputWord</code><span class="text" id="span_002567" smilref="Machine_Learning00016.smil#span_002567"> and </span><code xml:space="preserve" id="code_001112" smilref="Machine_Learning00016.smil#code_001112">frequency</code><span class="text" id="span_002568" smilref="Machine_Learning00016.smil#span_002568">.</span></p>
                <p xml:space="preserve" id="p_001116"><code class="preserve-whitespace" xml:space="preserve" id="code_001113" smilref="Machine_Learning00016.smil#code_001113">results &lt;- from.dfs(out)
## check top 30 frequent words
results.df &lt;- as.data.frame(results, stringsAsFactors=F)
colnames(results.df) &lt;- c('inputWord', 'frequency')
head(results.df[order(results.df$count, decreasing=T), ], 10) </code></p>
                <sidebar render="required" id="sidebar_000017">
                  <div class="top hr" id="div_000017" />
                  <level2 class="feature2" id="level2_000114">
                    <h2 xml:space="preserve" id="h2_000021" smilref="Machine_Learning00016.smil#h2_000021">Note</h2>
                    <pagenum epub:type="pagebreak" id="p345" page="normal" smilref="Machine_Learning00016.smil#p345">345</pagenum>
                    <p xml:space="preserve" id="p_001117"><span class="text" id="span_002569" smilref="Machine_Learning00016.smil#span_002569">Although I've concentrated on the RHadoop library, it's not the only one that exists. It's also worth checking out the RHIPE software libraries for R published by the Department of Statistics at Purdue University. You can find the website with all the details at </span><code xml:space="preserve" id="code_001114"><a href="http://www.datadr.org/install.html" external="true" id="a_000323" smilref="Machine_Learning00016.smil#a_000323">www.datadr.org/install.html</a></code><span class="text" id="span_002570" smilref="Machine_Learning00016.smil#span_002570">.</span></p>
                  </level2>
                </sidebar>
              </level4>
            </level3>
            <level3 id="level3_000235">
              <h3 xml:space="preserve" id="h3_000235" smilref="Machine_Learning00016.smil#h3_000235">Connecting to Social Media with R</h3>
              <p xml:space="preserve" id="p_001118" smilref="Machine_Learning00016.smil#p_001118">I know—another mention of the Twitter application program interface (API). This sort of data is important and not just for sentiment analysis. The majority of news, social graphs, and conversations happen on these platforms, and it's increasingly important to keep on top of developments. This goes for R, too; being able to connect to Twitter is important.</p>
              <p id="c12-c12-para-0119" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0119">In the previous examples you used Twitter's development account to create the authorization keys for the application. You're essentially forcing your application to use these pre-existing keys. That works fine, but you have to approach things a little differently for the twitteR library.</p>
              <p id="c12-c12-para-0120" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0120">Make a note of the consumer key and secret as you'll need those, but there are couple of other things you need to confirm.</p>
              <p id="c12-c12-para-0121" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0121">First of all, make sure there's no callback URL. You confirm this on the Settings tab of your application. Make sure the Allow This Application to Be Used to Sign In to Twitter check box is set to true as well. Don't forget to update the settings for them to take effect. Refresh the page until you see the settings are correct.</p>
              <p id="c12-c12-para-0122" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0122">Now that the Twitter side of things is set up you can look at some R code to help you log in to Twitter.</p>
              <p id="c12-c12-para-0123" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0123">You need to open a text editor and use the following code:</p>
              <p xml:space="preserve" id="p_001119"><code class="preserve-whitespace" xml:space="preserve" id="code_001115" smilref="Machine_Learning00016.smil#code_001115">library(twitteR)
cred &lt;- OAuthFactory$new(consumerKey="xxxxxxxxxxxxx",
 consumerSecret="xxxxxxxxxxxx",
 requestURL="http://api.twitter.com/oauth/request_token",
 accessURL="http://api.twitter.com/oauth/access_token",
 authURL="http://api.twitter.com/oauth/authorize")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
cred$handshake(cainfo="cacert.pem")</code></p>
              <p id="c12-c12-para-0124" xml:space="preserve"><span class="text" id="span_002571" smilref="Machine_Learning00016.smil#span_002571">Replace the consumer key and secret values with the ones you have for your application. Save the file as </span><code xml:space="preserve" id="code_001116" smilref="Machine_Learning00016.smil#code_001116">twitterconnect.r</code><span class="text" id="span_002572" smilref="Machine_Learning00016.smil#span_002572"> and then quit the text editor.</span></p>
              <p id="c12-c12-para-0125" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0125">Back in the R command line, you load the source file, and it runs as soon as it's loaded.</p>
              <p xml:space="preserve" id="p_001120"><code class="preserve-whitespace" xml:space="preserve" id="code_001117" smilref="Machine_Learning00016.smil#code_001117">&gt;source(twitterconnect.r')</code></p>
              <pagenum epub:type="pagebreak" id="p346" page="normal" smilref="Machine_Learning00016.smil#p346">346</pagenum>
              <p id="c12-c12-para-0126" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0126">You see the twitteR library load the dependencies and then attempt to connect to Twitter:</p>
              <p xml:space="preserve" id="p_001121"><code class="preserve-whitespace" xml:space="preserve" id="code_001118" smilref="Machine_Learning00016.smil#code_001118">&gt; source("twitterconnect.r")
Loading required package: ROAuth
Loading required package: RCurl
Loading required package: bitops
Loading required package: digest
Loading required package: rjson
trying URL 'http://curl.haxx.se/ca/cacert.pem'
Content type 'text/plain' length 251338 bytes (245 Kb)
opened URL
==================================================
downloaded 245 Kb
To enable the connection, please direct your web browser to:
http://api.twitter.com/oauth/authorize?oauth_token=cv88UGfPrAJnraJPqdGjeg5QJEUMk185jOUncJhDk
When complete, record the PIN given to you and provide it here:</code></p>
              <p id="c12-c12-para-0127" xml:space="preserve"><span class="text" id="span_002573" smilref="Machine_Learning00016.smil#span_002573">The main thing to look out for is the connecting URL with the </span><code xml:space="preserve" id="code_001119" smilref="Machine_Learning00016.smil#code_001119">oauth_token</code><span class="text" id="span_002574" smilref="Machine_Learning00016.smil#span_002574"> key. Copy the whole URL and paste it into a browser. You go to the Twitter site where you're asked to authorize your application request. When you accept this you'd normally return to the application, but because you've disabled that feature, you get a personal identification number (PIN) instead.</span></p>
              <p id="c12-c12-para-0128" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0128">Back at the R command line, the program you have written is currently waiting for input—the PIN—so type that in the R window.</p>
              <p id="c12-c12-para-0129" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0129">As soon as the PIN is entered you're returned to the R prompt. You need to register the oauth with the twitteR library, which you do with the following command:</p>
              <p xml:space="preserve" id="p_001122"><code class="preserve-whitespace" xml:space="preserve" id="code_001120" smilref="Machine_Learning00016.smil#code_001120">&gt;registerTwitterOAuth(cred)</code></p>
              <p id="c12-c12-para-0130" xml:space="preserve"><span class="text" id="span_002575" smilref="Machine_Learning00016.smil#span_002575">The R command line responds with </span><code xml:space="preserve" id="code_001121" smilref="Machine_Learning00016.smil#code_001121">TRUE</code><span class="text" id="span_002576" smilref="Machine_Learning00016.smil#span_002576"> when the credentials are registered. After that's done you can run a quick test:</span></p>
              <p xml:space="preserve" id="p_001123"><code class="preserve-whitespace" xml:space="preserve" id="code_001122" smilref="Machine_Learning00016.smil#code_001122">searchTwitter("#bigdata")</code></p>
              <p id="c12-c12-para-0131" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0131">You start to see results come through to the command line:</p>
              <p xml:space="preserve" id="p_001124"><code class="preserve-whitespace" xml:space="preserve" id="code_001123" smilref="Machine_Learning00016.smil#code_001123">[[1]]
[1] "eriksmits: #BigData could generate millions of new jobs http://t.co/w1FGdxjBI9 via @FortuneMagazine, is a Java Hadoop developer key for creating value?"
[[2]]
[1] "MobileBIAus: RT @BI_Television: RT @DavidAFrankel: Big Data Collides with Market Research http://t.co/M36yXMWJbg #bigdata #analytics"
[[3]]
[1] "alibaba_aus: @PracticalEcomm discusses how the use of #BigData can combat #ecommerce fraud http://t.co/fmd9m0wWeH"
[[4]]
[1] "alankayvr: RT @ventanaresearch: It's not too late! Join us in S.F. for the 2013 Technology Leadership Summit - sessions on #BigData #Cloud &amp; more http. . ."
[[5]]
[1] "DelrayMom: MT @Loyalty360: White Paper 6 #Tips for turning #BigData into key #insights, http://t.co/yuNRWxzXfZ, @SAS, #mktg #data #contentmarketing"</code></p>
              <pagenum epub:type="pagebreak" id="p347" page="normal" smilref="Machine_Learning00016.smil#p347">347</pagenum>
              <p id="c12-c12-para-0132" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0132">It's worth saving the credentials so you don't have to keep re-authorizing the access tokens via Twitter. You can save them to a file:</p>
              <p xml:space="preserve" id="p_001125"><code class="preserve-whitespace" xml:space="preserve" id="code_001124" smilref="Machine_Learning00016.smil#code_001124">&gt;save(cred,file="credentials.RData")</code></p>
              <p id="c12-c12-para-0133" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0133">The next time you want to use the Twitter credentials again, you can do it in two lines:</p>
              <p xml:space="preserve" id="p_001126"><code class="preserve-whitespace" xml:space="preserve" id="code_001125" smilref="Machine_Learning00016.smil#code_001125">&gt;load("credentials.RData")
&gt;registerTwitterOAuth(cred)</code></p>
            </level3>
          </level2>
          <level2 id="level2_000115">
            <h2 id="c12-c012_level1_11" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c012_level1_11">Summary</h2>
            <p xml:space="preserve" id="p_001127" smilref="Machine_Learning00016.smil#p_001127">R is a complex piece of software, but it's well-loved by data scientists (new and old ones alike) and also it's become the de facto statistics software for the open source generation.</p>
            <p id="c12-c12-para-0135" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0135">There are hundreds of well-developed and documented libraries for R within the CRAN package library.</p>
            <p id="c12-c12-para-0136" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0136">Development does come at a cost; it can be memory intensive for large and complex jobs. It doesn't handle huge amounts of data well, but this is improved by the work done by Revolution Analytics and Purdue University bringing Hadoop processing power to the R engine.</p>
            <p id="c12-c12-para-0137" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0137">If you still prefer the comfort of your “normal” programming language, such as Java, then use the JRI/RJava combinations; they work very well. Think about real-time analytics to your Java web servlets, for example—very powerful indeed.</p>
            <p id="c12-c12-para-0138" xml:space="preserve" smilref="Machine_Learning00016.smil#c12-c12-para-0138">Regardless of whether you're processing social media feeds, evaluating e-commerce shopping baskets, or reading sensor data from temperature gauges, look at R as an alternative for processing the data.</p>
          </level2>
        </section>
      </level1>
      <level1 id="bappxA">
        <header id="header_000013">
          <h1 xml:space="preserve" id="h1_000001" smilref="Machine_Learning00016.smil#h1_000001">Appendix A SpringXD Quick Start</h1>
        </header>
        <pagenum epub:type="pagebreak" id="p349" page="normal" smilref="Machine_Learning00016.smil#p349">349</pagenum>
        <p xml:space="preserve" id="p_001128"><span class="text" id="span_002577" smilref="Machine_Learning00016.smil#span_002577">You can download SpringXD from the Pivotal site at </span><code xml:space="preserve" id="code_001126"><a href="http://projects.spring.io/spring-xd" external="true" id="a_000324" smilref="Machine_Learning00016.smil#a_000324">http://projects.spring.io/spring-xd</a></code><span class="text" id="span_002578" smilref="Machine_Learning00016.smil#span_002578">.</span></p>
        <level2 id="level2_000116">
          <h2 id="bappxA-c0A_level1_1" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-c0A_level1_1">Installing Manually</h2>
          <p xml:space="preserve" id="p_001129" smilref="Machine_Learning00016.smil#p_001129">Use the following steps to install SpringXD:</p>
          <list type="ol" id="list_000070">
            <li id="li_000472">
              <span class="text" id="span_002579" smilref="Machine_Learning00016.smil#span_002579">Create a new directory:</span>
              <code class="preserve-whitespace" xml:space="preserve" id="code_001127" smilref="Machine_Learning00016.smil#code_001127">mkdir /opt/springxd</code>
            </li>
            <li id="li_000473" smilref="Machine_Learning00016.smil#li_000473">Unzip the contents of the downloaded zip file.</li>
            <li id="li_000474">
              <span class="text" id="span_002580" smilref="Machine_Learning00016.smil#span_002580">Set the environment variable to the directory:</span>
              <code class="preserve-whitespace" xml:space="preserve" id="code_001128" smilref="Machine_Learning00016.smil#code_001128">export XD_HOME=/opt/springxd/spring-xd-1.0.0.M7/</code>
            </li>
          </list>
        </level2>
        <level2 id="level2_000117">
          <h2 id="bappxA-c0A_level1_2" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-c0A_level1_2">Starting SpringXD</h2>
          <p xml:space="preserve" id="p_001130" smilref="Machine_Learning00016.smil#p_001130">Start SpringXD by doing the following:</p>
          <list type="ol" id="list_000071">
            <li id="li_000475">
              <span class="text" id="span_002581" smilref="Machine_Learning00016.smil#span_002581">Change the directory to the location in which you installed SpringXD:</span>
              <code class="preserve-whitespace" xml:space="preserve" id="code_001129" smilref="Machine_Learning00016.smil#code_001129">cd /opt/springxd/spring-xd-1.0.0.M7/xd</code>
            </li>
            <li id="li_000476">
              <span class="text" id="span_002582" smilref="Machine_Learning00016.smil#span_002582">Start the SpringXD server with the following command:</span>
              <code class="preserve-whitespace" xml:space="preserve" id="code_001130" smilref="Machine_Learning00016.smil#code_001130">./bin/xd-singlenode &amp; </code>
            </li>
          </list>
        </level2>
        <level2 id="level2_000118">
          <h2 id="bappxA-c0A_level1_3" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-c0A_level1_3">Creating a Stream</h2>
          <pagenum epub:type="pagebreak" id="p350" page="normal" smilref="Machine_Learning00016.smil#p350">350</pagenum>
          <p xml:space="preserve" id="p_001131" smilref="Machine_Learning00016.smil#p_001131">Assuming that the SpringXD server is up and running, launch the SpringXD shell in another terminal window:</p>
          <p xml:space="preserve" id="p_001132"><code class="preserve-whitespace" xml:space="preserve" id="code_001131" smilref="Machine_Learning00016.smil#code_001131">../shell/bin/xd-shell</code></p>
          <p id="bappxA-bappxA-para-0005" xml:space="preserve"><span class="text" id="span_002583" smilref="Machine_Learning00016.smil#span_002583">From the SpringXD </span><code xml:space="preserve" id="code_001132" smilref="Machine_Learning00016.smil#code_001132">xd:</code><span class="text" id="span_002584" smilref="Machine_Learning00016.smil#span_002584">&gt; command prompt, create a stream like so:</span></p>
          <p xml:space="preserve" id="p_001133"><code class="preserve-whitespace" xml:space="preserve" id="code_001133" smilref="Machine_Learning00016.smil#code_001133">xd:&gt;stream create --name ticker --definition "time | log" –deploy</code></p>
          <p id="bappxA-bappxA-para-0006" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-bappxA-para-0006">Go back to your SpringXD server terminal window and check the output of the stream to confirm it's working properly.</p>
          <p xml:space="preserve" id="p_001134"><code class="preserve-whitespace" xml:space="preserve" id="code_001134" smilref="Machine_Learning00016.smil#code_001134">16:39:06,323  INFO task-scheduler-1 sink.ticker:155 - 2014-06-30 16:39:06
16:39:07,326  INFO task-scheduler-4 sink.ticker:155 - 2014-06-30 16:39:07
16:39:08,330  INFO task-scheduler-1 sink.ticker:155 - 2014-06-30 16:39:08
16:39:09,331  INFO task-scheduler-1 sink.ticker:155 - 2014-06-30 16:39:09
16:39:10,333  INFO task-scheduler-1 sink.ticker:155 - 2014-06-30 16:39:10
16:39:11,339  INFO task-scheduler-7 sink.ticker:155 - 2014-06-30 16:39:11
16:39:12,341  INFO task-scheduler-8 sink.ticker:155 - 2014-06-30 16:39:12</code></p>
        </level2>
        <level2 id="level2_000119">
          <h2 id="bappxA-c0A_level1_4" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-c0A_level1_4">Adding a Twitter Application Key</h2>
          <p xml:space="preserve" id="p_001135"><span class="text" id="span_002585" smilref="Machine_Learning00016.smil#span_002585">If you want to use SpringXD to ingest data from the Twitter application programming interface (API), you first need to have created an application on the Twitter developer site (</span><code xml:space="preserve" id="code_001135"><a href="http://dev.twitter.com" external="true" id="a_000325" smilref="Machine_Learning00016.smil#a_000325">http://dev.twitter.com</a></code><span class="text" id="span_002586" smilref="Machine_Learning00016.smil#span_002586">).</span></p>
          <p id="bappxA-bappxA-para-0008" xml:space="preserve"><span class="text" id="span_002587" smilref="Machine_Learning00016.smil#span_002587">In SpringXD you can store the Twitter credentials in a properties file. You can find a template file in the </span><code xml:space="preserve" id="code_001136" smilref="Machine_Learning00016.smil#code_001136">./xd/config/modules/directory</code><span class="text" id="span_002588" smilref="Machine_Learning00016.smil#span_002588">. Older builds of SpringXD use the </span><code xml:space="preserve" id="code_001137" smilref="Machine_Learning00016.smil#code_001137">twitter.properties</code><span class="text" id="span_002589" smilref="Machine_Learning00016.smil#span_002589"> file directory and newer builds use the </span><code xml:space="preserve" id="code_001138" smilref="Machine_Learning00016.smil#code_001138">modules.yml</code><span class="text" id="span_002590" smilref="Machine_Learning00016.smil#span_002590"> file.</span></p>
          <p id="bappxA-bappxA-para-0009" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-bappxA-para-0009">To add a Twitter stream API key, add the following lines to the appropriate file with your text editor (I used vi in this example):</p>
          <p xml:space="preserve" id="p_001136"><code class="preserve-whitespace" xml:space="preserve" id="code_001139" smilref="Machine_Learning00016.smil#code_001139">vi modules.yml</code></p>
          <p id="bappxA-bappxA-para-0010" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-bappxA-para-0010">Uncomment the following lines:</p>
          <p xml:space="preserve" id="p_001137"><code class="preserve-whitespace" xml:space="preserve" id="code_001140" smilref="Machine_Learning00016.smil#code_001140">twitter:
consumerKey: wSs8crbV3Wa. . . .
consumerSecret: yKKv7UqutMsvXyMuQks. . . .
accessToken: 1248789104-k5QurElGEHMabclPw. . . .
accessTokenSecret: ceqZkUPUYqv391qoKlFx6YGAe. . . .</code></p>
          <p id="bappxA-bappxA-para-0011" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxA-bappxA-para-0011">Add the consumer key, secret and access tokens at their appropriate lines in the config file. If you want to use another set of credentials, you can define them within the stream. Changes to these files take effect only after you restart the SpringXD server.</p>
        </level2>
      </level1>
      <level1 id="bappxB">
        <header id="header_000014">
          <h1 xml:space="preserve" id="h1_000002" smilref="Machine_Learning00016.smil#h1_000002">Appendix B Hadoop 1.x Quick Start</h1>
        </header>
        <pagenum epub:type="pagebreak" id="p351" page="normal" smilref="Machine_Learning00016.smil#p351">351</pagenum>
        <p xml:space="preserve" id="p_001138" smilref="Machine_Learning00016.smil#p_001138">Chapter 10 covers Hadoop, and the example is based on Hadoop's MapReduce version 1 engine (MR1). The instructions in this appendix are for the MR1 engine. You might want to consider the Hadoop 2 version, which has performance improvements; installation is very similar to the following steps.</p>
        <sidebar render="required" id="sidebar_000018">
          <div class="top hr" id="div_000018" />
          <level2 class="feature1" id="level2_000120">
            <h2 xml:space="preserve" id="h2_000022" smilref="Machine_Learning00016.smil#h2_000022">A Note for Windows Users</h2>
            <p xml:space="preserve" id="p_001139" smilref="Machine_Learning00016.smil#p_001139">The Apache open source version of Hadoop is not really suitable for Windows operating systems. It's possible to run via Cygwin, but it is slow and clunky. If you are on Windows, you probably want to look at the Hortonworks open source Hadoop distribution. Hortonworks has developed a version of Hadoop for Windows that runs natively.</p>
          </level2>
        </sidebar>
        <p id="bappxB-bappxB-para-0003" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0003">If you are running Mac OS X or a Unix operating system (for example, Linux) then the following instructions apply.</p>
        <level2 id="level2_000121">
          <h2 id="bappxB-c0B_level1_1" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-c0B_level1_1">Downloading and Installing Hadoop</h2>
          <p xml:space="preserve" id="p_001140"><span class="text" id="span_002591" smilref="Machine_Learning00016.smil#span_002591">You can download Hadoop from one of the Apache mirror sites. I used </span><code xml:space="preserve" id="code_001141"><a href="http://mirrors.ukfast.co.uk/sites/ftp.apache.org/hadoop/common/" external="true" id="a_000326" smilref="Machine_Learning00016.smil#a_000326">http://mirrors.ukfast.co.uk/sites/ftp.apache.org/hadoop/common/</a></code><span class="text" id="span_002592" smilref="Machine_Learning00016.smil#span_002592">.</span></p>
          <pagenum epub:type="pagebreak" id="p352" page="normal" smilref="Machine_Learning00016.smil#p352">352</pagenum>
          <p id="bappxB-bappxB-para-0005" xml:space="preserve"><span class="text" id="span_002593" smilref="Machine_Learning00016.smil#span_002593">Look for the </span><code xml:space="preserve" id="code_001142" smilref="Machine_Learning00016.smil#code_001142">hadoop-1.2.x</code><span class="text" id="span_002594" smilref="Machine_Learning00016.smil#span_002594"> release and download the </span><code xml:space="preserve" id="code_001143" smilref="Machine_Learning00016.smil#code_001143">.tar.gz</code><span class="text" id="span_002595" smilref="Machine_Learning00016.smil#span_002595">, where x is the highest number. There are extra links to “stable1,” “stable2,” and “current,” that help guide you to the correct version.</span></p>
          <p xml:space="preserve" id="p_001141"><code class="preserve-whitespace" xml:space="preserve" id="code_001144" smilref="Machine_Learning00016.smil#code_001144">tar xvzf hadoop-x.x.x-bin.tar.gz</code></p>
          <p id="bappxB-bappxB-para-0006" xml:space="preserve"><span class="text" id="span_002596" smilref="Machine_Learning00016.smil#span_002596">In the configuration directory (called </span><code xml:space="preserve" id="code_001145" smilref="Machine_Learning00016.smil#code_001145">conf</code><span class="text" id="span_002597" smilref="Machine_Learning00016.smil#span_002597">), edit the </span><code xml:space="preserve" id="code_001146" smilref="Machine_Learning00016.smil#code_001146">hadoop-env.sh</code><span class="text" id="span_002598" smilref="Machine_Learning00016.smil#span_002598"> file and edit the </span><code xml:space="preserve" id="code_001147" smilref="Machine_Learning00016.smil#code_001147">JAVA_HOME</code><span class="text" id="span_002599" smilref="Machine_Learning00016.smil#span_002599"> line:</span></p>
          <p xml:space="preserve" id="p_001142"><code class="preserve-whitespace" xml:space="preserve" id="code_001148" smilref="Machine_Learning00016.smil#code_001148">export JAVA_HOME=/path/to/wherever/your-java/is</code></p>
          <p id="bappxB-bappxB-para-0007" xml:space="preserve"><span class="text" id="span_002600" smilref="Machine_Learning00016.smil#span_002600">Also (this is a part that's very rarely mentioned), if your </span><code xml:space="preserve" id="code_001149" smilref="Machine_Learning00016.smil#code_001149">SSH</code><span class="text" id="span_002601" smilref="Machine_Learning00016.smil#span_002601"> configuration has a different port set up (the default port is 22, but the paranoid among us run it on another port), then you also need to comment out the </span><code xml:space="preserve" id="code_001150" smilref="Machine_Learning00016.smil#code_001150">HADOOP_SSH_OPS</code><span class="text" id="span_002602" smilref="Machine_Learning00016.smil#span_002602"> and add a line that reads:</span></p>
          <p xml:space="preserve" id="p_001143"><code class="preserve-whitespace" xml:space="preserve" id="code_001151" smilref="Machine_Learning00016.smil#code_001151">export HADOOP_SSH_OPS="-p &lt;my ssh port&gt;" </code></p>
          <sidebar render="required" id="sidebar_000019">
            <div class="top hr" id="div_000019" />
            <level2 class="feature2" id="level2_000122">
              <h2 xml:space="preserve" id="h2_000023" smilref="Machine_Learning00016.smil#h2_000023">Tip</h2>
              <p xml:space="preserve" id="p_001144"><span class="text" id="span_002603" smilref="Machine_Learning00016.smil#span_002603">Obviously you should change </span><code xml:space="preserve" id="code_001152" smilref="Machine_Learning00016.smil#code_001152">&lt;my ssh port&gt;</code><span class="text" id="span_002604" smilref="Machine_Learning00016.smil#span_002604"> to the actual number on which your </span><code xml:space="preserve" id="code_001153" smilref="Machine_Learning00016.smil#code_001153">SSHD</code><span class="text" id="span_002605" smilref="Machine_Learning00016.smil#span_002605"> accepts connections.</span></p>
            </level2>
          </sidebar>
          <p id="bappxB-bappxB-para-0009" xml:space="preserve"><span class="text" id="span_002606" smilref="Machine_Learning00016.smil#span_002606">Next, if you have not already done so, create a passwordless </span><code xml:space="preserve" id="code_001154" smilref="Machine_Learning00016.smil#code_001154">RSA</code><span class="text" id="span_002607" smilref="Machine_Learning00016.smil#span_002607"> key on your machine:</span></p>
          <p xml:space="preserve" id="p_001145"><code class="preserve-whitespace" xml:space="preserve" id="code_001155" smilref="Machine_Learning00016.smil#code_001155">ssh-keygen -t rsa -P ''</code></p>
          <p id="bappxB-bappxB-para-0010" xml:space="preserve"><span class="text" id="span_002608" smilref="Machine_Learning00016.smil#span_002608">That command should save the key under your home directory in </span><code xml:space="preserve" id="code_001156" smilref="Machine_Learning00016.smil#code_001156">˜/.ssh/id_rsa</code><span class="text" id="span_002609" smilref="Machine_Learning00016.smil#span_002609">.</span></p>
          <p id="bappxB-bappxB-para-0011" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0011">Now, append that file to the authorized keys file in that same directory on the same machine:</p>
          <p xml:space="preserve" id="p_001146"><code class="preserve-whitespace" xml:space="preserve" id="code_001157" smilref="Machine_Learning00016.smil#code_001157">cat ˜/.ssh/id_rsa.pub &gt;&gt; ˜/.ssh/authorized_keys</code></p>
          <p id="bappxB-bappxB-para-0012" xml:space="preserve"><span class="text" id="span_002610" smilref="Machine_Learning00016.smil#span_002610">Add Hadoop's bin path to your working path. Consider also adding this line to your </span><code xml:space="preserve" id="code_001158" smilref="Machine_Learning00016.smil#code_001158">˜/.bash_profile</code><span class="text" id="span_002611" smilref="Machine_Learning00016.smil#span_002611"> so that it executes each time you log in.</span></p>
          <p xml:space="preserve" id="p_001147"><code class="preserve-whitespace" xml:space="preserve" id="code_001159" smilref="Machine_Learning00016.smil#code_001159">export PATH=$PATH:/path/to/hadoop/bin</code></p>
          <p id="bappxB-bappxB-para-0013" xml:space="preserve"><span class="text" id="span_002612" smilref="Machine_Learning00016.smil#span_002612">The last thing to do is to define Hadoop's filesystem settings in </span><code xml:space="preserve" id="code_001160" smilref="Machine_Learning00016.smil#code_001160">conf/core-site.xml</code><span class="text" id="span_002613" smilref="Machine_Learning00016.smil#span_002613">.</span></p>
          <p xml:space="preserve" id="p_001148"><code class="preserve-whitespace" xml:space="preserve" id="code_001161" smilref="Machine_Learning00016.smil#code_001161">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></p>
        </level2>
        <level2 id="level2_000123">
          <h2 id="bappxB-c0B_level1_2" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-c0B_level1_2">Formatting the HDFS Filesystem</h2>
          <p xml:space="preserve" id="p_001149" smilref="Machine_Learning00016.smil#p_001149">From the command line, run the following:</p>
          <p xml:space="preserve" id="p_001150"><code class="preserve-whitespace" xml:space="preserve" id="code_001162" smilref="Machine_Learning00016.smil#code_001162">hadoop namenode -format</code></p>
          <p id="bappxB-bappxB-para-0015" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0015">When executing this command, you're prompted with Y or N to proceed; make sure you enter uppercase Y and not lowercase y. It's case sensitive.</p>
        </level2>
        <level2 id="level2_000124">
          <h2 id="bappxB-c0B_level1_3" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-c0B_level1_3">Starting and Stopping Hadoop</h2>
          <pagenum epub:type="pagebreak" id="p353" page="normal" smilref="Machine_Learning00016.smil#p353">353</pagenum>
          <p xml:space="preserve" id="p_001151" smilref="Machine_Learning00016.smil#p_001151">To start Hadoop, run:</p>
          <p xml:space="preserve" id="p_001152"><code class="preserve-whitespace" xml:space="preserve" id="code_001163" smilref="Machine_Learning00016.smil#code_001163">start-all.sh</code></p>
          <p id="bappxB-bappxB-para-0017" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0017">To stop it, use:</p>
          <p xml:space="preserve" id="p_001153"><code class="preserve-whitespace" xml:space="preserve" id="code_001164" smilref="Machine_Learning00016.smil#code_001164">stop-all.sh</code></p>
        </level2>
        <level2 id="level2_000125">
          <h2 id="bappxB-c0B_level1_4" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-c0B_level1_4">Process List of a Basic Job</h2>
          <p xml:space="preserve" id="p_001154" smilref="Machine_Learning00016.smil#p_001154">Start up the server:</p>
          <p xml:space="preserve" id="p_001155"><code class="preserve-whitespace" xml:space="preserve" id="code_001165" smilref="Machine_Learning00016.smil#code_001165">start-all.sh</code></p>
          <p id="bappxB-bappxB-para-0019" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0019">Copy the data you want to process to the HDFS filesystem:</p>
          <p xml:space="preserve" id="p_001156"><code class="preserve-whitespace" xml:space="preserve" id="code_001166" smilref="Machine_Learning00016.smil#code_001166">hadoop fs -put mydata.txt mydata.txt</code></p>
          <p id="bappxB-bappxB-para-0020" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0020">Run the Hadoop job. There are two parameters: the input file or directory in HDFS and the directory to output the results (to ensure it doesn't already exist on HDFS):</p>
          <p xml:space="preserve" id="p_001157"><code class="preserve-whitespace" xml:space="preserve" id="code_001167" smilref="Machine_Learning00016.smil#code_001167">hadoop jar /path/to/hadoop-*-examples.jar wordcount mydata.txt output</code></p>
          <p id="bappxB-bappxB-para-0021" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0021">Hadoop then processes the job. To see the results, you need to copy the result data from the HDFS filesystem back to your local filesystem.</p>
          <p xml:space="preserve" id="p_001158"><code class="preserve-whitespace" xml:space="preserve" id="code_001168" smilref="Machine_Learning00016.smil#code_001168">hadoop fs --getmerge output output.txt</code></p>
          <p id="bappxB-bappxB-para-0022" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxB-bappxB-para-0022">Stop the server:</p>
          <p xml:space="preserve" id="p_001159"><code class="preserve-whitespace" xml:space="preserve" id="code_001169" smilref="Machine_Learning00016.smil#code_001169">stop-all.sh</code></p>
        </level2>
      </level1>
      <level1 id="bappxC">
        <header id="header_000015">
          <h1 xml:space="preserve" id="h1_000003" smilref="Machine_Learning00016.smil#h1_000003">Appendix C Useful Unix Commands</h1>
        </header>
        <pagenum epub:type="pagebreak" id="p355" page="normal" smilref="Machine_Learning00016.smil#p355">355</pagenum>
        <p xml:space="preserve" id="p_001160" smilref="Machine_Learning00016.smil#p_001160">Regardless of the operating system you use on a daily basis, there's nothing wrong with learning some handy Unix commands. The commands covered in this section will help you on the day-to-day tasks of quickly testing, parsing, and searching through your text data.</p>
        <p id="bappxC-bappxC-para-0002" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-bappxC-para-0002">If you're a Windows user, you can still join in by downloading Cygwin, which is a Unix shell command interpreter. Cygwin is a shell that sits on top of the Windows Command application and behaves like it's a Unix install.</p>
        <p id="bappxC-bappxC-para-0003" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-bappxC-para-0003">Some of these commands will appear from time to time in the chapters of this book, especially in Chapters 9 and 10, so it's worth reviewing them now. Experiment with them and study the output so you have an idea of what to expect.</p>
        <level2 id="level2_000126">
          <h2 id="bappxC-c0C_level1_1" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_1">Using Sample Data</h2>
          <p xml:space="preserve" id="p_001161" smilref="Machine_Learning00016.smil#p_001161">Before you get started with the tools, you need some sample data. With a text editor, type out the following lines and separate each value with a tab.</p>
          <p xml:space="preserve" id="p_001162"><code class="preserve-whitespace" xml:space="preserve" id="code_001170" smilref="Machine_Learning00016.smil#code_001170">987    1391548780   hhh bbb
988    1391548781   sda jjj
989    1391548782   asd asd
990    1391548783   gjh jkl
991    1391548784   abc abc
992    1391548785   ghj gjh
993    1391548785   hhh bbb
994    1391548785   sda jjj
995    1391548786   asd asd
996    1391548787   gjh jkl
997    1391548787   abc abc
998    1391548787   ghj gjh</code></p>
          <pagenum epub:type="pagebreak" id="p356" page="normal" smilref="Machine_Learning00016.smil#p356">356</pagenum>
          <p id="bappxC-bappxC-para-0005" xml:space="preserve"><span class="text" id="span_002614" smilref="Machine_Learning00016.smil#span_002614">Name the text file </span><code xml:space="preserve" id="code_001171" smilref="Machine_Learning00016.smil#code_001171">text.txt</code><span class="text" id="span_002615" smilref="Machine_Learning00016.smil#span_002615">, and then you can follow along with the following commands and see the output. The sample data is basically comprised of a unique id, a timestamp, and some text. It's the sort of thing you would see within a database table but is output as text. This example uses a tab delimiter, but you might find data with commas, semicolons, and other characters used as a delimiter.</span></p>
        </level2>
        <level2 id="level2_000127">
          <h2 id="bappxC-c0C_level1_2" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_2">Showing the Contents: cat, more, and less</h2>
          <p xml:space="preserve" id="p_001163"><span class="text" id="span_002616" smilref="Machine_Learning00016.smil#span_002616">The </span><code xml:space="preserve" id="code_001172" smilref="Machine_Learning00016.smil#code_001172">cat</code><span class="text" id="span_002617" smilref="Machine_Learning00016.smil#span_002617"> command concatenates and prints the contents of one or more files to the console output.</span></p>
          <level3 id="level3_000236">
            <h3 xml:space="preserve" id="h3_000236" smilref="Machine_Learning00016.smil#h3_000236">Example Command</h3>
            <p xml:space="preserve" id="p_001164"><code class="preserve-whitespace" xml:space="preserve" id="code_001173" smilref="Machine_Learning00016.smil#code_001173">cat text.txt text2.txt text3.txt</code></p>
          </level3>
          <level3 id="level3_000237">
            <h3 xml:space="preserve" id="h3_000237" smilref="Machine_Learning00016.smil#h3_000237">Expected Output</h3>
            <p xml:space="preserve" id="p_001165"><code class="preserve-whitespace" xml:space="preserve" id="code_001174" smilref="Machine_Learning00016.smil#code_001174">987    1391548780   hhh bbb
988    1391548781   sda jjj
989    1391548782   asd asd
990    1391548783   gjh jkl
991    1391548784   abc abc
992    1391548785   ghj gjh
993    1391548785   hhh bbb
994    1391548785   sda jjj
995    1391548786   asd asd
996    1391548787   gjh jkl
997    1391548787   abc abc
998    1391548787   ghj gjh</code></p>
            <p id="bappxC-bappxC-para-0009" xml:space="preserve"><span class="text" id="span_002618" smilref="Machine_Learning00016.smil#span_002618">Adding </span><code xml:space="preserve" id="code_001175" smilref="Machine_Learning00016.smil#code_001175">–b</code><span class="text" id="span_002619" smilref="Machine_Learning00016.smil#span_002619"> to the options gives you the line numbers, too.</span></p>
            <p xml:space="preserve" id="p_001166"><code class="preserve-whitespace" xml:space="preserve" id="code_001176" smilref="Machine_Learning00016.smil#code_001176">$ cat -b sample.txt
     1 987    1391548780   hhh bbb
     2 988    1391548781   sda jjj
     3 989    1391548782   asd asd
     4 990    1391548783   gjh jkl
     5 991    1391548784   abc abc
     6 992    1391548785   ghj gjh
     7 993    1391548785   hhh bbb
     8 994    1391548785   sda jjj
     9 995    1391548786   asd asd
    10 996    1391548787   gjh jkl
    11 997    1391548787   abc abc
    12 998    1391548787   ghj gjh</code></p>
            <pagenum epub:type="pagebreak" id="p357" page="normal" smilref="Machine_Learning00016.smil#p357">357</pagenum>
            <p id="bappxC-bappxC-para-0010" xml:space="preserve"><span class="text" id="span_002620" smilref="Machine_Learning00016.smil#span_002620">If too much content is showing in the console for you to keep up with, you can add the </span><code xml:space="preserve" id="code_001177" smilref="Machine_Learning00016.smil#code_001177">more</code><span class="text" id="span_002621" smilref="Machine_Learning00016.smil#span_002621"> command after the </span><code xml:space="preserve" id="code_001178" smilref="Machine_Learning00016.smil#code_001178">cat</code><span class="text" id="span_002622" smilref="Machine_Learning00016.smil#span_002622"> command:</span></p>
            <p xml:space="preserve" id="p_001167"><code class="preserve-whitespace" xml:space="preserve" id="code_001179" smilref="Machine_Learning00016.smil#code_001179">$ cat sample | more</code></p>
            <p id="bappxC-bappxC-para-0011" xml:space="preserve"><span class="text" id="span_002623" smilref="Machine_Learning00016.smil#span_002623">Alternatively the </span><code xml:space="preserve" id="code_001180" smilref="Machine_Learning00016.smil#code_001180">less</code><span class="text" id="span_002624" smilref="Machine_Learning00016.smil#span_002624"> command gives you a controlled environment for viewing the contents of files but does not let you edit them.</span></p>
          </level3>
        </level2>
        <level2 id="level2_000128">
          <h2 id="bappxC-c0C_level1_3" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_3">Filtering Content: grep</h2>
          <p xml:space="preserve" id="p_001168"><span class="text" id="span_002625" smilref="Machine_Learning00016.smil#span_002625">For matching patterns within text, </span><code xml:space="preserve" id="code_001181" smilref="Machine_Learning00016.smil#code_001181">grep</code><span class="text" id="span_002626" smilref="Machine_Learning00016.smil#span_002626"> is your friend. It's one of those utilities you'll use again and again after you get used to it. The syntax is very basic: </span><code xml:space="preserve" id="code_001182" smilref="Machine_Learning00016.smil#code_001182">grep [options] [pattern to find] [name of file(s)]</code><span class="text" id="span_002627" smilref="Machine_Learning00016.smil#span_002627">.</span></p>
          <level3 id="level3_000238">
            <h3 xml:space="preserve" id="h3_000238" smilref="Machine_Learning00016.smil#h3_000238">Example Command for Finding Text</h3>
            <p xml:space="preserve" id="p_001169"><code class="preserve-whitespace" xml:space="preserve" id="code_001183" smilref="Machine_Learning00016.smil#code_001183">$grep 'bbb bbb' sample.txt</code></p>
          </level3>
          <level3 id="level3_000239">
            <h3 xml:space="preserve" id="h3_000239" smilref="Machine_Learning00016.smil#h3_000239">Example Output</h3>
            <p xml:space="preserve" id="p_001170"><span class="text" id="span_002628" smilref="Machine_Learning00016.smil#span_002628">To invert the output, find the lines that don't match the pattern then add the </span><code xml:space="preserve" id="code_001184" smilref="Machine_Learning00016.smil#code_001184">–v</code><span class="text" id="span_002629" smilref="Machine_Learning00016.smil#span_002629"> flag before the pattern. </span><a id="bappxC-bappxC-tbl-anc-0001" href="#bappxC-bappxC-tbl-0001" external="false" smilref="Machine_Learning00016.smil#bappxC-bappxC-tbl-anc-0001">Table C-1</a><span class="text" id="span_002630" smilref="Machine_Learning00016.smil#span_002630"> shows other handy option flags you can use with </span><code xml:space="preserve" id="code_001185" smilref="Machine_Learning00016.smil#code_001185">grep</code><span class="text" id="span_002631" smilref="Machine_Learning00016.smil#span_002631">.</span></p>
            <figure id="figure_000119">
              <figcaption id="figcaption_000105">
                <p xml:space="preserve" id="p_001171"><span class="figureLabel" id="span_002632"><a id="bappxC-bappxC-tbl-0001" href="#bappxC-bappxC-tbl-anc-0001" external="false"><strong id="strong_000792" smilref="Machine_Learning00016.smil#strong_000792">Table C-1</strong></a></span><span class="text" id="span_002633" smilref="Machine_Learning00016.smil#span_002633"> grep Option Flags</span></p>
              </figcaption>
              <table border="1" id="table_000025">
                <tr id="tr_000141">
                  <td class="left" rowspan="1" colspan="1" id="td_000405" smilref="Machine_Learning00016.smil#td_000405">Flag</td>
                  <td class="left" rowspan="1" colspan="1" id="td_000406" smilref="Machine_Learning00016.smil#td_000406">Effect On Output</td>
                </tr>
                <tr id="tr_000142">
                  <td class="left" rowspan="1" colspan="1" id="td_000407">
                    <code xml:space="preserve" id="code_001186" smilref="Machine_Learning00016.smil#code_001186">-c</code>
                  </td>
                  <td class="left" rowspan="1" colspan="1" id="td_000408" smilref="Machine_Learning00016.smil#td_000408">Outputs the number of times the pattern was matched in the file</td>
                </tr>
                <tr id="tr_000143">
                  <td class="left" rowspan="1" colspan="1" id="td_000409">
                    <code xml:space="preserve" id="code_001187" smilref="Machine_Learning00016.smil#code_001187">-v</code>
                  </td>
                  <td class="left" rowspan="1" colspan="1" id="td_000410" smilref="Machine_Learning00016.smil#td_000410">Inverts the output to show lines that don't match the pattern</td>
                </tr>
                <tr id="tr_000144">
                  <td class="left" rowspan="1" colspan="1" id="td_000411">
                    <code xml:space="preserve" id="code_001188" smilref="Machine_Learning00016.smil#code_001188">-i</code>
                  </td>
                  <td class="left" rowspan="1" colspan="1" id="td_000412" smilref="Machine_Learning00016.smil#td_000412">Ignores the case on the input line so “BBB” and “bbb” would match</td>
                </tr>
                <tr id="tr_000145">
                  <td class="left" rowspan="1" colspan="1" id="td_000413">
                    <code xml:space="preserve" id="code_001189" smilref="Machine_Learning00016.smil#code_001189">-n</code>
                  </td>
                  <td class="left" rowspan="1" colspan="1" id="td_000414" smilref="Machine_Learning00016.smil#td_000414">Displays the line number on which the pattern match occurs</td>
                </tr>
                <tr id="tr_000146">
                  <td class="left" rowspan="1" colspan="1" id="td_000415">
                    <code xml:space="preserve" id="code_001190" smilref="Machine_Learning00016.smil#code_001190">-l</code>
                  </td>
                  <td class="left" rowspan="1" colspan="1" id="td_000416" smilref="Machine_Learning00016.smil#td_000416">Lists the filenames where the pattern matches</td>
                </tr>
              </table>
            </figure>
            <pagenum epub:type="pagebreak" id="p358" page="normal" smilref="Machine_Learning00016.smil#p358">358</pagenum>
            <p id="bappxC-bappxC-para-0015" xml:space="preserve"><span class="text" id="span_002634" smilref="Machine_Learning00016.smil#span_002634">The pattern matching can be taken a step further by introducing Perl-like patterns with the </span><code xml:space="preserve" id="code_001191" smilref="Machine_Learning00016.smil#code_001191">–P</code><span class="text" id="span_002635" smilref="Machine_Learning00016.smil#span_002635"> option. There are numerous books on the subject of Perl and Regular Expressions.</span></p>
            <p xml:space="preserve" id="p_001172"><code class="preserve-whitespace" xml:space="preserve" id="code_001192" smilref="Machine_Learning00016.smil#code_001192">$ grep -e '[1-5]\tsda' sample.txt
988    139154878    sda jjj
994    1391548785   sda jjj</code></p>
          </level3>
        </level2>
        <level2 id="level2_000129">
          <h2 id="bappxC-c0C_level1_4" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_4">Sorting Data: sort</h2>
          <p xml:space="preserve" id="p_001173"><span class="text" id="span_002636" smilref="Machine_Learning00016.smil#span_002636">The </span><code xml:space="preserve" id="code_001193" smilref="Machine_Learning00016.smil#code_001193">sort</code><span class="text" id="span_002637" smilref="Machine_Learning00016.smil#span_002637"> command takes the input file and sorts in ascending or descending order. By default, </span><code xml:space="preserve" id="code_001194" smilref="Machine_Learning00016.smil#code_001194">sort</code><span class="text" id="span_002638" smilref="Machine_Learning00016.smil#span_002638"> assumes that everything is a string. (You'll read about number values in a moment.)</span></p>
          <level3 id="level3_000240">
            <h3 xml:space="preserve" id="h3_000240" smilref="Machine_Learning00016.smil#h3_000240">Example Command for Basic Sorting</h3>
            <p xml:space="preserve" id="p_001174"><code class="preserve-whitespace" xml:space="preserve" id="code_001195" smilref="Machine_Learning00016.smil#code_001195">$sort sample.txt</code></p>
          </level3>
          <level3 id="level3_000241">
            <h3 xml:space="preserve" id="h3_000241" smilref="Machine_Learning00016.smil#h3_000241">Example Output</h3>
            <p xml:space="preserve" id="p_001175"><code class="preserve-whitespace" xml:space="preserve" id="code_001196" smilref="Machine_Learning00016.smil#code_001196">987    1391548780   hhh bbb
988    1391548781   sda jjj
989    1391548782   asd asd
990    1391548783   gjh jkl
991    1391548784   abc abc
992    1391548785   ghj gjh
993    1391548785   hhh bbb
994    1391548785   sda jjj
995    1391548786   asd asd
996    1391548787   gjh jkl
997    1391548787   abc abc
998    1391548787   ghj gjh</code></p>
            <p id="bappxC-bappxC-para-0019" xml:space="preserve"><span class="text" id="span_002639" smilref="Machine_Learning00016.smil#span_002639">The </span><code xml:space="preserve" id="code_001197" smilref="Machine_Learning00016.smil#code_001197">–r</code><span class="text" id="span_002640" smilref="Machine_Learning00016.smil#span_002640"> flag outputs the results in descending order.</span></p>
            <p xml:space="preserve" id="p_001176"><code class="preserve-whitespace" xml:space="preserve" id="code_001198" smilref="Machine_Learning00016.smil#code_001198">$ sort -r sample.txt
998    1391548787   ghj gjh
997    1391548787   abc abc
996    1391548787   gjh jkl
995    1391548786   asd asd
994    1391548785   sda jjj
993    1391548785   hhh bbb
992    1391548785   ghj gjh
991    1391548784   abc abc
990    1391548783   gjh jkl
989    1391548782   asd asd
988    1391548781   sda jjj
987    1391548780   hhh bbb</code></p>
            <pagenum epub:type="pagebreak" id="p359" page="normal" smilref="Machine_Learning00016.smil#p359">359</pagenum>
            <p id="bappxC-bappxC-para-0020" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-bappxC-para-0020">So far the example has covered sorting strings. Consider the following list of numbers:</p>
            <p xml:space="preserve" id="p_001177"><code class="preserve-whitespace" xml:space="preserve" id="code_001199" smilref="Machine_Learning00016.smil#code_001199">10
18
1
20
17
15
103
110
12
22
21
201</code></p>
            <p id="bappxC-bappxC-para-0021" xml:space="preserve"><span class="text" id="span_002641" smilref="Machine_Learning00016.smil#span_002641">Running a default </span><code xml:space="preserve" id="code_001200" smilref="Machine_Learning00016.smil#code_001200">sort</code><span class="text" id="span_002642" smilref="Machine_Learning00016.smil#span_002642"> command would sort the number values as strings, so the output would be correct, but it probably would not be what you hoped for.</span></p>
            <p xml:space="preserve" id="p_001178"><code class="preserve-whitespace" xml:space="preserve" id="code_001201" smilref="Machine_Learning00016.smil#code_001201">$ sort sample2.txt
1
10
103
110
12
15
17
18
20
201
21
22</code></p>
            <p id="bappxC-bappxC-para-0022" xml:space="preserve"><span class="text" id="span_002643" smilref="Machine_Learning00016.smil#span_002643">The </span><code xml:space="preserve" id="code_001202" smilref="Machine_Learning00016.smil#code_001202">–n</code><span class="text" id="span_002644" smilref="Machine_Learning00016.smil#span_002644"> option treats the input data as numeric.</span></p>
            <p xml:space="preserve" id="p_001179"><code class="preserve-whitespace" xml:space="preserve" id="code_001203" smilref="Machine_Learning00016.smil#code_001203">$ sort -n sample2.txt
1
10
12
15
17
18
20
21
22
103
110
201</code></p>
            <pagenum epub:type="pagebreak" id="p360" page="normal" smilref="Machine_Learning00016.smil#p360">360</pagenum>
            <p id="bappxC-bappxC-para-0023" xml:space="preserve"><span class="text" id="span_002645" smilref="Machine_Learning00016.smil#span_002645">The final useful option is the </span><code xml:space="preserve" id="code_001204" smilref="Machine_Learning00016.smil#code_001204">–k</code><span class="text" id="span_002646" smilref="Machine_Learning00016.smil#span_002646"> flag, which splits the input data into columns and lets you sort on a specific column. In the sample data, the first three-letter text column is the third, so by using the option </span><code xml:space="preserve" id="code_001205" smilref="Machine_Learning00016.smil#code_001205">–k3</code><span class="text" id="span_002647" smilref="Machine_Learning00016.smil#span_002647"> you sort on the text column.</span></p>
            <p xml:space="preserve" id="p_001180"><code class="preserve-whitespace" xml:space="preserve" id="code_001206" smilref="Machine_Learning00016.smil#code_001206">$ sort -k3 sample.txt
991    1391548784   abc abc
997    1391548787   abc abc
989    1391548782   asd asd
995    1391548786   asd asd
992    1391548785   ghj gjh
998    1391548787   ghj gjh
990    1391548783   gjh jkl
996    1391548787   gjh jkl
987    1391548780   hhh bbb
993    1391548785   hhh bbb
988    1391548781   sda jjj
994    1391548785   sda jjj</code></p>
            <p id="bappxC-bappxC-para-0024" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-bappxC-para-0024">When combining the sort option flags, you can output pretty much anything you want. For example, you could reverse sort the second column as a numeric value using the following code:</p>
            <p xml:space="preserve" id="p_001181"><code class="preserve-whitespace" xml:space="preserve" id="code_001207" smilref="Machine_Learning00016.smil#code_001207">$ sort -k2nr sample.txt
996    1391548787   gjh jkl
997    1391548787   abc abc
998    1391548787   ghj gjh
995    1391548786   asd asd
992    1391548785   ghj gjh
993    1391548785   hhh bbb
994    1391548785   sda jjj
991    1391548784   abc abc
990    1391548783   gjh jkl
989    1391548782   asd asd
988    1391548781   sda jjj
987    1391548780   hhh bbb</code></p>
            <p id="bappxC-bappxC-para-0025" xml:space="preserve"><span class="text" id="span_002648" smilref="Machine_Learning00016.smil#span_002648">The combination of the </span><code xml:space="preserve" id="code_001208" smilref="Machine_Learning00016.smil#code_001208">–k</code><span class="text" id="span_002649" smilref="Machine_Learning00016.smil#span_002649">, </span><code xml:space="preserve" id="code_001209" smilref="Machine_Learning00016.smil#code_001209">-n</code><span class="text" id="span_002650" smilref="Machine_Learning00016.smil#span_002650">, and </span><code xml:space="preserve" id="code_001210" smilref="Machine_Learning00016.smil#code_001210">–r</code><span class="text" id="span_002651" smilref="Machine_Learning00016.smil#span_002651"> flags is suitable for most applications when you're running through basic delimited data.</span></p>
          </level3>
        </level2>
        <level2 id="level2_000130">
          <h2 id="bappxC-c0C_level1_5" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_5">Finding Unique Occurrences: uniq</h2>
          <p xml:space="preserve" id="p_001182"><span class="text" id="span_002652" smilref="Machine_Learning00016.smil#span_002652">Sometimes data will have repeat lines in them due to a data entry error or a slightly error-prone database query. Before raising your voice at the database operator (I have to look in the mirror to talk to my DBA), you can use the </span><code xml:space="preserve" id="code_001211" smilref="Machine_Learning00016.smil#code_001211">uniq</code><span class="text" id="span_002653" smilref="Machine_Learning00016.smil#span_002653"> command to extract all the unique lines.</span></p>
          <p xml:space="preserve" id="p_001183"><code class="preserve-whitespace" xml:space="preserve" id="code_001212" smilref="Machine_Learning00016.smil#code_001212">$ uniq sample.txt
987    1391548780   hhh bbb
988    1391548781   sda jjj
989    1391548782   asd asd
990    1391548783   gjh jkl
991    1391548784   abc abc
992    1391548785   ghj gjh
993    1391548785   hhh bbb
994    1391548785   sda jjj
995    1391548786   asd asd
996    1391548787   gjh jkl
997    1391548787   abc abc
998    1391548787   ghj gjh</code></p>
          <pagenum epub:type="pagebreak" id="p361" page="normal" smilref="Machine_Learning00016.smil#p361">361</pagenum>
          <p id="bappxC-bappxC-para-0027" xml:space="preserve"><span class="text" id="span_002654" smilref="Machine_Learning00016.smil#span_002654">Using </span><code xml:space="preserve" id="code_001213" smilref="Machine_Learning00016.smil#code_001213">uniq</code><span class="text" id="span_002655" smilref="Machine_Learning00016.smil#span_002655"> in combination with the </span><code xml:space="preserve" id="code_001214" smilref="Machine_Learning00016.smil#code_001214">–c</code><span class="text" id="span_002656" smilref="Machine_Learning00016.smil#span_002656"> flag, the output will contain the number of repeats that were found within the file. If you do not need to see the counts then you can use the </span><code xml:space="preserve" id="code_001215" smilref="Machine_Learning00016.smil#code_001215">–u</code><span class="text" id="span_002657" smilref="Machine_Learning00016.smil#span_002657"> flag in the </span><code xml:space="preserve" id="code_001216" smilref="Machine_Learning00016.smil#code_001216">sort</code><span class="text" id="span_002658" smilref="Machine_Learning00016.smil#span_002658"> command.</span></p>
        </level2>
        <level2 id="level2_000131">
          <h2 id="bappxC-c0C_level1_6" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_6">Showing the Top of a File: head</h2>
          <p xml:space="preserve" id="p_001184"><span class="text" id="span_002659" smilref="Machine_Learning00016.smil#span_002659">When you've downloaded a 10,000-line file and you want to quickly inspect it, it's so easy to use the </span><code xml:space="preserve" id="code_001217" smilref="Machine_Learning00016.smil#code_001217">cat</code><span class="text" id="span_002660" smilref="Machine_Learning00016.smil#span_002660"> command and dump the whole file out. Obviously, you can't read it as the lines are appearing faster than your eyes. The </span><code xml:space="preserve" id="code_001218" smilref="Machine_Learning00016.smil#code_001218">head</code><span class="text" id="span_002661" smilref="Machine_Learning00016.smil#span_002661"> command shows the output of a defined number of lines.</span></p>
          <p xml:space="preserve" id="p_001185"><code class="preserve-whitespace" xml:space="preserve" id="code_001219" smilref="Machine_Learning00016.smil#code_001219">$ head -n 5 sample.txt
987    1391548780   hhh bbb
988    1391548781   sda jjj
989    1391548782   asd asd
990    1391548783   gjh jkl
991    1391548784   abc abc</code></p>
          <p id="bappxC-bappxC-para-0029" xml:space="preserve"><span class="text" id="span_002662" smilref="Machine_Learning00016.smil#span_002662">If you want to show the last number of lines of the file, then use the </span><code xml:space="preserve" id="code_001220" smilref="Machine_Learning00016.smil#code_001220">tail</code><span class="text" id="span_002663" smilref="Machine_Learning00016.smil#span_002663"> command.</span></p>
        </level2>
        <level2 id="level2_000132">
          <h2 id="bappxC-c0C_level1_7" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_7">Counting Words: wc</h2>
          <p xml:space="preserve" id="p_001186"><span class="text" id="span_002664" smilref="Machine_Learning00016.smil#span_002664">Using </span><code xml:space="preserve" id="code_001221" smilref="Machine_Learning00016.smil#code_001221">wc</code><span class="text" id="span_002665" smilref="Machine_Learning00016.smil#span_002665"> counts the number of lines, words, and characters used within the text document.</span></p>
          <p xml:space="preserve" id="p_001187"><code class="preserve-whitespace" xml:space="preserve" id="code_001222" smilref="Machine_Learning00016.smil#code_001222">$ wc sample.txt
      13      48     277 sample.txt</code></p>
          <p id="bappxC-bappxC-para-0031" xml:space="preserve"><span class="text" id="span_002666" smilref="Machine_Learning00016.smil#span_002666">If you only want to see the number of lines, then use </span><code xml:space="preserve" id="code_001223" smilref="Machine_Learning00016.smil#code_001223">–l</code><span class="text" id="span_002667" smilref="Machine_Learning00016.smil#span_002667"> as an option, </span><code xml:space="preserve" id="code_001224" smilref="Machine_Learning00016.smil#code_001224">-w</code><span class="text" id="span_002668" smilref="Machine_Learning00016.smil#span_002668"> for words, and </span><code xml:space="preserve" id="code_001225" smilref="Machine_Learning00016.smil#code_001225">–m</code><span class="text" id="span_002669" smilref="Machine_Learning00016.smil#span_002669"> for characters.</span></p>
        </level2>
        <level2 id="level2_000133">
          <h2 id="bappxC-c0C_level1_8" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_8">Locating Anything: find</h2>
          <pagenum epub:type="pagebreak" id="p362" page="normal" smilref="Machine_Learning00016.smil#p362">362</pagenum>
          <p xml:space="preserve" id="p_001188"><span class="text" id="span_002670" smilref="Machine_Learning00016.smil#span_002670">The </span><code xml:space="preserve" id="code_001226" smilref="Machine_Learning00016.smil#code_001226">find</code><span class="text" id="span_002671" smilref="Machine_Learning00016.smil#span_002671"> command is one of my favorites. It takes a little getting used to, but once you do, it will be a big help to you.</span></p>
          <p id="bappxC-bappxC-para-0033" xml:space="preserve"><span class="text" id="span_002672" smilref="Machine_Learning00016.smil#span_002672">The syntax starts with a source directory (using a period [.] if you want to start in the current directory) and various text options. For example, here's what it looks like to run the </span><code xml:space="preserve" id="code_001227" smilref="Machine_Learning00016.smil#code_001227">find</code><span class="text" id="span_002673" smilref="Machine_Learning00016.smil#span_002673"> command on the home directory on my machine.</span></p>
          <p xml:space="preserve" id="p_001189"><code class="preserve-whitespace" xml:space="preserve" id="code_001228" smilref="Machine_Learning00016.smil#code_001228">$ find . -type f -name '*.txt' -print
./.gradle/caches/1.10/scripts/build_361heej71i7errcd096649rjns/ProjectScript/buildscript/classes/emptyScript.txt
./.gradle/caches/1.8/scripts/build_4p3rjceekul5gbo8of3d9h4hso/ProjectScript/buildscript/classes/emptyScript.txt
./.rvm/config/displayed-notes.txt
./.rvm/gems/ruby-1.9.2-p320/gems/arel-3.0.2/History.txt
./.rvm/gems/ruby-1.9.2-p320/gems/arel-3.0.2/Manifest.txt</code></p>
          <p id="bappxC-bappxC-para-0034" xml:space="preserve"><span class="text" id="span_002674" smilref="Machine_Learning00016.smil#span_002674">With the </span><code xml:space="preserve" id="code_001229" smilref="Machine_Learning00016.smil#code_001229">–type</code><span class="text" id="span_002675" smilref="Machine_Learning00016.smil#span_002675"> flag, I am looking for files (</span><code xml:space="preserve" id="code_001230" smilref="Machine_Learning00016.smil#code_001230">f</code><span class="text" id="span_002676" smilref="Machine_Learning00016.smil#span_002676">). </span><code xml:space="preserve" id="code_001231" smilref="Machine_Learning00016.smil#code_001231">–name</code><span class="text" id="span_002677" smilref="Machine_Learning00016.smil#span_002677"> gives the types of file I'm looking for—in this instance any file with the extension </span><code xml:space="preserve" id="code_001232" smilref="Machine_Learning00016.smil#code_001232">.txt</code><span class="text" id="span_002678" smilref="Machine_Learning00016.smil#span_002678">. I print the results with the </span><code xml:space="preserve" id="code_001233" smilref="Machine_Learning00016.smil#code_001233">–print</code><span class="text" id="span_002679" smilref="Machine_Learning00016.smil#span_002679"> flag.</span></p>
          <p id="bappxC-bappxC-para-0035" xml:space="preserve"><span class="text" id="span_002680" smilref="Machine_Learning00016.smil#span_002680">So far, there's nothing here that a few Unix commands couldn't do. The great thing about </span><code xml:space="preserve" id="code_001234" smilref="Machine_Learning00016.smil#code_001234">find</code><span class="text" id="span_002681" smilref="Machine_Learning00016.smil#span_002681"> is that you can use Unix commands within the command itself. Imagine you're looking for any files with the phrase “SOFTWARE IS PROVIDED” in the body of the text file:</span></p>
          <p xml:space="preserve" id="p_001190"><code class="preserve-whitespace" xml:space="preserve" id="code_001235" smilref="Machine_Learning00016.smil#code_001235">$ find . -type f -name "*.txt" -exec grep "SOFTWARE IS PROVIDED" {} \; -print
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
./.rvm/gems/ruby-1.9.2-p320/gems/arel-3.0.2/MIT-LICENSE.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
./.rvm/gems/ruby-1.9.2-p320/gems/polyglot-0.3.3/License.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
./.rvm/gems/ruby-1.9.2-p320/gems/polyglot-0.3.3/README.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
./.rvm/gems/ruby-1.9.2-p320/gems/rack-test-0.6.1/MIT-LICENSE.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
./.rvm/gems/ruby-1.9.2-p320/gems/rack-test-0.6.2/MIT-LICENSE.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
./.rvm/gems/ruby-1.9.2-p320/gems/uglifier-1.2.6/LICENSE.txt
THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
./.rvm/gems/ruby-1.9.2-p320/gems/uglifier-1.3.0/LICENSE.txt</code></p>
          <p id="bappxC-bappxC-para-0036" xml:space="preserve"><span class="text" id="span_002682" smilref="Machine_Learning00016.smil#span_002682">This example uses the standard </span><code xml:space="preserve" id="code_001236" smilref="Machine_Learning00016.smil#code_001236">grep</code><span class="text" id="span_002683" smilref="Machine_Learning00016.smil#span_002683"> command that is covered earlier in this chapter, but it replaces the filename with </span><code xml:space="preserve" id="code_001237" smilref="Machine_Learning00016.smil#code_001237">{}</code><span class="text" id="span_002684" smilref="Machine_Learning00016.smil#span_002684">, which is a placeholder for the filename on which the </span><code xml:space="preserve" id="code_001238" smilref="Machine_Learning00016.smil#code_001238">find</code><span class="text" id="span_002685" smilref="Machine_Learning00016.smil#span_002685"> command is working.</span></p>
          <p id="bappxC-bappxC-para-0037" xml:space="preserve"><code xml:space="preserve" id="code_001239" smilref="Machine_Learning00016.smil#code_001239">find</code><span class="text" id="span_002686" smilref="Machine_Learning00016.smil#span_002686">has saved my programming sanity many times over, and if I'm looking for a file that has a method name but I can't remember where it is (this happens a lot with large codebases), I don't have to fire up my IDE. I just use </span><code xml:space="preserve" id="code_001240" smilref="Machine_Learning00016.smil#code_001240">find</code><span class="text" id="span_002687" smilref="Machine_Learning00016.smil#span_002687"> from the command line.</span></p>
        </level2>
        <level2 id="level2_000134">
          <h2 id="bappxC-c0C_level1_9" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_9">Combining Commands and Redirecting Output</h2>
          <pagenum epub:type="pagebreak" id="p363" page="normal" smilref="Machine_Learning00016.smil#p363">363</pagenum>
          <p xml:space="preserve" id="p_001191"><span class="text" id="span_002688" smilref="Machine_Learning00016.smil#span_002688">The explanations for the Unix commands showed you how to use one command at a time. Using the pipe symbol (</span><code xml:space="preserve" id="code_001241" smilref="Machine_Learning00016.smil#code_001241">|</code><span class="text" id="span_002689" smilref="Machine_Learning00016.smil#span_002689">), you can chain these commands together. With the greater than symbol (</span><code xml:space="preserve" id="code_001242" smilref="Machine_Learning00016.smil#code_001242">&gt;</code><span class="text" id="span_002690" smilref="Machine_Learning00016.smil#span_002690">), you can redirect output to a new file.</span></p>
          <p xml:space="preserve" id="p_001192"><code class="preserve-whitespace" xml:space="preserve" id="code_001243" smilref="Machine_Learning00016.smil#code_001243">$ grep 'hhh' sample.txt | sort | less
987    1391548780   hhh bbb
993    1391548785   hhh bbb</code></p>
          <p id="bappxC-bappxC-para-0039" xml:space="preserve"><span class="text" id="span_002691" smilref="Machine_Learning00016.smil#span_002691">The preceding command uses </span><code xml:space="preserve" id="code_001244" smilref="Machine_Learning00016.smil#code_001244">grep</code><span class="text" id="span_002692" smilref="Machine_Learning00016.smil#span_002692"> to search for </span><code xml:space="preserve" id="code_001245" smilref="Machine_Learning00016.smil#code_001245">'hhh'</code><span class="text" id="span_002693" smilref="Machine_Learning00016.smil#span_002693"> in the </span><code xml:space="preserve" id="code_001246" smilref="Machine_Learning00016.smil#code_001246">sample.txt</code><span class="text" id="span_002694" smilref="Machine_Learning00016.smil#span_002694"> file and then runs the result through the </span><code xml:space="preserve" id="code_001247" smilref="Machine_Learning00016.smil#code_001247">sort</code><span class="text" id="span_002695" smilref="Machine_Learning00016.smil#span_002695"> command; this is then written to a new file called </span><code xml:space="preserve" id="code_001248" smilref="Machine_Learning00016.smil#code_001248">newsample.txt</code><span class="text" id="span_002696" smilref="Machine_Learning00016.smil#span_002696">. Finally, the output of the new file is sent to the console with </span><code xml:space="preserve" id="code_001249" smilref="Machine_Learning00016.smil#code_001249">cat</code><span class="text" id="span_002697" smilref="Machine_Learning00016.smil#span_002697">.</span></p>
        </level2>
        <level2 id="level2_000135">
          <h2 id="bappxC-c0C_level1_10" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-c0C_level1_10">Picking a Text Editor</h2>
          <p xml:space="preserve" id="p_001193" smilref="Machine_Learning00016.smil#p_001193">The choice of text editor is a very personal one, akin to liking a specific music group, sports team, or a favorite actor or actress. I'm not saying fights have broken out about these editors, but conversations over coffee and beer have sometimes been emotional. If you want to work out the personality type of a software developer, just ask him what text editor he uses.</p>
          <p id="bappxC-bappxC-para-0041" xml:space="preserve" smilref="Machine_Learning00016.smil#bappxC-bappxC-para-0041">Ultimately it's up to you what sort of text editor you'll use. You might not be using it all the hours of the day, but for the times you need to quickly look at or edit something, you'll want an editor that you can use fluently and without fuss.</p>
          <level3 id="level3_000242">
            <h3 xml:space="preserve" id="h3_000242" smilref="Machine_Learning00016.smil#h3_000242">Colon Frenzy: Vi and Vim</h3>
            <p xml:space="preserve" id="p_001194"><span class="text" id="span_002698" smilref="Machine_Learning00016.smil#span_002698">Vi (see </span><a id="bappxC-bappxC-fig-anc-0001" href="#bappxC-bappxC-fig-0001" external="false" smilref="Machine_Learning00016.smil#bappxC-bappxC-fig-anc-0001">Figure C-1</a><span class="text" id="span_002699" smilref="Machine_Learning00016.smil#span_002699">) was written in 1976 by Bill Joy and was introduced in 1978 when it was released as part of BSD Unix. Pronounced “vee eye,” it's been the mainstay of Unix system administrators for a long time. It's still one of the most widely used text editors today.</span></p>
            <figure id="figure_000120">
              <img class="center" src="images/bapp03f001.jpg" alt="image" id="img_000144" />
              <figcaption id="figcaption_000106">
                <p xml:space="preserve" id="p_001195"><span class="figureLabel" id="span_002700"><a id="bappxC-bappxC-fig-0001" href="#bappxC-bappxC-fig-anc-0001" external="false"><strong id="strong_000793" smilref="Machine_Learning00016.smil#strong_000793">Figure C-1</strong></a></span><span class="text" id="span_002701" smilref="Machine_Learning00016.smil#span_002701"> The vi editor</span></p>
              </figcaption>
            </figure>
            <p id="bappxC-bappxC-para-0043" xml:space="preserve"><span class="text" id="span_002702" smilref="Machine_Learning00016.smil#span_002702">The thing that makes vi challenging is the concept of “modes” for the arcane commands: There are line-oriented “ex” commands that operate on lines of text; they are needed to write the file (</span><code xml:space="preserve" id="code_001250" smilref="Machine_Learning00016.smil#code_001250">:w</code><span class="text" id="span_002703" smilref="Machine_Learning00016.smil#span_002703">) or quit the application (</span><code xml:space="preserve" id="code_001251" smilref="Machine_Learning00017.smil#code_001251">:q</code><span class="text" id="span_002704" smilref="Machine_Learning00017.smil#span_002704">). If you want to quit without saving, then </span><code xml:space="preserve" id="code_001252" smilref="Machine_Learning00017.smil#code_001252">:q!</code><span class="text" id="span_002705" smilref="Machine_Learning00017.smil#span_002705"> is needed. Likewise, overwriting an existing file uses </span><code xml:space="preserve" id="code_001253" smilref="Machine_Learning00017.smil#code_001253">:w!</code><span class="text" id="span_002706" smilref="Machine_Learning00017.smil#span_002706"> There is an “insert mode” while you are entering new text, and there is an “edit mode” for moving and changing text. Vi is so simple there is a coffee mug available with all (100%) of the vi commands on it.</span></p>
            <p id="bappxC-bappxC-para-0044" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxC-bappxC-para-0044">It takes time to learn the commands, how to delete lines, yank text into “buffers” then paste it, how to search for text, and other basic functions. After a bit of time, the “modes” actually becomes second nature. Vi includes a powerful “macro language” for adding your own commands or command sequences.</p>
            <pagenum epub:type="pagebreak" id="p364" page="normal" smilref="Machine_Learning00017.smil#p364">364</pagenum>
            <p id="bappxC-bappxC-para-0045" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxC-bappxC-para-0045">I'm still a user of vi; it covers most of my needs. Though, I have to admit it drove me mad when I first used it in 1995. I've still not moved over to vim (Vi iMproved), though it has windows, better editing, mouse support, and colorful syntax highlighting.</p>
          </level3>
          <level3 id="level3_000243">
            <h3 xml:space="preserve" id="h3_000243" smilref="Machine_Learning00017.smil#h3_000243">Nano</h3>
            <p xml:space="preserve" id="p_001196"><span class="text" id="span_002707" smilref="Machine_Learning00017.smil#span_002707">For those that can't cope with the colon command, the nano editor (see </span><a id="bappxC-bappxC-fig-anc-0002" href="#bappxC-bappxC-fig-0002" external="false" smilref="Machine_Learning00017.smil#bappxC-bappxC-fig-anc-0002">Figure C-2</a><span class="text" id="span_002708" smilref="Machine_Learning00017.smil#span_002708">) provides command-line heaven without all the complication. The nano editor lets you navigate around using the arrow keys (vi uses the h, j, k, and l keys for navigating). The editor includes a decent number of hints at the bottom of the screen, so you can see how you can save and quit.</span></p>
            <figure id="figure_000121">
              <img class="center" src="images/bapp03f002.jpg" alt="image" id="img_000145" />
              <figcaption id="figcaption_000107">
                <p xml:space="preserve" id="p_001197"><span class="figureLabel" id="span_002709"><a id="bappxC-bappxC-fig-0002" href="#bappxC-bappxC-fig-anc-0002" external="false"><strong id="strong_000794" smilref="Machine_Learning00017.smil#strong_000794">Figure C-2</strong></a></span> <pagenum epub:type="pagebreak" id="p365" page="normal" smilref="Machine_Learning00017.smil#p365">365</pagenum><span class="text" id="span_002710" smilref="Machine_Learning00017.smil#span_002710">The nano editor</span></p>
              </figcaption>
            </figure>
            <p id="bappxC-bappxC-para-0047" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxC-bappxC-para-0047">For sheer speed of loading, editing, saving, and exiting a document, the nano is a very good choice.</p>
          </level3>
          <level3 id="level3_000244">
            <h3 xml:space="preserve" id="h3_000244" smilref="Machine_Learning00017.smil#h3_000244">Emacs</h3>
            <p xml:space="preserve" id="p_001198"><span class="text" id="span_002711" smilref="Machine_Learning00017.smil#span_002711">Compared to vi and nano, Emacs (see </span><a id="bappxC-bappxC-fig-anc-0003" href="#bappxC-bappxC-fig-0003" external="false" smilref="Machine_Learning00017.smil#bappxC-bappxC-fig-anc-0003">Figure C-3</a><span class="text" id="span_002712" smilref="Machine_Learning00017.smil#span_002712">) is the big gun of the text editors. It's highly customizable and configurable. With the resurgence in Lisp-like languages, Clojure being an example, usage of Emacs is on the rise.</span></p>
            <figure id="figure_000122">
              <img class="center" src="images/bapp03f003.jpg" alt="image" id="img_000146" />
              <figcaption id="figcaption_000108">
                <p xml:space="preserve" id="p_001199"><span class="figureLabel" id="span_002713"><a id="bappxC-bappxC-fig-0003" href="#bappxC-bappxC-fig-anc-0003" external="false"><strong id="strong_000795" smilref="Machine_Learning00017.smil#strong_000795">Figure C-3</strong></a></span><span class="text" id="span_002714" smilref="Machine_Learning00017.smil#span_002714"> The Emacs editor</span></p>
              </figcaption>
            </figure>
            <p id="bappxC-bappxC-para-0049" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxC-bappxC-para-0049">Richard Stallman and Guy Steel, Jr. wrote the original program in 1976. If you want to try Emacs I'd recommend the xemacs version of the program.</p>
            <p id="bappxC-bappxC-para-0050" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxC-bappxC-para-0050">Emacs bypasses the whole insert mode issue that vi users are willing to adopt. Like nano, in Emacs you type onscreen and you see the changes. It also has more than 2,000 built-in commands for those who are happy to use Emacs as their main editor for everything. It is extensible by writing Lisp programs. To exit Emacs if you start it accidentally, press Ctrl-X Ctrl-C.</p>
          </level3>
        </level2>
      </level1>
      <level1 id="bappxD">
        <header id="header_000016">
          <h1 xml:space="preserve" id="h1_000004" smilref="Machine_Learning00017.smil#h1_000004">Appendix D Further Reading</h1>
        </header>
        <pagenum epub:type="pagebreak" id="p367" page="normal" smilref="Machine_Learning00017.smil#p367">367</pagenum>
        <p xml:space="preserve" id="p_001200" smilref="Machine_Learning00017.smil#p_001200">Machine learning is only part of the story; it's the application of knowing what to use to get the insight you need. The domain of data science combines several disciplines that cover programming, math, domain knowledge, and visualization.</p>
        <p id="bappxD-bappxD-para-0002" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0002">It's very rare for one book to cover it all. To that end, I've included some further reading that will be of help to you on your machine learning and data journey. (I know what you're thinking, and yes, I have bought and read all of these books.)</p>
        <level2 id="level2_000136">
          <h2 id="bappxD-c0D_level1_1" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_1">Machine Learning</h2>
          <p xml:space="preserve" id="p_001201" smilref="Machine_Learning00017.smil#p_001201">The machine learning arena is a huge domain and the majority of the books written are big, in-depth, heavy affairs that can take time to read, digest, and appreciate. Two stand out:</p>
          <p id="bappxD-bappxD-para-0004" xml:space="preserve"><em id="em_000368" smilref="Machine_Learning00017.smil#em_000368">Data Mining – Practical Machine Learning Tools and Techniques</em><span class="text" id="span_002715" smilref="Machine_Learning00017.smil#span_002715"> by Ian H. Witten, Eibe Frank, and Mark A. Hall (Morgan Kaufmann, 2011, ISBN 9780123748560).</span></p>
          <p id="bappxD-bappxD-para-0005" xml:space="preserve"><em id="em_000369" smilref="Machine_Learning00017.smil#em_000369">Collective Intelligence in Action</em><span class="text" id="span_002716" smilref="Machine_Learning00017.smil#span_002716"> by Satnam Alag (Manning, 2008, ISBN 9781933988313).</span></p>
        </level2>
        <level2 id="level2_000137">
          <h2 id="bappxD-c0D_level1_2" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_2">Statistics</h2>
          <pagenum epub:type="pagebreak" id="p368" page="normal" smilref="Machine_Learning00017.smil#p368">368</pagenum>
          <p xml:space="preserve" id="p_001202" smilref="Machine_Learning00017.smil#p_001202">More and more emphasis is being put on statistical knowledge and its application. Sometimes it feels hard to get into, especially for software developers, so these two titles will help you along:</p>
          <p id="bappxD-bappxD-para-0007" xml:space="preserve"><em id="em_000370" smilref="Machine_Learning00017.smil#em_000370">Naked Statistics: Stripping the Dread from the Data</em><span class="text" id="span_002717" smilref="Machine_Learning00017.smil#span_002717"> by Charles Wheelan (Norton, 2013, ISBN 9780393071955).</span></p>
          <p id="bappxD-bappxD-para-0008" xml:space="preserve"><em id="em_000371" smilref="Machine_Learning00017.smil#em_000371">Keeping Up with the Quants: Your Guide to Understanding and Using Analytics</em><span class="text" id="span_002718" smilref="Machine_Learning00017.smil#span_002718"> by Thomas H. Davenport and Jinho Kim (Harvard Business Review Press, 2013, ISBN 9781422187258).</span></p>
        </level2>
        <level2 id="level2_000138">
          <h2 id="bappxD-c0D_level1_3" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_3">Big Data and Data Science</h2>
          <p xml:space="preserve" id="p_001203" smilref="Machine_Learning00017.smil#p_001203">Regardless of whether you are a supporter of the term “Big Data,” there's no denying the impact that data has on industry. In Big Data, planning is key, and it's important to have a proper understanding of the implications of planning and insight.</p>
          <p id="bappxD-bappxD-para-0010" xml:space="preserve"><em id="em_000372" smilref="Machine_Learning00017.smil#em_000372">Data Just Right: Introduction to Large-Scale Data &amp; Analytics</em><span class="text" id="span_002719" smilref="Machine_Learning00017.smil#span_002719"> by Michael Manoochehri (Addison-Wesley, 2014, ISBN 9780321898654).</span></p>
          <p id="bappxD-bappxD-para-0011" xml:space="preserve"><em id="em_000373" smilref="Machine_Learning00017.smil#em_000373">Big Data: Understanding How Data Powers Big Business</em><span class="text" id="span_002720" smilref="Machine_Learning00017.smil#span_002720"> by Bill Schmarzo (Wiley, 2013, ISBN 9781118739570).</span></p>
          <p id="bappxD-bappxD-para-0012" xml:space="preserve"><em id="em_000374" smilref="Machine_Learning00017.smil#em_000374">Big Data</em><span class="text" id="span_002721" smilref="Machine_Learning00017.smil#span_002721"> @ </span><em id="em_000375" smilref="Machine_Learning00017.smil#em_000375">Work: Dispelling the Myths, Uncovering the Opportunities</em><span class="text" id="span_002722" smilref="Machine_Learning00017.smil#span_002722"> by Thomas H. Davenport (Harvard Business Review Press, 2014, 9781422168165).</span></p>
          <p id="bappxD-bappxD-para-0013" xml:space="preserve"><em id="em_000376" smilref="Machine_Learning00017.smil#em_000376">Big Data: A Revolution That Will Transform How We Live, Work, and Think</em><span class="text" id="span_002723" smilref="Machine_Learning00017.smil#span_002723"> by Viktor Mayer-Schonberger and Kenneth Cukier (Eamon Dolan/Houghton Mifflin Harcourt, 2013, ISBN 9780544002692).</span></p>
          <p id="bappxD-bappxD-para-0014" xml:space="preserve"><em id="em_000377" smilref="Machine_Learning00017.smil#em_000377">Data Smart: Using Data Science to Transform Information into Insight</em><span class="text" id="span_002724" smilref="Machine_Learning00017.smil#span_002724"> by John W. Foreman (Wiley, 2013, ISBN 9781118661468).</span></p>
          <p id="bappxD-bappxD-para-0015" xml:space="preserve"><em id="em_000378" smilref="Machine_Learning00017.smil#em_000378">Data Science for Business: What You Need To Know About Data Mining and Data-Analytic Thinking</em><span class="text" id="span_002725" smilref="Machine_Learning00017.smil#span_002725"> by Foster Provost and Tom Fawcett (O'Reilly Media, 2013, ISBN 9781449361327).</span></p>
        </level2>
        <level2 id="level2_000139">
          <h2 id="bappxD-c0D_level1_4" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_4">Hadoop</h2>
          <p xml:space="preserve" id="p_001204" smilref="Machine_Learning00017.smil#p_001204">The Hadoop platform has earned its place as the tool of use for distributed computing. It has transformed how companies can process volumes of data over commodity hardware. Although Hadoop 1.x was about the processing of blocks of data, Hadoop 2.x is about the data platform as an enterprise operating system. These books will get you up to speed:</p>
          <p id="bappxD-bappxD-para-0017" xml:space="preserve"><em id="em_000379" smilref="Machine_Learning00017.smil#em_000379">Apache Hadoop YARN: Moving Beyond MapReduce and Batch Processing with Apache Hadoop 2</em><span class="text" id="span_002726" smilref="Machine_Learning00017.smil#span_002726"> by Arun C. Murthy, Vinod Kumar Vavilapalli, Doug Eadline, Joseph Niemiec, and Jeff Markham (Addison-Wesley, 2014, ISBN 9780321934505).</span></p>
          <pagenum epub:type="pagebreak" id="p369" page="normal" smilref="Machine_Learning00017.smil#p369">369</pagenum>
          <p id="bappxD-bappxD-para-0018" xml:space="preserve"><em id="em_000380" smilref="Machine_Learning00017.smil#em_000380">Professional Hadoop Solutions</em><span class="text" id="span_002727" smilref="Machine_Learning00017.smil#span_002727"> by Boris Lublinsky, Kevin T. Smith, and Alexey Yakubovich (Wiley, 2013, ISBN 9781118611937)</span></p>
          <p id="bappxD-bappxD-para-0019" xml:space="preserve"><em id="em_000381" smilref="Machine_Learning00017.smil#em_000381">Hadoop: The Definitive Guide</em><span class="text" id="span_002728" smilref="Machine_Learning00017.smil#span_002728"> by Tom White (O'Reilly Media, 2012, ISBN 9781449311520).</span></p>
          <p id="bappxD-bappxD-para-0020" xml:space="preserve"><em id="em_000382" smilref="Machine_Learning00017.smil#em_000382">Programming Pig</em><span class="text" id="span_002729" smilref="Machine_Learning00017.smil#span_002729"> by Alan Gates (O'Reilly Media, 2011, ISBN 9781449302641).</span></p>
        </level2>
        <level2 id="level2_000140">
          <h2 id="bappxD-c0D_level1_5" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_5">Visualization</h2>
          <p xml:space="preserve" id="p_001205" smilref="Machine_Learning00017.smil#p_001205">My book concentrates on the pure back-end processing of data with machine learning techniques, but do not discount the power of visualization to communicate your results. These books will help:</p>
          <p id="bappxD-bappxD-para-0022" xml:space="preserve"><em id="em_000383" smilref="Machine_Learning00017.smil#em_000383">Visualize This: The Flowing Data Guide to Design, Visualization, and Statistics</em><span class="text" id="span_002730" smilref="Machine_Learning00017.smil#span_002730"> by Nathan Yau (Wiley, 2011, ISBN 9780470944882).</span></p>
          <p id="bappxD-bappxD-para-0023" xml:space="preserve"><em id="em_000384" smilref="Machine_Learning00017.smil#em_000384">Information Is Beautiful</em><span class="text" id="span_002731" smilref="Machine_Learning00017.smil#span_002731"> by David McCandless (Harper Collins, 2012, ISBN 9780007492893).</span></p>
          <p id="bappxD-bappxD-para-0024" xml:space="preserve"><em id="em_000385" smilref="Machine_Learning00017.smil#em_000385">Facts Are Sacred</em><span class="text" id="span_002732" smilref="Machine_Learning00017.smil#span_002732"> by Simon Rogers (Faber &amp; Faber, 2013, 9780571301614).</span></p>
        </level2>
        <level2 id="level2_000141">
          <h2 id="bappxD-c0D_level1_6" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_6">Making Decisions</h2>
          <p xml:space="preserve" id="p_001206" smilref="Machine_Learning00017.smil#p_001206">The key to machine learning projects is making good decisions. With insight in hand, you can form next steps. The books listed here aren't software oriented at all, but they will give you vast pools of thinking about how to process and make decisions with the information you have:</p>
          <p id="bappxD-bappxD-para-0026" xml:space="preserve"><em id="em_000386" smilref="Machine_Learning00017.smil#em_000386">Eyes Wide Open</em><span class="text" id="span_002733" smilref="Machine_Learning00017.smil#span_002733"> by Noreena Hertz (HarperCollins, 2013, ISBN 9780062268617).</span></p>
          <p id="bappxD-bappxD-para-0027" xml:space="preserve"><em id="em_000387" smilref="Machine_Learning00017.smil#em_000387">The Signal and the Noise: Why So Many Predictions Fail—but Some Don't</em><span class="text" id="span_002734" smilref="Machine_Learning00017.smil#span_002734"> by Nate Silver (Penguin Books, 2012, ISBN 9781594204111).</span></p>
          <p id="bappxD-bappxD-para-0028" xml:space="preserve"><em id="em_000388" smilref="Machine_Learning00017.smil#em_000388">Risk Savvy: How to Make Good Decisions</em><span class="text" id="span_002735" smilref="Machine_Learning00017.smil#span_002735"> by Gerd Gigerenzer (Penguin Books, 2014, ISBN 9780670025657).</span></p>
          <p id="bappxD-bappxD-para-0029" xml:space="preserve"><em id="em_000389" smilref="Machine_Learning00017.smil#em_000389">Lean Analytics: Use Data to Build a Better Startup Faster</em><span class="text" id="span_002736" smilref="Machine_Learning00017.smil#span_002736"> by Alistair Croll and Benjamin Yoskovitz (O'Reilly Media, 2013, ISBN 9781449335670).</span></p>
        </level2>
        <level2 id="level2_000142">
          <h2 id="bappxD-c0D_level1_7" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_7">Datasets</h2>
          <p xml:space="preserve" id="p_001207" smilref="Machine_Learning00017.smil#p_001207">Sometimes it's hard to find data to play with. Luckily, there are a few websites with loads of the stuff to download:</p>
          <list type="ul" id="list_000072">
            <li id="li_000477">
              <p class="listpara1" id="bappxD-bappxD-para-0031" xml:space="preserve"><strong id="strong_000796" smilref="Machine_Learning00017.smil#strong_000796">UCI Machine Learning Repository:</strong> <code xml:space="preserve" id="code_001254"><a href="http://archive.ics.uci.edu/ml/" external="true" id="a_000327" smilref="Machine_Learning00017.smil#a_000327">http://archive.ics.uci.edu/ml/</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0032" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0032">The UCI maintains 290 datasets covering many different domains. What's the most popular downloaded dataset? It's still the iris.</p>
            </li>
            <li id="li_000478">
              <p class="listpara1" id="bappxD-bappxD-para-0033" xml:space="preserve"><strong id="strong_000797" smilref="Machine_Learning00017.smil#strong_000797">Hilary Mason:</strong> <code xml:space="preserve" id="code_001255"><a href="http://bit.ly/bundles/hmason/1" external="true" id="a_000328" smilref="Machine_Learning00017.smil#a_000328">http://bit.ly/bundles/hmason/1</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0034" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0034">Hilary is Scientist Emeritus at Bitly, and she's also a fan of data and cheeseburgers. The website gives you links to research-quality datasets that you can use.</p>
            </li>
            <pagenum epub:type="pagebreak" id="p370" page="normal" smilref="Machine_Learning00017.smil#p370">370</pagenum>
            <li id="li_000479">
              <p class="listpara1" id="bappxD-bappxD-para-0035" xml:space="preserve"><strong id="strong_000798" smilref="Machine_Learning00017.smil#strong_000798">Quora:</strong> <code xml:space="preserve" id="code_001256"><a href="http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public" external="true" id="a_000329" smilref="Machine_Learning00017.smil#a_000329">http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0036" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0036">Here you'll find a long list of URLs covering all sorts of topics that you can investigate. (This site requires you to sign in.)</p>
            </li>
          </list>
        </level2>
        <level2 id="level2_000143">
          <h2 id="bappxD-c0D_level1_8" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_8">Blogs</h2>
          <p xml:space="preserve" id="p_001208" smilref="Machine_Learning00017.smil#p_001208">And they said RSS feeds were dead…I don't think so! There are a few blogs that I keep an eye on regularly, and these are the ones that relate to what is covered in this book:</p>
          <list type="ul" id="list_000073">
            <li id="li_000480">
              <p class="listpara1" id="bappxD-bappxD-para-0038" xml:space="preserve"><strong id="strong_000799" smilref="Machine_Learning00017.smil#strong_000799">FiveThirtyEight:</strong> <code xml:space="preserve" id="code_001257"><a href="http://www.fivethirtyeight.com" external="true" id="a_000330" smilref="Machine_Learning00017.smil#a_000330">http://www.fivethirtyeight.com</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0039" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0039">Nate Silver and a team of contributors build this daily digest of stories with data, covering everything from politics down to which is the best burrito in the United States.</p>
            </li>
            <li id="li_000481">
              <p class="listpara1" id="bappxD-bappxD-para-0040" xml:space="preserve"><strong id="strong_000800" smilref="Machine_Learning00017.smil#strong_000800">Radar:</strong> <code xml:space="preserve" id="code_001258"><a href="http://radar.oreilly.com" external="true" id="a_000331" smilref="Machine_Learning00017.smil#a_000331">http://radar.oreilly.com</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0041" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0041">This site for emerging technologies is worth checking out for the daily “Four Short Links,” which pinpoints some very interesting programs, stories, and case studies from around the Internet.</p>
            </li>
            <li id="li_000482">
              <p class="listpara1" id="bappxD-bappxD-para-0042" xml:space="preserve"><strong id="strong_000801" smilref="Machine_Learning00017.smil#strong_000801">MathBabe:</strong> <code xml:space="preserve" id="code_001259"><a href="http://mathbabe.org" external="true" id="a_000332" smilref="Machine_Learning00017.smil#a_000332">http://mathbabe.org</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0043" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0043">Cathy O'Neill's blog discusses data, quantitative issues, and other subjects within the analytics arena.</p>
            </li>
          </list>
        </level2>
        <level2 id="level2_000144">
          <h2 id="bappxD-c0D_level1_9" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_9">Useful Websites</h2>
          <p xml:space="preserve" id="p_001209" smilref="Machine_Learning00017.smil#p_001209">Although Google does a very good job of showing you where to find the best sites, I still refer to the following sites when I'm looking for specifics.</p>
          <list type="ul" id="list_000074">
            <li id="li_000483">
              <p class="listpara1" id="bappxD-bappxD-para-0045" xml:space="preserve"><strong id="strong_000802" smilref="Machine_Learning00017.smil#strong_000802">Wiley:</strong> <code xml:space="preserve" id="code_001260"><a href="http://www.wiley.com" external="true" id="a_000333" smilref="Machine_Learning00017.smil#a_000333">http://www.wiley.com</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0046" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0046">This is the main website for all Wiley books and also the place to go for the sample code examples for this book.</p>
            </li>
            <li id="li_000484">
              <p class="listpara1" id="bappxD-bappxD-para-0047" xml:space="preserve"><strong id="strong_000803" smilref="Machine_Learning00017.smil#strong_000803">Stack Overflow:</strong> <code xml:space="preserve" id="code_001261"><a href="http://www.stackoverflow.com" external="true" id="a_000334" smilref="Machine_Learning00017.smil#a_000334">http://www.stackoverflow.com</a></code></p>
              <p class="listpara1" id="bappxD-bappxD-para-0048" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-bappxD-para-0048">A community of developers helping a community of developers, what's not to like? This site is definitely worth a quick look for answers on coding, servers, and machine learning.</p>
            </li>
          </list>
        </level2>
        <level2 id="level2_000145">
          <h2 id="bappxD-c0D_level1_10" xml:space="preserve" smilref="Machine_Learning00017.smil#bappxD-c0D_level1_10">The Tools of the Trade</h2>
          <p xml:space="preserve" id="p_001210" smilref="Machine_Learning00017.smil#p_001210">Here are the links to the tools that are used in this book. It's worth having them bookmarked for updates and announcements.</p>
          <p xml:space="preserve" id="p_001211"><strong id="strong_000804"><pagenum epub:type="pagebreak" id="p371" page="normal" smilref="Machine_Learning00017.smil#p371">371</pagenum><span class="text" id="span_002737" smilref="Machine_Learning00017.smil#span_002737">Apache Hadoop:</span></strong> <code xml:space="preserve" id="code_001262"><a href="http://hadoop.apache.org" external="true" id="a_000335" smilref="Machine_Learning00017.smil#a_000335">http://hadoop.apache.org</a></code></p>
          <p xml:space="preserve" id="p_001212"><strong id="strong_000805" smilref="Machine_Learning00017.smil#strong_000805">SpringXD:</strong> <code xml:space="preserve" id="code_001263"><a href="http://projects.spring.io/spring-xd" external="true" id="a_000336" smilref="Machine_Learning00017.smil#a_000336">http://projects.spring.io/spring-xd</a></code></p>
          <p xml:space="preserve" id="p_001213"><strong id="strong_000806" smilref="Machine_Learning00017.smil#strong_000806">Weka:</strong> <code xml:space="preserve" id="code_001264"><a href="http://www.cs.waikato.ac.nz/ml/weka" external="true" id="a_000337" smilref="Machine_Learning00017.smil#a_000337">http://www.cs.waikato.ac.nz/ml/weka</a></code></p>
          <p xml:space="preserve" id="p_001214"><strong id="strong_000807" smilref="Machine_Learning00017.smil#strong_000807">Mahout:</strong> <code xml:space="preserve" id="code_001265"><a href="http://mahout.apache.org" external="true" id="a_000338" smilref="Machine_Learning00017.smil#a_000338">http://mahout.apache.org</a></code></p>
        </level2>
      </level1>
      <level1 id="titlepage">
        <section class="titlePage" epub:type="titlepage" id="section_000014">
          <header id="header_000017">
            <h1 class="bookTitle" id="titlepage-titlepage" xml:space="preserve" smilref="Machine_Learning00017.smil#titlepage-titlepage">Machine Learning Hands-On for Developers and Technical Professionals</h1>
          </header>
          <section id="section_000015">
            <div class="authorGroup" id="div_000020">
              <div class="bookAuthor" id="div_000021">
                <p class="affiliation" xml:space="preserve" id="p_001215" smilref="Machine_Learning00017.smil#p_001215"> </p>
                <p class="affiliation" xml:space="preserve" id="p_001216" smilref="Machine_Learning00017.smil#p_001216"> </p>
                <p class="bookEditor" xml:space="preserve" id="p_001217"><strong id="strong_000808" smilref="Machine_Learning00017.smil#strong_000808">Jason Bell</strong></p>
                <p class="affiliation" xml:space="preserve" id="p_001218" smilref="Machine_Learning00017.smil#p_001218"> </p>
                <p class="affiliation" xml:space="preserve" id="p_001219" smilref="Machine_Learning00017.smil#p_001219"> </p>
                <p class="affiliation" xml:space="preserve" id="p_001220" smilref="Machine_Learning00017.smil#p_001220"> </p>
                <p class="affiliation" xml:space="preserve" id="p_001221" smilref="Machine_Learning00017.smil#p_001221"> </p>
              </div>
            </div>
            <p class="publisherWordMark" xml:space="preserve" id="p_001222"><img class="center" src="images/titlepage_fmt.png" alt="Title Page" id="img_000147" /> </p>
          </section>
        </section>
      </level1>
      <level1 id="f00">
        <section class="copyright" epub:type="copyright-page" id="section_000016">
          <p class="copyright" id="f00-f0" xml:space="preserve"><strong id="strong_000809" smilref="Machine_Learning00017.smil#strong_000809">Machine Learning: Hands-On for Developers and Technical Professionals</strong></p>
          <p class="copyright" xml:space="preserve" id="p_001223"><span class="text" id="span_002738" smilref="Machine_Learning00017.smil#span_002738">Published by</span><br id="br_000001" /><span class="text" id="span_002739" smilref="Machine_Learning00017.smil#span_002739">John Wiley &amp; Sons, Inc.</span><br id="br_000002" /><span class="text" id="span_002740" smilref="Machine_Learning00017.smil#span_002740">10475 Crosspoint Boulevard</span><br id="br_000003" /><span class="text" id="span_002741" smilref="Machine_Learning00017.smil#span_002741">Indianapolis, IN 46256</span><br id="br_000004" /><code xml:space="preserve" id="code_001266"><a href="http://www.wiley.com" external="true" id="a_000339" smilref="Machine_Learning00017.smil#a_000339">www.wiley.com</a></code></p>
          <p class="copyright" xml:space="preserve" id="p_001224"><span class="text" id="span_002742" smilref="Machine_Learning00017.smil#span_002742">Copyright © 2015 by John Wiley &amp; Sons, Inc., Indianapolis, Indiana</span><br id="br_000005" /><span class="text" id="span_002743" smilref="Machine_Learning00017.smil#span_002743">Published simultaneously in Canada</span></p>
          <p class="copyright" xml:space="preserve" id="p_001225"><span class="text" id="span_002744" smilref="Machine_Learning00017.smil#span_002744">ISBN: 978-1-118-88906-0</span><br id="br_000006" /><span class="text" id="span_002745" smilref="Machine_Learning00017.smil#span_002745">ISBN: 978-1-118-88939-8 (ebk)</span><br id="br_000007" /><span class="text" id="span_002746" smilref="Machine_Learning00017.smil#span_002746">ISBN: 978-1-118-88949-7 (ebk)</span></p>
          <p class="copyright" xml:space="preserve" id="p_001226" smilref="Machine_Learning00017.smil#p_001226">Manufactured in the United States of America </p>
          <p class="copyright" xml:space="preserve" id="p_001227" smilref="Machine_Learning00017.smil#p_001227">10 9 8 7 6 5 4 3 2 1</p>
          <p class="copyright" xml:space="preserve" id="p_001228"><span class="text" id="span_002747" smilref="Machine_Learning00017.smil#span_002747">No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley &amp; Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at </span><code xml:space="preserve" id="code_001267"><a href="http://www.wiley.com/go/permissions" external="true" id="a_000340" smilref="Machine_Learning00017.smil#a_000340">http://www.wiley.com/go/permissions</a></code><span class="text" id="span_002748" smilref="Machine_Learning00017.smil#span_002748">.</span></p>
          <p class="copyright" xml:space="preserve" id="p_001229"><strong id="strong_000810" smilref="Machine_Learning00017.smil#strong_000810">Limit of Liability/Disclaimer of Warranty:</strong><span class="text" id="span_002749" smilref="Machine_Learning00017.smil#span_002749"> The publisher and the author make no representations or warranties with respect to the accuracy or completeness of the contents of this work and specifically disclaim all warranties, including without limitation warranties of fitness for a particular purpose. No warranty may be created or extended by sales or promotional materials. The advice and strategies contained herein may not be suitable for every situation. This work is sold with the understanding that the publisher is not engaged in rendering legal, accounting, or other professional services. If professional assistance is required, the services of a competent professional person should be sought. Neither the publisher nor the author shall be liable for damages arising herefrom. The fact that an organization or Web site is referred to in this work as a citation and/or a potential source of further information does not mean that the author or the publisher endorses the information the organization or website may provide or recommendations it may make. Further, readers should be aware that Internet websites listed in this work may have changed or disappeared between when this work was written and when it is read.</span></p>
          <p class="copyright" xml:space="preserve" id="p_001230" smilref="Machine_Learning00017.smil#p_001230">For general information on our other products and services please contact our Customer Care Department within the United States at (877) 762-2974, outside the United States at (317) 572-3993 or fax (317) 572-4002.</p>
          <p class="copyright" xml:space="preserve" id="p_001231"><span class="text" id="span_002750" smilref="Machine_Learning00017.smil#span_002750">Wiley publishes in a variety of print and electronic formats and by print-on-demand. Some material included with standard print versions of this book may not be included in e-books or in print-on-demand. If this book refers to media such as a CD or DVD that is not included in the version you purchased, you may download this material at </span><code xml:space="preserve" id="code_001268"><a href="http://booksupport.wiley.com" external="true" id="a_000341" smilref="Machine_Learning00017.smil#a_000341">booksupport.wiley.com.</a></code><span class="text" id="span_002751" smilref="Machine_Learning00017.smil#span_002751">. For more information about Wiley products, visit </span><code xml:space="preserve" id="code_001269"><a href="http://www.wiley.com" external="true" id="a_000342" smilref="Machine_Learning00017.smil#a_000342">www.wiley.com</a></code><span class="text" id="span_002752" smilref="Machine_Learning00017.smil#span_002752">.</span></p>
          <p class="copyright" xml:space="preserve" id="p_001232"><strong id="strong_000811" smilref="Machine_Learning00017.smil#strong_000811">Library of Congress Control Number:</strong><span class="text" id="span_002753" smilref="Machine_Learning00017.smil#span_002753"> 2014946682</span></p>
          <p class="copyright" xml:space="preserve" id="p_001233"><strong id="strong_000812" smilref="Machine_Learning00017.smil#strong_000812">Trademarks:</strong><span class="text" id="span_002754" smilref="Machine_Learning00017.smil#span_002754"> Wiley and the Wiley logo are trademarks or registered trademarks of John Wiley &amp; Sons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without written permission. All other trademarks are the property of their respective owners. John Wiley &amp; Sons, Inc. is not associated with any product or vendor mentioned in this book.</span></p>
        </section>
      </level1>
      <level1 id="f01">
        <section class="dedication" epub:type="dedication" id="section_000017">
          <p id="f01-f1" xml:space="preserve"><em id="em_000390"><span class="text" id="span_002755" smilref="Machine_Learning00017.smil#span_002755">To </span><pagenum epub:type="pagebreak" id="piii" page="front" smilref="Machine_Learning00017.smil#piii">iii</pagenum><span class="text" id="span_002756" smilref="Machine_Learning00017.smil#span_002756">Wendy and Clarissa</span></em><span class="text" id="span_002757" smilref="Machine_Learning00017.smil#span_002757">.</span></p>
        </section>
      </level1>
      <level1 id="f02">
        <section id="section_000018">
          <header id="header_000018">
            <h1 id="f02-f2" xml:space="preserve" smilref="Machine_Learning00017.smil#f02-f2">Credits</h1>
          </header>
          <p xml:space="preserve" id="p_001234"><strong id="strong_000813"><span class="text" id="span_002758" smilref="Machine_Learning00017.smil#span_002758">Executive</span><pagenum epub:type="pagebreak" id="piv" page="front" smilref="Machine_Learning00017.smil#piv">iv</pagenum><span class="text" id="span_002759" smilref="Machine_Learning00017.smil#span_002759"> Editor</span></strong></p>
          <p xml:space="preserve" id="p_001235" smilref="Machine_Learning00017.smil#p_001235">Carol Long</p>
          <p xml:space="preserve" id="p_001236"><strong id="strong_000814" smilref="Machine_Learning00017.smil#strong_000814">Project Editor</strong></p>
          <p xml:space="preserve" id="p_001237" smilref="Machine_Learning00017.smil#p_001237">Charlotte Kughen</p>
          <p xml:space="preserve" id="p_001238"><strong id="strong_000815" smilref="Machine_Learning00017.smil#strong_000815">Technical Editor</strong></p>
          <p xml:space="preserve" id="p_001239" smilref="Machine_Learning00017.smil#p_001239">Mitchell Wyle</p>
          <p xml:space="preserve" id="p_001240"><strong id="strong_000816" smilref="Machine_Learning00017.smil#strong_000816">Production Editor</strong></p>
          <p xml:space="preserve" id="p_001241" smilref="Machine_Learning00017.smil#p_001241">Christine Mugnolo</p>
          <p xml:space="preserve" id="p_001242"><strong id="strong_000817" smilref="Machine_Learning00017.smil#strong_000817">Copy Editor</strong></p>
          <p xml:space="preserve" id="p_001243" smilref="Machine_Learning00017.smil#p_001243">Katherine Burt</p>
          <p xml:space="preserve" id="p_001244"><strong id="strong_000818" smilref="Machine_Learning00017.smil#strong_000818">Production Manager</strong></p>
          <p xml:space="preserve" id="p_001245" smilref="Machine_Learning00017.smil#p_001245">Kathleen Wisor</p>
          <p xml:space="preserve" id="p_001246"><strong id="strong_000819" smilref="Machine_Learning00017.smil#strong_000819">Manager of Content Development and Assembly</strong></p>
          <p xml:space="preserve" id="p_001247" smilref="Machine_Learning00017.smil#p_001247">Mary Beth Wakefield</p>
          <p xml:space="preserve" id="p_001248"><strong id="strong_000820" smilref="Machine_Learning00017.smil#strong_000820">Director of Community Marketing</strong></p>
          <p xml:space="preserve" id="p_001249" smilref="Machine_Learning00017.smil#p_001249">David Mayhew</p>
          <p xml:space="preserve" id="p_001250"><strong id="strong_000821" smilref="Machine_Learning00017.smil#strong_000821">Marketing Manager</strong></p>
          <p xml:space="preserve" id="p_001251" smilref="Machine_Learning00017.smil#p_001251">Carrie Sherrill</p>
          <p xml:space="preserve" id="p_001252"><strong id="strong_000822" smilref="Machine_Learning00017.smil#strong_000822">Business Manager</strong></p>
          <p xml:space="preserve" id="p_001253" smilref="Machine_Learning00017.smil#p_001253">Amy Knies</p>
          <p xml:space="preserve" id="p_001254"><strong id="strong_000823" smilref="Machine_Learning00017.smil#strong_000823">Professional Technology &amp; Strategy Director</strong></p>
          <p xml:space="preserve" id="p_001255" smilref="Machine_Learning00017.smil#p_001255">Barry Pruett</p>
          <p xml:space="preserve" id="p_001256"><strong id="strong_000824" smilref="Machine_Learning00017.smil#strong_000824">Associate Publisher</strong></p>
          <p xml:space="preserve" id="p_001257" smilref="Machine_Learning00017.smil#p_001257">Jim Minatel</p>
          <p xml:space="preserve" id="p_001258"><strong id="strong_000825" smilref="Machine_Learning00017.smil#strong_000825">Project Coordinator, Cover</strong></p>
          <p xml:space="preserve" id="p_001259" smilref="Machine_Learning00017.smil#p_001259">Patrick Redmond</p>
          <p xml:space="preserve" id="p_001260"><strong id="strong_000826" smilref="Machine_Learning00017.smil#strong_000826">Proofreader</strong></p>
          <p xml:space="preserve" id="p_001261" smilref="Machine_Learning00017.smil#p_001261">Nancy Carrasco</p>
          <p xml:space="preserve" id="p_001262"><strong id="strong_000827" smilref="Machine_Learning00017.smil#strong_000827">Indexer</strong></p>
          <p xml:space="preserve" id="p_001263" smilref="Machine_Learning00017.smil#p_001263">Johnna Dinse</p>
          <p xml:space="preserve" id="p_001264"><strong id="strong_000828" smilref="Machine_Learning00017.smil#strong_000828">Cover Designer</strong></p>
          <p xml:space="preserve" id="p_001265" smilref="Machine_Learning00017.smil#p_001265">Wiley</p>
          <p xml:space="preserve" id="p_001266"><strong id="strong_000829" smilref="Machine_Learning00017.smil#strong_000829">Cover Image</strong></p>
          <p xml:space="preserve" id="p_001267" smilref="Machine_Learning00017.smil#p_001267">© iStock.com/VLADGRIN</p>
        </section>
      </level1>
      <level1 id="f03">
        <section id="section_000019">
          <header id="header_000019">
            <h1 id="f03-f3" xml:space="preserve" smilref="Machine_Learning00017.smil#f03-f3">About the Author</h1>
          </header>
          <pagenum epub:type="pagebreak" id="pv" page="front" smilref="Machine_Learning00017.smil#pv">v</pagenum>
          <p xml:space="preserve" id="p_001268"><strong id="strong_000830" smilref="Machine_Learning00017.smil#strong_000830">Jason Bell</strong><span class="text" id="span_002760" smilref="Machine_Learning00017.smil#span_002760"> has been working with point-of-sale and customer-loyalty data since 2002, and he has been involved in software development for more than 25 years. He is founder of Datasentiment, a UK business that helps companies worldwide with data acquisition, processing, and insight.</span></p>
        </section>
      </level1>
      <level1 id="f04">
        <section id="section_000020">
          <header id="header_000020">
            <h1 id="f04-f4" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-f4">Acknowledgments</h1>
          </header>
          <pagenum epub:type="pagebreak" id="pvii" page="front" smilref="Machine_Learning00017.smil#pvii">vii</pagenum>
          <p xml:space="preserve" id="p_001269" smilref="Machine_Learning00017.smil#p_001269">During the autumn of 2013, I was presented with some interesting options: either do a research-based PhD or co-author a book on machine learning. One would take six years and the other would take seven to eight months. Because of the speed the data industry was, and still is, progressing, the idea of the book was more appealing because I would be able to get something out while it was still fresh and relevant, and that was more important to me.</p>
          <p id="f04-fother01-para-0002" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0002">I say “co-author” because the original plan was to write a machine learning book with Aidan Rogers. Due to circumstances beyond his control he had to pull out. With Aidan's blessing, I continued under my own steam, and for that opportunity I can't thank him enough for his grace, encouragement, and support in that decision.</p>
          <p id="f04-fother01-para-0003" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0003">Many thanks goes to Wiley, especially Executive Editor, Carol Long, for letting me tweak things here and there with the original concept and bring it to a more practical level than a theoretical one; Project Editor, Charlotte Kughen, who kept me on the straight and narrow when there were times I didn't make sense; and Mitchell Wyle for reviewing the technical side of things. Also big thanks to the Wiley family as a whole for looking after me with this project.</p>
          <p id="f04-fother01-para-0004" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0004">Over the years I've met and worked with some incredible people, so in no particular order here goes: Garrett Murphy, Clare Conway, Colin Mitchell, David Crozier, Edd Dumbill, Matt Biddulph, Jim Weber, Tara Simpson, Marty Neill, John Girvin, Greg O'Hanlon, Clare Rowland, Tim Spear, Ronan Cunningham, Tom Grey, Stevie Morrow, Steve Orr, Kevin Parker, John Reid, James Blundell, Mary McKenna, Mark Nagurski, Alan Hook, Jon Brookes, Conal Loughrey, Paul Graham, Frankie Colclough, and countless others (whom I will be kicking myself that I've forgotten) for all the meetings, the chats, the ideas, and the collaborations.</p>
          <pagenum epub:type="pagebreak" id="pviii" page="front" smilref="Machine_Learning00017.smil#pviii">viii</pagenum>
          <p id="f04-fother01-para-0005" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0005">Thanks to Tim Brundle, Matt Johnson, and Alan Thorburn for their support and for introducing me to the people who would inspire thoughts that would spur me on to bigger challenges with data. An enormous thank you to Thomas Spinks for having faith in me, without him there wouldn't have been a career in computing.</p>
          <p id="f04-fother01-para-0006" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0006">In relation to the challenge of writing a book I have to thank Ben Hammersley, Alistair Croll, Alasdair Allan, and John Foreman for their advice and support throughout the whole process.</p>
          <p id="f04-fother01-para-0007" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0007">I also must thank my dear friend, Colin McHale, who, on one late evening while waiting for the soccer data to refresh, taught me Perl on the back of a KitKat wrapper, thus kick-starting a journey of software development.</p>
          <p id="f04-fother01-para-0008" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0008">Finally, to my wife, Wendy, and my daughter, Clarissa, for absolutely everything and encouraging me to do this book to the best of my nerdy ability. I couldn't have done it without you both. And to the Bell family—George, Maggie and my sister Fern—who have encouraged my computing journey from a very early age.</p>
          <p id="f04-fother01-para-0009" xml:space="preserve" smilref="Machine_Learning00017.smil#f04-fother01-para-0009">During the course of writing this book, musical enlightenment was brought to me by St. Vincent, Trey Gunn, Suzanne Vega, Tackhead, Peter Gabriel, Doug Wimbish, King Crimson, and Level 42.</p>
        </section>
      </level1>
      <level1 id="f05">
        <section class="introduction" epub:type="introduction" id="section_000021">
          <header id="header_000021">
            <h1 id="f05-f5" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-f5">Introduction</h1>
          </header>
          <pagenum epub:type="pagebreak" id="pxix" page="front" smilref="Machine_Learning00017.smil#pxix">xix</pagenum>
          <p xml:space="preserve" id="p_001270" smilref="Machine_Learning00017.smil#p_001270">Data, data, data. You can't have escaped the headlines, reports, white papers, and even television coverage on the rise of Big Data and data science. The push is to learn, synthesize, and act upon all the data that comes out of social media, our phones, our hardware devices (otherwise known as “The Internet of Things”), sensors, and basically anything that can generate data.</p>
          <p id="f05-fintro-para-0002" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0002">The emphasis of most of this marketing is about data volumes and the velocity at which it arrives. Prophets of the data flood tell us we can't process this data fast enough, and the marketing machine will continue to hawk the services we need to buy to achieve all such speed. To some degree they are right, but it's worth stopping for a second and having a proper think about the task at hand.</p>
          <p id="f05-fintro-para-0003" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0003">Data mining and machine learning have been around for a number of years already, and the huge media push surrounding Big Data has to do with data volume. When you look at it closely, the machine learning algorithms that are being applied aren't any different from what they were years ago; what is new is how they are applied at scale. When you look at the number of organizations that are creating the data, it's really, in my opinion, the minority. Google, Facebook, Twitter, Netflix, and a small handful of others are the ones getting the majority of mentions in the headlines with a mixture of algorithmic learning and tools that enable them to scale. So, the real question you should ask is, “How does all this apply to the rest of us?”</p>
          <p id="f05-fintro-para-0004" xml:space="preserve"><span class="text" id="span_002761" smilref="Machine_Learning00017.smil#span_002761">I admit there will be times in this book when I look at the Big Data side of machine learning—it's a subject I can't ignore—but it's only a small factor in the overall picture of how to get insight from the available data. It is important to remember that I am talking about tools, and the key is figuring out which tools are right for the job you are trying to complete. Although the “tech press” </span><pagenum epub:type="pagebreak" id="pxx" page="front" smilref="Machine_Learning00017.smil#pxx">xx</pagenum><span class="text" id="span_002762" smilref="Machine_Learning00017.smil#span_002762">might want Hadoop stories, Hadoop is not always the right tool to use for the task you are trying to complete.</span></p>
          <level2 id="level2_000146">
            <h2 id="f05-c0x_level1_1" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_1">Aims of This Book</h2>
            <p xml:space="preserve" id="p_001271" smilref="Machine_Learning00017.smil#p_001271">This book is about machine learning and not about Big Data. It's about the various techniques used to gain insight from your data. By the end of the book, you will have seen how various methods of machine learning work, and you will also have had some practical explanations on how the code is put together, leaving you with a good idea of how you could apply the right machine learning techniques to your own problems.</p>
            <p id="f05-fintro-para-0006" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0006">There's no right or wrong way to use this book. You can start at the beginning and work your way through, or you can just dip in and out of the parts you need to know at the time you need to know them.</p>
          </level2>
          <level2 id="level2_000147">
            <h2 id="f05-c0x_level1_2" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_2">“Hands-On” Means Hands-On</h2>
            <p xml:space="preserve" id="p_001272" smilref="Machine_Learning00017.smil#p_001272">Many books on the subject of machine learning that I've read in the past have been very heavy on theory. That's not a bad thing. If you're looking for in-depth theory with really complex looking equations, I applaud your rigor. Me? I'm more hands-on with my approach to learning and to projects. My philosophy is quite simple:</p>
            <list type="ul" id="list_000075">
              <li id="li_000485" smilref="Machine_Learning00017.smil#li_000485">Start with a question in mind.</li>
              <li id="li_000486" smilref="Machine_Learning00017.smil#li_000486">Find the theory I need to learn.</li>
              <li id="li_000487" smilref="Machine_Learning00017.smil#li_000487">Find lots of examples I can learn from.</li>
              <li id="li_000488" smilref="Machine_Learning00017.smil#li_000488">Put them to work in my own projects.</li>
            </list>
            <p id="f05-fintro-para-0008" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0008">As a software developer, I personally like to see lots of examples. As a teacher, I like to get as much hands-on development time as possible but also get the message across to students as simply as possible. There's something about fingers on keys, coding away on your IDE, and getting things to work that's rather appealing, and it's something that I want to convey in the book.</p>
            <p id="f05-fintro-para-0009" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0009">Everyone has his or her own learning styles. I believe this book covers the most common methods, so everybody will benefit.</p>
          </level2>
          <level2 id="level2_000148">
            <h2 id="f05-c0x_level1_3" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_3">“What About the Math?”</h2>
            <p xml:space="preserve" id="p_001273"><span class="text" id="span_002763" smilref="Machine_Learning00017.smil#span_002763">Like arguing that your favorite football team is better than another, or trying to figure out whether Jimmy Page is a better guitarist than Jeff Beck </span><pagenum epub:type="pagebreak" id="pxxi" page="front" smilref="Machine_Learning00017.smil#pxxi">xxi</pagenum><span class="text" id="span_002764" smilref="Machine_Learning00017.smil#span_002764">(I prefer Beck), there are some things that will be debated forever and a day. One such debate is how much math you need to know before you can start to do machine learning.</span></p>
            <p id="f05-fintro-para-0011" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0011">Doing machine learning and learning the theory of machine learning are two very different subjects. To learn the theory, a good grounding in math is required. This book discusses a hands-on approach to machine learning. With the number of machine learning tools available for developers now, the emphasis is not so much on how these tools work but how you can make these tools work for you. The hard work has been done, and those who did it deserve to be credited and applauded.</p>
            <level3 id="level3_000245">
              <h3 xml:space="preserve" id="h3_000245" smilref="Machine_Learning00017.smil#h3_000245">“But You Need a PhD!”</h3>
              <p xml:space="preserve" id="p_001274" smilref="Machine_Learning00017.smil#p_001274">There's nothing like a statement from a peer to stop you dead in your tracks. A long-running debate rages about the level of knowledge you need before you can start doing analysis on data or claim that you are a “data scientist.” (I'll rip that term apart in a moment.) Personally, I believe that if you'd like to take a number of years completing a degree, then pursuing the likes of a master's degree and then a PhD, you should feel free to go that route. I'm a little more pragmatic about things and like to get reading and start doing.</p>
              <p id="f05-fintro-para-0013" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0013">Academia is great; and with the large number of online courses, papers, websites, and books on the subject of math, statistics, and data mining, there's enough to keep the most eager of minds occupied. I dip in and out of these resources a lot.</p>
              <p id="f05-fintro-para-0014" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0014">For me, though, there's nothing like getting my hands dirty, grabbing some data, trying out some methods, and looking at the results. If you need to brush up on linear regression theory, then let me reassure you now, there's plenty out there to read, and I'll also cover that in this book.</p>
              <p id="f05-fintro-para-0015" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0015">Lastly, can one gentleman or lady ever be a “data scientist?” I think it's more likely for a team of people to bring the various skills needed for machine learning into an organization. I talk about this some more in Chapter 2.</p>
              <p id="f05-fintro-para-0016" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0016">So, while others in the office are arguing whether to bring some PhD brains in on a project, you can be coding up a decision tree to see if it's viable.</p>
            </level3>
          </level2>
          <level2 id="level2_000149">
            <h2 id="f05-c0x_level1_4" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_4">What Will You Have Learned by the End?</h2>
            <p xml:space="preserve" id="p_001275" smilref="Machine_Learning00017.smil#p_001275">Assuming that you're reading the book from start to finish, you'll learn the common uses for machine learning, different methods of machine learning, and how to apply real-time and batch processing.</p>
            <p id="f05-fintro-para-0018" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0018">There's also nothing wrong with referencing a specific section that you want to learn. The chapters and examples were created in such a way that there's no dependency to learn one chapter over another.</p>
            <pagenum epub:type="pagebreak" id="pxxii" page="front" smilref="Machine_Learning00017.smil#pxxii">xxii</pagenum>
            <p id="f05-fintro-para-0019" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0019">The aim is to cover the common machine learning concepts in a practical manner. Using the existing free tools and libraries that are available to you, there's little stopping you from starting to gain insight from the existing data that you have.</p>
          </level2>
          <level2 id="level2_000150">
            <h2 id="f05-c0x_level1_5" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_5">Balancing Theory and Hands-On Learning</h2>
            <p xml:space="preserve" id="p_001276" smilref="Machine_Learning00017.smil#p_001276">There are many books on machine learning and data mining available, and finding the balance of theory and practical examples is hard. When planning this book I stressed the importance of practical and easy-to-use examples, providing step-by-step instruction, so you can see how things are put together.</p>
            <p id="f05-fintro-para-0021" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0021">I'm not saying that the theory is light, because it's not. Understanding what you want to learn or, more importantly, how you want to learn, will determine how you read this book.</p>
            <p id="f05-fintro-para-0022" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0022">The first two chapters focus on defining machine learning and data mining, using the tools and their results in the real world, and planning for machine learning. The main chapters (3 through 8) concentrate on the theory of different types of machine learning, using walkthrough tutorials, code fragments with explanations, and other handy things to ensure that you learn and retain the information presented.</p>
            <p id="f05-fintro-para-0023" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0023">Finally, you'll look at real-time and batch processing application methods and how they can integrate with each other. Then you'll look at Apache Spark and R, which is the language rooted in statistics.</p>
          </level2>
          <level2 id="level2_000151">
            <h2 id="f05-c0x_level1_6" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_6">Outline of the Chapters</h2>
            <p xml:space="preserve" id="p_001277" smilref="Machine_Learning00017.smil#p_001277">Chapter 1 considers the question, “What is machine learning?” and looks at the definition of machine learning, where it is used, and what type of algorithmic challenges you'll encounter. I also talk about the human side of machine learning and the need for future proofing your models and work.</p>
            <p id="f05-fintro-para-0025" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0025">Before any real coding can take place, you need to plan. Chapter 2, “How to Plan for Machine Learning,” concentrates on planning for machine learning. Planning includes engaging with data science teams, processing, defining storage requirements, protecting data privacy, cleaning data, and understanding that there is rarely one solution that fits all elements of your task. In Chapter 2 you also work through some handy Linux commands that will help you maintain the data before it goes for processing.</p>
            <p id="f05-fintro-para-0026" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0026">A decision tree is a common machine learning practice. Using results or observed behaviors and various input data (signals, features) in models, you can predict outcomes when presented with new data. Chapter 3 looks at designing decision tree learning with data and coding an example using Weka.</p>
            <pagenum epub:type="pagebreak" id="pxxiii" page="front" smilref="Machine_Learning00017.smil#pxxiii">xxiii</pagenum>
            <p id="f05-fintro-para-0027" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0027">Bayesian networks represent conditional dependencies against a set of random variables. In Chapter 4 you construct some simple examples to show you how Bayesian networks work and then look at some code to use.</p>
            <p id="f05-fintro-para-0028" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0028">Inspired by the workings of the central nervous system, neural network models are still used in deep learning systems. Chapter 5 looks at how this branch of machine learning works and shows you an example with inputs feeding information into a network.</p>
            <p id="f05-fintro-para-0029" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0029">If you are into basket analysis, then you'll like Chapter 6 on association rule learning and finding relations within large datasets. You'll have a close look at the Apriori algorithm and how it's used within the supermarket industry today.</p>
            <p id="f05-fintro-para-0030" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0030">Support vector machines are a supervised learning method to analyze data and recognize patterns. In Chapter 7 you look at text classification and other examples to see how it works.</p>
            <p id="f05-fintro-para-0031" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0031">Chapter 8 covers clustering—grouping objects—which is perfect for the likes of segmentation analysis in marketing. This approach is the best method of machine learning for attempting some trial-and-error suggestions during the initial learning phases.</p>
            <p id="f05-fintro-para-0032" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0032">Chapters 9 and 10 are walkthrough tutorials. The example in Chapter 9 concerns real-time processing. You use Spring XD, a “data ingesting engine,” and the streaming Twitter API to gather tweets as they happen.</p>
            <p id="f05-fintro-para-0033" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0033">In Chapter 10, you look at machine learning as a batch process. With the data acquired in Chapter 9, you set up a Hadoop cluster and run various jobs. You also look at the common issue of acquiring data from databases with Sqoop, performing customer recommendations with Mahout, and analyzing annual customer data with Hadoop and Pig.</p>
            <p id="f05-fintro-para-0034" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0034">Chapter 11 covers one of the newer entrants to the machine learning arena. The chapter looks at Apache Spark and also introduces you to the Scala language and performing SQL-like queries with in-memory data.</p>
            <p id="f05-fintro-para-0035" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0035">For a long time the R language has been used by statistics people the world over. Chapter 12 examines at the R language. With it you perform some of the machine learning algorithms covered in the previous chapters.</p>
          </level2>
          <level2 id="level2_000152">
            <h2 id="f05-c0x_level1_7" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_7">Source Code for This Book</h2>
            <p xml:space="preserve" id="p_001278"><span class="text" id="span_002765" smilref="Machine_Learning00017.smil#span_002765">All the code that is explained in the chapters of the book has been saved on a Github repository for you to download and try. The address for the repository is </span><a href="https://github.com/jasebell/mlbook" external="true" id="a_000343" smilref="Machine_Learning00017.smil#a_000343">https://github.com/jasebell/mlbook</a><span class="text" id="span_002766" smilref="Machine_Learning00017.smil#span_002766">. You can also find it on the Wiley website at </span><code xml:space="preserve" id="code_001270"><a href="http://www.wiley.com/go/machinelearning" external="true" id="a_000344" smilref="Machine_Learning00017.smil#a_000344">www.wiley.com/go/machinelearning</a></code><span class="text" id="span_002767" smilref="Machine_Learning00017.smil#span_002767">.</span></p>
            <p id="f05-fintro-para-0037" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0037">The examples are all in Java. If you want to extend your knowledge into other languages, then a search around the Github site might lead you to some interesting examples.</p>
            <pagenum epub:type="pagebreak" id="pxxiv" page="front" smilref="Machine_Learning00017.smil#pxxiv">xxiv</pagenum>
            <p id="f05-fintro-para-0038" xml:space="preserve"><span class="text" id="span_002768" smilref="Machine_Learning00017.smil#span_002768">Code has been separated by chapter; there's a folder in the repository for each of the chapters. If any extra libraries are required, there will be a note in the </span><code xml:space="preserve" id="code_001271" smilref="Machine_Learning00017.smil#code_001271">README</code><span class="text" id="span_002769" smilref="Machine_Learning00017.smil#span_002769"> file.</span></p>
          </level2>
          <level2 id="level2_000153">
            <h2 id="f05-c0x_level1_8" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-c0x_level1_8">Using Git</h2>
            <p xml:space="preserve" id="p_001279" smilref="Machine_Learning00017.smil#p_001279">Git is a version-control system that is widely used in business and the open source software community. If you are working in teams, it becomes very useful because you can create branches of codebase to work on then merge changes afterwards.</p>
            <p id="f05-fintro-para-0040" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0040">The uses for Git in this book are limited, but you need it for “cloning” the repository of examples if you want to use them.</p>
            <p id="f05-fintro-para-0041" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0041">To clone the examples for this book, use the following commands:</p>
            <p xml:space="preserve" id="p_001280"><code class="preserve-whitespace" xml:space="preserve" id="code_001272" smilref="Machine_Learning00017.smil#code_001272">$mkdir mlbookexamples
$cd mlbookexamples
$git clone https://github.com/jasebell/mlbook.git</code></p>
            <p id="f05-fintro-para-0042" xml:space="preserve" smilref="Machine_Learning00017.smil#f05-fintro-para-0042">You see the progress of the cloning and, when it's finished, you're able to change directory to the newly downloaded folder and look at the code samples.</p>
          </level2>
        </section>
      </level1>
      <level1 id="u9781118889497eula">
        <section class="EULAhead" epub:type="notice" id="section_000022">
          <header id="header_000022">
            <h1 id="u9781118889497eula-eula" xml:space="preserve" smilref="Machine_Learning00017.smil#u9781118889497eula-eula">WILEY END USER LICENSE AGREEMENT</h1>
          </header>
          <section class="EULA" id="section_000023">
            <p xml:space="preserve" id="p_001281"><span class="text" id="span_002770" smilref="Machine_Learning00017.smil#span_002770">Go to </span><a href="http://www.wiley.com/go/eula" external="true" id="a_000345" smilref="Machine_Learning00017.smil#a_000345">www.wiley.com/go/eula</a><span class="text" id="span_002771" smilref="Machine_Learning00017.smil#span_002771"> to access Wiley's ebook EULA. </span></p>
          </section>
        </section>
      </level1>
    </bodymatter>
  </book>
</dtbook>
